Classes: ['KICH', 'KIRC', 'KIRP']
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)
  (fc): Sequential(
    (0): Dropout(p=0.2)
    (1): Linear(in_features=512, out_features=3, bias=True)
  )
)
DEVICE cuda
[Train] Epoch: 0 [64/620022]    Loss: 0.025066   Batch Acc: 29.69
[Train] Epoch: 0 [128/620022]    Loss: 0.028015   Batch Acc: 25.00
[Train] Epoch: 0 [192/620022]    Loss: 0.025955   Batch Acc: 35.94
[Train] Epoch: 0 [256/620022]    Loss: 0.025203   Batch Acc: 29.69
[Train] Epoch: 0 [320/620022]    Loss: 0.026269   Batch Acc: 28.12
[Train] Epoch: 0 [384/620022]    Loss: 0.024050   Batch Acc: 34.38
[Train] Epoch: 0 [448/620022]    Loss: 0.022141   Batch Acc: 45.31
[Train] Epoch: 0 [512/620022]    Loss: 0.025471   Batch Acc: 34.38
[Train] Epoch: 0 [576/620022]    Loss: 0.025244   Batch Acc: 28.12
[Train] Epoch: 0 [640/620022]    Loss: 0.027825   Batch Acc: 20.31
[Train] Epoch: 0 [704/620022]    Loss: 0.024631   Batch Acc: 23.44
[Train] Epoch: 0 [768/620022]    Loss: 0.021827   Batch Acc: 39.06
[Train] Epoch: 0 [832/620022]    Loss: 0.022709   Batch Acc: 32.81
[Train] Epoch: 0 [896/620022]    Loss: 0.024670   Batch Acc: 32.81
[Train] Epoch: 0 [960/620022]    Loss: 0.024513   Batch Acc: 28.12
[Train] Epoch: 0 [1024/620022]    Loss: 0.025887   Batch Acc: 18.75
[Train] Epoch: 0 [1088/620022]    Loss: 0.025676   Batch Acc: 31.25
[Train] Epoch: 0 [1152/620022]    Loss: 0.022094   Batch Acc: 32.81
[Train] Epoch: 0 [1216/620022]    Loss: 0.021852   Batch Acc: 31.25
[Train] Epoch: 0 [1280/620022]    Loss: 0.021194   Batch Acc: 34.38
[Train] Epoch: 0 [1344/620022]    Loss: 0.021412   Batch Acc: 39.06
[Train] Epoch: 0 [1408/620022]    Loss: 0.020290   Batch Acc: 39.06
[Train] Epoch: 0 [1472/620022]    Loss: 0.023463   Batch Acc: 23.44
[Train] Epoch: 0 [1536/620022]    Loss: 0.022096   Batch Acc: 34.38
[Train] Epoch: 0 [1600/620022]    Loss: 0.020831   Batch Acc: 37.50
[Train] Epoch: 0 [1664/620022]    Loss: 0.021769   Batch Acc: 31.25
[Train] Epoch: 0 [1728/620022]    Loss: 0.021116   Batch Acc: 26.56
[Train] Epoch: 0 [1792/620022]    Loss: 0.021761   Batch Acc: 29.69
[Train] Epoch: 0 [1856/620022]    Loss: 0.021647   Batch Acc: 29.69
[Train] Epoch: 0 [1920/620022]    Loss: 0.020793   Batch Acc: 21.88
[Train] Epoch: 0 [1984/620022]    Loss: 0.022043   Batch Acc: 28.12
[Train] Epoch: 0 [2048/620022]    Loss: 0.018951   Batch Acc: 39.06
[Train] Epoch: 0 [2112/620022]    Loss: 0.020447   Batch Acc: 25.00
[Train] Epoch: 0 [2176/620022]    Loss: 0.020571   Batch Acc: 32.81
[Train] Epoch: 0 [2240/620022]    Loss: 0.022726   Batch Acc: 23.44
[Train] Epoch: 0 [2304/620022]    Loss: 0.018350   Batch Acc: 40.62
[Train] Epoch: 0 [2368/620022]    Loss: 0.021044   Batch Acc: 31.25
[Train] Epoch: 0 [2432/620022]    Loss: 0.022620   Batch Acc: 28.12
[Train] Epoch: 0 [2496/620022]    Loss: 0.020225   Batch Acc: 32.81
[Train] Epoch: 0 [2560/620022]    Loss: 0.021496   Batch Acc: 20.31
[Train] Epoch: 0 [2624/620022]    Loss: 0.019396   Batch Acc: 34.38
[Train] Epoch: 0 [2688/620022]    Loss: 0.021541   Batch Acc: 20.31
[Train] Epoch: 0 [2752/620022]    Loss: 0.021721   Batch Acc: 23.44
[Train] Epoch: 0 [2816/620022]    Loss: 0.020454   Batch Acc: 20.31
[Train] Epoch: 0 [2880/620022]    Loss: 0.020979   Batch Acc: 28.12
[Train] Epoch: 0 [2944/620022]    Loss: 0.020673   Batch Acc: 25.00
[Train] Epoch: 0 [3008/620022]    Loss: 0.019256   Batch Acc: 31.25
[Train] Epoch: 0 [3072/620022]    Loss: 0.019432   Batch Acc: 26.56
[Train] Epoch: 0 [3136/620022]    Loss: 0.020406   Batch Acc: 29.69
[Train] Epoch: 0 [3200/620022]    Loss: 0.019171   Batch Acc: 28.12
[Train] Epoch: 0 [3264/620022]    Loss: 0.020433   Batch Acc: 28.12
[Train] Epoch: 0 [3328/620022]    Loss: 0.020251   Batch Acc: 32.81
[Train] Epoch: 0 [3392/620022]    Loss: 0.018393   Batch Acc: 25.00
[Train] Epoch: 0 [3456/620022]    Loss: 0.020194   Batch Acc: 26.56
[Train] Epoch: 0 [3520/620022]    Loss: 0.020131   Batch Acc: 28.12
[Train] Epoch: 0 [3584/620022]    Loss: 0.019101   Batch Acc: 28.12
[Train] Epoch: 0 [3648/620022]    Loss: 0.018751   Batch Acc: 37.50
[Train] Epoch: 0 [3712/620022]    Loss: 0.019006   Batch Acc: 28.12
[Train] Epoch: 0 [3776/620022]    Loss: 0.018274   Batch Acc: 39.06
[Train] Epoch: 0 [3840/620022]    Loss: 0.017984   Batch Acc: 37.50
[Train] Epoch: 0 [3904/620022]    Loss: 0.019220   Batch Acc: 31.25
[Train] Epoch: 0 [3968/620022]    Loss: 0.018464   Batch Acc: 31.25
[Train] Epoch: 0 [4032/620022]    Loss: 0.021468   Batch Acc: 23.44
[Train] Epoch: 0 [4096/620022]    Loss: 0.019299   Batch Acc: 34.38
[Train] Epoch: 0 [4160/620022]    Loss: 0.018178   Batch Acc: 39.06
[Train] Epoch: 0 [4224/620022]    Loss: 0.018386   Batch Acc: 34.38
[Train] Epoch: 0 [4288/620022]    Loss: 0.020537   Batch Acc: 29.69
[Train] Epoch: 0 [4352/620022]    Loss: 0.019470   Batch Acc: 23.44
[Train] Epoch: 0 [4416/620022]    Loss: 0.017060   Batch Acc: 39.06
[Train] Epoch: 0 [4480/620022]    Loss: 0.019718   Batch Acc: 28.12
[Train] Epoch: 0 [4544/620022]    Loss: 0.019444   Batch Acc: 25.00
[Train] Epoch: 0 [4608/620022]    Loss: 0.019576   Batch Acc: 32.81
[Train] Epoch: 0 [4672/620022]    Loss: 0.019887   Batch Acc: 32.81
[Train] Epoch: 0 [4736/620022]    Loss: 0.019030   Batch Acc: 23.44
[Train] Epoch: 0 [4800/620022]    Loss: 0.019345   Batch Acc: 31.25
[Train] Epoch: 0 [4864/620022]    Loss: 0.018779   Batch Acc: 35.94
[Train] Epoch: 0 [4928/620022]    Loss: 0.018528   Batch Acc: 34.38
[Train] Epoch: 0 [4992/620022]    Loss: 0.019334   Batch Acc: 26.56
[Train] Epoch: 0 [5056/620022]    Loss: 0.018413   Batch Acc: 34.38
[Train] Epoch: 0 [5120/620022]    Loss: 0.019311   Batch Acc: 34.38
[Train] Epoch: 0 [5184/620022]    Loss: 0.018996   Batch Acc: 29.69
[Train] Epoch: 0 [5248/620022]    Loss: 0.019098   Batch Acc: 25.00
[Train] Epoch: 0 [5312/620022]    Loss: 0.016912   Batch Acc: 35.94
[Train] Epoch: 0 [5376/620022]    Loss: 0.017404   Batch Acc: 39.06
[Train] Epoch: 0 [5440/620022]    Loss: 0.018369   Batch Acc: 26.56
[Train] Epoch: 0 [5504/620022]    Loss: 0.018090   Batch Acc: 31.25
[Train] Epoch: 0 [5568/620022]    Loss: 0.018084   Batch Acc: 28.12
[Train] Epoch: 0 [5632/620022]    Loss: 0.017908   Batch Acc: 39.06
[Train] Epoch: 0 [5696/620022]    Loss: 0.020649   Batch Acc: 25.00
[Train] Epoch: 0 [5760/620022]    Loss: 0.017396   Batch Acc: 32.81
[Train] Epoch: 0 [5824/620022]    Loss: 0.017930   Batch Acc: 32.81
[Train] Epoch: 0 [5888/620022]    Loss: 0.019669   Batch Acc: 34.38
[Train] Epoch: 0 [5952/620022]    Loss: 0.018628   Batch Acc: 31.25
[Train] Epoch: 0 [6016/620022]    Loss: 0.018920   Batch Acc: 31.25
[Train] Epoch: 0 [6080/620022]    Loss: 0.017689   Batch Acc: 34.38
[Train] Epoch: 0 [6144/620022]    Loss: 0.019563   Batch Acc: 28.12
[Train] Epoch: 0 [6208/620022]    Loss: 0.017584   Batch Acc: 37.50
[Train] Epoch: 0 [6272/620022]    Loss: 0.018033   Batch Acc: 31.25
[Train] Epoch: 0 [6336/620022]    Loss: 0.019135   Batch Acc: 32.81
[Train] Epoch: 0 [6400/620022]    Loss: 0.018667   Batch Acc: 32.81
[Train] Epoch: 0 [6464/620022]    Loss: 0.017952   Batch Acc: 34.38
[Train] Epoch: 0 [6528/620022]    Loss: 0.018696   Batch Acc: 32.81
[Train] Epoch: 0 [6592/620022]    Loss: 0.018231   Batch Acc: 29.69
[Train] Epoch: 0 [6656/620022]    Loss: 0.017880   Batch Acc: 31.25
[Train] Epoch: 0 [6720/620022]    Loss: 0.020605   Batch Acc: 14.06
[Train] Epoch: 0 [6784/620022]    Loss: 0.018979   Batch Acc: 34.38
[Train] Epoch: 0 [6848/620022]    Loss: 0.020085   Batch Acc: 25.00
[Train] Epoch: 0 [6912/620022]    Loss: 0.017984   Batch Acc: 35.94
[Train] Epoch: 0 [6976/620022]    Loss: 0.017613   Batch Acc: 34.38
[Train] Epoch: 0 [7040/620022]    Loss: 0.019646   Batch Acc: 25.00
[Train] Epoch: 0 [7104/620022]    Loss: 0.018800   Batch Acc: 31.25
[Train] Epoch: 0 [7168/620022]    Loss: 0.017734   Batch Acc: 32.81
[Train] Epoch: 0 [7232/620022]    Loss: 0.017697   Batch Acc: 43.75
[Train] Epoch: 0 [7296/620022]    Loss: 0.018398   Batch Acc: 34.38
[Train] Epoch: 0 [7360/620022]    Loss: 0.018971   Batch Acc: 26.56
[Train] Epoch: 0 [7424/620022]    Loss: 0.018038   Batch Acc: 39.06
[Train] Epoch: 0 [7488/620022]    Loss: 0.019060   Batch Acc: 28.12
[Train] Epoch: 0 [7552/620022]    Loss: 0.018406   Batch Acc: 31.25
[Train] Epoch: 0 [7616/620022]    Loss: 0.018379   Batch Acc: 31.25
[Train] Epoch: 0 [7680/620022]    Loss: 0.018145   Batch Acc: 37.50
[Train] Epoch: 0 [7744/620022]    Loss: 0.018342   Batch Acc: 37.50
[Train] Epoch: 0 [7808/620022]    Loss: 0.017780   Batch Acc: 34.38
[Train] Epoch: 0 [7872/620022]    Loss: 0.019105   Batch Acc: 31.25
[Train] Epoch: 0 [7936/620022]    Loss: 0.018792   Batch Acc: 29.69
[Train] Epoch: 0 [8000/620022]    Loss: 0.017559   Batch Acc: 29.69
[Train] Epoch: 0 [8064/620022]    Loss: 0.019356   Batch Acc: 28.12
[Train] Epoch: 0 [8128/620022]    Loss: 0.017869   Batch Acc: 35.94
[Train] Epoch: 0 [8192/620022]    Loss: 0.017189   Batch Acc: 42.19
[Train] Epoch: 0 [8256/620022]    Loss: 0.017740   Batch Acc: 35.94
[Train] Epoch: 0 [8320/620022]    Loss: 0.016416   Batch Acc: 48.44
[Train] Epoch: 0 [8384/620022]    Loss: 0.019045   Batch Acc: 34.38
[Train] Epoch: 0 [8448/620022]    Loss: 0.016585   Batch Acc: 40.62
[Train] Epoch: 0 [8512/620022]    Loss: 0.017092   Batch Acc: 40.62
[Train] Epoch: 0 [8576/620022]    Loss: 0.018288   Batch Acc: 37.50
[Train] Epoch: 0 [8640/620022]    Loss: 0.018498   Batch Acc: 29.69
[Train] Epoch: 0 [8704/620022]    Loss: 0.019240   Batch Acc: 31.25
[Train] Epoch: 0 [8768/620022]    Loss: 0.018508   Batch Acc: 34.38
[Train] Epoch: 0 [8832/620022]    Loss: 0.017584   Batch Acc: 34.38
[Train] Epoch: 0 [8896/620022]    Loss: 0.018438   Batch Acc: 31.25
[Train] Epoch: 0 [8960/620022]    Loss: 0.018959   Batch Acc: 28.12
[Train] Epoch: 0 [9024/620022]    Loss: 0.017336   Batch Acc: 42.19
[Train] Epoch: 0 [9088/620022]    Loss: 0.018836   Batch Acc: 32.81
[Train] Epoch: 0 [9152/620022]    Loss: 0.018591   Batch Acc: 26.56
[Train] Epoch: 0 [9216/620022]    Loss: 0.017383   Batch Acc: 29.69
[Train] Epoch: 0 [9280/620022]    Loss: 0.017404   Batch Acc: 39.06
[Train] Epoch: 0 [9344/620022]    Loss: 0.017045   Batch Acc: 37.50
[Train] Epoch: 0 [9408/620022]    Loss: 0.017685   Batch Acc: 37.50
[Train] Epoch: 0 [9472/620022]    Loss: 0.016662   Batch Acc: 43.75
[Train] Epoch: 0 [9536/620022]    Loss: 0.018468   Batch Acc: 32.81
[Train] Epoch: 0 [9600/620022]    Loss: 0.016860   Batch Acc: 40.62
[Train] Epoch: 0 [9664/620022]    Loss: 0.018082   Batch Acc: 31.25
[Train] Epoch: 0 [9728/620022]    Loss: 0.018163   Batch Acc: 34.38
[Train] Epoch: 0 [9792/620022]    Loss: 0.017197   Batch Acc: 35.94
[Train] Epoch: 0 [9856/620022]    Loss: 0.015549   Batch Acc: 53.12
[Train] Epoch: 0 [9920/620022]    Loss: 0.018114   Batch Acc: 37.50
[Train] Epoch: 0 [9984/620022]    Loss: 0.017315   Batch Acc: 39.06
[Train] Epoch: 0 [10048/620022]    Loss: 0.017895   Batch Acc: 32.81
[Train] Epoch: 0 [10112/620022]    Loss: 0.017914   Batch Acc: 37.50
[Train] Epoch: 0 [10176/620022]    Loss: 0.019439   Batch Acc: 37.50
[Train] Epoch: 0 [10240/620022]    Loss: 0.018571   Batch Acc: 31.25
[Train] Epoch: 0 [10304/620022]    Loss: 0.018780   Batch Acc: 28.12
[Train] Epoch: 0 [10368/620022]    Loss: 0.017049   Batch Acc: 29.69
[Train] Epoch: 0 [10432/620022]    Loss: 0.017944   Batch Acc: 28.12
[Train] Epoch: 0 [10496/620022]    Loss: 0.015520   Batch Acc: 46.88
[Train] Epoch: 0 [10560/620022]    Loss: 0.016975   Batch Acc: 48.44
[Train] Epoch: 0 [10624/620022]    Loss: 0.017039   Batch Acc: 40.62
[Train] Epoch: 0 [10688/620022]    Loss: 0.018711   Batch Acc: 25.00
[Train] Epoch: 0 [10752/620022]    Loss: 0.017029   Batch Acc: 35.94
[Train] Epoch: 0 [10816/620022]    Loss: 0.018698   Batch Acc: 29.69
[Train] Epoch: 0 [10880/620022]    Loss: 0.016352   Batch Acc: 39.06
[Train] Epoch: 0 [10944/620022]    Loss: 0.018251   Batch Acc: 34.38
[Train] Epoch: 0 [11008/620022]    Loss: 0.016947   Batch Acc: 51.56
[Train] Epoch: 0 [11072/620022]    Loss: 0.016947   Batch Acc: 34.38
[Train] Epoch: 0 [11136/620022]    Loss: 0.017783   Batch Acc: 29.69
[Train] Epoch: 0 [11200/620022]    Loss: 0.017832   Batch Acc: 39.06
[Train] Epoch: 0 [11264/620022]    Loss: 0.016530   Batch Acc: 39.06
[Train] Epoch: 0 [11328/620022]    Loss: 0.017472   Batch Acc: 39.06
[Train] Epoch: 0 [11392/620022]    Loss: 0.015644   Batch Acc: 56.25
[Train] Epoch: 0 [11456/620022]    Loss: 0.016956   Batch Acc: 50.00
[Train] Epoch: 0 [11520/620022]    Loss: 0.017672   Batch Acc: 39.06
[Train] Epoch: 0 [11584/620022]    Loss: 0.018379   Batch Acc: 37.50
[Train] Epoch: 0 [11648/620022]    Loss: 0.016740   Batch Acc: 32.81
[Train] Epoch: 0 [11712/620022]    Loss: 0.017107   Batch Acc: 39.06
[Train] Epoch: 0 [11776/620022]    Loss: 0.017208   Batch Acc: 37.50
[Train] Epoch: 0 [11840/620022]    Loss: 0.015390   Batch Acc: 54.69
[Train] Epoch: 0 [11904/620022]    Loss: 0.018535   Batch Acc: 35.94
[Train] Epoch: 0 [11968/620022]    Loss: 0.016258   Batch Acc: 43.75
[Train] Epoch: 0 [12032/620022]    Loss: 0.017248   Batch Acc: 37.50
[Train] Epoch: 0 [12096/620022]    Loss: 0.016795   Batch Acc: 48.44
[Train] Epoch: 0 [12160/620022]    Loss: 0.017754   Batch Acc: 43.75
[Train] Epoch: 0 [12224/620022]    Loss: 0.017871   Batch Acc: 32.81
[Train] Epoch: 0 [12288/620022]    Loss: 0.016283   Batch Acc: 43.75
[Train] Epoch: 0 [12352/620022]    Loss: 0.018348   Batch Acc: 31.25
[Train] Epoch: 0 [12416/620022]    Loss: 0.016211   Batch Acc: 37.50
[Train] Epoch: 0 [12480/620022]    Loss: 0.015611   Batch Acc: 51.56
[Train] Epoch: 0 [12544/620022]    Loss: 0.018969   Batch Acc: 32.81
[Train] Epoch: 0 [12608/620022]    Loss: 0.017313   Batch Acc: 45.31
[Train] Epoch: 0 [12672/620022]    Loss: 0.017960   Batch Acc: 34.38
[Train] Epoch: 0 [12736/620022]    Loss: 0.016672   Batch Acc: 42.19
[Train] Epoch: 0 [12800/620022]    Loss: 0.017872   Batch Acc: 42.19
[Train] Epoch: 0 [12864/620022]    Loss: 0.017023   Batch Acc: 35.94
[Train] Epoch: 0 [12928/620022]    Loss: 0.016070   Batch Acc: 39.06
[Train] Epoch: 0 [12992/620022]    Loss: 0.016939   Batch Acc: 39.06
[Train] Epoch: 0 [13056/620022]    Loss: 0.016226   Batch Acc: 46.88
[Train] Epoch: 0 [13120/620022]    Loss: 0.017265   Batch Acc: 37.50
[Train] Epoch: 0 [13184/620022]    Loss: 0.017323   Batch Acc: 31.25
[Train] Epoch: 0 [13248/620022]    Loss: 0.018218   Batch Acc: 29.69
[Train] Epoch: 0 [13312/620022]    Loss: 0.017060   Batch Acc: 40.62
[Train] Epoch: 0 [13376/620022]    Loss: 0.017198   Batch Acc: 35.94
[Train] Epoch: 0 [13440/620022]    Loss: 0.016257   Batch Acc: 43.75
[Train] Epoch: 0 [13504/620022]    Loss: 0.016489   Batch Acc: 51.56
[Train] Epoch: 0 [13568/620022]    Loss: 0.016612   Batch Acc: 35.94
[Train] Epoch: 0 [13632/620022]    Loss: 0.017393   Batch Acc: 32.81
[Train] Epoch: 0 [13696/620022]    Loss: 0.015971   Batch Acc: 50.00
[Train] Epoch: 0 [13760/620022]    Loss: 0.016529   Batch Acc: 40.62
[Train] Epoch: 0 [13824/620022]    Loss: 0.016495   Batch Acc: 37.50
[Train] Epoch: 0 [13888/620022]    Loss: 0.017194   Batch Acc: 39.06
[Train] Epoch: 0 [13952/620022]    Loss: 0.017087   Batch Acc: 40.62
[Train] Epoch: 0 [14016/620022]    Loss: 0.016626   Batch Acc: 39.06
[Train] Epoch: 0 [14080/620022]    Loss: 0.017510   Batch Acc: 37.50
[Train] Epoch: 0 [14144/620022]    Loss: 0.016458   Batch Acc: 40.62
[Train] Epoch: 0 [14208/620022]    Loss: 0.017586   Batch Acc: 40.62
[Train] Epoch: 0 [14272/620022]    Loss: 0.017223   Batch Acc: 42.19
[Train] Epoch: 0 [14336/620022]    Loss: 0.017359   Batch Acc: 39.06
[Train] Epoch: 0 [14400/620022]    Loss: 0.017973   Batch Acc: 40.62
[Train] Epoch: 0 [14464/620022]    Loss: 0.017382   Batch Acc: 46.88
[Train] Epoch: 0 [14528/620022]    Loss: 0.016696   Batch Acc: 43.75
[Train] Epoch: 0 [14592/620022]    Loss: 0.016642   Batch Acc: 53.12
[Train] Epoch: 0 [14656/620022]    Loss: 0.016865   Batch Acc: 46.88
[Train] Epoch: 0 [14720/620022]    Loss: 0.017242   Batch Acc: 42.19
[Train] Epoch: 0 [14784/620022]    Loss: 0.016471   Batch Acc: 37.50
[Train] Epoch: 0 [14848/620022]    Loss: 0.015225   Batch Acc: 54.69
[Train] Epoch: 0 [14912/620022]    Loss: 0.016868   Batch Acc: 43.75
[Train] Epoch: 0 [14976/620022]    Loss: 0.016479   Batch Acc: 42.19
[Train] Epoch: 0 [15040/620022]    Loss: 0.016141   Batch Acc: 40.62
[Train] Epoch: 0 [15104/620022]    Loss: 0.016544   Batch Acc: 45.31
[Train] Epoch: 0 [15168/620022]    Loss: 0.015985   Batch Acc: 48.44
[Train] Epoch: 0 [15232/620022]    Loss: 0.016044   Batch Acc: 43.75
[Train] Epoch: 0 [15296/620022]    Loss: 0.017535   Batch Acc: 39.06
[Train] Epoch: 0 [15360/620022]    Loss: 0.016203   Batch Acc: 42.19
[Train] Epoch: 0 [15424/620022]    Loss: 0.017385   Batch Acc: 34.38
[Train] Epoch: 0 [15488/620022]    Loss: 0.016604   Batch Acc: 37.50
[Train] Epoch: 0 [15552/620022]    Loss: 0.015895   Batch Acc: 45.31
[Train] Epoch: 0 [15616/620022]    Loss: 0.016410   Batch Acc: 45.31
[Train] Epoch: 0 [15680/620022]    Loss: 0.015383   Batch Acc: 51.56
[Train] Epoch: 0 [15744/620022]    Loss: 0.016455   Batch Acc: 48.44
[Train] Epoch: 0 [15808/620022]    Loss: 0.017238   Batch Acc: 40.62
[Train] Epoch: 0 [15872/620022]    Loss: 0.017044   Batch Acc: 35.94
[Train] Epoch: 0 [15936/620022]    Loss: 0.014978   Batch Acc: 57.81
[Train] Epoch: 0 [16000/620022]    Loss: 0.015819   Batch Acc: 48.44
[Train] Epoch: 0 [16064/620022]    Loss: 0.016220   Batch Acc: 48.44
[Train] Epoch: 0 [16128/620022]    Loss: 0.015671   Batch Acc: 46.88
[Train] Epoch: 0 [16192/620022]    Loss: 0.014478   Batch Acc: 53.12
[Train] Epoch: 0 [16256/620022]    Loss: 0.015745   Batch Acc: 51.56
[Train] Epoch: 0 [16320/620022]    Loss: 0.017529   Batch Acc: 39.06
[Train] Epoch: 0 [16384/620022]    Loss: 0.014996   Batch Acc: 51.56
[Train] Epoch: 0 [16448/620022]    Loss: 0.016002   Batch Acc: 45.31
[Train] Epoch: 0 [16512/620022]    Loss: 0.015955   Batch Acc: 42.19
[Train] Epoch: 0 [16576/620022]    Loss: 0.016963   Batch Acc: 37.50
[Train] Epoch: 0 [16640/620022]    Loss: 0.015443   Batch Acc: 59.38
[Train] Epoch: 0 [16704/620022]    Loss: 0.017187   Batch Acc: 43.75
[Train] Epoch: 0 [16768/620022]    Loss: 0.015129   Batch Acc: 57.81
[Train] Epoch: 0 [16832/620022]    Loss: 0.014626   Batch Acc: 51.56
[Train] Epoch: 0 [16896/620022]    Loss: 0.015675   Batch Acc: 56.25
[Train] Epoch: 0 [16960/620022]    Loss: 0.017753   Batch Acc: 43.75
[Train] Epoch: 0 [17024/620022]    Loss: 0.015960   Batch Acc: 50.00
[Train] Epoch: 0 [17088/620022]    Loss: 0.015465   Batch Acc: 46.88
[Train] Epoch: 0 [17152/620022]    Loss: 0.015877   Batch Acc: 37.50
[Train] Epoch: 0 [17216/620022]    Loss: 0.015422   Batch Acc: 57.81
[Train] Epoch: 0 [17280/620022]    Loss: 0.015884   Batch Acc: 46.88
[Train] Epoch: 0 [17344/620022]    Loss: 0.017495   Batch Acc: 39.06
[Train] Epoch: 0 [17408/620022]    Loss: 0.015335   Batch Acc: 54.69
[Train] Epoch: 0 [17472/620022]    Loss: 0.015443   Batch Acc: 50.00
[Train] Epoch: 0 [17536/620022]    Loss: 0.015935   Batch Acc: 46.88
[Train] Epoch: 0 [17600/620022]    Loss: 0.016775   Batch Acc: 42.19
[Train] Epoch: 0 [17664/620022]    Loss: 0.016821   Batch Acc: 43.75
[Train] Epoch: 0 [17728/620022]    Loss: 0.015199   Batch Acc: 51.56
[Train] Epoch: 0 [17792/620022]    Loss: 0.015456   Batch Acc: 54.69
[Train] Epoch: 0 [17856/620022]    Loss: 0.016150   Batch Acc: 48.44
[Train] Epoch: 0 [17920/620022]    Loss: 0.015707   Batch Acc: 46.88
[Train] Epoch: 0 [17984/620022]    Loss: 0.016194   Batch Acc: 43.75
[Train] Epoch: 0 [18048/620022]    Loss: 0.016890   Batch Acc: 40.62
[Train] Epoch: 0 [18112/620022]    Loss: 0.015998   Batch Acc: 43.75
[Train] Epoch: 0 [18176/620022]    Loss: 0.015297   Batch Acc: 53.12
[Train] Epoch: 0 [18240/620022]    Loss: 0.016365   Batch Acc: 39.06
[Train] Epoch: 0 [18304/620022]    Loss: 0.015264   Batch Acc: 56.25
[Train] Epoch: 0 [18368/620022]    Loss: 0.016495   Batch Acc: 40.62
[Train] Epoch: 0 [18432/620022]    Loss: 0.015924   Batch Acc: 51.56
[Train] Epoch: 0 [18496/620022]    Loss: 0.015714   Batch Acc: 43.75
[Train] Epoch: 0 [18560/620022]    Loss: 0.015922   Batch Acc: 45.31
[Train] Epoch: 0 [18624/620022]    Loss: 0.016255   Batch Acc: 48.44
[Train] Epoch: 0 [18688/620022]    Loss: 0.016580   Batch Acc: 51.56
[Train] Epoch: 0 [18752/620022]    Loss: 0.015104   Batch Acc: 51.56
[Train] Epoch: 0 [18816/620022]    Loss: 0.015747   Batch Acc: 42.19
[Train] Epoch: 0 [18880/620022]    Loss: 0.016063   Batch Acc: 46.88
[Train] Epoch: 0 [18944/620022]    Loss: 0.016415   Batch Acc: 45.31
[Train] Epoch: 0 [19008/620022]    Loss: 0.014928   Batch Acc: 54.69
[Train] Epoch: 0 [19072/620022]    Loss: 0.015854   Batch Acc: 45.31
[Train] Epoch: 0 [19136/620022]    Loss: 0.014664   Batch Acc: 54.69
[Train] Epoch: 0 [19200/620022]    Loss: 0.015010   Batch Acc: 50.00
[Train] Epoch: 0 [19264/620022]    Loss: 0.014723   Batch Acc: 53.12
[Train] Epoch: 0 [19328/620022]    Loss: 0.016285   Batch Acc: 46.88
[Train] Epoch: 0 [19392/620022]    Loss: 0.016455   Batch Acc: 46.88
[Train] Epoch: 0 [19456/620022]    Loss: 0.016942   Batch Acc: 40.62
[Train] Epoch: 0 [19520/620022]    Loss: 0.015518   Batch Acc: 46.88
[Train] Epoch: 0 [19584/620022]    Loss: 0.016544   Batch Acc: 45.31
[Train] Epoch: 0 [19648/620022]    Loss: 0.016244   Batch Acc: 46.88
[Train] Epoch: 0 [19712/620022]    Loss: 0.014075   Batch Acc: 57.81
[Train] Epoch: 0 [19776/620022]    Loss: 0.015881   Batch Acc: 48.44
[Train] Epoch: 0 [19840/620022]    Loss: 0.016386   Batch Acc: 48.44
[Train] Epoch: 0 [19904/620022]    Loss: 0.015794   Batch Acc: 48.44
[Train] Epoch: 0 [19968/620022]    Loss: 0.015665   Batch Acc: 53.12
[Train] Epoch: 0 [20032/620022]    Loss: 0.014900   Batch Acc: 59.38
[Train] Epoch: 0 [20096/620022]    Loss: 0.015056   Batch Acc: 53.12
[Train] Epoch: 0 [20160/620022]    Loss: 0.015875   Batch Acc: 46.88
[Train] Epoch: 0 [20224/620022]    Loss: 0.014914   Batch Acc: 50.00
[Train] Epoch: 0 [20288/620022]    Loss: 0.015324   Batch Acc: 48.44
[Train] Epoch: 0 [20352/620022]    Loss: 0.016533   Batch Acc: 39.06
[Train] Epoch: 0 [20416/620022]    Loss: 0.016438   Batch Acc: 43.75
[Train] Epoch: 0 [20480/620022]    Loss: 0.016034   Batch Acc: 48.44
[Train] Epoch: 0 [20544/620022]    Loss: 0.016047   Batch Acc: 48.44
[Train] Epoch: 0 [20608/620022]    Loss: 0.015846   Batch Acc: 42.19
[Train] Epoch: 0 [20672/620022]    Loss: 0.015354   Batch Acc: 53.12
[Train] Epoch: 0 [20736/620022]    Loss: 0.016176   Batch Acc: 46.88
[Train] Epoch: 0 [20800/620022]    Loss: 0.014604   Batch Acc: 54.69
[Train] Epoch: 0 [20864/620022]    Loss: 0.018195   Batch Acc: 35.94
[Train] Epoch: 0 [20928/620022]    Loss: 0.015336   Batch Acc: 48.44
[Train] Epoch: 0 [20992/620022]    Loss: 0.015880   Batch Acc: 48.44
[Train] Epoch: 0 [21056/620022]    Loss: 0.015265   Batch Acc: 48.44
[Train] Epoch: 0 [21120/620022]    Loss: 0.014923   Batch Acc: 56.25
[Train] Epoch: 0 [21184/620022]    Loss: 0.015581   Batch Acc: 46.88
[Train] Epoch: 0 [21248/620022]    Loss: 0.015283   Batch Acc: 53.12
[Train] Epoch: 0 [21312/620022]    Loss: 0.017699   Batch Acc: 35.94
[Train] Epoch: 0 [21376/620022]    Loss: 0.014107   Batch Acc: 56.25
[Train] Epoch: 0 [21440/620022]    Loss: 0.015247   Batch Acc: 50.00
[Train] Epoch: 0 [21504/620022]    Loss: 0.016117   Batch Acc: 43.75
[Train] Epoch: 0 [21568/620022]    Loss: 0.014961   Batch Acc: 57.81
[Train] Epoch: 0 [21632/620022]    Loss: 0.013335   Batch Acc: 65.62
[Train] Epoch: 0 [21696/620022]    Loss: 0.016647   Batch Acc: 45.31
[Train] Epoch: 0 [21760/620022]    Loss: 0.015473   Batch Acc: 46.88
[Train] Epoch: 0 [21824/620022]    Loss: 0.014130   Batch Acc: 60.94
[Train] Epoch: 0 [21888/620022]    Loss: 0.014711   Batch Acc: 57.81
[Train] Epoch: 0 [21952/620022]    Loss: 0.015941   Batch Acc: 50.00
[Train] Epoch: 0 [22016/620022]    Loss: 0.014441   Batch Acc: 53.12
[Train] Epoch: 0 [22080/620022]    Loss: 0.015684   Batch Acc: 51.56
[Train] Epoch: 0 [22144/620022]    Loss: 0.015523   Batch Acc: 51.56
[Train] Epoch: 0 [22208/620022]    Loss: 0.017358   Batch Acc: 31.25
[Train] Epoch: 0 [22272/620022]    Loss: 0.014260   Batch Acc: 56.25
[Train] Epoch: 0 [22336/620022]    Loss: 0.014575   Batch Acc: 57.81
[Train] Epoch: 0 [22400/620022]    Loss: 0.016612   Batch Acc: 50.00
[Train] Epoch: 0 [22464/620022]    Loss: 0.016008   Batch Acc: 46.88
[Train] Epoch: 0 [22528/620022]    Loss: 0.015679   Batch Acc: 51.56
[Train] Epoch: 0 [22592/620022]    Loss: 0.015636   Batch Acc: 50.00
[Train] Epoch: 0 [22656/620022]    Loss: 0.014857   Batch Acc: 57.81
[Train] Epoch: 0 [22720/620022]    Loss: 0.015810   Batch Acc: 51.56
[Train] Epoch: 0 [22784/620022]    Loss: 0.015819   Batch Acc: 50.00
[Train] Epoch: 0 [22848/620022]    Loss: 0.016005   Batch Acc: 42.19
[Train] Epoch: 0 [22912/620022]    Loss: 0.017691   Batch Acc: 37.50
[Train] Epoch: 0 [22976/620022]    Loss: 0.014490   Batch Acc: 57.81
[Train] Epoch: 0 [23040/620022]    Loss: 0.015427   Batch Acc: 46.88
[Train] Epoch: 0 [23104/620022]    Loss: 0.014830   Batch Acc: 54.69
[Train] Epoch: 0 [23168/620022]    Loss: 0.015054   Batch Acc: 53.12
[Train] Epoch: 0 [23232/620022]    Loss: 0.014889   Batch Acc: 51.56
[Train] Epoch: 0 [23296/620022]    Loss: 0.015073   Batch Acc: 48.44
[Train] Epoch: 0 [23360/620022]    Loss: 0.017047   Batch Acc: 43.75
[Train] Epoch: 0 [23424/620022]    Loss: 0.014125   Batch Acc: 59.38
[Train] Epoch: 0 [23488/620022]    Loss: 0.016615   Batch Acc: 29.69
[Train] Epoch: 0 [23552/620022]    Loss: 0.014545   Batch Acc: 56.25
[Train] Epoch: 0 [23616/620022]    Loss: 0.015453   Batch Acc: 53.12
[Train] Epoch: 0 [23680/620022]    Loss: 0.015073   Batch Acc: 46.88
[Train] Epoch: 0 [23744/620022]    Loss: 0.016108   Batch Acc: 50.00
[Train] Epoch: 0 [23808/620022]    Loss: 0.015013   Batch Acc: 51.56
[Train] Epoch: 0 [23872/620022]    Loss: 0.015834   Batch Acc: 50.00
[Train] Epoch: 0 [23936/620022]    Loss: 0.014315   Batch Acc: 59.38
[Train] Epoch: 0 [24000/620022]    Loss: 0.015080   Batch Acc: 46.88
[Train] Epoch: 0 [24064/620022]    Loss: 0.014982   Batch Acc: 54.69
[Train] Epoch: 0 [24128/620022]    Loss: 0.014823   Batch Acc: 50.00
[Train] Epoch: 0 [24192/620022]    Loss: 0.012883   Batch Acc: 60.94
[Train] Epoch: 0 [24256/620022]    Loss: 0.016634   Batch Acc: 45.31
[Train] Epoch: 0 [24320/620022]    Loss: 0.015192   Batch Acc: 51.56
[Train] Epoch: 0 [24384/620022]    Loss: 0.014014   Batch Acc: 57.81
[Train] Epoch: 0 [24448/620022]    Loss: 0.014397   Batch Acc: 54.69
[Train] Epoch: 0 [24512/620022]    Loss: 0.015245   Batch Acc: 56.25
[Train] Epoch: 0 [24576/620022]    Loss: 0.015808   Batch Acc: 51.56
[Train] Epoch: 0 [24640/620022]    Loss: 0.013822   Batch Acc: 53.12
[Train] Epoch: 0 [24704/620022]    Loss: 0.015526   Batch Acc: 43.75
[Train] Epoch: 0 [24768/620022]    Loss: 0.015090   Batch Acc: 48.44
[Train] Epoch: 0 [24832/620022]    Loss: 0.013572   Batch Acc: 67.19
[Train] Epoch: 0 [24896/620022]    Loss: 0.015019   Batch Acc: 57.81
[Train] Epoch: 0 [24960/620022]    Loss: 0.014840   Batch Acc: 57.81
[Train] Epoch: 0 [25024/620022]    Loss: 0.013959   Batch Acc: 64.06
[Train] Epoch: 0 [25088/620022]    Loss: 0.015419   Batch Acc: 50.00
[Train] Epoch: 0 [25152/620022]    Loss: 0.015555   Batch Acc: 46.88
[Train] Epoch: 0 [25216/620022]    Loss: 0.015442   Batch Acc: 53.12
[Train] Epoch: 0 [25280/620022]    Loss: 0.015418   Batch Acc: 56.25
[Train] Epoch: 0 [25344/620022]    Loss: 0.016005   Batch Acc: 51.56
[Train] Epoch: 0 [25408/620022]    Loss: 0.014330   Batch Acc: 54.69
[Train] Epoch: 0 [25472/620022]    Loss: 0.015229   Batch Acc: 42.19
[Train] Epoch: 0 [25536/620022]    Loss: 0.014106   Batch Acc: 65.62
[Train] Epoch: 0 [25600/620022]    Loss: 0.014877   Batch Acc: 57.81
[Train] Epoch: 0 [25664/620022]    Loss: 0.015819   Batch Acc: 37.50
[Train] Epoch: 0 [25728/620022]    Loss: 0.014940   Batch Acc: 56.25
[Train] Epoch: 0 [25792/620022]    Loss: 0.015702   Batch Acc: 46.88
[Train] Epoch: 0 [25856/620022]    Loss: 0.014908   Batch Acc: 56.25
[Train] Epoch: 0 [25920/620022]    Loss: 0.016366   Batch Acc: 40.62
[Train] Epoch: 0 [25984/620022]    Loss: 0.015219   Batch Acc: 57.81
[Train] Epoch: 0 [26048/620022]    Loss: 0.017258   Batch Acc: 35.94
[Train] Epoch: 0 [26112/620022]    Loss: 0.016030   Batch Acc: 46.88
[Train] Epoch: 0 [26176/620022]    Loss: 0.015020   Batch Acc: 54.69
[Train] Epoch: 0 [26240/620022]    Loss: 0.014473   Batch Acc: 54.69
[Train] Epoch: 0 [26304/620022]    Loss: 0.015073   Batch Acc: 54.69
[Train] Epoch: 0 [26368/620022]    Loss: 0.015490   Batch Acc: 46.88
[Train] Epoch: 0 [26432/620022]    Loss: 0.014206   Batch Acc: 59.38
[Train] Epoch: 0 [26496/620022]    Loss: 0.014921   Batch Acc: 53.12
[Train] Epoch: 0 [26560/620022]    Loss: 0.014235   Batch Acc: 53.12
[Train] Epoch: 0 [26624/620022]    Loss: 0.015042   Batch Acc: 53.12
[Train] Epoch: 0 [26688/620022]    Loss: 0.016157   Batch Acc: 45.31
[Train] Epoch: 0 [26752/620022]    Loss: 0.014486   Batch Acc: 53.12
[Train] Epoch: 0 [26816/620022]    Loss: 0.013078   Batch Acc: 62.50
[Train] Epoch: 0 [26880/620022]    Loss: 0.014788   Batch Acc: 57.81
[Train] Epoch: 0 [26944/620022]    Loss: 0.014990   Batch Acc: 56.25
[Train] Epoch: 0 [27008/620022]    Loss: 0.014411   Batch Acc: 60.94
[Train] Epoch: 0 [27072/620022]    Loss: 0.015955   Batch Acc: 42.19
[Train] Epoch: 0 [27136/620022]    Loss: 0.013329   Batch Acc: 60.94
[Train] Epoch: 0 [27200/620022]    Loss: 0.014508   Batch Acc: 54.69
[Train] Epoch: 0 [27264/620022]    Loss: 0.013599   Batch Acc: 54.69
[Train] Epoch: 0 [27328/620022]    Loss: 0.015058   Batch Acc: 57.81
[Train] Epoch: 0 [27392/620022]    Loss: 0.014397   Batch Acc: 54.69
[Train] Epoch: 0 [27456/620022]    Loss: 0.016166   Batch Acc: 39.06
[Train] Epoch: 0 [27520/620022]    Loss: 0.015105   Batch Acc: 54.69
[Train] Epoch: 0 [27584/620022]    Loss: 0.014237   Batch Acc: 57.81
[Train] Epoch: 0 [27648/620022]    Loss: 0.013225   Batch Acc: 60.94
[Train] Epoch: 0 [27712/620022]    Loss: 0.014891   Batch Acc: 53.12
[Train] Epoch: 0 [27776/620022]    Loss: 0.014697   Batch Acc: 57.81
[Train] Epoch: 0 [27840/620022]    Loss: 0.015388   Batch Acc: 51.56
[Train] Epoch: 0 [27904/620022]    Loss: 0.015377   Batch Acc: 51.56
[Train] Epoch: 0 [27968/620022]    Loss: 0.014392   Batch Acc: 54.69
[Train] Epoch: 0 [28032/620022]    Loss: 0.013846   Batch Acc: 60.94
[Train] Epoch: 0 [28096/620022]    Loss: 0.013697   Batch Acc: 68.75
[Train] Epoch: 0 [28160/620022]    Loss: 0.014412   Batch Acc: 56.25
[Train] Epoch: 0 [28224/620022]    Loss: 0.014475   Batch Acc: 60.94
[Train] Epoch: 0 [28288/620022]    Loss: 0.014143   Batch Acc: 57.81
[Train] Epoch: 0 [28352/620022]    Loss: 0.013226   Batch Acc: 62.50
[Train] Epoch: 0 [28416/620022]    Loss: 0.015132   Batch Acc: 62.50
[Train] Epoch: 0 [28480/620022]    Loss: 0.014136   Batch Acc: 56.25
[Train] Epoch: 0 [28544/620022]    Loss: 0.014554   Batch Acc: 51.56
[Train] Epoch: 0 [28608/620022]    Loss: 0.015075   Batch Acc: 62.50
[Train] Epoch: 0 [28672/620022]    Loss: 0.014774   Batch Acc: 60.94
[Train] Epoch: 0 [28736/620022]    Loss: 0.013629   Batch Acc: 62.50
[Train] Epoch: 0 [28800/620022]    Loss: 0.014006   Batch Acc: 54.69
[Train] Epoch: 0 [28864/620022]    Loss: 0.013570   Batch Acc: 62.50
[Train] Epoch: 0 [28928/620022]    Loss: 0.015302   Batch Acc: 46.88
[Train] Epoch: 0 [28992/620022]    Loss: 0.014672   Batch Acc: 57.81
[Train] Epoch: 0 [29056/620022]    Loss: 0.014330   Batch Acc: 57.81
[Train] Epoch: 0 [29120/620022]    Loss: 0.013916   Batch Acc: 56.25
[Train] Epoch: 0 [29184/620022]    Loss: 0.014534   Batch Acc: 59.38
[Train] Epoch: 0 [29248/620022]    Loss: 0.013264   Batch Acc: 65.62
[Train] Epoch: 0 [29312/620022]    Loss: 0.013851   Batch Acc: 56.25
[Train] Epoch: 0 [29376/620022]    Loss: 0.014642   Batch Acc: 48.44
[Train] Epoch: 0 [29440/620022]    Loss: 0.013737   Batch Acc: 65.62
[Train] Epoch: 0 [29504/620022]    Loss: 0.014694   Batch Acc: 57.81
[Train] Epoch: 0 [29568/620022]    Loss: 0.013278   Batch Acc: 57.81
[Train] Epoch: 0 [29632/620022]    Loss: 0.013771   Batch Acc: 59.38
[Train] Epoch: 0 [29696/620022]    Loss: 0.012552   Batch Acc: 67.19
[Train] Epoch: 0 [29760/620022]    Loss: 0.014601   Batch Acc: 56.25
[Train] Epoch: 0 [29824/620022]    Loss: 0.013307   Batch Acc: 73.44
[Train] Epoch: 0 [29888/620022]    Loss: 0.013634   Batch Acc: 65.62
[Train] Epoch: 0 [29952/620022]    Loss: 0.014360   Batch Acc: 56.25
[Train] Epoch: 0 [30016/620022]    Loss: 0.014154   Batch Acc: 56.25
[Train] Epoch: 0 [30080/620022]    Loss: 0.014130   Batch Acc: 57.81
[Train] Epoch: 0 [30144/620022]    Loss: 0.013721   Batch Acc: 57.81
[Train] Epoch: 0 [30208/620022]    Loss: 0.014321   Batch Acc: 57.81
[Train] Epoch: 0 [30272/620022]    Loss: 0.014237   Batch Acc: 60.94
[Train] Epoch: 0 [30336/620022]    Loss: 0.014310   Batch Acc: 57.81
[Train] Epoch: 0 [30400/620022]    Loss: 0.013170   Batch Acc: 71.88
[Train] Epoch: 0 [30464/620022]    Loss: 0.013822   Batch Acc: 60.94
[Train] Epoch: 0 [30528/620022]    Loss: 0.013877   Batch Acc: 60.94
[Train] Epoch: 0 [30592/620022]    Loss: 0.013369   Batch Acc: 62.50
[Train] Epoch: 0 [30656/620022]    Loss: 0.014259   Batch Acc: 57.81
[Train] Epoch: 0 [30720/620022]    Loss: 0.013092   Batch Acc: 67.19
[Train] Epoch: 0 [30784/620022]    Loss: 0.013531   Batch Acc: 71.88
[Train] Epoch: 0 [30848/620022]    Loss: 0.013940   Batch Acc: 60.94
[Train] Epoch: 0 [30912/620022]    Loss: 0.014454   Batch Acc: 54.69
[Train] Epoch: 0 [30976/620022]    Loss: 0.014205   Batch Acc: 53.12
[Train] Epoch: 0 [31040/620022]    Loss: 0.013944   Batch Acc: 62.50
[Train] Epoch: 0 [31104/620022]    Loss: 0.014346   Batch Acc: 57.81
[Train] Epoch: 0 [31168/620022]    Loss: 0.013926   Batch Acc: 57.81
[Train] Epoch: 0 [31232/620022]    Loss: 0.015080   Batch Acc: 56.25
[Train] Epoch: 0 [31296/620022]    Loss: 0.015120   Batch Acc: 54.69
[Train] Epoch: 0 [31360/620022]    Loss: 0.014568   Batch Acc: 57.81
[Train] Epoch: 0 [31424/620022]    Loss: 0.013466   Batch Acc: 59.38
[Train] Epoch: 0 [31488/620022]    Loss: 0.014709   Batch Acc: 57.81
[Train] Epoch: 0 [31552/620022]    Loss: 0.013396   Batch Acc: 64.06
[Train] Epoch: 0 [31616/620022]    Loss: 0.016002   Batch Acc: 53.12
[Train] Epoch: 0 [31680/620022]    Loss: 0.015736   Batch Acc: 50.00
[Train] Epoch: 0 [31744/620022]    Loss: 0.015629   Batch Acc: 51.56
[Train] Epoch: 0 [31808/620022]    Loss: 0.013110   Batch Acc: 59.38
[Train] Epoch: 0 [31872/620022]    Loss: 0.014214   Batch Acc: 50.00
[Train] Epoch: 0 [31936/620022]    Loss: 0.013865   Batch Acc: 60.94
[Train] Epoch: 0 [32000/620022]    Loss: 0.015032   Batch Acc: 53.12
[Train] Epoch: 0 [32064/620022]    Loss: 0.014664   Batch Acc: 50.00
[Train] Epoch: 0 [32128/620022]    Loss: 0.014939   Batch Acc: 50.00
[Train] Epoch: 0 [32192/620022]    Loss: 0.013617   Batch Acc: 54.69
[Train] Epoch: 0 [32256/620022]    Loss: 0.013053   Batch Acc: 64.06
[Train] Epoch: 0 [32320/620022]    Loss: 0.011960   Batch Acc: 71.88
[Train] Epoch: 0 [32384/620022]    Loss: 0.013447   Batch Acc: 62.50
[Train] Epoch: 0 [32448/620022]    Loss: 0.014540   Batch Acc: 51.56
[Train] Epoch: 0 [32512/620022]    Loss: 0.013856   Batch Acc: 57.81
[Train] Epoch: 0 [32576/620022]    Loss: 0.013826   Batch Acc: 56.25
[Train] Epoch: 0 [32640/620022]    Loss: 0.014408   Batch Acc: 62.50
[Train] Epoch: 0 [32704/620022]    Loss: 0.014779   Batch Acc: 56.25
[Train] Epoch: 0 [32768/620022]    Loss: 0.015146   Batch Acc: 56.25
[Train] Epoch: 0 [32832/620022]    Loss: 0.013710   Batch Acc: 57.81
[Train] Epoch: 0 [32896/620022]    Loss: 0.013543   Batch Acc: 67.19
[Train] Epoch: 0 [32960/620022]    Loss: 0.014081   Batch Acc: 56.25
[Train] Epoch: 0 [33024/620022]    Loss: 0.014386   Batch Acc: 56.25
[Train] Epoch: 0 [33088/620022]    Loss: 0.012566   Batch Acc: 64.06
[Train] Epoch: 0 [33152/620022]    Loss: 0.014175   Batch Acc: 60.94
[Train] Epoch: 0 [33216/620022]    Loss: 0.013003   Batch Acc: 62.50
[Train] Epoch: 0 [33280/620022]    Loss: 0.014432   Batch Acc: 57.81
[Train] Epoch: 0 [33344/620022]    Loss: 0.013968   Batch Acc: 60.94
[Train] Epoch: 0 [33408/620022]    Loss: 0.012598   Batch Acc: 70.31
[Train] Epoch: 0 [33472/620022]    Loss: 0.014377   Batch Acc: 54.69
[Train] Epoch: 0 [33536/620022]    Loss: 0.013316   Batch Acc: 60.94
[Train] Epoch: 0 [33600/620022]    Loss: 0.013409   Batch Acc: 59.38
[Train] Epoch: 0 [33664/620022]    Loss: 0.012826   Batch Acc: 59.38
[Train] Epoch: 0 [33728/620022]    Loss: 0.015542   Batch Acc: 54.69
[Train] Epoch: 0 [33792/620022]    Loss: 0.013095   Batch Acc: 68.75
[Train] Epoch: 0 [33856/620022]    Loss: 0.014421   Batch Acc: 60.94
[Train] Epoch: 0 [33920/620022]    Loss: 0.013470   Batch Acc: 60.94
[Train] Epoch: 0 [33984/620022]    Loss: 0.013814   Batch Acc: 62.50
[Train] Epoch: 0 [34048/620022]    Loss: 0.013882   Batch Acc: 60.94
[Train] Epoch: 0 [34112/620022]    Loss: 0.014367   Batch Acc: 54.69
[Train] Epoch: 0 [34176/620022]    Loss: 0.013993   Batch Acc: 62.50
[Train] Epoch: 0 [34240/620022]    Loss: 0.014086   Batch Acc: 59.38
[Train] Epoch: 0 [34304/620022]    Loss: 0.014460   Batch Acc: 59.38
[Train] Epoch: 0 [34368/620022]    Loss: 0.014824   Batch Acc: 51.56
[Train] Epoch: 0 [34432/620022]    Loss: 0.014331   Batch Acc: 54.69
[Train] Epoch: 0 [34496/620022]    Loss: 0.015021   Batch Acc: 50.00
[Train] Epoch: 0 [34560/620022]    Loss: 0.012223   Batch Acc: 78.12
[Train] Epoch: 0 [34624/620022]    Loss: 0.012921   Batch Acc: 71.88
[Train] Epoch: 0 [34688/620022]    Loss: 0.013552   Batch Acc: 64.06
[Train] Epoch: 0 [34752/620022]    Loss: 0.013823   Batch Acc: 57.81
[Train] Epoch: 0 [34816/620022]    Loss: 0.013232   Batch Acc: 65.62
[Train] Epoch: 0 [34880/620022]    Loss: 0.013392   Batch Acc: 64.06
[Train] Epoch: 0 [34944/620022]    Loss: 0.013992   Batch Acc: 60.94
[Train] Epoch: 0 [35008/620022]    Loss: 0.012759   Batch Acc: 62.50
[Train] Epoch: 0 [35072/620022]    Loss: 0.013015   Batch Acc: 60.94
[Train] Epoch: 0 [35136/620022]    Loss: 0.013820   Batch Acc: 57.81
[Train] Epoch: 0 [35200/620022]    Loss: 0.013236   Batch Acc: 62.50
[Train] Epoch: 0 [35264/620022]    Loss: 0.014482   Batch Acc: 62.50
[Train] Epoch: 0 [35328/620022]    Loss: 0.013875   Batch Acc: 51.56
[Train] Epoch: 0 [35392/620022]    Loss: 0.015016   Batch Acc: 51.56
[Train] Epoch: 0 [35456/620022]    Loss: 0.012054   Batch Acc: 73.44
[Train] Epoch: 0 [35520/620022]    Loss: 0.012390   Batch Acc: 67.19
[Train] Epoch: 0 [35584/620022]    Loss: 0.014137   Batch Acc: 59.38
[Train] Epoch: 0 [35648/620022]    Loss: 0.012336   Batch Acc: 65.62
[Train] Epoch: 0 [35712/620022]    Loss: 0.013553   Batch Acc: 64.06
[Train] Epoch: 0 [35776/620022]    Loss: 0.014285   Batch Acc: 64.06
[Train] Epoch: 0 [35840/620022]    Loss: 0.013949   Batch Acc: 59.38
[Train] Epoch: 0 [35904/620022]    Loss: 0.013734   Batch Acc: 56.25
[Train] Epoch: 0 [35968/620022]    Loss: 0.012283   Batch Acc: 70.31
[Train] Epoch: 0 [36032/620022]    Loss: 0.013183   Batch Acc: 60.94
[Train] Epoch: 0 [36096/620022]    Loss: 0.012468   Batch Acc: 65.62
[Train] Epoch: 0 [36160/620022]    Loss: 0.013706   Batch Acc: 65.62
[Train] Epoch: 0 [36224/620022]    Loss: 0.013904   Batch Acc: 60.94
[Train] Epoch: 0 [36288/620022]    Loss: 0.011936   Batch Acc: 68.75
[Train] Epoch: 0 [36352/620022]    Loss: 0.014035   Batch Acc: 60.94
[Train] Epoch: 0 [36416/620022]    Loss: 0.015122   Batch Acc: 51.56
[Train] Epoch: 0 [36480/620022]    Loss: 0.013062   Batch Acc: 65.62
[Train] Epoch: 0 [36544/620022]    Loss: 0.013519   Batch Acc: 53.12
[Train] Epoch: 0 [36608/620022]    Loss: 0.013628   Batch Acc: 60.94
[Train] Epoch: 0 [36672/620022]    Loss: 0.015693   Batch Acc: 46.88
[Train] Epoch: 0 [36736/620022]    Loss: 0.013847   Batch Acc: 62.50
[Train] Epoch: 0 [36800/620022]    Loss: 0.014374   Batch Acc: 50.00
[Train] Epoch: 0 [36864/620022]    Loss: 0.011839   Batch Acc: 79.69
[Train] Epoch: 0 [36928/620022]    Loss: 0.013860   Batch Acc: 60.94
[Train] Epoch: 0 [36992/620022]    Loss: 0.013414   Batch Acc: 62.50
[Train] Epoch: 0 [37056/620022]    Loss: 0.014949   Batch Acc: 60.94
[Train] Epoch: 0 [37120/620022]    Loss: 0.012880   Batch Acc: 64.06
[Train] Epoch: 0 [37184/620022]    Loss: 0.013197   Batch Acc: 67.19
[Train] Epoch: 0 [37248/620022]    Loss: 0.014601   Batch Acc: 53.12
[Train] Epoch: 0 [37312/620022]    Loss: 0.013921   Batch Acc: 64.06
[Train] Epoch: 0 [37376/620022]    Loss: 0.013071   Batch Acc: 64.06
[Train] Epoch: 0 [37440/620022]    Loss: 0.013707   Batch Acc: 59.38
[Train] Epoch: 0 [37504/620022]    Loss: 0.013320   Batch Acc: 65.62
[Train] Epoch: 0 [37568/620022]    Loss: 0.014422   Batch Acc: 60.94
[Train] Epoch: 0 [37632/620022]    Loss: 0.014303   Batch Acc: 59.38
[Train] Epoch: 0 [37696/620022]    Loss: 0.013170   Batch Acc: 67.19
[Train] Epoch: 0 [37760/620022]    Loss: 0.013665   Batch Acc: 64.06
[Train] Epoch: 0 [37824/620022]    Loss: 0.013104   Batch Acc: 62.50
[Train] Epoch: 0 [37888/620022]    Loss: 0.013451   Batch Acc: 60.94
[Train] Epoch: 0 [37952/620022]    Loss: 0.013347   Batch Acc: 68.75
[Train] Epoch: 0 [38016/620022]    Loss: 0.013616   Batch Acc: 70.31
[Train] Epoch: 0 [38080/620022]    Loss: 0.013437   Batch Acc: 60.94
[Train] Epoch: 0 [38144/620022]    Loss: 0.013846   Batch Acc: 57.81
[Train] Epoch: 0 [38208/620022]    Loss: 0.014882   Batch Acc: 53.12
[Train] Epoch: 0 [38272/620022]    Loss: 0.013294   Batch Acc: 59.38
[Train] Epoch: 0 [38336/620022]    Loss: 0.014304   Batch Acc: 53.12
[Train] Epoch: 0 [38400/620022]    Loss: 0.012480   Batch Acc: 65.62
[Train] Epoch: 0 [38464/620022]    Loss: 0.014047   Batch Acc: 54.69
[Train] Epoch: 0 [38528/620022]    Loss: 0.013383   Batch Acc: 67.19
[Train] Epoch: 0 [38592/620022]    Loss: 0.014393   Batch Acc: 57.81
[Train] Epoch: 0 [38656/620022]    Loss: 0.013827   Batch Acc: 60.94
[Train] Epoch: 0 [38720/620022]    Loss: 0.013466   Batch Acc: 56.25
[Train] Epoch: 0 [38784/620022]    Loss: 0.013078   Batch Acc: 60.94
[Train] Epoch: 0 [38848/620022]    Loss: 0.011063   Batch Acc: 78.12
[Train] Epoch: 0 [38912/620022]    Loss: 0.013097   Batch Acc: 57.81
[Train] Epoch: 0 [38976/620022]    Loss: 0.013515   Batch Acc: 64.06
[Train] Epoch: 0 [39040/620022]    Loss: 0.014369   Batch Acc: 53.12
[Train] Epoch: 0 [39104/620022]    Loss: 0.012380   Batch Acc: 68.75
[Train] Epoch: 0 [39168/620022]    Loss: 0.012478   Batch Acc: 68.75
[Train] Epoch: 0 [39232/620022]    Loss: 0.015938   Batch Acc: 51.56
[Train] Epoch: 0 [39296/620022]    Loss: 0.012758   Batch Acc: 65.62
[Train] Epoch: 0 [39360/620022]    Loss: 0.012445   Batch Acc: 73.44
[Train] Epoch: 0 [39424/620022]    Loss: 0.014757   Batch Acc: 54.69
[Train] Epoch: 0 [39488/620022]    Loss: 0.013108   Batch Acc: 59.38
[Train] Epoch: 0 [39552/620022]    Loss: 0.014379   Batch Acc: 56.25
[Train] Epoch: 0 [39616/620022]    Loss: 0.013547   Batch Acc: 62.50
[Train] Epoch: 0 [39680/620022]    Loss: 0.014214   Batch Acc: 56.25
[Train] Epoch: 0 [39744/620022]    Loss: 0.013218   Batch Acc: 60.94
[Train] Epoch: 0 [39808/620022]    Loss: 0.015124   Batch Acc: 53.12
[Train] Epoch: 0 [39872/620022]    Loss: 0.013887   Batch Acc: 67.19
[Train] Epoch: 0 [39936/620022]    Loss: 0.015019   Batch Acc: 53.12
[Train] Epoch: 0 [40000/620022]    Loss: 0.012158   Batch Acc: 65.62
[Train] Epoch: 0 [40064/620022]    Loss: 0.013499   Batch Acc: 60.94
[Train] Epoch: 0 [40128/620022]    Loss: 0.012812   Batch Acc: 57.81
[Train] Epoch: 0 [40192/620022]    Loss: 0.014149   Batch Acc: 56.25
[Train] Epoch: 0 [40256/620022]    Loss: 0.012469   Batch Acc: 59.38
[Train] Epoch: 0 [40320/620022]    Loss: 0.012920   Batch Acc: 67.19
[Train] Epoch: 0 [40384/620022]    Loss: 0.012969   Batch Acc: 67.19
[Train] Epoch: 0 [40448/620022]    Loss: 0.012747   Batch Acc: 65.62
[Train] Epoch: 0 [40512/620022]    Loss: 0.012823   Batch Acc: 57.81
[Train] Epoch: 0 [40576/620022]    Loss: 0.013394   Batch Acc: 60.94
[Train] Epoch: 0 [40640/620022]    Loss: 0.012366   Batch Acc: 67.19
[Train] Epoch: 0 [40704/620022]    Loss: 0.013392   Batch Acc: 62.50
[Train] Epoch: 0 [40768/620022]    Loss: 0.014431   Batch Acc: 59.38
[Train] Epoch: 0 [40832/620022]    Loss: 0.012977   Batch Acc: 60.94
[Train] Epoch: 0 [40896/620022]    Loss: 0.014531   Batch Acc: 59.38
[Train] Epoch: 0 [40960/620022]    Loss: 0.013109   Batch Acc: 62.50
[Train] Epoch: 0 [41024/620022]    Loss: 0.012686   Batch Acc: 64.06
[Train] Epoch: 0 [41088/620022]    Loss: 0.011698   Batch Acc: 67.19
[Train] Epoch: 0 [41152/620022]    Loss: 0.012620   Batch Acc: 64.06
[Train] Epoch: 0 [41216/620022]    Loss: 0.014378   Batch Acc: 59.38
[Train] Epoch: 0 [41280/620022]    Loss: 0.013908   Batch Acc: 57.81
[Train] Epoch: 0 [41344/620022]    Loss: 0.011736   Batch Acc: 71.88
[Train] Epoch: 0 [41408/620022]    Loss: 0.011931   Batch Acc: 67.19
[Train] Epoch: 0 [41472/620022]    Loss: 0.013623   Batch Acc: 62.50
[Train] Epoch: 0 [41536/620022]    Loss: 0.012783   Batch Acc: 70.31
[Train] Epoch: 0 [41600/620022]    Loss: 0.013829   Batch Acc: 64.06
[Train] Epoch: 0 [41664/620022]    Loss: 0.013537   Batch Acc: 64.06
[Train] Epoch: 0 [41728/620022]    Loss: 0.012060   Batch Acc: 65.62
[Train] Epoch: 0 [41792/620022]    Loss: 0.014709   Batch Acc: 56.25
[Train] Epoch: 0 [41856/620022]    Loss: 0.012801   Batch Acc: 67.19
[Train] Epoch: 0 [41920/620022]    Loss: 0.014674   Batch Acc: 48.44
[Train] Epoch: 0 [41984/620022]    Loss: 0.012475   Batch Acc: 64.06
[Train] Epoch: 0 [42048/620022]    Loss: 0.013934   Batch Acc: 65.62
[Train] Epoch: 0 [42112/620022]    Loss: 0.014546   Batch Acc: 53.12
[Train] Epoch: 0 [42176/620022]    Loss: 0.011686   Batch Acc: 68.75
[Train] Epoch: 0 [42240/620022]    Loss: 0.014368   Batch Acc: 51.56
[Train] Epoch: 0 [42304/620022]    Loss: 0.013495   Batch Acc: 57.81
[Train] Epoch: 0 [42368/620022]    Loss: 0.012350   Batch Acc: 71.88
[Train] Epoch: 0 [42432/620022]    Loss: 0.015008   Batch Acc: 57.81
[Train] Epoch: 0 [42496/620022]    Loss: 0.011786   Batch Acc: 68.75
[Train] Epoch: 0 [42560/620022]    Loss: 0.014465   Batch Acc: 48.44
[Train] Epoch: 0 [42624/620022]    Loss: 0.012183   Batch Acc: 67.19
[Train] Epoch: 0 [42688/620022]    Loss: 0.013257   Batch Acc: 62.50
[Train] Epoch: 0 [42752/620022]    Loss: 0.011508   Batch Acc: 68.75
[Train] Epoch: 0 [42816/620022]    Loss: 0.013225   Batch Acc: 56.25
[Train] Epoch: 0 [42880/620022]    Loss: 0.014112   Batch Acc: 60.94
[Train] Epoch: 0 [42944/620022]    Loss: 0.014979   Batch Acc: 53.12
[Train] Epoch: 0 [43008/620022]    Loss: 0.012730   Batch Acc: 64.06
[Train] Epoch: 0 [43072/620022]    Loss: 0.012240   Batch Acc: 65.62
[Train] Epoch: 0 [43136/620022]    Loss: 0.013578   Batch Acc: 57.81
[Train] Epoch: 0 [43200/620022]    Loss: 0.012269   Batch Acc: 64.06
[Train] Epoch: 0 [43264/620022]    Loss: 0.013947   Batch Acc: 59.38
[Train] Epoch: 0 [43328/620022]    Loss: 0.013564   Batch Acc: 60.94
[Train] Epoch: 0 [43392/620022]    Loss: 0.012564   Batch Acc: 73.44
[Train] Epoch: 0 [43456/620022]    Loss: 0.013005   Batch Acc: 65.62
[Train] Epoch: 0 [43520/620022]    Loss: 0.014468   Batch Acc: 50.00
[Train] Epoch: 0 [43584/620022]    Loss: 0.010449   Batch Acc: 78.12
[Train] Epoch: 0 [43648/620022]    Loss: 0.012848   Batch Acc: 62.50
[Train] Epoch: 0 [43712/620022]    Loss: 0.013770   Batch Acc: 60.94
[Train] Epoch: 0 [43776/620022]    Loss: 0.013892   Batch Acc: 62.50
[Train] Epoch: 0 [43840/620022]    Loss: 0.013178   Batch Acc: 64.06
[Train] Epoch: 0 [43904/620022]    Loss: 0.012818   Batch Acc: 70.31
[Train] Epoch: 0 [43968/620022]    Loss: 0.012705   Batch Acc: 64.06
[Train] Epoch: 0 [44032/620022]    Loss: 0.012010   Batch Acc: 62.50
[Train] Epoch: 0 [44096/620022]    Loss: 0.014713   Batch Acc: 51.56
[Train] Epoch: 0 [44160/620022]    Loss: 0.011854   Batch Acc: 64.06
[Train] Epoch: 0 [44224/620022]    Loss: 0.013144   Batch Acc: 57.81
[Train] Epoch: 0 [44288/620022]    Loss: 0.011432   Batch Acc: 73.44
[Train] Epoch: 0 [44352/620022]    Loss: 0.013835   Batch Acc: 57.81
[Train] Epoch: 0 [44416/620022]    Loss: 0.013182   Batch Acc: 62.50
[Train] Epoch: 0 [44480/620022]    Loss: 0.014765   Batch Acc: 57.81
[Train] Epoch: 0 [44544/620022]    Loss: 0.011761   Batch Acc: 75.00
[Train] Epoch: 0 [44608/620022]    Loss: 0.014211   Batch Acc: 53.12
[Train] Epoch: 0 [44672/620022]    Loss: 0.012370   Batch Acc: 68.75
[Train] Epoch: 0 [44736/620022]    Loss: 0.012238   Batch Acc: 64.06
[Train] Epoch: 0 [44800/620022]    Loss: 0.011035   Batch Acc: 73.44
[Train] Epoch: 0 [44864/620022]    Loss: 0.014834   Batch Acc: 60.94
[Train] Epoch: 0 [44928/620022]    Loss: 0.013852   Batch Acc: 54.69
[Train] Epoch: 0 [44992/620022]    Loss: 0.012200   Batch Acc: 65.62
[Train] Epoch: 0 [45056/620022]    Loss: 0.013258   Batch Acc: 60.94
[Train] Epoch: 0 [45120/620022]    Loss: 0.013916   Batch Acc: 57.81
[Train] Epoch: 0 [45184/620022]    Loss: 0.012809   Batch Acc: 62.50
[Train] Epoch: 0 [45248/620022]    Loss: 0.012158   Batch Acc: 67.19
[Train] Epoch: 0 [45312/620022]    Loss: 0.014830   Batch Acc: 54.69
[Train] Epoch: 0 [45376/620022]    Loss: 0.014431   Batch Acc: 53.12
[Train] Epoch: 0 [45440/620022]    Loss: 0.013596   Batch Acc: 59.38
[Train] Epoch: 0 [45504/620022]    Loss: 0.012305   Batch Acc: 70.31
[Train] Epoch: 0 [45568/620022]    Loss: 0.013233   Batch Acc: 60.94
[Train] Epoch: 0 [45632/620022]    Loss: 0.011764   Batch Acc: 68.75
[Train] Epoch: 0 [45696/620022]    Loss: 0.012886   Batch Acc: 62.50
[Train] Epoch: 0 [45760/620022]    Loss: 0.013039   Batch Acc: 64.06
[Train] Epoch: 0 [45824/620022]    Loss: 0.014054   Batch Acc: 56.25
[Train] Epoch: 0 [45888/620022]    Loss: 0.012005   Batch Acc: 73.44
[Train] Epoch: 0 [45952/620022]    Loss: 0.011373   Batch Acc: 76.56
[Train] Epoch: 0 [46016/620022]    Loss: 0.012759   Batch Acc: 60.94
[Train] Epoch: 0 [46080/620022]    Loss: 0.013612   Batch Acc: 60.94
[Train] Epoch: 0 [46144/620022]    Loss: 0.013668   Batch Acc: 60.94
[Train] Epoch: 0 [46208/620022]    Loss: 0.012845   Batch Acc: 67.19
[Train] Epoch: 0 [46272/620022]    Loss: 0.013275   Batch Acc: 62.50
[Train] Epoch: 0 [46336/620022]    Loss: 0.012115   Batch Acc: 68.75
[Train] Epoch: 0 [46400/620022]    Loss: 0.012738   Batch Acc: 62.50
[Train] Epoch: 0 [46464/620022]    Loss: 0.013755   Batch Acc: 64.06
[Train] Epoch: 0 [46528/620022]    Loss: 0.014156   Batch Acc: 54.69
[Train] Epoch: 0 [46592/620022]    Loss: 0.014416   Batch Acc: 62.50
[Train] Epoch: 0 [46656/620022]    Loss: 0.012723   Batch Acc: 67.19
[Train] Epoch: 0 [46720/620022]    Loss: 0.012367   Batch Acc: 71.88
[Train] Epoch: 0 [46784/620022]    Loss: 0.013570   Batch Acc: 57.81
[Train] Epoch: 0 [46848/620022]    Loss: 0.012641   Batch Acc: 59.38
[Train] Epoch: 0 [46912/620022]    Loss: 0.011525   Batch Acc: 68.75
[Train] Epoch: 0 [46976/620022]    Loss: 0.012670   Batch Acc: 70.31
[Train] Epoch: 0 [47040/620022]    Loss: 0.012519   Batch Acc: 70.31
[Train] Epoch: 0 [47104/620022]    Loss: 0.013043   Batch Acc: 65.62
[Train] Epoch: 0 [47168/620022]    Loss: 0.012405   Batch Acc: 67.19
[Train] Epoch: 0 [47232/620022]    Loss: 0.011795   Batch Acc: 71.88
[Train] Epoch: 0 [47296/620022]    Loss: 0.013127   Batch Acc: 68.75
[Train] Epoch: 0 [47360/620022]    Loss: 0.011581   Batch Acc: 68.75
[Train] Epoch: 0 [47424/620022]    Loss: 0.012838   Batch Acc: 65.62
[Train] Epoch: 0 [47488/620022]    Loss: 0.012009   Batch Acc: 71.88
[Train] Epoch: 0 [47552/620022]    Loss: 0.011978   Batch Acc: 75.00
[Train] Epoch: 0 [47616/620022]    Loss: 0.013803   Batch Acc: 57.81
[Train] Epoch: 0 [47680/620022]    Loss: 0.013380   Batch Acc: 59.38
[Train] Epoch: 0 [47744/620022]    Loss: 0.012456   Batch Acc: 70.31
[Train] Epoch: 0 [47808/620022]    Loss: 0.011618   Batch Acc: 68.75
[Train] Epoch: 0 [47872/620022]    Loss: 0.011860   Batch Acc: 73.44
[Train] Epoch: 0 [47936/620022]    Loss: 0.012984   Batch Acc: 60.94
[Train] Epoch: 0 [48000/620022]    Loss: 0.012085   Batch Acc: 62.50
[Train] Epoch: 0 [48064/620022]    Loss: 0.012459   Batch Acc: 70.31
[Train] Epoch: 0 [48128/620022]    Loss: 0.012999   Batch Acc: 68.75
[Train] Epoch: 0 [48192/620022]    Loss: 0.011337   Batch Acc: 75.00
[Train] Epoch: 0 [48256/620022]    Loss: 0.013599   Batch Acc: 64.06
[Train] Epoch: 0 [48320/620022]    Loss: 0.012584   Batch Acc: 64.06
[Train] Epoch: 0 [48384/620022]    Loss: 0.013195   Batch Acc: 64.06
[Train] Epoch: 0 [48448/620022]    Loss: 0.012324   Batch Acc: 67.19
[Train] Epoch: 0 [48512/620022]    Loss: 0.011289   Batch Acc: 68.75
[Train] Epoch: 0 [48576/620022]    Loss: 0.013473   Batch Acc: 64.06
[Train] Epoch: 0 [48640/620022]    Loss: 0.013128   Batch Acc: 65.62
[Train] Epoch: 0 [48704/620022]    Loss: 0.011560   Batch Acc: 70.31
[Train] Epoch: 0 [48768/620022]    Loss: 0.011004   Batch Acc: 79.69
[Train] Epoch: 0 [48832/620022]    Loss: 0.011556   Batch Acc: 75.00
[Train] Epoch: 0 [48896/620022]    Loss: 0.012735   Batch Acc: 60.94
[Train] Epoch: 0 [48960/620022]    Loss: 0.013345   Batch Acc: 57.81
[Train] Epoch: 0 [49024/620022]    Loss: 0.012560   Batch Acc: 67.19
[Train] Epoch: 0 [49088/620022]    Loss: 0.012297   Batch Acc: 67.19
[Train] Epoch: 0 [49152/620022]    Loss: 0.012091   Batch Acc: 62.50
[Train] Epoch: 0 [49216/620022]    Loss: 0.012501   Batch Acc: 65.62
[Train] Epoch: 0 [49280/620022]    Loss: 0.013444   Batch Acc: 65.62
[Train] Epoch: 0 [49344/620022]    Loss: 0.013146   Batch Acc: 59.38
[Train] Epoch: 0 [49408/620022]    Loss: 0.012052   Batch Acc: 68.75
[Train] Epoch: 0 [49472/620022]    Loss: 0.013745   Batch Acc: 56.25
[Train] Epoch: 0 [49536/620022]    Loss: 0.011076   Batch Acc: 67.19
[Train] Epoch: 0 [49600/620022]    Loss: 0.013403   Batch Acc: 57.81
[Train] Epoch: 0 [49664/620022]    Loss: 0.013570   Batch Acc: 62.50
[Train] Epoch: 0 [49728/620022]    Loss: 0.013112   Batch Acc: 62.50
[Train] Epoch: 0 [49792/620022]    Loss: 0.012839   Batch Acc: 62.50
[Train] Epoch: 0 [49856/620022]    Loss: 0.012104   Batch Acc: 70.31
[Train] Epoch: 0 [49920/620022]    Loss: 0.011647   Batch Acc: 70.31
[Train] Epoch: 0 [49984/620022]    Loss: 0.012752   Batch Acc: 65.62
[Train] Epoch: 0 [50048/620022]    Loss: 0.013244   Batch Acc: 65.62
[Train] Epoch: 0 [50112/620022]    Loss: 0.014051   Batch Acc: 50.00
[Train] Epoch: 0 [50176/620022]    Loss: 0.012973   Batch Acc: 56.25
[Train] Epoch: 0 [50240/620022]    Loss: 0.011551   Batch Acc: 71.88
[Train] Epoch: 0 [50304/620022]    Loss: 0.010548   Batch Acc: 79.69
[Train] Epoch: 0 [50368/620022]    Loss: 0.010927   Batch Acc: 71.88
[Train] Epoch: 0 [50432/620022]    Loss: 0.012258   Batch Acc: 60.94
[Train] Epoch: 0 [50496/620022]    Loss: 0.012533   Batch Acc: 70.31
[Train] Epoch: 0 [50560/620022]    Loss: 0.011054   Batch Acc: 73.44
[Train] Epoch: 0 [50624/620022]    Loss: 0.011664   Batch Acc: 71.88
[Train] Epoch: 0 [50688/620022]    Loss: 0.012206   Batch Acc: 73.44
[Train] Epoch: 0 [50752/620022]    Loss: 0.012550   Batch Acc: 59.38
[Train] Epoch: 0 [50816/620022]    Loss: 0.011813   Batch Acc: 68.75
[Train] Epoch: 0 [50880/620022]    Loss: 0.013213   Batch Acc: 65.62
[Train] Epoch: 0 [50944/620022]    Loss: 0.012502   Batch Acc: 65.62
[Train] Epoch: 0 [51008/620022]    Loss: 0.012425   Batch Acc: 68.75
[Train] Epoch: 0 [51072/620022]    Loss: 0.010966   Batch Acc: 75.00
[Train] Epoch: 0 [51136/620022]    Loss: 0.012260   Batch Acc: 60.94
[Train] Epoch: 0 [51200/620022]    Loss: 0.011213   Batch Acc: 76.56
[Train] Epoch: 0 [51264/620022]    Loss: 0.012336   Batch Acc: 71.88
[Train] Epoch: 0 [51328/620022]    Loss: 0.012865   Batch Acc: 62.50
[Train] Epoch: 0 [51392/620022]    Loss: 0.011983   Batch Acc: 71.88
[Train] Epoch: 0 [51456/620022]    Loss: 0.012472   Batch Acc: 64.06
[Train] Epoch: 0 [51520/620022]    Loss: 0.012634   Batch Acc: 70.31
[Train] Epoch: 0 [51584/620022]    Loss: 0.013778   Batch Acc: 62.50
[Train] Epoch: 0 [51648/620022]    Loss: 0.011143   Batch Acc: 73.44
[Train] Epoch: 0 [51712/620022]    Loss: 0.011806   Batch Acc: 67.19
[Train] Epoch: 0 [51776/620022]    Loss: 0.012855   Batch Acc: 73.44
[Train] Epoch: 0 [51840/620022]    Loss: 0.011016   Batch Acc: 67.19
[Train] Epoch: 0 [51904/620022]    Loss: 0.012208   Batch Acc: 67.19
[Train] Epoch: 0 [51968/620022]    Loss: 0.012515   Batch Acc: 71.88
[Train] Epoch: 0 [52032/620022]    Loss: 0.013465   Batch Acc: 65.62
[Train] Epoch: 0 [52096/620022]    Loss: 0.013561   Batch Acc: 62.50
[Train] Epoch: 0 [52160/620022]    Loss: 0.012689   Batch Acc: 71.88
[Train] Epoch: 0 [52224/620022]    Loss: 0.011184   Batch Acc: 68.75
[Train] Epoch: 0 [52288/620022]    Loss: 0.012220   Batch Acc: 75.00
[Train] Epoch: 0 [52352/620022]    Loss: 0.012745   Batch Acc: 65.62
[Train] Epoch: 0 [52416/620022]    Loss: 0.013228   Batch Acc: 62.50
[Train] Epoch: 0 [52480/620022]    Loss: 0.012575   Batch Acc: 65.62
[Train] Epoch: 0 [52544/620022]    Loss: 0.011516   Batch Acc: 64.06
[Train] Epoch: 0 [52608/620022]    Loss: 0.012304   Batch Acc: 64.06
[Train] Epoch: 0 [52672/620022]    Loss: 0.013563   Batch Acc: 56.25
[Train] Epoch: 0 [52736/620022]    Loss: 0.014419   Batch Acc: 54.69
[Train] Epoch: 0 [52800/620022]    Loss: 0.012889   Batch Acc: 57.81
[Train] Epoch: 0 [52864/620022]    Loss: 0.012122   Batch Acc: 67.19
[Train] Epoch: 0 [52928/620022]    Loss: 0.012173   Batch Acc: 68.75
[Train] Epoch: 0 [52992/620022]    Loss: 0.011556   Batch Acc: 71.88
[Train] Epoch: 0 [53056/620022]    Loss: 0.012359   Batch Acc: 68.75
[Train] Epoch: 0 [53120/620022]    Loss: 0.011958   Batch Acc: 65.62
[Train] Epoch: 0 [53184/620022]    Loss: 0.011029   Batch Acc: 71.88
[Train] Epoch: 0 [53248/620022]    Loss: 0.012150   Batch Acc: 60.94
[Train] Epoch: 0 [53312/620022]    Loss: 0.013275   Batch Acc: 68.75
[Train] Epoch: 0 [53376/620022]    Loss: 0.013277   Batch Acc: 64.06
[Train] Epoch: 0 [53440/620022]    Loss: 0.013219   Batch Acc: 62.50
[Train] Epoch: 0 [53504/620022]    Loss: 0.012306   Batch Acc: 71.88
[Train] Epoch: 0 [53568/620022]    Loss: 0.011721   Batch Acc: 68.75
[Train] Epoch: 0 [53632/620022]    Loss: 0.011852   Batch Acc: 70.31
[Train] Epoch: 0 [53696/620022]    Loss: 0.013032   Batch Acc: 65.62
[Train] Epoch: 0 [53760/620022]    Loss: 0.013321   Batch Acc: 57.81
[Train] Epoch: 0 [53824/620022]    Loss: 0.013091   Batch Acc: 67.19
[Train] Epoch: 0 [53888/620022]    Loss: 0.010428   Batch Acc: 85.94
[Train] Epoch: 0 [53952/620022]    Loss: 0.012829   Batch Acc: 67.19
[Train] Epoch: 0 [54016/620022]    Loss: 0.012787   Batch Acc: 64.06
[Train] Epoch: 0 [54080/620022]    Loss: 0.012431   Batch Acc: 67.19
[Train] Epoch: 0 [54144/620022]    Loss: 0.012513   Batch Acc: 62.50
[Train] Epoch: 0 [54208/620022]    Loss: 0.012226   Batch Acc: 68.75
[Train] Epoch: 0 [54272/620022]    Loss: 0.011520   Batch Acc: 73.44
[Train] Epoch: 0 [54336/620022]    Loss: 0.013883   Batch Acc: 60.94
[Train] Epoch: 0 [54400/620022]    Loss: 0.011474   Batch Acc: 71.88
[Train] Epoch: 0 [54464/620022]    Loss: 0.012911   Batch Acc: 64.06
[Train] Epoch: 0 [54528/620022]    Loss: 0.013197   Batch Acc: 64.06
[Train] Epoch: 0 [54592/620022]    Loss: 0.011545   Batch Acc: 64.06
[Train] Epoch: 0 [54656/620022]    Loss: 0.013324   Batch Acc: 60.94
[Train] Epoch: 0 [54720/620022]    Loss: 0.012321   Batch Acc: 60.94
[Train] Epoch: 0 [54784/620022]    Loss: 0.012628   Batch Acc: 70.31
[Train] Epoch: 0 [54848/620022]    Loss: 0.013179   Batch Acc: 59.38
[Train] Epoch: 0 [54912/620022]    Loss: 0.012146   Batch Acc: 67.19
[Train] Epoch: 0 [54976/620022]    Loss: 0.013025   Batch Acc: 65.62
[Train] Epoch: 0 [55040/620022]    Loss: 0.014046   Batch Acc: 62.50
[Train] Epoch: 0 [55104/620022]    Loss: 0.011071   Batch Acc: 70.31
[Train] Epoch: 0 [55168/620022]    Loss: 0.010729   Batch Acc: 76.56
[Train] Epoch: 0 [55232/620022]    Loss: 0.014007   Batch Acc: 56.25
[Train] Epoch: 0 [55296/620022]    Loss: 0.010756   Batch Acc: 73.44
[Train] Epoch: 0 [55360/620022]    Loss: 0.012818   Batch Acc: 60.94
[Train] Epoch: 0 [55424/620022]    Loss: 0.012107   Batch Acc: 67.19
[Train] Epoch: 0 [55488/620022]    Loss: 0.011428   Batch Acc: 75.00
[Train] Epoch: 0 [55552/620022]    Loss: 0.011815   Batch Acc: 64.06
[Train] Epoch: 0 [55616/620022]    Loss: 0.012216   Batch Acc: 67.19
[Train] Epoch: 0 [55680/620022]    Loss: 0.013165   Batch Acc: 67.19
[Train] Epoch: 0 [55744/620022]    Loss: 0.010348   Batch Acc: 78.12
[Train] Epoch: 0 [55808/620022]    Loss: 0.013285   Batch Acc: 60.94
[Train] Epoch: 0 [55872/620022]    Loss: 0.012535   Batch Acc: 62.50
[Train] Epoch: 0 [55936/620022]    Loss: 0.012973   Batch Acc: 65.62
[Train] Epoch: 0 [56000/620022]    Loss: 0.011031   Batch Acc: 71.88
[Train] Epoch: 0 [56064/620022]    Loss: 0.011648   Batch Acc: 71.88
[Train] Epoch: 0 [56128/620022]    Loss: 0.012687   Batch Acc: 64.06
[Train] Epoch: 0 [56192/620022]    Loss: 0.013143   Batch Acc: 65.62
[Train] Epoch: 0 [56256/620022]    Loss: 0.011639   Batch Acc: 67.19
[Train] Epoch: 0 [56320/620022]    Loss: 0.014571   Batch Acc: 53.12
[Train] Epoch: 0 [56384/620022]    Loss: 0.012662   Batch Acc: 68.75
[Train] Epoch: 0 [56448/620022]    Loss: 0.010732   Batch Acc: 75.00
[Train] Epoch: 0 [56512/620022]    Loss: 0.013997   Batch Acc: 56.25
[Train] Epoch: 0 [56576/620022]    Loss: 0.011031   Batch Acc: 78.12
[Train] Epoch: 0 [56640/620022]    Loss: 0.011245   Batch Acc: 65.62
[Train] Epoch: 0 [56704/620022]    Loss: 0.014386   Batch Acc: 50.00
[Train] Epoch: 0 [56768/620022]    Loss: 0.011987   Batch Acc: 71.88
[Train] Epoch: 0 [56832/620022]    Loss: 0.013852   Batch Acc: 62.50
[Train] Epoch: 0 [56896/620022]    Loss: 0.013015   Batch Acc: 64.06
[Train] Epoch: 0 [56960/620022]    Loss: 0.012616   Batch Acc: 64.06
[Train] Epoch: 0 [57024/620022]    Loss: 0.013993   Batch Acc: 57.81
[Train] Epoch: 0 [57088/620022]    Loss: 0.011147   Batch Acc: 68.75
[Train] Epoch: 0 [57152/620022]    Loss: 0.011172   Batch Acc: 70.31
[Train] Epoch: 0 [57216/620022]    Loss: 0.013233   Batch Acc: 56.25
[Train] Epoch: 0 [57280/620022]    Loss: 0.010503   Batch Acc: 78.12
[Train] Epoch: 0 [57344/620022]    Loss: 0.012954   Batch Acc: 62.50
[Train] Epoch: 0 [57408/620022]    Loss: 0.013561   Batch Acc: 53.12
[Train] Epoch: 0 [57472/620022]    Loss: 0.012754   Batch Acc: 64.06
[Train] Epoch: 0 [57536/620022]    Loss: 0.011832   Batch Acc: 67.19
[Train] Epoch: 0 [57600/620022]    Loss: 0.011309   Batch Acc: 67.19
[Train] Epoch: 0 [57664/620022]    Loss: 0.011081   Batch Acc: 70.31
[Train] Epoch: 0 [57728/620022]    Loss: 0.013824   Batch Acc: 59.38
[Train] Epoch: 0 [57792/620022]    Loss: 0.012147   Batch Acc: 70.31
[Train] Epoch: 0 [57856/620022]    Loss: 0.011847   Batch Acc: 57.81
[Train] Epoch: 0 [57920/620022]    Loss: 0.011238   Batch Acc: 71.88
[Train] Epoch: 0 [57984/620022]    Loss: 0.012728   Batch Acc: 68.75
[Train] Epoch: 0 [58048/620022]    Loss: 0.011430   Batch Acc: 73.44
[Train] Epoch: 0 [58112/620022]    Loss: 0.012597   Batch Acc: 67.19
[Train] Epoch: 0 [58176/620022]    Loss: 0.011797   Batch Acc: 71.88
[Train] Epoch: 0 [58240/620022]    Loss: 0.012755   Batch Acc: 57.81
[Train] Epoch: 0 [58304/620022]    Loss: 0.013335   Batch Acc: 60.94
[Train] Epoch: 0 [58368/620022]    Loss: 0.012359   Batch Acc: 65.62
[Train] Epoch: 0 [58432/620022]    Loss: 0.011439   Batch Acc: 65.62
[Train] Epoch: 0 [58496/620022]    Loss: 0.010741   Batch Acc: 73.44
[Train] Epoch: 0 [58560/620022]    Loss: 0.011749   Batch Acc: 67.19
[Train] Epoch: 0 [58624/620022]    Loss: 0.011442   Batch Acc: 71.88
[Train] Epoch: 0 [58688/620022]    Loss: 0.011679   Batch Acc: 68.75
[Train] Epoch: 0 [58752/620022]    Loss: 0.011602   Batch Acc: 70.31
[Train] Epoch: 0 [58816/620022]    Loss: 0.011662   Batch Acc: 73.44
[Train] Epoch: 0 [58880/620022]    Loss: 0.011868   Batch Acc: 68.75
[Train] Epoch: 0 [58944/620022]    Loss: 0.012153   Batch Acc: 68.75
[Train] Epoch: 0 [59008/620022]    Loss: 0.012360   Batch Acc: 62.50
[Train] Epoch: 0 [59072/620022]    Loss: 0.011435   Batch Acc: 70.31
[Train] Epoch: 0 [59136/620022]    Loss: 0.012246   Batch Acc: 67.19
[Train] Epoch: 0 [59200/620022]    Loss: 0.011966   Batch Acc: 70.31
[Train] Epoch: 0 [59264/620022]    Loss: 0.008882   Batch Acc: 79.69
[Train] Epoch: 0 [59328/620022]    Loss: 0.012702   Batch Acc: 60.94
[Train] Epoch: 0 [59392/620022]    Loss: 0.012782   Batch Acc: 64.06
[Train] Epoch: 0 [59456/620022]    Loss: 0.012667   Batch Acc: 59.38
[Train] Epoch: 0 [59520/620022]    Loss: 0.012673   Batch Acc: 57.81
[Train] Epoch: 0 [59584/620022]    Loss: 0.014272   Batch Acc: 51.56
[Train] Epoch: 0 [59648/620022]    Loss: 0.011510   Batch Acc: 68.75
[Train] Epoch: 0 [59712/620022]    Loss: 0.011823   Batch Acc: 70.31
[Train] Epoch: 0 [59776/620022]    Loss: 0.011182   Batch Acc: 71.88
[Train] Epoch: 0 [59840/620022]    Loss: 0.014325   Batch Acc: 50.00
[Train] Epoch: 0 [59904/620022]    Loss: 0.012597   Batch Acc: 65.62
[Train] Epoch: 0 [59968/620022]    Loss: 0.011786   Batch Acc: 70.31
[Train] Epoch: 0 [60032/620022]    Loss: 0.010336   Batch Acc: 81.25
[Train] Epoch: 0 [60096/620022]    Loss: 0.012712   Batch Acc: 62.50
[Train] Epoch: 0 [60160/620022]    Loss: 0.012729   Batch Acc: 59.38
[Train] Epoch: 0 [60224/620022]    Loss: 0.011907   Batch Acc: 73.44
[Train] Epoch: 0 [60288/620022]    Loss: 0.010562   Batch Acc: 75.00
[Train] Epoch: 0 [60352/620022]    Loss: 0.013094   Batch Acc: 70.31
[Train] Epoch: 0 [60416/620022]    Loss: 0.013229   Batch Acc: 67.19
[Train] Epoch: 0 [60480/620022]    Loss: 0.010433   Batch Acc: 81.25
[Train] Epoch: 0 [60544/620022]    Loss: 0.011802   Batch Acc: 67.19
[Train] Epoch: 0 [60608/620022]    Loss: 0.013385   Batch Acc: 65.62
[Train] Epoch: 0 [60672/620022]    Loss: 0.013195   Batch Acc: 62.50
[Train] Epoch: 0 [60736/620022]    Loss: 0.011283   Batch Acc: 73.44
[Train] Epoch: 0 [60800/620022]    Loss: 0.012488   Batch Acc: 65.62
[Train] Epoch: 0 [60864/620022]    Loss: 0.012110   Batch Acc: 59.38
[Train] Epoch: 0 [60928/620022]    Loss: 0.013468   Batch Acc: 59.38
[Train] Epoch: 0 [60992/620022]    Loss: 0.012875   Batch Acc: 62.50
[Train] Epoch: 0 [61056/620022]    Loss: 0.010505   Batch Acc: 70.31
[Train] Epoch: 0 [61120/620022]    Loss: 0.010977   Batch Acc: 73.44
[Train] Epoch: 0 [61184/620022]    Loss: 0.011864   Batch Acc: 73.44
[Train] Epoch: 0 [61248/620022]    Loss: 0.010127   Batch Acc: 75.00
[Train] Epoch: 0 [61312/620022]    Loss: 0.010604   Batch Acc: 76.56
[Train] Epoch: 0 [61376/620022]    Loss: 0.013094   Batch Acc: 65.62
[Train] Epoch: 0 [61440/620022]    Loss: 0.012281   Batch Acc: 67.19
[Train] Epoch: 0 [61504/620022]    Loss: 0.011907   Batch Acc: 62.50
[Train] Epoch: 0 [61568/620022]    Loss: 0.012059   Batch Acc: 62.50
[Train] Epoch: 0 [61632/620022]    Loss: 0.011381   Batch Acc: 71.88
[Train] Epoch: 0 [61696/620022]    Loss: 0.011564   Batch Acc: 70.31
[Train] Epoch: 0 [61760/620022]    Loss: 0.012243   Batch Acc: 64.06
[Train] Epoch: 0 [61824/620022]    Loss: 0.011330   Batch Acc: 70.31
[Train] Epoch: 0 [61888/620022]    Loss: 0.012459   Batch Acc: 65.62
[Train] Epoch: 0 [61952/620022]    Loss: 0.013082   Batch Acc: 64.06
[Train] Epoch: 0 [62016/620022]    Loss: 0.012429   Batch Acc: 67.19
[Train] Epoch: 0 [62080/620022]    Loss: 0.013888   Batch Acc: 60.94
[Train] Epoch: 0 [62144/620022]    Loss: 0.012680   Batch Acc: 67.19
[Train] Epoch: 0 [62208/620022]    Loss: 0.012456   Batch Acc: 59.38
[Train] Epoch: 0 [62272/620022]    Loss: 0.011386   Batch Acc: 68.75
[Train] Epoch: 0 [62336/620022]    Loss: 0.011364   Batch Acc: 73.44
[Train] Epoch: 0 [62400/620022]    Loss: 0.012225   Batch Acc: 64.06
[Train] Epoch: 0 [62464/620022]    Loss: 0.009788   Batch Acc: 79.69
[Train] Epoch: 0 [62528/620022]    Loss: 0.010461   Batch Acc: 78.12
[Train] Epoch: 0 [62592/620022]    Loss: 0.013087   Batch Acc: 60.94
[Train] Epoch: 0 [62656/620022]    Loss: 0.010833   Batch Acc: 75.00
[Train] Epoch: 0 [62720/620022]    Loss: 0.010351   Batch Acc: 73.44
[Train] Epoch: 0 [62784/620022]    Loss: 0.010875   Batch Acc: 75.00
[Train] Epoch: 0 [62848/620022]    Loss: 0.012365   Batch Acc: 64.06
[Train] Epoch: 0 [62912/620022]    Loss: 0.011206   Batch Acc: 71.88
[Train] Epoch: 0 [62976/620022]    Loss: 0.012401   Batch Acc: 68.75
[Train] Epoch: 0 [63040/620022]    Loss: 0.010560   Batch Acc: 70.31
[Train] Epoch: 0 [63104/620022]    Loss: 0.011345   Batch Acc: 67.19
[Train] Epoch: 0 [63168/620022]    Loss: 0.011978   Batch Acc: 64.06
[Train] Epoch: 0 [63232/620022]    Loss: 0.012830   Batch Acc: 62.50
[Train] Epoch: 0 [63296/620022]    Loss: 0.011603   Batch Acc: 67.19
[Train] Epoch: 0 [63360/620022]    Loss: 0.012374   Batch Acc: 64.06
[Train] Epoch: 0 [63424/620022]    Loss: 0.013155   Batch Acc: 60.94
[Train] Epoch: 0 [63488/620022]    Loss: 0.012100   Batch Acc: 59.38
[Train] Epoch: 0 [63552/620022]    Loss: 0.010362   Batch Acc: 78.12
[Train] Epoch: 0 [63616/620022]    Loss: 0.011016   Batch Acc: 68.75
[Train] Epoch: 0 [63680/620022]    Loss: 0.011853   Batch Acc: 62.50
[Train] Epoch: 0 [63744/620022]    Loss: 0.010096   Batch Acc: 81.25
[Train] Epoch: 0 [63808/620022]    Loss: 0.014312   Batch Acc: 59.38
[Train] Epoch: 0 [63872/620022]    Loss: 0.013034   Batch Acc: 60.94
[Train] Epoch: 0 [63936/620022]    Loss: 0.012572   Batch Acc: 62.50
[Train] Epoch: 0 [64000/620022]    Loss: 0.013819   Batch Acc: 57.81
[Train] Epoch: 0 [64064/620022]    Loss: 0.010789   Batch Acc: 76.56
[Train] Epoch: 0 [64128/620022]    Loss: 0.012350   Batch Acc: 64.06
[Train] Epoch: 0 [64192/620022]    Loss: 0.011641   Batch Acc: 70.31
[Train] Epoch: 0 [64256/620022]    Loss: 0.012863   Batch Acc: 62.50
[Train] Epoch: 0 [64320/620022]    Loss: 0.013056   Batch Acc: 59.38
[Train] Epoch: 0 [64384/620022]    Loss: 0.010524   Batch Acc: 70.31
[Train] Epoch: 0 [64448/620022]    Loss: 0.010574   Batch Acc: 67.19
[Train] Epoch: 0 [64512/620022]    Loss: 0.012312   Batch Acc: 64.06
[Train] Epoch: 0 [64576/620022]    Loss: 0.013175   Batch Acc: 57.81
[Train] Epoch: 0 [64640/620022]    Loss: 0.012333   Batch Acc: 60.94
[Train] Epoch: 0 [64704/620022]    Loss: 0.012524   Batch Acc: 71.88
[Train] Epoch: 0 [64768/620022]    Loss: 0.012124   Batch Acc: 68.75
[Train] Epoch: 0 [64832/620022]    Loss: 0.012862   Batch Acc: 59.38
[Train] Epoch: 0 [64896/620022]    Loss: 0.013138   Batch Acc: 60.94
[Train] Epoch: 0 [64960/620022]    Loss: 0.011439   Batch Acc: 68.75
[Train] Epoch: 0 [65024/620022]    Loss: 0.011450   Batch Acc: 70.31
[Train] Epoch: 0 [65088/620022]    Loss: 0.012939   Batch Acc: 68.75
[Train] Epoch: 0 [65152/620022]    Loss: 0.012749   Batch Acc: 68.75
[Train] Epoch: 0 [65216/620022]    Loss: 0.013134   Batch Acc: 64.06
[Train] Epoch: 0 [65280/620022]    Loss: 0.011805   Batch Acc: 68.75
[Train] Epoch: 0 [65344/620022]    Loss: 0.012396   Batch Acc: 65.62
[Train] Epoch: 0 [65408/620022]    Loss: 0.014043   Batch Acc: 56.25
[Train] Epoch: 0 [65472/620022]    Loss: 0.012021   Batch Acc: 60.94
[Train] Epoch: 0 [65536/620022]    Loss: 0.014028   Batch Acc: 64.06
[Train] Epoch: 0 [65600/620022]    Loss: 0.014899   Batch Acc: 56.25
[Train] Epoch: 0 [65664/620022]    Loss: 0.010810   Batch Acc: 78.12
[Train] Epoch: 0 [65728/620022]    Loss: 0.013084   Batch Acc: 65.62
[Train] Epoch: 0 [65792/620022]    Loss: 0.011039   Batch Acc: 71.88
[Train] Epoch: 0 [65856/620022]    Loss: 0.010945   Batch Acc: 68.75
[Train] Epoch: 0 [65920/620022]    Loss: 0.012773   Batch Acc: 59.38
[Train] Epoch: 0 [65984/620022]    Loss: 0.011849   Batch Acc: 70.31
[Train] Epoch: 0 [66048/620022]    Loss: 0.010511   Batch Acc: 76.56
[Train] Epoch: 0 [66112/620022]    Loss: 0.011959   Batch Acc: 62.50
[Train] Epoch: 0 [66176/620022]    Loss: 0.010605   Batch Acc: 68.75
[Train] Epoch: 0 [66240/620022]    Loss: 0.010850   Batch Acc: 68.75
[Train] Epoch: 0 [66304/620022]    Loss: 0.010528   Batch Acc: 76.56
[Train] Epoch: 0 [66368/620022]    Loss: 0.011547   Batch Acc: 71.88
[Train] Epoch: 0 [66432/620022]    Loss: 0.010102   Batch Acc: 81.25
[Train] Epoch: 0 [66496/620022]    Loss: 0.010181   Batch Acc: 71.88
[Train] Epoch: 0 [66560/620022]    Loss: 0.012302   Batch Acc: 68.75
[Train] Epoch: 0 [66624/620022]    Loss: 0.012319   Batch Acc: 65.62
[Train] Epoch: 0 [66688/620022]    Loss: 0.011876   Batch Acc: 73.44
[Train] Epoch: 0 [66752/620022]    Loss: 0.012457   Batch Acc: 68.75
[Train] Epoch: 0 [66816/620022]    Loss: 0.013010   Batch Acc: 60.94
[Train] Epoch: 0 [66880/620022]    Loss: 0.011465   Batch Acc: 70.31
[Train] Epoch: 0 [66944/620022]    Loss: 0.012430   Batch Acc: 65.62
[Train] Epoch: 0 [67008/620022]    Loss: 0.012657   Batch Acc: 62.50
[Train] Epoch: 0 [67072/620022]    Loss: 0.014877   Batch Acc: 50.00
[Train] Epoch: 0 [67136/620022]    Loss: 0.010521   Batch Acc: 71.88
[Train] Epoch: 0 [67200/620022]    Loss: 0.013070   Batch Acc: 62.50
[Train] Epoch: 0 [67264/620022]    Loss: 0.013428   Batch Acc: 60.94
[Train] Epoch: 0 [67328/620022]    Loss: 0.013269   Batch Acc: 60.94
[Train] Epoch: 0 [67392/620022]    Loss: 0.011071   Batch Acc: 65.62
[Train] Epoch: 0 [67456/620022]    Loss: 0.012434   Batch Acc: 68.75
[Train] Epoch: 0 [67520/620022]    Loss: 0.013052   Batch Acc: 67.19
[Train] Epoch: 0 [67584/620022]    Loss: 0.011334   Batch Acc: 71.88
[Train] Epoch: 0 [67648/620022]    Loss: 0.010032   Batch Acc: 81.25
[Train] Epoch: 0 [67712/620022]    Loss: 0.013281   Batch Acc: 60.94
[Train] Epoch: 0 [67776/620022]    Loss: 0.011848   Batch Acc: 68.75
[Train] Epoch: 0 [67840/620022]    Loss: 0.011192   Batch Acc: 75.00
[Train] Epoch: 0 [67904/620022]    Loss: 0.013256   Batch Acc: 62.50
[Train] Epoch: 0 [67968/620022]    Loss: 0.011700   Batch Acc: 70.31
[Train] Epoch: 0 [68032/620022]    Loss: 0.009792   Batch Acc: 71.88
[Train] Epoch: 0 [68096/620022]    Loss: 0.011109   Batch Acc: 73.44
[Train] Epoch: 0 [68160/620022]    Loss: 0.015383   Batch Acc: 50.00
[Train] Epoch: 0 [68224/620022]    Loss: 0.011812   Batch Acc: 65.62
[Train] Epoch: 0 [68288/620022]    Loss: 0.011364   Batch Acc: 65.62
[Train] Epoch: 0 [68352/620022]    Loss: 0.009390   Batch Acc: 81.25
[Train] Epoch: 0 [68416/620022]    Loss: 0.011418   Batch Acc: 67.19
[Train] Epoch: 0 [68480/620022]    Loss: 0.011019   Batch Acc: 68.75
[Train] Epoch: 0 [68544/620022]    Loss: 0.011544   Batch Acc: 67.19
[Train] Epoch: 0 [68608/620022]    Loss: 0.011144   Batch Acc: 70.31
[Train] Epoch: 0 [68672/620022]    Loss: 0.013243   Batch Acc: 56.25
[Train] Epoch: 0 [68736/620022]    Loss: 0.012412   Batch Acc: 67.19
[Train] Epoch: 0 [68800/620022]    Loss: 0.010673   Batch Acc: 78.12
[Train] Epoch: 0 [68864/620022]    Loss: 0.010758   Batch Acc: 73.44
[Train] Epoch: 0 [68928/620022]    Loss: 0.012426   Batch Acc: 62.50
[Train] Epoch: 0 [68992/620022]    Loss: 0.011899   Batch Acc: 67.19
[Train] Epoch: 0 [69056/620022]    Loss: 0.010817   Batch Acc: 75.00
[Train] Epoch: 0 [69120/620022]    Loss: 0.013647   Batch Acc: 62.50
[Train] Epoch: 0 [69184/620022]    Loss: 0.009991   Batch Acc: 79.69
[Train] Epoch: 0 [69248/620022]    Loss: 0.010515   Batch Acc: 71.88
[Train] Epoch: 0 [69312/620022]    Loss: 0.011802   Batch Acc: 68.75
[Train] Epoch: 0 [69376/620022]    Loss: 0.013508   Batch Acc: 62.50
[Train] Epoch: 0 [69440/620022]    Loss: 0.012129   Batch Acc: 64.06
[Train] Epoch: 0 [69504/620022]    Loss: 0.011061   Batch Acc: 75.00
[Train] Epoch: 0 [69568/620022]    Loss: 0.012949   Batch Acc: 64.06
[Train] Epoch: 0 [69632/620022]    Loss: 0.013377   Batch Acc: 56.25
[Train] Epoch: 0 [69696/620022]    Loss: 0.012469   Batch Acc: 70.31
[Train] Epoch: 0 [69760/620022]    Loss: 0.011890   Batch Acc: 67.19
[Train] Epoch: 0 [69824/620022]    Loss: 0.012674   Batch Acc: 67.19
[Train] Epoch: 0 [69888/620022]    Loss: 0.009980   Batch Acc: 84.38
[Train] Epoch: 0 [69952/620022]    Loss: 0.013002   Batch Acc: 59.38
[Train] Epoch: 0 [70016/620022]    Loss: 0.012243   Batch Acc: 64.06
[Train] Epoch: 0 [70080/620022]    Loss: 0.012525   Batch Acc: 62.50
[Train] Epoch: 0 [70144/620022]    Loss: 0.010551   Batch Acc: 79.69
[Train] Epoch: 0 [70208/620022]    Loss: 0.011393   Batch Acc: 68.75
[Train] Epoch: 0 [70272/620022]    Loss: 0.010725   Batch Acc: 71.88
[Train] Epoch: 0 [70336/620022]    Loss: 0.010795   Batch Acc: 71.88
[Train] Epoch: 0 [70400/620022]    Loss: 0.012538   Batch Acc: 62.50
[Train] Epoch: 0 [70464/620022]    Loss: 0.011994   Batch Acc: 70.31
[Train] Epoch: 0 [70528/620022]    Loss: 0.012942   Batch Acc: 60.94
[Train] Epoch: 0 [70592/620022]    Loss: 0.012598   Batch Acc: 60.94
[Train] Epoch: 0 [70656/620022]    Loss: 0.012401   Batch Acc: 64.06
[Train] Epoch: 0 [70720/620022]    Loss: 0.011289   Batch Acc: 76.56
[Train] Epoch: 0 [70784/620022]    Loss: 0.011515   Batch Acc: 68.75
[Train] Epoch: 0 [70848/620022]    Loss: 0.012295   Batch Acc: 64.06
[Train] Epoch: 0 [70912/620022]    Loss: 0.010621   Batch Acc: 68.75
[Train] Epoch: 0 [70976/620022]    Loss: 0.011143   Batch Acc: 73.44
[Train] Epoch: 0 [71040/620022]    Loss: 0.012548   Batch Acc: 68.75
[Train] Epoch: 0 [71104/620022]    Loss: 0.012621   Batch Acc: 67.19
[Train] Epoch: 0 [71168/620022]    Loss: 0.010850   Batch Acc: 73.44
[Train] Epoch: 0 [71232/620022]    Loss: 0.010856   Batch Acc: 68.75
[Train] Epoch: 0 [71296/620022]    Loss: 0.011792   Batch Acc: 70.31
[Train] Epoch: 0 [71360/620022]    Loss: 0.010918   Batch Acc: 76.56
[Train] Epoch: 0 [71424/620022]    Loss: 0.012337   Batch Acc: 62.50
[Train] Epoch: 0 [71488/620022]    Loss: 0.012041   Batch Acc: 71.88
[Train] Epoch: 0 [71552/620022]    Loss: 0.012737   Batch Acc: 67.19
[Train] Epoch: 0 [71616/620022]    Loss: 0.010739   Batch Acc: 73.44
[Train] Epoch: 0 [71680/620022]    Loss: 0.013304   Batch Acc: 64.06
[Train] Epoch: 0 [71744/620022]    Loss: 0.010280   Batch Acc: 71.88
[Train] Epoch: 0 [71808/620022]    Loss: 0.009575   Batch Acc: 79.69
[Train] Epoch: 0 [71872/620022]    Loss: 0.012514   Batch Acc: 67.19
[Train] Epoch: 0 [71936/620022]    Loss: 0.011319   Batch Acc: 71.88
[Train] Epoch: 0 [72000/620022]    Loss: 0.013494   Batch Acc: 57.81
[Train] Epoch: 0 [72064/620022]    Loss: 0.011082   Batch Acc: 71.88
[Train] Epoch: 0 [72128/620022]    Loss: 0.013553   Batch Acc: 64.06
[Train] Epoch: 0 [72192/620022]    Loss: 0.010023   Batch Acc: 75.00
[Train] Epoch: 0 [72256/620022]    Loss: 0.011345   Batch Acc: 68.75
[Train] Epoch: 0 [72320/620022]    Loss: 0.010428   Batch Acc: 76.56
[Train] Epoch: 0 [72384/620022]    Loss: 0.010378   Batch Acc: 73.44
[Train] Epoch: 0 [72448/620022]    Loss: 0.012046   Batch Acc: 65.62
[Train] Epoch: 0 [72512/620022]    Loss: 0.010921   Batch Acc: 75.00
[Train] Epoch: 0 [72576/620022]    Loss: 0.012065   Batch Acc: 68.75
[Train] Epoch: 0 [72640/620022]    Loss: 0.011263   Batch Acc: 70.31
[Train] Epoch: 0 [72704/620022]    Loss: 0.011314   Batch Acc: 71.88
[Train] Epoch: 0 [72768/620022]    Loss: 0.012444   Batch Acc: 65.62
[Train] Epoch: 0 [72832/620022]    Loss: 0.011220   Batch Acc: 67.19
[Train] Epoch: 0 [72896/620022]    Loss: 0.012364   Batch Acc: 62.50
[Train] Epoch: 0 [72960/620022]    Loss: 0.010175   Batch Acc: 76.56
[Train] Epoch: 0 [73024/620022]    Loss: 0.013571   Batch Acc: 65.62
[Train] Epoch: 0 [73088/620022]    Loss: 0.011157   Batch Acc: 67.19
[Train] Epoch: 0 [73152/620022]    Loss: 0.013843   Batch Acc: 59.38
[Train] Epoch: 0 [73216/620022]    Loss: 0.011689   Batch Acc: 62.50
[Train] Epoch: 0 [73280/620022]    Loss: 0.010271   Batch Acc: 78.12
[Train] Epoch: 0 [73344/620022]    Loss: 0.012400   Batch Acc: 67.19
[Train] Epoch: 0 [73408/620022]    Loss: 0.012526   Batch Acc: 68.75
[Train] Epoch: 0 [73472/620022]    Loss: 0.011621   Batch Acc: 68.75
[Train] Epoch: 0 [73536/620022]    Loss: 0.011618   Batch Acc: 76.56
[Train] Epoch: 0 [73600/620022]    Loss: 0.010721   Batch Acc: 71.88
[Train] Epoch: 0 [73664/620022]    Loss: 0.011204   Batch Acc: 71.88
[Train] Epoch: 0 [73728/620022]    Loss: 0.010924   Batch Acc: 71.88
[Train] Epoch: 0 [73792/620022]    Loss: 0.012968   Batch Acc: 68.75
[Train] Epoch: 0 [73856/620022]    Loss: 0.011017   Batch Acc: 70.31
[Train] Epoch: 0 [73920/620022]    Loss: 0.011731   Batch Acc: 64.06
[Train] Epoch: 0 [73984/620022]    Loss: 0.010398   Batch Acc: 71.88
[Train] Epoch: 0 [74048/620022]    Loss: 0.010880   Batch Acc: 71.88
[Train] Epoch: 0 [74112/620022]    Loss: 0.010929   Batch Acc: 68.75
[Train] Epoch: 0 [74176/620022]    Loss: 0.010912   Batch Acc: 67.19
[Train] Epoch: 0 [74240/620022]    Loss: 0.010650   Batch Acc: 78.12
[Train] Epoch: 0 [74304/620022]    Loss: 0.012077   Batch Acc: 65.62
[Train] Epoch: 0 [74368/620022]    Loss: 0.012295   Batch Acc: 67.19
[Train] Epoch: 0 [74432/620022]    Loss: 0.010833   Batch Acc: 70.31
[Train] Epoch: 0 [74496/620022]    Loss: 0.013064   Batch Acc: 59.38
[Train] Epoch: 0 [74560/620022]    Loss: 0.012277   Batch Acc: 68.75
[Train] Epoch: 0 [74624/620022]    Loss: 0.009841   Batch Acc: 76.56
[Train] Epoch: 0 [74688/620022]    Loss: 0.011080   Batch Acc: 76.56
[Train] Epoch: 0 [74752/620022]    Loss: 0.010836   Batch Acc: 70.31
[Train] Epoch: 0 [74816/620022]    Loss: 0.013594   Batch Acc: 67.19
[Train] Epoch: 0 [74880/620022]    Loss: 0.013181   Batch Acc: 56.25
[Train] Epoch: 0 [74944/620022]    Loss: 0.009888   Batch Acc: 75.00
[Train] Epoch: 0 [75008/620022]    Loss: 0.010662   Batch Acc: 76.56
[Train] Epoch: 0 [75072/620022]    Loss: 0.012330   Batch Acc: 71.88
[Train] Epoch: 0 [75136/620022]    Loss: 0.012750   Batch Acc: 64.06
[Train] Epoch: 0 [75200/620022]    Loss: 0.010682   Batch Acc: 73.44
[Train] Epoch: 0 [75264/620022]    Loss: 0.012356   Batch Acc: 62.50
[Train] Epoch: 0 [75328/620022]    Loss: 0.010593   Batch Acc: 67.19
[Train] Epoch: 0 [75392/620022]    Loss: 0.012375   Batch Acc: 64.06
[Train] Epoch: 0 [75456/620022]    Loss: 0.011177   Batch Acc: 70.31
[Train] Epoch: 0 [75520/620022]    Loss: 0.010132   Batch Acc: 70.31
[Train] Epoch: 0 [75584/620022]    Loss: 0.010311   Batch Acc: 79.69
[Train] Epoch: 0 [75648/620022]    Loss: 0.012682   Batch Acc: 56.25
[Train] Epoch: 0 [75712/620022]    Loss: 0.012353   Batch Acc: 70.31
[Train] Epoch: 0 [75776/620022]    Loss: 0.012338   Batch Acc: 68.75
[Train] Epoch: 0 [75840/620022]    Loss: 0.009730   Batch Acc: 73.44
[Train] Epoch: 0 [75904/620022]    Loss: 0.014491   Batch Acc: 57.81
[Train] Epoch: 0 [75968/620022]    Loss: 0.011145   Batch Acc: 84.38
[Train] Epoch: 0 [76032/620022]    Loss: 0.009838   Batch Acc: 79.69
[Train] Epoch: 0 [76096/620022]    Loss: 0.011282   Batch Acc: 73.44
[Train] Epoch: 0 [76160/620022]    Loss: 0.011551   Batch Acc: 65.62
[Train] Epoch: 0 [76224/620022]    Loss: 0.012008   Batch Acc: 67.19
[Train] Epoch: 0 [76288/620022]    Loss: 0.010528   Batch Acc: 70.31
[Train] Epoch: 0 [76352/620022]    Loss: 0.010651   Batch Acc: 79.69
[Train] Epoch: 0 [76416/620022]    Loss: 0.012243   Batch Acc: 62.50
[Train] Epoch: 0 [76480/620022]    Loss: 0.011539   Batch Acc: 67.19
[Train] Epoch: 0 [76544/620022]    Loss: 0.012553   Batch Acc: 67.19
[Train] Epoch: 0 [76608/620022]    Loss: 0.012114   Batch Acc: 67.19
[Train] Epoch: 0 [76672/620022]    Loss: 0.011813   Batch Acc: 62.50
[Train] Epoch: 0 [76736/620022]    Loss: 0.012178   Batch Acc: 65.62
[Train] Epoch: 0 [76800/620022]    Loss: 0.010676   Batch Acc: 70.31
[Train] Epoch: 0 [76864/620022]    Loss: 0.011030   Batch Acc: 65.62
[Train] Epoch: 0 [76928/620022]    Loss: 0.012675   Batch Acc: 65.62
[Train] Epoch: 0 [76992/620022]    Loss: 0.010531   Batch Acc: 71.88
[Train] Epoch: 0 [77056/620022]    Loss: 0.009563   Batch Acc: 76.56
[Train] Epoch: 0 [77120/620022]    Loss: 0.010267   Batch Acc: 76.56
[Train] Epoch: 0 [77184/620022]    Loss: 0.011099   Batch Acc: 68.75
[Train] Epoch: 0 [77248/620022]    Loss: 0.012882   Batch Acc: 62.50
[Train] Epoch: 0 [77312/620022]    Loss: 0.010444   Batch Acc: 75.00
[Train] Epoch: 0 [77376/620022]    Loss: 0.013205   Batch Acc: 65.62
[Train] Epoch: 0 [77440/620022]    Loss: 0.012180   Batch Acc: 64.06
[Train] Epoch: 0 [77504/620022]    Loss: 0.012501   Batch Acc: 70.31
[Train] Epoch: 0 [77568/620022]    Loss: 0.010141   Batch Acc: 76.56
[Train] Epoch: 0 [77632/620022]    Loss: 0.010685   Batch Acc: 73.44
[Train] Epoch: 0 [77696/620022]    Loss: 0.011027   Batch Acc: 70.31
[Train] Epoch: 0 [77760/620022]    Loss: 0.010479   Batch Acc: 71.88
[Train] Epoch: 0 [77824/620022]    Loss: 0.011168   Batch Acc: 68.75
[Train] Epoch: 0 [77888/620022]    Loss: 0.011600   Batch Acc: 73.44
[Train] Epoch: 0 [77952/620022]    Loss: 0.009519   Batch Acc: 73.44
[Train] Epoch: 0 [78016/620022]    Loss: 0.012203   Batch Acc: 67.19
[Train] Epoch: 0 [78080/620022]    Loss: 0.010125   Batch Acc: 76.56
[Train] Epoch: 0 [78144/620022]    Loss: 0.011977   Batch Acc: 68.75
[Train] Epoch: 0 [78208/620022]    Loss: 0.011756   Batch Acc: 70.31
[Train] Epoch: 0 [78272/620022]    Loss: 0.013274   Batch Acc: 54.69
[Train] Epoch: 0 [78336/620022]    Loss: 0.012680   Batch Acc: 67.19
[Train] Epoch: 0 [78400/620022]    Loss: 0.011984   Batch Acc: 68.75
[Train] Epoch: 0 [78464/620022]    Loss: 0.009867   Batch Acc: 82.81
[Train] Epoch: 0 [78528/620022]    Loss: 0.013147   Batch Acc: 59.38
[Train] Epoch: 0 [78592/620022]    Loss: 0.012559   Batch Acc: 59.38
[Train] Epoch: 0 [78656/620022]    Loss: 0.011650   Batch Acc: 64.06
[Train] Epoch: 0 [78720/620022]    Loss: 0.013085   Batch Acc: 60.94
[Train] Epoch: 0 [78784/620022]    Loss: 0.012032   Batch Acc: 70.31
[Train] Epoch: 0 [78848/620022]    Loss: 0.011984   Batch Acc: 68.75
[Train] Epoch: 0 [78912/620022]    Loss: 0.011357   Batch Acc: 68.75
[Train] Epoch: 0 [78976/620022]    Loss: 0.012260   Batch Acc: 68.75
[Train] Epoch: 0 [79040/620022]    Loss: 0.012069   Batch Acc: 60.94
[Train] Epoch: 0 [79104/620022]    Loss: 0.009550   Batch Acc: 75.00
[Train] Epoch: 0 [79168/620022]    Loss: 0.012065   Batch Acc: 68.75
[Train] Epoch: 0 [79232/620022]    Loss: 0.011525   Batch Acc: 65.62
[Train] Epoch: 0 [79296/620022]    Loss: 0.011357   Batch Acc: 67.19
[Train] Epoch: 0 [79360/620022]    Loss: 0.010488   Batch Acc: 76.56
[Train] Epoch: 0 [79424/620022]    Loss: 0.012414   Batch Acc: 64.06
[Train] Epoch: 0 [79488/620022]    Loss: 0.010826   Batch Acc: 79.69
[Train] Epoch: 0 [79552/620022]    Loss: 0.011628   Batch Acc: 75.00
[Train] Epoch: 0 [79616/620022]    Loss: 0.012721   Batch Acc: 60.94
[Train] Epoch: 0 [79680/620022]    Loss: 0.013060   Batch Acc: 65.62
[Train] Epoch: 0 [79744/620022]    Loss: 0.012620   Batch Acc: 60.94
[Train] Epoch: 0 [79808/620022]    Loss: 0.011234   Batch Acc: 62.50
[Train] Epoch: 0 [79872/620022]    Loss: 0.010387   Batch Acc: 75.00
[Train] Epoch: 0 [79936/620022]    Loss: 0.012925   Batch Acc: 62.50
[Train] Epoch: 0 [80000/620022]    Loss: 0.012476   Batch Acc: 68.75
[Train] Epoch: 0 [80064/620022]    Loss: 0.013199   Batch Acc: 56.25
[Train] Epoch: 0 [80128/620022]    Loss: 0.010835   Batch Acc: 71.88
[Train] Epoch: 0 [80192/620022]    Loss: 0.012796   Batch Acc: 64.06
[Train] Epoch: 0 [80256/620022]    Loss: 0.013455   Batch Acc: 59.38
[Train] Epoch: 0 [80320/620022]    Loss: 0.013032   Batch Acc: 57.81
[Train] Epoch: 0 [80384/620022]    Loss: 0.011025   Batch Acc: 68.75
[Train] Epoch: 0 [80448/620022]    Loss: 0.013439   Batch Acc: 59.38
[Train] Epoch: 0 [80512/620022]    Loss: 0.011846   Batch Acc: 70.31
[Train] Epoch: 0 [80576/620022]    Loss: 0.010727   Batch Acc: 71.88
[Train] Epoch: 0 [80640/620022]    Loss: 0.009045   Batch Acc: 78.12
[Train] Epoch: 0 [80704/620022]    Loss: 0.012557   Batch Acc: 64.06
[Train] Epoch: 0 [80768/620022]    Loss: 0.011223   Batch Acc: 65.62
[Train] Epoch: 0 [80832/620022]    Loss: 0.010380   Batch Acc: 79.69
[Train] Epoch: 0 [80896/620022]    Loss: 0.011593   Batch Acc: 62.50
[Train] Epoch: 0 [80960/620022]    Loss: 0.010254   Batch Acc: 70.31
[Train] Epoch: 0 [81024/620022]    Loss: 0.011014   Batch Acc: 73.44
[Train] Epoch: 0 [81088/620022]    Loss: 0.010239   Batch Acc: 67.19
[Train] Epoch: 0 [81152/620022]    Loss: 0.011852   Batch Acc: 64.06
[Train] Epoch: 0 [81216/620022]    Loss: 0.010531   Batch Acc: 71.88
[Train] Epoch: 0 [81280/620022]    Loss: 0.012515   Batch Acc: 64.06
[Train] Epoch: 0 [81344/620022]    Loss: 0.009983   Batch Acc: 75.00
[Train] Epoch: 0 [81408/620022]    Loss: 0.009828   Batch Acc: 79.69
[Train] Epoch: 0 [81472/620022]    Loss: 0.012276   Batch Acc: 59.38
[Train] Epoch: 0 [81536/620022]    Loss: 0.008571   Batch Acc: 84.38
[Train] Epoch: 0 [81600/620022]    Loss: 0.010946   Batch Acc: 73.44
[Train] Epoch: 0 [81664/620022]    Loss: 0.011766   Batch Acc: 68.75
[Train] Epoch: 0 [81728/620022]    Loss: 0.011715   Batch Acc: 62.50
[Train] Epoch: 0 [81792/620022]    Loss: 0.010215   Batch Acc: 75.00
[Train] Epoch: 0 [81856/620022]    Loss: 0.011420   Batch Acc: 65.62
[Train] Epoch: 0 [81920/620022]    Loss: 0.010238   Batch Acc: 75.00
[Train] Epoch: 0 [81984/620022]    Loss: 0.010535   Batch Acc: 75.00
[Train] Epoch: 0 [82048/620022]    Loss: 0.011385   Batch Acc: 68.75
[Train] Epoch: 0 [82112/620022]    Loss: 0.012806   Batch Acc: 64.06
[Train] Epoch: 0 [82176/620022]    Loss: 0.010092   Batch Acc: 78.12
[Train] Epoch: 0 [82240/620022]    Loss: 0.011954   Batch Acc: 68.75
[Train] Epoch: 0 [82304/620022]    Loss: 0.012202   Batch Acc: 70.31
[Train] Epoch: 0 [82368/620022]    Loss: 0.008891   Batch Acc: 84.38
[Train] Epoch: 0 [82432/620022]    Loss: 0.011855   Batch Acc: 64.06
[Train] Epoch: 0 [82496/620022]    Loss: 0.011200   Batch Acc: 68.75
[Train] Epoch: 0 [82560/620022]    Loss: 0.010270   Batch Acc: 67.19
[Train] Epoch: 0 [82624/620022]    Loss: 0.011508   Batch Acc: 67.19
[Train] Epoch: 0 [82688/620022]    Loss: 0.010810   Batch Acc: 70.31
[Train] Epoch: 0 [82752/620022]    Loss: 0.010278   Batch Acc: 73.44
[Train] Epoch: 0 [82816/620022]    Loss: 0.011796   Batch Acc: 71.88
[Train] Epoch: 0 [82880/620022]    Loss: 0.010160   Batch Acc: 68.75
[Train] Epoch: 0 [82944/620022]    Loss: 0.009862   Batch Acc: 79.69
[Train] Epoch: 0 [83008/620022]    Loss: 0.010717   Batch Acc: 75.00
[Train] Epoch: 0 [83072/620022]    Loss: 0.010550   Batch Acc: 71.88
[Train] Epoch: 0 [83136/620022]    Loss: 0.010654   Batch Acc: 71.88
[Train] Epoch: 0 [83200/620022]    Loss: 0.009888   Batch Acc: 75.00
[Train] Epoch: 0 [83264/620022]    Loss: 0.010238   Batch Acc: 76.56
[Train] Epoch: 0 [83328/620022]    Loss: 0.009391   Batch Acc: 76.56
[Train] Epoch: 0 [83392/620022]    Loss: 0.009948   Batch Acc: 78.12
[Train] Epoch: 0 [83456/620022]    Loss: 0.009660   Batch Acc: 78.12
[Train] Epoch: 0 [83520/620022]    Loss: 0.010640   Batch Acc: 68.75
[Train] Epoch: 0 [83584/620022]    Loss: 0.011601   Batch Acc: 64.06
[Train] Epoch: 0 [83648/620022]    Loss: 0.011470   Batch Acc: 71.88
[Train] Epoch: 0 [83712/620022]    Loss: 0.010284   Batch Acc: 78.12
[Train] Epoch: 0 [83776/620022]    Loss: 0.011901   Batch Acc: 68.75
[Train] Epoch: 0 [83840/620022]    Loss: 0.010652   Batch Acc: 73.44
[Train] Epoch: 0 [83904/620022]    Loss: 0.010350   Batch Acc: 75.00
[Train] Epoch: 0 [83968/620022]    Loss: 0.011833   Batch Acc: 71.88
[Train] Epoch: 0 [84032/620022]    Loss: 0.010334   Batch Acc: 71.88
[Train] Epoch: 0 [84096/620022]    Loss: 0.010042   Batch Acc: 78.12
[Train] Epoch: 0 [84160/620022]    Loss: 0.013059   Batch Acc: 64.06
[Train] Epoch: 0 [84224/620022]    Loss: 0.011651   Batch Acc: 73.44
[Train] Epoch: 0 [84288/620022]    Loss: 0.011041   Batch Acc: 71.88
[Train] Epoch: 0 [84352/620022]    Loss: 0.013035   Batch Acc: 70.31
[Train] Epoch: 0 [84416/620022]    Loss: 0.010269   Batch Acc: 78.12
[Train] Epoch: 0 [84480/620022]    Loss: 0.011209   Batch Acc: 68.75
[Train] Epoch: 0 [84544/620022]    Loss: 0.012363   Batch Acc: 71.88
[Train] Epoch: 0 [84608/620022]    Loss: 0.010998   Batch Acc: 68.75
[Train] Epoch: 0 [84672/620022]    Loss: 0.011825   Batch Acc: 71.88
[Train] Epoch: 0 [84736/620022]    Loss: 0.011153   Batch Acc: 70.31
[Train] Epoch: 0 [84800/620022]    Loss: 0.011320   Batch Acc: 71.88
[Train] Epoch: 0 [84864/620022]    Loss: 0.011797   Batch Acc: 62.50
[Train] Epoch: 0 [84928/620022]    Loss: 0.011975   Batch Acc: 64.06
[Train] Epoch: 0 [84992/620022]    Loss: 0.012277   Batch Acc: 71.88
[Train] Epoch: 0 [85056/620022]    Loss: 0.012584   Batch Acc: 68.75
[Train] Epoch: 0 [85120/620022]    Loss: 0.012054   Batch Acc: 68.75
[Train] Epoch: 0 [85184/620022]    Loss: 0.010147   Batch Acc: 78.12
[Train] Epoch: 0 [85248/620022]    Loss: 0.010851   Batch Acc: 67.19
[Train] Epoch: 0 [85312/620022]    Loss: 0.009417   Batch Acc: 78.12
[Train] Epoch: 0 [85376/620022]    Loss: 0.010370   Batch Acc: 71.88
[Train] Epoch: 0 [85440/620022]    Loss: 0.010190   Batch Acc: 73.44
[Train] Epoch: 0 [85504/620022]    Loss: 0.012574   Batch Acc: 67.19
[Train] Epoch: 0 [85568/620022]    Loss: 0.010531   Batch Acc: 71.88
[Train] Epoch: 0 [85632/620022]    Loss: 0.009145   Batch Acc: 81.25
[Train] Epoch: 0 [85696/620022]    Loss: 0.009854   Batch Acc: 75.00
[Train] Epoch: 0 [85760/620022]    Loss: 0.010429   Batch Acc: 76.56
[Train] Epoch: 0 [85824/620022]    Loss: 0.011401   Batch Acc: 76.56
[Train] Epoch: 0 [85888/620022]    Loss: 0.011296   Batch Acc: 65.62
[Train] Epoch: 0 [85952/620022]    Loss: 0.011678   Batch Acc: 65.62
[Train] Epoch: 0 [86016/620022]    Loss: 0.010593   Batch Acc: 71.88
[Train] Epoch: 0 [86080/620022]    Loss: 0.012213   Batch Acc: 70.31
[Train] Epoch: 0 [86144/620022]    Loss: 0.011644   Batch Acc: 67.19
[Train] Epoch: 0 [86208/620022]    Loss: 0.011072   Batch Acc: 71.88
[Train] Epoch: 0 [86272/620022]    Loss: 0.011151   Batch Acc: 68.75
[Train] Epoch: 0 [86336/620022]    Loss: 0.013319   Batch Acc: 62.50
[Train] Epoch: 0 [86400/620022]    Loss: 0.010161   Batch Acc: 73.44
[Train] Epoch: 0 [86464/620022]    Loss: 0.010319   Batch Acc: 73.44
[Train] Epoch: 0 [86528/620022]    Loss: 0.009830   Batch Acc: 81.25
[Train] Epoch: 0 [86592/620022]    Loss: 0.010720   Batch Acc: 70.31
[Train] Epoch: 0 [86656/620022]    Loss: 0.010912   Batch Acc: 76.56
[Train] Epoch: 0 [86720/620022]    Loss: 0.012122   Batch Acc: 60.94
[Train] Epoch: 0 [86784/620022]    Loss: 0.011883   Batch Acc: 64.06
[Train] Epoch: 0 [86848/620022]    Loss: 0.011567   Batch Acc: 64.06
[Train] Epoch: 0 [86912/620022]    Loss: 0.011958   Batch Acc: 65.62
[Train] Epoch: 0 [86976/620022]    Loss: 0.012179   Batch Acc: 65.62
[Train] Epoch: 0 [87040/620022]    Loss: 0.012251   Batch Acc: 70.31
[Train] Epoch: 0 [87104/620022]    Loss: 0.010312   Batch Acc: 76.56
[Train] Epoch: 0 [87168/620022]    Loss: 0.011504   Batch Acc: 65.62
[Train] Epoch: 0 [87232/620022]    Loss: 0.011183   Batch Acc: 70.31
[Train] Epoch: 0 [87296/620022]    Loss: 0.013047   Batch Acc: 60.94
[Train] Epoch: 0 [87360/620022]    Loss: 0.008930   Batch Acc: 82.81
[Train] Epoch: 0 [87424/620022]    Loss: 0.010664   Batch Acc: 70.31
[Train] Epoch: 0 [87488/620022]    Loss: 0.009811   Batch Acc: 79.69
[Train] Epoch: 0 [87552/620022]    Loss: 0.010589   Batch Acc: 75.00
[Train] Epoch: 0 [87616/620022]    Loss: 0.011364   Batch Acc: 70.31
[Train] Epoch: 0 [87680/620022]    Loss: 0.010172   Batch Acc: 71.88
[Train] Epoch: 0 [87744/620022]    Loss: 0.009695   Batch Acc: 75.00
[Train] Epoch: 0 [87808/620022]    Loss: 0.011204   Batch Acc: 71.88
[Train] Epoch: 0 [87872/620022]    Loss: 0.011197   Batch Acc: 71.88
[Train] Epoch: 0 [87936/620022]    Loss: 0.011400   Batch Acc: 62.50
[Train] Epoch: 0 [88000/620022]    Loss: 0.011503   Batch Acc: 70.31
[Train] Epoch: 0 [88064/620022]    Loss: 0.011933   Batch Acc: 65.62
[Train] Epoch: 0 [88128/620022]    Loss: 0.012292   Batch Acc: 68.75
[Train] Epoch: 0 [88192/620022]    Loss: 0.011430   Batch Acc: 70.31
[Train] Epoch: 0 [88256/620022]    Loss: 0.011184   Batch Acc: 67.19
[Train] Epoch: 0 [88320/620022]    Loss: 0.012024   Batch Acc: 65.62
[Train] Epoch: 0 [88384/620022]    Loss: 0.010388   Batch Acc: 71.88
[Train] Epoch: 0 [88448/620022]    Loss: 0.010229   Batch Acc: 76.56
[Train] Epoch: 0 [88512/620022]    Loss: 0.012333   Batch Acc: 64.06
[Train] Epoch: 0 [88576/620022]    Loss: 0.012296   Batch Acc: 65.62
[Train] Epoch: 0 [88640/620022]    Loss: 0.015690   Batch Acc: 50.00
[Train] Epoch: 0 [88704/620022]    Loss: 0.010739   Batch Acc: 68.75
[Train] Epoch: 0 [88768/620022]    Loss: 0.011344   Batch Acc: 65.62
[Train] Epoch: 0 [88832/620022]    Loss: 0.010083   Batch Acc: 75.00
[Train] Epoch: 0 [88896/620022]    Loss: 0.011581   Batch Acc: 65.62
[Train] Epoch: 0 [88960/620022]    Loss: 0.013280   Batch Acc: 64.06
[Train] Epoch: 0 [89024/620022]    Loss: 0.011517   Batch Acc: 68.75
[Train] Epoch: 0 [89088/620022]    Loss: 0.011355   Batch Acc: 68.75
[Train] Epoch: 0 [89152/620022]    Loss: 0.009519   Batch Acc: 79.69
[Train] Epoch: 0 [89216/620022]    Loss: 0.011835   Batch Acc: 70.31
[Train] Epoch: 0 [89280/620022]    Loss: 0.011078   Batch Acc: 70.31
[Train] Epoch: 0 [89344/620022]    Loss: 0.009798   Batch Acc: 78.12
[Train] Epoch: 0 [89408/620022]    Loss: 0.011778   Batch Acc: 64.06
[Train] Epoch: 0 [89472/620022]    Loss: 0.012586   Batch Acc: 59.38
[Train] Epoch: 0 [89536/620022]    Loss: 0.010291   Batch Acc: 75.00
[Train] Epoch: 0 [89600/620022]    Loss: 0.012620   Batch Acc: 62.50
[Train] Epoch: 0 [89664/620022]    Loss: 0.008692   Batch Acc: 76.56
[Train] Epoch: 0 [89728/620022]    Loss: 0.012888   Batch Acc: 57.81
[Train] Epoch: 0 [89792/620022]    Loss: 0.012254   Batch Acc: 70.31
[Train] Epoch: 0 [89856/620022]    Loss: 0.012615   Batch Acc: 59.38
[Train] Epoch: 0 [89920/620022]    Loss: 0.011987   Batch Acc: 64.06
[Train] Epoch: 0 [89984/620022]    Loss: 0.011347   Batch Acc: 68.75
[Train] Epoch: 0 [90048/620022]    Loss: 0.010994   Batch Acc: 67.19
[Train] Epoch: 0 [90112/620022]    Loss: 0.010932   Batch Acc: 75.00
[Train] Epoch: 0 [90176/620022]    Loss: 0.011914   Batch Acc: 70.31
[Train] Epoch: 0 [90240/620022]    Loss: 0.012313   Batch Acc: 68.75
[Train] Epoch: 0 [90304/620022]    Loss: 0.010648   Batch Acc: 68.75
[Train] Epoch: 0 [90368/620022]    Loss: 0.010181   Batch Acc: 73.44
[Train] Epoch: 0 [90432/620022]    Loss: 0.011245   Batch Acc: 73.44
[Train] Epoch: 0 [90496/620022]    Loss: 0.011434   Batch Acc: 68.75
[Train] Epoch: 0 [90560/620022]    Loss: 0.011236   Batch Acc: 73.44
[Train] Epoch: 0 [90624/620022]    Loss: 0.010006   Batch Acc: 71.88
[Train] Epoch: 0 [90688/620022]    Loss: 0.012429   Batch Acc: 62.50
[Train] Epoch: 0 [90752/620022]    Loss: 0.010765   Batch Acc: 75.00
[Train] Epoch: 0 [90816/620022]    Loss: 0.010036   Batch Acc: 79.69
[Train] Epoch: 0 [90880/620022]    Loss: 0.010756   Batch Acc: 71.88
[Train] Epoch: 0 [90944/620022]    Loss: 0.010501   Batch Acc: 68.75
[Train] Epoch: 0 [91008/620022]    Loss: 0.011146   Batch Acc: 78.12
[Train] Epoch: 0 [91072/620022]    Loss: 0.011470   Batch Acc: 64.06
[Train] Epoch: 0 [91136/620022]    Loss: 0.011034   Batch Acc: 71.88
[Train] Epoch: 0 [91200/620022]    Loss: 0.009662   Batch Acc: 76.56
[Train] Epoch: 0 [91264/620022]    Loss: 0.009632   Batch Acc: 75.00
[Train] Epoch: 0 [91328/620022]    Loss: 0.011690   Batch Acc: 79.69
[Train] Epoch: 0 [91392/620022]    Loss: 0.009807   Batch Acc: 81.25
[Train] Epoch: 0 [91456/620022]    Loss: 0.012317   Batch Acc: 64.06
[Train] Epoch: 0 [91520/620022]    Loss: 0.011452   Batch Acc: 64.06
[Train] Epoch: 0 [91584/620022]    Loss: 0.012121   Batch Acc: 60.94
[Train] Epoch: 0 [91648/620022]    Loss: 0.010549   Batch Acc: 70.31
[Train] Epoch: 0 [91712/620022]    Loss: 0.010411   Batch Acc: 71.88
[Train] Epoch: 0 [91776/620022]    Loss: 0.010936   Batch Acc: 75.00
[Train] Epoch: 0 [91840/620022]    Loss: 0.012461   Batch Acc: 68.75
[Train] Epoch: 0 [91904/620022]    Loss: 0.009746   Batch Acc: 79.69
[Train] Epoch: 0 [91968/620022]    Loss: 0.010660   Batch Acc: 67.19
[Train] Epoch: 0 [92032/620022]    Loss: 0.012080   Batch Acc: 67.19
[Train] Epoch: 0 [92096/620022]    Loss: 0.010657   Batch Acc: 70.31
[Train] Epoch: 0 [92160/620022]    Loss: 0.012034   Batch Acc: 64.06
[Train] Epoch: 0 [92224/620022]    Loss: 0.010257   Batch Acc: 73.44
[Train] Epoch: 0 [92288/620022]    Loss: 0.008280   Batch Acc: 81.25
[Train] Epoch: 0 [92352/620022]    Loss: 0.010554   Batch Acc: 75.00
[Train] Epoch: 0 [92416/620022]    Loss: 0.010124   Batch Acc: 73.44
[Train] Epoch: 0 [92480/620022]    Loss: 0.014542   Batch Acc: 54.69
[Train] Epoch: 0 [92544/620022]    Loss: 0.012150   Batch Acc: 67.19
[Train] Epoch: 0 [92608/620022]    Loss: 0.011903   Batch Acc: 70.31
[Train] Epoch: 0 [92672/620022]    Loss: 0.012225   Batch Acc: 68.75
[Train] Epoch: 0 [92736/620022]    Loss: 0.011235   Batch Acc: 71.88
[Train] Epoch: 0 [92800/620022]    Loss: 0.010775   Batch Acc: 68.75
[Train] Epoch: 0 [92864/620022]    Loss: 0.011323   Batch Acc: 68.75
[Train] Epoch: 0 [92928/620022]    Loss: 0.011571   Batch Acc: 70.31
[Train] Epoch: 0 [92992/620022]    Loss: 0.011281   Batch Acc: 75.00
[Train] Epoch: 0 [93056/620022]    Loss: 0.009670   Batch Acc: 76.56
[Train] Epoch: 0 [93120/620022]    Loss: 0.011629   Batch Acc: 73.44
[Train] Epoch: 0 [93184/620022]    Loss: 0.010660   Batch Acc: 75.00
[Train] Epoch: 0 [93248/620022]    Loss: 0.009847   Batch Acc: 75.00
[Train] Epoch: 0 [93312/620022]    Loss: 0.012158   Batch Acc: 67.19
[Train] Epoch: 0 [93376/620022]    Loss: 0.010358   Batch Acc: 70.31
[Train] Epoch: 0 [93440/620022]    Loss: 0.011785   Batch Acc: 62.50
[Train] Epoch: 0 [93504/620022]    Loss: 0.008490   Batch Acc: 82.81
[Train] Epoch: 0 [93568/620022]    Loss: 0.008996   Batch Acc: 85.94
[Train] Epoch: 0 [93632/620022]    Loss: 0.009956   Batch Acc: 76.56
[Train] Epoch: 0 [93696/620022]    Loss: 0.010482   Batch Acc: 75.00
[Train] Epoch: 0 [93760/620022]    Loss: 0.009582   Batch Acc: 75.00
[Train] Epoch: 0 [93824/620022]    Loss: 0.012768   Batch Acc: 62.50
[Train] Epoch: 0 [93888/620022]    Loss: 0.011408   Batch Acc: 68.75
[Train] Epoch: 0 [93952/620022]    Loss: 0.012452   Batch Acc: 65.62
[Train] Epoch: 0 [94016/620022]    Loss: 0.012089   Batch Acc: 65.62
[Train] Epoch: 0 [94080/620022]    Loss: 0.010288   Batch Acc: 75.00
[Train] Epoch: 0 [94144/620022]    Loss: 0.011812   Batch Acc: 67.19
[Train] Epoch: 0 [94208/620022]    Loss: 0.011588   Batch Acc: 73.44
[Train] Epoch: 0 [94272/620022]    Loss: 0.010500   Batch Acc: 71.88
[Train] Epoch: 0 [94336/620022]    Loss: 0.011471   Batch Acc: 68.75
[Train] Epoch: 0 [94400/620022]    Loss: 0.009997   Batch Acc: 76.56
[Train] Epoch: 0 [94464/620022]    Loss: 0.011773   Batch Acc: 65.62
[Train] Epoch: 0 [94528/620022]    Loss: 0.011966   Batch Acc: 70.31
[Train] Epoch: 0 [94592/620022]    Loss: 0.013706   Batch Acc: 54.69
[Train] Epoch: 0 [94656/620022]    Loss: 0.010004   Batch Acc: 79.69
[Train] Epoch: 0 [94720/620022]    Loss: 0.010872   Batch Acc: 71.88
[Train] Epoch: 0 [94784/620022]    Loss: 0.010615   Batch Acc: 73.44
[Train] Epoch: 0 [94848/620022]    Loss: 0.013006   Batch Acc: 62.50
[Train] Epoch: 0 [94912/620022]    Loss: 0.008691   Batch Acc: 79.69
[Train] Epoch: 0 [94976/620022]    Loss: 0.010844   Batch Acc: 71.88
[Train] Epoch: 0 [95040/620022]    Loss: 0.012437   Batch Acc: 67.19
[Train] Epoch: 0 [95104/620022]    Loss: 0.011191   Batch Acc: 71.88
[Train] Epoch: 0 [95168/620022]    Loss: 0.012308   Batch Acc: 62.50
[Train] Epoch: 0 [95232/620022]    Loss: 0.010745   Batch Acc: 65.62
[Train] Epoch: 0 [95296/620022]    Loss: 0.011113   Batch Acc: 70.31
[Train] Epoch: 0 [95360/620022]    Loss: 0.011921   Batch Acc: 70.31
[Train] Epoch: 0 [95424/620022]    Loss: 0.011081   Batch Acc: 64.06
[Train] Epoch: 0 [95488/620022]    Loss: 0.011142   Batch Acc: 68.75
[Train] Epoch: 0 [95552/620022]    Loss: 0.009193   Batch Acc: 76.56
[Train] Epoch: 0 [95616/620022]    Loss: 0.011940   Batch Acc: 67.19
[Train] Epoch: 0 [95680/620022]    Loss: 0.012625   Batch Acc: 65.62
[Train] Epoch: 0 [95744/620022]    Loss: 0.010918   Batch Acc: 75.00
[Train] Epoch: 0 [95808/620022]    Loss: 0.010681   Batch Acc: 71.88
[Train] Epoch: 0 [95872/620022]    Loss: 0.008917   Batch Acc: 79.69
[Train] Epoch: 0 [95936/620022]    Loss: 0.011538   Batch Acc: 62.50
[Train] Epoch: 0 [96000/620022]    Loss: 0.011609   Batch Acc: 67.19
[Train] Epoch: 0 [96064/620022]    Loss: 0.007512   Batch Acc: 90.62
[Train] Epoch: 0 [96128/620022]    Loss: 0.010620   Batch Acc: 78.12
[Train] Epoch: 0 [96192/620022]    Loss: 0.011010   Batch Acc: 68.75
[Train] Epoch: 0 [96256/620022]    Loss: 0.009183   Batch Acc: 82.81
[Train] Epoch: 0 [96320/620022]    Loss: 0.010716   Batch Acc: 71.88
[Train] Epoch: 0 [96384/620022]    Loss: 0.010849   Batch Acc: 78.12
[Train] Epoch: 0 [96448/620022]    Loss: 0.009889   Batch Acc: 75.00
[Train] Epoch: 0 [96512/620022]    Loss: 0.009973   Batch Acc: 73.44
[Train] Epoch: 0 [96576/620022]    Loss: 0.011394   Batch Acc: 59.38
[Train] Epoch: 0 [96640/620022]    Loss: 0.013611   Batch Acc: 65.62
[Train] Epoch: 0 [96704/620022]    Loss: 0.013094   Batch Acc: 57.81
[Train] Epoch: 0 [96768/620022]    Loss: 0.009885   Batch Acc: 79.69
[Train] Epoch: 0 [96832/620022]    Loss: 0.011269   Batch Acc: 70.31
[Train] Epoch: 0 [96896/620022]    Loss: 0.011024   Batch Acc: 68.75
[Train] Epoch: 0 [96960/620022]    Loss: 0.011570   Batch Acc: 71.88
[Train] Epoch: 0 [97024/620022]    Loss: 0.011554   Batch Acc: 65.62
[Train] Epoch: 0 [97088/620022]    Loss: 0.013100   Batch Acc: 65.62
[Train] Epoch: 0 [97152/620022]    Loss: 0.011050   Batch Acc: 73.44
[Train] Epoch: 0 [97216/620022]    Loss: 0.011002   Batch Acc: 70.31
[Train] Epoch: 0 [97280/620022]    Loss: 0.011397   Batch Acc: 65.62
[Train] Epoch: 0 [97344/620022]    Loss: 0.010201   Batch Acc: 75.00
[Train] Epoch: 0 [97408/620022]    Loss: 0.010748   Batch Acc: 78.12
[Train] Epoch: 0 [97472/620022]    Loss: 0.010335   Batch Acc: 75.00
[Train] Epoch: 0 [97536/620022]    Loss: 0.010265   Batch Acc: 73.44
[Train] Epoch: 0 [97600/620022]    Loss: 0.011406   Batch Acc: 64.06
[Train] Epoch: 0 [97664/620022]    Loss: 0.010787   Batch Acc: 67.19
[Train] Epoch: 0 [97728/620022]    Loss: 0.010409   Batch Acc: 73.44
[Train] Epoch: 0 [97792/620022]    Loss: 0.009263   Batch Acc: 76.56
[Train] Epoch: 0 [97856/620022]    Loss: 0.012459   Batch Acc: 62.50
[Train] Epoch: 0 [97920/620022]    Loss: 0.010082   Batch Acc: 75.00
[Train] Epoch: 0 [97984/620022]    Loss: 0.010685   Batch Acc: 75.00
[Train] Epoch: 0 [98048/620022]    Loss: 0.012628   Batch Acc: 68.75
[Train] Epoch: 0 [98112/620022]    Loss: 0.009926   Batch Acc: 73.44
[Train] Epoch: 0 [98176/620022]    Loss: 0.010915   Batch Acc: 68.75
[Train] Epoch: 0 [98240/620022]    Loss: 0.010808   Batch Acc: 68.75
[Train] Epoch: 0 [98304/620022]    Loss: 0.010646   Batch Acc: 73.44
[Train] Epoch: 0 [98368/620022]    Loss: 0.010269   Batch Acc: 68.75
[Train] Epoch: 0 [98432/620022]    Loss: 0.010326   Batch Acc: 73.44
[Train] Epoch: 0 [98496/620022]    Loss: 0.010660   Batch Acc: 71.88
[Train] Epoch: 0 [98560/620022]    Loss: 0.011520   Batch Acc: 68.75
[Train] Epoch: 0 [98624/620022]    Loss: 0.011908   Batch Acc: 67.19
[Train] Epoch: 0 [98688/620022]    Loss: 0.011680   Batch Acc: 62.50
[Train] Epoch: 0 [98752/620022]    Loss: 0.010359   Batch Acc: 75.00
[Train] Epoch: 0 [98816/620022]    Loss: 0.008901   Batch Acc: 79.69
[Train] Epoch: 0 [98880/620022]    Loss: 0.012062   Batch Acc: 62.50
[Train] Epoch: 0 [98944/620022]    Loss: 0.010190   Batch Acc: 73.44
[Train] Epoch: 0 [99008/620022]    Loss: 0.012726   Batch Acc: 64.06
[Train] Epoch: 0 [99072/620022]    Loss: 0.011491   Batch Acc: 65.62
[Train] Epoch: 0 [99136/620022]    Loss: 0.010910   Batch Acc: 76.56
[Train] Epoch: 0 [99200/620022]    Loss: 0.012495   Batch Acc: 64.06
[Train] Epoch: 0 [99264/620022]    Loss: 0.010218   Batch Acc: 75.00
[Train] Epoch: 0 [99328/620022]    Loss: 0.008975   Batch Acc: 81.25
[Train] Epoch: 0 [99392/620022]    Loss: 0.009317   Batch Acc: 82.81
[Train] Epoch: 0 [99456/620022]    Loss: 0.014056   Batch Acc: 62.50
[Train] Epoch: 0 [99520/620022]    Loss: 0.011166   Batch Acc: 68.75
[Train] Epoch: 0 [99584/620022]    Loss: 0.010087   Batch Acc: 73.44
[Train] Epoch: 0 [99648/620022]    Loss: 0.010893   Batch Acc: 71.88
[Train] Epoch: 0 [99712/620022]    Loss: 0.010765   Batch Acc: 75.00
[Train] Epoch: 0 [99776/620022]    Loss: 0.010752   Batch Acc: 70.31
[Train] Epoch: 0 [99840/620022]    Loss: 0.010591   Batch Acc: 78.12
[Train] Epoch: 0 [99904/620022]    Loss: 0.010231   Batch Acc: 76.56
[Train] Epoch: 0 [99968/620022]    Loss: 0.010649   Batch Acc: 67.19
[Train] Epoch: 0 [100032/620022]    Loss: 0.011888   Batch Acc: 64.06
[Train] Epoch: 0 [100096/620022]    Loss: 0.011471   Batch Acc: 65.62
[Train] Epoch: 0 [100160/620022]    Loss: 0.010726   Batch Acc: 70.31
[Train] Epoch: 0 [100224/620022]    Loss: 0.013507   Batch Acc: 67.19
[Train] Epoch: 0 [100288/620022]    Loss: 0.011007   Batch Acc: 73.44
[Train] Epoch: 0 [100352/620022]    Loss: 0.010815   Batch Acc: 68.75
[Train] Epoch: 0 [100416/620022]    Loss: 0.011417   Batch Acc: 65.62
[Train] Epoch: 0 [100480/620022]    Loss: 0.010471   Batch Acc: 71.88
[Train] Epoch: 0 [100544/620022]    Loss: 0.011067   Batch Acc: 71.88
[Train] Epoch: 0 [100608/620022]    Loss: 0.011430   Batch Acc: 68.75
[Train] Epoch: 0 [100672/620022]    Loss: 0.009330   Batch Acc: 79.69
[Train] Epoch: 0 [100736/620022]    Loss: 0.012608   Batch Acc: 64.06
[Train] Epoch: 0 [100800/620022]    Loss: 0.009962   Batch Acc: 73.44
[Train] Epoch: 0 [100864/620022]    Loss: 0.009205   Batch Acc: 78.12
[Train] Epoch: 0 [100928/620022]    Loss: 0.008549   Batch Acc: 79.69
[Train] Epoch: 0 [100992/620022]    Loss: 0.009493   Batch Acc: 78.12
[Train] Epoch: 0 [101056/620022]    Loss: 0.011093   Batch Acc: 64.06
[Train] Epoch: 0 [101120/620022]    Loss: 0.010805   Batch Acc: 71.88
[Train] Epoch: 0 [101184/620022]    Loss: 0.010782   Batch Acc: 75.00
[Train] Epoch: 0 [101248/620022]    Loss: 0.011239   Batch Acc: 70.31
[Train] Epoch: 0 [101312/620022]    Loss: 0.011546   Batch Acc: 70.31
[Train] Epoch: 0 [101376/620022]    Loss: 0.009826   Batch Acc: 76.56
[Train] Epoch: 0 [101440/620022]    Loss: 0.009954   Batch Acc: 73.44
[Train] Epoch: 0 [101504/620022]    Loss: 0.012219   Batch Acc: 64.06
[Train] Epoch: 0 [101568/620022]    Loss: 0.009617   Batch Acc: 76.56
[Train] Epoch: 0 [101632/620022]    Loss: 0.009990   Batch Acc: 73.44
[Train] Epoch: 0 [101696/620022]    Loss: 0.010197   Batch Acc: 68.75
[Train] Epoch: 0 [101760/620022]    Loss: 0.008561   Batch Acc: 81.25
[Train] Epoch: 0 [101824/620022]    Loss: 0.013691   Batch Acc: 59.38
[Train] Epoch: 0 [101888/620022]    Loss: 0.011041   Batch Acc: 68.75
[Train] Epoch: 0 [101952/620022]    Loss: 0.012761   Batch Acc: 57.81
[Train] Epoch: 0 [102016/620022]    Loss: 0.010052   Batch Acc: 76.56
[Train] Epoch: 0 [102080/620022]    Loss: 0.009923   Batch Acc: 73.44
[Train] Epoch: 0 [102144/620022]    Loss: 0.013708   Batch Acc: 60.94
[Train] Epoch: 0 [102208/620022]    Loss: 0.012150   Batch Acc: 67.19
[Train] Epoch: 0 [102272/620022]    Loss: 0.010342   Batch Acc: 76.56
[Train] Epoch: 0 [102336/620022]    Loss: 0.009454   Batch Acc: 75.00
[Train] Epoch: 0 [102400/620022]    Loss: 0.010365   Batch Acc: 70.31
[Train] Epoch: 0 [102464/620022]    Loss: 0.010835   Batch Acc: 70.31
[Train] Epoch: 0 [102528/620022]    Loss: 0.010338   Batch Acc: 70.31
[Train] Epoch: 0 [102592/620022]    Loss: 0.010364   Batch Acc: 75.00
[Train] Epoch: 0 [102656/620022]    Loss: 0.009860   Batch Acc: 73.44
[Train] Epoch: 0 [102720/620022]    Loss: 0.010416   Batch Acc: 79.69
[Train] Epoch: 0 [102784/620022]    Loss: 0.011377   Batch Acc: 70.31
[Train] Epoch: 0 [102848/620022]    Loss: 0.009477   Batch Acc: 82.81
[Train] Epoch: 0 [102912/620022]    Loss: 0.010531   Batch Acc: 68.75
[Train] Epoch: 0 [102976/620022]    Loss: 0.009725   Batch Acc: 75.00
[Train] Epoch: 0 [103040/620022]    Loss: 0.009771   Batch Acc: 79.69
[Train] Epoch: 0 [103104/620022]    Loss: 0.011404   Batch Acc: 68.75
[Train] Epoch: 0 [103168/620022]    Loss: 0.012927   Batch Acc: 57.81
[Train] Epoch: 0 [103232/620022]    Loss: 0.009361   Batch Acc: 75.00
[Train] Epoch: 0 [103296/620022]    Loss: 0.009764   Batch Acc: 75.00
[Train] Epoch: 0 [103360/620022]    Loss: 0.011220   Batch Acc: 75.00
[Train] Epoch: 0 [103424/620022]    Loss: 0.010172   Batch Acc: 76.56
[Train] Epoch: 0 [103488/620022]    Loss: 0.010889   Batch Acc: 71.88
[Train] Epoch: 0 [103552/620022]    Loss: 0.012643   Batch Acc: 64.06
[Train] Epoch: 0 [103616/620022]    Loss: 0.010364   Batch Acc: 76.56
[Train] Epoch: 0 [103680/620022]    Loss: 0.010585   Batch Acc: 68.75
[Train] Epoch: 0 [103744/620022]    Loss: 0.012452   Batch Acc: 60.94
[Train] Epoch: 0 [103808/620022]    Loss: 0.008512   Batch Acc: 79.69
[Train] Epoch: 0 [103872/620022]    Loss: 0.011005   Batch Acc: 70.31
[Train] Epoch: 0 [103936/620022]    Loss: 0.009847   Batch Acc: 79.69
[Train] Epoch: 0 [104000/620022]    Loss: 0.009724   Batch Acc: 78.12
[Train] Epoch: 0 [104064/620022]    Loss: 0.008686   Batch Acc: 87.50
[Train] Epoch: 0 [104128/620022]    Loss: 0.010238   Batch Acc: 70.31
[Train] Epoch: 0 [104192/620022]    Loss: 0.011363   Batch Acc: 75.00
[Train] Epoch: 0 [104256/620022]    Loss: 0.011001   Batch Acc: 71.88
[Train] Epoch: 0 [104320/620022]    Loss: 0.011625   Batch Acc: 68.75
[Train] Epoch: 0 [104384/620022]    Loss: 0.011340   Batch Acc: 68.75
[Train] Epoch: 0 [104448/620022]    Loss: 0.012458   Batch Acc: 62.50
[Train] Epoch: 0 [104512/620022]    Loss: 0.010725   Batch Acc: 76.56
[Train] Epoch: 0 [104576/620022]    Loss: 0.010994   Batch Acc: 75.00
[Train] Epoch: 0 [104640/620022]    Loss: 0.010932   Batch Acc: 70.31
[Train] Epoch: 0 [104704/620022]    Loss: 0.008421   Batch Acc: 82.81
[Train] Epoch: 0 [104768/620022]    Loss: 0.010372   Batch Acc: 73.44
[Train] Epoch: 0 [104832/620022]    Loss: 0.011825   Batch Acc: 65.62
[Train] Epoch: 0 [104896/620022]    Loss: 0.008747   Batch Acc: 79.69
[Train] Epoch: 0 [104960/620022]    Loss: 0.011413   Batch Acc: 73.44
[Train] Epoch: 0 [105024/620022]    Loss: 0.011219   Batch Acc: 71.88
[Train] Epoch: 0 [105088/620022]    Loss: 0.010949   Batch Acc: 71.88
[Train] Epoch: 0 [105152/620022]    Loss: 0.008236   Batch Acc: 81.25
[Train] Epoch: 0 [105216/620022]    Loss: 0.011855   Batch Acc: 75.00
[Train] Epoch: 0 [105280/620022]    Loss: 0.010996   Batch Acc: 75.00
[Train] Epoch: 0 [105344/620022]    Loss: 0.011264   Batch Acc: 67.19
[Train] Epoch: 0 [105408/620022]    Loss: 0.009702   Batch Acc: 76.56
[Train] Epoch: 0 [105472/620022]    Loss: 0.012138   Batch Acc: 68.75
[Train] Epoch: 0 [105536/620022]    Loss: 0.008970   Batch Acc: 81.25
[Train] Epoch: 0 [105600/620022]    Loss: 0.009432   Batch Acc: 78.12
[Train] Epoch: 0 [105664/620022]    Loss: 0.009304   Batch Acc: 76.56
[Train] Epoch: 0 [105728/620022]    Loss: 0.010879   Batch Acc: 70.31
[Train] Epoch: 0 [105792/620022]    Loss: 0.011856   Batch Acc: 64.06
[Train] Epoch: 0 [105856/620022]    Loss: 0.009698   Batch Acc: 75.00
[Train] Epoch: 0 [105920/620022]    Loss: 0.011263   Batch Acc: 71.88
[Train] Epoch: 0 [105984/620022]    Loss: 0.010300   Batch Acc: 67.19
[Train] Epoch: 0 [106048/620022]    Loss: 0.010050   Batch Acc: 71.88
[Train] Epoch: 0 [106112/620022]    Loss: 0.011776   Batch Acc: 60.94
[Train] Epoch: 0 [106176/620022]    Loss: 0.009340   Batch Acc: 71.88
[Train] Epoch: 0 [106240/620022]    Loss: 0.009199   Batch Acc: 73.44
[Train] Epoch: 0 [106304/620022]    Loss: 0.013450   Batch Acc: 53.12
[Train] Epoch: 0 [106368/620022]    Loss: 0.009974   Batch Acc: 73.44
[Train] Epoch: 0 [106432/620022]    Loss: 0.010810   Batch Acc: 76.56
[Train] Epoch: 0 [106496/620022]    Loss: 0.010029   Batch Acc: 71.88
[Train] Epoch: 0 [106560/620022]    Loss: 0.011196   Batch Acc: 68.75
[Train] Epoch: 0 [106624/620022]    Loss: 0.011247   Batch Acc: 68.75
[Train] Epoch: 0 [106688/620022]    Loss: 0.012888   Batch Acc: 75.00
[Train] Epoch: 0 [106752/620022]    Loss: 0.012052   Batch Acc: 64.06
[Train] Epoch: 0 [106816/620022]    Loss: 0.011963   Batch Acc: 70.31
[Train] Epoch: 0 [106880/620022]    Loss: 0.009807   Batch Acc: 78.12
[Train] Epoch: 0 [106944/620022]    Loss: 0.009470   Batch Acc: 71.88
[Train] Epoch: 0 [107008/620022]    Loss: 0.009365   Batch Acc: 76.56
[Train] Epoch: 0 [107072/620022]    Loss: 0.010551   Batch Acc: 75.00
[Train] Epoch: 0 [107136/620022]    Loss: 0.008382   Batch Acc: 82.81
[Train] Epoch: 0 [107200/620022]    Loss: 0.010971   Batch Acc: 71.88
[Train] Epoch: 0 [107264/620022]    Loss: 0.009711   Batch Acc: 78.12
[Train] Epoch: 0 [107328/620022]    Loss: 0.012443   Batch Acc: 59.38
[Train] Epoch: 0 [107392/620022]    Loss: 0.008784   Batch Acc: 78.12
[Train] Epoch: 0 [107456/620022]    Loss: 0.011169   Batch Acc: 73.44
[Train] Epoch: 0 [107520/620022]    Loss: 0.012058   Batch Acc: 65.62
[Train] Epoch: 0 [107584/620022]    Loss: 0.010770   Batch Acc: 73.44
[Train] Epoch: 0 [107648/620022]    Loss: 0.010004   Batch Acc: 73.44
[Train] Epoch: 0 [107712/620022]    Loss: 0.012233   Batch Acc: 64.06
[Train] Epoch: 0 [107776/620022]    Loss: 0.010558   Batch Acc: 68.75
[Train] Epoch: 0 [107840/620022]    Loss: 0.009594   Batch Acc: 78.12
[Train] Epoch: 0 [107904/620022]    Loss: 0.009957   Batch Acc: 73.44
[Train] Epoch: 0 [107968/620022]    Loss: 0.009286   Batch Acc: 70.31
[Train] Epoch: 0 [108032/620022]    Loss: 0.009846   Batch Acc: 75.00
[Train] Epoch: 0 [108096/620022]    Loss: 0.011234   Batch Acc: 68.75
[Train] Epoch: 0 [108160/620022]    Loss: 0.009024   Batch Acc: 78.12
[Train] Epoch: 0 [108224/620022]    Loss: 0.009404   Batch Acc: 70.31
[Train] Epoch: 0 [108288/620022]    Loss: 0.012820   Batch Acc: 65.62
[Train] Epoch: 0 [108352/620022]    Loss: 0.010561   Batch Acc: 71.88
[Train] Epoch: 0 [108416/620022]    Loss: 0.010570   Batch Acc: 71.88
[Train] Epoch: 0 [108480/620022]    Loss: 0.010674   Batch Acc: 73.44
[Train] Epoch: 0 [108544/620022]    Loss: 0.010841   Batch Acc: 73.44
[Train] Epoch: 0 [108608/620022]    Loss: 0.010082   Batch Acc: 76.56
[Train] Epoch: 0 [108672/620022]    Loss: 0.011497   Batch Acc: 68.75
[Train] Epoch: 0 [108736/620022]    Loss: 0.010911   Batch Acc: 73.44
[Train] Epoch: 0 [108800/620022]    Loss: 0.011780   Batch Acc: 64.06
[Train] Epoch: 0 [108864/620022]    Loss: 0.009070   Batch Acc: 76.56
[Train] Epoch: 0 [108928/620022]    Loss: 0.010299   Batch Acc: 75.00
[Train] Epoch: 0 [108992/620022]    Loss: 0.011063   Batch Acc: 70.31
[Train] Epoch: 0 [109056/620022]    Loss: 0.010020   Batch Acc: 68.75
[Train] Epoch: 0 [109120/620022]    Loss: 0.010713   Batch Acc: 70.31
[Train] Epoch: 0 [109184/620022]    Loss: 0.011725   Batch Acc: 70.31
[Train] Epoch: 0 [109248/620022]    Loss: 0.010271   Batch Acc: 78.12
[Train] Epoch: 0 [109312/620022]    Loss: 0.009698   Batch Acc: 78.12
[Train] Epoch: 0 [109376/620022]    Loss: 0.010183   Batch Acc: 70.31
[Train] Epoch: 0 [109440/620022]    Loss: 0.011663   Batch Acc: 65.62
[Train] Epoch: 0 [109504/620022]    Loss: 0.011967   Batch Acc: 67.19
[Train] Epoch: 0 [109568/620022]    Loss: 0.011777   Batch Acc: 70.31
[Train] Epoch: 0 [109632/620022]    Loss: 0.010046   Batch Acc: 71.88
[Train] Epoch: 0 [109696/620022]    Loss: 0.012598   Batch Acc: 64.06
[Train] Epoch: 0 [109760/620022]    Loss: 0.010484   Batch Acc: 70.31
[Train] Epoch: 0 [109824/620022]    Loss: 0.010492   Batch Acc: 68.75
[Train] Epoch: 0 [109888/620022]    Loss: 0.011655   Batch Acc: 75.00
[Train] Epoch: 0 [109952/620022]    Loss: 0.009762   Batch Acc: 75.00
[Train] Epoch: 0 [110016/620022]    Loss: 0.012395   Batch Acc: 62.50
[Train] Epoch: 0 [110080/620022]    Loss: 0.010942   Batch Acc: 75.00
[Train] Epoch: 0 [110144/620022]    Loss: 0.010668   Batch Acc: 70.31
[Train] Epoch: 0 [110208/620022]    Loss: 0.010999   Batch Acc: 73.44
[Train] Epoch: 0 [110272/620022]    Loss: 0.011296   Batch Acc: 68.75
[Train] Epoch: 0 [110336/620022]    Loss: 0.009645   Batch Acc: 71.88
[Train] Epoch: 0 [110400/620022]    Loss: 0.011472   Batch Acc: 67.19
[Train] Epoch: 0 [110464/620022]    Loss: 0.011276   Batch Acc: 65.62
[Train] Epoch: 0 [110528/620022]    Loss: 0.009509   Batch Acc: 82.81
[Train] Epoch: 0 [110592/620022]    Loss: 0.009926   Batch Acc: 75.00
[Train] Epoch: 0 [110656/620022]    Loss: 0.011202   Batch Acc: 65.62
[Train] Epoch: 0 [110720/620022]    Loss: 0.011041   Batch Acc: 67.19
[Train] Epoch: 0 [110784/620022]    Loss: 0.010640   Batch Acc: 70.31
[Train] Epoch: 0 [110848/620022]    Loss: 0.011100   Batch Acc: 70.31
[Train] Epoch: 0 [110912/620022]    Loss: 0.012959   Batch Acc: 59.38
[Train] Epoch: 0 [110976/620022]    Loss: 0.009338   Batch Acc: 71.88
[Train] Epoch: 0 [111040/620022]    Loss: 0.011034   Batch Acc: 73.44
[Train] Epoch: 0 [111104/620022]    Loss: 0.010100   Batch Acc: 73.44
[Train] Epoch: 0 [111168/620022]    Loss: 0.009899   Batch Acc: 70.31
[Train] Epoch: 0 [111232/620022]    Loss: 0.010965   Batch Acc: 67.19
[Train] Epoch: 0 [111296/620022]    Loss: 0.010324   Batch Acc: 70.31
[Train] Epoch: 0 [111360/620022]    Loss: 0.008186   Batch Acc: 81.25
[Train] Epoch: 0 [111424/620022]    Loss: 0.011268   Batch Acc: 70.31
[Train] Epoch: 0 [111488/620022]    Loss: 0.010484   Batch Acc: 73.44
[Train] Epoch: 0 [111552/620022]    Loss: 0.010867   Batch Acc: 73.44
[Train] Epoch: 0 [111616/620022]    Loss: 0.010393   Batch Acc: 70.31
[Train] Epoch: 0 [111680/620022]    Loss: 0.012357   Batch Acc: 67.19
[Train] Epoch: 0 [111744/620022]    Loss: 0.012213   Batch Acc: 62.50
[Train] Epoch: 0 [111808/620022]    Loss: 0.012827   Batch Acc: 62.50
[Train] Epoch: 0 [111872/620022]    Loss: 0.010604   Batch Acc: 75.00
[Train] Epoch: 0 [111936/620022]    Loss: 0.009483   Batch Acc: 73.44
[Train] Epoch: 0 [112000/620022]    Loss: 0.010340   Batch Acc: 73.44
[Train] Epoch: 0 [112064/620022]    Loss: 0.010578   Batch Acc: 78.12
[Train] Epoch: 0 [112128/620022]    Loss: 0.011060   Batch Acc: 68.75
[Train] Epoch: 0 [112192/620022]    Loss: 0.009234   Batch Acc: 85.94
[Train] Epoch: 0 [112256/620022]    Loss: 0.009789   Batch Acc: 75.00
[Train] Epoch: 0 [112320/620022]    Loss: 0.010342   Batch Acc: 76.56
[Train] Epoch: 0 [112384/620022]    Loss: 0.009917   Batch Acc: 76.56
[Train] Epoch: 0 [112448/620022]    Loss: 0.010927   Batch Acc: 76.56
[Train] Epoch: 0 [112512/620022]    Loss: 0.010134   Batch Acc: 73.44
[Train] Epoch: 0 [112576/620022]    Loss: 0.010485   Batch Acc: 71.88
[Train] Epoch: 0 [112640/620022]    Loss: 0.008490   Batch Acc: 79.69
[Train] Epoch: 0 [112704/620022]    Loss: 0.010586   Batch Acc: 67.19
[Train] Epoch: 0 [112768/620022]    Loss: 0.010562   Batch Acc: 70.31
[Train] Epoch: 0 [112832/620022]    Loss: 0.009131   Batch Acc: 73.44
[Train] Epoch: 0 [112896/620022]    Loss: 0.010710   Batch Acc: 71.88
[Train] Epoch: 0 [112960/620022]    Loss: 0.009419   Batch Acc: 75.00
[Train] Epoch: 0 [113024/620022]    Loss: 0.010090   Batch Acc: 81.25
[Train] Epoch: 0 [113088/620022]    Loss: 0.009596   Batch Acc: 75.00
[Train] Epoch: 0 [113152/620022]    Loss: 0.008078   Batch Acc: 82.81
[Train] Epoch: 0 [113216/620022]    Loss: 0.011324   Batch Acc: 70.31
[Train] Epoch: 0 [113280/620022]    Loss: 0.010410   Batch Acc: 75.00
[Train] Epoch: 0 [113344/620022]    Loss: 0.011431   Batch Acc: 71.88
[Train] Epoch: 0 [113408/620022]    Loss: 0.010006   Batch Acc: 75.00
[Train] Epoch: 0 [113472/620022]    Loss: 0.009942   Batch Acc: 76.56
[Train] Epoch: 0 [113536/620022]    Loss: 0.009063   Batch Acc: 82.81
[Train] Epoch: 0 [113600/620022]    Loss: 0.011422   Batch Acc: 73.44
[Train] Epoch: 0 [113664/620022]    Loss: 0.009838   Batch Acc: 71.88
[Train] Epoch: 0 [113728/620022]    Loss: 0.009907   Batch Acc: 76.56
[Train] Epoch: 0 [113792/620022]    Loss: 0.010372   Batch Acc: 75.00
[Train] Epoch: 0 [113856/620022]    Loss: 0.011358   Batch Acc: 70.31
[Train] Epoch: 0 [113920/620022]    Loss: 0.009833   Batch Acc: 73.44
[Train] Epoch: 0 [113984/620022]    Loss: 0.009931   Batch Acc: 78.12
[Train] Epoch: 0 [114048/620022]    Loss: 0.009737   Batch Acc: 75.00
[Train] Epoch: 0 [114112/620022]    Loss: 0.010160   Batch Acc: 71.88
[Train] Epoch: 0 [114176/620022]    Loss: 0.010738   Batch Acc: 79.69
[Train] Epoch: 0 [114240/620022]    Loss: 0.012422   Batch Acc: 67.19
[Train] Epoch: 0 [114304/620022]    Loss: 0.010552   Batch Acc: 75.00
[Train] Epoch: 0 [114368/620022]    Loss: 0.012096   Batch Acc: 60.94
[Train] Epoch: 0 [114432/620022]    Loss: 0.011485   Batch Acc: 70.31
[Train] Epoch: 0 [114496/620022]    Loss: 0.011520   Batch Acc: 68.75
[Train] Epoch: 0 [114560/620022]    Loss: 0.011889   Batch Acc: 73.44
[Train] Epoch: 0 [114624/620022]    Loss: 0.010709   Batch Acc: 75.00
[Train] Epoch: 0 [114688/620022]    Loss: 0.010443   Batch Acc: 70.31
[Train] Epoch: 0 [114752/620022]    Loss: 0.010593   Batch Acc: 68.75
[Train] Epoch: 0 [114816/620022]    Loss: 0.011719   Batch Acc: 67.19
[Train] Epoch: 0 [114880/620022]    Loss: 0.011638   Batch Acc: 67.19
[Train] Epoch: 0 [114944/620022]    Loss: 0.010794   Batch Acc: 76.56
[Train] Epoch: 0 [115008/620022]    Loss: 0.010213   Batch Acc: 78.12
[Train] Epoch: 0 [115072/620022]    Loss: 0.010319   Batch Acc: 75.00
[Train] Epoch: 0 [115136/620022]    Loss: 0.012245   Batch Acc: 65.62
[Train] Epoch: 0 [115200/620022]    Loss: 0.013745   Batch Acc: 60.94
[Train] Epoch: 0 [115264/620022]    Loss: 0.011128   Batch Acc: 70.31
[Train] Epoch: 0 [115328/620022]    Loss: 0.008292   Batch Acc: 82.81
[Train] Epoch: 0 [115392/620022]    Loss: 0.009882   Batch Acc: 75.00
[Train] Epoch: 0 [115456/620022]    Loss: 0.012948   Batch Acc: 68.75
[Train] Epoch: 0 [115520/620022]    Loss: 0.011390   Batch Acc: 68.75
[Train] Epoch: 0 [115584/620022]    Loss: 0.010180   Batch Acc: 73.44
[Train] Epoch: 0 [115648/620022]    Loss: 0.010499   Batch Acc: 75.00
[Train] Epoch: 0 [115712/620022]    Loss: 0.009485   Batch Acc: 78.12
[Train] Epoch: 0 [115776/620022]    Loss: 0.009928   Batch Acc: 75.00
[Train] Epoch: 0 [115840/620022]    Loss: 0.010478   Batch Acc: 75.00
[Train] Epoch: 0 [115904/620022]    Loss: 0.010585   Batch Acc: 70.31
[Train] Epoch: 0 [115968/620022]    Loss: 0.010716   Batch Acc: 71.88
[Train] Epoch: 0 [116032/620022]    Loss: 0.009109   Batch Acc: 78.12
[Train] Epoch: 0 [116096/620022]    Loss: 0.009782   Batch Acc: 76.56
[Train] Epoch: 0 [116160/620022]    Loss: 0.011999   Batch Acc: 64.06
[Train] Epoch: 0 [116224/620022]    Loss: 0.011784   Batch Acc: 67.19
[Train] Epoch: 0 [116288/620022]    Loss: 0.009978   Batch Acc: 78.12
[Train] Epoch: 0 [116352/620022]    Loss: 0.010881   Batch Acc: 71.88
[Train] Epoch: 0 [116416/620022]    Loss: 0.008337   Batch Acc: 84.38
[Train] Epoch: 0 [116480/620022]    Loss: 0.010238   Batch Acc: 71.88
[Train] Epoch: 0 [116544/620022]    Loss: 0.008898   Batch Acc: 78.12
[Train] Epoch: 0 [116608/620022]    Loss: 0.008798   Batch Acc: 73.44
[Train] Epoch: 0 [116672/620022]    Loss: 0.009416   Batch Acc: 76.56
[Train] Epoch: 0 [116736/620022]    Loss: 0.011358   Batch Acc: 70.31
[Train] Epoch: 0 [116800/620022]    Loss: 0.010855   Batch Acc: 71.88
[Train] Epoch: 0 [116864/620022]    Loss: 0.008958   Batch Acc: 82.81
[Train] Epoch: 0 [116928/620022]    Loss: 0.010723   Batch Acc: 73.44
[Train] Epoch: 0 [116992/620022]    Loss: 0.011709   Batch Acc: 68.75
[Train] Epoch: 0 [117056/620022]    Loss: 0.009464   Batch Acc: 75.00
[Train] Epoch: 0 [117120/620022]    Loss: 0.010910   Batch Acc: 68.75
[Train] Epoch: 0 [117184/620022]    Loss: 0.010613   Batch Acc: 70.31
[Train] Epoch: 0 [117248/620022]    Loss: 0.010286   Batch Acc: 70.31
[Train] Epoch: 0 [117312/620022]    Loss: 0.011254   Batch Acc: 70.31
[Train] Epoch: 0 [117376/620022]    Loss: 0.010060   Batch Acc: 75.00
[Train] Epoch: 0 [117440/620022]    Loss: 0.010924   Batch Acc: 70.31
[Train] Epoch: 0 [117504/620022]    Loss: 0.011165   Batch Acc: 70.31
[Train] Epoch: 0 [117568/620022]    Loss: 0.010402   Batch Acc: 67.19
[Train] Epoch: 0 [117632/620022]    Loss: 0.010503   Batch Acc: 70.31
[Train] Epoch: 0 [117696/620022]    Loss: 0.011471   Batch Acc: 65.62
[Train] Epoch: 0 [117760/620022]    Loss: 0.011516   Batch Acc: 76.56
[Train] Epoch: 0 [117824/620022]    Loss: 0.009974   Batch Acc: 78.12
[Train] Epoch: 0 [117888/620022]    Loss: 0.011788   Batch Acc: 67.19
[Train] Epoch: 0 [117952/620022]    Loss: 0.010956   Batch Acc: 71.88
[Train] Epoch: 0 [118016/620022]    Loss: 0.009394   Batch Acc: 78.12
[Train] Epoch: 0 [118080/620022]    Loss: 0.010496   Batch Acc: 68.75
[Train] Epoch: 0 [118144/620022]    Loss: 0.010638   Batch Acc: 68.75
[Train] Epoch: 0 [118208/620022]    Loss: 0.009045   Batch Acc: 79.69
[Train] Epoch: 0 [118272/620022]    Loss: 0.010270   Batch Acc: 70.31
[Train] Epoch: 0 [118336/620022]    Loss: 0.012164   Batch Acc: 71.88
[Train] Epoch: 0 [118400/620022]    Loss: 0.011031   Batch Acc: 73.44
[Train] Epoch: 0 [118464/620022]    Loss: 0.009330   Batch Acc: 73.44
[Train] Epoch: 0 [118528/620022]    Loss: 0.009944   Batch Acc: 76.56
[Train] Epoch: 0 [118592/620022]    Loss: 0.008040   Batch Acc: 84.38
[Train] Epoch: 0 [118656/620022]    Loss: 0.009324   Batch Acc: 75.00
[Train] Epoch: 0 [118720/620022]    Loss: 0.013423   Batch Acc: 57.81
[Train] Epoch: 0 [118784/620022]    Loss: 0.010474   Batch Acc: 76.56
[Train] Epoch: 0 [118848/620022]    Loss: 0.011401   Batch Acc: 70.31
[Train] Epoch: 0 [118912/620022]    Loss: 0.011443   Batch Acc: 68.75
[Train] Epoch: 0 [118976/620022]    Loss: 0.009766   Batch Acc: 78.12
[Train] Epoch: 0 [119040/620022]    Loss: 0.008715   Batch Acc: 73.44
[Train] Epoch: 0 [119104/620022]    Loss: 0.010577   Batch Acc: 68.75
[Train] Epoch: 0 [119168/620022]    Loss: 0.008665   Batch Acc: 79.69
[Train] Epoch: 0 [119232/620022]    Loss: 0.009482   Batch Acc: 78.12
[Train] Epoch: 0 [119296/620022]    Loss: 0.012403   Batch Acc: 59.38
[Train] Epoch: 0 [119360/620022]    Loss: 0.009077   Batch Acc: 75.00
[Train] Epoch: 0 [119424/620022]    Loss: 0.009669   Batch Acc: 76.56
[Train] Epoch: 0 [119488/620022]    Loss: 0.009723   Batch Acc: 81.25
[Train] Epoch: 0 [119552/620022]    Loss: 0.009273   Batch Acc: 73.44
[Train] Epoch: 0 [119616/620022]    Loss: 0.009822   Batch Acc: 78.12
[Train] Epoch: 0 [119680/620022]    Loss: 0.011523   Batch Acc: 68.75
[Train] Epoch: 0 [119744/620022]    Loss: 0.010358   Batch Acc: 76.56
[Train] Epoch: 0 [119808/620022]    Loss: 0.011953   Batch Acc: 68.75
[Train] Epoch: 0 [119872/620022]    Loss: 0.009750   Batch Acc: 75.00
[Train] Epoch: 0 [119936/620022]    Loss: 0.009714   Batch Acc: 75.00
[Train] Epoch: 0 [120000/620022]    Loss: 0.008850   Batch Acc: 79.69
[Train] Epoch: 0 [120064/620022]    Loss: 0.009304   Batch Acc: 76.56
[Train] Epoch: 0 [120128/620022]    Loss: 0.010783   Batch Acc: 71.88
[Train] Epoch: 0 [120192/620022]    Loss: 0.010126   Batch Acc: 76.56
[Train] Epoch: 0 [120256/620022]    Loss: 0.011601   Batch Acc: 68.75
[Train] Epoch: 0 [120320/620022]    Loss: 0.011109   Batch Acc: 73.44
[Train] Epoch: 0 [120384/620022]    Loss: 0.008702   Batch Acc: 76.56
[Train] Epoch: 0 [120448/620022]    Loss: 0.013638   Batch Acc: 53.12
[Train] Epoch: 0 [120512/620022]    Loss: 0.008488   Batch Acc: 79.69
[Train] Epoch: 0 [120576/620022]    Loss: 0.010355   Batch Acc: 82.81
[Train] Epoch: 0 [120640/620022]    Loss: 0.010630   Batch Acc: 71.88
[Train] Epoch: 0 [120704/620022]    Loss: 0.013147   Batch Acc: 62.50
[Train] Epoch: 0 [120768/620022]    Loss: 0.008644   Batch Acc: 78.12
[Train] Epoch: 0 [120832/620022]    Loss: 0.011563   Batch Acc: 65.62
[Train] Epoch: 0 [120896/620022]    Loss: 0.009749   Batch Acc: 75.00
[Train] Epoch: 0 [120960/620022]    Loss: 0.010017   Batch Acc: 76.56
[Train] Epoch: 0 [121024/620022]    Loss: 0.011920   Batch Acc: 71.88
[Train] Epoch: 0 [121088/620022]    Loss: 0.011299   Batch Acc: 67.19
[Train] Epoch: 0 [121152/620022]    Loss: 0.010874   Batch Acc: 68.75
[Train] Epoch: 0 [121216/620022]    Loss: 0.010710   Batch Acc: 67.19
[Train] Epoch: 0 [121280/620022]    Loss: 0.010295   Batch Acc: 68.75
[Train] Epoch: 0 [121344/620022]    Loss: 0.009933   Batch Acc: 75.00
[Train] Epoch: 0 [121408/620022]    Loss: 0.011250   Batch Acc: 73.44
[Train] Epoch: 0 [121472/620022]    Loss: 0.012815   Batch Acc: 64.06
[Train] Epoch: 0 [121536/620022]    Loss: 0.011503   Batch Acc: 65.62
[Train] Epoch: 0 [121600/620022]    Loss: 0.010047   Batch Acc: 75.00
[Train] Epoch: 0 [121664/620022]    Loss: 0.010679   Batch Acc: 75.00
[Train] Epoch: 0 [121728/620022]    Loss: 0.010483   Batch Acc: 73.44
[Train] Epoch: 0 [121792/620022]    Loss: 0.009303   Batch Acc: 76.56
[Train] Epoch: 0 [121856/620022]    Loss: 0.011583   Batch Acc: 68.75
[Train] Epoch: 0 [121920/620022]    Loss: 0.010691   Batch Acc: 71.88
[Train] Epoch: 0 [121984/620022]    Loss: 0.013456   Batch Acc: 57.81
[Train] Epoch: 0 [122048/620022]    Loss: 0.010616   Batch Acc: 71.88
[Train] Epoch: 0 [122112/620022]    Loss: 0.007807   Batch Acc: 82.81
[Train] Epoch: 0 [122176/620022]    Loss: 0.012116   Batch Acc: 64.06
[Train] Epoch: 0 [122240/620022]    Loss: 0.008274   Batch Acc: 79.69
[Train] Epoch: 0 [122304/620022]    Loss: 0.009709   Batch Acc: 76.56
[Train] Epoch: 0 [122368/620022]    Loss: 0.010047   Batch Acc: 78.12
[Train] Epoch: 0 [122432/620022]    Loss: 0.010672   Batch Acc: 70.31
[Train] Epoch: 0 [122496/620022]    Loss: 0.011061   Batch Acc: 65.62
[Train] Epoch: 0 [122560/620022]    Loss: 0.012165   Batch Acc: 65.62
[Train] Epoch: 0 [122624/620022]    Loss: 0.011658   Batch Acc: 67.19
[Train] Epoch: 0 [122688/620022]    Loss: 0.009601   Batch Acc: 78.12
[Train] Epoch: 0 [122752/620022]    Loss: 0.011946   Batch Acc: 65.62
[Train] Epoch: 0 [122816/620022]    Loss: 0.010431   Batch Acc: 73.44
[Train] Epoch: 0 [122880/620022]    Loss: 0.009882   Batch Acc: 79.69
[Train] Epoch: 0 [122944/620022]    Loss: 0.011254   Batch Acc: 60.94
[Train] Epoch: 0 [123008/620022]    Loss: 0.009518   Batch Acc: 76.56
[Train] Epoch: 0 [123072/620022]    Loss: 0.010169   Batch Acc: 75.00
[Train] Epoch: 0 [123136/620022]    Loss: 0.011063   Batch Acc: 68.75
[Train] Epoch: 0 [123200/620022]    Loss: 0.008939   Batch Acc: 85.94
[Train] Epoch: 0 [123264/620022]    Loss: 0.010320   Batch Acc: 75.00
[Train] Epoch: 0 [123328/620022]    Loss: 0.010894   Batch Acc: 71.88
[Train] Epoch: 0 [123392/620022]    Loss: 0.009718   Batch Acc: 81.25
[Train] Epoch: 0 [123456/620022]    Loss: 0.009125   Batch Acc: 79.69
[Train] Epoch: 0 [123520/620022]    Loss: 0.010662   Batch Acc: 70.31
[Train] Epoch: 0 [123584/620022]    Loss: 0.011451   Batch Acc: 64.06
[Train] Epoch: 0 [123648/620022]    Loss: 0.008877   Batch Acc: 79.69
[Train] Epoch: 0 [123712/620022]    Loss: 0.009133   Batch Acc: 82.81
[Train] Epoch: 0 [123776/620022]    Loss: 0.008550   Batch Acc: 79.69
[Train] Epoch: 0 [123840/620022]    Loss: 0.010444   Batch Acc: 68.75
[Train] Epoch: 0 [123904/620022]    Loss: 0.009452   Batch Acc: 78.12
[Train] Epoch: 0 [123968/620022]    Loss: 0.010680   Batch Acc: 71.88
[Train] Epoch: 0 [124032/620022]    Loss: 0.012630   Batch Acc: 62.50
[Train] Epoch: 0 [124096/620022]    Loss: 0.008101   Batch Acc: 81.25
[Train] Epoch: 0 [124160/620022]    Loss: 0.010992   Batch Acc: 75.00
[Train] Epoch: 0 [124224/620022]    Loss: 0.012542   Batch Acc: 56.25
[Train] Epoch: 0 [124288/620022]    Loss: 0.012100   Batch Acc: 60.94
[Train] Epoch: 0 [124352/620022]    Loss: 0.009681   Batch Acc: 82.81
[Train] Epoch: 0 [124416/620022]    Loss: 0.013381   Batch Acc: 62.50
[Train] Epoch: 0 [124480/620022]    Loss: 0.010812   Batch Acc: 68.75
[Train] Epoch: 0 [124544/620022]    Loss: 0.011922   Batch Acc: 64.06
[Train] Epoch: 0 [124608/620022]    Loss: 0.010032   Batch Acc: 78.12
[Train] Epoch: 0 [124672/620022]    Loss: 0.009821   Batch Acc: 75.00
[Train] Epoch: 0 [124736/620022]    Loss: 0.009991   Batch Acc: 78.12
[Train] Epoch: 0 [124800/620022]    Loss: 0.010550   Batch Acc: 68.75
[Train] Epoch: 0 [124864/620022]    Loss: 0.009280   Batch Acc: 81.25
[Train] Epoch: 0 [124928/620022]    Loss: 0.010306   Batch Acc: 76.56
[Train] Epoch: 0 [124992/620022]    Loss: 0.009461   Batch Acc: 78.12
[Train] Epoch: 0 [125056/620022]    Loss: 0.011595   Batch Acc: 70.31
[Train] Epoch: 0 [125120/620022]    Loss: 0.009193   Batch Acc: 81.25
[Train] Epoch: 0 [125184/620022]    Loss: 0.011220   Batch Acc: 71.88
[Train] Epoch: 0 [125248/620022]    Loss: 0.010045   Batch Acc: 76.56
[Train] Epoch: 0 [125312/620022]    Loss: 0.011310   Batch Acc: 64.06
[Train] Epoch: 0 [125376/620022]    Loss: 0.008969   Batch Acc: 79.69
[Train] Epoch: 0 [125440/620022]    Loss: 0.009945   Batch Acc: 70.31
[Train] Epoch: 0 [125504/620022]    Loss: 0.011201   Batch Acc: 71.88
[Train] Epoch: 0 [125568/620022]    Loss: 0.009537   Batch Acc: 75.00
[Train] Epoch: 0 [125632/620022]    Loss: 0.010378   Batch Acc: 78.12
[Train] Epoch: 0 [125696/620022]    Loss: 0.010524   Batch Acc: 70.31
[Train] Epoch: 0 [125760/620022]    Loss: 0.009997   Batch Acc: 70.31
[Train] Epoch: 0 [125824/620022]    Loss: 0.010069   Batch Acc: 73.44
[Train] Epoch: 0 [125888/620022]    Loss: 0.010809   Batch Acc: 65.62
[Train] Epoch: 0 [125952/620022]    Loss: 0.012246   Batch Acc: 67.19
[Train] Epoch: 0 [126016/620022]    Loss: 0.010163   Batch Acc: 76.56
[Train] Epoch: 0 [126080/620022]    Loss: 0.009771   Batch Acc: 73.44
[Train] Epoch: 0 [126144/620022]    Loss: 0.009708   Batch Acc: 76.56
[Train] Epoch: 0 [126208/620022]    Loss: 0.010078   Batch Acc: 70.31
[Train] Epoch: 0 [126272/620022]    Loss: 0.011391   Batch Acc: 65.62
[Train] Epoch: 0 [126336/620022]    Loss: 0.010119   Batch Acc: 73.44
[Train] Epoch: 0 [126400/620022]    Loss: 0.008746   Batch Acc: 84.38
[Train] Epoch: 0 [126464/620022]    Loss: 0.010264   Batch Acc: 71.88
[Train] Epoch: 0 [126528/620022]    Loss: 0.012267   Batch Acc: 67.19
[Train] Epoch: 0 [126592/620022]    Loss: 0.011741   Batch Acc: 70.31
[Train] Epoch: 0 [126656/620022]    Loss: 0.010714   Batch Acc: 68.75
[Train] Epoch: 0 [126720/620022]    Loss: 0.010518   Batch Acc: 68.75
[Train] Epoch: 0 [126784/620022]    Loss: 0.009140   Batch Acc: 87.50
[Train] Epoch: 0 [126848/620022]    Loss: 0.009563   Batch Acc: 71.88
[Train] Epoch: 0 [126912/620022]    Loss: 0.009503   Batch Acc: 79.69
[Train] Epoch: 0 [126976/620022]    Loss: 0.010436   Batch Acc: 76.56
[Train] Epoch: 0 [127040/620022]    Loss: 0.012722   Batch Acc: 67.19
[Train] Epoch: 0 [127104/620022]    Loss: 0.011966   Batch Acc: 68.75
[Train] Epoch: 0 [127168/620022]    Loss: 0.010618   Batch Acc: 70.31
[Train] Epoch: 0 [127232/620022]    Loss: 0.011592   Batch Acc: 71.88
[Train] Epoch: 0 [127296/620022]    Loss: 0.009277   Batch Acc: 78.12
[Train] Epoch: 0 [127360/620022]    Loss: 0.009894   Batch Acc: 78.12
[Train] Epoch: 0 [127424/620022]    Loss: 0.009688   Batch Acc: 78.12
[Train] Epoch: 0 [127488/620022]    Loss: 0.012566   Batch Acc: 67.19
[Train] Epoch: 0 [127552/620022]    Loss: 0.010093   Batch Acc: 78.12
[Train] Epoch: 0 [127616/620022]    Loss: 0.010914   Batch Acc: 70.31
[Train] Epoch: 0 [127680/620022]    Loss: 0.009961   Batch Acc: 68.75
[Train] Epoch: 0 [127744/620022]    Loss: 0.011495   Batch Acc: 65.62
[Train] Epoch: 0 [127808/620022]    Loss: 0.011369   Batch Acc: 68.75
[Train] Epoch: 0 [127872/620022]    Loss: 0.010119   Batch Acc: 73.44
[Train] Epoch: 0 [127936/620022]    Loss: 0.010568   Batch Acc: 75.00
[Train] Epoch: 0 [128000/620022]    Loss: 0.011158   Batch Acc: 71.88
[Train] Epoch: 0 [128064/620022]    Loss: 0.010563   Batch Acc: 75.00
[Train] Epoch: 0 [128128/620022]    Loss: 0.010371   Batch Acc: 70.31
[Train] Epoch: 0 [128192/620022]    Loss: 0.007941   Batch Acc: 79.69
[Train] Epoch: 0 [128256/620022]    Loss: 0.010096   Batch Acc: 71.88
[Train] Epoch: 0 [128320/620022]    Loss: 0.011237   Batch Acc: 68.75
[Train] Epoch: 0 [128384/620022]    Loss: 0.008868   Batch Acc: 79.69
[Train] Epoch: 0 [128448/620022]    Loss: 0.008864   Batch Acc: 79.69
[Train] Epoch: 0 [128512/620022]    Loss: 0.010410   Batch Acc: 71.88
[Train] Epoch: 0 [128576/620022]    Loss: 0.010456   Batch Acc: 71.88
[Train] Epoch: 0 [128640/620022]    Loss: 0.009905   Batch Acc: 78.12
[Train] Epoch: 0 [128704/620022]    Loss: 0.011599   Batch Acc: 68.75
[Train] Epoch: 0 [128768/620022]    Loss: 0.011054   Batch Acc: 67.19
[Train] Epoch: 0 [128832/620022]    Loss: 0.010200   Batch Acc: 71.88
[Train] Epoch: 0 [128896/620022]    Loss: 0.010597   Batch Acc: 70.31
[Train] Epoch: 0 [128960/620022]    Loss: 0.008539   Batch Acc: 79.69
[Train] Epoch: 0 [129024/620022]    Loss: 0.010274   Batch Acc: 73.44
[Train] Epoch: 0 [129088/620022]    Loss: 0.009669   Batch Acc: 75.00
[Train] Epoch: 0 [129152/620022]    Loss: 0.009691   Batch Acc: 75.00
[Train] Epoch: 0 [129216/620022]    Loss: 0.010190   Batch Acc: 73.44
[Train] Epoch: 0 [129280/620022]    Loss: 0.008731   Batch Acc: 75.00
[Train] Epoch: 0 [129344/620022]    Loss: 0.010567   Batch Acc: 73.44
[Train] Epoch: 0 [129408/620022]    Loss: 0.010238   Batch Acc: 71.88
[Train] Epoch: 0 [129472/620022]    Loss: 0.010019   Batch Acc: 73.44
[Train] Epoch: 0 [129536/620022]    Loss: 0.009840   Batch Acc: 78.12
[Train] Epoch: 0 [129600/620022]    Loss: 0.011335   Batch Acc: 75.00
[Train] Epoch: 0 [129664/620022]    Loss: 0.009904   Batch Acc: 71.88
[Train] Epoch: 0 [129728/620022]    Loss: 0.011646   Batch Acc: 70.31
[Train] Epoch: 0 [129792/620022]    Loss: 0.011481   Batch Acc: 71.88
[Train] Epoch: 0 [129856/620022]    Loss: 0.011076   Batch Acc: 68.75
[Train] Epoch: 0 [129920/620022]    Loss: 0.011945   Batch Acc: 64.06
[Train] Epoch: 0 [129984/620022]    Loss: 0.011863   Batch Acc: 64.06
[Train] Epoch: 0 [130048/620022]    Loss: 0.011158   Batch Acc: 70.31
[Train] Epoch: 0 [130112/620022]    Loss: 0.008836   Batch Acc: 75.00
[Train] Epoch: 0 [130176/620022]    Loss: 0.010421   Batch Acc: 71.88
[Train] Epoch: 0 [130240/620022]    Loss: 0.009672   Batch Acc: 76.56
[Train] Epoch: 0 [130304/620022]    Loss: 0.012558   Batch Acc: 67.19
[Train] Epoch: 0 [130368/620022]    Loss: 0.009147   Batch Acc: 81.25
[Train] Epoch: 0 [130432/620022]    Loss: 0.010159   Batch Acc: 64.06
[Train] Epoch: 0 [130496/620022]    Loss: 0.008590   Batch Acc: 82.81
[Train] Epoch: 0 [130560/620022]    Loss: 0.009910   Batch Acc: 71.88
[Train] Epoch: 0 [130624/620022]    Loss: 0.010639   Batch Acc: 78.12
[Train] Epoch: 0 [130688/620022]    Loss: 0.011499   Batch Acc: 60.94
[Train] Epoch: 0 [130752/620022]    Loss: 0.010408   Batch Acc: 71.88
[Train] Epoch: 0 [130816/620022]    Loss: 0.010735   Batch Acc: 75.00
[Train] Epoch: 0 [130880/620022]    Loss: 0.010282   Batch Acc: 67.19
[Train] Epoch: 0 [130944/620022]    Loss: 0.010362   Batch Acc: 75.00
[Train] Epoch: 0 [131008/620022]    Loss: 0.010520   Batch Acc: 75.00
[Train] Epoch: 0 [131072/620022]    Loss: 0.007918   Batch Acc: 84.38
[Train] Epoch: 0 [131136/620022]    Loss: 0.011039   Batch Acc: 73.44
[Train] Epoch: 0 [131200/620022]    Loss: 0.010564   Batch Acc: 73.44
[Train] Epoch: 0 [131264/620022]    Loss: 0.009229   Batch Acc: 76.56
[Train] Epoch: 0 [131328/620022]    Loss: 0.009839   Batch Acc: 75.00
[Train] Epoch: 0 [131392/620022]    Loss: 0.011192   Batch Acc: 68.75
[Train] Epoch: 0 [131456/620022]    Loss: 0.013819   Batch Acc: 57.81
[Train] Epoch: 0 [131520/620022]    Loss: 0.010581   Batch Acc: 68.75
[Train] Epoch: 0 [131584/620022]    Loss: 0.013491   Batch Acc: 62.50
[Train] Epoch: 0 [131648/620022]    Loss: 0.009640   Batch Acc: 73.44
[Train] Epoch: 0 [131712/620022]    Loss: 0.013041   Batch Acc: 62.50
[Train] Epoch: 0 [131776/620022]    Loss: 0.008966   Batch Acc: 81.25
[Train] Epoch: 0 [131840/620022]    Loss: 0.010582   Batch Acc: 71.88
[Train] Epoch: 0 [131904/620022]    Loss: 0.010831   Batch Acc: 68.75
[Train] Epoch: 0 [131968/620022]    Loss: 0.010657   Batch Acc: 79.69
[Train] Epoch: 0 [132032/620022]    Loss: 0.009824   Batch Acc: 73.44
[Train] Epoch: 0 [132096/620022]    Loss: 0.010638   Batch Acc: 75.00
[Train] Epoch: 0 [132160/620022]    Loss: 0.010666   Batch Acc: 68.75
[Train] Epoch: 0 [132224/620022]    Loss: 0.010942   Batch Acc: 73.44
[Train] Epoch: 0 [132288/620022]    Loss: 0.011677   Batch Acc: 62.50
[Train] Epoch: 0 [132352/620022]    Loss: 0.010637   Batch Acc: 71.88
[Train] Epoch: 0 [132416/620022]    Loss: 0.009367   Batch Acc: 75.00
[Train] Epoch: 0 [132480/620022]    Loss: 0.010451   Batch Acc: 76.56
[Train] Epoch: 0 [132544/620022]    Loss: 0.009688   Batch Acc: 76.56
[Train] Epoch: 0 [132608/620022]    Loss: 0.009961   Batch Acc: 75.00
[Train] Epoch: 0 [132672/620022]    Loss: 0.009787   Batch Acc: 71.88
[Train] Epoch: 0 [132736/620022]    Loss: 0.009099   Batch Acc: 78.12
[Train] Epoch: 0 [132800/620022]    Loss: 0.009367   Batch Acc: 76.56
[Train] Epoch: 0 [132864/620022]    Loss: 0.009264   Batch Acc: 78.12
[Train] Epoch: 0 [132928/620022]    Loss: 0.009111   Batch Acc: 79.69
[Train] Epoch: 0 [132992/620022]    Loss: 0.009426   Batch Acc: 84.38
[Train] Epoch: 0 [133056/620022]    Loss: 0.009007   Batch Acc: 75.00
[Train] Epoch: 0 [133120/620022]    Loss: 0.010393   Batch Acc: 78.12
[Train] Epoch: 0 [133184/620022]    Loss: 0.009845   Batch Acc: 76.56
[Train] Epoch: 0 [133248/620022]    Loss: 0.010133   Batch Acc: 75.00
[Train] Epoch: 0 [133312/620022]    Loss: 0.010216   Batch Acc: 73.44
[Train] Epoch: 0 [133376/620022]    Loss: 0.012401   Batch Acc: 65.62
[Train] Epoch: 0 [133440/620022]    Loss: 0.012242   Batch Acc: 71.88
[Train] Epoch: 0 [133504/620022]    Loss: 0.009576   Batch Acc: 76.56
[Train] Epoch: 0 [133568/620022]    Loss: 0.009712   Batch Acc: 78.12
[Train] Epoch: 0 [133632/620022]    Loss: 0.008561   Batch Acc: 82.81
[Train] Epoch: 0 [133696/620022]    Loss: 0.009992   Batch Acc: 76.56
[Train] Epoch: 0 [133760/620022]    Loss: 0.010149   Batch Acc: 70.31
[Train] Epoch: 0 [133824/620022]    Loss: 0.011222   Batch Acc: 70.31
[Train] Epoch: 0 [133888/620022]    Loss: 0.010525   Batch Acc: 73.44
[Train] Epoch: 0 [133952/620022]    Loss: 0.012024   Batch Acc: 67.19
[Train] Epoch: 0 [134016/620022]    Loss: 0.009722   Batch Acc: 71.88
[Train] Epoch: 0 [134080/620022]    Loss: 0.009310   Batch Acc: 78.12
[Train] Epoch: 0 [134144/620022]    Loss: 0.010821   Batch Acc: 67.19
[Train] Epoch: 0 [134208/620022]    Loss: 0.010020   Batch Acc: 75.00
[Train] Epoch: 0 [134272/620022]    Loss: 0.010900   Batch Acc: 71.88
[Train] Epoch: 0 [134336/620022]    Loss: 0.010889   Batch Acc: 67.19
[Train] Epoch: 0 [134400/620022]    Loss: 0.010599   Batch Acc: 71.88
[Train] Epoch: 0 [134464/620022]    Loss: 0.010754   Batch Acc: 75.00
[Train] Epoch: 0 [134528/620022]    Loss: 0.011199   Batch Acc: 70.31
[Train] Epoch: 0 [134592/620022]    Loss: 0.009065   Batch Acc: 79.69
[Train] Epoch: 0 [134656/620022]    Loss: 0.009564   Batch Acc: 76.56
[Train] Epoch: 0 [134720/620022]    Loss: 0.011592   Batch Acc: 71.88
[Train] Epoch: 0 [134784/620022]    Loss: 0.010778   Batch Acc: 73.44
[Train] Epoch: 0 [134848/620022]    Loss: 0.009882   Batch Acc: 75.00
[Train] Epoch: 0 [134912/620022]    Loss: 0.009800   Batch Acc: 71.88
[Train] Epoch: 0 [134976/620022]    Loss: 0.008799   Batch Acc: 78.12
[Train] Epoch: 0 [135040/620022]    Loss: 0.009544   Batch Acc: 79.69
[Train] Epoch: 0 [135104/620022]    Loss: 0.010670   Batch Acc: 62.50
[Train] Epoch: 0 [135168/620022]    Loss: 0.012278   Batch Acc: 68.75
[Train] Epoch: 0 [135232/620022]    Loss: 0.009733   Batch Acc: 70.31
[Train] Epoch: 0 [135296/620022]    Loss: 0.011962   Batch Acc: 75.00
[Train] Epoch: 0 [135360/620022]    Loss: 0.008361   Batch Acc: 82.81
[Train] Epoch: 0 [135424/620022]    Loss: 0.009864   Batch Acc: 75.00
[Train] Epoch: 0 [135488/620022]    Loss: 0.010843   Batch Acc: 70.31
[Train] Epoch: 0 [135552/620022]    Loss: 0.010556   Batch Acc: 75.00
[Train] Epoch: 0 [135616/620022]    Loss: 0.008881   Batch Acc: 79.69
[Train] Epoch: 0 [135680/620022]    Loss: 0.011305   Batch Acc: 65.62
[Train] Epoch: 0 [135744/620022]    Loss: 0.009517   Batch Acc: 78.12
[Train] Epoch: 0 [135808/620022]    Loss: 0.011147   Batch Acc: 75.00
[Train] Epoch: 0 [135872/620022]    Loss: 0.011176   Batch Acc: 62.50
[Train] Epoch: 0 [135936/620022]    Loss: 0.007431   Batch Acc: 90.62
[Train] Epoch: 0 [136000/620022]    Loss: 0.011452   Batch Acc: 70.31
[Train] Epoch: 0 [136064/620022]    Loss: 0.010083   Batch Acc: 75.00
[Train] Epoch: 0 [136128/620022]    Loss: 0.009543   Batch Acc: 76.56
[Train] Epoch: 0 [136192/620022]    Loss: 0.009500   Batch Acc: 78.12
[Train] Epoch: 0 [136256/620022]    Loss: 0.008633   Batch Acc: 78.12
[Train] Epoch: 0 [136320/620022]    Loss: 0.007545   Batch Acc: 85.94
[Train] Epoch: 0 [136384/620022]    Loss: 0.010646   Batch Acc: 71.88
[Train] Epoch: 0 [136448/620022]    Loss: 0.009564   Batch Acc: 78.12
[Train] Epoch: 0 [136512/620022]    Loss: 0.011558   Batch Acc: 64.06
[Train] Epoch: 0 [136576/620022]    Loss: 0.010166   Batch Acc: 71.88
[Train] Epoch: 0 [136640/620022]    Loss: 0.009618   Batch Acc: 76.56
[Train] Epoch: 0 [136704/620022]    Loss: 0.011475   Batch Acc: 62.50
[Train] Epoch: 0 [136768/620022]    Loss: 0.010916   Batch Acc: 68.75
[Train] Epoch: 0 [136832/620022]    Loss: 0.011411   Batch Acc: 68.75
[Train] Epoch: 0 [136896/620022]    Loss: 0.008183   Batch Acc: 82.81
[Train] Epoch: 0 [136960/620022]    Loss: 0.010217   Batch Acc: 71.88
[Train] Epoch: 0 [137024/620022]    Loss: 0.011410   Batch Acc: 67.19
[Train] Epoch: 0 [137088/620022]    Loss: 0.010297   Batch Acc: 73.44
[Train] Epoch: 0 [137152/620022]    Loss: 0.010380   Batch Acc: 68.75
[Train] Epoch: 0 [137216/620022]    Loss: 0.008534   Batch Acc: 78.12
[Train] Epoch: 0 [137280/620022]    Loss: 0.011702   Batch Acc: 67.19
[Train] Epoch: 0 [137344/620022]    Loss: 0.009834   Batch Acc: 65.62
[Train] Epoch: 0 [137408/620022]    Loss: 0.011883   Batch Acc: 67.19
[Train] Epoch: 0 [137472/620022]    Loss: 0.011186   Batch Acc: 64.06
[Train] Epoch: 0 [137536/620022]    Loss: 0.011039   Batch Acc: 67.19
[Train] Epoch: 0 [137600/620022]    Loss: 0.009786   Batch Acc: 81.25
[Train] Epoch: 0 [137664/620022]    Loss: 0.009780   Batch Acc: 75.00
[Train] Epoch: 0 [137728/620022]    Loss: 0.010196   Batch Acc: 71.88
[Train] Epoch: 0 [137792/620022]    Loss: 0.011397   Batch Acc: 64.06
[Train] Epoch: 0 [137856/620022]    Loss: 0.008639   Batch Acc: 78.12
[Train] Epoch: 0 [137920/620022]    Loss: 0.011754   Batch Acc: 64.06
[Train] Epoch: 0 [137984/620022]    Loss: 0.008694   Batch Acc: 76.56
[Train] Epoch: 0 [138048/620022]    Loss: 0.010537   Batch Acc: 67.19
[Train] Epoch: 0 [138112/620022]    Loss: 0.009497   Batch Acc: 78.12
[Train] Epoch: 0 [138176/620022]    Loss: 0.010365   Batch Acc: 73.44
[Train] Epoch: 0 [138240/620022]    Loss: 0.011516   Batch Acc: 70.31
[Train] Epoch: 0 [138304/620022]    Loss: 0.010270   Batch Acc: 70.31
[Train] Epoch: 0 [138368/620022]    Loss: 0.012848   Batch Acc: 62.50
[Train] Epoch: 0 [138432/620022]    Loss: 0.009817   Batch Acc: 81.25
[Train] Epoch: 0 [138496/620022]    Loss: 0.010879   Batch Acc: 71.88
[Train] Epoch: 0 [138560/620022]    Loss: 0.010319   Batch Acc: 78.12
[Train] Epoch: 0 [138624/620022]    Loss: 0.009804   Batch Acc: 73.44
[Train] Epoch: 0 [138688/620022]    Loss: 0.009905   Batch Acc: 76.56
[Train] Epoch: 0 [138752/620022]    Loss: 0.009665   Batch Acc: 75.00
[Train] Epoch: 0 [138816/620022]    Loss: 0.011177   Batch Acc: 60.94
[Train] Epoch: 0 [138880/620022]    Loss: 0.011501   Batch Acc: 68.75
[Train] Epoch: 0 [138944/620022]    Loss: 0.011448   Batch Acc: 70.31
[Train] Epoch: 0 [139008/620022]    Loss: 0.009968   Batch Acc: 65.62
[Train] Epoch: 0 [139072/620022]    Loss: 0.008290   Batch Acc: 79.69
[Train] Epoch: 0 [139136/620022]    Loss: 0.012778   Batch Acc: 67.19
[Train] Epoch: 0 [139200/620022]    Loss: 0.009075   Batch Acc: 76.56
[Train] Epoch: 0 [139264/620022]    Loss: 0.008623   Batch Acc: 76.56
[Train] Epoch: 0 [139328/620022]    Loss: 0.010204   Batch Acc: 75.00
[Train] Epoch: 0 [139392/620022]    Loss: 0.009686   Batch Acc: 78.12
[Train] Epoch: 0 [139456/620022]    Loss: 0.011787   Batch Acc: 73.44
[Train] Epoch: 0 [139520/620022]    Loss: 0.010658   Batch Acc: 70.31
[Train] Epoch: 0 [139584/620022]    Loss: 0.010902   Batch Acc: 64.06
[Train] Epoch: 0 [139648/620022]    Loss: 0.007088   Batch Acc: 87.50
[Train] Epoch: 0 [139712/620022]    Loss: 0.011051   Batch Acc: 68.75
[Train] Epoch: 0 [139776/620022]    Loss: 0.010499   Batch Acc: 70.31
[Train] Epoch: 0 [139840/620022]    Loss: 0.011532   Batch Acc: 71.88
[Train] Epoch: 0 [139904/620022]    Loss: 0.012406   Batch Acc: 59.38
[Train] Epoch: 0 [139968/620022]    Loss: 0.009184   Batch Acc: 79.69
[Train] Epoch: 0 [140032/620022]    Loss: 0.009374   Batch Acc: 70.31
[Train] Epoch: 0 [140096/620022]    Loss: 0.009831   Batch Acc: 67.19
[Train] Epoch: 0 [140160/620022]    Loss: 0.010065   Batch Acc: 75.00
[Train] Epoch: 0 [140224/620022]    Loss: 0.010915   Batch Acc: 73.44
[Train] Epoch: 0 [140288/620022]    Loss: 0.010507   Batch Acc: 78.12
[Train] Epoch: 0 [140352/620022]    Loss: 0.009577   Batch Acc: 76.56
[Train] Epoch: 0 [140416/620022]    Loss: 0.011571   Batch Acc: 68.75
[Train] Epoch: 0 [140480/620022]    Loss: 0.010229   Batch Acc: 75.00
[Train] Epoch: 0 [140544/620022]    Loss: 0.010991   Batch Acc: 60.94
[Train] Epoch: 0 [140608/620022]    Loss: 0.010595   Batch Acc: 75.00
[Train] Epoch: 0 [140672/620022]    Loss: 0.009283   Batch Acc: 73.44
[Train] Epoch: 0 [140736/620022]    Loss: 0.010532   Batch Acc: 67.19
[Train] Epoch: 0 [140800/620022]    Loss: 0.011171   Batch Acc: 65.62
[Train] Epoch: 0 [140864/620022]    Loss: 0.009397   Batch Acc: 73.44
[Train] Epoch: 0 [140928/620022]    Loss: 0.012505   Batch Acc: 60.94
[Train] Epoch: 0 [140992/620022]    Loss: 0.009028   Batch Acc: 76.56
[Train] Epoch: 0 [141056/620022]    Loss: 0.009732   Batch Acc: 73.44
[Train] Epoch: 0 [141120/620022]    Loss: 0.010200   Batch Acc: 62.50
[Train] Epoch: 0 [141184/620022]    Loss: 0.011752   Batch Acc: 67.19
[Train] Epoch: 0 [141248/620022]    Loss: 0.008416   Batch Acc: 84.38
[Train] Epoch: 0 [141312/620022]    Loss: 0.011186   Batch Acc: 68.75
[Train] Epoch: 0 [141376/620022]    Loss: 0.009001   Batch Acc: 78.12
[Train] Epoch: 0 [141440/620022]    Loss: 0.009823   Batch Acc: 76.56
[Train] Epoch: 0 [141504/620022]    Loss: 0.009680   Batch Acc: 75.00
[Train] Epoch: 0 [141568/620022]    Loss: 0.011622   Batch Acc: 67.19
[Train] Epoch: 0 [141632/620022]    Loss: 0.009596   Batch Acc: 76.56
[Train] Epoch: 0 [141696/620022]    Loss: 0.009562   Batch Acc: 76.56
[Train] Epoch: 0 [141760/620022]    Loss: 0.010013   Batch Acc: 78.12
[Train] Epoch: 0 [141824/620022]    Loss: 0.008798   Batch Acc: 78.12
[Train] Epoch: 0 [141888/620022]    Loss: 0.010619   Batch Acc: 73.44
[Train] Epoch: 0 [141952/620022]    Loss: 0.012350   Batch Acc: 64.06
[Train] Epoch: 0 [142016/620022]    Loss: 0.011939   Batch Acc: 65.62
[Train] Epoch: 0 [142080/620022]    Loss: 0.009507   Batch Acc: 84.38
[Train] Epoch: 0 [142144/620022]    Loss: 0.010198   Batch Acc: 75.00
[Train] Epoch: 0 [142208/620022]    Loss: 0.010623   Batch Acc: 75.00
[Train] Epoch: 0 [142272/620022]    Loss: 0.011129   Batch Acc: 71.88
[Train] Epoch: 0 [142336/620022]    Loss: 0.008605   Batch Acc: 75.00
[Train] Epoch: 0 [142400/620022]    Loss: 0.009994   Batch Acc: 70.31
[Train] Epoch: 0 [142464/620022]    Loss: 0.010119   Batch Acc: 75.00
[Train] Epoch: 0 [142528/620022]    Loss: 0.010433   Batch Acc: 70.31
[Train] Epoch: 0 [142592/620022]    Loss: 0.010284   Batch Acc: 73.44
[Train] Epoch: 0 [142656/620022]    Loss: 0.008641   Batch Acc: 81.25
[Train] Epoch: 0 [142720/620022]    Loss: 0.013446   Batch Acc: 65.62
[Train] Epoch: 0 [142784/620022]    Loss: 0.010964   Batch Acc: 65.62
[Train] Epoch: 0 [142848/620022]    Loss: 0.009362   Batch Acc: 65.62
[Train] Epoch: 0 [142912/620022]    Loss: 0.010910   Batch Acc: 76.56
[Train] Epoch: 0 [142976/620022]    Loss: 0.009201   Batch Acc: 68.75
[Train] Epoch: 0 [143040/620022]    Loss: 0.009697   Batch Acc: 73.44
[Train] Epoch: 0 [143104/620022]    Loss: 0.010158   Batch Acc: 75.00
[Train] Epoch: 0 [143168/620022]    Loss: 0.010198   Batch Acc: 71.88
[Train] Epoch: 0 [143232/620022]    Loss: 0.008945   Batch Acc: 76.56
[Train] Epoch: 0 [143296/620022]    Loss: 0.008782   Batch Acc: 70.31
[Train] Epoch: 0 [143360/620022]    Loss: 0.010635   Batch Acc: 67.19
[Train] Epoch: 0 [143424/620022]    Loss: 0.010282   Batch Acc: 73.44
[Train] Epoch: 0 [143488/620022]    Loss: 0.008082   Batch Acc: 84.38
[Train] Epoch: 0 [143552/620022]    Loss: 0.009807   Batch Acc: 70.31
[Train] Epoch: 0 [143616/620022]    Loss: 0.009881   Batch Acc: 71.88
[Train] Epoch: 0 [143680/620022]    Loss: 0.008866   Batch Acc: 78.12
[Train] Epoch: 0 [143744/620022]    Loss: 0.009122   Batch Acc: 79.69
[Train] Epoch: 0 [143808/620022]    Loss: 0.008388   Batch Acc: 85.94
[Train] Epoch: 0 [143872/620022]    Loss: 0.013399   Batch Acc: 62.50
[Train] Epoch: 0 [143936/620022]    Loss: 0.009565   Batch Acc: 70.31
[Train] Epoch: 0 [144000/620022]    Loss: 0.009709   Batch Acc: 75.00
[Train] Epoch: 0 [144064/620022]    Loss: 0.010594   Batch Acc: 71.88
[Train] Epoch: 0 [144128/620022]    Loss: 0.009411   Batch Acc: 70.31
[Train] Epoch: 0 [144192/620022]    Loss: 0.009863   Batch Acc: 78.12
[Train] Epoch: 0 [144256/620022]    Loss: 0.009760   Batch Acc: 82.81
[Train] Epoch: 0 [144320/620022]    Loss: 0.009978   Batch Acc: 73.44
[Train] Epoch: 0 [144384/620022]    Loss: 0.010860   Batch Acc: 75.00
[Train] Epoch: 0 [144448/620022]    Loss: 0.008519   Batch Acc: 79.69
[Train] Epoch: 0 [144512/620022]    Loss: 0.009822   Batch Acc: 71.88
[Train] Epoch: 0 [144576/620022]    Loss: 0.008824   Batch Acc: 76.56
[Train] Epoch: 0 [144640/620022]    Loss: 0.011125   Batch Acc: 71.88
[Train] Epoch: 0 [144704/620022]    Loss: 0.011167   Batch Acc: 68.75
[Train] Epoch: 0 [144768/620022]    Loss: 0.009200   Batch Acc: 78.12
[Train] Epoch: 0 [144832/620022]    Loss: 0.009197   Batch Acc: 81.25
[Train] Epoch: 0 [144896/620022]    Loss: 0.010137   Batch Acc: 71.88
[Train] Epoch: 0 [144960/620022]    Loss: 0.009783   Batch Acc: 70.31
[Train] Epoch: 0 [145024/620022]    Loss: 0.009971   Batch Acc: 81.25
[Train] Epoch: 0 [145088/620022]    Loss: 0.011774   Batch Acc: 70.31
[Train] Epoch: 0 [145152/620022]    Loss: 0.010607   Batch Acc: 76.56
[Train] Epoch: 0 [145216/620022]    Loss: 0.011502   Batch Acc: 78.12
[Train] Epoch: 0 [145280/620022]    Loss: 0.011417   Batch Acc: 70.31
[Train] Epoch: 0 [145344/620022]    Loss: 0.009998   Batch Acc: 75.00
[Train] Epoch: 0 [145408/620022]    Loss: 0.012247   Batch Acc: 62.50
[Train] Epoch: 0 [145472/620022]    Loss: 0.010674   Batch Acc: 70.31
[Train] Epoch: 0 [145536/620022]    Loss: 0.010731   Batch Acc: 70.31
[Train] Epoch: 0 [145600/620022]    Loss: 0.009823   Batch Acc: 73.44
[Train] Epoch: 0 [145664/620022]    Loss: 0.011703   Batch Acc: 65.62
[Train] Epoch: 0 [145728/620022]    Loss: 0.010607   Batch Acc: 68.75
[Train] Epoch: 0 [145792/620022]    Loss: 0.008290   Batch Acc: 82.81
[Train] Epoch: 0 [145856/620022]    Loss: 0.009965   Batch Acc: 71.88
[Train] Epoch: 0 [145920/620022]    Loss: 0.009611   Batch Acc: 78.12
[Train] Epoch: 0 [145984/620022]    Loss: 0.012475   Batch Acc: 65.62
[Train] Epoch: 0 [146048/620022]    Loss: 0.009893   Batch Acc: 75.00
[Train] Epoch: 0 [146112/620022]    Loss: 0.008075   Batch Acc: 85.94
[Train] Epoch: 0 [146176/620022]    Loss: 0.010044   Batch Acc: 73.44
[Train] Epoch: 0 [146240/620022]    Loss: 0.008151   Batch Acc: 82.81
[Train] Epoch: 0 [146304/620022]    Loss: 0.009838   Batch Acc: 73.44
[Train] Epoch: 0 [146368/620022]    Loss: 0.012113   Batch Acc: 71.88
[Train] Epoch: 0 [146432/620022]    Loss: 0.010557   Batch Acc: 79.69
[Train] Epoch: 0 [146496/620022]    Loss: 0.009293   Batch Acc: 79.69
[Train] Epoch: 0 [146560/620022]    Loss: 0.008379   Batch Acc: 79.69
[Train] Epoch: 0 [146624/620022]    Loss: 0.011530   Batch Acc: 65.62
[Train] Epoch: 0 [146688/620022]    Loss: 0.009685   Batch Acc: 71.88
[Train] Epoch: 0 [146752/620022]    Loss: 0.013732   Batch Acc: 65.62
[Train] Epoch: 0 [146816/620022]    Loss: 0.011097   Batch Acc: 68.75
[Train] Epoch: 0 [146880/620022]    Loss: 0.008248   Batch Acc: 79.69
[Train] Epoch: 0 [146944/620022]    Loss: 0.010511   Batch Acc: 68.75
[Train] Epoch: 0 [147008/620022]    Loss: 0.009352   Batch Acc: 73.44
[Train] Epoch: 0 [147072/620022]    Loss: 0.009864   Batch Acc: 70.31
[Train] Epoch: 0 [147136/620022]    Loss: 0.010066   Batch Acc: 71.88
[Train] Epoch: 0 [147200/620022]    Loss: 0.010239   Batch Acc: 71.88
[Train] Epoch: 0 [147264/620022]    Loss: 0.010662   Batch Acc: 75.00
[Train] Epoch: 0 [147328/620022]    Loss: 0.010840   Batch Acc: 70.31
[Train] Epoch: 0 [147392/620022]    Loss: 0.011763   Batch Acc: 71.88
[Train] Epoch: 0 [147456/620022]    Loss: 0.012558   Batch Acc: 67.19
[Train] Epoch: 0 [147520/620022]    Loss: 0.007364   Batch Acc: 81.25
[Train] Epoch: 0 [147584/620022]    Loss: 0.010132   Batch Acc: 67.19
[Train] Epoch: 0 [147648/620022]    Loss: 0.012023   Batch Acc: 70.31
[Train] Epoch: 0 [147712/620022]    Loss: 0.010742   Batch Acc: 70.31
[Train] Epoch: 0 [147776/620022]    Loss: 0.010685   Batch Acc: 73.44
[Train] Epoch: 0 [147840/620022]    Loss: 0.008477   Batch Acc: 79.69
[Train] Epoch: 0 [147904/620022]    Loss: 0.010828   Batch Acc: 68.75
[Train] Epoch: 0 [147968/620022]    Loss: 0.009569   Batch Acc: 70.31
[Train] Epoch: 0 [148032/620022]    Loss: 0.012374   Batch Acc: 68.75
[Train] Epoch: 0 [148096/620022]    Loss: 0.011645   Batch Acc: 70.31
[Train] Epoch: 0 [148160/620022]    Loss: 0.009894   Batch Acc: 78.12
[Train] Epoch: 0 [148224/620022]    Loss: 0.010550   Batch Acc: 67.19
[Train] Epoch: 0 [148288/620022]    Loss: 0.010189   Batch Acc: 78.12
[Train] Epoch: 0 [148352/620022]    Loss: 0.010771   Batch Acc: 68.75
[Train] Epoch: 0 [148416/620022]    Loss: 0.011012   Batch Acc: 70.31
[Train] Epoch: 0 [148480/620022]    Loss: 0.010046   Batch Acc: 73.44
[Train] Epoch: 0 [148544/620022]    Loss: 0.009009   Batch Acc: 73.44
[Train] Epoch: 0 [148608/620022]    Loss: 0.010713   Batch Acc: 71.88
[Train] Epoch: 0 [148672/620022]    Loss: 0.010880   Batch Acc: 71.88
[Train] Epoch: 0 [148736/620022]    Loss: 0.008790   Batch Acc: 73.44
[Train] Epoch: 0 [148800/620022]    Loss: 0.010069   Batch Acc: 73.44
[Train] Epoch: 0 [148864/620022]    Loss: 0.009668   Batch Acc: 75.00
[Train] Epoch: 0 [148928/620022]    Loss: 0.008694   Batch Acc: 70.31
[Train] Epoch: 0 [148992/620022]    Loss: 0.010864   Batch Acc: 70.31
[Train] Epoch: 0 [149056/620022]    Loss: 0.010473   Batch Acc: 68.75
[Train] Epoch: 0 [149120/620022]    Loss: 0.008297   Batch Acc: 85.94
[Train] Epoch: 0 [149184/620022]    Loss: 0.009435   Batch Acc: 81.25
[Train] Epoch: 0 [149248/620022]    Loss: 0.012200   Batch Acc: 64.06
[Train] Epoch: 0 [149312/620022]    Loss: 0.011030   Batch Acc: 73.44
[Train] Epoch: 0 [149376/620022]    Loss: 0.009356   Batch Acc: 81.25
[Train] Epoch: 0 [149440/620022]    Loss: 0.010980   Batch Acc: 73.44
[Train] Epoch: 0 [149504/620022]    Loss: 0.010817   Batch Acc: 70.31
[Train] Epoch: 0 [149568/620022]    Loss: 0.009933   Batch Acc: 71.88
[Train] Epoch: 0 [149632/620022]    Loss: 0.009492   Batch Acc: 75.00
[Train] Epoch: 0 [149696/620022]    Loss: 0.010650   Batch Acc: 68.75
[Train] Epoch: 0 [149760/620022]    Loss: 0.011451   Batch Acc: 71.88
[Train] Epoch: 0 [149824/620022]    Loss: 0.009963   Batch Acc: 76.56
[Train] Epoch: 0 [149888/620022]    Loss: 0.011647   Batch Acc: 70.31
[Train] Epoch: 0 [149952/620022]    Loss: 0.008071   Batch Acc: 78.12
[Train] Epoch: 0 [150016/620022]    Loss: 0.009946   Batch Acc: 75.00
[Train] Epoch: 0 [150080/620022]    Loss: 0.009905   Batch Acc: 78.12
[Train] Epoch: 0 [150144/620022]    Loss: 0.010682   Batch Acc: 73.44
[Train] Epoch: 0 [150208/620022]    Loss: 0.009778   Batch Acc: 82.81
[Train] Epoch: 0 [150272/620022]    Loss: 0.010459   Batch Acc: 71.88
[Train] Epoch: 0 [150336/620022]    Loss: 0.011630   Batch Acc: 67.19
[Train] Epoch: 0 [150400/620022]    Loss: 0.010484   Batch Acc: 71.88
[Train] Epoch: 0 [150464/620022]    Loss: 0.010569   Batch Acc: 76.56
[Train] Epoch: 0 [150528/620022]    Loss: 0.008482   Batch Acc: 82.81
[Train] Epoch: 0 [150592/620022]    Loss: 0.010991   Batch Acc: 70.31
[Train] Epoch: 0 [150656/620022]    Loss: 0.008379   Batch Acc: 81.25
[Train] Epoch: 0 [150720/620022]    Loss: 0.009958   Batch Acc: 76.56
[Train] Epoch: 0 [150784/620022]    Loss: 0.010811   Batch Acc: 68.75
[Train] Epoch: 0 [150848/620022]    Loss: 0.010598   Batch Acc: 71.88
[Train] Epoch: 0 [150912/620022]    Loss: 0.010340   Batch Acc: 75.00
[Train] Epoch: 0 [150976/620022]    Loss: 0.010576   Batch Acc: 62.50
[Train] Epoch: 0 [151040/620022]    Loss: 0.008337   Batch Acc: 85.94
[Train] Epoch: 0 [151104/620022]    Loss: 0.009366   Batch Acc: 73.44
[Train] Epoch: 0 [151168/620022]    Loss: 0.009485   Batch Acc: 81.25
[Train] Epoch: 0 [151232/620022]    Loss: 0.009971   Batch Acc: 76.56
[Train] Epoch: 0 [151296/620022]    Loss: 0.009922   Batch Acc: 78.12
[Train] Epoch: 0 [151360/620022]    Loss: 0.008375   Batch Acc: 78.12
[Train] Epoch: 0 [151424/620022]    Loss: 0.010072   Batch Acc: 75.00
[Train] Epoch: 0 [151488/620022]    Loss: 0.010180   Batch Acc: 73.44
[Train] Epoch: 0 [151552/620022]    Loss: 0.008829   Batch Acc: 78.12
[Train] Epoch: 0 [151616/620022]    Loss: 0.012506   Batch Acc: 65.62
[Train] Epoch: 0 [151680/620022]    Loss: 0.009935   Batch Acc: 73.44
[Train] Epoch: 0 [151744/620022]    Loss: 0.008341   Batch Acc: 79.69
[Train] Epoch: 0 [151808/620022]    Loss: 0.009710   Batch Acc: 75.00
[Train] Epoch: 0 [151872/620022]    Loss: 0.010061   Batch Acc: 71.88
[Train] Epoch: 0 [151936/620022]    Loss: 0.008384   Batch Acc: 75.00
[Train] Epoch: 0 [152000/620022]    Loss: 0.012234   Batch Acc: 57.81
[Train] Epoch: 0 [152064/620022]    Loss: 0.009206   Batch Acc: 81.25
[Train] Epoch: 0 [152128/620022]    Loss: 0.008204   Batch Acc: 81.25
[Train] Epoch: 0 [152192/620022]    Loss: 0.010287   Batch Acc: 68.75
[Train] Epoch: 0 [152256/620022]    Loss: 0.008730   Batch Acc: 75.00
[Train] Epoch: 0 [152320/620022]    Loss: 0.009296   Batch Acc: 73.44
[Train] Epoch: 0 [152384/620022]    Loss: 0.009596   Batch Acc: 78.12
[Train] Epoch: 0 [152448/620022]    Loss: 0.011707   Batch Acc: 64.06
[Train] Epoch: 0 [152512/620022]    Loss: 0.009789   Batch Acc: 75.00
[Train] Epoch: 0 [152576/620022]    Loss: 0.008922   Batch Acc: 71.88
[Train] Epoch: 0 [152640/620022]    Loss: 0.011375   Batch Acc: 67.19
[Train] Epoch: 0 [152704/620022]    Loss: 0.011735   Batch Acc: 73.44
[Train] Epoch: 0 [152768/620022]    Loss: 0.010540   Batch Acc: 68.75
[Train] Epoch: 0 [152832/620022]    Loss: 0.010746   Batch Acc: 70.31
[Train] Epoch: 0 [152896/620022]    Loss: 0.010904   Batch Acc: 70.31
[Train] Epoch: 0 [152960/620022]    Loss: 0.012122   Batch Acc: 65.62
[Train] Epoch: 0 [153024/620022]    Loss: 0.011124   Batch Acc: 70.31
[Train] Epoch: 0 [153088/620022]    Loss: 0.010402   Batch Acc: 67.19
[Train] Epoch: 0 [153152/620022]    Loss: 0.012118   Batch Acc: 64.06
[Train] Epoch: 0 [153216/620022]    Loss: 0.008613   Batch Acc: 76.56
[Train] Epoch: 0 [153280/620022]    Loss: 0.009900   Batch Acc: 75.00
[Train] Epoch: 0 [153344/620022]    Loss: 0.009916   Batch Acc: 73.44
[Train] Epoch: 0 [153408/620022]    Loss: 0.010005   Batch Acc: 70.31
[Train] Epoch: 0 [153472/620022]    Loss: 0.011062   Batch Acc: 73.44
[Train] Epoch: 0 [153536/620022]    Loss: 0.010864   Batch Acc: 67.19
[Train] Epoch: 0 [153600/620022]    Loss: 0.010698   Batch Acc: 73.44
[Train] Epoch: 0 [153664/620022]    Loss: 0.010131   Batch Acc: 73.44
[Train] Epoch: 0 [153728/620022]    Loss: 0.009690   Batch Acc: 73.44
[Train] Epoch: 0 [153792/620022]    Loss: 0.008674   Batch Acc: 76.56
[Train] Epoch: 0 [153856/620022]    Loss: 0.010835   Batch Acc: 71.88
[Train] Epoch: 0 [153920/620022]    Loss: 0.010105   Batch Acc: 76.56
[Train] Epoch: 0 [153984/620022]    Loss: 0.009698   Batch Acc: 73.44
[Train] Epoch: 0 [154048/620022]    Loss: 0.011990   Batch Acc: 67.19
[Train] Epoch: 0 [154112/620022]    Loss: 0.008152   Batch Acc: 82.81
[Train] Epoch: 0 [154176/620022]    Loss: 0.007650   Batch Acc: 84.38
[Train] Epoch: 0 [154240/620022]    Loss: 0.010044   Batch Acc: 75.00
[Train] Epoch: 0 [154304/620022]    Loss: 0.010732   Batch Acc: 70.31
[Train] Epoch: 0 [154368/620022]    Loss: 0.009729   Batch Acc: 75.00
[Train] Epoch: 0 [154432/620022]    Loss: 0.009395   Batch Acc: 84.38
[Train] Epoch: 0 [154496/620022]    Loss: 0.009848   Batch Acc: 76.56
[Train] Epoch: 0 [154560/620022]    Loss: 0.009642   Batch Acc: 71.88
[Train] Epoch: 0 [154624/620022]    Loss: 0.010274   Batch Acc: 65.62
[Train] Epoch: 0 [154688/620022]    Loss: 0.008344   Batch Acc: 75.00
[Train] Epoch: 0 [154752/620022]    Loss: 0.009498   Batch Acc: 75.00
[Train] Epoch: 0 [154816/620022]    Loss: 0.009484   Batch Acc: 79.69
[Train] Epoch: 0 [154880/620022]    Loss: 0.009924   Batch Acc: 73.44
[Train] Epoch: 0 [154944/620022]    Loss: 0.011102   Batch Acc: 67.19
[Train] Epoch: 0 [155008/620022]    Loss: 0.009846   Batch Acc: 71.88
[Train] Epoch: 0 [155072/620022]    Loss: 0.010078   Batch Acc: 68.75
[Train] Epoch: 0 [155136/620022]    Loss: 0.010163   Batch Acc: 79.69
[Train] Epoch: 0 [155200/620022]    Loss: 0.009436   Batch Acc: 81.25
[Train] Epoch: 0 [155264/620022]    Loss: 0.007915   Batch Acc: 78.12
[Train] Epoch: 0 [155328/620022]    Loss: 0.009533   Batch Acc: 78.12
[Train] Epoch: 0 [155392/620022]    Loss: 0.008331   Batch Acc: 81.25
[Train] Epoch: 0 [155456/620022]    Loss: 0.010197   Batch Acc: 73.44
[Train] Epoch: 0 [155520/620022]    Loss: 0.009710   Batch Acc: 75.00
[Train] Epoch: 0 [155584/620022]    Loss: 0.009151   Batch Acc: 79.69
[Train] Epoch: 0 [155648/620022]    Loss: 0.008235   Batch Acc: 78.12
[Train] Epoch: 0 [155712/620022]    Loss: 0.008252   Batch Acc: 79.69
[Train] Epoch: 0 [155776/620022]    Loss: 0.011008   Batch Acc: 71.88
[Train] Epoch: 0 [155840/620022]    Loss: 0.009446   Batch Acc: 68.75
[Train] Epoch: 0 [155904/620022]    Loss: 0.010121   Batch Acc: 71.88
[Train] Epoch: 0 [155968/620022]    Loss: 0.011080   Batch Acc: 71.88
[Train] Epoch: 0 [156032/620022]    Loss: 0.010315   Batch Acc: 68.75
[Train] Epoch: 0 [156096/620022]    Loss: 0.007424   Batch Acc: 87.50
[Train] Epoch: 0 [156160/620022]    Loss: 0.011027   Batch Acc: 68.75
[Train] Epoch: 0 [156224/620022]    Loss: 0.009018   Batch Acc: 81.25
[Train] Epoch: 0 [156288/620022]    Loss: 0.010544   Batch Acc: 67.19
[Train] Epoch: 0 [156352/620022]    Loss: 0.010900   Batch Acc: 70.31
[Train] Epoch: 0 [156416/620022]    Loss: 0.011111   Batch Acc: 70.31
[Train] Epoch: 0 [156480/620022]    Loss: 0.010525   Batch Acc: 76.56
[Train] Epoch: 0 [156544/620022]    Loss: 0.010770   Batch Acc: 70.31
[Train] Epoch: 0 [156608/620022]    Loss: 0.011343   Batch Acc: 67.19
[Train] Epoch: 0 [156672/620022]    Loss: 0.010511   Batch Acc: 71.88
[Train] Epoch: 0 [156736/620022]    Loss: 0.010456   Batch Acc: 73.44
[Train] Epoch: 0 [156800/620022]    Loss: 0.008301   Batch Acc: 84.38
[Train] Epoch: 0 [156864/620022]    Loss: 0.008769   Batch Acc: 73.44
[Train] Epoch: 0 [156928/620022]    Loss: 0.009912   Batch Acc: 73.44
[Train] Epoch: 0 [156992/620022]    Loss: 0.009767   Batch Acc: 71.88
[Train] Epoch: 0 [157056/620022]    Loss: 0.010650   Batch Acc: 73.44
[Train] Epoch: 0 [157120/620022]    Loss: 0.010876   Batch Acc: 68.75
[Train] Epoch: 0 [157184/620022]    Loss: 0.011662   Batch Acc: 64.06
[Train] Epoch: 0 [157248/620022]    Loss: 0.009973   Batch Acc: 75.00
[Train] Epoch: 0 [157312/620022]    Loss: 0.011909   Batch Acc: 65.62
[Train] Epoch: 0 [157376/620022]    Loss: 0.008563   Batch Acc: 82.81
[Train] Epoch: 0 [157440/620022]    Loss: 0.009282   Batch Acc: 78.12
[Train] Epoch: 0 [157504/620022]    Loss: 0.008727   Batch Acc: 75.00
[Train] Epoch: 0 [157568/620022]    Loss: 0.010250   Batch Acc: 68.75
[Train] Epoch: 0 [157632/620022]    Loss: 0.009328   Batch Acc: 76.56
[Train] Epoch: 0 [157696/620022]    Loss: 0.006258   Batch Acc: 92.19
[Train] Epoch: 0 [157760/620022]    Loss: 0.009449   Batch Acc: 79.69
[Train] Epoch: 0 [157824/620022]    Loss: 0.009106   Batch Acc: 73.44
[Train] Epoch: 0 [157888/620022]    Loss: 0.011211   Batch Acc: 71.88
[Train] Epoch: 0 [157952/620022]    Loss: 0.008455   Batch Acc: 79.69
[Train] Epoch: 0 [158016/620022]    Loss: 0.009908   Batch Acc: 78.12
[Train] Epoch: 0 [158080/620022]    Loss: 0.009386   Batch Acc: 76.56
[Train] Epoch: 0 [158144/620022]    Loss: 0.010392   Batch Acc: 78.12
[Train] Epoch: 0 [158208/620022]    Loss: 0.009527   Batch Acc: 76.56
[Train] Epoch: 0 [158272/620022]    Loss: 0.010578   Batch Acc: 70.31
[Train] Epoch: 0 [158336/620022]    Loss: 0.011735   Batch Acc: 57.81
[Train] Epoch: 0 [158400/620022]    Loss: 0.010795   Batch Acc: 68.75
[Train] Epoch: 0 [158464/620022]    Loss: 0.010238   Batch Acc: 68.75
[Train] Epoch: 0 [158528/620022]    Loss: 0.008352   Batch Acc: 75.00
[Train] Epoch: 0 [158592/620022]    Loss: 0.009353   Batch Acc: 73.44
[Train] Epoch: 0 [158656/620022]    Loss: 0.011128   Batch Acc: 64.06
[Train] Epoch: 0 [158720/620022]    Loss: 0.010062   Batch Acc: 70.31
[Train] Epoch: 0 [158784/620022]    Loss: 0.010888   Batch Acc: 70.31
[Train] Epoch: 0 [158848/620022]    Loss: 0.009369   Batch Acc: 73.44
[Train] Epoch: 0 [158912/620022]    Loss: 0.011077   Batch Acc: 70.31
[Train] Epoch: 0 [158976/620022]    Loss: 0.008605   Batch Acc: 76.56
[Train] Epoch: 0 [159040/620022]    Loss: 0.009619   Batch Acc: 68.75
[Train] Epoch: 0 [159104/620022]    Loss: 0.012389   Batch Acc: 60.94
[Train] Epoch: 0 [159168/620022]    Loss: 0.010031   Batch Acc: 68.75
[Train] Epoch: 0 [159232/620022]    Loss: 0.011229   Batch Acc: 71.88
[Train] Epoch: 0 [159296/620022]    Loss: 0.010258   Batch Acc: 71.88
[Train] Epoch: 0 [159360/620022]    Loss: 0.011164   Batch Acc: 73.44
[Train] Epoch: 0 [159424/620022]    Loss: 0.011553   Batch Acc: 67.19
[Train] Epoch: 0 [159488/620022]    Loss: 0.011764   Batch Acc: 73.44
[Train] Epoch: 0 [159552/620022]    Loss: 0.009229   Batch Acc: 78.12
[Train] Epoch: 0 [159616/620022]    Loss: 0.009838   Batch Acc: 70.31
[Train] Epoch: 0 [159680/620022]    Loss: 0.011457   Batch Acc: 73.44
[Train] Epoch: 0 [159744/620022]    Loss: 0.009944   Batch Acc: 76.56
[Train] Epoch: 0 [159808/620022]    Loss: 0.009846   Batch Acc: 73.44
[Train] Epoch: 0 [159872/620022]    Loss: 0.009729   Batch Acc: 75.00
[Train] Epoch: 0 [159936/620022]    Loss: 0.009565   Batch Acc: 79.69
[Train] Epoch: 0 [160000/620022]    Loss: 0.011300   Batch Acc: 67.19
[Train] Epoch: 0 [160064/620022]    Loss: 0.009476   Batch Acc: 78.12
[Train] Epoch: 0 [160128/620022]    Loss: 0.011398   Batch Acc: 67.19
[Train] Epoch: 0 [160192/620022]    Loss: 0.008744   Batch Acc: 78.12
[Train] Epoch: 0 [160256/620022]    Loss: 0.010018   Batch Acc: 75.00
[Train] Epoch: 0 [160320/620022]    Loss: 0.011918   Batch Acc: 65.62
[Train] Epoch: 0 [160384/620022]    Loss: 0.008348   Batch Acc: 85.94
[Train] Epoch: 0 [160448/620022]    Loss: 0.011734   Batch Acc: 67.19
[Train] Epoch: 0 [160512/620022]    Loss: 0.012107   Batch Acc: 67.19
[Train] Epoch: 0 [160576/620022]    Loss: 0.009992   Batch Acc: 78.12
[Train] Epoch: 0 [160640/620022]    Loss: 0.010086   Batch Acc: 73.44
[Train] Epoch: 0 [160704/620022]    Loss: 0.007696   Batch Acc: 85.94
[Train] Epoch: 0 [160768/620022]    Loss: 0.008677   Batch Acc: 79.69
[Train] Epoch: 0 [160832/620022]    Loss: 0.010597   Batch Acc: 65.62
[Train] Epoch: 0 [160896/620022]    Loss: 0.010305   Batch Acc: 70.31
[Train] Epoch: 0 [160960/620022]    Loss: 0.008963   Batch Acc: 76.56
[Train] Epoch: 0 [161024/620022]    Loss: 0.008937   Batch Acc: 76.56
[Train] Epoch: 0 [161088/620022]    Loss: 0.011759   Batch Acc: 71.88
[Train] Epoch: 0 [161152/620022]    Loss: 0.011984   Batch Acc: 75.00
[Train] Epoch: 0 [161216/620022]    Loss: 0.011361   Batch Acc: 68.75
[Train] Epoch: 0 [161280/620022]    Loss: 0.009083   Batch Acc: 79.69
[Train] Epoch: 0 [161344/620022]    Loss: 0.009436   Batch Acc: 79.69
[Train] Epoch: 0 [161408/620022]    Loss: 0.010810   Batch Acc: 71.88
[Train] Epoch: 0 [161472/620022]    Loss: 0.009154   Batch Acc: 76.56
[Train] Epoch: 0 [161536/620022]    Loss: 0.009743   Batch Acc: 79.69
[Train] Epoch: 0 [161600/620022]    Loss: 0.008840   Batch Acc: 78.12
[Train] Epoch: 0 [161664/620022]    Loss: 0.010630   Batch Acc: 73.44
[Train] Epoch: 0 [161728/620022]    Loss: 0.009651   Batch Acc: 65.62
[Train] Epoch: 0 [161792/620022]    Loss: 0.009697   Batch Acc: 75.00
[Train] Epoch: 0 [161856/620022]    Loss: 0.009379   Batch Acc: 76.56
[Train] Epoch: 0 [161920/620022]    Loss: 0.012110   Batch Acc: 68.75
[Train] Epoch: 0 [161984/620022]    Loss: 0.009617   Batch Acc: 71.88
[Train] Epoch: 0 [162048/620022]    Loss: 0.009789   Batch Acc: 73.44
[Train] Epoch: 0 [162112/620022]    Loss: 0.009062   Batch Acc: 78.12
[Train] Epoch: 0 [162176/620022]    Loss: 0.008453   Batch Acc: 79.69
[Train] Epoch: 0 [162240/620022]    Loss: 0.010699   Batch Acc: 78.12
[Train] Epoch: 0 [162304/620022]    Loss: 0.011004   Batch Acc: 70.31
[Train] Epoch: 0 [162368/620022]    Loss: 0.007709   Batch Acc: 84.38
[Train] Epoch: 0 [162432/620022]    Loss: 0.010291   Batch Acc: 76.56
[Train] Epoch: 0 [162496/620022]    Loss: 0.007884   Batch Acc: 89.06
[Train] Epoch: 0 [162560/620022]    Loss: 0.010820   Batch Acc: 67.19
[Train] Epoch: 0 [162624/620022]    Loss: 0.010740   Batch Acc: 71.88
[Train] Epoch: 0 [162688/620022]    Loss: 0.009991   Batch Acc: 75.00
[Train] Epoch: 0 [162752/620022]    Loss: 0.010299   Batch Acc: 67.19
[Train] Epoch: 0 [162816/620022]    Loss: 0.009386   Batch Acc: 75.00
[Train] Epoch: 0 [162880/620022]    Loss: 0.010694   Batch Acc: 65.62
[Train] Epoch: 0 [162944/620022]    Loss: 0.009797   Batch Acc: 71.88
[Train] Epoch: 0 [163008/620022]    Loss: 0.009609   Batch Acc: 75.00
[Train] Epoch: 0 [163072/620022]    Loss: 0.010292   Batch Acc: 71.88
[Train] Epoch: 0 [163136/620022]    Loss: 0.009853   Batch Acc: 78.12
[Train] Epoch: 0 [163200/620022]    Loss: 0.010816   Batch Acc: 71.88
[Train] Epoch: 0 [163264/620022]    Loss: 0.010101   Batch Acc: 73.44
[Train] Epoch: 0 [163328/620022]    Loss: 0.009995   Batch Acc: 73.44
[Train] Epoch: 0 [163392/620022]    Loss: 0.009112   Batch Acc: 76.56
[Train] Epoch: 0 [163456/620022]    Loss: 0.009545   Batch Acc: 67.19
[Train] Epoch: 0 [163520/620022]    Loss: 0.010829   Batch Acc: 71.88
[Train] Epoch: 0 [163584/620022]    Loss: 0.007872   Batch Acc: 82.81
[Train] Epoch: 0 [163648/620022]    Loss: 0.010467   Batch Acc: 76.56
[Train] Epoch: 0 [163712/620022]    Loss: 0.010863   Batch Acc: 67.19
[Train] Epoch: 0 [163776/620022]    Loss: 0.010084   Batch Acc: 73.44
[Train] Epoch: 0 [163840/620022]    Loss: 0.009282   Batch Acc: 71.88
[Train] Epoch: 0 [163904/620022]    Loss: 0.009732   Batch Acc: 73.44
[Train] Epoch: 0 [163968/620022]    Loss: 0.010638   Batch Acc: 75.00
[Train] Epoch: 0 [164032/620022]    Loss: 0.010176   Batch Acc: 73.44
[Train] Epoch: 0 [164096/620022]    Loss: 0.009931   Batch Acc: 71.88
[Train] Epoch: 0 [164160/620022]    Loss: 0.009703   Batch Acc: 79.69
[Train] Epoch: 0 [164224/620022]    Loss: 0.009808   Batch Acc: 68.75
[Train] Epoch: 0 [164288/620022]    Loss: 0.011568   Batch Acc: 67.19
[Train] Epoch: 0 [164352/620022]    Loss: 0.008722   Batch Acc: 81.25
[Train] Epoch: 0 [164416/620022]    Loss: 0.010664   Batch Acc: 70.31
[Train] Epoch: 0 [164480/620022]    Loss: 0.011273   Batch Acc: 68.75
[Train] Epoch: 0 [164544/620022]    Loss: 0.010327   Batch Acc: 70.31
[Train] Epoch: 0 [164608/620022]    Loss: 0.009212   Batch Acc: 84.38
[Train] Epoch: 0 [164672/620022]    Loss: 0.008320   Batch Acc: 81.25
[Train] Epoch: 0 [164736/620022]    Loss: 0.010283   Batch Acc: 70.31
[Train] Epoch: 0 [164800/620022]    Loss: 0.008811   Batch Acc: 76.56
[Train] Epoch: 0 [164864/620022]    Loss: 0.011540   Batch Acc: 64.06
[Train] Epoch: 0 [164928/620022]    Loss: 0.009397   Batch Acc: 78.12
[Train] Epoch: 0 [164992/620022]    Loss: 0.009693   Batch Acc: 76.56
[Train] Epoch: 0 [165056/620022]    Loss: 0.012519   Batch Acc: 64.06
[Train] Epoch: 0 [165120/620022]    Loss: 0.008222   Batch Acc: 81.25
[Train] Epoch: 0 [165184/620022]    Loss: 0.009907   Batch Acc: 73.44
[Train] Epoch: 0 [165248/620022]    Loss: 0.010211   Batch Acc: 78.12
[Train] Epoch: 0 [165312/620022]    Loss: 0.009866   Batch Acc: 68.75
[Train] Epoch: 0 [165376/620022]    Loss: 0.010192   Batch Acc: 76.56
[Train] Epoch: 0 [165440/620022]    Loss: 0.009623   Batch Acc: 71.88
[Train] Epoch: 0 [165504/620022]    Loss: 0.008126   Batch Acc: 81.25
[Train] Epoch: 0 [165568/620022]    Loss: 0.009200   Batch Acc: 75.00
[Train] Epoch: 0 [165632/620022]    Loss: 0.009635   Batch Acc: 73.44
[Train] Epoch: 0 [165696/620022]    Loss: 0.008220   Batch Acc: 76.56
[Train] Epoch: 0 [165760/620022]    Loss: 0.007783   Batch Acc: 82.81
[Train] Epoch: 0 [165824/620022]    Loss: 0.010161   Batch Acc: 76.56
[Train] Epoch: 0 [165888/620022]    Loss: 0.010907   Batch Acc: 65.62
[Train] Epoch: 0 [165952/620022]    Loss: 0.007948   Batch Acc: 79.69
[Train] Epoch: 0 [166016/620022]    Loss: 0.008728   Batch Acc: 79.69
[Train] Epoch: 0 [166080/620022]    Loss: 0.008898   Batch Acc: 84.38
[Train] Epoch: 0 [166144/620022]    Loss: 0.010833   Batch Acc: 71.88
[Train] Epoch: 0 [166208/620022]    Loss: 0.008369   Batch Acc: 78.12
[Train] Epoch: 0 [166272/620022]    Loss: 0.010808   Batch Acc: 75.00
[Train] Epoch: 0 [166336/620022]    Loss: 0.009606   Batch Acc: 75.00
[Train] Epoch: 0 [166400/620022]    Loss: 0.009355   Batch Acc: 71.88
[Train] Epoch: 0 [166464/620022]    Loss: 0.009221   Batch Acc: 81.25
[Train] Epoch: 0 [166528/620022]    Loss: 0.009794   Batch Acc: 73.44
[Train] Epoch: 0 [166592/620022]    Loss: 0.009453   Batch Acc: 73.44
[Train] Epoch: 0 [166656/620022]    Loss: 0.007136   Batch Acc: 85.94
[Train] Epoch: 0 [166720/620022]    Loss: 0.010683   Batch Acc: 68.75
[Train] Epoch: 0 [166784/620022]    Loss: 0.008788   Batch Acc: 79.69
[Train] Epoch: 0 [166848/620022]    Loss: 0.011228   Batch Acc: 70.31
[Train] Epoch: 0 [166912/620022]    Loss: 0.010142   Batch Acc: 67.19
[Train] Epoch: 0 [166976/620022]    Loss: 0.010729   Batch Acc: 71.88
[Train] Epoch: 0 [167040/620022]    Loss: 0.011980   Batch Acc: 64.06
[Train] Epoch: 0 [167104/620022]    Loss: 0.008725   Batch Acc: 79.69
[Train] Epoch: 0 [167168/620022]    Loss: 0.011199   Batch Acc: 70.31
[Train] Epoch: 0 [167232/620022]    Loss: 0.012238   Batch Acc: 70.31
[Train] Epoch: 0 [167296/620022]    Loss: 0.010514   Batch Acc: 67.19
[Train] Epoch: 0 [167360/620022]    Loss: 0.009659   Batch Acc: 81.25
[Train] Epoch: 0 [167424/620022]    Loss: 0.007232   Batch Acc: 84.38
[Train] Epoch: 0 [167488/620022]    Loss: 0.010450   Batch Acc: 73.44
[Train] Epoch: 0 [167552/620022]    Loss: 0.010937   Batch Acc: 78.12
[Train] Epoch: 0 [167616/620022]    Loss: 0.009888   Batch Acc: 75.00
[Train] Epoch: 0 [167680/620022]    Loss: 0.009046   Batch Acc: 71.88
[Train] Epoch: 0 [167744/620022]    Loss: 0.014272   Batch Acc: 56.25
[Train] Epoch: 0 [167808/620022]    Loss: 0.009268   Batch Acc: 75.00
[Train] Epoch: 0 [167872/620022]    Loss: 0.009330   Batch Acc: 79.69
[Train] Epoch: 0 [167936/620022]    Loss: 0.009744   Batch Acc: 73.44
[Train] Epoch: 0 [168000/620022]    Loss: 0.010290   Batch Acc: 82.81
[Train] Epoch: 0 [168064/620022]    Loss: 0.009144   Batch Acc: 78.12
[Train] Epoch: 0 [168128/620022]    Loss: 0.012708   Batch Acc: 68.75
[Train] Epoch: 0 [168192/620022]    Loss: 0.010564   Batch Acc: 73.44
[Train] Epoch: 0 [168256/620022]    Loss: 0.008432   Batch Acc: 79.69
[Train] Epoch: 0 [168320/620022]    Loss: 0.010255   Batch Acc: 70.31
[Train] Epoch: 0 [168384/620022]    Loss: 0.011083   Batch Acc: 70.31
[Train] Epoch: 0 [168448/620022]    Loss: 0.012546   Batch Acc: 65.62
[Train] Epoch: 0 [168512/620022]    Loss: 0.008537   Batch Acc: 84.38
[Train] Epoch: 0 [168576/620022]    Loss: 0.010275   Batch Acc: 67.19
[Train] Epoch: 0 [168640/620022]    Loss: 0.010012   Batch Acc: 76.56
[Train] Epoch: 0 [168704/620022]    Loss: 0.010971   Batch Acc: 65.62
[Train] Epoch: 0 [168768/620022]    Loss: 0.008193   Batch Acc: 79.69
[Train] Epoch: 0 [168832/620022]    Loss: 0.008146   Batch Acc: 85.94
[Train] Epoch: 0 [168896/620022]    Loss: 0.009076   Batch Acc: 73.44
[Train] Epoch: 0 [168960/620022]    Loss: 0.012004   Batch Acc: 65.62
[Train] Epoch: 0 [169024/620022]    Loss: 0.009516   Batch Acc: 75.00
[Train] Epoch: 0 [169088/620022]    Loss: 0.009993   Batch Acc: 70.31
[Train] Epoch: 0 [169152/620022]    Loss: 0.007608   Batch Acc: 84.38
[Train] Epoch: 0 [169216/620022]    Loss: 0.010163   Batch Acc: 71.88
[Train] Epoch: 0 [169280/620022]    Loss: 0.007788   Batch Acc: 81.25
[Train] Epoch: 0 [169344/620022]    Loss: 0.011627   Batch Acc: 67.19
[Train] Epoch: 0 [169408/620022]    Loss: 0.008665   Batch Acc: 82.81
[Train] Epoch: 0 [169472/620022]    Loss: 0.008705   Batch Acc: 79.69
[Train] Epoch: 0 [169536/620022]    Loss: 0.008183   Batch Acc: 81.25
[Train] Epoch: 0 [169600/620022]    Loss: 0.011239   Batch Acc: 67.19
[Train] Epoch: 0 [169664/620022]    Loss: 0.010402   Batch Acc: 68.75
[Train] Epoch: 0 [169728/620022]    Loss: 0.009256   Batch Acc: 75.00
[Train] Epoch: 0 [169792/620022]    Loss: 0.010516   Batch Acc: 68.75
[Train] Epoch: 0 [169856/620022]    Loss: 0.011516   Batch Acc: 65.62
[Train] Epoch: 0 [169920/620022]    Loss: 0.006824   Batch Acc: 82.81
[Train] Epoch: 0 [169984/620022]    Loss: 0.009202   Batch Acc: 78.12
[Train] Epoch: 0 [170048/620022]    Loss: 0.009669   Batch Acc: 76.56
[Train] Epoch: 0 [170112/620022]    Loss: 0.012472   Batch Acc: 70.31
[Train] Epoch: 0 [170176/620022]    Loss: 0.010121   Batch Acc: 75.00
[Train] Epoch: 0 [170240/620022]    Loss: 0.009629   Batch Acc: 76.56
[Train] Epoch: 0 [170304/620022]    Loss: 0.008398   Batch Acc: 81.25
[Train] Epoch: 0 [170368/620022]    Loss: 0.009135   Batch Acc: 75.00
[Train] Epoch: 0 [170432/620022]    Loss: 0.007995   Batch Acc: 84.38
[Train] Epoch: 0 [170496/620022]    Loss: 0.009953   Batch Acc: 71.88
[Train] Epoch: 0 [170560/620022]    Loss: 0.010562   Batch Acc: 67.19
[Train] Epoch: 0 [170624/620022]    Loss: 0.010494   Batch Acc: 68.75
[Train] Epoch: 0 [170688/620022]    Loss: 0.011407   Batch Acc: 64.06
[Train] Epoch: 0 [170752/620022]    Loss: 0.009091   Batch Acc: 76.56
[Train] Epoch: 0 [170816/620022]    Loss: 0.011757   Batch Acc: 62.50
[Train] Epoch: 0 [170880/620022]    Loss: 0.009428   Batch Acc: 79.69
[Train] Epoch: 0 [170944/620022]    Loss: 0.009448   Batch Acc: 76.56
[Train] Epoch: 0 [171008/620022]    Loss: 0.008803   Batch Acc: 73.44
[Train] Epoch: 0 [171072/620022]    Loss: 0.008852   Batch Acc: 79.69
[Train] Epoch: 0 [171136/620022]    Loss: 0.009058   Batch Acc: 73.44
[Train] Epoch: 0 [171200/620022]    Loss: 0.009419   Batch Acc: 82.81
[Train] Epoch: 0 [171264/620022]    Loss: 0.010973   Batch Acc: 68.75
[Train] Epoch: 0 [171328/620022]    Loss: 0.010723   Batch Acc: 76.56
[Train] Epoch: 0 [171392/620022]    Loss: 0.008190   Batch Acc: 81.25
[Train] Epoch: 0 [171456/620022]    Loss: 0.009957   Batch Acc: 76.56
[Train] Epoch: 0 [171520/620022]    Loss: 0.012160   Batch Acc: 67.19
[Train] Epoch: 0 [171584/620022]    Loss: 0.011398   Batch Acc: 73.44
[Train] Epoch: 0 [171648/620022]    Loss: 0.010350   Batch Acc: 70.31
[Train] Epoch: 0 [171712/620022]    Loss: 0.009556   Batch Acc: 78.12
[Train] Epoch: 0 [171776/620022]    Loss: 0.008700   Batch Acc: 75.00
[Train] Epoch: 0 [171840/620022]    Loss: 0.008748   Batch Acc: 79.69
[Train] Epoch: 0 [171904/620022]    Loss: 0.009760   Batch Acc: 75.00
[Train] Epoch: 0 [171968/620022]    Loss: 0.010575   Batch Acc: 73.44
[Train] Epoch: 0 [172032/620022]    Loss: 0.008141   Batch Acc: 82.81
[Train] Epoch: 0 [172096/620022]    Loss: 0.010878   Batch Acc: 68.75
[Train] Epoch: 0 [172160/620022]    Loss: 0.007534   Batch Acc: 79.69
[Train] Epoch: 0 [172224/620022]    Loss: 0.010154   Batch Acc: 70.31
[Train] Epoch: 0 [172288/620022]    Loss: 0.010093   Batch Acc: 68.75
[Train] Epoch: 0 [172352/620022]    Loss: 0.009415   Batch Acc: 76.56
[Train] Epoch: 0 [172416/620022]    Loss: 0.011914   Batch Acc: 68.75
[Train] Epoch: 0 [172480/620022]    Loss: 0.009051   Batch Acc: 73.44
[Train] Epoch: 0 [172544/620022]    Loss: 0.011408   Batch Acc: 67.19
[Train] Epoch: 0 [172608/620022]    Loss: 0.009341   Batch Acc: 82.81
[Train] Epoch: 0 [172672/620022]    Loss: 0.008203   Batch Acc: 78.12
[Train] Epoch: 0 [172736/620022]    Loss: 0.010775   Batch Acc: 68.75
[Train] Epoch: 0 [172800/620022]    Loss: 0.010594   Batch Acc: 75.00
[Train] Epoch: 0 [172864/620022]    Loss: 0.009781   Batch Acc: 76.56
[Train] Epoch: 0 [172928/620022]    Loss: 0.008962   Batch Acc: 73.44
[Train] Epoch: 0 [172992/620022]    Loss: 0.009310   Batch Acc: 75.00
[Train] Epoch: 0 [173056/620022]    Loss: 0.008905   Batch Acc: 79.69
[Train] Epoch: 0 [173120/620022]    Loss: 0.009338   Batch Acc: 79.69
[Train] Epoch: 0 [173184/620022]    Loss: 0.009536   Batch Acc: 78.12
[Train] Epoch: 0 [173248/620022]    Loss: 0.008438   Batch Acc: 79.69
[Train] Epoch: 0 [173312/620022]    Loss: 0.009558   Batch Acc: 73.44
[Train] Epoch: 0 [173376/620022]    Loss: 0.010649   Batch Acc: 70.31
[Train] Epoch: 0 [173440/620022]    Loss: 0.010484   Batch Acc: 78.12
[Train] Epoch: 0 [173504/620022]    Loss: 0.010084   Batch Acc: 71.88
[Train] Epoch: 0 [173568/620022]    Loss: 0.011792   Batch Acc: 71.88
[Train] Epoch: 0 [173632/620022]    Loss: 0.008787   Batch Acc: 78.12
[Train] Epoch: 0 [173696/620022]    Loss: 0.008071   Batch Acc: 78.12
[Train] Epoch: 0 [173760/620022]    Loss: 0.009059   Batch Acc: 76.56
[Train] Epoch: 0 [173824/620022]    Loss: 0.009192   Batch Acc: 75.00
[Train] Epoch: 0 [173888/620022]    Loss: 0.011262   Batch Acc: 67.19
[Train] Epoch: 0 [173952/620022]    Loss: 0.009999   Batch Acc: 76.56
[Train] Epoch: 0 [174016/620022]    Loss: 0.011674   Batch Acc: 71.88
[Train] Epoch: 0 [174080/620022]    Loss: 0.009866   Batch Acc: 75.00
[Train] Epoch: 0 [174144/620022]    Loss: 0.008868   Batch Acc: 75.00
[Train] Epoch: 0 [174208/620022]    Loss: 0.009320   Batch Acc: 78.12
[Train] Epoch: 0 [174272/620022]    Loss: 0.008646   Batch Acc: 78.12
[Train] Epoch: 0 [174336/620022]    Loss: 0.010510   Batch Acc: 68.75
[Train] Epoch: 0 [174400/620022]    Loss: 0.010359   Batch Acc: 71.88
[Train] Epoch: 0 [174464/620022]    Loss: 0.008450   Batch Acc: 78.12
[Train] Epoch: 0 [174528/620022]    Loss: 0.009295   Batch Acc: 70.31
[Train] Epoch: 0 [174592/620022]    Loss: 0.011470   Batch Acc: 65.62
[Train] Epoch: 0 [174656/620022]    Loss: 0.010122   Batch Acc: 73.44
[Train] Epoch: 0 [174720/620022]    Loss: 0.011381   Batch Acc: 71.88
[Train] Epoch: 0 [174784/620022]    Loss: 0.006943   Batch Acc: 89.06
[Train] Epoch: 0 [174848/620022]    Loss: 0.009432   Batch Acc: 76.56
[Train] Epoch: 0 [174912/620022]    Loss: 0.011564   Batch Acc: 65.62
[Train] Epoch: 0 [174976/620022]    Loss: 0.011666   Batch Acc: 70.31
[Train] Epoch: 0 [175040/620022]    Loss: 0.008795   Batch Acc: 81.25
[Train] Epoch: 0 [175104/620022]    Loss: 0.010664   Batch Acc: 78.12
[Train] Epoch: 0 [175168/620022]    Loss: 0.008880   Batch Acc: 75.00
[Train] Epoch: 0 [175232/620022]    Loss: 0.012290   Batch Acc: 65.62
[Train] Epoch: 0 [175296/620022]    Loss: 0.008499   Batch Acc: 81.25
[Train] Epoch: 0 [175360/620022]    Loss: 0.009821   Batch Acc: 73.44
[Train] Epoch: 0 [175424/620022]    Loss: 0.008858   Batch Acc: 81.25
[Train] Epoch: 0 [175488/620022]    Loss: 0.012561   Batch Acc: 64.06
[Train] Epoch: 0 [175552/620022]    Loss: 0.008414   Batch Acc: 82.81
[Train] Epoch: 0 [175616/620022]    Loss: 0.008470   Batch Acc: 85.94
[Train] Epoch: 0 [175680/620022]    Loss: 0.010907   Batch Acc: 75.00
[Train] Epoch: 0 [175744/620022]    Loss: 0.010215   Batch Acc: 71.88
[Train] Epoch: 0 [175808/620022]    Loss: 0.009543   Batch Acc: 76.56
[Train] Epoch: 0 [175872/620022]    Loss: 0.010463   Batch Acc: 70.31
[Train] Epoch: 0 [175936/620022]    Loss: 0.008924   Batch Acc: 78.12
[Train] Epoch: 0 [176000/620022]    Loss: 0.010563   Batch Acc: 68.75
[Train] Epoch: 0 [176064/620022]    Loss: 0.011711   Batch Acc: 67.19
[Train] Epoch: 0 [176128/620022]    Loss: 0.009633   Batch Acc: 78.12
[Train] Epoch: 0 [176192/620022]    Loss: 0.009669   Batch Acc: 73.44
[Train] Epoch: 0 [176256/620022]    Loss: 0.010768   Batch Acc: 67.19
[Train] Epoch: 0 [176320/620022]    Loss: 0.012965   Batch Acc: 64.06
[Train] Epoch: 0 [176384/620022]    Loss: 0.008363   Batch Acc: 82.81
[Train] Epoch: 0 [176448/620022]    Loss: 0.010290   Batch Acc: 75.00
[Train] Epoch: 0 [176512/620022]    Loss: 0.009990   Batch Acc: 75.00
[Train] Epoch: 0 [176576/620022]    Loss: 0.010089   Batch Acc: 75.00
[Train] Epoch: 0 [176640/620022]    Loss: 0.010934   Batch Acc: 70.31
[Train] Epoch: 0 [176704/620022]    Loss: 0.009649   Batch Acc: 71.88
[Train] Epoch: 0 [176768/620022]    Loss: 0.009700   Batch Acc: 79.69
[Train] Epoch: 0 [176832/620022]    Loss: 0.011546   Batch Acc: 68.75
[Train] Epoch: 0 [176896/620022]    Loss: 0.010139   Batch Acc: 79.69
[Train] Epoch: 0 [176960/620022]    Loss: 0.011595   Batch Acc: 70.31
[Train] Epoch: 0 [177024/620022]    Loss: 0.009479   Batch Acc: 76.56
[Train] Epoch: 0 [177088/620022]    Loss: 0.013427   Batch Acc: 57.81
[Train] Epoch: 0 [177152/620022]    Loss: 0.011309   Batch Acc: 65.62
[Train] Epoch: 0 [177216/620022]    Loss: 0.009624   Batch Acc: 78.12
[Train] Epoch: 0 [177280/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 0 [177344/620022]    Loss: 0.009307   Batch Acc: 75.00
[Train] Epoch: 0 [177408/620022]    Loss: 0.008566   Batch Acc: 79.69
[Train] Epoch: 0 [177472/620022]    Loss: 0.009872   Batch Acc: 73.44
[Train] Epoch: 0 [177536/620022]    Loss: 0.012693   Batch Acc: 64.06
[Train] Epoch: 0 [177600/620022]    Loss: 0.009021   Batch Acc: 76.56
[Train] Epoch: 0 [177664/620022]    Loss: 0.011555   Batch Acc: 65.62
[Train] Epoch: 0 [177728/620022]    Loss: 0.009127   Batch Acc: 78.12
[Train] Epoch: 0 [177792/620022]    Loss: 0.010381   Batch Acc: 76.56
[Train] Epoch: 0 [177856/620022]    Loss: 0.009969   Batch Acc: 68.75
[Train] Epoch: 0 [177920/620022]    Loss: 0.011576   Batch Acc: 60.94
[Train] Epoch: 0 [177984/620022]    Loss: 0.008902   Batch Acc: 76.56
[Train] Epoch: 0 [178048/620022]    Loss: 0.010187   Batch Acc: 76.56
[Train] Epoch: 0 [178112/620022]    Loss: 0.009328   Batch Acc: 70.31
[Train] Epoch: 0 [178176/620022]    Loss: 0.007881   Batch Acc: 76.56
[Train] Epoch: 0 [178240/620022]    Loss: 0.010570   Batch Acc: 70.31
[Train] Epoch: 0 [178304/620022]    Loss: 0.007501   Batch Acc: 79.69
[Train] Epoch: 0 [178368/620022]    Loss: 0.010168   Batch Acc: 75.00
[Train] Epoch: 0 [178432/620022]    Loss: 0.008650   Batch Acc: 79.69
[Train] Epoch: 0 [178496/620022]    Loss: 0.009270   Batch Acc: 70.31
[Train] Epoch: 0 [178560/620022]    Loss: 0.010291   Batch Acc: 71.88
[Train] Epoch: 0 [178624/620022]    Loss: 0.009285   Batch Acc: 82.81
[Train] Epoch: 0 [178688/620022]    Loss: 0.009074   Batch Acc: 75.00
[Train] Epoch: 0 [178752/620022]    Loss: 0.011365   Batch Acc: 65.62
[Train] Epoch: 0 [178816/620022]    Loss: 0.009992   Batch Acc: 71.88
[Train] Epoch: 0 [178880/620022]    Loss: 0.009662   Batch Acc: 76.56
[Train] Epoch: 0 [178944/620022]    Loss: 0.008669   Batch Acc: 79.69
[Train] Epoch: 0 [179008/620022]    Loss: 0.009824   Batch Acc: 71.88
[Train] Epoch: 0 [179072/620022]    Loss: 0.010216   Batch Acc: 71.88
[Train] Epoch: 0 [179136/620022]    Loss: 0.008856   Batch Acc: 84.38
[Train] Epoch: 0 [179200/620022]    Loss: 0.011243   Batch Acc: 65.62
[Train] Epoch: 0 [179264/620022]    Loss: 0.009748   Batch Acc: 68.75
[Train] Epoch: 0 [179328/620022]    Loss: 0.009941   Batch Acc: 67.19
[Train] Epoch: 0 [179392/620022]    Loss: 0.009654   Batch Acc: 75.00
[Train] Epoch: 0 [179456/620022]    Loss: 0.012852   Batch Acc: 67.19
[Train] Epoch: 0 [179520/620022]    Loss: 0.009089   Batch Acc: 76.56
[Train] Epoch: 0 [179584/620022]    Loss: 0.010096   Batch Acc: 73.44
[Train] Epoch: 0 [179648/620022]    Loss: 0.010290   Batch Acc: 70.31
[Train] Epoch: 0 [179712/620022]    Loss: 0.008630   Batch Acc: 76.56
[Train] Epoch: 0 [179776/620022]    Loss: 0.009337   Batch Acc: 76.56
[Train] Epoch: 0 [179840/620022]    Loss: 0.008418   Batch Acc: 81.25
[Train] Epoch: 0 [179904/620022]    Loss: 0.009285   Batch Acc: 79.69
[Train] Epoch: 0 [179968/620022]    Loss: 0.008992   Batch Acc: 81.25
[Train] Epoch: 0 [180032/620022]    Loss: 0.008490   Batch Acc: 82.81
[Train] Epoch: 0 [180096/620022]    Loss: 0.010930   Batch Acc: 70.31
[Train] Epoch: 0 [180160/620022]    Loss: 0.010602   Batch Acc: 76.56
[Train] Epoch: 0 [180224/620022]    Loss: 0.008476   Batch Acc: 82.81
[Train] Epoch: 0 [180288/620022]    Loss: 0.009920   Batch Acc: 71.88
[Train] Epoch: 0 [180352/620022]    Loss: 0.010414   Batch Acc: 70.31
[Train] Epoch: 0 [180416/620022]    Loss: 0.009417   Batch Acc: 76.56
[Train] Epoch: 0 [180480/620022]    Loss: 0.007934   Batch Acc: 79.69
[Train] Epoch: 0 [180544/620022]    Loss: 0.009350   Batch Acc: 75.00
[Train] Epoch: 0 [180608/620022]    Loss: 0.011657   Batch Acc: 67.19
[Train] Epoch: 0 [180672/620022]    Loss: 0.008817   Batch Acc: 75.00
[Train] Epoch: 0 [180736/620022]    Loss: 0.007505   Batch Acc: 84.38
[Train] Epoch: 0 [180800/620022]    Loss: 0.010236   Batch Acc: 75.00
[Train] Epoch: 0 [180864/620022]    Loss: 0.009750   Batch Acc: 73.44
[Train] Epoch: 0 [180928/620022]    Loss: 0.009904   Batch Acc: 73.44
[Train] Epoch: 0 [180992/620022]    Loss: 0.010665   Batch Acc: 73.44
[Train] Epoch: 0 [181056/620022]    Loss: 0.009853   Batch Acc: 76.56
[Train] Epoch: 0 [181120/620022]    Loss: 0.009582   Batch Acc: 78.12
[Train] Epoch: 0 [181184/620022]    Loss: 0.009723   Batch Acc: 71.88
[Train] Epoch: 0 [181248/620022]    Loss: 0.009726   Batch Acc: 78.12
[Train] Epoch: 0 [181312/620022]    Loss: 0.011962   Batch Acc: 71.88
[Train] Epoch: 0 [181376/620022]    Loss: 0.009868   Batch Acc: 78.12
[Train] Epoch: 0 [181440/620022]    Loss: 0.009240   Batch Acc: 76.56
[Train] Epoch: 0 [181504/620022]    Loss: 0.009760   Batch Acc: 71.88
[Train] Epoch: 0 [181568/620022]    Loss: 0.009371   Batch Acc: 76.56
[Train] Epoch: 0 [181632/620022]    Loss: 0.009865   Batch Acc: 73.44
[Train] Epoch: 0 [181696/620022]    Loss: 0.010836   Batch Acc: 70.31
[Train] Epoch: 0 [181760/620022]    Loss: 0.009714   Batch Acc: 71.88
[Train] Epoch: 0 [181824/620022]    Loss: 0.008543   Batch Acc: 82.81
[Train] Epoch: 0 [181888/620022]    Loss: 0.009276   Batch Acc: 76.56
[Train] Epoch: 0 [181952/620022]    Loss: 0.006956   Batch Acc: 85.94
[Train] Epoch: 0 [182016/620022]    Loss: 0.009504   Batch Acc: 75.00
[Train] Epoch: 0 [182080/620022]    Loss: 0.010810   Batch Acc: 71.88
[Train] Epoch: 0 [182144/620022]    Loss: 0.009395   Batch Acc: 78.12
[Train] Epoch: 0 [182208/620022]    Loss: 0.009139   Batch Acc: 79.69
[Train] Epoch: 0 [182272/620022]    Loss: 0.010769   Batch Acc: 75.00
[Train] Epoch: 0 [182336/620022]    Loss: 0.010051   Batch Acc: 78.12
[Train] Epoch: 0 [182400/620022]    Loss: 0.009840   Batch Acc: 71.88
[Train] Epoch: 0 [182464/620022]    Loss: 0.007670   Batch Acc: 81.25
[Train] Epoch: 0 [182528/620022]    Loss: 0.008436   Batch Acc: 79.69
[Train] Epoch: 0 [182592/620022]    Loss: 0.009435   Batch Acc: 75.00
[Train] Epoch: 0 [182656/620022]    Loss: 0.009090   Batch Acc: 76.56
[Train] Epoch: 0 [182720/620022]    Loss: 0.009902   Batch Acc: 76.56
[Train] Epoch: 0 [182784/620022]    Loss: 0.007915   Batch Acc: 81.25
[Train] Epoch: 0 [182848/620022]    Loss: 0.009773   Batch Acc: 71.88
[Train] Epoch: 0 [182912/620022]    Loss: 0.007686   Batch Acc: 79.69
[Train] Epoch: 0 [182976/620022]    Loss: 0.008868   Batch Acc: 78.12
[Train] Epoch: 0 [183040/620022]    Loss: 0.010381   Batch Acc: 68.75
[Train] Epoch: 0 [183104/620022]    Loss: 0.008997   Batch Acc: 78.12
[Train] Epoch: 0 [183168/620022]    Loss: 0.008488   Batch Acc: 75.00
[Train] Epoch: 0 [183232/620022]    Loss: 0.009891   Batch Acc: 70.31
[Train] Epoch: 0 [183296/620022]    Loss: 0.012044   Batch Acc: 64.06
[Train] Epoch: 0 [183360/620022]    Loss: 0.010111   Batch Acc: 68.75
[Train] Epoch: 0 [183424/620022]    Loss: 0.010697   Batch Acc: 67.19
[Train] Epoch: 0 [183488/620022]    Loss: 0.008980   Batch Acc: 78.12
[Train] Epoch: 0 [183552/620022]    Loss: 0.010786   Batch Acc: 68.75
[Train] Epoch: 0 [183616/620022]    Loss: 0.009891   Batch Acc: 71.88
[Train] Epoch: 0 [183680/620022]    Loss: 0.008383   Batch Acc: 76.56
[Train] Epoch: 0 [183744/620022]    Loss: 0.010252   Batch Acc: 75.00
[Train] Epoch: 0 [183808/620022]    Loss: 0.008967   Batch Acc: 81.25
[Train] Epoch: 0 [183872/620022]    Loss: 0.011392   Batch Acc: 62.50
[Train] Epoch: 0 [183936/620022]    Loss: 0.009298   Batch Acc: 81.25
[Train] Epoch: 0 [184000/620022]    Loss: 0.011092   Batch Acc: 73.44
[Train] Epoch: 0 [184064/620022]    Loss: 0.008767   Batch Acc: 76.56
[Train] Epoch: 0 [184128/620022]    Loss: 0.007466   Batch Acc: 87.50
[Train] Epoch: 0 [184192/620022]    Loss: 0.006283   Batch Acc: 89.06
[Train] Epoch: 0 [184256/620022]    Loss: 0.010556   Batch Acc: 71.88
[Train] Epoch: 0 [184320/620022]    Loss: 0.010125   Batch Acc: 70.31
[Train] Epoch: 0 [184384/620022]    Loss: 0.010798   Batch Acc: 78.12
[Train] Epoch: 0 [184448/620022]    Loss: 0.009591   Batch Acc: 78.12
[Train] Epoch: 0 [184512/620022]    Loss: 0.009543   Batch Acc: 79.69
[Train] Epoch: 0 [184576/620022]    Loss: 0.008669   Batch Acc: 75.00
[Train] Epoch: 0 [184640/620022]    Loss: 0.009932   Batch Acc: 73.44
[Train] Epoch: 0 [184704/620022]    Loss: 0.011560   Batch Acc: 67.19
[Train] Epoch: 0 [184768/620022]    Loss: 0.008533   Batch Acc: 82.81
[Train] Epoch: 0 [184832/620022]    Loss: 0.013363   Batch Acc: 65.62
[Train] Epoch: 0 [184896/620022]    Loss: 0.010144   Batch Acc: 67.19
[Train] Epoch: 0 [184960/620022]    Loss: 0.008407   Batch Acc: 84.38
[Train] Epoch: 0 [185024/620022]    Loss: 0.010292   Batch Acc: 70.31
[Train] Epoch: 0 [185088/620022]    Loss: 0.008978   Batch Acc: 81.25
[Train] Epoch: 0 [185152/620022]    Loss: 0.010252   Batch Acc: 70.31
[Train] Epoch: 0 [185216/620022]    Loss: 0.009848   Batch Acc: 67.19
[Train] Epoch: 0 [185280/620022]    Loss: 0.013234   Batch Acc: 60.94
[Train] Epoch: 0 [185344/620022]    Loss: 0.008583   Batch Acc: 70.31
[Train] Epoch: 0 [185408/620022]    Loss: 0.009751   Batch Acc: 73.44
[Train] Epoch: 0 [185472/620022]    Loss: 0.009593   Batch Acc: 73.44
[Train] Epoch: 0 [185536/620022]    Loss: 0.008548   Batch Acc: 81.25
[Train] Epoch: 0 [185600/620022]    Loss: 0.008310   Batch Acc: 76.56
[Train] Epoch: 0 [185664/620022]    Loss: 0.011609   Batch Acc: 65.62
[Train] Epoch: 0 [185728/620022]    Loss: 0.010701   Batch Acc: 68.75
[Train] Epoch: 0 [185792/620022]    Loss: 0.011688   Batch Acc: 68.75
[Train] Epoch: 0 [185856/620022]    Loss: 0.009738   Batch Acc: 75.00
[Train] Epoch: 0 [185920/620022]    Loss: 0.008560   Batch Acc: 81.25
[Train] Epoch: 0 [185984/620022]    Loss: 0.011884   Batch Acc: 67.19
[Train] Epoch: 0 [186048/620022]    Loss: 0.007110   Batch Acc: 90.62
[Train] Epoch: 0 [186112/620022]    Loss: 0.008578   Batch Acc: 84.38
[Train] Epoch: 0 [186176/620022]    Loss: 0.010711   Batch Acc: 73.44
[Train] Epoch: 0 [186240/620022]    Loss: 0.007390   Batch Acc: 79.69
[Train] Epoch: 0 [186304/620022]    Loss: 0.010599   Batch Acc: 73.44
[Train] Epoch: 0 [186368/620022]    Loss: 0.008076   Batch Acc: 81.25
[Train] Epoch: 0 [186432/620022]    Loss: 0.011145   Batch Acc: 64.06
[Train] Epoch: 0 [186496/620022]    Loss: 0.011867   Batch Acc: 67.19
[Train] Epoch: 0 [186560/620022]    Loss: 0.009882   Batch Acc: 71.88
[Train] Epoch: 0 [186624/620022]    Loss: 0.008483   Batch Acc: 78.12
[Train] Epoch: 0 [186688/620022]    Loss: 0.009225   Batch Acc: 73.44
[Train] Epoch: 0 [186752/620022]    Loss: 0.010421   Batch Acc: 73.44
[Train] Epoch: 0 [186816/620022]    Loss: 0.008230   Batch Acc: 76.56
[Train] Epoch: 0 [186880/620022]    Loss: 0.010115   Batch Acc: 71.88
[Train] Epoch: 0 [186944/620022]    Loss: 0.010442   Batch Acc: 70.31
[Train] Epoch: 0 [187008/620022]    Loss: 0.011549   Batch Acc: 59.38
[Train] Epoch: 0 [187072/620022]    Loss: 0.008388   Batch Acc: 79.69
[Train] Epoch: 0 [187136/620022]    Loss: 0.008790   Batch Acc: 78.12
[Train] Epoch: 0 [187200/620022]    Loss: 0.009618   Batch Acc: 71.88
[Train] Epoch: 0 [187264/620022]    Loss: 0.009532   Batch Acc: 79.69
[Train] Epoch: 0 [187328/620022]    Loss: 0.010434   Batch Acc: 67.19
[Train] Epoch: 0 [187392/620022]    Loss: 0.011357   Batch Acc: 68.75
[Train] Epoch: 0 [187456/620022]    Loss: 0.010363   Batch Acc: 71.88
[Train] Epoch: 0 [187520/620022]    Loss: 0.011507   Batch Acc: 70.31
[Train] Epoch: 0 [187584/620022]    Loss: 0.008561   Batch Acc: 81.25
[Train] Epoch: 0 [187648/620022]    Loss: 0.010867   Batch Acc: 68.75
[Train] Epoch: 0 [187712/620022]    Loss: 0.008346   Batch Acc: 81.25
[Train] Epoch: 0 [187776/620022]    Loss: 0.009497   Batch Acc: 75.00
[Train] Epoch: 0 [187840/620022]    Loss: 0.011036   Batch Acc: 68.75
[Train] Epoch: 0 [187904/620022]    Loss: 0.009092   Batch Acc: 78.12
[Train] Epoch: 0 [187968/620022]    Loss: 0.007418   Batch Acc: 79.69
[Train] Epoch: 0 [188032/620022]    Loss: 0.009277   Batch Acc: 78.12
[Train] Epoch: 0 [188096/620022]    Loss: 0.008815   Batch Acc: 81.25
[Train] Epoch: 0 [188160/620022]    Loss: 0.009353   Batch Acc: 76.56
[Train] Epoch: 0 [188224/620022]    Loss: 0.008441   Batch Acc: 81.25
[Train] Epoch: 0 [188288/620022]    Loss: 0.009165   Batch Acc: 75.00
[Train] Epoch: 0 [188352/620022]    Loss: 0.008821   Batch Acc: 76.56
[Train] Epoch: 0 [188416/620022]    Loss: 0.010212   Batch Acc: 73.44
[Train] Epoch: 0 [188480/620022]    Loss: 0.010240   Batch Acc: 71.88
[Train] Epoch: 0 [188544/620022]    Loss: 0.009474   Batch Acc: 75.00
[Train] Epoch: 0 [188608/620022]    Loss: 0.008371   Batch Acc: 71.88
[Train] Epoch: 0 [188672/620022]    Loss: 0.009781   Batch Acc: 78.12
[Train] Epoch: 0 [188736/620022]    Loss: 0.008659   Batch Acc: 81.25
[Train] Epoch: 0 [188800/620022]    Loss: 0.008701   Batch Acc: 79.69
[Train] Epoch: 0 [188864/620022]    Loss: 0.009459   Batch Acc: 75.00
[Train] Epoch: 0 [188928/620022]    Loss: 0.008988   Batch Acc: 78.12
[Train] Epoch: 0 [188992/620022]    Loss: 0.010473   Batch Acc: 75.00
[Train] Epoch: 0 [189056/620022]    Loss: 0.011137   Batch Acc: 75.00
[Train] Epoch: 0 [189120/620022]    Loss: 0.010553   Batch Acc: 75.00
[Train] Epoch: 0 [189184/620022]    Loss: 0.010086   Batch Acc: 76.56
[Train] Epoch: 0 [189248/620022]    Loss: 0.008342   Batch Acc: 79.69
[Train] Epoch: 0 [189312/620022]    Loss: 0.010021   Batch Acc: 81.25
[Train] Epoch: 0 [189376/620022]    Loss: 0.008720   Batch Acc: 82.81
[Train] Epoch: 0 [189440/620022]    Loss: 0.008643   Batch Acc: 75.00
[Train] Epoch: 0 [189504/620022]    Loss: 0.009515   Batch Acc: 75.00
[Train] Epoch: 0 [189568/620022]    Loss: 0.012158   Batch Acc: 67.19
[Train] Epoch: 0 [189632/620022]    Loss: 0.008581   Batch Acc: 79.69
[Train] Epoch: 0 [189696/620022]    Loss: 0.008008   Batch Acc: 81.25
[Train] Epoch: 0 [189760/620022]    Loss: 0.009391   Batch Acc: 73.44
[Train] Epoch: 0 [189824/620022]    Loss: 0.008716   Batch Acc: 75.00
[Train] Epoch: 0 [189888/620022]    Loss: 0.008694   Batch Acc: 79.69
[Train] Epoch: 0 [189952/620022]    Loss: 0.009146   Batch Acc: 81.25
[Train] Epoch: 0 [190016/620022]    Loss: 0.009059   Batch Acc: 81.25
[Train] Epoch: 0 [190080/620022]    Loss: 0.011209   Batch Acc: 71.88
[Train] Epoch: 0 [190144/620022]    Loss: 0.007592   Batch Acc: 81.25
[Train] Epoch: 0 [190208/620022]    Loss: 0.009380   Batch Acc: 76.56
[Train] Epoch: 0 [190272/620022]    Loss: 0.009791   Batch Acc: 73.44
[Train] Epoch: 0 [190336/620022]    Loss: 0.011626   Batch Acc: 68.75
[Train] Epoch: 0 [190400/620022]    Loss: 0.010057   Batch Acc: 73.44
[Train] Epoch: 0 [190464/620022]    Loss: 0.009798   Batch Acc: 75.00
[Train] Epoch: 0 [190528/620022]    Loss: 0.009547   Batch Acc: 78.12
[Train] Epoch: 0 [190592/620022]    Loss: 0.006852   Batch Acc: 87.50
[Train] Epoch: 0 [190656/620022]    Loss: 0.008575   Batch Acc: 81.25
[Train] Epoch: 0 [190720/620022]    Loss: 0.010566   Batch Acc: 71.88
[Train] Epoch: 0 [190784/620022]    Loss: 0.010267   Batch Acc: 75.00
[Train] Epoch: 0 [190848/620022]    Loss: 0.010729   Batch Acc: 68.75
[Train] Epoch: 0 [190912/620022]    Loss: 0.010791   Batch Acc: 67.19
[Train] Epoch: 0 [190976/620022]    Loss: 0.012079   Batch Acc: 67.19
[Train] Epoch: 0 [191040/620022]    Loss: 0.011122   Batch Acc: 67.19
[Train] Epoch: 0 [191104/620022]    Loss: 0.009177   Batch Acc: 70.31
[Train] Epoch: 0 [191168/620022]    Loss: 0.009596   Batch Acc: 67.19
[Train] Epoch: 0 [191232/620022]    Loss: 0.010580   Batch Acc: 68.75
[Train] Epoch: 0 [191296/620022]    Loss: 0.010622   Batch Acc: 73.44
[Train] Epoch: 0 [191360/620022]    Loss: 0.009915   Batch Acc: 75.00
[Train] Epoch: 0 [191424/620022]    Loss: 0.008886   Batch Acc: 79.69
[Train] Epoch: 0 [191488/620022]    Loss: 0.009775   Batch Acc: 76.56
[Train] Epoch: 0 [191552/620022]    Loss: 0.010681   Batch Acc: 78.12
[Train] Epoch: 0 [191616/620022]    Loss: 0.006598   Batch Acc: 89.06
[Train] Epoch: 0 [191680/620022]    Loss: 0.009547   Batch Acc: 75.00
[Train] Epoch: 0 [191744/620022]    Loss: 0.009732   Batch Acc: 76.56
[Train] Epoch: 0 [191808/620022]    Loss: 0.010737   Batch Acc: 71.88
[Train] Epoch: 0 [191872/620022]    Loss: 0.009532   Batch Acc: 75.00
[Train] Epoch: 0 [191936/620022]    Loss: 0.010527   Batch Acc: 76.56
[Train] Epoch: 0 [192000/620022]    Loss: 0.008016   Batch Acc: 79.69
[Train] Epoch: 0 [192064/620022]    Loss: 0.010396   Batch Acc: 71.88
[Train] Epoch: 0 [192128/620022]    Loss: 0.011960   Batch Acc: 62.50
[Train] Epoch: 0 [192192/620022]    Loss: 0.008489   Batch Acc: 76.56
[Train] Epoch: 0 [192256/620022]    Loss: 0.007928   Batch Acc: 82.81
[Train] Epoch: 0 [192320/620022]    Loss: 0.010854   Batch Acc: 71.88
[Train] Epoch: 0 [192384/620022]    Loss: 0.010242   Batch Acc: 70.31
[Train] Epoch: 0 [192448/620022]    Loss: 0.008859   Batch Acc: 81.25
[Train] Epoch: 0 [192512/620022]    Loss: 0.007840   Batch Acc: 79.69
[Train] Epoch: 0 [192576/620022]    Loss: 0.008854   Batch Acc: 78.12
[Train] Epoch: 0 [192640/620022]    Loss: 0.010045   Batch Acc: 76.56
[Train] Epoch: 0 [192704/620022]    Loss: 0.009766   Batch Acc: 75.00
[Train] Epoch: 0 [192768/620022]    Loss: 0.011217   Batch Acc: 70.31
[Train] Epoch: 0 [192832/620022]    Loss: 0.009986   Batch Acc: 71.88
[Train] Epoch: 0 [192896/620022]    Loss: 0.009572   Batch Acc: 76.56
[Train] Epoch: 0 [192960/620022]    Loss: 0.009380   Batch Acc: 78.12
[Train] Epoch: 0 [193024/620022]    Loss: 0.009508   Batch Acc: 75.00
[Train] Epoch: 0 [193088/620022]    Loss: 0.009545   Batch Acc: 78.12
[Train] Epoch: 0 [193152/620022]    Loss: 0.007434   Batch Acc: 82.81
[Train] Epoch: 0 [193216/620022]    Loss: 0.007556   Batch Acc: 79.69
[Train] Epoch: 0 [193280/620022]    Loss: 0.009525   Batch Acc: 73.44
[Train] Epoch: 0 [193344/620022]    Loss: 0.010754   Batch Acc: 78.12
[Train] Epoch: 0 [193408/620022]    Loss: 0.009569   Batch Acc: 76.56
[Train] Epoch: 0 [193472/620022]    Loss: 0.007574   Batch Acc: 82.81
[Train] Epoch: 0 [193536/620022]    Loss: 0.010297   Batch Acc: 70.31
[Train] Epoch: 0 [193600/620022]    Loss: 0.011917   Batch Acc: 67.19
[Train] Epoch: 0 [193664/620022]    Loss: 0.011427   Batch Acc: 65.62
[Train] Epoch: 0 [193728/620022]    Loss: 0.010479   Batch Acc: 75.00
[Train] Epoch: 0 [193792/620022]    Loss: 0.010124   Batch Acc: 76.56
[Train] Epoch: 0 [193856/620022]    Loss: 0.010227   Batch Acc: 71.88
[Train] Epoch: 0 [193920/620022]    Loss: 0.010047   Batch Acc: 76.56
[Train] Epoch: 0 [193984/620022]    Loss: 0.009421   Batch Acc: 78.12
[Train] Epoch: 0 [194048/620022]    Loss: 0.008638   Batch Acc: 76.56
[Train] Epoch: 0 [194112/620022]    Loss: 0.011609   Batch Acc: 67.19
[Train] Epoch: 0 [194176/620022]    Loss: 0.011658   Batch Acc: 64.06
[Train] Epoch: 0 [194240/620022]    Loss: 0.009358   Batch Acc: 75.00
[Train] Epoch: 0 [194304/620022]    Loss: 0.009262   Batch Acc: 76.56
[Train] Epoch: 0 [194368/620022]    Loss: 0.009396   Batch Acc: 79.69
[Train] Epoch: 0 [194432/620022]    Loss: 0.011522   Batch Acc: 57.81
[Train] Epoch: 0 [194496/620022]    Loss: 0.009160   Batch Acc: 68.75
[Train] Epoch: 0 [194560/620022]    Loss: 0.010923   Batch Acc: 71.88
[Train] Epoch: 0 [194624/620022]    Loss: 0.009512   Batch Acc: 65.62
[Train] Epoch: 0 [194688/620022]    Loss: 0.011466   Batch Acc: 73.44
[Train] Epoch: 0 [194752/620022]    Loss: 0.008672   Batch Acc: 82.81
[Train] Epoch: 0 [194816/620022]    Loss: 0.010254   Batch Acc: 70.31
[Train] Epoch: 0 [194880/620022]    Loss: 0.011217   Batch Acc: 70.31
[Train] Epoch: 0 [194944/620022]    Loss: 0.008475   Batch Acc: 78.12
[Train] Epoch: 0 [195008/620022]    Loss: 0.007570   Batch Acc: 84.38
[Train] Epoch: 0 [195072/620022]    Loss: 0.009827   Batch Acc: 78.12
[Train] Epoch: 0 [195136/620022]    Loss: 0.008143   Batch Acc: 84.38
[Train] Epoch: 0 [195200/620022]    Loss: 0.009215   Batch Acc: 75.00
[Train] Epoch: 0 [195264/620022]    Loss: 0.011053   Batch Acc: 67.19
[Train] Epoch: 0 [195328/620022]    Loss: 0.009299   Batch Acc: 76.56
[Train] Epoch: 0 [195392/620022]    Loss: 0.010087   Batch Acc: 78.12
[Train] Epoch: 0 [195456/620022]    Loss: 0.012582   Batch Acc: 68.75
[Train] Epoch: 0 [195520/620022]    Loss: 0.007501   Batch Acc: 85.94
[Train] Epoch: 0 [195584/620022]    Loss: 0.008296   Batch Acc: 82.81
[Train] Epoch: 0 [195648/620022]    Loss: 0.008218   Batch Acc: 82.81
[Train] Epoch: 0 [195712/620022]    Loss: 0.011061   Batch Acc: 73.44
[Train] Epoch: 0 [195776/620022]    Loss: 0.008354   Batch Acc: 82.81
[Train] Epoch: 0 [195840/620022]    Loss: 0.009958   Batch Acc: 71.88
[Train] Epoch: 0 [195904/620022]    Loss: 0.008499   Batch Acc: 76.56
[Train] Epoch: 0 [195968/620022]    Loss: 0.008086   Batch Acc: 82.81
[Train] Epoch: 0 [196032/620022]    Loss: 0.010092   Batch Acc: 73.44
[Train] Epoch: 0 [196096/620022]    Loss: 0.010873   Batch Acc: 76.56
[Train] Epoch: 0 [196160/620022]    Loss: 0.011639   Batch Acc: 75.00
[Train] Epoch: 0 [196224/620022]    Loss: 0.009946   Batch Acc: 67.19
[Train] Epoch: 0 [196288/620022]    Loss: 0.008619   Batch Acc: 82.81
[Train] Epoch: 0 [196352/620022]    Loss: 0.008473   Batch Acc: 82.81
[Train] Epoch: 0 [196416/620022]    Loss: 0.008393   Batch Acc: 75.00
[Train] Epoch: 0 [196480/620022]    Loss: 0.011559   Batch Acc: 68.75
[Train] Epoch: 0 [196544/620022]    Loss: 0.011741   Batch Acc: 68.75
[Train] Epoch: 0 [196608/620022]    Loss: 0.010539   Batch Acc: 78.12
[Train] Epoch: 0 [196672/620022]    Loss: 0.010225   Batch Acc: 73.44
[Train] Epoch: 0 [196736/620022]    Loss: 0.009959   Batch Acc: 75.00
[Train] Epoch: 0 [196800/620022]    Loss: 0.007934   Batch Acc: 82.81
[Train] Epoch: 0 [196864/620022]    Loss: 0.010960   Batch Acc: 75.00
[Train] Epoch: 0 [196928/620022]    Loss: 0.008711   Batch Acc: 73.44
[Train] Epoch: 0 [196992/620022]    Loss: 0.009883   Batch Acc: 75.00
[Train] Epoch: 0 [197056/620022]    Loss: 0.009989   Batch Acc: 75.00
[Train] Epoch: 0 [197120/620022]    Loss: 0.009791   Batch Acc: 76.56
[Train] Epoch: 0 [197184/620022]    Loss: 0.010175   Batch Acc: 65.62
[Train] Epoch: 0 [197248/620022]    Loss: 0.008132   Batch Acc: 78.12
[Train] Epoch: 0 [197312/620022]    Loss: 0.008772   Batch Acc: 78.12
[Train] Epoch: 0 [197376/620022]    Loss: 0.007694   Batch Acc: 84.38
[Train] Epoch: 0 [197440/620022]    Loss: 0.009114   Batch Acc: 78.12
[Train] Epoch: 0 [197504/620022]    Loss: 0.008223   Batch Acc: 75.00
[Train] Epoch: 0 [197568/620022]    Loss: 0.010874   Batch Acc: 67.19
[Train] Epoch: 0 [197632/620022]    Loss: 0.012224   Batch Acc: 62.50
[Train] Epoch: 0 [197696/620022]    Loss: 0.009767   Batch Acc: 71.88
[Train] Epoch: 0 [197760/620022]    Loss: 0.011105   Batch Acc: 67.19
[Train] Epoch: 0 [197824/620022]    Loss: 0.009959   Batch Acc: 75.00
[Train] Epoch: 0 [197888/620022]    Loss: 0.007907   Batch Acc: 81.25
[Train] Epoch: 0 [197952/620022]    Loss: 0.008509   Batch Acc: 78.12
[Train] Epoch: 0 [198016/620022]    Loss: 0.008445   Batch Acc: 76.56
[Train] Epoch: 0 [198080/620022]    Loss: 0.010332   Batch Acc: 73.44
[Train] Epoch: 0 [198144/620022]    Loss: 0.009493   Batch Acc: 76.56
[Train] Epoch: 0 [198208/620022]    Loss: 0.007867   Batch Acc: 81.25
[Train] Epoch: 0 [198272/620022]    Loss: 0.008591   Batch Acc: 75.00
[Train] Epoch: 0 [198336/620022]    Loss: 0.009205   Batch Acc: 76.56
[Train] Epoch: 0 [198400/620022]    Loss: 0.011921   Batch Acc: 65.62
[Train] Epoch: 0 [198464/620022]    Loss: 0.007342   Batch Acc: 81.25
[Train] Epoch: 0 [198528/620022]    Loss: 0.011212   Batch Acc: 68.75
[Train] Epoch: 0 [198592/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 0 [198656/620022]    Loss: 0.006193   Batch Acc: 87.50
[Train] Epoch: 0 [198720/620022]    Loss: 0.008193   Batch Acc: 78.12
[Train] Epoch: 0 [198784/620022]    Loss: 0.012368   Batch Acc: 65.62
[Train] Epoch: 0 [198848/620022]    Loss: 0.009472   Batch Acc: 75.00
[Train] Epoch: 0 [198912/620022]    Loss: 0.010287   Batch Acc: 68.75
[Train] Epoch: 0 [198976/620022]    Loss: 0.009999   Batch Acc: 68.75
[Train] Epoch: 0 [199040/620022]    Loss: 0.010224   Batch Acc: 70.31
[Train] Epoch: 0 [199104/620022]    Loss: 0.009744   Batch Acc: 75.00
[Train] Epoch: 0 [199168/620022]    Loss: 0.008074   Batch Acc: 87.50
[Train] Epoch: 0 [199232/620022]    Loss: 0.009570   Batch Acc: 79.69
[Train] Epoch: 0 [199296/620022]    Loss: 0.009362   Batch Acc: 79.69
[Train] Epoch: 0 [199360/620022]    Loss: 0.008558   Batch Acc: 78.12
[Train] Epoch: 0 [199424/620022]    Loss: 0.010095   Batch Acc: 76.56
[Train] Epoch: 0 [199488/620022]    Loss: 0.008711   Batch Acc: 76.56
[Train] Epoch: 0 [199552/620022]    Loss: 0.009713   Batch Acc: 79.69
[Train] Epoch: 0 [199616/620022]    Loss: 0.008860   Batch Acc: 76.56
[Train] Epoch: 0 [199680/620022]    Loss: 0.008052   Batch Acc: 87.50
[Train] Epoch: 0 [199744/620022]    Loss: 0.010259   Batch Acc: 73.44
[Train] Epoch: 0 [199808/620022]    Loss: 0.009636   Batch Acc: 68.75
[Train] Epoch: 0 [199872/620022]    Loss: 0.009211   Batch Acc: 71.88
[Train] Epoch: 0 [199936/620022]    Loss: 0.011877   Batch Acc: 70.31
[Train] Epoch: 0 [200000/620022]    Loss: 0.010307   Batch Acc: 68.75
[Train] Epoch: 0 [200064/620022]    Loss: 0.009120   Batch Acc: 79.69
[Train] Epoch: 0 [200128/620022]    Loss: 0.008340   Batch Acc: 82.81
[Train] Epoch: 0 [200192/620022]    Loss: 0.009190   Batch Acc: 78.12
[Train] Epoch: 0 [200256/620022]    Loss: 0.006872   Batch Acc: 87.50
[Train] Epoch: 0 [200320/620022]    Loss: 0.008738   Batch Acc: 78.12
[Train] Epoch: 0 [200384/620022]    Loss: 0.010562   Batch Acc: 73.44
[Train] Epoch: 0 [200448/620022]    Loss: 0.010760   Batch Acc: 68.75
[Train] Epoch: 0 [200512/620022]    Loss: 0.010832   Batch Acc: 73.44
[Train] Epoch: 0 [200576/620022]    Loss: 0.011850   Batch Acc: 75.00
[Train] Epoch: 0 [200640/620022]    Loss: 0.009710   Batch Acc: 70.31
[Train] Epoch: 0 [200704/620022]    Loss: 0.009330   Batch Acc: 78.12
[Train] Epoch: 0 [200768/620022]    Loss: 0.009966   Batch Acc: 71.88
[Train] Epoch: 0 [200832/620022]    Loss: 0.007903   Batch Acc: 81.25
[Train] Epoch: 0 [200896/620022]    Loss: 0.007933   Batch Acc: 82.81
[Train] Epoch: 0 [200960/620022]    Loss: 0.008533   Batch Acc: 85.94
[Train] Epoch: 0 [201024/620022]    Loss: 0.009552   Batch Acc: 70.31
[Train] Epoch: 0 [201088/620022]    Loss: 0.010131   Batch Acc: 73.44
[Train] Epoch: 0 [201152/620022]    Loss: 0.009741   Batch Acc: 76.56
[Train] Epoch: 0 [201216/620022]    Loss: 0.010206   Batch Acc: 73.44
[Train] Epoch: 0 [201280/620022]    Loss: 0.009769   Batch Acc: 67.19
[Train] Epoch: 0 [201344/620022]    Loss: 0.008903   Batch Acc: 78.12
[Train] Epoch: 0 [201408/620022]    Loss: 0.009384   Batch Acc: 76.56
[Train] Epoch: 0 [201472/620022]    Loss: 0.009178   Batch Acc: 75.00
[Train] Epoch: 0 [201536/620022]    Loss: 0.010297   Batch Acc: 70.31
[Train] Epoch: 0 [201600/620022]    Loss: 0.009024   Batch Acc: 78.12
[Train] Epoch: 0 [201664/620022]    Loss: 0.010454   Batch Acc: 75.00
[Train] Epoch: 0 [201728/620022]    Loss: 0.008597   Batch Acc: 82.81
[Train] Epoch: 0 [201792/620022]    Loss: 0.010125   Batch Acc: 75.00
[Train] Epoch: 0 [201856/620022]    Loss: 0.011060   Batch Acc: 64.06
[Train] Epoch: 0 [201920/620022]    Loss: 0.009541   Batch Acc: 81.25
[Train] Epoch: 0 [201984/620022]    Loss: 0.010901   Batch Acc: 70.31
[Train] Epoch: 0 [202048/620022]    Loss: 0.010128   Batch Acc: 75.00
[Train] Epoch: 0 [202112/620022]    Loss: 0.009668   Batch Acc: 75.00
[Train] Epoch: 0 [202176/620022]    Loss: 0.009177   Batch Acc: 78.12
[Train] Epoch: 0 [202240/620022]    Loss: 0.010531   Batch Acc: 71.88
[Train] Epoch: 0 [202304/620022]    Loss: 0.008611   Batch Acc: 78.12
[Train] Epoch: 0 [202368/620022]    Loss: 0.009463   Batch Acc: 71.88
[Train] Epoch: 0 [202432/620022]    Loss: 0.008945   Batch Acc: 75.00
[Train] Epoch: 0 [202496/620022]    Loss: 0.008635   Batch Acc: 82.81
[Train] Epoch: 0 [202560/620022]    Loss: 0.009234   Batch Acc: 76.56
[Train] Epoch: 0 [202624/620022]    Loss: 0.009096   Batch Acc: 76.56
[Train] Epoch: 0 [202688/620022]    Loss: 0.007674   Batch Acc: 81.25
[Train] Epoch: 0 [202752/620022]    Loss: 0.008940   Batch Acc: 79.69
[Train] Epoch: 0 [202816/620022]    Loss: 0.007297   Batch Acc: 84.38
[Train] Epoch: 0 [202880/620022]    Loss: 0.008780   Batch Acc: 84.38
[Train] Epoch: 0 [202944/620022]    Loss: 0.011058   Batch Acc: 75.00
[Train] Epoch: 0 [203008/620022]    Loss: 0.009664   Batch Acc: 78.12
[Train] Epoch: 0 [203072/620022]    Loss: 0.010304   Batch Acc: 73.44
[Train] Epoch: 0 [203136/620022]    Loss: 0.010185   Batch Acc: 68.75
[Train] Epoch: 0 [203200/620022]    Loss: 0.009230   Batch Acc: 73.44
[Train] Epoch: 0 [203264/620022]    Loss: 0.008509   Batch Acc: 79.69
[Train] Epoch: 0 [203328/620022]    Loss: 0.011838   Batch Acc: 59.38
[Train] Epoch: 0 [203392/620022]    Loss: 0.009645   Batch Acc: 73.44
[Train] Epoch: 0 [203456/620022]    Loss: 0.008254   Batch Acc: 81.25
[Train] Epoch: 0 [203520/620022]    Loss: 0.012374   Batch Acc: 70.31
[Train] Epoch: 0 [203584/620022]    Loss: 0.010237   Batch Acc: 78.12
[Train] Epoch: 0 [203648/620022]    Loss: 0.009335   Batch Acc: 76.56
[Train] Epoch: 0 [203712/620022]    Loss: 0.009873   Batch Acc: 71.88
[Train] Epoch: 0 [203776/620022]    Loss: 0.009794   Batch Acc: 78.12
[Train] Epoch: 0 [203840/620022]    Loss: 0.008558   Batch Acc: 79.69
[Train] Epoch: 0 [203904/620022]    Loss: 0.011334   Batch Acc: 68.75
[Train] Epoch: 0 [203968/620022]    Loss: 0.011978   Batch Acc: 65.62
[Train] Epoch: 0 [204032/620022]    Loss: 0.010001   Batch Acc: 71.88
[Train] Epoch: 0 [204096/620022]    Loss: 0.011090   Batch Acc: 68.75
[Train] Epoch: 0 [204160/620022]    Loss: 0.009550   Batch Acc: 71.88
[Train] Epoch: 0 [204224/620022]    Loss: 0.009024   Batch Acc: 73.44
[Train] Epoch: 0 [204288/620022]    Loss: 0.007559   Batch Acc: 84.38
[Train] Epoch: 0 [204352/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 0 [204416/620022]    Loss: 0.010774   Batch Acc: 73.44
[Train] Epoch: 0 [204480/620022]    Loss: 0.011919   Batch Acc: 68.75
[Train] Epoch: 0 [204544/620022]    Loss: 0.009255   Batch Acc: 73.44
[Train] Epoch: 0 [204608/620022]    Loss: 0.010361   Batch Acc: 76.56
[Train] Epoch: 0 [204672/620022]    Loss: 0.009987   Batch Acc: 81.25
[Train] Epoch: 0 [204736/620022]    Loss: 0.010965   Batch Acc: 71.88
[Train] Epoch: 0 [204800/620022]    Loss: 0.009838   Batch Acc: 73.44
[Train] Epoch: 0 [204864/620022]    Loss: 0.010217   Batch Acc: 76.56
[Train] Epoch: 0 [204928/620022]    Loss: 0.009778   Batch Acc: 73.44
[Train] Epoch: 0 [204992/620022]    Loss: 0.012462   Batch Acc: 57.81
[Train] Epoch: 0 [205056/620022]    Loss: 0.008593   Batch Acc: 81.25
[Train] Epoch: 0 [205120/620022]    Loss: 0.008489   Batch Acc: 79.69
[Train] Epoch: 0 [205184/620022]    Loss: 0.009906   Batch Acc: 76.56
[Train] Epoch: 0 [205248/620022]    Loss: 0.008823   Batch Acc: 81.25
[Train] Epoch: 0 [205312/620022]    Loss: 0.008087   Batch Acc: 85.94
[Train] Epoch: 0 [205376/620022]    Loss: 0.011020   Batch Acc: 76.56
[Train] Epoch: 0 [205440/620022]    Loss: 0.010038   Batch Acc: 68.75
[Train] Epoch: 0 [205504/620022]    Loss: 0.013768   Batch Acc: 60.94
[Train] Epoch: 0 [205568/620022]    Loss: 0.010322   Batch Acc: 75.00
[Train] Epoch: 0 [205632/620022]    Loss: 0.011318   Batch Acc: 68.75
[Train] Epoch: 0 [205696/620022]    Loss: 0.011385   Batch Acc: 65.62
[Train] Epoch: 0 [205760/620022]    Loss: 0.009806   Batch Acc: 71.88
[Train] Epoch: 0 [205824/620022]    Loss: 0.008497   Batch Acc: 81.25
[Train] Epoch: 0 [205888/620022]    Loss: 0.008995   Batch Acc: 78.12
[Train] Epoch: 0 [205952/620022]    Loss: 0.011310   Batch Acc: 70.31
[Train] Epoch: 0 [206016/620022]    Loss: 0.011088   Batch Acc: 67.19
[Train] Epoch: 0 [206080/620022]    Loss: 0.009777   Batch Acc: 73.44
[Train] Epoch: 0 [206144/620022]    Loss: 0.010991   Batch Acc: 70.31
[Train] Epoch: 0 [206208/620022]    Loss: 0.009485   Batch Acc: 76.56
[Train] Epoch: 0 [206272/620022]    Loss: 0.009651   Batch Acc: 75.00
[Train] Epoch: 0 [206336/620022]    Loss: 0.009719   Batch Acc: 73.44
[Train] Epoch: 0 [206400/620022]    Loss: 0.010158   Batch Acc: 70.31
[Train] Epoch: 0 [206464/620022]    Loss: 0.009153   Batch Acc: 79.69
[Train] Epoch: 0 [206528/620022]    Loss: 0.008917   Batch Acc: 79.69
[Train] Epoch: 0 [206592/620022]    Loss: 0.009582   Batch Acc: 75.00
[Train] Epoch: 0 [206656/620022]    Loss: 0.010408   Batch Acc: 64.06
[Train] Epoch: 0 [206720/620022]    Loss: 0.011035   Batch Acc: 73.44
[Train] Epoch: 0 [206784/620022]    Loss: 0.009138   Batch Acc: 78.12
[Train] Epoch: 0 [206848/620022]    Loss: 0.009800   Batch Acc: 71.88
[Train] Epoch: 0 [206912/620022]    Loss: 0.009537   Batch Acc: 78.12
[Train] Epoch: 0 [206976/620022]    Loss: 0.008686   Batch Acc: 75.00
[Train] Epoch: 0 [207040/620022]    Loss: 0.009868   Batch Acc: 71.88
[Train] Epoch: 0 [207104/620022]    Loss: 0.008198   Batch Acc: 81.25
[Train] Epoch: 0 [207168/620022]    Loss: 0.008968   Batch Acc: 76.56
[Train] Epoch: 0 [207232/620022]    Loss: 0.008962   Batch Acc: 76.56
[Train] Epoch: 0 [207296/620022]    Loss: 0.008189   Batch Acc: 78.12
[Train] Epoch: 0 [207360/620022]    Loss: 0.008470   Batch Acc: 75.00
[Train] Epoch: 0 [207424/620022]    Loss: 0.009050   Batch Acc: 79.69
[Train] Epoch: 0 [207488/620022]    Loss: 0.009941   Batch Acc: 68.75
[Train] Epoch: 0 [207552/620022]    Loss: 0.008719   Batch Acc: 79.69
[Train] Epoch: 0 [207616/620022]    Loss: 0.009293   Batch Acc: 70.31
[Train] Epoch: 0 [207680/620022]    Loss: 0.009445   Batch Acc: 79.69
[Train] Epoch: 0 [207744/620022]    Loss: 0.009153   Batch Acc: 73.44
[Train] Epoch: 0 [207808/620022]    Loss: 0.012011   Batch Acc: 71.88
[Train] Epoch: 0 [207872/620022]    Loss: 0.010017   Batch Acc: 75.00
[Train] Epoch: 0 [207936/620022]    Loss: 0.008865   Batch Acc: 79.69
[Train] Epoch: 0 [208000/620022]    Loss: 0.012166   Batch Acc: 71.88
[Train] Epoch: 0 [208064/620022]    Loss: 0.009043   Batch Acc: 73.44
[Train] Epoch: 0 [208128/620022]    Loss: 0.008592   Batch Acc: 76.56
[Train] Epoch: 0 [208192/620022]    Loss: 0.011074   Batch Acc: 73.44
[Train] Epoch: 0 [208256/620022]    Loss: 0.010348   Batch Acc: 73.44
[Train] Epoch: 0 [208320/620022]    Loss: 0.008478   Batch Acc: 79.69
[Train] Epoch: 0 [208384/620022]    Loss: 0.009200   Batch Acc: 73.44
[Train] Epoch: 0 [208448/620022]    Loss: 0.008705   Batch Acc: 79.69
[Train] Epoch: 0 [208512/620022]    Loss: 0.011430   Batch Acc: 70.31
[Train] Epoch: 0 [208576/620022]    Loss: 0.008818   Batch Acc: 76.56
[Train] Epoch: 0 [208640/620022]    Loss: 0.010628   Batch Acc: 68.75
[Train] Epoch: 0 [208704/620022]    Loss: 0.009269   Batch Acc: 78.12
[Train] Epoch: 0 [208768/620022]    Loss: 0.008157   Batch Acc: 78.12
[Train] Epoch: 0 [208832/620022]    Loss: 0.008052   Batch Acc: 78.12
[Train] Epoch: 0 [208896/620022]    Loss: 0.010784   Batch Acc: 68.75
[Train] Epoch: 0 [208960/620022]    Loss: 0.009687   Batch Acc: 75.00
[Train] Epoch: 0 [209024/620022]    Loss: 0.010106   Batch Acc: 73.44
[Train] Epoch: 0 [209088/620022]    Loss: 0.008838   Batch Acc: 82.81
[Train] Epoch: 0 [209152/620022]    Loss: 0.009845   Batch Acc: 75.00
[Train] Epoch: 0 [209216/620022]    Loss: 0.008783   Batch Acc: 75.00
[Train] Epoch: 0 [209280/620022]    Loss: 0.008799   Batch Acc: 78.12
[Train] Epoch: 0 [209344/620022]    Loss: 0.006195   Batch Acc: 87.50
[Train] Epoch: 0 [209408/620022]    Loss: 0.010769   Batch Acc: 71.88
[Train] Epoch: 0 [209472/620022]    Loss: 0.008050   Batch Acc: 78.12
[Train] Epoch: 0 [209536/620022]    Loss: 0.007873   Batch Acc: 84.38
[Train] Epoch: 0 [209600/620022]    Loss: 0.010864   Batch Acc: 71.88
[Train] Epoch: 0 [209664/620022]    Loss: 0.008283   Batch Acc: 84.38
[Train] Epoch: 0 [209728/620022]    Loss: 0.008632   Batch Acc: 82.81
[Train] Epoch: 0 [209792/620022]    Loss: 0.011023   Batch Acc: 76.56
[Train] Epoch: 0 [209856/620022]    Loss: 0.008302   Batch Acc: 81.25
[Train] Epoch: 0 [209920/620022]    Loss: 0.011554   Batch Acc: 62.50
[Train] Epoch: 0 [209984/620022]    Loss: 0.010345   Batch Acc: 64.06
[Train] Epoch: 0 [210048/620022]    Loss: 0.010801   Batch Acc: 71.88
[Train] Epoch: 0 [210112/620022]    Loss: 0.009241   Batch Acc: 73.44
[Train] Epoch: 0 [210176/620022]    Loss: 0.011770   Batch Acc: 68.75
[Train] Epoch: 0 [210240/620022]    Loss: 0.008740   Batch Acc: 79.69
[Train] Epoch: 0 [210304/620022]    Loss: 0.009344   Batch Acc: 76.56
[Train] Epoch: 0 [210368/620022]    Loss: 0.009925   Batch Acc: 76.56
[Train] Epoch: 0 [210432/620022]    Loss: 0.010139   Batch Acc: 71.88
[Train] Epoch: 0 [210496/620022]    Loss: 0.009999   Batch Acc: 76.56
[Train] Epoch: 0 [210560/620022]    Loss: 0.010066   Batch Acc: 79.69
[Train] Epoch: 0 [210624/620022]    Loss: 0.008805   Batch Acc: 73.44
[Train] Epoch: 0 [210688/620022]    Loss: 0.010836   Batch Acc: 70.31
[Train] Epoch: 0 [210752/620022]    Loss: 0.010768   Batch Acc: 67.19
[Train] Epoch: 0 [210816/620022]    Loss: 0.008448   Batch Acc: 76.56
[Train] Epoch: 0 [210880/620022]    Loss: 0.008165   Batch Acc: 78.12
[Train] Epoch: 0 [210944/620022]    Loss: 0.009551   Batch Acc: 75.00
[Train] Epoch: 0 [211008/620022]    Loss: 0.009399   Batch Acc: 71.88
[Train] Epoch: 0 [211072/620022]    Loss: 0.008881   Batch Acc: 78.12
[Train] Epoch: 0 [211136/620022]    Loss: 0.008693   Batch Acc: 75.00
[Train] Epoch: 0 [211200/620022]    Loss: 0.007279   Batch Acc: 84.38
[Train] Epoch: 0 [211264/620022]    Loss: 0.011587   Batch Acc: 73.44
[Train] Epoch: 0 [211328/620022]    Loss: 0.009723   Batch Acc: 71.88
[Train] Epoch: 0 [211392/620022]    Loss: 0.006902   Batch Acc: 84.38
[Train] Epoch: 0 [211456/620022]    Loss: 0.009307   Batch Acc: 75.00
[Train] Epoch: 0 [211520/620022]    Loss: 0.009529   Batch Acc: 75.00
[Train] Epoch: 0 [211584/620022]    Loss: 0.010710   Batch Acc: 78.12
[Train] Epoch: 0 [211648/620022]    Loss: 0.008539   Batch Acc: 76.56
[Train] Epoch: 0 [211712/620022]    Loss: 0.011043   Batch Acc: 70.31
[Train] Epoch: 0 [211776/620022]    Loss: 0.009599   Batch Acc: 73.44
[Train] Epoch: 0 [211840/620022]    Loss: 0.009128   Batch Acc: 78.12
[Train] Epoch: 0 [211904/620022]    Loss: 0.007991   Batch Acc: 82.81
[Train] Epoch: 0 [211968/620022]    Loss: 0.010094   Batch Acc: 75.00
[Train] Epoch: 0 [212032/620022]    Loss: 0.008274   Batch Acc: 75.00
[Train] Epoch: 0 [212096/620022]    Loss: 0.008628   Batch Acc: 71.88
[Train] Epoch: 0 [212160/620022]    Loss: 0.011984   Batch Acc: 70.31
[Train] Epoch: 0 [212224/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 0 [212288/620022]    Loss: 0.009265   Batch Acc: 76.56
[Train] Epoch: 0 [212352/620022]    Loss: 0.009724   Batch Acc: 75.00
[Train] Epoch: 0 [212416/620022]    Loss: 0.010666   Batch Acc: 70.31
[Train] Epoch: 0 [212480/620022]    Loss: 0.009237   Batch Acc: 75.00
[Train] Epoch: 0 [212544/620022]    Loss: 0.008416   Batch Acc: 87.50
[Train] Epoch: 0 [212608/620022]    Loss: 0.010561   Batch Acc: 75.00
[Train] Epoch: 0 [212672/620022]    Loss: 0.008133   Batch Acc: 82.81
[Train] Epoch: 0 [212736/620022]    Loss: 0.007205   Batch Acc: 85.94
[Train] Epoch: 0 [212800/620022]    Loss: 0.008659   Batch Acc: 75.00
[Train] Epoch: 0 [212864/620022]    Loss: 0.011115   Batch Acc: 65.62
[Train] Epoch: 0 [212928/620022]    Loss: 0.011184   Batch Acc: 71.88
[Train] Epoch: 0 [212992/620022]    Loss: 0.009945   Batch Acc: 73.44
[Train] Epoch: 0 [213056/620022]    Loss: 0.010553   Batch Acc: 64.06
[Train] Epoch: 0 [213120/620022]    Loss: 0.008134   Batch Acc: 78.12
[Train] Epoch: 0 [213184/620022]    Loss: 0.011378   Batch Acc: 70.31
[Train] Epoch: 0 [213248/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 0 [213312/620022]    Loss: 0.009385   Batch Acc: 73.44
[Train] Epoch: 0 [213376/620022]    Loss: 0.007894   Batch Acc: 85.94
[Train] Epoch: 0 [213440/620022]    Loss: 0.009525   Batch Acc: 75.00
[Train] Epoch: 0 [213504/620022]    Loss: 0.008327   Batch Acc: 79.69
[Train] Epoch: 0 [213568/620022]    Loss: 0.007621   Batch Acc: 87.50
[Train] Epoch: 0 [213632/620022]    Loss: 0.007579   Batch Acc: 82.81
[Train] Epoch: 0 [213696/620022]    Loss: 0.008211   Batch Acc: 84.38
[Train] Epoch: 0 [213760/620022]    Loss: 0.009590   Batch Acc: 76.56
[Train] Epoch: 0 [213824/620022]    Loss: 0.010663   Batch Acc: 73.44
[Train] Epoch: 0 [213888/620022]    Loss: 0.006965   Batch Acc: 87.50
[Train] Epoch: 0 [213952/620022]    Loss: 0.008902   Batch Acc: 75.00
[Train] Epoch: 0 [214016/620022]    Loss: 0.008705   Batch Acc: 84.38
[Train] Epoch: 0 [214080/620022]    Loss: 0.009025   Batch Acc: 76.56
[Train] Epoch: 0 [214144/620022]    Loss: 0.009854   Batch Acc: 73.44
[Train] Epoch: 0 [214208/620022]    Loss: 0.009409   Batch Acc: 76.56
[Train] Epoch: 0 [214272/620022]    Loss: 0.008199   Batch Acc: 79.69
[Train] Epoch: 0 [214336/620022]    Loss: 0.007594   Batch Acc: 87.50
[Train] Epoch: 0 [214400/620022]    Loss: 0.011591   Batch Acc: 67.19
[Train] Epoch: 0 [214464/620022]    Loss: 0.009739   Batch Acc: 75.00
[Train] Epoch: 0 [214528/620022]    Loss: 0.010421   Batch Acc: 78.12
[Train] Epoch: 0 [214592/620022]    Loss: 0.008894   Batch Acc: 76.56
[Train] Epoch: 0 [214656/620022]    Loss: 0.009869   Batch Acc: 73.44
[Train] Epoch: 0 [214720/620022]    Loss: 0.010824   Batch Acc: 78.12
[Train] Epoch: 0 [214784/620022]    Loss: 0.007724   Batch Acc: 81.25
[Train] Epoch: 0 [214848/620022]    Loss: 0.011670   Batch Acc: 73.44
[Train] Epoch: 0 [214912/620022]    Loss: 0.007301   Batch Acc: 78.12
[Train] Epoch: 0 [214976/620022]    Loss: 0.009799   Batch Acc: 73.44
[Train] Epoch: 0 [215040/620022]    Loss: 0.009204   Batch Acc: 76.56
[Train] Epoch: 0 [215104/620022]    Loss: 0.011227   Batch Acc: 70.31
[Train] Epoch: 0 [215168/620022]    Loss: 0.010187   Batch Acc: 76.56
[Train] Epoch: 0 [215232/620022]    Loss: 0.011324   Batch Acc: 70.31
[Train] Epoch: 0 [215296/620022]    Loss: 0.013496   Batch Acc: 62.50
[Train] Epoch: 0 [215360/620022]    Loss: 0.009965   Batch Acc: 73.44
[Train] Epoch: 0 [215424/620022]    Loss: 0.009649   Batch Acc: 76.56
[Train] Epoch: 0 [215488/620022]    Loss: 0.009788   Batch Acc: 73.44
[Train] Epoch: 0 [215552/620022]    Loss: 0.008423   Batch Acc: 81.25
[Train] Epoch: 0 [215616/620022]    Loss: 0.010852   Batch Acc: 70.31
[Train] Epoch: 0 [215680/620022]    Loss: 0.010105   Batch Acc: 73.44
[Train] Epoch: 0 [215744/620022]    Loss: 0.009060   Batch Acc: 78.12
[Train] Epoch: 0 [215808/620022]    Loss: 0.008320   Batch Acc: 79.69
[Train] Epoch: 0 [215872/620022]    Loss: 0.009139   Batch Acc: 71.88
[Train] Epoch: 0 [215936/620022]    Loss: 0.008934   Batch Acc: 75.00
[Train] Epoch: 0 [216000/620022]    Loss: 0.008918   Batch Acc: 78.12
[Train] Epoch: 0 [216064/620022]    Loss: 0.010093   Batch Acc: 70.31
[Train] Epoch: 0 [216128/620022]    Loss: 0.008914   Batch Acc: 78.12
[Train] Epoch: 0 [216192/620022]    Loss: 0.010890   Batch Acc: 68.75
[Train] Epoch: 0 [216256/620022]    Loss: 0.010341   Batch Acc: 73.44
[Train] Epoch: 0 [216320/620022]    Loss: 0.008397   Batch Acc: 76.56
[Train] Epoch: 0 [216384/620022]    Loss: 0.008705   Batch Acc: 76.56
[Train] Epoch: 0 [216448/620022]    Loss: 0.008961   Batch Acc: 78.12
[Train] Epoch: 0 [216512/620022]    Loss: 0.011724   Batch Acc: 67.19
[Train] Epoch: 0 [216576/620022]    Loss: 0.012276   Batch Acc: 65.62
[Train] Epoch: 0 [216640/620022]    Loss: 0.010197   Batch Acc: 76.56
[Train] Epoch: 0 [216704/620022]    Loss: 0.008582   Batch Acc: 75.00
[Train] Epoch: 0 [216768/620022]    Loss: 0.009838   Batch Acc: 78.12
[Train] Epoch: 0 [216832/620022]    Loss: 0.011366   Batch Acc: 65.62
[Train] Epoch: 0 [216896/620022]    Loss: 0.010274   Batch Acc: 70.31
[Train] Epoch: 0 [216960/620022]    Loss: 0.009501   Batch Acc: 68.75
[Train] Epoch: 0 [217024/620022]    Loss: 0.008586   Batch Acc: 78.12
[Train] Epoch: 0 [217088/620022]    Loss: 0.009752   Batch Acc: 70.31
[Train] Epoch: 0 [217152/620022]    Loss: 0.008238   Batch Acc: 84.38
[Train] Epoch: 0 [217216/620022]    Loss: 0.008051   Batch Acc: 76.56
[Train] Epoch: 0 [217280/620022]    Loss: 0.011163   Batch Acc: 68.75
[Train] Epoch: 0 [217344/620022]    Loss: 0.008731   Batch Acc: 82.81
[Train] Epoch: 0 [217408/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 0 [217472/620022]    Loss: 0.009258   Batch Acc: 81.25
[Train] Epoch: 0 [217536/620022]    Loss: 0.009019   Batch Acc: 79.69
[Train] Epoch: 0 [217600/620022]    Loss: 0.008145   Batch Acc: 79.69
[Train] Epoch: 0 [217664/620022]    Loss: 0.008336   Batch Acc: 78.12
[Train] Epoch: 0 [217728/620022]    Loss: 0.008928   Batch Acc: 75.00
[Train] Epoch: 0 [217792/620022]    Loss: 0.010720   Batch Acc: 68.75
[Train] Epoch: 0 [217856/620022]    Loss: 0.009702   Batch Acc: 73.44
[Train] Epoch: 0 [217920/620022]    Loss: 0.009509   Batch Acc: 73.44
[Train] Epoch: 0 [217984/620022]    Loss: 0.008358   Batch Acc: 81.25
[Train] Epoch: 0 [218048/620022]    Loss: 0.010565   Batch Acc: 71.88
[Train] Epoch: 0 [218112/620022]    Loss: 0.009528   Batch Acc: 75.00
[Train] Epoch: 0 [218176/620022]    Loss: 0.013346   Batch Acc: 62.50
[Train] Epoch: 0 [218240/620022]    Loss: 0.010322   Batch Acc: 75.00
[Train] Epoch: 0 [218304/620022]    Loss: 0.007646   Batch Acc: 85.94
[Train] Epoch: 0 [218368/620022]    Loss: 0.008802   Batch Acc: 73.44
[Train] Epoch: 0 [218432/620022]    Loss: 0.009049   Batch Acc: 75.00
[Train] Epoch: 0 [218496/620022]    Loss: 0.010353   Batch Acc: 75.00
[Train] Epoch: 0 [218560/620022]    Loss: 0.012512   Batch Acc: 62.50
[Train] Epoch: 0 [218624/620022]    Loss: 0.008641   Batch Acc: 75.00
[Train] Epoch: 0 [218688/620022]    Loss: 0.009866   Batch Acc: 68.75
[Train] Epoch: 0 [218752/620022]    Loss: 0.010500   Batch Acc: 68.75
[Train] Epoch: 0 [218816/620022]    Loss: 0.011019   Batch Acc: 60.94
[Train] Epoch: 0 [218880/620022]    Loss: 0.009712   Batch Acc: 78.12
[Train] Epoch: 0 [218944/620022]    Loss: 0.009236   Batch Acc: 78.12
[Train] Epoch: 0 [219008/620022]    Loss: 0.010056   Batch Acc: 73.44
[Train] Epoch: 0 [219072/620022]    Loss: 0.008120   Batch Acc: 78.12
[Train] Epoch: 0 [219136/620022]    Loss: 0.009802   Batch Acc: 75.00
[Train] Epoch: 0 [219200/620022]    Loss: 0.009424   Batch Acc: 79.69
[Train] Epoch: 0 [219264/620022]    Loss: 0.010928   Batch Acc: 71.88
[Train] Epoch: 0 [219328/620022]    Loss: 0.009175   Batch Acc: 81.25
[Train] Epoch: 0 [219392/620022]    Loss: 0.010110   Batch Acc: 70.31
[Train] Epoch: 0 [219456/620022]    Loss: 0.009873   Batch Acc: 81.25
[Train] Epoch: 0 [219520/620022]    Loss: 0.008399   Batch Acc: 79.69
[Train] Epoch: 0 [219584/620022]    Loss: 0.009684   Batch Acc: 73.44
[Train] Epoch: 0 [219648/620022]    Loss: 0.009077   Batch Acc: 73.44
[Train] Epoch: 0 [219712/620022]    Loss: 0.009296   Batch Acc: 78.12
[Train] Epoch: 0 [219776/620022]    Loss: 0.009574   Batch Acc: 81.25
[Train] Epoch: 0 [219840/620022]    Loss: 0.009903   Batch Acc: 76.56
[Train] Epoch: 0 [219904/620022]    Loss: 0.012579   Batch Acc: 62.50
[Train] Epoch: 0 [219968/620022]    Loss: 0.009198   Batch Acc: 78.12
[Train] Epoch: 0 [220032/620022]    Loss: 0.009245   Batch Acc: 76.56
[Train] Epoch: 0 [220096/620022]    Loss: 0.010055   Batch Acc: 76.56
[Train] Epoch: 0 [220160/620022]    Loss: 0.008321   Batch Acc: 79.69
[Train] Epoch: 0 [220224/620022]    Loss: 0.009864   Batch Acc: 73.44
[Train] Epoch: 0 [220288/620022]    Loss: 0.010644   Batch Acc: 70.31
[Train] Epoch: 0 [220352/620022]    Loss: 0.010551   Batch Acc: 65.62
[Train] Epoch: 0 [220416/620022]    Loss: 0.009500   Batch Acc: 71.88
[Train] Epoch: 0 [220480/620022]    Loss: 0.009277   Batch Acc: 76.56
[Train] Epoch: 0 [220544/620022]    Loss: 0.008708   Batch Acc: 76.56
[Train] Epoch: 0 [220608/620022]    Loss: 0.010652   Batch Acc: 70.31
[Train] Epoch: 0 [220672/620022]    Loss: 0.009385   Batch Acc: 81.25
[Train] Epoch: 0 [220736/620022]    Loss: 0.007452   Batch Acc: 82.81
[Train] Epoch: 0 [220800/620022]    Loss: 0.011160   Batch Acc: 70.31
[Train] Epoch: 0 [220864/620022]    Loss: 0.010123   Batch Acc: 71.88
[Train] Epoch: 0 [220928/620022]    Loss: 0.009798   Batch Acc: 73.44
[Train] Epoch: 0 [220992/620022]    Loss: 0.010076   Batch Acc: 71.88
[Train] Epoch: 0 [221056/620022]    Loss: 0.007797   Batch Acc: 82.81
[Train] Epoch: 0 [221120/620022]    Loss: 0.008877   Batch Acc: 79.69
[Train] Epoch: 0 [221184/620022]    Loss: 0.010964   Batch Acc: 70.31
[Train] Epoch: 0 [221248/620022]    Loss: 0.008659   Batch Acc: 81.25
[Train] Epoch: 0 [221312/620022]    Loss: 0.008994   Batch Acc: 73.44
[Train] Epoch: 0 [221376/620022]    Loss: 0.009965   Batch Acc: 70.31
[Train] Epoch: 0 [221440/620022]    Loss: 0.007094   Batch Acc: 81.25
[Train] Epoch: 0 [221504/620022]    Loss: 0.010075   Batch Acc: 65.62
[Train] Epoch: 0 [221568/620022]    Loss: 0.009560   Batch Acc: 64.06
[Train] Epoch: 0 [221632/620022]    Loss: 0.009083   Batch Acc: 79.69
[Train] Epoch: 0 [221696/620022]    Loss: 0.010477   Batch Acc: 67.19
[Train] Epoch: 0 [221760/620022]    Loss: 0.010183   Batch Acc: 65.62
[Train] Epoch: 0 [221824/620022]    Loss: 0.008658   Batch Acc: 78.12
[Train] Epoch: 0 [221888/620022]    Loss: 0.008967   Batch Acc: 76.56
[Train] Epoch: 0 [221952/620022]    Loss: 0.009985   Batch Acc: 73.44
[Train] Epoch: 0 [222016/620022]    Loss: 0.010024   Batch Acc: 70.31
[Train] Epoch: 0 [222080/620022]    Loss: 0.008270   Batch Acc: 84.38
[Train] Epoch: 0 [222144/620022]    Loss: 0.009803   Batch Acc: 76.56
[Train] Epoch: 0 [222208/620022]    Loss: 0.007833   Batch Acc: 84.38
[Train] Epoch: 0 [222272/620022]    Loss: 0.007700   Batch Acc: 85.94
[Train] Epoch: 0 [222336/620022]    Loss: 0.008747   Batch Acc: 78.12
[Train] Epoch: 0 [222400/620022]    Loss: 0.010061   Batch Acc: 70.31
[Train] Epoch: 0 [222464/620022]    Loss: 0.010553   Batch Acc: 71.88
[Train] Epoch: 0 [222528/620022]    Loss: 0.010370   Batch Acc: 68.75
[Train] Epoch: 0 [222592/620022]    Loss: 0.009596   Batch Acc: 73.44
[Train] Epoch: 0 [222656/620022]    Loss: 0.006787   Batch Acc: 85.94
[Train] Epoch: 0 [222720/620022]    Loss: 0.008610   Batch Acc: 73.44
[Train] Epoch: 0 [222784/620022]    Loss: 0.007691   Batch Acc: 75.00
[Train] Epoch: 0 [222848/620022]    Loss: 0.007702   Batch Acc: 85.94
[Train] Epoch: 0 [222912/620022]    Loss: 0.010915   Batch Acc: 70.31
[Train] Epoch: 0 [222976/620022]    Loss: 0.008384   Batch Acc: 73.44
[Train] Epoch: 0 [223040/620022]    Loss: 0.010267   Batch Acc: 75.00
[Train] Epoch: 0 [223104/620022]    Loss: 0.009119   Batch Acc: 76.56
[Train] Epoch: 0 [223168/620022]    Loss: 0.008466   Batch Acc: 78.12
[Train] Epoch: 0 [223232/620022]    Loss: 0.008207   Batch Acc: 81.25
[Train] Epoch: 0 [223296/620022]    Loss: 0.008858   Batch Acc: 75.00
[Train] Epoch: 0 [223360/620022]    Loss: 0.010877   Batch Acc: 73.44
[Train] Epoch: 0 [223424/620022]    Loss: 0.008556   Batch Acc: 75.00
[Train] Epoch: 0 [223488/620022]    Loss: 0.008422   Batch Acc: 75.00
[Train] Epoch: 0 [223552/620022]    Loss: 0.010091   Batch Acc: 75.00
[Train] Epoch: 0 [223616/620022]    Loss: 0.009871   Batch Acc: 76.56
[Train] Epoch: 0 [223680/620022]    Loss: 0.006263   Batch Acc: 85.94
[Train] Epoch: 0 [223744/620022]    Loss: 0.009263   Batch Acc: 76.56
[Train] Epoch: 0 [223808/620022]    Loss: 0.013781   Batch Acc: 59.38
[Train] Epoch: 0 [223872/620022]    Loss: 0.006606   Batch Acc: 84.38
[Train] Epoch: 0 [223936/620022]    Loss: 0.008773   Batch Acc: 82.81
[Train] Epoch: 0 [224000/620022]    Loss: 0.008346   Batch Acc: 79.69
[Train] Epoch: 0 [224064/620022]    Loss: 0.008393   Batch Acc: 76.56
[Train] Epoch: 0 [224128/620022]    Loss: 0.009239   Batch Acc: 75.00
[Train] Epoch: 0 [224192/620022]    Loss: 0.010743   Batch Acc: 71.88
[Train] Epoch: 0 [224256/620022]    Loss: 0.008468   Batch Acc: 78.12
[Train] Epoch: 0 [224320/620022]    Loss: 0.008709   Batch Acc: 76.56
[Train] Epoch: 0 [224384/620022]    Loss: 0.008881   Batch Acc: 79.69
[Train] Epoch: 0 [224448/620022]    Loss: 0.011330   Batch Acc: 64.06
[Train] Epoch: 0 [224512/620022]    Loss: 0.013095   Batch Acc: 71.88
[Train] Epoch: 0 [224576/620022]    Loss: 0.009647   Batch Acc: 71.88
[Train] Epoch: 0 [224640/620022]    Loss: 0.008456   Batch Acc: 79.69
[Train] Epoch: 0 [224704/620022]    Loss: 0.008372   Batch Acc: 76.56
[Train] Epoch: 0 [224768/620022]    Loss: 0.008242   Batch Acc: 81.25
[Train] Epoch: 0 [224832/620022]    Loss: 0.010336   Batch Acc: 76.56
[Train] Epoch: 0 [224896/620022]    Loss: 0.009867   Batch Acc: 76.56
[Train] Epoch: 0 [224960/620022]    Loss: 0.009790   Batch Acc: 78.12
[Train] Epoch: 0 [225024/620022]    Loss: 0.010087   Batch Acc: 68.75
[Train] Epoch: 0 [225088/620022]    Loss: 0.009676   Batch Acc: 78.12
[Train] Epoch: 0 [225152/620022]    Loss: 0.008048   Batch Acc: 84.38
[Train] Epoch: 0 [225216/620022]    Loss: 0.009340   Batch Acc: 78.12
[Train] Epoch: 0 [225280/620022]    Loss: 0.010817   Batch Acc: 71.88
[Train] Epoch: 0 [225344/620022]    Loss: 0.008285   Batch Acc: 84.38
[Train] Epoch: 0 [225408/620022]    Loss: 0.012287   Batch Acc: 65.62
[Train] Epoch: 0 [225472/620022]    Loss: 0.008831   Batch Acc: 76.56
[Train] Epoch: 0 [225536/620022]    Loss: 0.008064   Batch Acc: 79.69
[Train] Epoch: 0 [225600/620022]    Loss: 0.009722   Batch Acc: 75.00
[Train] Epoch: 0 [225664/620022]    Loss: 0.008196   Batch Acc: 78.12
[Train] Epoch: 0 [225728/620022]    Loss: 0.008958   Batch Acc: 70.31
[Train] Epoch: 0 [225792/620022]    Loss: 0.010298   Batch Acc: 70.31
[Train] Epoch: 0 [225856/620022]    Loss: 0.008523   Batch Acc: 79.69
[Train] Epoch: 0 [225920/620022]    Loss: 0.009536   Batch Acc: 75.00
[Train] Epoch: 0 [225984/620022]    Loss: 0.010720   Batch Acc: 73.44
[Train] Epoch: 0 [226048/620022]    Loss: 0.008342   Batch Acc: 79.69
[Train] Epoch: 0 [226112/620022]    Loss: 0.010884   Batch Acc: 67.19
[Train] Epoch: 0 [226176/620022]    Loss: 0.008084   Batch Acc: 81.25
[Train] Epoch: 0 [226240/620022]    Loss: 0.010351   Batch Acc: 67.19
[Train] Epoch: 0 [226304/620022]    Loss: 0.009568   Batch Acc: 79.69
[Train] Epoch: 0 [226368/620022]    Loss: 0.011778   Batch Acc: 71.88
[Train] Epoch: 0 [226432/620022]    Loss: 0.009640   Batch Acc: 76.56
[Train] Epoch: 0 [226496/620022]    Loss: 0.009047   Batch Acc: 81.25
[Train] Epoch: 0 [226560/620022]    Loss: 0.010055   Batch Acc: 78.12
[Train] Epoch: 0 [226624/620022]    Loss: 0.008589   Batch Acc: 78.12
[Train] Epoch: 0 [226688/620022]    Loss: 0.008215   Batch Acc: 76.56
[Train] Epoch: 0 [226752/620022]    Loss: 0.010732   Batch Acc: 73.44
[Train] Epoch: 0 [226816/620022]    Loss: 0.008273   Batch Acc: 81.25
[Train] Epoch: 0 [226880/620022]    Loss: 0.009267   Batch Acc: 70.31
[Train] Epoch: 0 [226944/620022]    Loss: 0.008427   Batch Acc: 78.12
[Train] Epoch: 0 [227008/620022]    Loss: 0.011416   Batch Acc: 70.31
[Train] Epoch: 0 [227072/620022]    Loss: 0.010261   Batch Acc: 67.19
[Train] Epoch: 0 [227136/620022]    Loss: 0.010486   Batch Acc: 67.19
[Train] Epoch: 0 [227200/620022]    Loss: 0.009382   Batch Acc: 68.75
[Train] Epoch: 0 [227264/620022]    Loss: 0.009194   Batch Acc: 79.69
[Train] Epoch: 0 [227328/620022]    Loss: 0.010240   Batch Acc: 71.88
[Train] Epoch: 0 [227392/620022]    Loss: 0.008088   Batch Acc: 81.25
[Train] Epoch: 0 [227456/620022]    Loss: 0.009247   Batch Acc: 75.00
[Train] Epoch: 0 [227520/620022]    Loss: 0.010031   Batch Acc: 73.44
[Train] Epoch: 0 [227584/620022]    Loss: 0.008000   Batch Acc: 85.94
[Train] Epoch: 0 [227648/620022]    Loss: 0.012553   Batch Acc: 70.31
[Train] Epoch: 0 [227712/620022]    Loss: 0.009387   Batch Acc: 78.12
[Train] Epoch: 0 [227776/620022]    Loss: 0.009971   Batch Acc: 76.56
[Train] Epoch: 0 [227840/620022]    Loss: 0.009468   Batch Acc: 73.44
[Train] Epoch: 0 [227904/620022]    Loss: 0.009189   Batch Acc: 75.00
[Train] Epoch: 0 [227968/620022]    Loss: 0.009889   Batch Acc: 79.69
[Train] Epoch: 0 [228032/620022]    Loss: 0.008458   Batch Acc: 79.69
[Train] Epoch: 0 [228096/620022]    Loss: 0.011109   Batch Acc: 75.00
[Train] Epoch: 0 [228160/620022]    Loss: 0.009085   Batch Acc: 76.56
[Train] Epoch: 0 [228224/620022]    Loss: 0.009485   Batch Acc: 75.00
[Train] Epoch: 0 [228288/620022]    Loss: 0.010194   Batch Acc: 76.56
[Train] Epoch: 0 [228352/620022]    Loss: 0.008839   Batch Acc: 79.69
[Train] Epoch: 0 [228416/620022]    Loss: 0.010135   Batch Acc: 78.12
[Train] Epoch: 0 [228480/620022]    Loss: 0.007801   Batch Acc: 84.38
[Train] Epoch: 0 [228544/620022]    Loss: 0.008299   Batch Acc: 75.00
[Train] Epoch: 0 [228608/620022]    Loss: 0.009030   Batch Acc: 76.56
[Train] Epoch: 0 [228672/620022]    Loss: 0.010067   Batch Acc: 70.31
[Train] Epoch: 0 [228736/620022]    Loss: 0.011183   Batch Acc: 68.75
[Train] Epoch: 0 [228800/620022]    Loss: 0.008290   Batch Acc: 75.00
[Train] Epoch: 0 [228864/620022]    Loss: 0.007472   Batch Acc: 78.12
[Train] Epoch: 0 [228928/620022]    Loss: 0.007279   Batch Acc: 87.50
[Train] Epoch: 0 [228992/620022]    Loss: 0.009854   Batch Acc: 76.56
[Train] Epoch: 0 [229056/620022]    Loss: 0.012168   Batch Acc: 67.19
[Train] Epoch: 0 [229120/620022]    Loss: 0.008282   Batch Acc: 78.12
[Train] Epoch: 0 [229184/620022]    Loss: 0.009755   Batch Acc: 75.00
[Train] Epoch: 0 [229248/620022]    Loss: 0.012472   Batch Acc: 67.19
[Train] Epoch: 0 [229312/620022]    Loss: 0.009719   Batch Acc: 71.88
[Train] Epoch: 0 [229376/620022]    Loss: 0.008166   Batch Acc: 79.69
[Train] Epoch: 0 [229440/620022]    Loss: 0.010663   Batch Acc: 73.44
[Train] Epoch: 0 [229504/620022]    Loss: 0.007349   Batch Acc: 81.25
[Train] Epoch: 0 [229568/620022]    Loss: 0.008994   Batch Acc: 81.25
[Train] Epoch: 0 [229632/620022]    Loss: 0.010927   Batch Acc: 71.88
[Train] Epoch: 0 [229696/620022]    Loss: 0.010764   Batch Acc: 67.19
[Train] Epoch: 0 [229760/620022]    Loss: 0.010998   Batch Acc: 70.31
[Train] Epoch: 0 [229824/620022]    Loss: 0.011661   Batch Acc: 67.19
[Train] Epoch: 0 [229888/620022]    Loss: 0.010539   Batch Acc: 71.88
[Train] Epoch: 0 [229952/620022]    Loss: 0.009911   Batch Acc: 71.88
[Train] Epoch: 0 [230016/620022]    Loss: 0.009663   Batch Acc: 71.88
[Train] Epoch: 0 [230080/620022]    Loss: 0.008069   Batch Acc: 81.25
[Train] Epoch: 0 [230144/620022]    Loss: 0.009259   Batch Acc: 82.81
[Train] Epoch: 0 [230208/620022]    Loss: 0.012178   Batch Acc: 70.31
[Train] Epoch: 0 [230272/620022]    Loss: 0.011073   Batch Acc: 78.12
[Train] Epoch: 0 [230336/620022]    Loss: 0.008313   Batch Acc: 76.56
[Train] Epoch: 0 [230400/620022]    Loss: 0.010481   Batch Acc: 71.88
[Train] Epoch: 0 [230464/620022]    Loss: 0.009602   Batch Acc: 76.56
[Train] Epoch: 0 [230528/620022]    Loss: 0.011304   Batch Acc: 68.75
[Train] Epoch: 0 [230592/620022]    Loss: 0.007358   Batch Acc: 84.38
[Train] Epoch: 0 [230656/620022]    Loss: 0.011754   Batch Acc: 67.19
[Train] Epoch: 0 [230720/620022]    Loss: 0.007912   Batch Acc: 81.25
[Train] Epoch: 0 [230784/620022]    Loss: 0.009517   Batch Acc: 78.12
[Train] Epoch: 0 [230848/620022]    Loss: 0.009582   Batch Acc: 79.69
[Train] Epoch: 0 [230912/620022]    Loss: 0.010072   Batch Acc: 71.88
[Train] Epoch: 0 [230976/620022]    Loss: 0.008939   Batch Acc: 73.44
[Train] Epoch: 0 [231040/620022]    Loss: 0.009365   Batch Acc: 73.44
[Train] Epoch: 0 [231104/620022]    Loss: 0.008844   Batch Acc: 75.00
[Train] Epoch: 0 [231168/620022]    Loss: 0.008895   Batch Acc: 78.12
[Train] Epoch: 0 [231232/620022]    Loss: 0.009654   Batch Acc: 71.88
[Train] Epoch: 0 [231296/620022]    Loss: 0.008636   Batch Acc: 76.56
[Train] Epoch: 0 [231360/620022]    Loss: 0.007934   Batch Acc: 78.12
[Train] Epoch: 0 [231424/620022]    Loss: 0.009275   Batch Acc: 78.12
[Train] Epoch: 0 [231488/620022]    Loss: 0.009562   Batch Acc: 78.12
[Train] Epoch: 0 [231552/620022]    Loss: 0.009727   Batch Acc: 76.56
[Train] Epoch: 0 [231616/620022]    Loss: 0.010647   Batch Acc: 70.31
[Train] Epoch: 0 [231680/620022]    Loss: 0.008390   Batch Acc: 81.25
[Train] Epoch: 0 [231744/620022]    Loss: 0.006979   Batch Acc: 84.38
[Train] Epoch: 0 [231808/620022]    Loss: 0.009655   Batch Acc: 75.00
[Train] Epoch: 0 [231872/620022]    Loss: 0.009332   Batch Acc: 79.69
[Train] Epoch: 0 [231936/620022]    Loss: 0.009818   Batch Acc: 75.00
[Train] Epoch: 0 [232000/620022]    Loss: 0.009630   Batch Acc: 68.75
[Train] Epoch: 0 [232064/620022]    Loss: 0.008381   Batch Acc: 78.12
[Train] Epoch: 0 [232128/620022]    Loss: 0.010364   Batch Acc: 68.75
[Train] Epoch: 0 [232192/620022]    Loss: 0.011263   Batch Acc: 68.75
[Train] Epoch: 0 [232256/620022]    Loss: 0.009478   Batch Acc: 78.12
[Train] Epoch: 0 [232320/620022]    Loss: 0.008867   Batch Acc: 76.56
[Train] Epoch: 0 [232384/620022]    Loss: 0.008425   Batch Acc: 78.12
[Train] Epoch: 0 [232448/620022]    Loss: 0.012349   Batch Acc: 68.75
[Train] Epoch: 0 [232512/620022]    Loss: 0.011176   Batch Acc: 76.56
[Train] Epoch: 0 [232576/620022]    Loss: 0.009114   Batch Acc: 82.81
[Train] Epoch: 0 [232640/620022]    Loss: 0.010148   Batch Acc: 73.44
[Train] Epoch: 0 [232704/620022]    Loss: 0.010023   Batch Acc: 75.00
[Train] Epoch: 0 [232768/620022]    Loss: 0.008694   Batch Acc: 79.69
[Train] Epoch: 0 [232832/620022]    Loss: 0.009080   Batch Acc: 78.12
[Train] Epoch: 0 [232896/620022]    Loss: 0.009046   Batch Acc: 78.12
[Train] Epoch: 0 [232960/620022]    Loss: 0.010379   Batch Acc: 70.31
[Train] Epoch: 0 [233024/620022]    Loss: 0.010881   Batch Acc: 65.62
[Train] Epoch: 0 [233088/620022]    Loss: 0.007216   Batch Acc: 82.81
[Train] Epoch: 0 [233152/620022]    Loss: 0.010825   Batch Acc: 71.88
[Train] Epoch: 0 [233216/620022]    Loss: 0.009935   Batch Acc: 75.00
[Train] Epoch: 0 [233280/620022]    Loss: 0.008671   Batch Acc: 76.56
[Train] Epoch: 0 [233344/620022]    Loss: 0.010869   Batch Acc: 78.12
[Train] Epoch: 0 [233408/620022]    Loss: 0.009813   Batch Acc: 71.88
[Train] Epoch: 0 [233472/620022]    Loss: 0.010451   Batch Acc: 71.88
[Train] Epoch: 0 [233536/620022]    Loss: 0.010011   Batch Acc: 70.31
[Train] Epoch: 0 [233600/620022]    Loss: 0.010304   Batch Acc: 65.62
[Train] Epoch: 0 [233664/620022]    Loss: 0.007231   Batch Acc: 84.38
[Train] Epoch: 0 [233728/620022]    Loss: 0.009452   Batch Acc: 76.56
[Train] Epoch: 0 [233792/620022]    Loss: 0.009412   Batch Acc: 73.44
[Train] Epoch: 0 [233856/620022]    Loss: 0.006917   Batch Acc: 85.94
[Train] Epoch: 0 [233920/620022]    Loss: 0.008518   Batch Acc: 78.12
[Train] Epoch: 0 [233984/620022]    Loss: 0.010100   Batch Acc: 71.88
[Train] Epoch: 0 [234048/620022]    Loss: 0.010187   Batch Acc: 70.31
[Train] Epoch: 0 [234112/620022]    Loss: 0.009380   Batch Acc: 73.44
[Train] Epoch: 0 [234176/620022]    Loss: 0.007880   Batch Acc: 79.69
[Train] Epoch: 0 [234240/620022]    Loss: 0.008303   Batch Acc: 78.12
[Train] Epoch: 0 [234304/620022]    Loss: 0.007229   Batch Acc: 85.94
[Train] Epoch: 0 [234368/620022]    Loss: 0.010384   Batch Acc: 70.31
[Train] Epoch: 0 [234432/620022]    Loss: 0.009899   Batch Acc: 75.00
[Train] Epoch: 0 [234496/620022]    Loss: 0.011815   Batch Acc: 73.44
[Train] Epoch: 0 [234560/620022]    Loss: 0.009837   Batch Acc: 68.75
[Train] Epoch: 0 [234624/620022]    Loss: 0.011061   Batch Acc: 65.62
[Train] Epoch: 0 [234688/620022]    Loss: 0.010693   Batch Acc: 70.31
[Train] Epoch: 0 [234752/620022]    Loss: 0.009076   Batch Acc: 75.00
[Train] Epoch: 0 [234816/620022]    Loss: 0.010085   Batch Acc: 79.69
[Train] Epoch: 0 [234880/620022]    Loss: 0.010209   Batch Acc: 75.00
[Train] Epoch: 0 [234944/620022]    Loss: 0.008490   Batch Acc: 82.81
[Train] Epoch: 0 [235008/620022]    Loss: 0.010011   Batch Acc: 70.31
[Train] Epoch: 0 [235072/620022]    Loss: 0.008849   Batch Acc: 78.12
[Train] Epoch: 0 [235136/620022]    Loss: 0.012546   Batch Acc: 65.62
[Train] Epoch: 0 [235200/620022]    Loss: 0.010499   Batch Acc: 73.44
[Train] Epoch: 0 [235264/620022]    Loss: 0.007645   Batch Acc: 78.12
[Train] Epoch: 0 [235328/620022]    Loss: 0.011093   Batch Acc: 71.88
[Train] Epoch: 0 [235392/620022]    Loss: 0.007689   Batch Acc: 78.12
[Train] Epoch: 0 [235456/620022]    Loss: 0.009711   Batch Acc: 73.44
[Train] Epoch: 0 [235520/620022]    Loss: 0.009055   Batch Acc: 71.88
[Train] Epoch: 0 [235584/620022]    Loss: 0.009304   Batch Acc: 73.44
[Train] Epoch: 0 [235648/620022]    Loss: 0.008534   Batch Acc: 82.81
[Train] Epoch: 0 [235712/620022]    Loss: 0.008865   Batch Acc: 73.44
[Train] Epoch: 0 [235776/620022]    Loss: 0.009466   Batch Acc: 75.00
[Train] Epoch: 0 [235840/620022]    Loss: 0.009096   Batch Acc: 73.44
[Train] Epoch: 0 [235904/620022]    Loss: 0.008720   Batch Acc: 78.12
[Train] Epoch: 0 [235968/620022]    Loss: 0.010926   Batch Acc: 68.75
[Train] Epoch: 0 [236032/620022]    Loss: 0.010044   Batch Acc: 73.44
[Train] Epoch: 0 [236096/620022]    Loss: 0.008617   Batch Acc: 81.25
[Train] Epoch: 0 [236160/620022]    Loss: 0.009163   Batch Acc: 73.44
[Train] Epoch: 0 [236224/620022]    Loss: 0.007225   Batch Acc: 82.81
[Train] Epoch: 0 [236288/620022]    Loss: 0.009658   Batch Acc: 73.44
[Train] Epoch: 0 [236352/620022]    Loss: 0.008704   Batch Acc: 76.56
[Train] Epoch: 0 [236416/620022]    Loss: 0.009929   Batch Acc: 67.19
[Train] Epoch: 0 [236480/620022]    Loss: 0.009147   Batch Acc: 73.44
[Train] Epoch: 0 [236544/620022]    Loss: 0.009748   Batch Acc: 76.56
[Train] Epoch: 0 [236608/620022]    Loss: 0.009868   Batch Acc: 79.69
[Train] Epoch: 0 [236672/620022]    Loss: 0.008971   Batch Acc: 79.69
[Train] Epoch: 0 [236736/620022]    Loss: 0.009818   Batch Acc: 75.00
[Train] Epoch: 0 [236800/620022]    Loss: 0.010624   Batch Acc: 71.88
[Train] Epoch: 0 [236864/620022]    Loss: 0.009591   Batch Acc: 76.56
[Train] Epoch: 0 [236928/620022]    Loss: 0.008698   Batch Acc: 82.81
[Train] Epoch: 0 [236992/620022]    Loss: 0.008065   Batch Acc: 84.38
[Train] Epoch: 0 [237056/620022]    Loss: 0.007716   Batch Acc: 84.38
[Train] Epoch: 0 [237120/620022]    Loss: 0.010276   Batch Acc: 73.44
[Train] Epoch: 0 [237184/620022]    Loss: 0.008813   Batch Acc: 78.12
[Train] Epoch: 0 [237248/620022]    Loss: 0.009552   Batch Acc: 79.69
[Train] Epoch: 0 [237312/620022]    Loss: 0.008939   Batch Acc: 75.00
[Train] Epoch: 0 [237376/620022]    Loss: 0.010250   Batch Acc: 73.44
[Train] Epoch: 0 [237440/620022]    Loss: 0.009466   Batch Acc: 70.31
[Train] Epoch: 0 [237504/620022]    Loss: 0.010721   Batch Acc: 76.56
[Train] Epoch: 0 [237568/620022]    Loss: 0.007210   Batch Acc: 85.94
[Train] Epoch: 0 [237632/620022]    Loss: 0.008229   Batch Acc: 78.12
[Train] Epoch: 0 [237696/620022]    Loss: 0.008789   Batch Acc: 76.56
[Train] Epoch: 0 [237760/620022]    Loss: 0.009578   Batch Acc: 75.00
[Train] Epoch: 0 [237824/620022]    Loss: 0.010618   Batch Acc: 70.31
[Train] Epoch: 0 [237888/620022]    Loss: 0.007755   Batch Acc: 81.25
[Train] Epoch: 0 [237952/620022]    Loss: 0.007577   Batch Acc: 81.25
[Train] Epoch: 0 [238016/620022]    Loss: 0.009524   Batch Acc: 81.25
[Train] Epoch: 0 [238080/620022]    Loss: 0.009539   Batch Acc: 76.56
[Train] Epoch: 0 [238144/620022]    Loss: 0.008903   Batch Acc: 76.56
[Train] Epoch: 0 [238208/620022]    Loss: 0.009208   Batch Acc: 71.88
[Train] Epoch: 0 [238272/620022]    Loss: 0.011077   Batch Acc: 71.88
[Train] Epoch: 0 [238336/620022]    Loss: 0.009597   Batch Acc: 76.56
[Train] Epoch: 0 [238400/620022]    Loss: 0.008861   Batch Acc: 78.12
[Train] Epoch: 0 [238464/620022]    Loss: 0.012059   Batch Acc: 60.94
[Train] Epoch: 0 [238528/620022]    Loss: 0.008594   Batch Acc: 81.25
[Train] Epoch: 0 [238592/620022]    Loss: 0.009562   Batch Acc: 79.69
[Train] Epoch: 0 [238656/620022]    Loss: 0.008935   Batch Acc: 76.56
[Train] Epoch: 0 [238720/620022]    Loss: 0.007908   Batch Acc: 79.69
[Train] Epoch: 0 [238784/620022]    Loss: 0.007708   Batch Acc: 79.69
[Train] Epoch: 0 [238848/620022]    Loss: 0.007448   Batch Acc: 79.69
[Train] Epoch: 0 [238912/620022]    Loss: 0.010101   Batch Acc: 73.44
[Train] Epoch: 0 [238976/620022]    Loss: 0.010183   Batch Acc: 78.12
[Train] Epoch: 0 [239040/620022]    Loss: 0.009820   Batch Acc: 71.88
[Train] Epoch: 0 [239104/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 0 [239168/620022]    Loss: 0.007966   Batch Acc: 81.25
[Train] Epoch: 0 [239232/620022]    Loss: 0.008757   Batch Acc: 79.69
[Train] Epoch: 0 [239296/620022]    Loss: 0.010500   Batch Acc: 68.75
[Train] Epoch: 0 [239360/620022]    Loss: 0.010182   Batch Acc: 70.31
[Train] Epoch: 0 [239424/620022]    Loss: 0.008608   Batch Acc: 76.56
[Train] Epoch: 0 [239488/620022]    Loss: 0.012261   Batch Acc: 68.75
[Train] Epoch: 0 [239552/620022]    Loss: 0.009127   Batch Acc: 76.56
[Train] Epoch: 0 [239616/620022]    Loss: 0.010534   Batch Acc: 76.56
[Train] Epoch: 0 [239680/620022]    Loss: 0.013459   Batch Acc: 64.06
[Train] Epoch: 0 [239744/620022]    Loss: 0.010159   Batch Acc: 71.88
[Train] Epoch: 0 [239808/620022]    Loss: 0.009240   Batch Acc: 76.56
[Train] Epoch: 0 [239872/620022]    Loss: 0.012874   Batch Acc: 67.19
[Train] Epoch: 0 [239936/620022]    Loss: 0.009098   Batch Acc: 71.88
[Train] Epoch: 0 [240000/620022]    Loss: 0.008025   Batch Acc: 81.25
[Train] Epoch: 0 [240064/620022]    Loss: 0.010516   Batch Acc: 73.44
[Train] Epoch: 0 [240128/620022]    Loss: 0.010187   Batch Acc: 76.56
[Train] Epoch: 0 [240192/620022]    Loss: 0.009251   Batch Acc: 78.12
[Train] Epoch: 0 [240256/620022]    Loss: 0.008674   Batch Acc: 75.00
[Train] Epoch: 0 [240320/620022]    Loss: 0.007665   Batch Acc: 82.81
[Train] Epoch: 0 [240384/620022]    Loss: 0.008755   Batch Acc: 73.44
[Train] Epoch: 0 [240448/620022]    Loss: 0.009371   Batch Acc: 78.12
[Train] Epoch: 0 [240512/620022]    Loss: 0.007633   Batch Acc: 76.56
[Train] Epoch: 0 [240576/620022]    Loss: 0.009320   Batch Acc: 71.88
[Train] Epoch: 0 [240640/620022]    Loss: 0.008895   Batch Acc: 78.12
[Train] Epoch: 0 [240704/620022]    Loss: 0.009538   Batch Acc: 75.00
[Train] Epoch: 0 [240768/620022]    Loss: 0.009161   Batch Acc: 78.12
[Train] Epoch: 0 [240832/620022]    Loss: 0.009414   Batch Acc: 73.44
[Train] Epoch: 0 [240896/620022]    Loss: 0.007467   Batch Acc: 81.25
[Train] Epoch: 0 [240960/620022]    Loss: 0.008931   Batch Acc: 73.44
[Train] Epoch: 0 [241024/620022]    Loss: 0.008242   Batch Acc: 79.69
[Train] Epoch: 0 [241088/620022]    Loss: 0.010005   Batch Acc: 71.88
[Train] Epoch: 0 [241152/620022]    Loss: 0.009960   Batch Acc: 75.00
[Train] Epoch: 0 [241216/620022]    Loss: 0.011319   Batch Acc: 59.38
[Train] Epoch: 0 [241280/620022]    Loss: 0.008701   Batch Acc: 79.69
[Train] Epoch: 0 [241344/620022]    Loss: 0.010554   Batch Acc: 73.44
[Train] Epoch: 0 [241408/620022]    Loss: 0.010557   Batch Acc: 75.00
[Train] Epoch: 0 [241472/620022]    Loss: 0.009839   Batch Acc: 79.69
[Train] Epoch: 0 [241536/620022]    Loss: 0.008807   Batch Acc: 81.25
[Train] Epoch: 0 [241600/620022]    Loss: 0.009827   Batch Acc: 76.56
[Train] Epoch: 0 [241664/620022]    Loss: 0.009231   Batch Acc: 71.88
[Train] Epoch: 0 [241728/620022]    Loss: 0.008159   Batch Acc: 82.81
[Train] Epoch: 0 [241792/620022]    Loss: 0.009467   Batch Acc: 76.56
[Train] Epoch: 0 [241856/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 0 [241920/620022]    Loss: 0.011184   Batch Acc: 68.75
[Train] Epoch: 0 [241984/620022]    Loss: 0.009621   Batch Acc: 75.00
[Train] Epoch: 0 [242048/620022]    Loss: 0.009006   Batch Acc: 79.69
[Train] Epoch: 0 [242112/620022]    Loss: 0.012454   Batch Acc: 75.00
[Train] Epoch: 0 [242176/620022]    Loss: 0.011514   Batch Acc: 68.75
[Train] Epoch: 0 [242240/620022]    Loss: 0.008861   Batch Acc: 76.56
[Train] Epoch: 0 [242304/620022]    Loss: 0.010023   Batch Acc: 68.75
[Train] Epoch: 0 [242368/620022]    Loss: 0.010048   Batch Acc: 68.75
[Train] Epoch: 0 [242432/620022]    Loss: 0.008852   Batch Acc: 78.12
[Train] Epoch: 0 [242496/620022]    Loss: 0.009448   Batch Acc: 68.75
[Train] Epoch: 0 [242560/620022]    Loss: 0.010726   Batch Acc: 79.69
[Train] Epoch: 0 [242624/620022]    Loss: 0.008563   Batch Acc: 76.56
[Train] Epoch: 0 [242688/620022]    Loss: 0.010881   Batch Acc: 75.00
[Train] Epoch: 0 [242752/620022]    Loss: 0.007603   Batch Acc: 84.38
[Train] Epoch: 0 [242816/620022]    Loss: 0.011801   Batch Acc: 67.19
[Train] Epoch: 0 [242880/620022]    Loss: 0.008634   Batch Acc: 75.00
[Train] Epoch: 0 [242944/620022]    Loss: 0.009956   Batch Acc: 73.44
[Train] Epoch: 0 [243008/620022]    Loss: 0.010465   Batch Acc: 75.00
[Train] Epoch: 0 [243072/620022]    Loss: 0.009518   Batch Acc: 78.12
[Train] Epoch: 0 [243136/620022]    Loss: 0.009439   Batch Acc: 75.00
[Train] Epoch: 0 [243200/620022]    Loss: 0.010075   Batch Acc: 76.56
[Train] Epoch: 0 [243264/620022]    Loss: 0.008358   Batch Acc: 82.81
[Train] Epoch: 0 [243328/620022]    Loss: 0.009645   Batch Acc: 75.00
[Train] Epoch: 0 [243392/620022]    Loss: 0.009517   Batch Acc: 75.00
[Train] Epoch: 0 [243456/620022]    Loss: 0.011193   Batch Acc: 68.75
[Train] Epoch: 0 [243520/620022]    Loss: 0.009632   Batch Acc: 73.44
[Train] Epoch: 0 [243584/620022]    Loss: 0.010262   Batch Acc: 71.88
[Train] Epoch: 0 [243648/620022]    Loss: 0.008914   Batch Acc: 78.12
[Train] Epoch: 0 [243712/620022]    Loss: 0.009362   Batch Acc: 78.12
[Train] Epoch: 0 [243776/620022]    Loss: 0.008908   Batch Acc: 73.44
[Train] Epoch: 0 [243840/620022]    Loss: 0.008638   Batch Acc: 81.25
[Train] Epoch: 0 [243904/620022]    Loss: 0.008176   Batch Acc: 75.00
[Train] Epoch: 0 [243968/620022]    Loss: 0.010990   Batch Acc: 71.88
[Train] Epoch: 0 [244032/620022]    Loss: 0.009538   Batch Acc: 75.00
[Train] Epoch: 0 [244096/620022]    Loss: 0.010373   Batch Acc: 73.44
[Train] Epoch: 0 [244160/620022]    Loss: 0.009037   Batch Acc: 73.44
[Train] Epoch: 0 [244224/620022]    Loss: 0.007222   Batch Acc: 85.94
[Train] Epoch: 0 [244288/620022]    Loss: 0.011691   Batch Acc: 64.06
[Train] Epoch: 0 [244352/620022]    Loss: 0.009329   Batch Acc: 79.69
[Train] Epoch: 0 [244416/620022]    Loss: 0.009959   Batch Acc: 70.31
[Train] Epoch: 0 [244480/620022]    Loss: 0.008718   Batch Acc: 76.56
[Train] Epoch: 0 [244544/620022]    Loss: 0.010222   Batch Acc: 78.12
[Train] Epoch: 0 [244608/620022]    Loss: 0.010425   Batch Acc: 76.56
[Train] Epoch: 0 [244672/620022]    Loss: 0.009339   Batch Acc: 81.25
[Train] Epoch: 0 [244736/620022]    Loss: 0.011269   Batch Acc: 67.19
[Train] Epoch: 0 [244800/620022]    Loss: 0.009055   Batch Acc: 76.56
[Train] Epoch: 0 [244864/620022]    Loss: 0.010738   Batch Acc: 70.31
[Train] Epoch: 0 [244928/620022]    Loss: 0.011421   Batch Acc: 73.44
[Train] Epoch: 0 [244992/620022]    Loss: 0.009659   Batch Acc: 78.12
[Train] Epoch: 0 [245056/620022]    Loss: 0.010472   Batch Acc: 70.31
[Train] Epoch: 0 [245120/620022]    Loss: 0.009469   Batch Acc: 68.75
[Train] Epoch: 0 [245184/620022]    Loss: 0.010616   Batch Acc: 70.31
[Train] Epoch: 0 [245248/620022]    Loss: 0.009744   Batch Acc: 75.00
[Train] Epoch: 0 [245312/620022]    Loss: 0.008984   Batch Acc: 81.25
[Train] Epoch: 0 [245376/620022]    Loss: 0.009799   Batch Acc: 71.88
[Train] Epoch: 0 [245440/620022]    Loss: 0.008322   Batch Acc: 79.69
[Train] Epoch: 0 [245504/620022]    Loss: 0.011665   Batch Acc: 71.88
[Train] Epoch: 0 [245568/620022]    Loss: 0.009020   Batch Acc: 76.56
[Train] Epoch: 0 [245632/620022]    Loss: 0.011627   Batch Acc: 75.00
[Train] Epoch: 0 [245696/620022]    Loss: 0.012129   Batch Acc: 67.19
[Train] Epoch: 0 [245760/620022]    Loss: 0.012139   Batch Acc: 65.62
[Train] Epoch: 0 [245824/620022]    Loss: 0.010787   Batch Acc: 73.44
[Train] Epoch: 0 [245888/620022]    Loss: 0.008371   Batch Acc: 81.25
[Train] Epoch: 0 [245952/620022]    Loss: 0.008307   Batch Acc: 75.00
[Train] Epoch: 0 [246016/620022]    Loss: 0.010945   Batch Acc: 73.44
[Train] Epoch: 0 [246080/620022]    Loss: 0.009781   Batch Acc: 70.31
[Train] Epoch: 0 [246144/620022]    Loss: 0.010142   Batch Acc: 68.75
[Train] Epoch: 0 [246208/620022]    Loss: 0.008950   Batch Acc: 79.69
[Train] Epoch: 0 [246272/620022]    Loss: 0.010403   Batch Acc: 67.19
[Train] Epoch: 0 [246336/620022]    Loss: 0.009365   Batch Acc: 78.12
[Train] Epoch: 0 [246400/620022]    Loss: 0.008516   Batch Acc: 82.81
[Train] Epoch: 0 [246464/620022]    Loss: 0.010484   Batch Acc: 70.31
[Train] Epoch: 0 [246528/620022]    Loss: 0.011587   Batch Acc: 65.62
[Train] Epoch: 0 [246592/620022]    Loss: 0.009216   Batch Acc: 79.69
[Train] Epoch: 0 [246656/620022]    Loss: 0.012785   Batch Acc: 64.06
[Train] Epoch: 0 [246720/620022]    Loss: 0.009199   Batch Acc: 81.25
[Train] Epoch: 0 [246784/620022]    Loss: 0.008592   Batch Acc: 79.69
[Train] Epoch: 0 [246848/620022]    Loss: 0.009746   Batch Acc: 76.56
[Train] Epoch: 0 [246912/620022]    Loss: 0.008329   Batch Acc: 76.56
[Train] Epoch: 0 [246976/620022]    Loss: 0.009164   Batch Acc: 75.00
[Train] Epoch: 0 [247040/620022]    Loss: 0.009795   Batch Acc: 78.12
[Train] Epoch: 0 [247104/620022]    Loss: 0.009280   Batch Acc: 75.00
[Train] Epoch: 0 [247168/620022]    Loss: 0.009558   Batch Acc: 81.25
[Train] Epoch: 0 [247232/620022]    Loss: 0.011419   Batch Acc: 71.88
[Train] Epoch: 0 [247296/620022]    Loss: 0.007470   Batch Acc: 76.56
[Train] Epoch: 0 [247360/620022]    Loss: 0.008624   Batch Acc: 78.12
[Train] Epoch: 0 [247424/620022]    Loss: 0.009689   Batch Acc: 70.31
[Train] Epoch: 0 [247488/620022]    Loss: 0.009643   Batch Acc: 75.00
[Train] Epoch: 0 [247552/620022]    Loss: 0.011215   Batch Acc: 64.06
[Train] Epoch: 0 [247616/620022]    Loss: 0.008012   Batch Acc: 81.25
[Train] Epoch: 0 [247680/620022]    Loss: 0.010336   Batch Acc: 70.31
[Train] Epoch: 0 [247744/620022]    Loss: 0.009072   Batch Acc: 84.38
[Train] Epoch: 0 [247808/620022]    Loss: 0.009889   Batch Acc: 71.88
[Train] Epoch: 0 [247872/620022]    Loss: 0.009059   Batch Acc: 79.69
[Train] Epoch: 0 [247936/620022]    Loss: 0.010189   Batch Acc: 73.44
[Train] Epoch: 0 [248000/620022]    Loss: 0.008426   Batch Acc: 84.38
[Train] Epoch: 0 [248064/620022]    Loss: 0.010055   Batch Acc: 70.31
[Train] Epoch: 0 [248128/620022]    Loss: 0.008422   Batch Acc: 79.69
[Train] Epoch: 0 [248192/620022]    Loss: 0.007526   Batch Acc: 84.38
[Train] Epoch: 0 [248256/620022]    Loss: 0.007957   Batch Acc: 81.25
[Train] Epoch: 0 [248320/620022]    Loss: 0.009182   Batch Acc: 75.00
[Train] Epoch: 0 [248384/620022]    Loss: 0.007176   Batch Acc: 81.25
[Train] Epoch: 0 [248448/620022]    Loss: 0.012120   Batch Acc: 67.19
[Train] Epoch: 0 [248512/620022]    Loss: 0.006222   Batch Acc: 85.94
[Train] Epoch: 0 [248576/620022]    Loss: 0.008834   Batch Acc: 76.56
[Train] Epoch: 0 [248640/620022]    Loss: 0.007355   Batch Acc: 81.25
[Train] Epoch: 0 [248704/620022]    Loss: 0.013438   Batch Acc: 60.94
[Train] Epoch: 0 [248768/620022]    Loss: 0.010233   Batch Acc: 65.62
[Train] Epoch: 0 [248832/620022]    Loss: 0.009585   Batch Acc: 71.88
[Train] Epoch: 0 [248896/620022]    Loss: 0.009698   Batch Acc: 75.00
[Train] Epoch: 0 [248960/620022]    Loss: 0.008367   Batch Acc: 78.12
[Train] Epoch: 0 [249024/620022]    Loss: 0.009003   Batch Acc: 71.88
[Train] Epoch: 0 [249088/620022]    Loss: 0.009803   Batch Acc: 68.75
[Train] Epoch: 0 [249152/620022]    Loss: 0.008752   Batch Acc: 76.56
[Train] Epoch: 0 [249216/620022]    Loss: 0.006808   Batch Acc: 84.38
[Train] Epoch: 0 [249280/620022]    Loss: 0.008765   Batch Acc: 73.44
[Train] Epoch: 0 [249344/620022]    Loss: 0.007835   Batch Acc: 78.12
[Train] Epoch: 0 [249408/620022]    Loss: 0.009812   Batch Acc: 76.56
[Train] Epoch: 0 [249472/620022]    Loss: 0.007963   Batch Acc: 81.25
[Train] Epoch: 0 [249536/620022]    Loss: 0.011322   Batch Acc: 65.62
[Train] Epoch: 0 [249600/620022]    Loss: 0.007840   Batch Acc: 81.25
[Train] Epoch: 0 [249664/620022]    Loss: 0.009456   Batch Acc: 78.12
[Train] Epoch: 0 [249728/620022]    Loss: 0.011181   Batch Acc: 70.31
[Train] Epoch: 0 [249792/620022]    Loss: 0.008771   Batch Acc: 76.56
[Train] Epoch: 0 [249856/620022]    Loss: 0.009023   Batch Acc: 84.38
[Train] Epoch: 0 [249920/620022]    Loss: 0.006933   Batch Acc: 84.38
[Train] Epoch: 0 [249984/620022]    Loss: 0.009161   Batch Acc: 73.44
[Train] Epoch: 0 [250048/620022]    Loss: 0.007575   Batch Acc: 81.25
[Train] Epoch: 0 [250112/620022]    Loss: 0.008924   Batch Acc: 76.56
[Train] Epoch: 0 [250176/620022]    Loss: 0.008701   Batch Acc: 79.69
[Train] Epoch: 0 [250240/620022]    Loss: 0.009626   Batch Acc: 78.12
[Train] Epoch: 0 [250304/620022]    Loss: 0.012856   Batch Acc: 62.50
[Train] Epoch: 0 [250368/620022]    Loss: 0.011010   Batch Acc: 71.88
[Train] Epoch: 0 [250432/620022]    Loss: 0.010458   Batch Acc: 68.75
[Train] Epoch: 0 [250496/620022]    Loss: 0.007826   Batch Acc: 81.25
[Train] Epoch: 0 [250560/620022]    Loss: 0.011056   Batch Acc: 71.88
[Train] Epoch: 0 [250624/620022]    Loss: 0.011689   Batch Acc: 67.19
[Train] Epoch: 0 [250688/620022]    Loss: 0.009291   Batch Acc: 73.44
[Train] Epoch: 0 [250752/620022]    Loss: 0.008632   Batch Acc: 75.00
[Train] Epoch: 0 [250816/620022]    Loss: 0.009074   Batch Acc: 76.56
[Train] Epoch: 0 [250880/620022]    Loss: 0.009279   Batch Acc: 82.81
[Train] Epoch: 0 [250944/620022]    Loss: 0.007818   Batch Acc: 79.69
[Train] Epoch: 0 [251008/620022]    Loss: 0.010474   Batch Acc: 73.44
[Train] Epoch: 0 [251072/620022]    Loss: 0.009720   Batch Acc: 76.56
[Train] Epoch: 0 [251136/620022]    Loss: 0.010112   Batch Acc: 73.44
[Train] Epoch: 0 [251200/620022]    Loss: 0.007172   Batch Acc: 85.94
[Train] Epoch: 0 [251264/620022]    Loss: 0.009415   Batch Acc: 76.56
[Train] Epoch: 0 [251328/620022]    Loss: 0.009165   Batch Acc: 73.44
[Train] Epoch: 0 [251392/620022]    Loss: 0.009008   Batch Acc: 75.00
[Train] Epoch: 0 [251456/620022]    Loss: 0.012042   Batch Acc: 67.19
[Train] Epoch: 0 [251520/620022]    Loss: 0.008182   Batch Acc: 78.12
[Train] Epoch: 0 [251584/620022]    Loss: 0.008619   Batch Acc: 81.25
[Train] Epoch: 0 [251648/620022]    Loss: 0.010020   Batch Acc: 70.31
[Train] Epoch: 0 [251712/620022]    Loss: 0.008497   Batch Acc: 75.00
[Train] Epoch: 0 [251776/620022]    Loss: 0.008690   Batch Acc: 79.69
[Train] Epoch: 0 [251840/620022]    Loss: 0.009177   Batch Acc: 71.88
[Train] Epoch: 0 [251904/620022]    Loss: 0.008508   Batch Acc: 82.81
[Train] Epoch: 0 [251968/620022]    Loss: 0.009439   Batch Acc: 79.69
[Train] Epoch: 0 [252032/620022]    Loss: 0.009442   Batch Acc: 76.56
[Train] Epoch: 0 [252096/620022]    Loss: 0.009382   Batch Acc: 79.69
[Train] Epoch: 0 [252160/620022]    Loss: 0.010264   Batch Acc: 73.44
[Train] Epoch: 0 [252224/620022]    Loss: 0.008672   Batch Acc: 78.12
[Train] Epoch: 0 [252288/620022]    Loss: 0.011020   Batch Acc: 67.19
[Train] Epoch: 0 [252352/620022]    Loss: 0.008114   Batch Acc: 78.12
[Train] Epoch: 0 [252416/620022]    Loss: 0.010470   Batch Acc: 70.31
[Train] Epoch: 0 [252480/620022]    Loss: 0.008016   Batch Acc: 84.38
[Train] Epoch: 0 [252544/620022]    Loss: 0.008825   Batch Acc: 78.12
[Train] Epoch: 0 [252608/620022]    Loss: 0.010274   Batch Acc: 73.44
[Train] Epoch: 0 [252672/620022]    Loss: 0.011107   Batch Acc: 73.44
[Train] Epoch: 0 [252736/620022]    Loss: 0.010651   Batch Acc: 70.31
[Train] Epoch: 0 [252800/620022]    Loss: 0.010208   Batch Acc: 71.88
[Train] Epoch: 0 [252864/620022]    Loss: 0.007551   Batch Acc: 81.25
[Train] Epoch: 0 [252928/620022]    Loss: 0.010371   Batch Acc: 71.88
[Train] Epoch: 0 [252992/620022]    Loss: 0.010592   Batch Acc: 73.44
[Train] Epoch: 0 [253056/620022]    Loss: 0.009051   Batch Acc: 68.75
[Train] Epoch: 0 [253120/620022]    Loss: 0.008190   Batch Acc: 79.69
[Train] Epoch: 0 [253184/620022]    Loss: 0.008880   Batch Acc: 76.56
[Train] Epoch: 0 [253248/620022]    Loss: 0.008184   Batch Acc: 81.25
[Train] Epoch: 0 [253312/620022]    Loss: 0.010836   Batch Acc: 75.00
[Train] Epoch: 0 [253376/620022]    Loss: 0.008530   Batch Acc: 79.69
[Train] Epoch: 0 [253440/620022]    Loss: 0.010953   Batch Acc: 68.75
[Train] Epoch: 0 [253504/620022]    Loss: 0.010044   Batch Acc: 73.44
[Train] Epoch: 0 [253568/620022]    Loss: 0.009416   Batch Acc: 75.00
[Train] Epoch: 0 [253632/620022]    Loss: 0.011172   Batch Acc: 67.19
[Train] Epoch: 0 [253696/620022]    Loss: 0.008215   Batch Acc: 79.69
[Train] Epoch: 0 [253760/620022]    Loss: 0.008583   Batch Acc: 78.12
[Train] Epoch: 0 [253824/620022]    Loss: 0.008542   Batch Acc: 78.12
[Train] Epoch: 0 [253888/620022]    Loss: 0.010349   Batch Acc: 76.56
[Train] Epoch: 0 [253952/620022]    Loss: 0.010354   Batch Acc: 71.88
[Train] Epoch: 0 [254016/620022]    Loss: 0.008720   Batch Acc: 81.25
[Train] Epoch: 0 [254080/620022]    Loss: 0.008816   Batch Acc: 76.56
[Train] Epoch: 0 [254144/620022]    Loss: 0.010780   Batch Acc: 71.88
[Train] Epoch: 0 [254208/620022]    Loss: 0.008116   Batch Acc: 81.25
[Train] Epoch: 0 [254272/620022]    Loss: 0.009284   Batch Acc: 76.56
[Train] Epoch: 0 [254336/620022]    Loss: 0.007778   Batch Acc: 78.12
[Train] Epoch: 0 [254400/620022]    Loss: 0.010421   Batch Acc: 76.56
[Train] Epoch: 0 [254464/620022]    Loss: 0.007436   Batch Acc: 82.81
[Train] Epoch: 0 [254528/620022]    Loss: 0.008267   Batch Acc: 71.88
[Train] Epoch: 0 [254592/620022]    Loss: 0.007873   Batch Acc: 78.12
[Train] Epoch: 0 [254656/620022]    Loss: 0.009426   Batch Acc: 81.25
[Train] Epoch: 0 [254720/620022]    Loss: 0.010033   Batch Acc: 76.56
[Train] Epoch: 0 [254784/620022]    Loss: 0.009437   Batch Acc: 75.00
[Train] Epoch: 0 [254848/620022]    Loss: 0.007382   Batch Acc: 81.25
[Train] Epoch: 0 [254912/620022]    Loss: 0.008620   Batch Acc: 79.69
[Train] Epoch: 0 [254976/620022]    Loss: 0.008985   Batch Acc: 76.56
[Train] Epoch: 0 [255040/620022]    Loss: 0.007877   Batch Acc: 81.25
[Train] Epoch: 0 [255104/620022]    Loss: 0.010101   Batch Acc: 73.44
[Train] Epoch: 0 [255168/620022]    Loss: 0.010148   Batch Acc: 75.00
[Train] Epoch: 0 [255232/620022]    Loss: 0.009286   Batch Acc: 81.25
[Train] Epoch: 0 [255296/620022]    Loss: 0.009522   Batch Acc: 75.00
[Train] Epoch: 0 [255360/620022]    Loss: 0.010480   Batch Acc: 81.25
[Train] Epoch: 0 [255424/620022]    Loss: 0.008752   Batch Acc: 79.69
[Train] Epoch: 0 [255488/620022]    Loss: 0.005829   Batch Acc: 90.62
[Train] Epoch: 0 [255552/620022]    Loss: 0.008972   Batch Acc: 81.25
[Train] Epoch: 0 [255616/620022]    Loss: 0.008849   Batch Acc: 76.56
[Train] Epoch: 0 [255680/620022]    Loss: 0.009625   Batch Acc: 76.56
[Train] Epoch: 0 [255744/620022]    Loss: 0.009673   Batch Acc: 79.69
[Train] Epoch: 0 [255808/620022]    Loss: 0.009471   Batch Acc: 76.56
[Train] Epoch: 0 [255872/620022]    Loss: 0.008520   Batch Acc: 85.94
[Train] Epoch: 0 [255936/620022]    Loss: 0.009739   Batch Acc: 79.69
[Train] Epoch: 0 [256000/620022]    Loss: 0.009337   Batch Acc: 76.56
[Train] Epoch: 0 [256064/620022]    Loss: 0.011725   Batch Acc: 67.19
[Train] Epoch: 0 [256128/620022]    Loss: 0.010958   Batch Acc: 73.44
[Train] Epoch: 0 [256192/620022]    Loss: 0.009061   Batch Acc: 73.44
[Train] Epoch: 0 [256256/620022]    Loss: 0.010559   Batch Acc: 70.31
[Train] Epoch: 0 [256320/620022]    Loss: 0.009829   Batch Acc: 71.88
[Train] Epoch: 0 [256384/620022]    Loss: 0.007745   Batch Acc: 82.81
[Train] Epoch: 0 [256448/620022]    Loss: 0.009744   Batch Acc: 71.88
[Train] Epoch: 0 [256512/620022]    Loss: 0.009699   Batch Acc: 71.88
[Train] Epoch: 0 [256576/620022]    Loss: 0.007587   Batch Acc: 85.94
[Train] Epoch: 0 [256640/620022]    Loss: 0.010261   Batch Acc: 67.19
[Train] Epoch: 0 [256704/620022]    Loss: 0.009820   Batch Acc: 78.12
[Train] Epoch: 0 [256768/620022]    Loss: 0.009652   Batch Acc: 73.44
[Train] Epoch: 0 [256832/620022]    Loss: 0.008561   Batch Acc: 78.12
[Train] Epoch: 0 [256896/620022]    Loss: 0.008665   Batch Acc: 78.12
[Train] Epoch: 0 [256960/620022]    Loss: 0.008532   Batch Acc: 81.25
[Train] Epoch: 0 [257024/620022]    Loss: 0.012728   Batch Acc: 64.06
[Train] Epoch: 0 [257088/620022]    Loss: 0.008697   Batch Acc: 79.69
[Train] Epoch: 0 [257152/620022]    Loss: 0.008734   Batch Acc: 79.69
[Train] Epoch: 0 [257216/620022]    Loss: 0.011291   Batch Acc: 60.94
[Train] Epoch: 0 [257280/620022]    Loss: 0.011024   Batch Acc: 68.75
[Train] Epoch: 0 [257344/620022]    Loss: 0.009551   Batch Acc: 73.44
[Train] Epoch: 0 [257408/620022]    Loss: 0.007332   Batch Acc: 87.50
[Train] Epoch: 0 [257472/620022]    Loss: 0.008816   Batch Acc: 75.00
[Train] Epoch: 0 [257536/620022]    Loss: 0.010786   Batch Acc: 70.31
[Train] Epoch: 0 [257600/620022]    Loss: 0.009870   Batch Acc: 76.56
[Train] Epoch: 0 [257664/620022]    Loss: 0.010028   Batch Acc: 68.75
[Train] Epoch: 0 [257728/620022]    Loss: 0.009869   Batch Acc: 71.88
[Train] Epoch: 0 [257792/620022]    Loss: 0.009359   Batch Acc: 78.12
[Train] Epoch: 0 [257856/620022]    Loss: 0.008155   Batch Acc: 78.12
[Train] Epoch: 0 [257920/620022]    Loss: 0.009347   Batch Acc: 76.56
[Train] Epoch: 0 [257984/620022]    Loss: 0.008763   Batch Acc: 81.25
[Train] Epoch: 0 [258048/620022]    Loss: 0.009985   Batch Acc: 68.75
[Train] Epoch: 0 [258112/620022]    Loss: 0.009145   Batch Acc: 78.12
[Train] Epoch: 0 [258176/620022]    Loss: 0.010188   Batch Acc: 78.12
[Train] Epoch: 0 [258240/620022]    Loss: 0.008210   Batch Acc: 84.38
[Train] Epoch: 0 [258304/620022]    Loss: 0.010521   Batch Acc: 75.00
[Train] Epoch: 0 [258368/620022]    Loss: 0.009095   Batch Acc: 78.12
[Train] Epoch: 0 [258432/620022]    Loss: 0.010815   Batch Acc: 71.88
[Train] Epoch: 0 [258496/620022]    Loss: 0.010980   Batch Acc: 78.12
[Train] Epoch: 0 [258560/620022]    Loss: 0.010437   Batch Acc: 73.44
[Train] Epoch: 0 [258624/620022]    Loss: 0.009963   Batch Acc: 68.75
[Train] Epoch: 0 [258688/620022]    Loss: 0.007350   Batch Acc: 81.25
[Train] Epoch: 0 [258752/620022]    Loss: 0.010183   Batch Acc: 71.88
[Train] Epoch: 0 [258816/620022]    Loss: 0.008975   Batch Acc: 73.44
[Train] Epoch: 0 [258880/620022]    Loss: 0.009492   Batch Acc: 76.56
[Train] Epoch: 0 [258944/620022]    Loss: 0.010620   Batch Acc: 76.56
[Train] Epoch: 0 [259008/620022]    Loss: 0.010329   Batch Acc: 75.00
[Train] Epoch: 0 [259072/620022]    Loss: 0.007874   Batch Acc: 81.25
[Train] Epoch: 0 [259136/620022]    Loss: 0.008955   Batch Acc: 78.12
[Train] Epoch: 0 [259200/620022]    Loss: 0.011830   Batch Acc: 68.75
[Train] Epoch: 0 [259264/620022]    Loss: 0.010245   Batch Acc: 73.44
[Train] Epoch: 0 [259328/620022]    Loss: 0.009365   Batch Acc: 75.00
[Train] Epoch: 0 [259392/620022]    Loss: 0.007916   Batch Acc: 82.81
[Train] Epoch: 0 [259456/620022]    Loss: 0.009373   Batch Acc: 81.25
[Train] Epoch: 0 [259520/620022]    Loss: 0.010593   Batch Acc: 64.06
[Train] Epoch: 0 [259584/620022]    Loss: 0.009087   Batch Acc: 75.00
[Train] Epoch: 0 [259648/620022]    Loss: 0.009331   Batch Acc: 70.31
[Train] Epoch: 0 [259712/620022]    Loss: 0.006438   Batch Acc: 87.50
[Train] Epoch: 0 [259776/620022]    Loss: 0.008214   Batch Acc: 76.56
[Train] Epoch: 0 [259840/620022]    Loss: 0.010279   Batch Acc: 71.88
[Train] Epoch: 0 [259904/620022]    Loss: 0.007835   Batch Acc: 82.81
[Train] Epoch: 0 [259968/620022]    Loss: 0.007403   Batch Acc: 81.25
[Train] Epoch: 0 [260032/620022]    Loss: 0.007996   Batch Acc: 76.56
[Train] Epoch: 0 [260096/620022]    Loss: 0.010743   Batch Acc: 75.00
[Train] Epoch: 0 [260160/620022]    Loss: 0.006910   Batch Acc: 84.38
[Train] Epoch: 0 [260224/620022]    Loss: 0.008313   Batch Acc: 75.00
[Train] Epoch: 0 [260288/620022]    Loss: 0.008624   Batch Acc: 82.81
[Train] Epoch: 0 [260352/620022]    Loss: 0.008441   Batch Acc: 79.69
[Train] Epoch: 0 [260416/620022]    Loss: 0.011656   Batch Acc: 71.88
[Train] Epoch: 0 [260480/620022]    Loss: 0.009003   Batch Acc: 87.50
[Train] Epoch: 0 [260544/620022]    Loss: 0.007730   Batch Acc: 78.12
[Train] Epoch: 0 [260608/620022]    Loss: 0.008457   Batch Acc: 82.81
[Train] Epoch: 0 [260672/620022]    Loss: 0.008663   Batch Acc: 78.12
[Train] Epoch: 0 [260736/620022]    Loss: 0.009735   Batch Acc: 75.00
[Train] Epoch: 0 [260800/620022]    Loss: 0.009539   Batch Acc: 71.88
[Train] Epoch: 0 [260864/620022]    Loss: 0.007060   Batch Acc: 85.94
[Train] Epoch: 0 [260928/620022]    Loss: 0.009177   Batch Acc: 76.56
[Train] Epoch: 0 [260992/620022]    Loss: 0.007665   Batch Acc: 79.69
[Train] Epoch: 0 [261056/620022]    Loss: 0.009625   Batch Acc: 76.56
[Train] Epoch: 0 [261120/620022]    Loss: 0.009545   Batch Acc: 75.00
[Train] Epoch: 0 [261184/620022]    Loss: 0.009659   Batch Acc: 73.44
[Train] Epoch: 0 [261248/620022]    Loss: 0.009460   Batch Acc: 76.56
[Train] Epoch: 0 [261312/620022]    Loss: 0.009219   Batch Acc: 73.44
[Train] Epoch: 0 [261376/620022]    Loss: 0.008395   Batch Acc: 78.12
[Train] Epoch: 0 [261440/620022]    Loss: 0.006757   Batch Acc: 89.06
[Train] Epoch: 0 [261504/620022]    Loss: 0.008542   Batch Acc: 81.25
[Train] Epoch: 0 [261568/620022]    Loss: 0.009441   Batch Acc: 76.56
[Train] Epoch: 0 [261632/620022]    Loss: 0.011085   Batch Acc: 64.06
[Train] Epoch: 0 [261696/620022]    Loss: 0.009505   Batch Acc: 78.12
[Train] Epoch: 0 [261760/620022]    Loss: 0.010195   Batch Acc: 70.31
[Train] Epoch: 0 [261824/620022]    Loss: 0.006916   Batch Acc: 84.38
[Train] Epoch: 0 [261888/620022]    Loss: 0.011226   Batch Acc: 71.88
[Train] Epoch: 0 [261952/620022]    Loss: 0.009089   Batch Acc: 85.94
[Train] Epoch: 0 [262016/620022]    Loss: 0.008181   Batch Acc: 84.38
[Train] Epoch: 0 [262080/620022]    Loss: 0.008460   Batch Acc: 79.69
[Train] Epoch: 0 [262144/620022]    Loss: 0.008610   Batch Acc: 75.00
[Train] Epoch: 0 [262208/620022]    Loss: 0.010899   Batch Acc: 71.88
[Train] Epoch: 0 [262272/620022]    Loss: 0.009569   Batch Acc: 76.56
[Train] Epoch: 0 [262336/620022]    Loss: 0.007870   Batch Acc: 79.69
[Train] Epoch: 0 [262400/620022]    Loss: 0.010583   Batch Acc: 71.88
[Train] Epoch: 0 [262464/620022]    Loss: 0.009237   Batch Acc: 76.56
[Train] Epoch: 0 [262528/620022]    Loss: 0.010566   Batch Acc: 73.44
[Train] Epoch: 0 [262592/620022]    Loss: 0.007013   Batch Acc: 84.38
[Train] Epoch: 0 [262656/620022]    Loss: 0.007411   Batch Acc: 82.81
[Train] Epoch: 0 [262720/620022]    Loss: 0.009433   Batch Acc: 75.00
[Train] Epoch: 0 [262784/620022]    Loss: 0.010646   Batch Acc: 76.56
[Train] Epoch: 0 [262848/620022]    Loss: 0.009318   Batch Acc: 78.12
[Train] Epoch: 0 [262912/620022]    Loss: 0.008417   Batch Acc: 78.12
[Train] Epoch: 0 [262976/620022]    Loss: 0.009843   Batch Acc: 75.00
[Train] Epoch: 0 [263040/620022]    Loss: 0.008859   Batch Acc: 82.81
[Train] Epoch: 0 [263104/620022]    Loss: 0.012361   Batch Acc: 68.75
[Train] Epoch: 0 [263168/620022]    Loss: 0.010109   Batch Acc: 70.31
[Train] Epoch: 0 [263232/620022]    Loss: 0.010554   Batch Acc: 67.19
[Train] Epoch: 0 [263296/620022]    Loss: 0.010044   Batch Acc: 71.88
[Train] Epoch: 0 [263360/620022]    Loss: 0.009108   Batch Acc: 82.81
[Train] Epoch: 0 [263424/620022]    Loss: 0.008810   Batch Acc: 81.25
[Train] Epoch: 0 [263488/620022]    Loss: 0.009886   Batch Acc: 70.31
[Train] Epoch: 0 [263552/620022]    Loss: 0.010066   Batch Acc: 75.00
[Train] Epoch: 0 [263616/620022]    Loss: 0.009190   Batch Acc: 73.44
[Train] Epoch: 0 [263680/620022]    Loss: 0.009359   Batch Acc: 76.56
[Train] Epoch: 0 [263744/620022]    Loss: 0.010592   Batch Acc: 71.88
[Train] Epoch: 0 [263808/620022]    Loss: 0.008790   Batch Acc: 75.00
[Train] Epoch: 0 [263872/620022]    Loss: 0.010046   Batch Acc: 75.00
[Train] Epoch: 0 [263936/620022]    Loss: 0.007696   Batch Acc: 78.12
[Train] Epoch: 0 [264000/620022]    Loss: 0.010138   Batch Acc: 73.44
[Train] Epoch: 0 [264064/620022]    Loss: 0.009368   Batch Acc: 76.56
[Train] Epoch: 0 [264128/620022]    Loss: 0.009979   Batch Acc: 76.56
[Train] Epoch: 0 [264192/620022]    Loss: 0.010994   Batch Acc: 70.31
[Train] Epoch: 0 [264256/620022]    Loss: 0.008123   Batch Acc: 82.81
[Train] Epoch: 0 [264320/620022]    Loss: 0.009201   Batch Acc: 76.56
[Train] Epoch: 0 [264384/620022]    Loss: 0.009767   Batch Acc: 78.12
[Train] Epoch: 0 [264448/620022]    Loss: 0.008237   Batch Acc: 79.69
[Train] Epoch: 0 [264512/620022]    Loss: 0.010348   Batch Acc: 70.31
[Train] Epoch: 0 [264576/620022]    Loss: 0.010748   Batch Acc: 65.62
[Train] Epoch: 0 [264640/620022]    Loss: 0.008826   Batch Acc: 78.12
[Train] Epoch: 0 [264704/620022]    Loss: 0.008501   Batch Acc: 76.56
[Train] Epoch: 0 [264768/620022]    Loss: 0.009308   Batch Acc: 75.00
[Train] Epoch: 0 [264832/620022]    Loss: 0.008287   Batch Acc: 76.56
[Train] Epoch: 0 [264896/620022]    Loss: 0.009892   Batch Acc: 70.31
[Train] Epoch: 0 [264960/620022]    Loss: 0.008650   Batch Acc: 76.56
[Train] Epoch: 0 [265024/620022]    Loss: 0.010472   Batch Acc: 67.19
[Train] Epoch: 0 [265088/620022]    Loss: 0.008676   Batch Acc: 78.12
[Train] Epoch: 0 [265152/620022]    Loss: 0.010800   Batch Acc: 67.19
[Train] Epoch: 0 [265216/620022]    Loss: 0.009181   Batch Acc: 82.81
[Train] Epoch: 0 [265280/620022]    Loss: 0.007108   Batch Acc: 81.25
[Train] Epoch: 0 [265344/620022]    Loss: 0.009631   Batch Acc: 79.69
[Train] Epoch: 0 [265408/620022]    Loss: 0.011333   Batch Acc: 73.44
[Train] Epoch: 0 [265472/620022]    Loss: 0.010472   Batch Acc: 60.94
[Train] Epoch: 0 [265536/620022]    Loss: 0.009561   Batch Acc: 68.75
[Train] Epoch: 0 [265600/620022]    Loss: 0.008507   Batch Acc: 79.69
[Train] Epoch: 0 [265664/620022]    Loss: 0.006590   Batch Acc: 87.50
[Train] Epoch: 0 [265728/620022]    Loss: 0.008717   Batch Acc: 73.44
[Train] Epoch: 0 [265792/620022]    Loss: 0.011250   Batch Acc: 70.31
[Train] Epoch: 0 [265856/620022]    Loss: 0.008738   Batch Acc: 76.56
[Train] Epoch: 0 [265920/620022]    Loss: 0.008660   Batch Acc: 75.00
[Train] Epoch: 0 [265984/620022]    Loss: 0.008280   Batch Acc: 84.38
[Train] Epoch: 0 [266048/620022]    Loss: 0.007364   Batch Acc: 84.38
[Train] Epoch: 0 [266112/620022]    Loss: 0.008207   Batch Acc: 75.00
[Train] Epoch: 0 [266176/620022]    Loss: 0.007379   Batch Acc: 79.69
[Train] Epoch: 0 [266240/620022]    Loss: 0.010001   Batch Acc: 76.56
[Train] Epoch: 0 [266304/620022]    Loss: 0.008813   Batch Acc: 76.56
[Train] Epoch: 0 [266368/620022]    Loss: 0.008075   Batch Acc: 79.69
[Train] Epoch: 0 [266432/620022]    Loss: 0.009013   Batch Acc: 76.56
[Train] Epoch: 0 [266496/620022]    Loss: 0.009539   Batch Acc: 81.25
[Train] Epoch: 0 [266560/620022]    Loss: 0.009120   Batch Acc: 76.56
[Train] Epoch: 0 [266624/620022]    Loss: 0.009669   Batch Acc: 76.56
[Train] Epoch: 0 [266688/620022]    Loss: 0.009751   Batch Acc: 73.44
[Train] Epoch: 0 [266752/620022]    Loss: 0.008937   Batch Acc: 75.00
[Train] Epoch: 0 [266816/620022]    Loss: 0.009338   Batch Acc: 76.56
[Train] Epoch: 0 [266880/620022]    Loss: 0.007763   Batch Acc: 81.25
[Train] Epoch: 0 [266944/620022]    Loss: 0.011507   Batch Acc: 65.62
[Train] Epoch: 0 [267008/620022]    Loss: 0.007701   Batch Acc: 82.81
[Train] Epoch: 0 [267072/620022]    Loss: 0.007865   Batch Acc: 84.38
[Train] Epoch: 0 [267136/620022]    Loss: 0.009997   Batch Acc: 76.56
[Train] Epoch: 0 [267200/620022]    Loss: 0.010449   Batch Acc: 73.44
[Train] Epoch: 0 [267264/620022]    Loss: 0.008601   Batch Acc: 78.12
[Train] Epoch: 0 [267328/620022]    Loss: 0.008128   Batch Acc: 82.81
[Train] Epoch: 0 [267392/620022]    Loss: 0.009384   Batch Acc: 76.56
[Train] Epoch: 0 [267456/620022]    Loss: 0.007625   Batch Acc: 81.25
[Train] Epoch: 0 [267520/620022]    Loss: 0.008878   Batch Acc: 70.31
[Train] Epoch: 0 [267584/620022]    Loss: 0.008927   Batch Acc: 75.00
[Train] Epoch: 0 [267648/620022]    Loss: 0.009282   Batch Acc: 82.81
[Train] Epoch: 0 [267712/620022]    Loss: 0.009445   Batch Acc: 76.56
[Train] Epoch: 0 [267776/620022]    Loss: 0.010607   Batch Acc: 73.44
[Train] Epoch: 0 [267840/620022]    Loss: 0.010113   Batch Acc: 75.00
[Train] Epoch: 0 [267904/620022]    Loss: 0.009187   Batch Acc: 75.00
[Train] Epoch: 0 [267968/620022]    Loss: 0.009513   Batch Acc: 71.88
[Train] Epoch: 0 [268032/620022]    Loss: 0.007600   Batch Acc: 85.94
[Train] Epoch: 0 [268096/620022]    Loss: 0.009289   Batch Acc: 75.00
[Train] Epoch: 0 [268160/620022]    Loss: 0.010052   Batch Acc: 71.88
[Train] Epoch: 0 [268224/620022]    Loss: 0.009028   Batch Acc: 78.12
[Train] Epoch: 0 [268288/620022]    Loss: 0.013366   Batch Acc: 64.06
[Train] Epoch: 0 [268352/620022]    Loss: 0.011533   Batch Acc: 71.88
[Train] Epoch: 0 [268416/620022]    Loss: 0.008138   Batch Acc: 81.25
[Train] Epoch: 0 [268480/620022]    Loss: 0.008607   Batch Acc: 84.38
[Train] Epoch: 0 [268544/620022]    Loss: 0.011520   Batch Acc: 73.44
[Train] Epoch: 0 [268608/620022]    Loss: 0.011560   Batch Acc: 68.75
[Train] Epoch: 0 [268672/620022]    Loss: 0.007939   Batch Acc: 84.38
[Train] Epoch: 0 [268736/620022]    Loss: 0.011504   Batch Acc: 67.19
[Train] Epoch: 0 [268800/620022]    Loss: 0.010886   Batch Acc: 71.88
[Train] Epoch: 0 [268864/620022]    Loss: 0.010510   Batch Acc: 64.06
[Train] Epoch: 0 [268928/620022]    Loss: 0.009107   Batch Acc: 73.44
[Train] Epoch: 0 [268992/620022]    Loss: 0.009541   Batch Acc: 73.44
[Train] Epoch: 0 [269056/620022]    Loss: 0.009582   Batch Acc: 76.56
[Train] Epoch: 0 [269120/620022]    Loss: 0.012343   Batch Acc: 64.06
[Train] Epoch: 0 [269184/620022]    Loss: 0.008680   Batch Acc: 81.25
[Train] Epoch: 0 [269248/620022]    Loss: 0.012331   Batch Acc: 70.31
[Train] Epoch: 0 [269312/620022]    Loss: 0.007510   Batch Acc: 81.25
[Train] Epoch: 0 [269376/620022]    Loss: 0.011022   Batch Acc: 68.75
[Train] Epoch: 0 [269440/620022]    Loss: 0.007663   Batch Acc: 84.38
[Train] Epoch: 0 [269504/620022]    Loss: 0.010626   Batch Acc: 78.12
[Train] Epoch: 0 [269568/620022]    Loss: 0.010910   Batch Acc: 71.88
[Train] Epoch: 0 [269632/620022]    Loss: 0.008707   Batch Acc: 76.56
[Train] Epoch: 0 [269696/620022]    Loss: 0.011180   Batch Acc: 67.19
[Train] Epoch: 0 [269760/620022]    Loss: 0.008683   Batch Acc: 82.81
[Train] Epoch: 0 [269824/620022]    Loss: 0.008223   Batch Acc: 78.12
[Train] Epoch: 0 [269888/620022]    Loss: 0.007528   Batch Acc: 85.94
[Train] Epoch: 0 [269952/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 0 [270016/620022]    Loss: 0.007818   Batch Acc: 79.69
[Train] Epoch: 0 [270080/620022]    Loss: 0.009788   Batch Acc: 79.69
[Train] Epoch: 0 [270144/620022]    Loss: 0.011552   Batch Acc: 70.31
[Train] Epoch: 0 [270208/620022]    Loss: 0.008836   Batch Acc: 70.31
[Train] Epoch: 0 [270272/620022]    Loss: 0.008600   Batch Acc: 81.25
[Train] Epoch: 0 [270336/620022]    Loss: 0.010228   Batch Acc: 71.88
[Train] Epoch: 0 [270400/620022]    Loss: 0.008827   Batch Acc: 79.69
[Train] Epoch: 0 [270464/620022]    Loss: 0.010685   Batch Acc: 71.88
[Train] Epoch: 0 [270528/620022]    Loss: 0.008631   Batch Acc: 75.00
[Train] Epoch: 0 [270592/620022]    Loss: 0.010982   Batch Acc: 71.88
[Train] Epoch: 0 [270656/620022]    Loss: 0.009865   Batch Acc: 70.31
[Train] Epoch: 0 [270720/620022]    Loss: 0.011481   Batch Acc: 73.44
[Train] Epoch: 0 [270784/620022]    Loss: 0.009089   Batch Acc: 73.44
[Train] Epoch: 0 [270848/620022]    Loss: 0.009038   Batch Acc: 81.25
[Train] Epoch: 0 [270912/620022]    Loss: 0.008562   Batch Acc: 79.69
[Train] Epoch: 0 [270976/620022]    Loss: 0.007178   Batch Acc: 82.81
[Train] Epoch: 0 [271040/620022]    Loss: 0.010765   Batch Acc: 70.31
[Train] Epoch: 0 [271104/620022]    Loss: 0.009914   Batch Acc: 75.00
[Train] Epoch: 0 [271168/620022]    Loss: 0.010173   Batch Acc: 73.44
[Train] Epoch: 0 [271232/620022]    Loss: 0.008021   Batch Acc: 78.12
[Train] Epoch: 0 [271296/620022]    Loss: 0.009541   Batch Acc: 81.25
[Train] Epoch: 0 [271360/620022]    Loss: 0.009661   Batch Acc: 73.44
[Train] Epoch: 0 [271424/620022]    Loss: 0.010434   Batch Acc: 73.44
[Train] Epoch: 0 [271488/620022]    Loss: 0.010711   Batch Acc: 71.88
[Train] Epoch: 0 [271552/620022]    Loss: 0.009637   Batch Acc: 68.75
[Train] Epoch: 0 [271616/620022]    Loss: 0.010831   Batch Acc: 70.31
[Train] Epoch: 0 [271680/620022]    Loss: 0.010388   Batch Acc: 71.88
[Train] Epoch: 0 [271744/620022]    Loss: 0.007832   Batch Acc: 82.81
[Train] Epoch: 0 [271808/620022]    Loss: 0.007832   Batch Acc: 78.12
[Train] Epoch: 0 [271872/620022]    Loss: 0.011171   Batch Acc: 71.88
[Train] Epoch: 0 [271936/620022]    Loss: 0.011608   Batch Acc: 71.88
[Train] Epoch: 0 [272000/620022]    Loss: 0.011028   Batch Acc: 71.88
[Train] Epoch: 0 [272064/620022]    Loss: 0.008802   Batch Acc: 76.56
[Train] Epoch: 0 [272128/620022]    Loss: 0.008920   Batch Acc: 81.25
[Train] Epoch: 0 [272192/620022]    Loss: 0.009450   Batch Acc: 75.00
[Train] Epoch: 0 [272256/620022]    Loss: 0.009009   Batch Acc: 73.44
[Train] Epoch: 0 [272320/620022]    Loss: 0.009653   Batch Acc: 76.56
[Train] Epoch: 0 [272384/620022]    Loss: 0.009193   Batch Acc: 81.25
[Train] Epoch: 0 [272448/620022]    Loss: 0.010160   Batch Acc: 68.75
[Train] Epoch: 0 [272512/620022]    Loss: 0.011371   Batch Acc: 68.75
[Train] Epoch: 0 [272576/620022]    Loss: 0.007409   Batch Acc: 85.94
[Train] Epoch: 0 [272640/620022]    Loss: 0.010878   Batch Acc: 75.00
[Train] Epoch: 0 [272704/620022]    Loss: 0.009624   Batch Acc: 70.31
[Train] Epoch: 0 [272768/620022]    Loss: 0.009173   Batch Acc: 76.56
[Train] Epoch: 0 [272832/620022]    Loss: 0.006603   Batch Acc: 89.06
[Train] Epoch: 0 [272896/620022]    Loss: 0.008593   Batch Acc: 78.12
[Train] Epoch: 0 [272960/620022]    Loss: 0.009822   Batch Acc: 70.31
[Train] Epoch: 0 [273024/620022]    Loss: 0.009969   Batch Acc: 70.31
[Train] Epoch: 0 [273088/620022]    Loss: 0.008315   Batch Acc: 78.12
[Train] Epoch: 0 [273152/620022]    Loss: 0.009104   Batch Acc: 76.56
[Train] Epoch: 0 [273216/620022]    Loss: 0.008020   Batch Acc: 78.12
[Train] Epoch: 0 [273280/620022]    Loss: 0.011763   Batch Acc: 64.06
[Train] Epoch: 0 [273344/620022]    Loss: 0.009039   Batch Acc: 75.00
[Train] Epoch: 0 [273408/620022]    Loss: 0.010680   Batch Acc: 68.75
[Train] Epoch: 0 [273472/620022]    Loss: 0.012164   Batch Acc: 65.62
[Train] Epoch: 0 [273536/620022]    Loss: 0.010430   Batch Acc: 68.75
[Train] Epoch: 0 [273600/620022]    Loss: 0.008059   Batch Acc: 79.69
[Train] Epoch: 0 [273664/620022]    Loss: 0.010013   Batch Acc: 73.44
[Train] Epoch: 0 [273728/620022]    Loss: 0.009053   Batch Acc: 75.00
[Train] Epoch: 0 [273792/620022]    Loss: 0.008653   Batch Acc: 79.69
[Train] Epoch: 0 [273856/620022]    Loss: 0.009738   Batch Acc: 73.44
[Train] Epoch: 0 [273920/620022]    Loss: 0.008922   Batch Acc: 75.00
[Train] Epoch: 0 [273984/620022]    Loss: 0.008904   Batch Acc: 78.12
[Train] Epoch: 0 [274048/620022]    Loss: 0.009906   Batch Acc: 73.44
[Train] Epoch: 0 [274112/620022]    Loss: 0.009926   Batch Acc: 73.44
[Train] Epoch: 0 [274176/620022]    Loss: 0.008633   Batch Acc: 79.69
[Train] Epoch: 0 [274240/620022]    Loss: 0.008322   Batch Acc: 82.81
[Train] Epoch: 0 [274304/620022]    Loss: 0.009356   Batch Acc: 76.56
[Train] Epoch: 0 [274368/620022]    Loss: 0.006788   Batch Acc: 85.94
[Train] Epoch: 0 [274432/620022]    Loss: 0.007128   Batch Acc: 81.25
[Train] Epoch: 0 [274496/620022]    Loss: 0.009199   Batch Acc: 75.00
[Train] Epoch: 0 [274560/620022]    Loss: 0.008196   Batch Acc: 79.69
[Train] Epoch: 0 [274624/620022]    Loss: 0.008481   Batch Acc: 81.25
[Train] Epoch: 0 [274688/620022]    Loss: 0.010438   Batch Acc: 73.44
[Train] Epoch: 0 [274752/620022]    Loss: 0.009354   Batch Acc: 75.00
[Train] Epoch: 0 [274816/620022]    Loss: 0.007953   Batch Acc: 85.94
[Train] Epoch: 0 [274880/620022]    Loss: 0.009011   Batch Acc: 78.12
[Train] Epoch: 0 [274944/620022]    Loss: 0.011134   Batch Acc: 71.88
[Train] Epoch: 0 [275008/620022]    Loss: 0.011563   Batch Acc: 68.75
[Train] Epoch: 0 [275072/620022]    Loss: 0.010616   Batch Acc: 67.19
[Train] Epoch: 0 [275136/620022]    Loss: 0.008728   Batch Acc: 84.38
[Train] Epoch: 0 [275200/620022]    Loss: 0.008872   Batch Acc: 75.00
[Train] Epoch: 0 [275264/620022]    Loss: 0.008509   Batch Acc: 78.12
[Train] Epoch: 0 [275328/620022]    Loss: 0.008118   Batch Acc: 75.00
[Train] Epoch: 0 [275392/620022]    Loss: 0.012687   Batch Acc: 68.75
[Train] Epoch: 0 [275456/620022]    Loss: 0.009662   Batch Acc: 76.56
[Train] Epoch: 0 [275520/620022]    Loss: 0.009230   Batch Acc: 75.00
[Train] Epoch: 0 [275584/620022]    Loss: 0.008463   Batch Acc: 75.00
[Train] Epoch: 0 [275648/620022]    Loss: 0.008062   Batch Acc: 78.12
[Train] Epoch: 0 [275712/620022]    Loss: 0.009150   Batch Acc: 75.00
[Train] Epoch: 0 [275776/620022]    Loss: 0.007013   Batch Acc: 82.81
[Train] Epoch: 0 [275840/620022]    Loss: 0.010194   Batch Acc: 68.75
[Train] Epoch: 0 [275904/620022]    Loss: 0.008051   Batch Acc: 81.25
[Train] Epoch: 0 [275968/620022]    Loss: 0.008953   Batch Acc: 76.56
[Train] Epoch: 0 [276032/620022]    Loss: 0.008568   Batch Acc: 78.12
[Train] Epoch: 0 [276096/620022]    Loss: 0.008575   Batch Acc: 79.69
[Train] Epoch: 0 [276160/620022]    Loss: 0.009623   Batch Acc: 75.00
[Train] Epoch: 0 [276224/620022]    Loss: 0.009708   Batch Acc: 75.00
[Train] Epoch: 0 [276288/620022]    Loss: 0.009315   Batch Acc: 75.00
[Train] Epoch: 0 [276352/620022]    Loss: 0.007879   Batch Acc: 79.69
[Train] Epoch: 0 [276416/620022]    Loss: 0.007796   Batch Acc: 81.25
[Train] Epoch: 0 [276480/620022]    Loss: 0.009955   Batch Acc: 75.00
[Train] Epoch: 0 [276544/620022]    Loss: 0.009842   Batch Acc: 68.75
[Train] Epoch: 0 [276608/620022]    Loss: 0.007650   Batch Acc: 84.38
[Train] Epoch: 0 [276672/620022]    Loss: 0.008940   Batch Acc: 75.00
[Train] Epoch: 0 [276736/620022]    Loss: 0.009273   Batch Acc: 73.44
[Train] Epoch: 0 [276800/620022]    Loss: 0.011134   Batch Acc: 70.31
[Train] Epoch: 0 [276864/620022]    Loss: 0.008095   Batch Acc: 78.12
[Train] Epoch: 0 [276928/620022]    Loss: 0.008776   Batch Acc: 81.25
[Train] Epoch: 0 [276992/620022]    Loss: 0.009353   Batch Acc: 75.00
[Train] Epoch: 0 [277056/620022]    Loss: 0.010265   Batch Acc: 75.00
[Train] Epoch: 0 [277120/620022]    Loss: 0.009010   Batch Acc: 76.56
[Train] Epoch: 0 [277184/620022]    Loss: 0.008144   Batch Acc: 78.12
[Train] Epoch: 0 [277248/620022]    Loss: 0.008416   Batch Acc: 76.56
[Train] Epoch: 0 [277312/620022]    Loss: 0.008110   Batch Acc: 81.25
[Train] Epoch: 0 [277376/620022]    Loss: 0.010445   Batch Acc: 71.88
[Train] Epoch: 0 [277440/620022]    Loss: 0.010393   Batch Acc: 68.75
[Train] Epoch: 0 [277504/620022]    Loss: 0.009917   Batch Acc: 78.12
[Train] Epoch: 0 [277568/620022]    Loss: 0.009818   Batch Acc: 75.00
[Train] Epoch: 0 [277632/620022]    Loss: 0.009540   Batch Acc: 70.31
[Train] Epoch: 0 [277696/620022]    Loss: 0.010644   Batch Acc: 76.56
[Train] Epoch: 0 [277760/620022]    Loss: 0.009337   Batch Acc: 79.69
[Train] Epoch: 0 [277824/620022]    Loss: 0.007463   Batch Acc: 85.94
[Train] Epoch: 0 [277888/620022]    Loss: 0.009104   Batch Acc: 79.69
[Train] Epoch: 0 [277952/620022]    Loss: 0.011456   Batch Acc: 67.19
[Train] Epoch: 0 [278016/620022]    Loss: 0.009305   Batch Acc: 76.56
[Train] Epoch: 0 [278080/620022]    Loss: 0.007143   Batch Acc: 85.94
[Train] Epoch: 0 [278144/620022]    Loss: 0.009603   Batch Acc: 78.12
[Train] Epoch: 0 [278208/620022]    Loss: 0.010795   Batch Acc: 70.31
[Train] Epoch: 0 [278272/620022]    Loss: 0.008952   Batch Acc: 71.88
[Train] Epoch: 0 [278336/620022]    Loss: 0.010223   Batch Acc: 73.44
[Train] Epoch: 0 [278400/620022]    Loss: 0.009391   Batch Acc: 76.56
[Train] Epoch: 0 [278464/620022]    Loss: 0.010898   Batch Acc: 71.88
[Train] Epoch: 0 [278528/620022]    Loss: 0.009246   Batch Acc: 75.00
[Train] Epoch: 0 [278592/620022]    Loss: 0.007986   Batch Acc: 84.38
[Train] Epoch: 0 [278656/620022]    Loss: 0.008600   Batch Acc: 79.69
[Train] Epoch: 0 [278720/620022]    Loss: 0.008613   Batch Acc: 76.56
[Train] Epoch: 0 [278784/620022]    Loss: 0.006354   Batch Acc: 85.94
[Train] Epoch: 0 [278848/620022]    Loss: 0.008513   Batch Acc: 81.25
[Train] Epoch: 0 [278912/620022]    Loss: 0.009396   Batch Acc: 75.00
[Train] Epoch: 0 [278976/620022]    Loss: 0.008694   Batch Acc: 79.69
[Train] Epoch: 0 [279040/620022]    Loss: 0.012621   Batch Acc: 68.75
[Train] Epoch: 0 [279104/620022]    Loss: 0.009841   Batch Acc: 73.44
[Train] Epoch: 0 [279168/620022]    Loss: 0.008640   Batch Acc: 73.44
[Train] Epoch: 0 [279232/620022]    Loss: 0.009032   Batch Acc: 78.12
[Train] Epoch: 0 [279296/620022]    Loss: 0.009212   Batch Acc: 75.00
[Train] Epoch: 0 [279360/620022]    Loss: 0.007727   Batch Acc: 78.12
[Train] Epoch: 0 [279424/620022]    Loss: 0.009544   Batch Acc: 78.12
[Train] Epoch: 0 [279488/620022]    Loss: 0.006509   Batch Acc: 87.50
[Train] Epoch: 0 [279552/620022]    Loss: 0.008338   Batch Acc: 75.00
[Train] Epoch: 0 [279616/620022]    Loss: 0.008481   Batch Acc: 79.69
[Train] Epoch: 0 [279680/620022]    Loss: 0.008418   Batch Acc: 78.12
[Train] Epoch: 0 [279744/620022]    Loss: 0.010023   Batch Acc: 73.44
[Train] Epoch: 0 [279808/620022]    Loss: 0.007324   Batch Acc: 82.81
[Train] Epoch: 0 [279872/620022]    Loss: 0.009795   Batch Acc: 70.31
[Train] Epoch: 0 [279936/620022]    Loss: 0.010293   Batch Acc: 70.31
[Train] Epoch: 0 [280000/620022]    Loss: 0.010649   Batch Acc: 68.75
[Train] Epoch: 0 [280064/620022]    Loss: 0.008101   Batch Acc: 81.25
[Train] Epoch: 0 [280128/620022]    Loss: 0.011067   Batch Acc: 68.75
[Train] Epoch: 0 [280192/620022]    Loss: 0.009097   Batch Acc: 76.56
[Train] Epoch: 0 [280256/620022]    Loss: 0.008574   Batch Acc: 78.12
[Train] Epoch: 0 [280320/620022]    Loss: 0.009898   Batch Acc: 76.56
[Train] Epoch: 0 [280384/620022]    Loss: 0.011845   Batch Acc: 70.31
[Train] Epoch: 0 [280448/620022]    Loss: 0.007860   Batch Acc: 85.94
[Train] Epoch: 0 [280512/620022]    Loss: 0.010110   Batch Acc: 75.00
[Train] Epoch: 0 [280576/620022]    Loss: 0.007482   Batch Acc: 84.38
[Train] Epoch: 0 [280640/620022]    Loss: 0.009134   Batch Acc: 76.56
[Train] Epoch: 0 [280704/620022]    Loss: 0.007194   Batch Acc: 82.81
[Train] Epoch: 0 [280768/620022]    Loss: 0.010036   Batch Acc: 79.69
[Train] Epoch: 0 [280832/620022]    Loss: 0.010218   Batch Acc: 73.44
[Train] Epoch: 0 [280896/620022]    Loss: 0.010893   Batch Acc: 75.00
[Train] Epoch: 0 [280960/620022]    Loss: 0.010098   Batch Acc: 73.44
[Train] Epoch: 0 [281024/620022]    Loss: 0.010918   Batch Acc: 78.12
[Train] Epoch: 0 [281088/620022]    Loss: 0.010299   Batch Acc: 67.19
[Train] Epoch: 0 [281152/620022]    Loss: 0.009500   Batch Acc: 76.56
[Train] Epoch: 0 [281216/620022]    Loss: 0.008183   Batch Acc: 79.69
[Train] Epoch: 0 [281280/620022]    Loss: 0.010637   Batch Acc: 64.06
[Train] Epoch: 0 [281344/620022]    Loss: 0.010264   Batch Acc: 73.44
[Train] Epoch: 0 [281408/620022]    Loss: 0.008609   Batch Acc: 79.69
[Train] Epoch: 0 [281472/620022]    Loss: 0.009511   Batch Acc: 71.88
[Train] Epoch: 0 [281536/620022]    Loss: 0.008518   Batch Acc: 79.69
[Train] Epoch: 0 [281600/620022]    Loss: 0.011013   Batch Acc: 68.75
[Train] Epoch: 0 [281664/620022]    Loss: 0.009086   Batch Acc: 71.88
[Train] Epoch: 0 [281728/620022]    Loss: 0.010072   Batch Acc: 76.56
[Train] Epoch: 0 [281792/620022]    Loss: 0.011863   Batch Acc: 73.44
[Train] Epoch: 0 [281856/620022]    Loss: 0.010136   Batch Acc: 76.56
[Train] Epoch: 0 [281920/620022]    Loss: 0.009209   Batch Acc: 75.00
[Train] Epoch: 0 [281984/620022]    Loss: 0.009089   Batch Acc: 76.56
[Train] Epoch: 0 [282048/620022]    Loss: 0.009341   Batch Acc: 76.56
[Train] Epoch: 0 [282112/620022]    Loss: 0.009997   Batch Acc: 73.44
[Train] Epoch: 0 [282176/620022]    Loss: 0.007796   Batch Acc: 82.81
[Train] Epoch: 0 [282240/620022]    Loss: 0.008301   Batch Acc: 84.38
[Train] Epoch: 0 [282304/620022]    Loss: 0.010158   Batch Acc: 75.00
[Train] Epoch: 0 [282368/620022]    Loss: 0.011568   Batch Acc: 71.88
[Train] Epoch: 0 [282432/620022]    Loss: 0.008481   Batch Acc: 73.44
[Train] Epoch: 0 [282496/620022]    Loss: 0.010740   Batch Acc: 68.75
[Train] Epoch: 0 [282560/620022]    Loss: 0.007954   Batch Acc: 78.12
[Train] Epoch: 0 [282624/620022]    Loss: 0.008670   Batch Acc: 81.25
[Train] Epoch: 0 [282688/620022]    Loss: 0.009303   Batch Acc: 71.88
[Train] Epoch: 0 [282752/620022]    Loss: 0.011765   Batch Acc: 67.19
[Train] Epoch: 0 [282816/620022]    Loss: 0.009405   Batch Acc: 75.00
[Train] Epoch: 0 [282880/620022]    Loss: 0.009535   Batch Acc: 73.44
[Train] Epoch: 0 [282944/620022]    Loss: 0.009812   Batch Acc: 78.12
[Train] Epoch: 0 [283008/620022]    Loss: 0.009134   Batch Acc: 79.69
[Train] Epoch: 0 [283072/620022]    Loss: 0.009379   Batch Acc: 82.81
[Train] Epoch: 0 [283136/620022]    Loss: 0.008517   Batch Acc: 76.56
[Train] Epoch: 0 [283200/620022]    Loss: 0.008306   Batch Acc: 75.00
[Train] Epoch: 0 [283264/620022]    Loss: 0.009449   Batch Acc: 79.69
[Train] Epoch: 0 [283328/620022]    Loss: 0.011755   Batch Acc: 68.75
[Train] Epoch: 0 [283392/620022]    Loss: 0.009004   Batch Acc: 75.00
[Train] Epoch: 0 [283456/620022]    Loss: 0.010500   Batch Acc: 71.88
[Train] Epoch: 0 [283520/620022]    Loss: 0.007669   Batch Acc: 76.56
[Train] Epoch: 0 [283584/620022]    Loss: 0.009386   Batch Acc: 67.19
[Train] Epoch: 0 [283648/620022]    Loss: 0.008955   Batch Acc: 79.69
[Train] Epoch: 0 [283712/620022]    Loss: 0.007624   Batch Acc: 81.25
[Train] Epoch: 0 [283776/620022]    Loss: 0.009769   Batch Acc: 79.69
[Train] Epoch: 0 [283840/620022]    Loss: 0.009827   Batch Acc: 68.75
[Train] Epoch: 0 [283904/620022]    Loss: 0.007643   Batch Acc: 82.81
[Train] Epoch: 0 [283968/620022]    Loss: 0.009650   Batch Acc: 75.00
[Train] Epoch: 0 [284032/620022]    Loss: 0.008895   Batch Acc: 78.12
[Train] Epoch: 0 [284096/620022]    Loss: 0.009082   Batch Acc: 70.31
[Train] Epoch: 0 [284160/620022]    Loss: 0.008376   Batch Acc: 76.56
[Train] Epoch: 0 [284224/620022]    Loss: 0.007528   Batch Acc: 81.25
[Train] Epoch: 0 [284288/620022]    Loss: 0.010346   Batch Acc: 68.75
[Train] Epoch: 0 [284352/620022]    Loss: 0.009075   Batch Acc: 75.00
[Train] Epoch: 0 [284416/620022]    Loss: 0.007986   Batch Acc: 79.69
[Train] Epoch: 0 [284480/620022]    Loss: 0.008341   Batch Acc: 79.69
[Train] Epoch: 0 [284544/620022]    Loss: 0.008588   Batch Acc: 76.56
[Train] Epoch: 0 [284608/620022]    Loss: 0.008959   Batch Acc: 76.56
[Train] Epoch: 0 [284672/620022]    Loss: 0.010349   Batch Acc: 70.31
[Train] Epoch: 0 [284736/620022]    Loss: 0.007440   Batch Acc: 81.25
[Train] Epoch: 0 [284800/620022]    Loss: 0.009156   Batch Acc: 70.31
[Train] Epoch: 0 [284864/620022]    Loss: 0.009538   Batch Acc: 79.69
[Train] Epoch: 0 [284928/620022]    Loss: 0.009256   Batch Acc: 75.00
[Train] Epoch: 0 [284992/620022]    Loss: 0.009380   Batch Acc: 76.56
[Train] Epoch: 0 [285056/620022]    Loss: 0.008823   Batch Acc: 78.12
[Train] Epoch: 0 [285120/620022]    Loss: 0.009866   Batch Acc: 73.44
[Train] Epoch: 0 [285184/620022]    Loss: 0.007947   Batch Acc: 79.69
[Train] Epoch: 0 [285248/620022]    Loss: 0.007834   Batch Acc: 81.25
[Train] Epoch: 0 [285312/620022]    Loss: 0.008040   Batch Acc: 82.81
[Train] Epoch: 0 [285376/620022]    Loss: 0.008728   Batch Acc: 82.81
[Train] Epoch: 0 [285440/620022]    Loss: 0.008158   Batch Acc: 81.25
[Train] Epoch: 0 [285504/620022]    Loss: 0.011606   Batch Acc: 76.56
[Train] Epoch: 0 [285568/620022]    Loss: 0.010523   Batch Acc: 70.31
[Train] Epoch: 0 [285632/620022]    Loss: 0.009686   Batch Acc: 76.56
[Train] Epoch: 0 [285696/620022]    Loss: 0.006093   Batch Acc: 90.62
[Train] Epoch: 0 [285760/620022]    Loss: 0.008924   Batch Acc: 73.44
[Train] Epoch: 0 [285824/620022]    Loss: 0.009048   Batch Acc: 73.44
[Train] Epoch: 0 [285888/620022]    Loss: 0.008635   Batch Acc: 76.56
[Train] Epoch: 0 [285952/620022]    Loss: 0.008866   Batch Acc: 78.12
[Train] Epoch: 0 [286016/620022]    Loss: 0.008467   Batch Acc: 76.56
[Train] Epoch: 0 [286080/620022]    Loss: 0.010045   Batch Acc: 76.56
[Train] Epoch: 0 [286144/620022]    Loss: 0.008812   Batch Acc: 79.69
[Train] Epoch: 0 [286208/620022]    Loss: 0.009535   Batch Acc: 73.44
[Train] Epoch: 0 [286272/620022]    Loss: 0.009595   Batch Acc: 71.88
[Train] Epoch: 0 [286336/620022]    Loss: 0.007737   Batch Acc: 84.38
[Train] Epoch: 0 [286400/620022]    Loss: 0.010522   Batch Acc: 65.62
[Train] Epoch: 0 [286464/620022]    Loss: 0.008766   Batch Acc: 78.12
[Train] Epoch: 0 [286528/620022]    Loss: 0.008783   Batch Acc: 78.12
[Train] Epoch: 0 [286592/620022]    Loss: 0.010919   Batch Acc: 67.19
[Train] Epoch: 0 [286656/620022]    Loss: 0.010765   Batch Acc: 70.31
[Train] Epoch: 0 [286720/620022]    Loss: 0.008405   Batch Acc: 76.56
[Train] Epoch: 0 [286784/620022]    Loss: 0.009503   Batch Acc: 75.00
[Train] Epoch: 0 [286848/620022]    Loss: 0.009910   Batch Acc: 81.25
[Train] Epoch: 0 [286912/620022]    Loss: 0.009213   Batch Acc: 73.44
[Train] Epoch: 0 [286976/620022]    Loss: 0.007414   Batch Acc: 82.81
[Train] Epoch: 0 [287040/620022]    Loss: 0.009051   Batch Acc: 71.88
[Train] Epoch: 0 [287104/620022]    Loss: 0.008985   Batch Acc: 76.56
[Train] Epoch: 0 [287168/620022]    Loss: 0.010514   Batch Acc: 73.44
[Train] Epoch: 0 [287232/620022]    Loss: 0.008986   Batch Acc: 81.25
[Train] Epoch: 0 [287296/620022]    Loss: 0.007688   Batch Acc: 84.38
[Train] Epoch: 0 [287360/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 0 [287424/620022]    Loss: 0.009673   Batch Acc: 78.12
[Train] Epoch: 0 [287488/620022]    Loss: 0.008243   Batch Acc: 81.25
[Train] Epoch: 0 [287552/620022]    Loss: 0.009795   Batch Acc: 76.56
[Train] Epoch: 0 [287616/620022]    Loss: 0.008606   Batch Acc: 78.12
[Train] Epoch: 0 [287680/620022]    Loss: 0.011487   Batch Acc: 73.44
[Train] Epoch: 0 [287744/620022]    Loss: 0.011560   Batch Acc: 70.31
[Train] Epoch: 0 [287808/620022]    Loss: 0.010101   Batch Acc: 65.62
[Train] Epoch: 0 [287872/620022]    Loss: 0.011997   Batch Acc: 71.88
[Train] Epoch: 0 [287936/620022]    Loss: 0.009098   Batch Acc: 75.00
[Train] Epoch: 0 [288000/620022]    Loss: 0.010318   Batch Acc: 76.56
[Train] Epoch: 0 [288064/620022]    Loss: 0.008301   Batch Acc: 84.38
[Train] Epoch: 0 [288128/620022]    Loss: 0.010840   Batch Acc: 67.19
[Train] Epoch: 0 [288192/620022]    Loss: 0.010175   Batch Acc: 73.44
[Train] Epoch: 0 [288256/620022]    Loss: 0.011449   Batch Acc: 71.88
[Train] Epoch: 0 [288320/620022]    Loss: 0.008631   Batch Acc: 81.25
[Train] Epoch: 0 [288384/620022]    Loss: 0.008414   Batch Acc: 78.12
[Train] Epoch: 0 [288448/620022]    Loss: 0.009035   Batch Acc: 79.69
[Train] Epoch: 0 [288512/620022]    Loss: 0.008217   Batch Acc: 78.12
[Train] Epoch: 0 [288576/620022]    Loss: 0.010325   Batch Acc: 71.88
[Train] Epoch: 0 [288640/620022]    Loss: 0.007390   Batch Acc: 81.25
[Train] Epoch: 0 [288704/620022]    Loss: 0.009557   Batch Acc: 79.69
[Train] Epoch: 0 [288768/620022]    Loss: 0.007412   Batch Acc: 82.81
[Train] Epoch: 0 [288832/620022]    Loss: 0.009508   Batch Acc: 70.31
[Train] Epoch: 0 [288896/620022]    Loss: 0.007582   Batch Acc: 79.69
[Train] Epoch: 0 [288960/620022]    Loss: 0.011200   Batch Acc: 68.75
[Train] Epoch: 0 [289024/620022]    Loss: 0.008280   Batch Acc: 76.56
[Train] Epoch: 0 [289088/620022]    Loss: 0.010355   Batch Acc: 68.75
[Train] Epoch: 0 [289152/620022]    Loss: 0.009337   Batch Acc: 79.69
[Train] Epoch: 0 [289216/620022]    Loss: 0.009349   Batch Acc: 76.56
[Train] Epoch: 0 [289280/620022]    Loss: 0.009165   Batch Acc: 78.12
[Train] Epoch: 0 [289344/620022]    Loss: 0.009514   Batch Acc: 76.56
[Train] Epoch: 0 [289408/620022]    Loss: 0.010230   Batch Acc: 70.31
[Train] Epoch: 0 [289472/620022]    Loss: 0.008954   Batch Acc: 81.25
[Train] Epoch: 0 [289536/620022]    Loss: 0.011817   Batch Acc: 67.19
[Train] Epoch: 0 [289600/620022]    Loss: 0.007988   Batch Acc: 78.12
[Train] Epoch: 0 [289664/620022]    Loss: 0.010972   Batch Acc: 65.62
[Train] Epoch: 0 [289728/620022]    Loss: 0.009328   Batch Acc: 73.44
[Train] Epoch: 0 [289792/620022]    Loss: 0.010173   Batch Acc: 68.75
[Train] Epoch: 0 [289856/620022]    Loss: 0.008653   Batch Acc: 79.69
[Train] Epoch: 0 [289920/620022]    Loss: 0.011573   Batch Acc: 68.75
[Train] Epoch: 0 [289984/620022]    Loss: 0.008886   Batch Acc: 76.56
[Train] Epoch: 0 [290048/620022]    Loss: 0.009409   Batch Acc: 82.81
[Train] Epoch: 0 [290112/620022]    Loss: 0.008383   Batch Acc: 76.56
[Train] Epoch: 0 [290176/620022]    Loss: 0.008315   Batch Acc: 76.56
[Train] Epoch: 0 [290240/620022]    Loss: 0.009259   Batch Acc: 73.44
[Train] Epoch: 0 [290304/620022]    Loss: 0.008953   Batch Acc: 78.12
[Train] Epoch: 0 [290368/620022]    Loss: 0.010052   Batch Acc: 75.00
[Train] Epoch: 0 [290432/620022]    Loss: 0.011197   Batch Acc: 70.31
[Train] Epoch: 0 [290496/620022]    Loss: 0.010221   Batch Acc: 73.44
[Train] Epoch: 0 [290560/620022]    Loss: 0.009928   Batch Acc: 68.75
[Train] Epoch: 0 [290624/620022]    Loss: 0.008840   Batch Acc: 73.44
[Train] Epoch: 0 [290688/620022]    Loss: 0.008292   Batch Acc: 81.25
[Train] Epoch: 0 [290752/620022]    Loss: 0.010848   Batch Acc: 73.44
[Train] Epoch: 0 [290816/620022]    Loss: 0.007923   Batch Acc: 79.69
[Train] Epoch: 0 [290880/620022]    Loss: 0.011561   Batch Acc: 71.88
[Train] Epoch: 0 [290944/620022]    Loss: 0.009743   Batch Acc: 75.00
[Train] Epoch: 0 [291008/620022]    Loss: 0.009010   Batch Acc: 78.12
[Train] Epoch: 0 [291072/620022]    Loss: 0.009729   Batch Acc: 68.75
[Train] Epoch: 0 [291136/620022]    Loss: 0.008646   Batch Acc: 76.56
[Train] Epoch: 0 [291200/620022]    Loss: 0.008238   Batch Acc: 76.56
[Train] Epoch: 0 [291264/620022]    Loss: 0.009950   Batch Acc: 75.00
[Train] Epoch: 0 [291328/620022]    Loss: 0.007988   Batch Acc: 82.81
[Train] Epoch: 0 [291392/620022]    Loss: 0.008772   Batch Acc: 81.25
[Train] Epoch: 0 [291456/620022]    Loss: 0.009045   Batch Acc: 76.56
[Train] Epoch: 0 [291520/620022]    Loss: 0.008194   Batch Acc: 79.69
[Train] Epoch: 0 [291584/620022]    Loss: 0.011548   Batch Acc: 67.19
[Train] Epoch: 0 [291648/620022]    Loss: 0.012572   Batch Acc: 68.75
[Train] Epoch: 0 [291712/620022]    Loss: 0.007609   Batch Acc: 81.25
[Train] Epoch: 0 [291776/620022]    Loss: 0.009702   Batch Acc: 76.56
[Train] Epoch: 0 [291840/620022]    Loss: 0.009260   Batch Acc: 75.00
[Train] Epoch: 0 [291904/620022]    Loss: 0.008127   Batch Acc: 79.69
[Train] Epoch: 0 [291968/620022]    Loss: 0.009006   Batch Acc: 76.56
[Train] Epoch: 0 [292032/620022]    Loss: 0.010937   Batch Acc: 75.00
[Train] Epoch: 0 [292096/620022]    Loss: 0.008278   Batch Acc: 82.81
[Train] Epoch: 0 [292160/620022]    Loss: 0.007835   Batch Acc: 82.81
[Train] Epoch: 0 [292224/620022]    Loss: 0.010407   Batch Acc: 67.19
[Train] Epoch: 0 [292288/620022]    Loss: 0.009157   Batch Acc: 79.69
[Train] Epoch: 0 [292352/620022]    Loss: 0.008795   Batch Acc: 70.31
[Train] Epoch: 0 [292416/620022]    Loss: 0.006493   Batch Acc: 87.50
[Train] Epoch: 0 [292480/620022]    Loss: 0.008601   Batch Acc: 81.25
[Train] Epoch: 0 [292544/620022]    Loss: 0.009687   Batch Acc: 71.88
[Train] Epoch: 0 [292608/620022]    Loss: 0.011827   Batch Acc: 68.75
[Train] Epoch: 0 [292672/620022]    Loss: 0.008817   Batch Acc: 70.31
[Train] Epoch: 0 [292736/620022]    Loss: 0.009723   Batch Acc: 75.00
[Train] Epoch: 0 [292800/620022]    Loss: 0.010700   Batch Acc: 75.00
[Train] Epoch: 0 [292864/620022]    Loss: 0.011168   Batch Acc: 68.75
[Train] Epoch: 0 [292928/620022]    Loss: 0.008463   Batch Acc: 75.00
[Train] Epoch: 0 [292992/620022]    Loss: 0.008738   Batch Acc: 76.56
[Train] Epoch: 0 [293056/620022]    Loss: 0.009910   Batch Acc: 73.44
[Train] Epoch: 0 [293120/620022]    Loss: 0.007277   Batch Acc: 79.69
[Train] Epoch: 0 [293184/620022]    Loss: 0.008003   Batch Acc: 85.94
[Train] Epoch: 0 [293248/620022]    Loss: 0.007726   Batch Acc: 82.81
[Train] Epoch: 0 [293312/620022]    Loss: 0.008310   Batch Acc: 78.12
[Train] Epoch: 0 [293376/620022]    Loss: 0.009169   Batch Acc: 79.69
[Train] Epoch: 0 [293440/620022]    Loss: 0.008218   Batch Acc: 78.12
[Train] Epoch: 0 [293504/620022]    Loss: 0.008232   Batch Acc: 85.94
[Train] Epoch: 0 [293568/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 0 [293632/620022]    Loss: 0.010140   Batch Acc: 75.00
[Train] Epoch: 0 [293696/620022]    Loss: 0.010774   Batch Acc: 60.94
[Train] Epoch: 0 [293760/620022]    Loss: 0.009941   Batch Acc: 75.00
[Train] Epoch: 0 [293824/620022]    Loss: 0.007512   Batch Acc: 79.69
[Train] Epoch: 0 [293888/620022]    Loss: 0.008673   Batch Acc: 79.69
[Train] Epoch: 0 [293952/620022]    Loss: 0.008498   Batch Acc: 79.69
[Train] Epoch: 0 [294016/620022]    Loss: 0.010160   Batch Acc: 70.31
[Train] Epoch: 0 [294080/620022]    Loss: 0.009590   Batch Acc: 67.19
[Train] Epoch: 0 [294144/620022]    Loss: 0.009829   Batch Acc: 76.56
[Train] Epoch: 0 [294208/620022]    Loss: 0.010915   Batch Acc: 71.88
[Train] Epoch: 0 [294272/620022]    Loss: 0.010673   Batch Acc: 73.44
[Train] Epoch: 0 [294336/620022]    Loss: 0.007659   Batch Acc: 84.38
[Train] Epoch: 0 [294400/620022]    Loss: 0.006814   Batch Acc: 81.25
[Train] Epoch: 0 [294464/620022]    Loss: 0.009030   Batch Acc: 81.25
[Train] Epoch: 0 [294528/620022]    Loss: 0.007872   Batch Acc: 84.38
[Train] Epoch: 0 [294592/620022]    Loss: 0.010024   Batch Acc: 75.00
[Train] Epoch: 0 [294656/620022]    Loss: 0.008922   Batch Acc: 71.88
[Train] Epoch: 0 [294720/620022]    Loss: 0.007721   Batch Acc: 85.94
[Train] Epoch: 0 [294784/620022]    Loss: 0.009654   Batch Acc: 70.31
[Train] Epoch: 0 [294848/620022]    Loss: 0.010713   Batch Acc: 68.75
[Train] Epoch: 0 [294912/620022]    Loss: 0.011147   Batch Acc: 70.31
[Train] Epoch: 0 [294976/620022]    Loss: 0.009964   Batch Acc: 70.31
[Train] Epoch: 0 [295040/620022]    Loss: 0.009404   Batch Acc: 75.00
[Train] Epoch: 0 [295104/620022]    Loss: 0.011326   Batch Acc: 65.62
[Train] Epoch: 0 [295168/620022]    Loss: 0.008509   Batch Acc: 79.69
[Train] Epoch: 0 [295232/620022]    Loss: 0.008618   Batch Acc: 78.12
[Train] Epoch: 0 [295296/620022]    Loss: 0.009274   Batch Acc: 73.44
[Train] Epoch: 0 [295360/620022]    Loss: 0.010018   Batch Acc: 70.31
[Train] Epoch: 0 [295424/620022]    Loss: 0.008848   Batch Acc: 79.69
[Train] Epoch: 0 [295488/620022]    Loss: 0.009928   Batch Acc: 73.44
[Train] Epoch: 0 [295552/620022]    Loss: 0.010023   Batch Acc: 73.44
[Train] Epoch: 0 [295616/620022]    Loss: 0.008199   Batch Acc: 82.81
[Train] Epoch: 0 [295680/620022]    Loss: 0.008631   Batch Acc: 79.69
[Train] Epoch: 0 [295744/620022]    Loss: 0.007164   Batch Acc: 82.81
[Train] Epoch: 0 [295808/620022]    Loss: 0.009676   Batch Acc: 73.44
[Train] Epoch: 0 [295872/620022]    Loss: 0.010538   Batch Acc: 67.19
[Train] Epoch: 0 [295936/620022]    Loss: 0.011430   Batch Acc: 62.50
[Train] Epoch: 0 [296000/620022]    Loss: 0.008756   Batch Acc: 81.25
[Train] Epoch: 0 [296064/620022]    Loss: 0.008258   Batch Acc: 81.25
[Train] Epoch: 0 [296128/620022]    Loss: 0.010571   Batch Acc: 71.88
[Train] Epoch: 0 [296192/620022]    Loss: 0.010964   Batch Acc: 75.00
[Train] Epoch: 0 [296256/620022]    Loss: 0.007844   Batch Acc: 78.12
[Train] Epoch: 0 [296320/620022]    Loss: 0.010421   Batch Acc: 75.00
[Train] Epoch: 0 [296384/620022]    Loss: 0.007953   Batch Acc: 78.12
[Train] Epoch: 0 [296448/620022]    Loss: 0.011405   Batch Acc: 71.88
[Train] Epoch: 0 [296512/620022]    Loss: 0.007616   Batch Acc: 84.38
[Train] Epoch: 0 [296576/620022]    Loss: 0.009097   Batch Acc: 78.12
[Train] Epoch: 0 [296640/620022]    Loss: 0.007776   Batch Acc: 81.25
[Train] Epoch: 0 [296704/620022]    Loss: 0.009610   Batch Acc: 71.88
[Train] Epoch: 0 [296768/620022]    Loss: 0.009990   Batch Acc: 78.12
[Train] Epoch: 0 [296832/620022]    Loss: 0.010075   Batch Acc: 76.56
[Train] Epoch: 0 [296896/620022]    Loss: 0.009052   Batch Acc: 79.69
[Train] Epoch: 0 [296960/620022]    Loss: 0.009369   Batch Acc: 73.44
[Train] Epoch: 0 [297024/620022]    Loss: 0.009028   Batch Acc: 79.69
[Train] Epoch: 0 [297088/620022]    Loss: 0.008076   Batch Acc: 79.69
[Train] Epoch: 0 [297152/620022]    Loss: 0.011635   Batch Acc: 70.31
[Train] Epoch: 0 [297216/620022]    Loss: 0.009560   Batch Acc: 76.56
[Train] Epoch: 0 [297280/620022]    Loss: 0.010174   Batch Acc: 75.00
[Train] Epoch: 0 [297344/620022]    Loss: 0.008132   Batch Acc: 76.56
[Train] Epoch: 0 [297408/620022]    Loss: 0.007989   Batch Acc: 79.69
[Train] Epoch: 0 [297472/620022]    Loss: 0.009176   Batch Acc: 73.44
[Train] Epoch: 0 [297536/620022]    Loss: 0.011232   Batch Acc: 71.88
[Train] Epoch: 0 [297600/620022]    Loss: 0.006846   Batch Acc: 85.94
[Train] Epoch: 0 [297664/620022]    Loss: 0.009863   Batch Acc: 75.00
[Train] Epoch: 0 [297728/620022]    Loss: 0.009447   Batch Acc: 78.12
[Train] Epoch: 0 [297792/620022]    Loss: 0.008364   Batch Acc: 82.81
[Train] Epoch: 0 [297856/620022]    Loss: 0.008964   Batch Acc: 78.12
[Train] Epoch: 0 [297920/620022]    Loss: 0.009218   Batch Acc: 79.69
[Train] Epoch: 0 [297984/620022]    Loss: 0.006808   Batch Acc: 84.38
[Train] Epoch: 0 [298048/620022]    Loss: 0.008604   Batch Acc: 71.88
[Train] Epoch: 0 [298112/620022]    Loss: 0.009398   Batch Acc: 73.44
[Train] Epoch: 0 [298176/620022]    Loss: 0.009802   Batch Acc: 76.56
[Train] Epoch: 0 [298240/620022]    Loss: 0.008811   Batch Acc: 81.25
[Train] Epoch: 0 [298304/620022]    Loss: 0.010297   Batch Acc: 71.88
[Train] Epoch: 0 [298368/620022]    Loss: 0.007553   Batch Acc: 87.50
[Train] Epoch: 0 [298432/620022]    Loss: 0.010618   Batch Acc: 73.44
[Train] Epoch: 0 [298496/620022]    Loss: 0.008489   Batch Acc: 78.12
[Train] Epoch: 0 [298560/620022]    Loss: 0.007546   Batch Acc: 85.94
[Train] Epoch: 0 [298624/620022]    Loss: 0.009423   Batch Acc: 71.88
[Train] Epoch: 0 [298688/620022]    Loss: 0.008672   Batch Acc: 79.69
[Train] Epoch: 0 [298752/620022]    Loss: 0.011334   Batch Acc: 67.19
[Train] Epoch: 0 [298816/620022]    Loss: 0.008905   Batch Acc: 76.56
[Train] Epoch: 0 [298880/620022]    Loss: 0.008171   Batch Acc: 81.25
[Train] Epoch: 0 [298944/620022]    Loss: 0.010162   Batch Acc: 75.00
[Train] Epoch: 0 [299008/620022]    Loss: 0.008451   Batch Acc: 76.56
[Train] Epoch: 0 [299072/620022]    Loss: 0.009654   Batch Acc: 70.31
[Train] Epoch: 0 [299136/620022]    Loss: 0.009739   Batch Acc: 71.88
[Train] Epoch: 0 [299200/620022]    Loss: 0.009144   Batch Acc: 79.69
[Train] Epoch: 0 [299264/620022]    Loss: 0.009192   Batch Acc: 76.56
[Train] Epoch: 0 [299328/620022]    Loss: 0.009629   Batch Acc: 70.31
[Train] Epoch: 0 [299392/620022]    Loss: 0.007916   Batch Acc: 81.25
[Train] Epoch: 0 [299456/620022]    Loss: 0.009172   Batch Acc: 73.44
[Train] Epoch: 0 [299520/620022]    Loss: 0.007687   Batch Acc: 85.94
[Train] Epoch: 0 [299584/620022]    Loss: 0.008285   Batch Acc: 81.25
[Train] Epoch: 0 [299648/620022]    Loss: 0.011957   Batch Acc: 67.19
[Train] Epoch: 0 [299712/620022]    Loss: 0.007876   Batch Acc: 78.12
[Train] Epoch: 0 [299776/620022]    Loss: 0.008220   Batch Acc: 82.81
[Train] Epoch: 0 [299840/620022]    Loss: 0.008531   Batch Acc: 78.12
[Train] Epoch: 0 [299904/620022]    Loss: 0.009220   Batch Acc: 76.56
[Train] Epoch: 0 [299968/620022]    Loss: 0.008546   Batch Acc: 81.25
[Train] Epoch: 0 [300032/620022]    Loss: 0.010358   Batch Acc: 67.19
[Train] Epoch: 0 [300096/620022]    Loss: 0.009318   Batch Acc: 73.44
[Train] Epoch: 0 [300160/620022]    Loss: 0.010031   Batch Acc: 76.56
[Train] Epoch: 0 [300224/620022]    Loss: 0.008368   Batch Acc: 76.56
[Train] Epoch: 0 [300288/620022]    Loss: 0.007253   Batch Acc: 78.12
[Train] Epoch: 0 [300352/620022]    Loss: 0.009091   Batch Acc: 75.00
[Train] Epoch: 0 [300416/620022]    Loss: 0.009713   Batch Acc: 75.00
[Train] Epoch: 0 [300480/620022]    Loss: 0.010162   Batch Acc: 73.44
[Train] Epoch: 0 [300544/620022]    Loss: 0.009558   Batch Acc: 78.12
[Train] Epoch: 0 [300608/620022]    Loss: 0.010867   Batch Acc: 70.31
[Train] Epoch: 0 [300672/620022]    Loss: 0.009919   Batch Acc: 71.88
[Train] Epoch: 0 [300736/620022]    Loss: 0.011895   Batch Acc: 65.62
[Train] Epoch: 0 [300800/620022]    Loss: 0.008821   Batch Acc: 76.56
[Train] Epoch: 0 [300864/620022]    Loss: 0.010350   Batch Acc: 67.19
[Train] Epoch: 0 [300928/620022]    Loss: 0.007889   Batch Acc: 79.69
[Train] Epoch: 0 [300992/620022]    Loss: 0.009453   Batch Acc: 71.88
[Train] Epoch: 0 [301056/620022]    Loss: 0.008331   Batch Acc: 76.56
[Train] Epoch: 0 [301120/620022]    Loss: 0.007417   Batch Acc: 84.38
[Train] Epoch: 0 [301184/620022]    Loss: 0.007411   Batch Acc: 82.81
[Train] Epoch: 0 [301248/620022]    Loss: 0.009883   Batch Acc: 70.31
[Train] Epoch: 0 [301312/620022]    Loss: 0.009616   Batch Acc: 73.44
[Train] Epoch: 0 [301376/620022]    Loss: 0.007604   Batch Acc: 81.25
[Train] Epoch: 0 [301440/620022]    Loss: 0.008870   Batch Acc: 79.69
[Train] Epoch: 0 [301504/620022]    Loss: 0.006936   Batch Acc: 85.94
[Train] Epoch: 0 [301568/620022]    Loss: 0.011258   Batch Acc: 70.31
[Train] Epoch: 0 [301632/620022]    Loss: 0.010092   Batch Acc: 67.19
[Train] Epoch: 0 [301696/620022]    Loss: 0.010007   Batch Acc: 75.00
[Train] Epoch: 0 [301760/620022]    Loss: 0.014157   Batch Acc: 53.12
[Train] Epoch: 0 [301824/620022]    Loss: 0.008907   Batch Acc: 76.56
[Train] Epoch: 0 [301888/620022]    Loss: 0.007217   Batch Acc: 87.50
[Train] Epoch: 0 [301952/620022]    Loss: 0.011338   Batch Acc: 67.19
[Train] Epoch: 0 [302016/620022]    Loss: 0.007785   Batch Acc: 82.81
[Train] Epoch: 0 [302080/620022]    Loss: 0.009235   Batch Acc: 78.12
[Train] Epoch: 0 [302144/620022]    Loss: 0.009539   Batch Acc: 73.44
[Train] Epoch: 0 [302208/620022]    Loss: 0.009926   Batch Acc: 75.00
[Train] Epoch: 0 [302272/620022]    Loss: 0.010073   Batch Acc: 81.25
[Train] Epoch: 0 [302336/620022]    Loss: 0.007125   Batch Acc: 82.81
[Train] Epoch: 0 [302400/620022]    Loss: 0.009638   Batch Acc: 75.00
[Train] Epoch: 0 [302464/620022]    Loss: 0.009485   Batch Acc: 75.00
[Train] Epoch: 0 [302528/620022]    Loss: 0.008559   Batch Acc: 76.56
[Train] Epoch: 0 [302592/620022]    Loss: 0.009954   Batch Acc: 79.69
[Train] Epoch: 0 [302656/620022]    Loss: 0.010927   Batch Acc: 64.06
[Train] Epoch: 0 [302720/620022]    Loss: 0.010436   Batch Acc: 76.56
[Train] Epoch: 0 [302784/620022]    Loss: 0.011097   Batch Acc: 71.88
[Train] Epoch: 0 [302848/620022]    Loss: 0.009998   Batch Acc: 78.12
[Train] Epoch: 0 [302912/620022]    Loss: 0.010083   Batch Acc: 70.31
[Train] Epoch: 0 [302976/620022]    Loss: 0.009340   Batch Acc: 76.56
[Train] Epoch: 0 [303040/620022]    Loss: 0.008620   Batch Acc: 75.00
[Train] Epoch: 0 [303104/620022]    Loss: 0.008656   Batch Acc: 75.00
[Train] Epoch: 0 [303168/620022]    Loss: 0.008591   Batch Acc: 78.12
[Train] Epoch: 0 [303232/620022]    Loss: 0.008019   Batch Acc: 82.81
[Train] Epoch: 0 [303296/620022]    Loss: 0.010541   Batch Acc: 67.19
[Train] Epoch: 0 [303360/620022]    Loss: 0.009224   Batch Acc: 81.25
[Train] Epoch: 0 [303424/620022]    Loss: 0.008409   Batch Acc: 82.81
[Train] Epoch: 0 [303488/620022]    Loss: 0.008822   Batch Acc: 81.25
[Train] Epoch: 0 [303552/620022]    Loss: 0.008530   Batch Acc: 81.25
[Train] Epoch: 0 [303616/620022]    Loss: 0.007912   Batch Acc: 79.69
[Train] Epoch: 0 [303680/620022]    Loss: 0.011214   Batch Acc: 71.88
[Train] Epoch: 0 [303744/620022]    Loss: 0.010164   Batch Acc: 73.44
[Train] Epoch: 0 [303808/620022]    Loss: 0.010455   Batch Acc: 73.44
[Train] Epoch: 0 [303872/620022]    Loss: 0.008133   Batch Acc: 79.69
[Train] Epoch: 0 [303936/620022]    Loss: 0.010247   Batch Acc: 76.56
[Train] Epoch: 0 [304000/620022]    Loss: 0.008386   Batch Acc: 78.12
[Train] Epoch: 0 [304064/620022]    Loss: 0.008507   Batch Acc: 84.38
[Train] Epoch: 0 [304128/620022]    Loss: 0.007792   Batch Acc: 76.56
[Train] Epoch: 0 [304192/620022]    Loss: 0.009183   Batch Acc: 76.56
[Train] Epoch: 0 [304256/620022]    Loss: 0.007038   Batch Acc: 81.25
[Train] Epoch: 0 [304320/620022]    Loss: 0.011708   Batch Acc: 67.19
[Train] Epoch: 0 [304384/620022]    Loss: 0.007517   Batch Acc: 82.81
[Train] Epoch: 0 [304448/620022]    Loss: 0.009324   Batch Acc: 70.31
[Train] Epoch: 0 [304512/620022]    Loss: 0.010758   Batch Acc: 62.50
[Train] Epoch: 0 [304576/620022]    Loss: 0.007022   Batch Acc: 81.25
[Train] Epoch: 0 [304640/620022]    Loss: 0.009388   Batch Acc: 75.00
[Train] Epoch: 0 [304704/620022]    Loss: 0.009318   Batch Acc: 78.12
[Train] Epoch: 0 [304768/620022]    Loss: 0.008661   Batch Acc: 71.88
[Train] Epoch: 0 [304832/620022]    Loss: 0.009348   Batch Acc: 73.44
[Train] Epoch: 0 [304896/620022]    Loss: 0.011496   Batch Acc: 71.88
[Train] Epoch: 0 [304960/620022]    Loss: 0.008027   Batch Acc: 78.12
[Train] Epoch: 0 [305024/620022]    Loss: 0.010950   Batch Acc: 75.00
[Train] Epoch: 0 [305088/620022]    Loss: 0.009777   Batch Acc: 68.75
[Train] Epoch: 0 [305152/620022]    Loss: 0.009738   Batch Acc: 76.56
[Train] Epoch: 0 [305216/620022]    Loss: 0.008285   Batch Acc: 79.69
[Train] Epoch: 0 [305280/620022]    Loss: 0.008620   Batch Acc: 75.00
[Train] Epoch: 0 [305344/620022]    Loss: 0.009451   Batch Acc: 79.69
[Train] Epoch: 0 [305408/620022]    Loss: 0.011282   Batch Acc: 62.50
[Train] Epoch: 0 [305472/620022]    Loss: 0.008794   Batch Acc: 82.81
[Train] Epoch: 0 [305536/620022]    Loss: 0.009886   Batch Acc: 75.00
[Train] Epoch: 0 [305600/620022]    Loss: 0.009059   Batch Acc: 76.56
[Train] Epoch: 0 [305664/620022]    Loss: 0.007573   Batch Acc: 84.38
[Train] Epoch: 0 [305728/620022]    Loss: 0.007684   Batch Acc: 81.25
[Train] Epoch: 0 [305792/620022]    Loss: 0.011386   Batch Acc: 71.88
[Train] Epoch: 0 [305856/620022]    Loss: 0.010329   Batch Acc: 70.31
[Train] Epoch: 0 [305920/620022]    Loss: 0.009318   Batch Acc: 78.12
[Train] Epoch: 0 [305984/620022]    Loss: 0.008609   Batch Acc: 81.25
[Train] Epoch: 0 [306048/620022]    Loss: 0.009834   Batch Acc: 67.19
[Train] Epoch: 0 [306112/620022]    Loss: 0.010733   Batch Acc: 73.44
[Train] Epoch: 0 [306176/620022]    Loss: 0.011962   Batch Acc: 60.94
[Train] Epoch: 0 [306240/620022]    Loss: 0.008942   Batch Acc: 79.69
[Train] Epoch: 0 [306304/620022]    Loss: 0.009998   Batch Acc: 75.00
[Train] Epoch: 0 [306368/620022]    Loss: 0.010857   Batch Acc: 67.19
[Train] Epoch: 0 [306432/620022]    Loss: 0.008095   Batch Acc: 82.81
[Train] Epoch: 0 [306496/620022]    Loss: 0.013171   Batch Acc: 54.69
[Train] Epoch: 0 [306560/620022]    Loss: 0.008904   Batch Acc: 76.56
[Train] Epoch: 0 [306624/620022]    Loss: 0.011024   Batch Acc: 70.31
[Train] Epoch: 0 [306688/620022]    Loss: 0.008272   Batch Acc: 76.56
[Train] Epoch: 0 [306752/620022]    Loss: 0.010493   Batch Acc: 68.75
[Train] Epoch: 0 [306816/620022]    Loss: 0.009216   Batch Acc: 78.12
[Train] Epoch: 0 [306880/620022]    Loss: 0.010354   Batch Acc: 73.44
[Train] Epoch: 0 [306944/620022]    Loss: 0.010566   Batch Acc: 68.75
[Train] Epoch: 0 [307008/620022]    Loss: 0.009443   Batch Acc: 73.44
[Train] Epoch: 0 [307072/620022]    Loss: 0.009163   Batch Acc: 75.00
[Train] Epoch: 0 [307136/620022]    Loss: 0.010226   Batch Acc: 70.31
[Train] Epoch: 0 [307200/620022]    Loss: 0.008149   Batch Acc: 81.25
[Train] Epoch: 0 [307264/620022]    Loss: 0.008754   Batch Acc: 76.56
[Train] Epoch: 0 [307328/620022]    Loss: 0.011188   Batch Acc: 67.19
[Train] Epoch: 0 [307392/620022]    Loss: 0.009784   Batch Acc: 73.44
[Train] Epoch: 0 [307456/620022]    Loss: 0.007932   Batch Acc: 81.25
[Train] Epoch: 0 [307520/620022]    Loss: 0.009487   Batch Acc: 76.56
[Train] Epoch: 0 [307584/620022]    Loss: 0.009196   Batch Acc: 75.00
[Train] Epoch: 0 [307648/620022]    Loss: 0.008538   Batch Acc: 78.12
[Train] Epoch: 0 [307712/620022]    Loss: 0.008710   Batch Acc: 76.56
[Train] Epoch: 0 [307776/620022]    Loss: 0.008795   Batch Acc: 76.56
[Train] Epoch: 0 [307840/620022]    Loss: 0.008535   Batch Acc: 79.69
[Train] Epoch: 0 [307904/620022]    Loss: 0.010814   Batch Acc: 68.75
[Train] Epoch: 0 [307968/620022]    Loss: 0.008559   Batch Acc: 81.25
[Train] Epoch: 0 [308032/620022]    Loss: 0.008614   Batch Acc: 81.25
[Train] Epoch: 0 [308096/620022]    Loss: 0.008770   Batch Acc: 79.69
[Train] Epoch: 0 [308160/620022]    Loss: 0.007249   Batch Acc: 84.38
[Train] Epoch: 0 [308224/620022]    Loss: 0.007499   Batch Acc: 85.94
[Train] Epoch: 0 [308288/620022]    Loss: 0.009608   Batch Acc: 73.44
[Train] Epoch: 0 [308352/620022]    Loss: 0.008573   Batch Acc: 75.00
[Train] Epoch: 0 [308416/620022]    Loss: 0.007553   Batch Acc: 84.38
[Train] Epoch: 0 [308480/620022]    Loss: 0.008602   Batch Acc: 78.12
[Train] Epoch: 0 [308544/620022]    Loss: 0.011271   Batch Acc: 68.75
[Train] Epoch: 0 [308608/620022]    Loss: 0.009008   Batch Acc: 75.00
[Train] Epoch: 0 [308672/620022]    Loss: 0.007202   Batch Acc: 79.69
[Train] Epoch: 0 [308736/620022]    Loss: 0.010665   Batch Acc: 70.31
[Train] Epoch: 0 [308800/620022]    Loss: 0.008749   Batch Acc: 82.81
[Train] Epoch: 0 [308864/620022]    Loss: 0.009261   Batch Acc: 71.88
[Train] Epoch: 0 [308928/620022]    Loss: 0.007590   Batch Acc: 82.81
[Train] Epoch: 0 [308992/620022]    Loss: 0.008087   Batch Acc: 81.25
[Train] Epoch: 0 [309056/620022]    Loss: 0.007999   Batch Acc: 81.25
[Train] Epoch: 0 [309120/620022]    Loss: 0.008768   Batch Acc: 79.69
[Train] Epoch: 0 [309184/620022]    Loss: 0.008474   Batch Acc: 81.25
[Train] Epoch: 0 [309248/620022]    Loss: 0.009787   Batch Acc: 78.12
[Train] Epoch: 0 [309312/620022]    Loss: 0.006549   Batch Acc: 85.94
[Train] Epoch: 0 [309376/620022]    Loss: 0.007316   Batch Acc: 82.81
[Train] Epoch: 0 [309440/620022]    Loss: 0.008779   Batch Acc: 78.12
[Train] Epoch: 0 [309504/620022]    Loss: 0.008771   Batch Acc: 75.00
[Train] Epoch: 0 [309568/620022]    Loss: 0.008844   Batch Acc: 73.44
[Train] Epoch: 0 [309632/620022]    Loss: 0.010199   Batch Acc: 75.00
[Train] Epoch: 0 [309696/620022]    Loss: 0.008263   Batch Acc: 79.69
[Train] Epoch: 0 [309760/620022]    Loss: 0.010502   Batch Acc: 71.88
[Train] Epoch: 0 [309824/620022]    Loss: 0.008363   Batch Acc: 78.12
[Train] Epoch: 0 [309888/620022]    Loss: 0.010726   Batch Acc: 65.62
[Train] Epoch: 0 [309952/620022]    Loss: 0.009782   Batch Acc: 81.25
[Train] Epoch: 0 [310016/620022]    Loss: 0.009117   Batch Acc: 81.25
[Train] Epoch: 0 [310080/620022]    Loss: 0.009222   Batch Acc: 78.12
[Train] Epoch: 0 [310144/620022]    Loss: 0.010439   Batch Acc: 64.06
[Train] Epoch: 0 [310208/620022]    Loss: 0.009299   Batch Acc: 76.56
[Train] Epoch: 0 [310272/620022]    Loss: 0.007847   Batch Acc: 81.25
[Train] Epoch: 0 [310336/620022]    Loss: 0.007559   Batch Acc: 81.25
[Train] Epoch: 0 [310400/620022]    Loss: 0.009249   Batch Acc: 78.12
[Train] Epoch: 0 [310464/620022]    Loss: 0.007858   Batch Acc: 84.38
[Train] Epoch: 0 [310528/620022]    Loss: 0.008281   Batch Acc: 76.56
[Train] Epoch: 0 [310592/620022]    Loss: 0.009099   Batch Acc: 75.00
[Train] Epoch: 0 [310656/620022]    Loss: 0.009021   Batch Acc: 71.88
[Train] Epoch: 0 [310720/620022]    Loss: 0.007381   Batch Acc: 79.69
[Train] Epoch: 0 [310784/620022]    Loss: 0.008863   Batch Acc: 76.56
[Train] Epoch: 0 [310848/620022]    Loss: 0.010797   Batch Acc: 68.75
[Train] Epoch: 0 [310912/620022]    Loss: 0.009907   Batch Acc: 78.12
[Train] Epoch: 0 [310976/620022]    Loss: 0.008186   Batch Acc: 87.50
[Train] Epoch: 0 [311040/620022]    Loss: 0.010950   Batch Acc: 71.88
[Train] Epoch: 0 [311104/620022]    Loss: 0.009830   Batch Acc: 75.00
[Train] Epoch: 0 [311168/620022]    Loss: 0.010714   Batch Acc: 67.19
[Train] Epoch: 0 [311232/620022]    Loss: 0.008713   Batch Acc: 78.12
[Train] Epoch: 0 [311296/620022]    Loss: 0.008392   Batch Acc: 79.69
[Train] Epoch: 0 [311360/620022]    Loss: 0.010055   Batch Acc: 79.69
[Train] Epoch: 0 [311424/620022]    Loss: 0.010878   Batch Acc: 68.75
[Train] Epoch: 0 [311488/620022]    Loss: 0.011613   Batch Acc: 68.75
[Train] Epoch: 0 [311552/620022]    Loss: 0.006922   Batch Acc: 84.38
[Train] Epoch: 0 [311616/620022]    Loss: 0.008988   Batch Acc: 75.00
[Train] Epoch: 0 [311680/620022]    Loss: 0.010531   Batch Acc: 71.88
[Train] Epoch: 0 [311744/620022]    Loss: 0.008406   Batch Acc: 82.81
[Train] Epoch: 0 [311808/620022]    Loss: 0.008967   Batch Acc: 82.81
[Train] Epoch: 0 [311872/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 0 [311936/620022]    Loss: 0.008493   Batch Acc: 81.25
[Train] Epoch: 0 [312000/620022]    Loss: 0.007211   Batch Acc: 84.38
[Train] Epoch: 0 [312064/620022]    Loss: 0.009253   Batch Acc: 78.12
[Train] Epoch: 0 [312128/620022]    Loss: 0.010852   Batch Acc: 70.31
[Train] Epoch: 0 [312192/620022]    Loss: 0.009593   Batch Acc: 75.00
[Train] Epoch: 0 [312256/620022]    Loss: 0.009960   Batch Acc: 75.00
[Train] Epoch: 0 [312320/620022]    Loss: 0.007640   Batch Acc: 78.12
[Train] Epoch: 0 [312384/620022]    Loss: 0.009844   Batch Acc: 73.44
[Train] Epoch: 0 [312448/620022]    Loss: 0.009337   Batch Acc: 68.75
[Train] Epoch: 0 [312512/620022]    Loss: 0.005707   Batch Acc: 89.06
[Train] Epoch: 0 [312576/620022]    Loss: 0.010475   Batch Acc: 68.75
[Train] Epoch: 0 [312640/620022]    Loss: 0.009911   Batch Acc: 71.88
[Train] Epoch: 0 [312704/620022]    Loss: 0.012659   Batch Acc: 62.50
[Train] Epoch: 0 [312768/620022]    Loss: 0.007258   Batch Acc: 81.25
[Train] Epoch: 0 [312832/620022]    Loss: 0.011281   Batch Acc: 79.69
[Train] Epoch: 0 [312896/620022]    Loss: 0.009294   Batch Acc: 73.44
[Train] Epoch: 0 [312960/620022]    Loss: 0.009271   Batch Acc: 73.44
[Train] Epoch: 0 [313024/620022]    Loss: 0.007925   Batch Acc: 79.69
[Train] Epoch: 0 [313088/620022]    Loss: 0.009934   Batch Acc: 73.44
[Train] Epoch: 0 [313152/620022]    Loss: 0.008616   Batch Acc: 73.44
[Train] Epoch: 0 [313216/620022]    Loss: 0.011299   Batch Acc: 64.06
[Train] Epoch: 0 [313280/620022]    Loss: 0.010391   Batch Acc: 73.44
[Train] Epoch: 0 [313344/620022]    Loss: 0.008422   Batch Acc: 79.69
[Train] Epoch: 0 [313408/620022]    Loss: 0.009848   Batch Acc: 78.12
[Train] Epoch: 0 [313472/620022]    Loss: 0.006452   Batch Acc: 90.62
[Train] Epoch: 0 [313536/620022]    Loss: 0.009221   Batch Acc: 70.31
[Train] Epoch: 0 [313600/620022]    Loss: 0.008737   Batch Acc: 76.56
[Train] Epoch: 0 [313664/620022]    Loss: 0.008336   Batch Acc: 81.25
[Train] Epoch: 0 [313728/620022]    Loss: 0.006850   Batch Acc: 84.38
[Train] Epoch: 0 [313792/620022]    Loss: 0.007202   Batch Acc: 79.69
[Train] Epoch: 0 [313856/620022]    Loss: 0.010076   Batch Acc: 70.31
[Train] Epoch: 0 [313920/620022]    Loss: 0.010553   Batch Acc: 67.19
[Train] Epoch: 0 [313984/620022]    Loss: 0.009279   Batch Acc: 79.69
[Train] Epoch: 0 [314048/620022]    Loss: 0.011054   Batch Acc: 73.44
[Train] Epoch: 0 [314112/620022]    Loss: 0.009898   Batch Acc: 75.00
[Train] Epoch: 0 [314176/620022]    Loss: 0.007237   Batch Acc: 84.38
[Train] Epoch: 0 [314240/620022]    Loss: 0.009499   Batch Acc: 82.81
[Train] Epoch: 0 [314304/620022]    Loss: 0.009412   Batch Acc: 78.12
[Train] Epoch: 0 [314368/620022]    Loss: 0.009329   Batch Acc: 78.12
[Train] Epoch: 0 [314432/620022]    Loss: 0.012232   Batch Acc: 62.50
[Train] Epoch: 0 [314496/620022]    Loss: 0.012611   Batch Acc: 62.50
[Train] Epoch: 0 [314560/620022]    Loss: 0.010833   Batch Acc: 68.75
[Train] Epoch: 0 [314624/620022]    Loss: 0.008749   Batch Acc: 81.25
[Train] Epoch: 0 [314688/620022]    Loss: 0.011497   Batch Acc: 71.88
[Train] Epoch: 0 [314752/620022]    Loss: 0.007010   Batch Acc: 84.38
[Train] Epoch: 0 [314816/620022]    Loss: 0.008633   Batch Acc: 87.50
[Train] Epoch: 0 [314880/620022]    Loss: 0.008845   Batch Acc: 79.69
[Train] Epoch: 0 [314944/620022]    Loss: 0.009409   Batch Acc: 81.25
[Train] Epoch: 0 [315008/620022]    Loss: 0.007046   Batch Acc: 81.25
[Train] Epoch: 0 [315072/620022]    Loss: 0.009318   Batch Acc: 76.56
[Train] Epoch: 0 [315136/620022]    Loss: 0.008494   Batch Acc: 76.56
[Train] Epoch: 0 [315200/620022]    Loss: 0.009753   Batch Acc: 71.88
[Train] Epoch: 0 [315264/620022]    Loss: 0.006453   Batch Acc: 87.50
[Train] Epoch: 0 [315328/620022]    Loss: 0.007682   Batch Acc: 79.69
[Train] Epoch: 0 [315392/620022]    Loss: 0.009016   Batch Acc: 75.00
[Train] Epoch: 0 [315456/620022]    Loss: 0.008577   Batch Acc: 76.56
[Train] Epoch: 0 [315520/620022]    Loss: 0.007617   Batch Acc: 79.69
[Train] Epoch: 0 [315584/620022]    Loss: 0.009941   Batch Acc: 68.75
[Train] Epoch: 0 [315648/620022]    Loss: 0.010390   Batch Acc: 68.75
[Train] Epoch: 0 [315712/620022]    Loss: 0.009377   Batch Acc: 79.69
[Train] Epoch: 0 [315776/620022]    Loss: 0.009227   Batch Acc: 78.12
[Train] Epoch: 0 [315840/620022]    Loss: 0.008514   Batch Acc: 76.56
[Train] Epoch: 0 [315904/620022]    Loss: 0.008010   Batch Acc: 78.12
[Train] Epoch: 0 [315968/620022]    Loss: 0.008910   Batch Acc: 71.88
[Train] Epoch: 0 [316032/620022]    Loss: 0.009028   Batch Acc: 81.25
[Train] Epoch: 0 [316096/620022]    Loss: 0.007510   Batch Acc: 85.94
[Train] Epoch: 0 [316160/620022]    Loss: 0.008081   Batch Acc: 79.69
[Train] Epoch: 0 [316224/620022]    Loss: 0.008239   Batch Acc: 76.56
[Train] Epoch: 0 [316288/620022]    Loss: 0.007897   Batch Acc: 78.12
[Train] Epoch: 0 [316352/620022]    Loss: 0.009337   Batch Acc: 78.12
[Train] Epoch: 0 [316416/620022]    Loss: 0.011255   Batch Acc: 65.62
[Train] Epoch: 0 [316480/620022]    Loss: 0.008698   Batch Acc: 79.69
[Train] Epoch: 0 [316544/620022]    Loss: 0.008992   Batch Acc: 78.12
[Train] Epoch: 0 [316608/620022]    Loss: 0.009661   Batch Acc: 75.00
[Train] Epoch: 0 [316672/620022]    Loss: 0.008277   Batch Acc: 76.56
[Train] Epoch: 0 [316736/620022]    Loss: 0.009656   Batch Acc: 78.12
[Train] Epoch: 0 [316800/620022]    Loss: 0.007188   Batch Acc: 87.50
[Train] Epoch: 0 [316864/620022]    Loss: 0.007115   Batch Acc: 84.38
[Train] Epoch: 0 [316928/620022]    Loss: 0.010589   Batch Acc: 73.44
[Train] Epoch: 0 [316992/620022]    Loss: 0.008311   Batch Acc: 78.12
[Train] Epoch: 0 [317056/620022]    Loss: 0.009158   Batch Acc: 75.00
[Train] Epoch: 0 [317120/620022]    Loss: 0.008664   Batch Acc: 75.00
[Train] Epoch: 0 [317184/620022]    Loss: 0.008571   Batch Acc: 75.00
[Train] Epoch: 0 [317248/620022]    Loss: 0.007974   Batch Acc: 79.69
[Train] Epoch: 0 [317312/620022]    Loss: 0.006187   Batch Acc: 87.50
[Train] Epoch: 0 [317376/620022]    Loss: 0.010592   Batch Acc: 73.44
[Train] Epoch: 0 [317440/620022]    Loss: 0.009181   Batch Acc: 75.00
[Train] Epoch: 0 [317504/620022]    Loss: 0.008268   Batch Acc: 75.00
[Train] Epoch: 0 [317568/620022]    Loss: 0.010954   Batch Acc: 68.75
[Train] Epoch: 0 [317632/620022]    Loss: 0.006510   Batch Acc: 92.19
[Train] Epoch: 0 [317696/620022]    Loss: 0.011204   Batch Acc: 62.50
[Train] Epoch: 0 [317760/620022]    Loss: 0.008992   Batch Acc: 73.44
[Train] Epoch: 0 [317824/620022]    Loss: 0.009873   Batch Acc: 67.19
[Train] Epoch: 0 [317888/620022]    Loss: 0.010128   Batch Acc: 71.88
[Train] Epoch: 0 [317952/620022]    Loss: 0.008385   Batch Acc: 82.81
[Train] Epoch: 0 [318016/620022]    Loss: 0.010028   Batch Acc: 73.44
[Train] Epoch: 0 [318080/620022]    Loss: 0.007824   Batch Acc: 79.69
[Train] Epoch: 0 [318144/620022]    Loss: 0.006712   Batch Acc: 82.81
[Train] Epoch: 0 [318208/620022]    Loss: 0.009601   Batch Acc: 75.00
[Train] Epoch: 0 [318272/620022]    Loss: 0.009207   Batch Acc: 68.75
[Train] Epoch: 0 [318336/620022]    Loss: 0.011242   Batch Acc: 68.75
[Train] Epoch: 0 [318400/620022]    Loss: 0.009108   Batch Acc: 71.88
[Train] Epoch: 0 [318464/620022]    Loss: 0.009632   Batch Acc: 75.00
[Train] Epoch: 0 [318528/620022]    Loss: 0.009957   Batch Acc: 75.00
[Train] Epoch: 0 [318592/620022]    Loss: 0.008826   Batch Acc: 76.56
[Train] Epoch: 0 [318656/620022]    Loss: 0.007950   Batch Acc: 82.81
[Train] Epoch: 0 [318720/620022]    Loss: 0.008182   Batch Acc: 78.12
[Train] Epoch: 0 [318784/620022]    Loss: 0.010006   Batch Acc: 78.12
[Train] Epoch: 0 [318848/620022]    Loss: 0.006885   Batch Acc: 85.94
[Train] Epoch: 0 [318912/620022]    Loss: 0.009900   Batch Acc: 76.56
[Train] Epoch: 0 [318976/620022]    Loss: 0.006663   Batch Acc: 84.38
[Train] Epoch: 0 [319040/620022]    Loss: 0.009438   Batch Acc: 75.00
[Train] Epoch: 0 [319104/620022]    Loss: 0.009925   Batch Acc: 70.31
[Train] Epoch: 0 [319168/620022]    Loss: 0.008301   Batch Acc: 79.69
[Train] Epoch: 0 [319232/620022]    Loss: 0.009324   Batch Acc: 78.12
[Train] Epoch: 0 [319296/620022]    Loss: 0.010102   Batch Acc: 73.44
[Train] Epoch: 0 [319360/620022]    Loss: 0.011952   Batch Acc: 64.06
[Train] Epoch: 0 [319424/620022]    Loss: 0.009715   Batch Acc: 73.44
[Train] Epoch: 0 [319488/620022]    Loss: 0.010872   Batch Acc: 68.75
[Train] Epoch: 0 [319552/620022]    Loss: 0.011591   Batch Acc: 70.31
[Train] Epoch: 0 [319616/620022]    Loss: 0.007615   Batch Acc: 82.81
[Train] Epoch: 0 [319680/620022]    Loss: 0.011846   Batch Acc: 62.50
[Train] Epoch: 0 [319744/620022]    Loss: 0.009359   Batch Acc: 70.31
[Train] Epoch: 0 [319808/620022]    Loss: 0.010262   Batch Acc: 73.44
[Train] Epoch: 0 [319872/620022]    Loss: 0.009946   Batch Acc: 70.31
[Train] Epoch: 0 [319936/620022]    Loss: 0.008617   Batch Acc: 78.12
[Train] Epoch: 0 [320000/620022]    Loss: 0.008704   Batch Acc: 84.38
[Train] Epoch: 0 [320064/620022]    Loss: 0.009140   Batch Acc: 71.88
[Train] Epoch: 0 [320128/620022]    Loss: 0.006553   Batch Acc: 85.94
[Train] Epoch: 0 [320192/620022]    Loss: 0.008541   Batch Acc: 75.00
[Train] Epoch: 0 [320256/620022]    Loss: 0.009469   Batch Acc: 71.88
[Train] Epoch: 0 [320320/620022]    Loss: 0.009031   Batch Acc: 75.00
[Train] Epoch: 0 [320384/620022]    Loss: 0.008727   Batch Acc: 79.69
[Train] Epoch: 0 [320448/620022]    Loss: 0.011328   Batch Acc: 68.75
[Train] Epoch: 0 [320512/620022]    Loss: 0.010454   Batch Acc: 73.44
[Train] Epoch: 0 [320576/620022]    Loss: 0.009679   Batch Acc: 73.44
[Train] Epoch: 0 [320640/620022]    Loss: 0.009339   Batch Acc: 71.88
[Train] Epoch: 0 [320704/620022]    Loss: 0.009337   Batch Acc: 82.81
[Train] Epoch: 0 [320768/620022]    Loss: 0.009802   Batch Acc: 73.44
[Train] Epoch: 0 [320832/620022]    Loss: 0.009998   Batch Acc: 76.56
[Train] Epoch: 0 [320896/620022]    Loss: 0.010670   Batch Acc: 68.75
[Train] Epoch: 0 [320960/620022]    Loss: 0.006839   Batch Acc: 87.50
[Train] Epoch: 0 [321024/620022]    Loss: 0.010004   Batch Acc: 73.44
[Train] Epoch: 0 [321088/620022]    Loss: 0.009695   Batch Acc: 70.31
[Train] Epoch: 0 [321152/620022]    Loss: 0.008065   Batch Acc: 78.12
[Train] Epoch: 0 [321216/620022]    Loss: 0.009070   Batch Acc: 71.88
[Train] Epoch: 0 [321280/620022]    Loss: 0.009086   Batch Acc: 78.12
[Train] Epoch: 0 [321344/620022]    Loss: 0.009952   Batch Acc: 68.75
[Train] Epoch: 0 [321408/620022]    Loss: 0.008602   Batch Acc: 76.56
[Train] Epoch: 0 [321472/620022]    Loss: 0.010505   Batch Acc: 76.56
[Train] Epoch: 0 [321536/620022]    Loss: 0.010010   Batch Acc: 73.44
[Train] Epoch: 0 [321600/620022]    Loss: 0.007247   Batch Acc: 84.38
[Train] Epoch: 0 [321664/620022]    Loss: 0.011698   Batch Acc: 73.44
[Train] Epoch: 0 [321728/620022]    Loss: 0.010645   Batch Acc: 68.75
[Train] Epoch: 0 [321792/620022]    Loss: 0.009882   Batch Acc: 75.00
[Train] Epoch: 0 [321856/620022]    Loss: 0.012194   Batch Acc: 65.62
[Train] Epoch: 0 [321920/620022]    Loss: 0.006910   Batch Acc: 89.06
[Train] Epoch: 0 [321984/620022]    Loss: 0.008825   Batch Acc: 76.56
[Train] Epoch: 0 [322048/620022]    Loss: 0.008618   Batch Acc: 85.94
[Train] Epoch: 0 [322112/620022]    Loss: 0.009101   Batch Acc: 75.00
[Train] Epoch: 0 [322176/620022]    Loss: 0.008565   Batch Acc: 75.00
[Train] Epoch: 0 [322240/620022]    Loss: 0.008103   Batch Acc: 81.25
[Train] Epoch: 0 [322304/620022]    Loss: 0.010242   Batch Acc: 68.75
[Train] Epoch: 0 [322368/620022]    Loss: 0.009000   Batch Acc: 73.44
[Train] Epoch: 0 [322432/620022]    Loss: 0.008617   Batch Acc: 81.25
[Train] Epoch: 0 [322496/620022]    Loss: 0.008612   Batch Acc: 82.81
[Train] Epoch: 0 [322560/620022]    Loss: 0.007908   Batch Acc: 82.81
[Train] Epoch: 0 [322624/620022]    Loss: 0.009965   Batch Acc: 76.56
[Train] Epoch: 0 [322688/620022]    Loss: 0.007936   Batch Acc: 81.25
[Train] Epoch: 0 [322752/620022]    Loss: 0.008485   Batch Acc: 73.44
[Train] Epoch: 0 [322816/620022]    Loss: 0.010944   Batch Acc: 73.44
[Train] Epoch: 0 [322880/620022]    Loss: 0.009774   Batch Acc: 68.75
[Train] Epoch: 0 [322944/620022]    Loss: 0.007074   Batch Acc: 84.38
[Train] Epoch: 0 [323008/620022]    Loss: 0.009213   Batch Acc: 73.44
[Train] Epoch: 0 [323072/620022]    Loss: 0.007629   Batch Acc: 81.25
[Train] Epoch: 0 [323136/620022]    Loss: 0.008144   Batch Acc: 78.12
[Train] Epoch: 0 [323200/620022]    Loss: 0.010162   Batch Acc: 73.44
[Train] Epoch: 0 [323264/620022]    Loss: 0.008647   Batch Acc: 78.12
[Train] Epoch: 0 [323328/620022]    Loss: 0.011216   Batch Acc: 65.62
[Train] Epoch: 0 [323392/620022]    Loss: 0.008981   Batch Acc: 78.12
[Train] Epoch: 0 [323456/620022]    Loss: 0.010360   Batch Acc: 73.44
[Train] Epoch: 0 [323520/620022]    Loss: 0.010659   Batch Acc: 70.31
[Train] Epoch: 0 [323584/620022]    Loss: 0.009217   Batch Acc: 76.56
[Train] Epoch: 0 [323648/620022]    Loss: 0.008601   Batch Acc: 82.81
[Train] Epoch: 0 [323712/620022]    Loss: 0.008483   Batch Acc: 78.12
[Train] Epoch: 0 [323776/620022]    Loss: 0.008783   Batch Acc: 76.56
[Train] Epoch: 0 [323840/620022]    Loss: 0.010001   Batch Acc: 75.00
[Train] Epoch: 0 [323904/620022]    Loss: 0.010252   Batch Acc: 70.31
[Train] Epoch: 0 [323968/620022]    Loss: 0.009123   Batch Acc: 70.31
[Train] Epoch: 0 [324032/620022]    Loss: 0.009970   Batch Acc: 70.31
[Train] Epoch: 0 [324096/620022]    Loss: 0.010065   Batch Acc: 81.25
[Train] Epoch: 0 [324160/620022]    Loss: 0.007979   Batch Acc: 81.25
[Train] Epoch: 0 [324224/620022]    Loss: 0.008733   Batch Acc: 78.12
[Train] Epoch: 0 [324288/620022]    Loss: 0.009327   Batch Acc: 75.00
[Train] Epoch: 0 [324352/620022]    Loss: 0.009236   Batch Acc: 79.69
[Train] Epoch: 0 [324416/620022]    Loss: 0.009742   Batch Acc: 76.56
[Train] Epoch: 0 [324480/620022]    Loss: 0.009363   Batch Acc: 75.00
[Train] Epoch: 0 [324544/620022]    Loss: 0.007591   Batch Acc: 82.81
[Train] Epoch: 0 [324608/620022]    Loss: 0.008543   Batch Acc: 78.12
[Train] Epoch: 0 [324672/620022]    Loss: 0.009061   Batch Acc: 75.00
[Train] Epoch: 0 [324736/620022]    Loss: 0.010677   Batch Acc: 68.75
[Train] Epoch: 0 [324800/620022]    Loss: 0.010825   Batch Acc: 75.00
[Train] Epoch: 0 [324864/620022]    Loss: 0.009087   Batch Acc: 73.44
[Train] Epoch: 0 [324928/620022]    Loss: 0.010244   Batch Acc: 65.62
[Train] Epoch: 0 [324992/620022]    Loss: 0.009549   Batch Acc: 78.12
[Train] Epoch: 0 [325056/620022]    Loss: 0.007677   Batch Acc: 78.12
[Train] Epoch: 0 [325120/620022]    Loss: 0.009737   Batch Acc: 78.12
[Train] Epoch: 0 [325184/620022]    Loss: 0.008267   Batch Acc: 79.69
[Train] Epoch: 0 [325248/620022]    Loss: 0.008359   Batch Acc: 78.12
[Train] Epoch: 0 [325312/620022]    Loss: 0.008162   Batch Acc: 78.12
[Train] Epoch: 0 [325376/620022]    Loss: 0.010327   Batch Acc: 70.31
[Train] Epoch: 0 [325440/620022]    Loss: 0.008780   Batch Acc: 75.00
[Train] Epoch: 0 [325504/620022]    Loss: 0.009159   Batch Acc: 78.12
[Train] Epoch: 0 [325568/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 0 [325632/620022]    Loss: 0.010575   Batch Acc: 67.19
[Train] Epoch: 0 [325696/620022]    Loss: 0.010638   Batch Acc: 71.88
[Train] Epoch: 0 [325760/620022]    Loss: 0.009475   Batch Acc: 76.56
[Train] Epoch: 0 [325824/620022]    Loss: 0.008690   Batch Acc: 70.31
[Train] Epoch: 0 [325888/620022]    Loss: 0.011363   Batch Acc: 75.00
[Train] Epoch: 0 [325952/620022]    Loss: 0.009254   Batch Acc: 76.56
[Train] Epoch: 0 [326016/620022]    Loss: 0.007056   Batch Acc: 85.94
[Train] Epoch: 0 [326080/620022]    Loss: 0.009439   Batch Acc: 76.56
[Train] Epoch: 0 [326144/620022]    Loss: 0.008396   Batch Acc: 78.12
[Train] Epoch: 0 [326208/620022]    Loss: 0.009888   Batch Acc: 75.00
[Train] Epoch: 0 [326272/620022]    Loss: 0.007105   Batch Acc: 82.81
[Train] Epoch: 0 [326336/620022]    Loss: 0.010630   Batch Acc: 70.31
[Train] Epoch: 0 [326400/620022]    Loss: 0.007805   Batch Acc: 78.12
[Train] Epoch: 0 [326464/620022]    Loss: 0.012487   Batch Acc: 71.88
[Train] Epoch: 0 [326528/620022]    Loss: 0.010364   Batch Acc: 73.44
[Train] Epoch: 0 [326592/620022]    Loss: 0.010148   Batch Acc: 71.88
[Train] Epoch: 0 [326656/620022]    Loss: 0.007728   Batch Acc: 78.12
[Train] Epoch: 0 [326720/620022]    Loss: 0.007360   Batch Acc: 81.25
[Train] Epoch: 0 [326784/620022]    Loss: 0.010564   Batch Acc: 68.75
[Train] Epoch: 0 [326848/620022]    Loss: 0.008353   Batch Acc: 79.69
[Train] Epoch: 0 [326912/620022]    Loss: 0.008314   Batch Acc: 79.69
[Train] Epoch: 0 [326976/620022]    Loss: 0.006794   Batch Acc: 84.38
[Train] Epoch: 0 [327040/620022]    Loss: 0.006305   Batch Acc: 85.94
[Train] Epoch: 0 [327104/620022]    Loss: 0.009462   Batch Acc: 78.12
[Train] Epoch: 0 [327168/620022]    Loss: 0.009040   Batch Acc: 79.69
[Train] Epoch: 0 [327232/620022]    Loss: 0.010112   Batch Acc: 71.88
[Train] Epoch: 0 [327296/620022]    Loss: 0.008508   Batch Acc: 82.81
[Train] Epoch: 0 [327360/620022]    Loss: 0.008206   Batch Acc: 76.56
[Train] Epoch: 0 [327424/620022]    Loss: 0.010393   Batch Acc: 75.00
[Train] Epoch: 0 [327488/620022]    Loss: 0.010143   Batch Acc: 71.88
[Train] Epoch: 0 [327552/620022]    Loss: 0.006954   Batch Acc: 84.38
[Train] Epoch: 0 [327616/620022]    Loss: 0.008056   Batch Acc: 76.56
[Train] Epoch: 0 [327680/620022]    Loss: 0.009044   Batch Acc: 71.88
[Train] Epoch: 0 [327744/620022]    Loss: 0.011132   Batch Acc: 65.62
[Train] Epoch: 0 [327808/620022]    Loss: 0.010005   Batch Acc: 78.12
[Train] Epoch: 0 [327872/620022]    Loss: 0.009861   Batch Acc: 75.00
[Train] Epoch: 0 [327936/620022]    Loss: 0.009412   Batch Acc: 71.88
[Train] Epoch: 0 [328000/620022]    Loss: 0.008367   Batch Acc: 76.56
[Train] Epoch: 0 [328064/620022]    Loss: 0.007909   Batch Acc: 84.38
[Train] Epoch: 0 [328128/620022]    Loss: 0.011588   Batch Acc: 62.50
[Train] Epoch: 0 [328192/620022]    Loss: 0.008825   Batch Acc: 78.12
[Train] Epoch: 0 [328256/620022]    Loss: 0.008120   Batch Acc: 81.25
[Train] Epoch: 0 [328320/620022]    Loss: 0.009235   Batch Acc: 78.12
[Train] Epoch: 0 [328384/620022]    Loss: 0.008163   Batch Acc: 79.69
[Train] Epoch: 0 [328448/620022]    Loss: 0.011130   Batch Acc: 73.44
[Train] Epoch: 0 [328512/620022]    Loss: 0.007659   Batch Acc: 82.81
[Train] Epoch: 0 [328576/620022]    Loss: 0.008603   Batch Acc: 76.56
[Train] Epoch: 0 [328640/620022]    Loss: 0.009760   Batch Acc: 75.00
[Train] Epoch: 0 [328704/620022]    Loss: 0.009395   Batch Acc: 78.12
[Train] Epoch: 0 [328768/620022]    Loss: 0.009232   Batch Acc: 78.12
[Train] Epoch: 0 [328832/620022]    Loss: 0.010316   Batch Acc: 70.31
[Train] Epoch: 0 [328896/620022]    Loss: 0.009111   Batch Acc: 76.56
[Train] Epoch: 0 [328960/620022]    Loss: 0.010607   Batch Acc: 73.44
[Train] Epoch: 0 [329024/620022]    Loss: 0.009684   Batch Acc: 73.44
[Train] Epoch: 0 [329088/620022]    Loss: 0.009396   Batch Acc: 76.56
[Train] Epoch: 0 [329152/620022]    Loss: 0.009377   Batch Acc: 73.44
[Train] Epoch: 0 [329216/620022]    Loss: 0.011522   Batch Acc: 70.31
[Train] Epoch: 0 [329280/620022]    Loss: 0.010313   Batch Acc: 78.12
[Train] Epoch: 0 [329344/620022]    Loss: 0.008473   Batch Acc: 76.56
[Train] Epoch: 0 [329408/620022]    Loss: 0.008524   Batch Acc: 79.69
[Train] Epoch: 0 [329472/620022]    Loss: 0.006086   Batch Acc: 90.62
[Train] Epoch: 0 [329536/620022]    Loss: 0.009347   Batch Acc: 70.31
[Train] Epoch: 0 [329600/620022]    Loss: 0.011238   Batch Acc: 73.44
[Train] Epoch: 0 [329664/620022]    Loss: 0.008493   Batch Acc: 79.69
[Train] Epoch: 0 [329728/620022]    Loss: 0.009276   Batch Acc: 75.00
[Train] Epoch: 0 [329792/620022]    Loss: 0.007287   Batch Acc: 84.38
[Train] Epoch: 0 [329856/620022]    Loss: 0.009381   Batch Acc: 81.25
[Train] Epoch: 0 [329920/620022]    Loss: 0.007918   Batch Acc: 81.25
[Train] Epoch: 0 [329984/620022]    Loss: 0.009916   Batch Acc: 71.88
[Train] Epoch: 0 [330048/620022]    Loss: 0.011446   Batch Acc: 71.88
[Train] Epoch: 0 [330112/620022]    Loss: 0.009829   Batch Acc: 76.56
[Train] Epoch: 0 [330176/620022]    Loss: 0.008263   Batch Acc: 78.12
[Train] Epoch: 0 [330240/620022]    Loss: 0.010809   Batch Acc: 68.75
[Train] Epoch: 0 [330304/620022]    Loss: 0.010198   Batch Acc: 70.31
[Train] Epoch: 0 [330368/620022]    Loss: 0.009691   Batch Acc: 78.12
[Train] Epoch: 0 [330432/620022]    Loss: 0.008260   Batch Acc: 81.25
[Train] Epoch: 0 [330496/620022]    Loss: 0.008542   Batch Acc: 78.12
[Train] Epoch: 0 [330560/620022]    Loss: 0.008243   Batch Acc: 82.81
[Train] Epoch: 0 [330624/620022]    Loss: 0.007550   Batch Acc: 82.81
[Train] Epoch: 0 [330688/620022]    Loss: 0.009149   Batch Acc: 82.81
[Train] Epoch: 0 [330752/620022]    Loss: 0.009958   Batch Acc: 71.88
[Train] Epoch: 0 [330816/620022]    Loss: 0.008977   Batch Acc: 73.44
[Train] Epoch: 0 [330880/620022]    Loss: 0.009232   Batch Acc: 76.56
[Train] Epoch: 0 [330944/620022]    Loss: 0.007975   Batch Acc: 76.56
[Train] Epoch: 0 [331008/620022]    Loss: 0.007932   Batch Acc: 81.25
[Train] Epoch: 0 [331072/620022]    Loss: 0.010693   Batch Acc: 70.31
[Train] Epoch: 0 [331136/620022]    Loss: 0.009957   Batch Acc: 76.56
[Train] Epoch: 0 [331200/620022]    Loss: 0.007340   Batch Acc: 84.38
[Train] Epoch: 0 [331264/620022]    Loss: 0.007817   Batch Acc: 82.81
[Train] Epoch: 0 [331328/620022]    Loss: 0.008907   Batch Acc: 81.25
[Train] Epoch: 0 [331392/620022]    Loss: 0.008224   Batch Acc: 81.25
[Train] Epoch: 0 [331456/620022]    Loss: 0.006004   Batch Acc: 90.62
[Train] Epoch: 0 [331520/620022]    Loss: 0.008223   Batch Acc: 84.38
[Train] Epoch: 0 [331584/620022]    Loss: 0.008597   Batch Acc: 75.00
[Train] Epoch: 0 [331648/620022]    Loss: 0.009168   Batch Acc: 76.56
[Train] Epoch: 0 [331712/620022]    Loss: 0.008032   Batch Acc: 76.56
[Train] Epoch: 0 [331776/620022]    Loss: 0.013296   Batch Acc: 65.62
[Train] Epoch: 0 [331840/620022]    Loss: 0.007889   Batch Acc: 79.69
[Train] Epoch: 0 [331904/620022]    Loss: 0.008118   Batch Acc: 79.69
[Train] Epoch: 0 [331968/620022]    Loss: 0.009703   Batch Acc: 70.31
[Train] Epoch: 0 [332032/620022]    Loss: 0.009358   Batch Acc: 81.25
[Train] Epoch: 0 [332096/620022]    Loss: 0.008607   Batch Acc: 78.12
[Train] Epoch: 0 [332160/620022]    Loss: 0.008483   Batch Acc: 79.69
[Train] Epoch: 0 [332224/620022]    Loss: 0.007237   Batch Acc: 82.81
[Train] Epoch: 0 [332288/620022]    Loss: 0.011085   Batch Acc: 70.31
[Train] Epoch: 0 [332352/620022]    Loss: 0.009668   Batch Acc: 71.88
[Train] Epoch: 0 [332416/620022]    Loss: 0.008621   Batch Acc: 73.44
[Train] Epoch: 0 [332480/620022]    Loss: 0.009129   Batch Acc: 75.00
[Train] Epoch: 0 [332544/620022]    Loss: 0.011373   Batch Acc: 68.75
[Train] Epoch: 0 [332608/620022]    Loss: 0.007520   Batch Acc: 82.81
[Train] Epoch: 0 [332672/620022]    Loss: 0.008991   Batch Acc: 76.56
[Train] Epoch: 0 [332736/620022]    Loss: 0.010119   Batch Acc: 78.12
[Train] Epoch: 0 [332800/620022]    Loss: 0.008393   Batch Acc: 79.69
[Train] Epoch: 0 [332864/620022]    Loss: 0.009332   Batch Acc: 76.56
[Train] Epoch: 0 [332928/620022]    Loss: 0.010306   Batch Acc: 78.12
[Train] Epoch: 0 [332992/620022]    Loss: 0.009637   Batch Acc: 73.44
[Train] Epoch: 0 [333056/620022]    Loss: 0.010508   Batch Acc: 71.88
[Train] Epoch: 0 [333120/620022]    Loss: 0.011695   Batch Acc: 75.00
[Train] Epoch: 0 [333184/620022]    Loss: 0.009670   Batch Acc: 70.31
[Train] Epoch: 0 [333248/620022]    Loss: 0.011690   Batch Acc: 70.31
[Train] Epoch: 0 [333312/620022]    Loss: 0.009291   Batch Acc: 71.88
[Train] Epoch: 0 [333376/620022]    Loss: 0.009448   Batch Acc: 73.44
[Train] Epoch: 0 [333440/620022]    Loss: 0.009929   Batch Acc: 75.00
[Train] Epoch: 0 [333504/620022]    Loss: 0.008744   Batch Acc: 79.69
[Train] Epoch: 0 [333568/620022]    Loss: 0.009736   Batch Acc: 70.31
[Train] Epoch: 0 [333632/620022]    Loss: 0.009527   Batch Acc: 79.69
[Train] Epoch: 0 [333696/620022]    Loss: 0.008358   Batch Acc: 75.00
[Train] Epoch: 0 [333760/620022]    Loss: 0.007750   Batch Acc: 81.25
[Train] Epoch: 0 [333824/620022]    Loss: 0.011596   Batch Acc: 71.88
[Train] Epoch: 0 [333888/620022]    Loss: 0.007739   Batch Acc: 82.81
[Train] Epoch: 0 [333952/620022]    Loss: 0.009199   Batch Acc: 73.44
[Train] Epoch: 0 [334016/620022]    Loss: 0.009146   Batch Acc: 81.25
[Train] Epoch: 0 [334080/620022]    Loss: 0.008308   Batch Acc: 78.12
[Train] Epoch: 0 [334144/620022]    Loss: 0.010066   Batch Acc: 70.31
[Train] Epoch: 0 [334208/620022]    Loss: 0.009703   Batch Acc: 68.75
[Train] Epoch: 0 [334272/620022]    Loss: 0.008933   Batch Acc: 76.56
[Train] Epoch: 0 [334336/620022]    Loss: 0.009482   Batch Acc: 75.00
[Train] Epoch: 0 [334400/620022]    Loss: 0.007287   Batch Acc: 82.81
[Train] Epoch: 0 [334464/620022]    Loss: 0.007709   Batch Acc: 81.25
[Train] Epoch: 0 [334528/620022]    Loss: 0.009613   Batch Acc: 78.12
[Train] Epoch: 0 [334592/620022]    Loss: 0.007560   Batch Acc: 84.38
[Train] Epoch: 0 [334656/620022]    Loss: 0.009221   Batch Acc: 78.12
[Train] Epoch: 0 [334720/620022]    Loss: 0.006862   Batch Acc: 85.94
[Train] Epoch: 0 [334784/620022]    Loss: 0.010696   Batch Acc: 76.56
[Train] Epoch: 0 [334848/620022]    Loss: 0.009196   Batch Acc: 81.25
[Train] Epoch: 0 [334912/620022]    Loss: 0.010144   Batch Acc: 70.31
[Train] Epoch: 0 [334976/620022]    Loss: 0.010739   Batch Acc: 70.31
[Train] Epoch: 0 [335040/620022]    Loss: 0.007750   Batch Acc: 84.38
[Train] Epoch: 0 [335104/620022]    Loss: 0.008000   Batch Acc: 78.12
[Train] Epoch: 0 [335168/620022]    Loss: 0.009401   Batch Acc: 75.00
[Train] Epoch: 0 [335232/620022]    Loss: 0.007788   Batch Acc: 81.25
[Train] Epoch: 0 [335296/620022]    Loss: 0.008474   Batch Acc: 78.12
[Train] Epoch: 0 [335360/620022]    Loss: 0.009509   Batch Acc: 73.44
[Train] Epoch: 0 [335424/620022]    Loss: 0.008742   Batch Acc: 73.44
[Train] Epoch: 0 [335488/620022]    Loss: 0.007857   Batch Acc: 81.25
[Train] Epoch: 0 [335552/620022]    Loss: 0.010026   Batch Acc: 67.19
[Train] Epoch: 0 [335616/620022]    Loss: 0.010019   Batch Acc: 75.00
[Train] Epoch: 0 [335680/620022]    Loss: 0.009546   Batch Acc: 73.44
[Train] Epoch: 0 [335744/620022]    Loss: 0.009299   Batch Acc: 78.12
[Train] Epoch: 0 [335808/620022]    Loss: 0.008139   Batch Acc: 79.69
[Train] Epoch: 0 [335872/620022]    Loss: 0.008398   Batch Acc: 79.69
[Train] Epoch: 0 [335936/620022]    Loss: 0.008087   Batch Acc: 79.69
[Train] Epoch: 0 [336000/620022]    Loss: 0.009734   Batch Acc: 68.75
[Train] Epoch: 0 [336064/620022]    Loss: 0.010303   Batch Acc: 70.31
[Train] Epoch: 0 [336128/620022]    Loss: 0.008829   Batch Acc: 73.44
[Train] Epoch: 0 [336192/620022]    Loss: 0.011030   Batch Acc: 68.75
[Train] Epoch: 0 [336256/620022]    Loss: 0.009062   Batch Acc: 78.12
[Train] Epoch: 0 [336320/620022]    Loss: 0.007545   Batch Acc: 85.94
[Train] Epoch: 0 [336384/620022]    Loss: 0.012069   Batch Acc: 71.88
[Train] Epoch: 0 [336448/620022]    Loss: 0.009745   Batch Acc: 76.56
[Train] Epoch: 0 [336512/620022]    Loss: 0.006324   Batch Acc: 81.25
[Train] Epoch: 0 [336576/620022]    Loss: 0.009125   Batch Acc: 79.69
[Train] Epoch: 0 [336640/620022]    Loss: 0.010005   Batch Acc: 79.69
[Train] Epoch: 0 [336704/620022]    Loss: 0.007825   Batch Acc: 75.00
[Train] Epoch: 0 [336768/620022]    Loss: 0.009256   Batch Acc: 79.69
[Train] Epoch: 0 [336832/620022]    Loss: 0.009223   Batch Acc: 78.12
[Train] Epoch: 0 [336896/620022]    Loss: 0.008223   Batch Acc: 76.56
[Train] Epoch: 0 [336960/620022]    Loss: 0.010106   Batch Acc: 75.00
[Train] Epoch: 0 [337024/620022]    Loss: 0.010058   Batch Acc: 78.12
[Train] Epoch: 0 [337088/620022]    Loss: 0.008056   Batch Acc: 79.69
[Train] Epoch: 0 [337152/620022]    Loss: 0.010784   Batch Acc: 71.88
[Train] Epoch: 0 [337216/620022]    Loss: 0.007690   Batch Acc: 78.12
[Train] Epoch: 0 [337280/620022]    Loss: 0.008136   Batch Acc: 81.25
[Train] Epoch: 0 [337344/620022]    Loss: 0.009098   Batch Acc: 71.88
[Train] Epoch: 0 [337408/620022]    Loss: 0.005981   Batch Acc: 89.06
[Train] Epoch: 0 [337472/620022]    Loss: 0.009796   Batch Acc: 73.44
[Train] Epoch: 0 [337536/620022]    Loss: 0.009408   Batch Acc: 82.81
[Train] Epoch: 0 [337600/620022]    Loss: 0.009516   Batch Acc: 71.88
[Train] Epoch: 0 [337664/620022]    Loss: 0.009554   Batch Acc: 73.44
[Train] Epoch: 0 [337728/620022]    Loss: 0.010953   Batch Acc: 73.44
[Train] Epoch: 0 [337792/620022]    Loss: 0.011717   Batch Acc: 67.19
[Train] Epoch: 0 [337856/620022]    Loss: 0.010000   Batch Acc: 76.56
[Train] Epoch: 0 [337920/620022]    Loss: 0.009669   Batch Acc: 71.88
[Train] Epoch: 0 [337984/620022]    Loss: 0.007244   Batch Acc: 76.56
[Train] Epoch: 0 [338048/620022]    Loss: 0.007970   Batch Acc: 79.69
[Train] Epoch: 0 [338112/620022]    Loss: 0.010022   Batch Acc: 68.75
[Train] Epoch: 0 [338176/620022]    Loss: 0.009394   Batch Acc: 73.44
[Train] Epoch: 0 [338240/620022]    Loss: 0.009439   Batch Acc: 78.12
[Train] Epoch: 0 [338304/620022]    Loss: 0.009500   Batch Acc: 75.00
[Train] Epoch: 0 [338368/620022]    Loss: 0.010743   Batch Acc: 68.75
[Train] Epoch: 0 [338432/620022]    Loss: 0.008371   Batch Acc: 79.69
[Train] Epoch: 0 [338496/620022]    Loss: 0.008815   Batch Acc: 76.56
[Train] Epoch: 0 [338560/620022]    Loss: 0.008446   Batch Acc: 76.56
[Train] Epoch: 0 [338624/620022]    Loss: 0.008268   Batch Acc: 79.69
[Train] Epoch: 0 [338688/620022]    Loss: 0.010204   Batch Acc: 70.31
[Train] Epoch: 0 [338752/620022]    Loss: 0.009540   Batch Acc: 70.31
[Train] Epoch: 0 [338816/620022]    Loss: 0.009252   Batch Acc: 71.88
[Train] Epoch: 0 [338880/620022]    Loss: 0.010492   Batch Acc: 73.44
[Train] Epoch: 0 [338944/620022]    Loss: 0.008806   Batch Acc: 79.69
[Train] Epoch: 0 [339008/620022]    Loss: 0.009193   Batch Acc: 78.12
[Train] Epoch: 0 [339072/620022]    Loss: 0.009508   Batch Acc: 75.00
[Train] Epoch: 0 [339136/620022]    Loss: 0.008479   Batch Acc: 78.12
[Train] Epoch: 0 [339200/620022]    Loss: 0.008376   Batch Acc: 76.56
[Train] Epoch: 0 [339264/620022]    Loss: 0.009966   Batch Acc: 76.56
[Train] Epoch: 0 [339328/620022]    Loss: 0.008338   Batch Acc: 76.56
[Train] Epoch: 0 [339392/620022]    Loss: 0.008230   Batch Acc: 84.38
[Train] Epoch: 0 [339456/620022]    Loss: 0.008865   Batch Acc: 71.88
[Train] Epoch: 0 [339520/620022]    Loss: 0.007891   Batch Acc: 79.69
[Train] Epoch: 0 [339584/620022]    Loss: 0.008134   Batch Acc: 79.69
[Train] Epoch: 0 [339648/620022]    Loss: 0.009708   Batch Acc: 79.69
[Train] Epoch: 0 [339712/620022]    Loss: 0.009067   Batch Acc: 73.44
[Train] Epoch: 0 [339776/620022]    Loss: 0.010157   Batch Acc: 75.00
[Train] Epoch: 0 [339840/620022]    Loss: 0.009391   Batch Acc: 78.12
[Train] Epoch: 0 [339904/620022]    Loss: 0.009684   Batch Acc: 79.69
[Train] Epoch: 0 [339968/620022]    Loss: 0.010349   Batch Acc: 73.44
[Train] Epoch: 0 [340032/620022]    Loss: 0.009845   Batch Acc: 76.56
[Train] Epoch: 0 [340096/620022]    Loss: 0.010941   Batch Acc: 67.19
[Train] Epoch: 0 [340160/620022]    Loss: 0.010188   Batch Acc: 76.56
[Train] Epoch: 0 [340224/620022]    Loss: 0.007257   Batch Acc: 85.94
[Train] Epoch: 0 [340288/620022]    Loss: 0.009541   Batch Acc: 75.00
[Train] Epoch: 0 [340352/620022]    Loss: 0.008638   Batch Acc: 82.81
[Train] Epoch: 0 [340416/620022]    Loss: 0.008969   Batch Acc: 75.00
[Train] Epoch: 0 [340480/620022]    Loss: 0.009082   Batch Acc: 73.44
[Train] Epoch: 0 [340544/620022]    Loss: 0.010125   Batch Acc: 73.44
[Train] Epoch: 0 [340608/620022]    Loss: 0.009891   Batch Acc: 76.56
[Train] Epoch: 0 [340672/620022]    Loss: 0.009293   Batch Acc: 73.44
[Train] Epoch: 0 [340736/620022]    Loss: 0.008665   Batch Acc: 75.00
[Train] Epoch: 0 [340800/620022]    Loss: 0.009896   Batch Acc: 73.44
[Train] Epoch: 0 [340864/620022]    Loss: 0.008413   Batch Acc: 78.12
[Train] Epoch: 0 [340928/620022]    Loss: 0.010213   Batch Acc: 71.88
[Train] Epoch: 0 [340992/620022]    Loss: 0.010237   Batch Acc: 76.56
[Train] Epoch: 0 [341056/620022]    Loss: 0.010908   Batch Acc: 60.94
[Train] Epoch: 0 [341120/620022]    Loss: 0.009736   Batch Acc: 71.88
[Train] Epoch: 0 [341184/620022]    Loss: 0.007190   Batch Acc: 79.69
[Train] Epoch: 0 [341248/620022]    Loss: 0.010125   Batch Acc: 70.31
[Train] Epoch: 0 [341312/620022]    Loss: 0.009973   Batch Acc: 71.88
[Train] Epoch: 0 [341376/620022]    Loss: 0.008310   Batch Acc: 81.25
[Train] Epoch: 0 [341440/620022]    Loss: 0.007379   Batch Acc: 81.25
[Train] Epoch: 0 [341504/620022]    Loss: 0.008798   Batch Acc: 76.56
[Train] Epoch: 0 [341568/620022]    Loss: 0.007816   Batch Acc: 79.69
[Train] Epoch: 0 [341632/620022]    Loss: 0.010520   Batch Acc: 73.44
[Train] Epoch: 0 [341696/620022]    Loss: 0.008334   Batch Acc: 79.69
[Train] Epoch: 0 [341760/620022]    Loss: 0.008925   Batch Acc: 81.25
[Train] Epoch: 0 [341824/620022]    Loss: 0.008208   Batch Acc: 81.25
[Train] Epoch: 0 [341888/620022]    Loss: 0.007448   Batch Acc: 85.94
[Train] Epoch: 0 [341952/620022]    Loss: 0.007874   Batch Acc: 82.81
[Train] Epoch: 0 [342016/620022]    Loss: 0.008602   Batch Acc: 76.56
[Train] Epoch: 0 [342080/620022]    Loss: 0.009547   Batch Acc: 73.44
[Train] Epoch: 0 [342144/620022]    Loss: 0.007732   Batch Acc: 79.69
[Train] Epoch: 0 [342208/620022]    Loss: 0.010391   Batch Acc: 71.88
[Train] Epoch: 0 [342272/620022]    Loss: 0.008176   Batch Acc: 75.00
[Train] Epoch: 0 [342336/620022]    Loss: 0.009425   Batch Acc: 73.44
[Train] Epoch: 0 [342400/620022]    Loss: 0.008171   Batch Acc: 75.00
[Train] Epoch: 0 [342464/620022]    Loss: 0.007927   Batch Acc: 82.81
[Train] Epoch: 0 [342528/620022]    Loss: 0.010826   Batch Acc: 71.88
[Train] Epoch: 0 [342592/620022]    Loss: 0.007296   Batch Acc: 81.25
[Train] Epoch: 0 [342656/620022]    Loss: 0.008684   Batch Acc: 81.25
[Train] Epoch: 0 [342720/620022]    Loss: 0.008263   Batch Acc: 84.38
[Train] Epoch: 0 [342784/620022]    Loss: 0.009722   Batch Acc: 79.69
[Train] Epoch: 0 [342848/620022]    Loss: 0.009796   Batch Acc: 75.00
[Train] Epoch: 0 [342912/620022]    Loss: 0.010362   Batch Acc: 78.12
[Train] Epoch: 0 [342976/620022]    Loss: 0.009749   Batch Acc: 76.56
[Train] Epoch: 0 [343040/620022]    Loss: 0.009783   Batch Acc: 71.88
[Train] Epoch: 0 [343104/620022]    Loss: 0.007867   Batch Acc: 82.81
[Train] Epoch: 0 [343168/620022]    Loss: 0.011533   Batch Acc: 76.56
[Train] Epoch: 0 [343232/620022]    Loss: 0.008666   Batch Acc: 76.56
[Train] Epoch: 0 [343296/620022]    Loss: 0.010444   Batch Acc: 73.44
[Train] Epoch: 0 [343360/620022]    Loss: 0.009132   Batch Acc: 78.12
[Train] Epoch: 0 [343424/620022]    Loss: 0.009879   Batch Acc: 73.44
[Train] Epoch: 0 [343488/620022]    Loss: 0.009851   Batch Acc: 76.56
[Train] Epoch: 0 [343552/620022]    Loss: 0.009412   Batch Acc: 75.00
[Train] Epoch: 0 [343616/620022]    Loss: 0.009139   Batch Acc: 73.44
[Train] Epoch: 0 [343680/620022]    Loss: 0.009190   Batch Acc: 79.69
[Train] Epoch: 0 [343744/620022]    Loss: 0.007494   Batch Acc: 84.38
[Train] Epoch: 0 [343808/620022]    Loss: 0.008774   Batch Acc: 82.81
[Train] Epoch: 0 [343872/620022]    Loss: 0.008400   Batch Acc: 76.56
[Train] Epoch: 0 [343936/620022]    Loss: 0.010848   Batch Acc: 70.31
[Train] Epoch: 0 [344000/620022]    Loss: 0.010828   Batch Acc: 73.44
[Train] Epoch: 0 [344064/620022]    Loss: 0.008704   Batch Acc: 70.31
[Train] Epoch: 0 [344128/620022]    Loss: 0.010382   Batch Acc: 70.31
[Train] Epoch: 0 [344192/620022]    Loss: 0.008294   Batch Acc: 76.56
[Train] Epoch: 0 [344256/620022]    Loss: 0.009272   Batch Acc: 73.44
[Train] Epoch: 0 [344320/620022]    Loss: 0.009405   Batch Acc: 76.56
[Train] Epoch: 0 [344384/620022]    Loss: 0.008350   Batch Acc: 78.12
[Train] Epoch: 0 [344448/620022]    Loss: 0.009497   Batch Acc: 76.56
[Train] Epoch: 0 [344512/620022]    Loss: 0.008744   Batch Acc: 78.12
[Train] Epoch: 0 [344576/620022]    Loss: 0.008273   Batch Acc: 78.12
[Train] Epoch: 0 [344640/620022]    Loss: 0.008861   Batch Acc: 75.00
[Train] Epoch: 0 [344704/620022]    Loss: 0.008813   Batch Acc: 78.12
[Train] Epoch: 0 [344768/620022]    Loss: 0.011723   Batch Acc: 65.62
[Train] Epoch: 0 [344832/620022]    Loss: 0.009844   Batch Acc: 70.31
[Train] Epoch: 0 [344896/620022]    Loss: 0.010308   Batch Acc: 75.00
[Train] Epoch: 0 [344960/620022]    Loss: 0.007468   Batch Acc: 78.12
[Train] Epoch: 0 [345024/620022]    Loss: 0.008137   Batch Acc: 81.25
[Train] Epoch: 0 [345088/620022]    Loss: 0.008732   Batch Acc: 76.56
[Train] Epoch: 0 [345152/620022]    Loss: 0.009740   Batch Acc: 79.69
[Train] Epoch: 0 [345216/620022]    Loss: 0.010058   Batch Acc: 71.88
[Train] Epoch: 0 [345280/620022]    Loss: 0.008618   Batch Acc: 71.88
[Train] Epoch: 0 [345344/620022]    Loss: 0.008917   Batch Acc: 76.56
[Train] Epoch: 0 [345408/620022]    Loss: 0.007068   Batch Acc: 84.38
[Train] Epoch: 0 [345472/620022]    Loss: 0.008799   Batch Acc: 78.12
[Train] Epoch: 0 [345536/620022]    Loss: 0.007615   Batch Acc: 76.56
[Train] Epoch: 0 [345600/620022]    Loss: 0.007885   Batch Acc: 75.00
[Train] Epoch: 0 [345664/620022]    Loss: 0.010436   Batch Acc: 68.75
[Train] Epoch: 0 [345728/620022]    Loss: 0.006879   Batch Acc: 84.38
[Train] Epoch: 0 [345792/620022]    Loss: 0.008024   Batch Acc: 78.12
[Train] Epoch: 0 [345856/620022]    Loss: 0.009443   Batch Acc: 78.12
[Train] Epoch: 0 [345920/620022]    Loss: 0.009743   Batch Acc: 75.00
[Train] Epoch: 0 [345984/620022]    Loss: 0.008356   Batch Acc: 73.44
[Train] Epoch: 0 [346048/620022]    Loss: 0.011997   Batch Acc: 65.62
[Train] Epoch: 0 [346112/620022]    Loss: 0.009218   Batch Acc: 68.75
[Train] Epoch: 0 [346176/620022]    Loss: 0.008613   Batch Acc: 78.12
[Train] Epoch: 0 [346240/620022]    Loss: 0.009289   Batch Acc: 81.25
[Train] Epoch: 0 [346304/620022]    Loss: 0.008203   Batch Acc: 78.12
[Train] Epoch: 0 [346368/620022]    Loss: 0.008216   Batch Acc: 78.12
[Train] Epoch: 0 [346432/620022]    Loss: 0.008151   Batch Acc: 79.69
[Train] Epoch: 0 [346496/620022]    Loss: 0.010599   Batch Acc: 73.44
[Train] Epoch: 0 [346560/620022]    Loss: 0.008523   Batch Acc: 81.25
[Train] Epoch: 0 [346624/620022]    Loss: 0.008731   Batch Acc: 75.00
[Train] Epoch: 0 [346688/620022]    Loss: 0.008398   Batch Acc: 85.94
[Train] Epoch: 0 [346752/620022]    Loss: 0.011291   Batch Acc: 68.75
[Train] Epoch: 0 [346816/620022]    Loss: 0.008878   Batch Acc: 71.88
[Train] Epoch: 0 [346880/620022]    Loss: 0.008814   Batch Acc: 81.25
[Train] Epoch: 0 [346944/620022]    Loss: 0.009340   Batch Acc: 68.75
[Train] Epoch: 0 [347008/620022]    Loss: 0.011779   Batch Acc: 70.31
[Train] Epoch: 0 [347072/620022]    Loss: 0.009870   Batch Acc: 73.44
[Train] Epoch: 0 [347136/620022]    Loss: 0.008881   Batch Acc: 65.62
[Train] Epoch: 0 [347200/620022]    Loss: 0.008542   Batch Acc: 79.69
[Train] Epoch: 0 [347264/620022]    Loss: 0.010248   Batch Acc: 73.44
[Train] Epoch: 0 [347328/620022]    Loss: 0.009815   Batch Acc: 70.31
[Train] Epoch: 0 [347392/620022]    Loss: 0.008945   Batch Acc: 75.00
[Train] Epoch: 0 [347456/620022]    Loss: 0.007721   Batch Acc: 78.12
[Train] Epoch: 0 [347520/620022]    Loss: 0.009717   Batch Acc: 68.75
[Train] Epoch: 0 [347584/620022]    Loss: 0.007663   Batch Acc: 84.38
[Train] Epoch: 0 [347648/620022]    Loss: 0.008750   Batch Acc: 76.56
[Train] Epoch: 0 [347712/620022]    Loss: 0.008661   Batch Acc: 73.44
[Train] Epoch: 0 [347776/620022]    Loss: 0.008554   Batch Acc: 73.44
[Train] Epoch: 0 [347840/620022]    Loss: 0.009682   Batch Acc: 71.88
[Train] Epoch: 0 [347904/620022]    Loss: 0.007847   Batch Acc: 84.38
[Train] Epoch: 0 [347968/620022]    Loss: 0.008771   Batch Acc: 76.56
[Train] Epoch: 0 [348032/620022]    Loss: 0.007704   Batch Acc: 82.81
[Train] Epoch: 0 [348096/620022]    Loss: 0.008652   Batch Acc: 76.56
[Train] Epoch: 0 [348160/620022]    Loss: 0.011565   Batch Acc: 73.44
[Train] Epoch: 0 [348224/620022]    Loss: 0.007979   Batch Acc: 82.81
[Train] Epoch: 0 [348288/620022]    Loss: 0.010478   Batch Acc: 71.88
[Train] Epoch: 0 [348352/620022]    Loss: 0.012747   Batch Acc: 68.75
[Train] Epoch: 0 [348416/620022]    Loss: 0.009874   Batch Acc: 75.00
[Train] Epoch: 0 [348480/620022]    Loss: 0.010218   Batch Acc: 73.44
[Train] Epoch: 0 [348544/620022]    Loss: 0.007912   Batch Acc: 79.69
[Train] Epoch: 0 [348608/620022]    Loss: 0.009545   Batch Acc: 68.75
[Train] Epoch: 0 [348672/620022]    Loss: 0.008036   Batch Acc: 79.69
[Train] Epoch: 0 [348736/620022]    Loss: 0.010244   Batch Acc: 76.56
[Train] Epoch: 0 [348800/620022]    Loss: 0.007861   Batch Acc: 84.38
[Train] Epoch: 0 [348864/620022]    Loss: 0.008707   Batch Acc: 73.44
[Train] Epoch: 0 [348928/620022]    Loss: 0.007388   Batch Acc: 84.38
[Train] Epoch: 0 [348992/620022]    Loss: 0.008275   Batch Acc: 71.88
[Train] Epoch: 0 [349056/620022]    Loss: 0.009973   Batch Acc: 76.56
[Train] Epoch: 0 [349120/620022]    Loss: 0.008860   Batch Acc: 76.56
[Train] Epoch: 0 [349184/620022]    Loss: 0.005873   Batch Acc: 92.19
[Train] Epoch: 0 [349248/620022]    Loss: 0.008516   Batch Acc: 79.69
[Train] Epoch: 0 [349312/620022]    Loss: 0.011713   Batch Acc: 71.88
[Train] Epoch: 0 [349376/620022]    Loss: 0.007801   Batch Acc: 82.81
[Train] Epoch: 0 [349440/620022]    Loss: 0.008292   Batch Acc: 79.69
[Train] Epoch: 0 [349504/620022]    Loss: 0.008893   Batch Acc: 81.25
[Train] Epoch: 0 [349568/620022]    Loss: 0.010619   Batch Acc: 73.44
[Train] Epoch: 0 [349632/620022]    Loss: 0.009940   Batch Acc: 71.88
[Train] Epoch: 0 [349696/620022]    Loss: 0.010093   Batch Acc: 78.12
[Train] Epoch: 0 [349760/620022]    Loss: 0.009696   Batch Acc: 78.12
[Train] Epoch: 0 [349824/620022]    Loss: 0.012174   Batch Acc: 67.19
[Train] Epoch: 0 [349888/620022]    Loss: 0.007637   Batch Acc: 84.38
[Train] Epoch: 0 [349952/620022]    Loss: 0.010423   Batch Acc: 68.75
[Train] Epoch: 0 [350016/620022]    Loss: 0.008256   Batch Acc: 81.25
[Train] Epoch: 0 [350080/620022]    Loss: 0.008369   Batch Acc: 76.56
[Train] Epoch: 0 [350144/620022]    Loss: 0.009941   Batch Acc: 73.44
[Train] Epoch: 0 [350208/620022]    Loss: 0.011170   Batch Acc: 70.31
[Train] Epoch: 0 [350272/620022]    Loss: 0.008591   Batch Acc: 82.81
[Train] Epoch: 0 [350336/620022]    Loss: 0.011394   Batch Acc: 70.31
[Train] Epoch: 0 [350400/620022]    Loss: 0.006350   Batch Acc: 81.25
[Train] Epoch: 0 [350464/620022]    Loss: 0.010237   Batch Acc: 70.31
[Train] Epoch: 0 [350528/620022]    Loss: 0.009487   Batch Acc: 79.69
[Train] Epoch: 0 [350592/620022]    Loss: 0.007749   Batch Acc: 81.25
[Train] Epoch: 0 [350656/620022]    Loss: 0.008358   Batch Acc: 79.69
[Train] Epoch: 0 [350720/620022]    Loss: 0.010375   Batch Acc: 75.00
[Train] Epoch: 0 [350784/620022]    Loss: 0.008866   Batch Acc: 73.44
[Train] Epoch: 0 [350848/620022]    Loss: 0.010284   Batch Acc: 76.56
[Train] Epoch: 0 [350912/620022]    Loss: 0.007153   Batch Acc: 84.38
[Train] Epoch: 0 [350976/620022]    Loss: 0.009598   Batch Acc: 73.44
[Train] Epoch: 0 [351040/620022]    Loss: 0.009354   Batch Acc: 76.56
[Train] Epoch: 0 [351104/620022]    Loss: 0.008993   Batch Acc: 76.56
[Train] Epoch: 0 [351168/620022]    Loss: 0.007798   Batch Acc: 76.56
[Train] Epoch: 0 [351232/620022]    Loss: 0.010149   Batch Acc: 68.75
[Train] Epoch: 0 [351296/620022]    Loss: 0.009886   Batch Acc: 75.00
[Train] Epoch: 0 [351360/620022]    Loss: 0.007611   Batch Acc: 81.25
[Train] Epoch: 0 [351424/620022]    Loss: 0.008405   Batch Acc: 75.00
[Train] Epoch: 0 [351488/620022]    Loss: 0.008795   Batch Acc: 78.12
[Train] Epoch: 0 [351552/620022]    Loss: 0.009914   Batch Acc: 71.88
[Train] Epoch: 0 [351616/620022]    Loss: 0.009794   Batch Acc: 75.00
[Train] Epoch: 0 [351680/620022]    Loss: 0.007770   Batch Acc: 81.25
[Train] Epoch: 0 [351744/620022]    Loss: 0.008069   Batch Acc: 71.88
[Train] Epoch: 0 [351808/620022]    Loss: 0.009056   Batch Acc: 76.56
[Train] Epoch: 0 [351872/620022]    Loss: 0.010282   Batch Acc: 70.31
[Train] Epoch: 0 [351936/620022]    Loss: 0.009029   Batch Acc: 78.12
[Train] Epoch: 0 [352000/620022]    Loss: 0.006875   Batch Acc: 85.94
[Train] Epoch: 0 [352064/620022]    Loss: 0.009252   Batch Acc: 76.56
[Train] Epoch: 0 [352128/620022]    Loss: 0.008323   Batch Acc: 82.81
[Train] Epoch: 0 [352192/620022]    Loss: 0.008849   Batch Acc: 75.00
[Train] Epoch: 0 [352256/620022]    Loss: 0.009268   Batch Acc: 76.56
[Train] Epoch: 0 [352320/620022]    Loss: 0.008730   Batch Acc: 78.12
[Train] Epoch: 0 [352384/620022]    Loss: 0.008918   Batch Acc: 71.88
[Train] Epoch: 0 [352448/620022]    Loss: 0.008518   Batch Acc: 78.12
[Train] Epoch: 0 [352512/620022]    Loss: 0.005945   Batch Acc: 82.81
[Train] Epoch: 0 [352576/620022]    Loss: 0.008318   Batch Acc: 75.00
[Train] Epoch: 0 [352640/620022]    Loss: 0.009472   Batch Acc: 76.56
[Train] Epoch: 0 [352704/620022]    Loss: 0.010788   Batch Acc: 75.00
[Train] Epoch: 0 [352768/620022]    Loss: 0.008820   Batch Acc: 73.44
[Train] Epoch: 0 [352832/620022]    Loss: 0.007036   Batch Acc: 82.81
[Train] Epoch: 0 [352896/620022]    Loss: 0.008063   Batch Acc: 78.12
[Train] Epoch: 0 [352960/620022]    Loss: 0.009187   Batch Acc: 82.81
[Train] Epoch: 0 [353024/620022]    Loss: 0.007518   Batch Acc: 79.69
[Train] Epoch: 0 [353088/620022]    Loss: 0.008880   Batch Acc: 76.56
[Train] Epoch: 0 [353152/620022]    Loss: 0.008121   Batch Acc: 75.00
[Train] Epoch: 0 [353216/620022]    Loss: 0.009480   Batch Acc: 76.56
[Train] Epoch: 0 [353280/620022]    Loss: 0.009864   Batch Acc: 78.12
[Train] Epoch: 0 [353344/620022]    Loss: 0.008099   Batch Acc: 82.81
[Train] Epoch: 0 [353408/620022]    Loss: 0.008965   Batch Acc: 75.00
[Train] Epoch: 0 [353472/620022]    Loss: 0.008517   Batch Acc: 75.00
[Train] Epoch: 0 [353536/620022]    Loss: 0.009728   Batch Acc: 75.00
[Train] Epoch: 0 [353600/620022]    Loss: 0.007848   Batch Acc: 81.25
[Train] Epoch: 0 [353664/620022]    Loss: 0.009053   Batch Acc: 75.00
[Train] Epoch: 0 [353728/620022]    Loss: 0.009958   Batch Acc: 76.56
[Train] Epoch: 0 [353792/620022]    Loss: 0.010279   Batch Acc: 73.44
[Train] Epoch: 0 [353856/620022]    Loss: 0.009349   Batch Acc: 78.12
[Train] Epoch: 0 [353920/620022]    Loss: 0.009417   Batch Acc: 75.00
[Train] Epoch: 0 [353984/620022]    Loss: 0.009343   Batch Acc: 76.56
[Train] Epoch: 0 [354048/620022]    Loss: 0.008333   Batch Acc: 81.25
[Train] Epoch: 0 [354112/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 0 [354176/620022]    Loss: 0.009640   Batch Acc: 78.12
[Train] Epoch: 0 [354240/620022]    Loss: 0.011206   Batch Acc: 71.88
[Train] Epoch: 0 [354304/620022]    Loss: 0.007841   Batch Acc: 82.81
[Train] Epoch: 0 [354368/620022]    Loss: 0.009663   Batch Acc: 71.88
[Train] Epoch: 0 [354432/620022]    Loss: 0.007368   Batch Acc: 84.38
[Train] Epoch: 0 [354496/620022]    Loss: 0.010545   Batch Acc: 65.62
[Train] Epoch: 0 [354560/620022]    Loss: 0.007684   Batch Acc: 78.12
[Train] Epoch: 0 [354624/620022]    Loss: 0.009609   Batch Acc: 71.88
[Train] Epoch: 0 [354688/620022]    Loss: 0.009152   Batch Acc: 76.56
[Train] Epoch: 0 [354752/620022]    Loss: 0.007297   Batch Acc: 84.38
[Train] Epoch: 0 [354816/620022]    Loss: 0.009248   Batch Acc: 71.88
[Train] Epoch: 0 [354880/620022]    Loss: 0.008005   Batch Acc: 78.12
[Train] Epoch: 0 [354944/620022]    Loss: 0.009885   Batch Acc: 70.31
[Train] Epoch: 0 [355008/620022]    Loss: 0.010198   Batch Acc: 73.44
[Train] Epoch: 0 [355072/620022]    Loss: 0.010383   Batch Acc: 73.44
[Train] Epoch: 0 [355136/620022]    Loss: 0.008048   Batch Acc: 79.69
[Train] Epoch: 0 [355200/620022]    Loss: 0.008703   Batch Acc: 79.69
[Train] Epoch: 0 [355264/620022]    Loss: 0.008361   Batch Acc: 71.88
[Train] Epoch: 0 [355328/620022]    Loss: 0.011649   Batch Acc: 67.19
[Train] Epoch: 0 [355392/620022]    Loss: 0.009956   Batch Acc: 81.25
[Train] Epoch: 0 [355456/620022]    Loss: 0.008964   Batch Acc: 75.00
[Train] Epoch: 0 [355520/620022]    Loss: 0.009592   Batch Acc: 78.12
[Train] Epoch: 0 [355584/620022]    Loss: 0.010090   Batch Acc: 70.31
[Train] Epoch: 0 [355648/620022]    Loss: 0.008219   Batch Acc: 76.56
[Train] Epoch: 0 [355712/620022]    Loss: 0.008688   Batch Acc: 84.38
[Train] Epoch: 0 [355776/620022]    Loss: 0.009956   Batch Acc: 78.12
[Train] Epoch: 0 [355840/620022]    Loss: 0.008526   Batch Acc: 84.38
[Train] Epoch: 0 [355904/620022]    Loss: 0.007681   Batch Acc: 82.81
[Train] Epoch: 0 [355968/620022]    Loss: 0.007926   Batch Acc: 81.25
[Train] Epoch: 0 [356032/620022]    Loss: 0.009385   Batch Acc: 75.00
[Train] Epoch: 0 [356096/620022]    Loss: 0.008316   Batch Acc: 75.00
[Train] Epoch: 0 [356160/620022]    Loss: 0.007012   Batch Acc: 87.50
[Train] Epoch: 0 [356224/620022]    Loss: 0.010323   Batch Acc: 68.75
[Train] Epoch: 0 [356288/620022]    Loss: 0.008015   Batch Acc: 82.81
[Train] Epoch: 0 [356352/620022]    Loss: 0.009310   Batch Acc: 76.56
[Train] Epoch: 0 [356416/620022]    Loss: 0.011642   Batch Acc: 73.44
[Train] Epoch: 0 [356480/620022]    Loss: 0.007880   Batch Acc: 78.12
[Train] Epoch: 0 [356544/620022]    Loss: 0.008025   Batch Acc: 85.94
[Train] Epoch: 0 [356608/620022]    Loss: 0.009022   Batch Acc: 73.44
[Train] Epoch: 0 [356672/620022]    Loss: 0.010440   Batch Acc: 70.31
[Train] Epoch: 0 [356736/620022]    Loss: 0.007764   Batch Acc: 81.25
[Train] Epoch: 0 [356800/620022]    Loss: 0.011584   Batch Acc: 68.75
[Train] Epoch: 0 [356864/620022]    Loss: 0.008111   Batch Acc: 79.69
[Train] Epoch: 0 [356928/620022]    Loss: 0.008647   Batch Acc: 75.00
[Train] Epoch: 0 [356992/620022]    Loss: 0.007545   Batch Acc: 79.69
[Train] Epoch: 0 [357056/620022]    Loss: 0.008700   Batch Acc: 79.69
[Train] Epoch: 0 [357120/620022]    Loss: 0.009768   Batch Acc: 71.88
[Train] Epoch: 0 [357184/620022]    Loss: 0.007968   Batch Acc: 78.12
[Train] Epoch: 0 [357248/620022]    Loss: 0.010786   Batch Acc: 68.75
[Train] Epoch: 0 [357312/620022]    Loss: 0.008159   Batch Acc: 75.00
[Train] Epoch: 0 [357376/620022]    Loss: 0.009150   Batch Acc: 76.56
[Train] Epoch: 0 [357440/620022]    Loss: 0.010087   Batch Acc: 81.25
[Train] Epoch: 0 [357504/620022]    Loss: 0.011275   Batch Acc: 73.44
[Train] Epoch: 0 [357568/620022]    Loss: 0.010925   Batch Acc: 70.31
[Train] Epoch: 0 [357632/620022]    Loss: 0.010150   Batch Acc: 73.44
[Train] Epoch: 0 [357696/620022]    Loss: 0.007508   Batch Acc: 78.12
[Train] Epoch: 0 [357760/620022]    Loss: 0.007577   Batch Acc: 84.38
[Train] Epoch: 0 [357824/620022]    Loss: 0.009357   Batch Acc: 75.00
[Train] Epoch: 0 [357888/620022]    Loss: 0.008923   Batch Acc: 76.56
[Train] Epoch: 0 [357952/620022]    Loss: 0.007155   Batch Acc: 85.94
[Train] Epoch: 0 [358016/620022]    Loss: 0.006684   Batch Acc: 87.50
[Train] Epoch: 0 [358080/620022]    Loss: 0.008607   Batch Acc: 81.25
[Train] Epoch: 0 [358144/620022]    Loss: 0.008185   Batch Acc: 79.69
[Train] Epoch: 0 [358208/620022]    Loss: 0.009311   Batch Acc: 71.88
[Train] Epoch: 0 [358272/620022]    Loss: 0.009326   Batch Acc: 81.25
[Train] Epoch: 0 [358336/620022]    Loss: 0.008551   Batch Acc: 79.69
[Train] Epoch: 0 [358400/620022]    Loss: 0.008158   Batch Acc: 79.69
[Train] Epoch: 0 [358464/620022]    Loss: 0.011451   Batch Acc: 64.06
[Train] Epoch: 0 [358528/620022]    Loss: 0.008378   Batch Acc: 78.12
[Train] Epoch: 0 [358592/620022]    Loss: 0.010099   Batch Acc: 71.88
[Train] Epoch: 0 [358656/620022]    Loss: 0.010828   Batch Acc: 73.44
[Train] Epoch: 0 [358720/620022]    Loss: 0.008244   Batch Acc: 75.00
[Train] Epoch: 0 [358784/620022]    Loss: 0.012139   Batch Acc: 65.62
[Train] Epoch: 0 [358848/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 0 [358912/620022]    Loss: 0.009505   Batch Acc: 71.88
[Train] Epoch: 0 [358976/620022]    Loss: 0.010849   Batch Acc: 70.31
[Train] Epoch: 0 [359040/620022]    Loss: 0.011762   Batch Acc: 71.88
[Train] Epoch: 0 [359104/620022]    Loss: 0.007308   Batch Acc: 81.25
[Train] Epoch: 0 [359168/620022]    Loss: 0.007067   Batch Acc: 79.69
[Train] Epoch: 0 [359232/620022]    Loss: 0.008707   Batch Acc: 79.69
[Train] Epoch: 0 [359296/620022]    Loss: 0.008746   Batch Acc: 75.00
[Train] Epoch: 0 [359360/620022]    Loss: 0.008545   Batch Acc: 82.81
[Train] Epoch: 0 [359424/620022]    Loss: 0.011153   Batch Acc: 65.62
[Train] Epoch: 0 [359488/620022]    Loss: 0.009634   Batch Acc: 75.00
[Train] Epoch: 0 [359552/620022]    Loss: 0.008686   Batch Acc: 75.00
[Train] Epoch: 0 [359616/620022]    Loss: 0.009239   Batch Acc: 76.56
[Train] Epoch: 0 [359680/620022]    Loss: 0.007760   Batch Acc: 81.25
[Train] Epoch: 0 [359744/620022]    Loss: 0.009687   Batch Acc: 73.44
[Train] Epoch: 0 [359808/620022]    Loss: 0.007298   Batch Acc: 81.25
[Train] Epoch: 0 [359872/620022]    Loss: 0.009711   Batch Acc: 78.12
[Train] Epoch: 0 [359936/620022]    Loss: 0.009961   Batch Acc: 76.56
[Train] Epoch: 0 [360000/620022]    Loss: 0.008407   Batch Acc: 76.56
[Train] Epoch: 0 [360064/620022]    Loss: 0.006293   Batch Acc: 89.06
[Train] Epoch: 0 [360128/620022]    Loss: 0.007426   Batch Acc: 82.81
[Train] Epoch: 0 [360192/620022]    Loss: 0.008826   Batch Acc: 79.69
[Train] Epoch: 0 [360256/620022]    Loss: 0.008528   Batch Acc: 76.56
[Train] Epoch: 0 [360320/620022]    Loss: 0.010364   Batch Acc: 78.12
[Train] Epoch: 0 [360384/620022]    Loss: 0.009952   Batch Acc: 78.12
[Train] Epoch: 0 [360448/620022]    Loss: 0.008759   Batch Acc: 79.69
[Train] Epoch: 0 [360512/620022]    Loss: 0.008046   Batch Acc: 82.81
[Train] Epoch: 0 [360576/620022]    Loss: 0.011472   Batch Acc: 70.31
[Train] Epoch: 0 [360640/620022]    Loss: 0.007959   Batch Acc: 78.12
[Train] Epoch: 0 [360704/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 0 [360768/620022]    Loss: 0.009941   Batch Acc: 76.56
[Train] Epoch: 0 [360832/620022]    Loss: 0.009046   Batch Acc: 81.25
[Train] Epoch: 0 [360896/620022]    Loss: 0.007313   Batch Acc: 84.38
[Train] Epoch: 0 [360960/620022]    Loss: 0.006290   Batch Acc: 84.38
[Train] Epoch: 0 [361024/620022]    Loss: 0.008934   Batch Acc: 78.12
[Train] Epoch: 0 [361088/620022]    Loss: 0.010555   Batch Acc: 78.12
[Train] Epoch: 0 [361152/620022]    Loss: 0.008440   Batch Acc: 76.56
[Train] Epoch: 0 [361216/620022]    Loss: 0.008423   Batch Acc: 76.56
[Train] Epoch: 0 [361280/620022]    Loss: 0.010129   Batch Acc: 76.56
[Train] Epoch: 0 [361344/620022]    Loss: 0.009852   Batch Acc: 71.88
[Train] Epoch: 0 [361408/620022]    Loss: 0.009110   Batch Acc: 71.88
[Train] Epoch: 0 [361472/620022]    Loss: 0.009453   Batch Acc: 75.00
[Train] Epoch: 0 [361536/620022]    Loss: 0.009433   Batch Acc: 79.69
[Train] Epoch: 0 [361600/620022]    Loss: 0.008737   Batch Acc: 75.00
[Train] Epoch: 0 [361664/620022]    Loss: 0.010945   Batch Acc: 79.69
[Train] Epoch: 0 [361728/620022]    Loss: 0.007864   Batch Acc: 78.12
[Train] Epoch: 0 [361792/620022]    Loss: 0.009883   Batch Acc: 70.31
[Train] Epoch: 0 [361856/620022]    Loss: 0.009426   Batch Acc: 71.88
[Train] Epoch: 0 [361920/620022]    Loss: 0.008898   Batch Acc: 76.56
[Train] Epoch: 0 [361984/620022]    Loss: 0.008054   Batch Acc: 79.69
[Train] Epoch: 0 [362048/620022]    Loss: 0.007666   Batch Acc: 79.69
[Train] Epoch: 0 [362112/620022]    Loss: 0.008717   Batch Acc: 76.56
[Train] Epoch: 0 [362176/620022]    Loss: 0.009562   Batch Acc: 75.00
[Train] Epoch: 0 [362240/620022]    Loss: 0.008107   Batch Acc: 78.12
[Train] Epoch: 0 [362304/620022]    Loss: 0.008650   Batch Acc: 78.12
[Train] Epoch: 0 [362368/620022]    Loss: 0.011133   Batch Acc: 67.19
[Train] Epoch: 0 [362432/620022]    Loss: 0.007518   Batch Acc: 81.25
[Train] Epoch: 0 [362496/620022]    Loss: 0.008129   Batch Acc: 75.00
[Train] Epoch: 0 [362560/620022]    Loss: 0.011098   Batch Acc: 68.75
[Train] Epoch: 0 [362624/620022]    Loss: 0.010346   Batch Acc: 75.00
[Train] Epoch: 0 [362688/620022]    Loss: 0.009748   Batch Acc: 76.56
[Train] Epoch: 0 [362752/620022]    Loss: 0.010959   Batch Acc: 75.00
[Train] Epoch: 0 [362816/620022]    Loss: 0.007963   Batch Acc: 79.69
[Train] Epoch: 0 [362880/620022]    Loss: 0.008098   Batch Acc: 76.56
[Train] Epoch: 0 [362944/620022]    Loss: 0.009754   Batch Acc: 79.69
[Train] Epoch: 0 [363008/620022]    Loss: 0.009527   Batch Acc: 73.44
[Train] Epoch: 0 [363072/620022]    Loss: 0.007169   Batch Acc: 79.69
[Train] Epoch: 0 [363136/620022]    Loss: 0.007001   Batch Acc: 81.25
[Train] Epoch: 0 [363200/620022]    Loss: 0.008250   Batch Acc: 79.69
[Train] Epoch: 0 [363264/620022]    Loss: 0.010570   Batch Acc: 67.19
[Train] Epoch: 0 [363328/620022]    Loss: 0.007677   Batch Acc: 78.12
[Train] Epoch: 0 [363392/620022]    Loss: 0.007584   Batch Acc: 81.25
[Train] Epoch: 0 [363456/620022]    Loss: 0.007630   Batch Acc: 75.00
[Train] Epoch: 0 [363520/620022]    Loss: 0.010196   Batch Acc: 70.31
[Train] Epoch: 0 [363584/620022]    Loss: 0.011432   Batch Acc: 68.75
[Train] Epoch: 0 [363648/620022]    Loss: 0.007274   Batch Acc: 84.38
[Train] Epoch: 0 [363712/620022]    Loss: 0.009766   Batch Acc: 71.88
[Train] Epoch: 0 [363776/620022]    Loss: 0.009558   Batch Acc: 75.00
[Train] Epoch: 0 [363840/620022]    Loss: 0.009031   Batch Acc: 76.56
[Train] Epoch: 0 [363904/620022]    Loss: 0.007874   Batch Acc: 78.12
[Train] Epoch: 0 [363968/620022]    Loss: 0.010995   Batch Acc: 71.88
[Train] Epoch: 0 [364032/620022]    Loss: 0.006143   Batch Acc: 84.38
[Train] Epoch: 0 [364096/620022]    Loss: 0.010854   Batch Acc: 76.56
[Train] Epoch: 0 [364160/620022]    Loss: 0.008266   Batch Acc: 76.56
[Train] Epoch: 0 [364224/620022]    Loss: 0.011308   Batch Acc: 70.31
[Train] Epoch: 0 [364288/620022]    Loss: 0.009323   Batch Acc: 75.00
[Train] Epoch: 0 [364352/620022]    Loss: 0.008502   Batch Acc: 76.56
[Train] Epoch: 0 [364416/620022]    Loss: 0.010071   Batch Acc: 81.25
[Train] Epoch: 0 [364480/620022]    Loss: 0.010090   Batch Acc: 71.88
[Train] Epoch: 0 [364544/620022]    Loss: 0.009534   Batch Acc: 78.12
[Train] Epoch: 0 [364608/620022]    Loss: 0.007410   Batch Acc: 81.25
[Train] Epoch: 0 [364672/620022]    Loss: 0.009467   Batch Acc: 73.44
[Train] Epoch: 0 [364736/620022]    Loss: 0.008059   Batch Acc: 78.12
[Train] Epoch: 0 [364800/620022]    Loss: 0.008030   Batch Acc: 85.94
[Train] Epoch: 0 [364864/620022]    Loss: 0.010303   Batch Acc: 70.31
[Train] Epoch: 0 [364928/620022]    Loss: 0.008101   Batch Acc: 79.69
[Train] Epoch: 0 [364992/620022]    Loss: 0.008483   Batch Acc: 78.12
[Train] Epoch: 0 [365056/620022]    Loss: 0.011415   Batch Acc: 71.88
[Train] Epoch: 0 [365120/620022]    Loss: 0.010143   Batch Acc: 75.00
[Train] Epoch: 0 [365184/620022]    Loss: 0.008592   Batch Acc: 75.00
[Train] Epoch: 0 [365248/620022]    Loss: 0.007575   Batch Acc: 82.81
[Train] Epoch: 0 [365312/620022]    Loss: 0.010653   Batch Acc: 73.44
[Train] Epoch: 0 [365376/620022]    Loss: 0.009525   Batch Acc: 78.12
[Train] Epoch: 0 [365440/620022]    Loss: 0.009310   Batch Acc: 81.25
[Train] Epoch: 0 [365504/620022]    Loss: 0.010803   Batch Acc: 73.44
[Train] Epoch: 0 [365568/620022]    Loss: 0.010050   Batch Acc: 75.00
[Train] Epoch: 0 [365632/620022]    Loss: 0.011091   Batch Acc: 70.31
[Train] Epoch: 0 [365696/620022]    Loss: 0.009864   Batch Acc: 78.12
[Train] Epoch: 0 [365760/620022]    Loss: 0.008458   Batch Acc: 78.12
[Train] Epoch: 0 [365824/620022]    Loss: 0.008752   Batch Acc: 81.25
[Train] Epoch: 0 [365888/620022]    Loss: 0.008147   Batch Acc: 78.12
[Train] Epoch: 0 [365952/620022]    Loss: 0.010138   Batch Acc: 75.00
[Train] Epoch: 0 [366016/620022]    Loss: 0.008443   Batch Acc: 82.81
[Train] Epoch: 0 [366080/620022]    Loss: 0.009025   Batch Acc: 76.56
[Train] Epoch: 0 [366144/620022]    Loss: 0.007592   Batch Acc: 76.56
[Train] Epoch: 0 [366208/620022]    Loss: 0.012324   Batch Acc: 71.88
[Train] Epoch: 0 [366272/620022]    Loss: 0.006453   Batch Acc: 84.38
[Train] Epoch: 0 [366336/620022]    Loss: 0.010386   Batch Acc: 73.44
[Train] Epoch: 0 [366400/620022]    Loss: 0.007857   Batch Acc: 82.81
[Train] Epoch: 0 [366464/620022]    Loss: 0.008909   Batch Acc: 73.44
[Train] Epoch: 0 [366528/620022]    Loss: 0.008973   Batch Acc: 79.69
[Train] Epoch: 0 [366592/620022]    Loss: 0.008731   Batch Acc: 73.44
[Train] Epoch: 0 [366656/620022]    Loss: 0.008599   Batch Acc: 79.69
[Train] Epoch: 0 [366720/620022]    Loss: 0.009955   Batch Acc: 73.44
[Train] Epoch: 0 [366784/620022]    Loss: 0.008951   Batch Acc: 79.69
[Train] Epoch: 0 [366848/620022]    Loss: 0.007870   Batch Acc: 82.81
[Train] Epoch: 0 [366912/620022]    Loss: 0.011307   Batch Acc: 70.31
[Train] Epoch: 0 [366976/620022]    Loss: 0.008602   Batch Acc: 79.69
[Train] Epoch: 0 [367040/620022]    Loss: 0.008241   Batch Acc: 79.69
[Train] Epoch: 0 [367104/620022]    Loss: 0.009991   Batch Acc: 71.88
[Train] Epoch: 0 [367168/620022]    Loss: 0.007058   Batch Acc: 84.38
[Train] Epoch: 0 [367232/620022]    Loss: 0.010218   Batch Acc: 75.00
[Train] Epoch: 0 [367296/620022]    Loss: 0.007145   Batch Acc: 82.81
[Train] Epoch: 0 [367360/620022]    Loss: 0.008145   Batch Acc: 75.00
[Train] Epoch: 0 [367424/620022]    Loss: 0.007785   Batch Acc: 84.38
[Train] Epoch: 0 [367488/620022]    Loss: 0.008784   Batch Acc: 82.81
[Train] Epoch: 0 [367552/620022]    Loss: 0.010478   Batch Acc: 71.88
[Train] Epoch: 0 [367616/620022]    Loss: 0.008239   Batch Acc: 79.69
[Train] Epoch: 0 [367680/620022]    Loss: 0.010415   Batch Acc: 71.88
[Train] Epoch: 0 [367744/620022]    Loss: 0.010150   Batch Acc: 73.44
[Train] Epoch: 0 [367808/620022]    Loss: 0.011079   Batch Acc: 64.06
[Train] Epoch: 0 [367872/620022]    Loss: 0.007935   Batch Acc: 78.12
[Train] Epoch: 0 [367936/620022]    Loss: 0.008643   Batch Acc: 76.56
[Train] Epoch: 0 [368000/620022]    Loss: 0.010366   Batch Acc: 68.75
[Train] Epoch: 0 [368064/620022]    Loss: 0.008594   Batch Acc: 76.56
[Train] Epoch: 0 [368128/620022]    Loss: 0.006870   Batch Acc: 89.06
[Train] Epoch: 0 [368192/620022]    Loss: 0.009357   Batch Acc: 73.44
[Train] Epoch: 0 [368256/620022]    Loss: 0.010590   Batch Acc: 65.62
[Train] Epoch: 0 [368320/620022]    Loss: 0.008647   Batch Acc: 75.00
[Train] Epoch: 0 [368384/620022]    Loss: 0.010254   Batch Acc: 70.31
[Train] Epoch: 0 [368448/620022]    Loss: 0.010759   Batch Acc: 73.44
[Train] Epoch: 0 [368512/620022]    Loss: 0.008645   Batch Acc: 76.56
[Train] Epoch: 0 [368576/620022]    Loss: 0.010528   Batch Acc: 68.75
[Train] Epoch: 0 [368640/620022]    Loss: 0.009979   Batch Acc: 70.31
[Train] Epoch: 0 [368704/620022]    Loss: 0.007972   Batch Acc: 79.69
[Train] Epoch: 0 [368768/620022]    Loss: 0.009508   Batch Acc: 75.00
[Train] Epoch: 0 [368832/620022]    Loss: 0.009432   Batch Acc: 73.44
[Train] Epoch: 0 [368896/620022]    Loss: 0.011013   Batch Acc: 76.56
[Train] Epoch: 0 [368960/620022]    Loss: 0.007487   Batch Acc: 89.06
[Train] Epoch: 0 [369024/620022]    Loss: 0.009291   Batch Acc: 79.69
[Train] Epoch: 0 [369088/620022]    Loss: 0.010358   Batch Acc: 68.75
[Train] Epoch: 0 [369152/620022]    Loss: 0.009944   Batch Acc: 78.12
[Train] Epoch: 0 [369216/620022]    Loss: 0.008959   Batch Acc: 79.69
[Train] Epoch: 0 [369280/620022]    Loss: 0.008877   Batch Acc: 75.00
[Train] Epoch: 0 [369344/620022]    Loss: 0.010333   Batch Acc: 68.75
[Train] Epoch: 0 [369408/620022]    Loss: 0.008678   Batch Acc: 76.56
[Train] Epoch: 0 [369472/620022]    Loss: 0.009784   Batch Acc: 76.56
[Train] Epoch: 0 [369536/620022]    Loss: 0.008246   Batch Acc: 79.69
[Train] Epoch: 0 [369600/620022]    Loss: 0.011005   Batch Acc: 68.75
[Train] Epoch: 0 [369664/620022]    Loss: 0.010309   Batch Acc: 76.56
[Train] Epoch: 0 [369728/620022]    Loss: 0.010102   Batch Acc: 73.44
[Train] Epoch: 0 [369792/620022]    Loss: 0.010316   Batch Acc: 81.25
[Train] Epoch: 0 [369856/620022]    Loss: 0.010074   Batch Acc: 71.88
[Train] Epoch: 0 [369920/620022]    Loss: 0.007812   Batch Acc: 73.44
[Train] Epoch: 0 [369984/620022]    Loss: 0.009022   Batch Acc: 76.56
[Train] Epoch: 0 [370048/620022]    Loss: 0.008643   Batch Acc: 75.00
[Train] Epoch: 0 [370112/620022]    Loss: 0.007401   Batch Acc: 81.25
[Train] Epoch: 0 [370176/620022]    Loss: 0.007569   Batch Acc: 82.81
[Train] Epoch: 0 [370240/620022]    Loss: 0.009970   Batch Acc: 73.44
[Train] Epoch: 0 [370304/620022]    Loss: 0.010481   Batch Acc: 68.75
[Train] Epoch: 0 [370368/620022]    Loss: 0.008470   Batch Acc: 76.56
[Train] Epoch: 0 [370432/620022]    Loss: 0.008686   Batch Acc: 78.12
[Train] Epoch: 0 [370496/620022]    Loss: 0.010536   Batch Acc: 65.62
[Train] Epoch: 0 [370560/620022]    Loss: 0.010076   Batch Acc: 75.00
[Train] Epoch: 0 [370624/620022]    Loss: 0.011414   Batch Acc: 75.00
[Train] Epoch: 0 [370688/620022]    Loss: 0.008456   Batch Acc: 75.00
[Train] Epoch: 0 [370752/620022]    Loss: 0.011237   Batch Acc: 71.88
[Train] Epoch: 0 [370816/620022]    Loss: 0.009195   Batch Acc: 78.12
[Train] Epoch: 0 [370880/620022]    Loss: 0.009206   Batch Acc: 73.44
[Train] Epoch: 0 [370944/620022]    Loss: 0.009713   Batch Acc: 71.88
[Train] Epoch: 0 [371008/620022]    Loss: 0.011620   Batch Acc: 75.00
[Train] Epoch: 0 [371072/620022]    Loss: 0.007399   Batch Acc: 81.25
[Train] Epoch: 0 [371136/620022]    Loss: 0.011643   Batch Acc: 65.62
[Train] Epoch: 0 [371200/620022]    Loss: 0.007473   Batch Acc: 85.94
[Train] Epoch: 0 [371264/620022]    Loss: 0.009214   Batch Acc: 81.25
[Train] Epoch: 0 [371328/620022]    Loss: 0.007926   Batch Acc: 78.12
[Train] Epoch: 0 [371392/620022]    Loss: 0.008713   Batch Acc: 79.69
[Train] Epoch: 0 [371456/620022]    Loss: 0.009407   Batch Acc: 70.31
[Train] Epoch: 0 [371520/620022]    Loss: 0.009675   Batch Acc: 76.56
[Train] Epoch: 0 [371584/620022]    Loss: 0.008566   Batch Acc: 79.69
[Train] Epoch: 0 [371648/620022]    Loss: 0.007498   Batch Acc: 85.94
[Train] Epoch: 0 [371712/620022]    Loss: 0.006479   Batch Acc: 89.06
[Train] Epoch: 0 [371776/620022]    Loss: 0.008177   Batch Acc: 75.00
[Train] Epoch: 0 [371840/620022]    Loss: 0.009668   Batch Acc: 70.31
[Train] Epoch: 0 [371904/620022]    Loss: 0.008939   Batch Acc: 73.44
[Train] Epoch: 0 [371968/620022]    Loss: 0.009922   Batch Acc: 76.56
[Train] Epoch: 0 [372032/620022]    Loss: 0.008795   Batch Acc: 75.00
[Train] Epoch: 0 [372096/620022]    Loss: 0.009137   Batch Acc: 78.12
[Train] Epoch: 0 [372160/620022]    Loss: 0.008753   Batch Acc: 76.56
[Train] Epoch: 0 [372224/620022]    Loss: 0.007822   Batch Acc: 84.38
[Train] Epoch: 0 [372288/620022]    Loss: 0.009090   Batch Acc: 75.00
[Train] Epoch: 0 [372352/620022]    Loss: 0.009812   Batch Acc: 73.44
[Train] Epoch: 0 [372416/620022]    Loss: 0.008913   Batch Acc: 68.75
[Train] Epoch: 0 [372480/620022]    Loss: 0.008234   Batch Acc: 82.81
[Train] Epoch: 0 [372544/620022]    Loss: 0.009171   Batch Acc: 76.56
[Train] Epoch: 0 [372608/620022]    Loss: 0.007002   Batch Acc: 81.25
[Train] Epoch: 0 [372672/620022]    Loss: 0.008552   Batch Acc: 79.69
[Train] Epoch: 0 [372736/620022]    Loss: 0.008966   Batch Acc: 75.00
[Train] Epoch: 0 [372800/620022]    Loss: 0.008854   Batch Acc: 79.69
[Train] Epoch: 0 [372864/620022]    Loss: 0.009603   Batch Acc: 78.12
[Train] Epoch: 0 [372928/620022]    Loss: 0.007993   Batch Acc: 81.25
[Train] Epoch: 0 [372992/620022]    Loss: 0.010103   Batch Acc: 73.44
[Train] Epoch: 0 [373056/620022]    Loss: 0.008099   Batch Acc: 78.12
[Train] Epoch: 0 [373120/620022]    Loss: 0.010462   Batch Acc: 73.44
[Train] Epoch: 0 [373184/620022]    Loss: 0.008706   Batch Acc: 73.44
[Train] Epoch: 0 [373248/620022]    Loss: 0.010165   Batch Acc: 71.88
[Train] Epoch: 0 [373312/620022]    Loss: 0.009758   Batch Acc: 71.88
[Train] Epoch: 0 [373376/620022]    Loss: 0.009156   Batch Acc: 75.00
[Train] Epoch: 0 [373440/620022]    Loss: 0.008834   Batch Acc: 75.00
[Train] Epoch: 0 [373504/620022]    Loss: 0.007707   Batch Acc: 87.50
[Train] Epoch: 0 [373568/620022]    Loss: 0.008791   Batch Acc: 79.69
[Train] Epoch: 0 [373632/620022]    Loss: 0.010367   Batch Acc: 70.31
[Train] Epoch: 0 [373696/620022]    Loss: 0.012430   Batch Acc: 65.62
[Train] Epoch: 0 [373760/620022]    Loss: 0.008606   Batch Acc: 76.56
[Train] Epoch: 0 [373824/620022]    Loss: 0.008078   Batch Acc: 82.81
[Train] Epoch: 0 [373888/620022]    Loss: 0.009959   Batch Acc: 73.44
[Train] Epoch: 0 [373952/620022]    Loss: 0.010176   Batch Acc: 70.31
[Train] Epoch: 0 [374016/620022]    Loss: 0.007961   Batch Acc: 82.81
[Train] Epoch: 0 [374080/620022]    Loss: 0.007485   Batch Acc: 84.38
[Train] Epoch: 0 [374144/620022]    Loss: 0.009972   Batch Acc: 73.44
[Train] Epoch: 0 [374208/620022]    Loss: 0.008363   Batch Acc: 76.56
[Train] Epoch: 0 [374272/620022]    Loss: 0.009036   Batch Acc: 79.69
[Train] Epoch: 0 [374336/620022]    Loss: 0.009770   Batch Acc: 76.56
[Train] Epoch: 0 [374400/620022]    Loss: 0.012243   Batch Acc: 60.94
[Train] Epoch: 0 [374464/620022]    Loss: 0.007439   Batch Acc: 81.25
[Train] Epoch: 0 [374528/620022]    Loss: 0.008711   Batch Acc: 76.56
[Train] Epoch: 0 [374592/620022]    Loss: 0.007835   Batch Acc: 78.12
[Train] Epoch: 0 [374656/620022]    Loss: 0.008654   Batch Acc: 81.25
[Train] Epoch: 0 [374720/620022]    Loss: 0.011296   Batch Acc: 71.88
[Train] Epoch: 0 [374784/620022]    Loss: 0.010113   Batch Acc: 71.88
[Train] Epoch: 0 [374848/620022]    Loss: 0.010703   Batch Acc: 75.00
[Train] Epoch: 0 [374912/620022]    Loss: 0.009971   Batch Acc: 82.81
[Train] Epoch: 0 [374976/620022]    Loss: 0.008421   Batch Acc: 73.44
[Train] Epoch: 0 [375040/620022]    Loss: 0.009724   Batch Acc: 73.44
[Train] Epoch: 0 [375104/620022]    Loss: 0.009104   Batch Acc: 70.31
[Train] Epoch: 0 [375168/620022]    Loss: 0.009339   Batch Acc: 75.00
[Train] Epoch: 0 [375232/620022]    Loss: 0.007703   Batch Acc: 76.56
[Train] Epoch: 0 [375296/620022]    Loss: 0.011163   Batch Acc: 70.31
[Train] Epoch: 0 [375360/620022]    Loss: 0.008644   Batch Acc: 75.00
[Train] Epoch: 0 [375424/620022]    Loss: 0.008479   Batch Acc: 79.69
[Train] Epoch: 0 [375488/620022]    Loss: 0.011418   Batch Acc: 70.31
[Train] Epoch: 0 [375552/620022]    Loss: 0.009371   Batch Acc: 73.44
[Train] Epoch: 0 [375616/620022]    Loss: 0.010907   Batch Acc: 70.31
[Train] Epoch: 0 [375680/620022]    Loss: 0.007434   Batch Acc: 81.25
[Train] Epoch: 0 [375744/620022]    Loss: 0.008908   Batch Acc: 81.25
[Train] Epoch: 0 [375808/620022]    Loss: 0.008479   Batch Acc: 73.44
[Train] Epoch: 0 [375872/620022]    Loss: 0.009670   Batch Acc: 71.88
[Train] Epoch: 0 [375936/620022]    Loss: 0.008979   Batch Acc: 75.00
[Train] Epoch: 0 [376000/620022]    Loss: 0.009359   Batch Acc: 71.88
[Train] Epoch: 0 [376064/620022]    Loss: 0.011315   Batch Acc: 68.75
[Train] Epoch: 0 [376128/620022]    Loss: 0.008112   Batch Acc: 78.12
[Train] Epoch: 0 [376192/620022]    Loss: 0.011250   Batch Acc: 68.75
[Train] Epoch: 0 [376256/620022]    Loss: 0.012148   Batch Acc: 68.75
[Train] Epoch: 0 [376320/620022]    Loss: 0.008602   Batch Acc: 79.69
[Train] Epoch: 0 [376384/620022]    Loss: 0.010042   Batch Acc: 71.88
[Train] Epoch: 0 [376448/620022]    Loss: 0.010895   Batch Acc: 70.31
[Train] Epoch: 0 [376512/620022]    Loss: 0.011529   Batch Acc: 71.88
[Train] Epoch: 0 [376576/620022]    Loss: 0.006788   Batch Acc: 84.38
[Train] Epoch: 0 [376640/620022]    Loss: 0.009224   Batch Acc: 73.44
[Train] Epoch: 0 [376704/620022]    Loss: 0.008919   Batch Acc: 79.69
[Train] Epoch: 0 [376768/620022]    Loss: 0.008420   Batch Acc: 78.12
[Train] Epoch: 0 [376832/620022]    Loss: 0.009737   Batch Acc: 78.12
[Train] Epoch: 0 [376896/620022]    Loss: 0.008295   Batch Acc: 78.12
[Train] Epoch: 0 [376960/620022]    Loss: 0.010032   Batch Acc: 70.31
[Train] Epoch: 0 [377024/620022]    Loss: 0.010049   Batch Acc: 71.88
[Train] Epoch: 0 [377088/620022]    Loss: 0.007215   Batch Acc: 81.25
[Train] Epoch: 0 [377152/620022]    Loss: 0.008701   Batch Acc: 81.25
[Train] Epoch: 0 [377216/620022]    Loss: 0.009119   Batch Acc: 75.00
[Train] Epoch: 0 [377280/620022]    Loss: 0.009790   Batch Acc: 68.75
[Train] Epoch: 0 [377344/620022]    Loss: 0.009073   Batch Acc: 75.00
[Train] Epoch: 0 [377408/620022]    Loss: 0.008053   Batch Acc: 75.00
[Train] Epoch: 0 [377472/620022]    Loss: 0.007125   Batch Acc: 87.50
[Train] Epoch: 0 [377536/620022]    Loss: 0.008377   Batch Acc: 78.12
[Train] Epoch: 0 [377600/620022]    Loss: 0.010204   Batch Acc: 73.44
[Train] Epoch: 0 [377664/620022]    Loss: 0.011096   Batch Acc: 78.12
[Train] Epoch: 0 [377728/620022]    Loss: 0.009837   Batch Acc: 78.12
[Train] Epoch: 0 [377792/620022]    Loss: 0.008754   Batch Acc: 73.44
[Train] Epoch: 0 [377856/620022]    Loss: 0.011032   Batch Acc: 68.75
[Train] Epoch: 0 [377920/620022]    Loss: 0.009001   Batch Acc: 75.00
[Train] Epoch: 0 [377984/620022]    Loss: 0.010601   Batch Acc: 70.31
[Train] Epoch: 0 [378048/620022]    Loss: 0.010165   Batch Acc: 70.31
[Train] Epoch: 0 [378112/620022]    Loss: 0.007994   Batch Acc: 75.00
[Train] Epoch: 0 [378176/620022]    Loss: 0.008626   Batch Acc: 79.69
[Train] Epoch: 0 [378240/620022]    Loss: 0.007865   Batch Acc: 81.25
[Train] Epoch: 0 [378304/620022]    Loss: 0.013529   Batch Acc: 64.06
[Train] Epoch: 0 [378368/620022]    Loss: 0.009534   Batch Acc: 71.88
[Train] Epoch: 0 [378432/620022]    Loss: 0.008971   Batch Acc: 81.25
[Train] Epoch: 0 [378496/620022]    Loss: 0.008727   Batch Acc: 73.44
[Train] Epoch: 0 [378560/620022]    Loss: 0.010892   Batch Acc: 71.88
[Train] Epoch: 0 [378624/620022]    Loss: 0.007939   Batch Acc: 81.25
[Train] Epoch: 0 [378688/620022]    Loss: 0.008016   Batch Acc: 82.81
[Train] Epoch: 0 [378752/620022]    Loss: 0.008746   Batch Acc: 70.31
[Train] Epoch: 0 [378816/620022]    Loss: 0.008133   Batch Acc: 85.94
[Train] Epoch: 0 [378880/620022]    Loss: 0.008727   Batch Acc: 76.56
[Train] Epoch: 0 [378944/620022]    Loss: 0.008771   Batch Acc: 78.12
[Train] Epoch: 0 [379008/620022]    Loss: 0.007451   Batch Acc: 85.94
[Train] Epoch: 0 [379072/620022]    Loss: 0.011847   Batch Acc: 68.75
[Train] Epoch: 0 [379136/620022]    Loss: 0.006644   Batch Acc: 85.94
[Train] Epoch: 0 [379200/620022]    Loss: 0.008967   Batch Acc: 78.12
[Train] Epoch: 0 [379264/620022]    Loss: 0.005709   Batch Acc: 90.62
[Train] Epoch: 0 [379328/620022]    Loss: 0.006586   Batch Acc: 81.25
[Train] Epoch: 0 [379392/620022]    Loss: 0.008712   Batch Acc: 76.56
[Train] Epoch: 0 [379456/620022]    Loss: 0.008308   Batch Acc: 84.38
[Train] Epoch: 0 [379520/620022]    Loss: 0.011213   Batch Acc: 64.06
[Train] Epoch: 0 [379584/620022]    Loss: 0.010514   Batch Acc: 67.19
[Train] Epoch: 0 [379648/620022]    Loss: 0.007366   Batch Acc: 84.38
[Train] Epoch: 0 [379712/620022]    Loss: 0.011183   Batch Acc: 68.75
[Train] Epoch: 0 [379776/620022]    Loss: 0.007664   Batch Acc: 81.25
[Train] Epoch: 0 [379840/620022]    Loss: 0.006397   Batch Acc: 85.94
[Train] Epoch: 0 [379904/620022]    Loss: 0.008438   Batch Acc: 82.81
[Train] Epoch: 0 [379968/620022]    Loss: 0.009599   Batch Acc: 76.56
[Train] Epoch: 0 [380032/620022]    Loss: 0.010616   Batch Acc: 71.88
[Train] Epoch: 0 [380096/620022]    Loss: 0.013178   Batch Acc: 67.19
[Train] Epoch: 0 [380160/620022]    Loss: 0.012466   Batch Acc: 68.75
[Train] Epoch: 0 [380224/620022]    Loss: 0.007556   Batch Acc: 82.81
[Train] Epoch: 0 [380288/620022]    Loss: 0.006901   Batch Acc: 79.69
[Train] Epoch: 0 [380352/620022]    Loss: 0.009197   Batch Acc: 78.12
[Train] Epoch: 0 [380416/620022]    Loss: 0.007269   Batch Acc: 82.81
[Train] Epoch: 0 [380480/620022]    Loss: 0.009488   Batch Acc: 76.56
[Train] Epoch: 0 [380544/620022]    Loss: 0.009256   Batch Acc: 75.00
[Train] Epoch: 0 [380608/620022]    Loss: 0.010708   Batch Acc: 75.00
[Train] Epoch: 0 [380672/620022]    Loss: 0.007715   Batch Acc: 78.12
[Train] Epoch: 0 [380736/620022]    Loss: 0.008276   Batch Acc: 78.12
[Train] Epoch: 0 [380800/620022]    Loss: 0.007855   Batch Acc: 82.81
[Train] Epoch: 0 [380864/620022]    Loss: 0.008212   Batch Acc: 79.69
[Train] Epoch: 0 [380928/620022]    Loss: 0.010548   Batch Acc: 71.88
[Train] Epoch: 0 [380992/620022]    Loss: 0.007611   Batch Acc: 81.25
[Train] Epoch: 0 [381056/620022]    Loss: 0.012227   Batch Acc: 60.94
[Train] Epoch: 0 [381120/620022]    Loss: 0.009671   Batch Acc: 75.00
[Train] Epoch: 0 [381184/620022]    Loss: 0.007424   Batch Acc: 79.69
[Train] Epoch: 0 [381248/620022]    Loss: 0.009127   Batch Acc: 75.00
[Train] Epoch: 0 [381312/620022]    Loss: 0.009489   Batch Acc: 78.12
[Train] Epoch: 0 [381376/620022]    Loss: 0.012205   Batch Acc: 67.19
[Train] Epoch: 0 [381440/620022]    Loss: 0.009157   Batch Acc: 79.69
[Train] Epoch: 0 [381504/620022]    Loss: 0.012674   Batch Acc: 68.75
[Train] Epoch: 0 [381568/620022]    Loss: 0.009911   Batch Acc: 73.44
[Train] Epoch: 0 [381632/620022]    Loss: 0.011328   Batch Acc: 71.88
[Train] Epoch: 0 [381696/620022]    Loss: 0.011048   Batch Acc: 75.00
[Train] Epoch: 0 [381760/620022]    Loss: 0.009012   Batch Acc: 79.69
[Train] Epoch: 0 [381824/620022]    Loss: 0.010366   Batch Acc: 78.12
[Train] Epoch: 0 [381888/620022]    Loss: 0.009971   Batch Acc: 71.88
[Train] Epoch: 0 [381952/620022]    Loss: 0.008348   Batch Acc: 82.81
[Train] Epoch: 0 [382016/620022]    Loss: 0.011060   Batch Acc: 71.88
[Train] Epoch: 0 [382080/620022]    Loss: 0.007118   Batch Acc: 89.06
[Train] Epoch: 0 [382144/620022]    Loss: 0.008957   Batch Acc: 76.56
[Train] Epoch: 0 [382208/620022]    Loss: 0.009686   Batch Acc: 75.00
[Train] Epoch: 0 [382272/620022]    Loss: 0.011927   Batch Acc: 62.50
[Train] Epoch: 0 [382336/620022]    Loss: 0.010927   Batch Acc: 70.31
[Train] Epoch: 0 [382400/620022]    Loss: 0.012080   Batch Acc: 68.75
[Train] Epoch: 0 [382464/620022]    Loss: 0.012027   Batch Acc: 75.00
[Train] Epoch: 0 [382528/620022]    Loss: 0.010692   Batch Acc: 79.69
[Train] Epoch: 0 [382592/620022]    Loss: 0.010262   Batch Acc: 68.75
[Train] Epoch: 0 [382656/620022]    Loss: 0.008651   Batch Acc: 82.81
[Train] Epoch: 0 [382720/620022]    Loss: 0.009686   Batch Acc: 71.88
[Train] Epoch: 0 [382784/620022]    Loss: 0.008610   Batch Acc: 79.69
[Train] Epoch: 0 [382848/620022]    Loss: 0.009361   Batch Acc: 78.12
[Train] Epoch: 0 [382912/620022]    Loss: 0.008139   Batch Acc: 81.25
[Train] Epoch: 0 [382976/620022]    Loss: 0.008924   Batch Acc: 73.44
[Train] Epoch: 0 [383040/620022]    Loss: 0.008230   Batch Acc: 82.81
[Train] Epoch: 0 [383104/620022]    Loss: 0.009880   Batch Acc: 78.12
[Train] Epoch: 0 [383168/620022]    Loss: 0.008004   Batch Acc: 84.38
[Train] Epoch: 0 [383232/620022]    Loss: 0.009704   Batch Acc: 73.44
[Train] Epoch: 0 [383296/620022]    Loss: 0.008340   Batch Acc: 75.00
[Train] Epoch: 0 [383360/620022]    Loss: 0.011065   Batch Acc: 70.31
[Train] Epoch: 0 [383424/620022]    Loss: 0.007367   Batch Acc: 84.38
[Train] Epoch: 0 [383488/620022]    Loss: 0.008142   Batch Acc: 79.69
[Train] Epoch: 0 [383552/620022]    Loss: 0.009589   Batch Acc: 75.00
[Train] Epoch: 0 [383616/620022]    Loss: 0.009590   Batch Acc: 79.69
[Train] Epoch: 0 [383680/620022]    Loss: 0.009403   Batch Acc: 67.19
[Train] Epoch: 0 [383744/620022]    Loss: 0.008237   Batch Acc: 82.81
[Train] Epoch: 0 [383808/620022]    Loss: 0.010497   Batch Acc: 75.00
[Train] Epoch: 0 [383872/620022]    Loss: 0.007879   Batch Acc: 82.81
[Train] Epoch: 0 [383936/620022]    Loss: 0.008753   Batch Acc: 79.69
[Train] Epoch: 0 [384000/620022]    Loss: 0.006309   Batch Acc: 82.81
[Train] Epoch: 0 [384064/620022]    Loss: 0.009089   Batch Acc: 78.12
[Train] Epoch: 0 [384128/620022]    Loss: 0.009408   Batch Acc: 73.44
[Train] Epoch: 0 [384192/620022]    Loss: 0.007954   Batch Acc: 81.25
[Train] Epoch: 0 [384256/620022]    Loss: 0.008304   Batch Acc: 79.69
[Train] Epoch: 0 [384320/620022]    Loss: 0.009594   Batch Acc: 71.88
[Train] Epoch: 0 [384384/620022]    Loss: 0.006595   Batch Acc: 85.94
[Train] Epoch: 0 [384448/620022]    Loss: 0.009509   Batch Acc: 71.88
[Train] Epoch: 0 [384512/620022]    Loss: 0.007703   Batch Acc: 85.94
[Train] Epoch: 0 [384576/620022]    Loss: 0.009975   Batch Acc: 75.00
[Train] Epoch: 0 [384640/620022]    Loss: 0.007782   Batch Acc: 76.56
[Train] Epoch: 0 [384704/620022]    Loss: 0.007863   Batch Acc: 79.69
[Train] Epoch: 0 [384768/620022]    Loss: 0.008073   Batch Acc: 76.56
[Train] Epoch: 0 [384832/620022]    Loss: 0.009681   Batch Acc: 78.12
[Train] Epoch: 0 [384896/620022]    Loss: 0.008467   Batch Acc: 81.25
[Train] Epoch: 0 [384960/620022]    Loss: 0.009375   Batch Acc: 75.00
[Train] Epoch: 0 [385024/620022]    Loss: 0.008476   Batch Acc: 81.25
[Train] Epoch: 0 [385088/620022]    Loss: 0.008141   Batch Acc: 82.81
[Train] Epoch: 0 [385152/620022]    Loss: 0.010586   Batch Acc: 73.44
[Train] Epoch: 0 [385216/620022]    Loss: 0.009264   Batch Acc: 75.00
[Train] Epoch: 0 [385280/620022]    Loss: 0.008735   Batch Acc: 76.56
[Train] Epoch: 0 [385344/620022]    Loss: 0.007117   Batch Acc: 84.38
[Train] Epoch: 0 [385408/620022]    Loss: 0.011485   Batch Acc: 71.88
[Train] Epoch: 0 [385472/620022]    Loss: 0.010663   Batch Acc: 68.75
[Train] Epoch: 0 [385536/620022]    Loss: 0.006806   Batch Acc: 84.38
[Train] Epoch: 0 [385600/620022]    Loss: 0.008779   Batch Acc: 79.69
[Train] Epoch: 0 [385664/620022]    Loss: 0.008135   Batch Acc: 81.25
[Train] Epoch: 0 [385728/620022]    Loss: 0.009737   Batch Acc: 75.00
[Train] Epoch: 0 [385792/620022]    Loss: 0.005839   Batch Acc: 87.50
[Train] Epoch: 0 [385856/620022]    Loss: 0.008869   Batch Acc: 76.56
[Train] Epoch: 0 [385920/620022]    Loss: 0.008910   Batch Acc: 75.00
[Train] Epoch: 0 [385984/620022]    Loss: 0.007985   Batch Acc: 79.69
[Train] Epoch: 0 [386048/620022]    Loss: 0.009694   Batch Acc: 76.56
[Train] Epoch: 0 [386112/620022]    Loss: 0.009075   Batch Acc: 70.31
[Train] Epoch: 0 [386176/620022]    Loss: 0.007775   Batch Acc: 82.81
[Train] Epoch: 0 [386240/620022]    Loss: 0.009828   Batch Acc: 75.00
[Train] Epoch: 0 [386304/620022]    Loss: 0.010423   Batch Acc: 70.31
[Train] Epoch: 0 [386368/620022]    Loss: 0.008275   Batch Acc: 84.38
[Train] Epoch: 0 [386432/620022]    Loss: 0.010397   Batch Acc: 70.31
[Train] Epoch: 0 [386496/620022]    Loss: 0.007616   Batch Acc: 85.94
[Train] Epoch: 0 [386560/620022]    Loss: 0.009943   Batch Acc: 70.31
[Train] Epoch: 0 [386624/620022]    Loss: 0.010833   Batch Acc: 70.31
[Train] Epoch: 0 [386688/620022]    Loss: 0.007924   Batch Acc: 79.69
[Train] Epoch: 0 [386752/620022]    Loss: 0.008208   Batch Acc: 79.69
[Train] Epoch: 0 [386816/620022]    Loss: 0.010237   Batch Acc: 75.00
[Train] Epoch: 0 [386880/620022]    Loss: 0.008690   Batch Acc: 75.00
[Train] Epoch: 0 [386944/620022]    Loss: 0.010527   Batch Acc: 71.88
[Train] Epoch: 0 [387008/620022]    Loss: 0.008691   Batch Acc: 82.81
[Train] Epoch: 0 [387072/620022]    Loss: 0.008619   Batch Acc: 75.00
[Train] Epoch: 0 [387136/620022]    Loss: 0.007177   Batch Acc: 85.94
[Train] Epoch: 0 [387200/620022]    Loss: 0.009989   Batch Acc: 79.69
[Train] Epoch: 0 [387264/620022]    Loss: 0.009298   Batch Acc: 71.88
[Train] Epoch: 0 [387328/620022]    Loss: 0.014349   Batch Acc: 59.38
[Train] Epoch: 0 [387392/620022]    Loss: 0.008652   Batch Acc: 82.81
[Train] Epoch: 0 [387456/620022]    Loss: 0.009881   Batch Acc: 71.88
[Train] Epoch: 0 [387520/620022]    Loss: 0.008769   Batch Acc: 79.69
[Train] Epoch: 0 [387584/620022]    Loss: 0.010007   Batch Acc: 67.19
[Train] Epoch: 0 [387648/620022]    Loss: 0.009744   Batch Acc: 73.44
[Train] Epoch: 0 [387712/620022]    Loss: 0.008355   Batch Acc: 75.00
[Train] Epoch: 0 [387776/620022]    Loss: 0.008088   Batch Acc: 78.12
[Train] Epoch: 0 [387840/620022]    Loss: 0.009947   Batch Acc: 73.44
[Train] Epoch: 0 [387904/620022]    Loss: 0.009011   Batch Acc: 75.00
[Train] Epoch: 0 [387968/620022]    Loss: 0.008294   Batch Acc: 71.88
[Train] Epoch: 0 [388032/620022]    Loss: 0.008986   Batch Acc: 78.12
[Train] Epoch: 0 [388096/620022]    Loss: 0.008188   Batch Acc: 79.69
[Train] Epoch: 0 [388160/620022]    Loss: 0.007827   Batch Acc: 84.38
[Train] Epoch: 0 [388224/620022]    Loss: 0.007140   Batch Acc: 81.25
[Train] Epoch: 0 [388288/620022]    Loss: 0.007548   Batch Acc: 82.81
[Train] Epoch: 0 [388352/620022]    Loss: 0.008708   Batch Acc: 81.25
[Train] Epoch: 0 [388416/620022]    Loss: 0.008558   Batch Acc: 75.00
[Train] Epoch: 0 [388480/620022]    Loss: 0.008579   Batch Acc: 76.56
[Train] Epoch: 0 [388544/620022]    Loss: 0.009075   Batch Acc: 73.44
[Train] Epoch: 0 [388608/620022]    Loss: 0.007888   Batch Acc: 81.25
[Train] Epoch: 0 [388672/620022]    Loss: 0.011791   Batch Acc: 67.19
[Train] Epoch: 0 [388736/620022]    Loss: 0.011200   Batch Acc: 70.31
[Train] Epoch: 0 [388800/620022]    Loss: 0.008327   Batch Acc: 75.00
[Train] Epoch: 0 [388864/620022]    Loss: 0.010179   Batch Acc: 68.75
[Train] Epoch: 0 [388928/620022]    Loss: 0.006565   Batch Acc: 82.81
[Train] Epoch: 0 [388992/620022]    Loss: 0.007164   Batch Acc: 81.25
[Train] Epoch: 0 [389056/620022]    Loss: 0.010196   Batch Acc: 73.44
[Train] Epoch: 0 [389120/620022]    Loss: 0.008981   Batch Acc: 79.69
[Train] Epoch: 0 [389184/620022]    Loss: 0.009634   Batch Acc: 73.44
[Train] Epoch: 0 [389248/620022]    Loss: 0.008807   Batch Acc: 76.56
[Train] Epoch: 0 [389312/620022]    Loss: 0.007635   Batch Acc: 82.81
[Train] Epoch: 0 [389376/620022]    Loss: 0.009546   Batch Acc: 71.88
[Train] Epoch: 0 [389440/620022]    Loss: 0.011459   Batch Acc: 71.88
[Train] Epoch: 0 [389504/620022]    Loss: 0.008919   Batch Acc: 71.88
[Train] Epoch: 0 [389568/620022]    Loss: 0.009627   Batch Acc: 73.44
[Train] Epoch: 0 [389632/620022]    Loss: 0.007066   Batch Acc: 85.94
[Train] Epoch: 0 [389696/620022]    Loss: 0.009226   Batch Acc: 76.56
[Train] Epoch: 0 [389760/620022]    Loss: 0.007990   Batch Acc: 76.56
[Train] Epoch: 0 [389824/620022]    Loss: 0.008037   Batch Acc: 79.69
[Train] Epoch: 0 [389888/620022]    Loss: 0.010322   Batch Acc: 75.00
[Train] Epoch: 0 [389952/620022]    Loss: 0.007761   Batch Acc: 81.25
[Train] Epoch: 0 [390016/620022]    Loss: 0.010163   Batch Acc: 70.31
[Train] Epoch: 0 [390080/620022]    Loss: 0.010513   Batch Acc: 71.88
[Train] Epoch: 0 [390144/620022]    Loss: 0.007137   Batch Acc: 89.06
[Train] Epoch: 0 [390208/620022]    Loss: 0.009506   Batch Acc: 73.44
[Train] Epoch: 0 [390272/620022]    Loss: 0.008709   Batch Acc: 78.12
[Train] Epoch: 0 [390336/620022]    Loss: 0.011525   Batch Acc: 70.31
[Train] Epoch: 0 [390400/620022]    Loss: 0.010753   Batch Acc: 65.62
[Train] Epoch: 0 [390464/620022]    Loss: 0.009993   Batch Acc: 70.31
[Train] Epoch: 0 [390528/620022]    Loss: 0.010160   Batch Acc: 73.44
[Train] Epoch: 0 [390592/620022]    Loss: 0.007546   Batch Acc: 82.81
[Train] Epoch: 0 [390656/620022]    Loss: 0.009382   Batch Acc: 68.75
[Train] Epoch: 0 [390720/620022]    Loss: 0.010381   Batch Acc: 75.00
[Train] Epoch: 0 [390784/620022]    Loss: 0.011651   Batch Acc: 67.19
[Train] Epoch: 0 [390848/620022]    Loss: 0.010040   Batch Acc: 70.31
[Train] Epoch: 0 [390912/620022]    Loss: 0.011035   Batch Acc: 67.19
[Train] Epoch: 0 [390976/620022]    Loss: 0.008511   Batch Acc: 81.25
[Train] Epoch: 0 [391040/620022]    Loss: 0.011095   Batch Acc: 67.19
[Train] Epoch: 0 [391104/620022]    Loss: 0.009921   Batch Acc: 71.88
[Train] Epoch: 0 [391168/620022]    Loss: 0.009549   Batch Acc: 76.56
[Train] Epoch: 0 [391232/620022]    Loss: 0.008652   Batch Acc: 76.56
[Train] Epoch: 0 [391296/620022]    Loss: 0.007826   Batch Acc: 78.12
[Train] Epoch: 0 [391360/620022]    Loss: 0.009751   Batch Acc: 78.12
[Train] Epoch: 0 [391424/620022]    Loss: 0.008802   Batch Acc: 79.69
[Train] Epoch: 0 [391488/620022]    Loss: 0.008298   Batch Acc: 71.88
[Train] Epoch: 0 [391552/620022]    Loss: 0.010410   Batch Acc: 76.56
[Train] Epoch: 0 [391616/620022]    Loss: 0.009075   Batch Acc: 75.00
[Train] Epoch: 0 [391680/620022]    Loss: 0.008830   Batch Acc: 76.56
[Train] Epoch: 0 [391744/620022]    Loss: 0.007794   Batch Acc: 82.81
[Train] Epoch: 0 [391808/620022]    Loss: 0.011291   Batch Acc: 67.19
[Train] Epoch: 0 [391872/620022]    Loss: 0.007143   Batch Acc: 78.12
[Train] Epoch: 0 [391936/620022]    Loss: 0.007310   Batch Acc: 84.38
[Train] Epoch: 0 [392000/620022]    Loss: 0.011149   Batch Acc: 64.06
[Train] Epoch: 0 [392064/620022]    Loss: 0.008444   Batch Acc: 78.12
[Train] Epoch: 0 [392128/620022]    Loss: 0.008733   Batch Acc: 78.12
[Train] Epoch: 0 [392192/620022]    Loss: 0.007052   Batch Acc: 84.38
[Train] Epoch: 0 [392256/620022]    Loss: 0.009777   Batch Acc: 73.44
[Train] Epoch: 0 [392320/620022]    Loss: 0.008860   Batch Acc: 75.00
[Train] Epoch: 0 [392384/620022]    Loss: 0.010535   Batch Acc: 73.44
[Train] Epoch: 0 [392448/620022]    Loss: 0.009252   Batch Acc: 79.69
[Train] Epoch: 0 [392512/620022]    Loss: 0.008782   Batch Acc: 73.44
[Train] Epoch: 0 [392576/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 0 [392640/620022]    Loss: 0.007492   Batch Acc: 82.81
[Train] Epoch: 0 [392704/620022]    Loss: 0.007958   Batch Acc: 85.94
[Train] Epoch: 0 [392768/620022]    Loss: 0.009837   Batch Acc: 76.56
[Train] Epoch: 0 [392832/620022]    Loss: 0.008045   Batch Acc: 76.56
[Train] Epoch: 0 [392896/620022]    Loss: 0.008913   Batch Acc: 76.56
[Train] Epoch: 0 [392960/620022]    Loss: 0.009335   Batch Acc: 79.69
[Train] Epoch: 0 [393024/620022]    Loss: 0.009593   Batch Acc: 78.12
[Train] Epoch: 0 [393088/620022]    Loss: 0.008629   Batch Acc: 78.12
[Train] Epoch: 0 [393152/620022]    Loss: 0.009601   Batch Acc: 71.88
[Train] Epoch: 0 [393216/620022]    Loss: 0.007801   Batch Acc: 81.25
[Train] Epoch: 0 [393280/620022]    Loss: 0.008737   Batch Acc: 73.44
[Train] Epoch: 0 [393344/620022]    Loss: 0.009204   Batch Acc: 73.44
[Train] Epoch: 0 [393408/620022]    Loss: 0.009879   Batch Acc: 71.88
[Train] Epoch: 0 [393472/620022]    Loss: 0.007964   Batch Acc: 79.69
[Train] Epoch: 0 [393536/620022]    Loss: 0.009668   Batch Acc: 78.12
[Train] Epoch: 0 [393600/620022]    Loss: 0.009307   Batch Acc: 75.00
[Train] Epoch: 0 [393664/620022]    Loss: 0.008448   Batch Acc: 81.25
[Train] Epoch: 0 [393728/620022]    Loss: 0.007681   Batch Acc: 82.81
[Train] Epoch: 0 [393792/620022]    Loss: 0.010330   Batch Acc: 70.31
[Train] Epoch: 0 [393856/620022]    Loss: 0.011576   Batch Acc: 71.88
[Train] Epoch: 0 [393920/620022]    Loss: 0.007805   Batch Acc: 84.38
[Train] Epoch: 0 [393984/620022]    Loss: 0.009000   Batch Acc: 81.25
[Train] Epoch: 0 [394048/620022]    Loss: 0.007940   Batch Acc: 81.25
[Train] Epoch: 0 [394112/620022]    Loss: 0.007920   Batch Acc: 82.81
[Train] Epoch: 0 [394176/620022]    Loss: 0.008163   Batch Acc: 76.56
[Train] Epoch: 0 [394240/620022]    Loss: 0.010566   Batch Acc: 68.75
[Train] Epoch: 0 [394304/620022]    Loss: 0.009417   Batch Acc: 76.56
[Train] Epoch: 0 [394368/620022]    Loss: 0.009044   Batch Acc: 76.56
[Train] Epoch: 0 [394432/620022]    Loss: 0.009889   Batch Acc: 73.44
[Train] Epoch: 0 [394496/620022]    Loss: 0.010113   Batch Acc: 76.56
[Train] Epoch: 0 [394560/620022]    Loss: 0.011374   Batch Acc: 68.75
[Train] Epoch: 0 [394624/620022]    Loss: 0.008711   Batch Acc: 73.44
[Train] Epoch: 0 [394688/620022]    Loss: 0.007377   Batch Acc: 79.69
[Train] Epoch: 0 [394752/620022]    Loss: 0.009423   Batch Acc: 75.00
[Train] Epoch: 0 [394816/620022]    Loss: 0.009524   Batch Acc: 75.00
[Train] Epoch: 0 [394880/620022]    Loss: 0.009998   Batch Acc: 71.88
[Train] Epoch: 0 [394944/620022]    Loss: 0.009269   Batch Acc: 68.75
[Train] Epoch: 0 [395008/620022]    Loss: 0.010867   Batch Acc: 71.88
[Train] Epoch: 0 [395072/620022]    Loss: 0.007751   Batch Acc: 81.25
[Train] Epoch: 0 [395136/620022]    Loss: 0.009377   Batch Acc: 78.12
[Train] Epoch: 0 [395200/620022]    Loss: 0.007975   Batch Acc: 82.81
[Train] Epoch: 0 [395264/620022]    Loss: 0.008242   Batch Acc: 76.56
[Train] Epoch: 0 [395328/620022]    Loss: 0.007310   Batch Acc: 78.12
[Train] Epoch: 0 [395392/620022]    Loss: 0.011534   Batch Acc: 68.75
[Train] Epoch: 0 [395456/620022]    Loss: 0.009570   Batch Acc: 75.00
[Train] Epoch: 0 [395520/620022]    Loss: 0.010891   Batch Acc: 71.88
[Train] Epoch: 0 [395584/620022]    Loss: 0.008559   Batch Acc: 78.12
[Train] Epoch: 0 [395648/620022]    Loss: 0.010271   Batch Acc: 73.44
[Train] Epoch: 0 [395712/620022]    Loss: 0.009665   Batch Acc: 78.12
[Train] Epoch: 0 [395776/620022]    Loss: 0.008950   Batch Acc: 71.88
[Train] Epoch: 0 [395840/620022]    Loss: 0.009104   Batch Acc: 73.44
[Train] Epoch: 0 [395904/620022]    Loss: 0.011293   Batch Acc: 67.19
[Train] Epoch: 0 [395968/620022]    Loss: 0.008050   Batch Acc: 75.00
[Train] Epoch: 0 [396032/620022]    Loss: 0.009099   Batch Acc: 75.00
[Train] Epoch: 0 [396096/620022]    Loss: 0.007659   Batch Acc: 82.81
[Train] Epoch: 0 [396160/620022]    Loss: 0.008817   Batch Acc: 76.56
[Train] Epoch: 0 [396224/620022]    Loss: 0.010253   Batch Acc: 71.88
[Train] Epoch: 0 [396288/620022]    Loss: 0.009814   Batch Acc: 73.44
[Train] Epoch: 0 [396352/620022]    Loss: 0.008768   Batch Acc: 79.69
[Train] Epoch: 0 [396416/620022]    Loss: 0.006326   Batch Acc: 81.25
[Train] Epoch: 0 [396480/620022]    Loss: 0.010631   Batch Acc: 71.88
[Train] Epoch: 0 [396544/620022]    Loss: 0.007797   Batch Acc: 81.25
[Train] Epoch: 0 [396608/620022]    Loss: 0.008584   Batch Acc: 81.25
[Train] Epoch: 0 [396672/620022]    Loss: 0.010537   Batch Acc: 76.56
[Train] Epoch: 0 [396736/620022]    Loss: 0.008824   Batch Acc: 78.12
[Train] Epoch: 0 [396800/620022]    Loss: 0.009041   Batch Acc: 79.69
[Train] Epoch: 0 [396864/620022]    Loss: 0.008844   Batch Acc: 75.00
[Train] Epoch: 0 [396928/620022]    Loss: 0.011206   Batch Acc: 67.19
[Train] Epoch: 0 [396992/620022]    Loss: 0.008560   Batch Acc: 82.81
[Train] Epoch: 0 [397056/620022]    Loss: 0.007003   Batch Acc: 84.38
[Train] Epoch: 0 [397120/620022]    Loss: 0.009133   Batch Acc: 71.88
[Train] Epoch: 0 [397184/620022]    Loss: 0.008008   Batch Acc: 81.25
[Train] Epoch: 0 [397248/620022]    Loss: 0.011559   Batch Acc: 67.19
[Train] Epoch: 0 [397312/620022]    Loss: 0.009291   Batch Acc: 78.12
[Train] Epoch: 0 [397376/620022]    Loss: 0.009879   Batch Acc: 68.75
[Train] Epoch: 0 [397440/620022]    Loss: 0.006956   Batch Acc: 82.81
[Train] Epoch: 0 [397504/620022]    Loss: 0.007503   Batch Acc: 87.50
[Train] Epoch: 0 [397568/620022]    Loss: 0.008095   Batch Acc: 79.69
[Train] Epoch: 0 [397632/620022]    Loss: 0.009492   Batch Acc: 71.88
[Train] Epoch: 0 [397696/620022]    Loss: 0.008661   Batch Acc: 79.69
[Train] Epoch: 0 [397760/620022]    Loss: 0.009799   Batch Acc: 75.00
[Train] Epoch: 0 [397824/620022]    Loss: 0.007671   Batch Acc: 79.69
[Train] Epoch: 0 [397888/620022]    Loss: 0.007816   Batch Acc: 78.12
[Train] Epoch: 0 [397952/620022]    Loss: 0.010048   Batch Acc: 73.44
[Train] Epoch: 0 [398016/620022]    Loss: 0.008708   Batch Acc: 84.38
[Train] Epoch: 0 [398080/620022]    Loss: 0.006400   Batch Acc: 87.50
[Train] Epoch: 0 [398144/620022]    Loss: 0.008126   Batch Acc: 75.00
[Train] Epoch: 0 [398208/620022]    Loss: 0.007156   Batch Acc: 81.25
[Train] Epoch: 0 [398272/620022]    Loss: 0.009631   Batch Acc: 71.88
[Train] Epoch: 0 [398336/620022]    Loss: 0.007413   Batch Acc: 84.38
[Train] Epoch: 0 [398400/620022]    Loss: 0.009055   Batch Acc: 73.44
[Train] Epoch: 0 [398464/620022]    Loss: 0.008502   Batch Acc: 82.81
[Train] Epoch: 0 [398528/620022]    Loss: 0.007980   Batch Acc: 79.69
[Train] Epoch: 0 [398592/620022]    Loss: 0.010189   Batch Acc: 76.56
[Train] Epoch: 0 [398656/620022]    Loss: 0.008671   Batch Acc: 76.56
[Train] Epoch: 0 [398720/620022]    Loss: 0.008926   Batch Acc: 71.88
[Train] Epoch: 0 [398784/620022]    Loss: 0.009386   Batch Acc: 78.12
[Train] Epoch: 0 [398848/620022]    Loss: 0.009832   Batch Acc: 76.56
[Train] Epoch: 0 [398912/620022]    Loss: 0.010797   Batch Acc: 73.44
[Train] Epoch: 0 [398976/620022]    Loss: 0.008061   Batch Acc: 84.38
[Train] Epoch: 0 [399040/620022]    Loss: 0.009151   Batch Acc: 75.00
[Train] Epoch: 0 [399104/620022]    Loss: 0.009101   Batch Acc: 76.56
[Train] Epoch: 0 [399168/620022]    Loss: 0.009192   Batch Acc: 76.56
[Train] Epoch: 0 [399232/620022]    Loss: 0.011642   Batch Acc: 73.44
[Train] Epoch: 0 [399296/620022]    Loss: 0.009264   Batch Acc: 78.12
[Train] Epoch: 0 [399360/620022]    Loss: 0.008227   Batch Acc: 76.56
[Train] Epoch: 0 [399424/620022]    Loss: 0.008416   Batch Acc: 78.12
[Train] Epoch: 0 [399488/620022]    Loss: 0.008025   Batch Acc: 84.38
[Train] Epoch: 0 [399552/620022]    Loss: 0.010611   Batch Acc: 76.56
[Train] Epoch: 0 [399616/620022]    Loss: 0.007179   Batch Acc: 79.69
[Train] Epoch: 0 [399680/620022]    Loss: 0.010749   Batch Acc: 71.88
[Train] Epoch: 0 [399744/620022]    Loss: 0.008413   Batch Acc: 79.69
[Train] Epoch: 0 [399808/620022]    Loss: 0.008444   Batch Acc: 75.00
[Train] Epoch: 0 [399872/620022]    Loss: 0.011103   Batch Acc: 71.88
[Train] Epoch: 0 [399936/620022]    Loss: 0.007202   Batch Acc: 82.81
[Train] Epoch: 0 [400000/620022]    Loss: 0.014291   Batch Acc: 62.50
[Train] Epoch: 0 [400064/620022]    Loss: 0.008765   Batch Acc: 76.56
[Train] Epoch: 0 [400128/620022]    Loss: 0.008510   Batch Acc: 79.69
[Train] Epoch: 0 [400192/620022]    Loss: 0.007108   Batch Acc: 85.94
[Train] Epoch: 0 [400256/620022]    Loss: 0.007717   Batch Acc: 81.25
[Train] Epoch: 0 [400320/620022]    Loss: 0.008587   Batch Acc: 79.69
[Train] Epoch: 0 [400384/620022]    Loss: 0.010247   Batch Acc: 76.56
[Train] Epoch: 0 [400448/620022]    Loss: 0.009688   Batch Acc: 75.00
[Train] Epoch: 0 [400512/620022]    Loss: 0.012141   Batch Acc: 68.75
[Train] Epoch: 0 [400576/620022]    Loss: 0.008027   Batch Acc: 81.25
[Train] Epoch: 0 [400640/620022]    Loss: 0.008854   Batch Acc: 76.56
[Train] Epoch: 0 [400704/620022]    Loss: 0.008519   Batch Acc: 81.25
[Train] Epoch: 0 [400768/620022]    Loss: 0.008058   Batch Acc: 78.12
[Train] Epoch: 0 [400832/620022]    Loss: 0.009959   Batch Acc: 75.00
[Train] Epoch: 0 [400896/620022]    Loss: 0.009328   Batch Acc: 75.00
[Train] Epoch: 0 [400960/620022]    Loss: 0.007766   Batch Acc: 81.25
[Train] Epoch: 0 [401024/620022]    Loss: 0.008985   Batch Acc: 76.56
[Train] Epoch: 0 [401088/620022]    Loss: 0.008424   Batch Acc: 76.56
[Train] Epoch: 0 [401152/620022]    Loss: 0.007261   Batch Acc: 82.81
[Train] Epoch: 0 [401216/620022]    Loss: 0.008436   Batch Acc: 78.12
[Train] Epoch: 0 [401280/620022]    Loss: 0.012103   Batch Acc: 64.06
[Train] Epoch: 0 [401344/620022]    Loss: 0.009002   Batch Acc: 75.00
[Train] Epoch: 0 [401408/620022]    Loss: 0.007752   Batch Acc: 85.94
[Train] Epoch: 0 [401472/620022]    Loss: 0.010221   Batch Acc: 71.88
[Train] Epoch: 0 [401536/620022]    Loss: 0.009520   Batch Acc: 75.00
[Train] Epoch: 0 [401600/620022]    Loss: 0.010224   Batch Acc: 78.12
[Train] Epoch: 0 [401664/620022]    Loss: 0.007960   Batch Acc: 84.38
[Train] Epoch: 0 [401728/620022]    Loss: 0.008047   Batch Acc: 81.25
[Train] Epoch: 0 [401792/620022]    Loss: 0.007956   Batch Acc: 82.81
[Train] Epoch: 0 [401856/620022]    Loss: 0.010002   Batch Acc: 81.25
[Train] Epoch: 0 [401920/620022]    Loss: 0.011549   Batch Acc: 68.75
[Train] Epoch: 0 [401984/620022]    Loss: 0.009466   Batch Acc: 79.69
[Train] Epoch: 0 [402048/620022]    Loss: 0.008965   Batch Acc: 75.00
[Train] Epoch: 0 [402112/620022]    Loss: 0.010231   Batch Acc: 76.56
[Train] Epoch: 0 [402176/620022]    Loss: 0.010944   Batch Acc: 75.00
[Train] Epoch: 0 [402240/620022]    Loss: 0.008017   Batch Acc: 85.94
[Train] Epoch: 0 [402304/620022]    Loss: 0.007709   Batch Acc: 79.69
[Train] Epoch: 0 [402368/620022]    Loss: 0.008663   Batch Acc: 78.12
[Train] Epoch: 0 [402432/620022]    Loss: 0.008146   Batch Acc: 78.12
[Train] Epoch: 0 [402496/620022]    Loss: 0.010601   Batch Acc: 68.75
[Train] Epoch: 0 [402560/620022]    Loss: 0.009420   Batch Acc: 76.56
[Train] Epoch: 0 [402624/620022]    Loss: 0.008896   Batch Acc: 76.56
[Train] Epoch: 0 [402688/620022]    Loss: 0.009596   Batch Acc: 65.62
[Train] Epoch: 0 [402752/620022]    Loss: 0.008476   Batch Acc: 73.44
[Train] Epoch: 0 [402816/620022]    Loss: 0.009592   Batch Acc: 73.44
[Train] Epoch: 0 [402880/620022]    Loss: 0.010652   Batch Acc: 70.31
[Train] Epoch: 0 [402944/620022]    Loss: 0.008763   Batch Acc: 76.56
[Train] Epoch: 0 [403008/620022]    Loss: 0.007794   Batch Acc: 84.38
[Train] Epoch: 0 [403072/620022]    Loss: 0.009789   Batch Acc: 71.88
[Train] Epoch: 0 [403136/620022]    Loss: 0.008090   Batch Acc: 82.81
[Train] Epoch: 0 [403200/620022]    Loss: 0.008088   Batch Acc: 84.38
[Train] Epoch: 0 [403264/620022]    Loss: 0.008498   Batch Acc: 84.38
[Train] Epoch: 0 [403328/620022]    Loss: 0.008751   Batch Acc: 71.88
[Train] Epoch: 0 [403392/620022]    Loss: 0.010282   Batch Acc: 67.19
[Train] Epoch: 0 [403456/620022]    Loss: 0.009085   Batch Acc: 71.88
[Train] Epoch: 0 [403520/620022]    Loss: 0.008695   Batch Acc: 78.12
[Train] Epoch: 0 [403584/620022]    Loss: 0.008682   Batch Acc: 76.56
[Train] Epoch: 0 [403648/620022]    Loss: 0.009500   Batch Acc: 67.19
[Train] Epoch: 0 [403712/620022]    Loss: 0.007772   Batch Acc: 79.69
[Train] Epoch: 0 [403776/620022]    Loss: 0.007449   Batch Acc: 85.94
[Train] Epoch: 0 [403840/620022]    Loss: 0.009296   Batch Acc: 79.69
[Train] Epoch: 0 [403904/620022]    Loss: 0.010721   Batch Acc: 75.00
[Train] Epoch: 0 [403968/620022]    Loss: 0.010379   Batch Acc: 76.56
[Train] Epoch: 0 [404032/620022]    Loss: 0.007777   Batch Acc: 81.25
[Train] Epoch: 0 [404096/620022]    Loss: 0.009046   Batch Acc: 75.00
[Train] Epoch: 0 [404160/620022]    Loss: 0.010465   Batch Acc: 71.88
[Train] Epoch: 0 [404224/620022]    Loss: 0.010731   Batch Acc: 75.00
[Train] Epoch: 0 [404288/620022]    Loss: 0.007441   Batch Acc: 79.69
[Train] Epoch: 0 [404352/620022]    Loss: 0.011910   Batch Acc: 67.19
[Train] Epoch: 0 [404416/620022]    Loss: 0.010012   Batch Acc: 71.88
[Train] Epoch: 0 [404480/620022]    Loss: 0.009970   Batch Acc: 71.88
[Train] Epoch: 0 [404544/620022]    Loss: 0.007623   Batch Acc: 79.69
[Train] Epoch: 0 [404608/620022]    Loss: 0.008457   Batch Acc: 81.25
[Train] Epoch: 0 [404672/620022]    Loss: 0.009603   Batch Acc: 71.88
[Train] Epoch: 0 [404736/620022]    Loss: 0.008905   Batch Acc: 70.31
[Train] Epoch: 0 [404800/620022]    Loss: 0.009425   Batch Acc: 75.00
[Train] Epoch: 0 [404864/620022]    Loss: 0.007522   Batch Acc: 81.25
[Train] Epoch: 0 [404928/620022]    Loss: 0.008750   Batch Acc: 82.81
[Train] Epoch: 0 [404992/620022]    Loss: 0.007917   Batch Acc: 81.25
[Train] Epoch: 0 [405056/620022]    Loss: 0.007565   Batch Acc: 78.12
[Train] Epoch: 0 [405120/620022]    Loss: 0.008041   Batch Acc: 81.25
[Train] Epoch: 0 [405184/620022]    Loss: 0.010260   Batch Acc: 75.00
[Train] Epoch: 0 [405248/620022]    Loss: 0.010100   Batch Acc: 70.31
[Train] Epoch: 0 [405312/620022]    Loss: 0.008651   Batch Acc: 75.00
[Train] Epoch: 0 [405376/620022]    Loss: 0.008496   Batch Acc: 78.12
[Train] Epoch: 0 [405440/620022]    Loss: 0.008622   Batch Acc: 79.69
[Train] Epoch: 0 [405504/620022]    Loss: 0.009290   Batch Acc: 75.00
[Train] Epoch: 0 [405568/620022]    Loss: 0.009198   Batch Acc: 75.00
[Train] Epoch: 0 [405632/620022]    Loss: 0.008890   Batch Acc: 70.31
[Train] Epoch: 0 [405696/620022]    Loss: 0.009565   Batch Acc: 70.31
[Train] Epoch: 0 [405760/620022]    Loss: 0.007492   Batch Acc: 82.81
[Train] Epoch: 0 [405824/620022]    Loss: 0.007663   Batch Acc: 78.12
[Train] Epoch: 0 [405888/620022]    Loss: 0.008205   Batch Acc: 79.69
[Train] Epoch: 0 [405952/620022]    Loss: 0.008318   Batch Acc: 82.81
[Train] Epoch: 0 [406016/620022]    Loss: 0.009723   Batch Acc: 70.31
[Train] Epoch: 0 [406080/620022]    Loss: 0.008056   Batch Acc: 73.44
[Train] Epoch: 0 [406144/620022]    Loss: 0.009288   Batch Acc: 73.44
[Train] Epoch: 0 [406208/620022]    Loss: 0.009132   Batch Acc: 78.12
[Train] Epoch: 0 [406272/620022]    Loss: 0.007393   Batch Acc: 81.25
[Train] Epoch: 0 [406336/620022]    Loss: 0.007779   Batch Acc: 81.25
[Train] Epoch: 0 [406400/620022]    Loss: 0.011033   Batch Acc: 64.06
[Train] Epoch: 0 [406464/620022]    Loss: 0.009116   Batch Acc: 78.12
[Train] Epoch: 0 [406528/620022]    Loss: 0.010318   Batch Acc: 70.31
[Train] Epoch: 0 [406592/620022]    Loss: 0.009687   Batch Acc: 76.56
[Train] Epoch: 0 [406656/620022]    Loss: 0.009002   Batch Acc: 81.25
[Train] Epoch: 0 [406720/620022]    Loss: 0.009465   Batch Acc: 75.00
[Train] Epoch: 0 [406784/620022]    Loss: 0.008000   Batch Acc: 79.69
[Train] Epoch: 0 [406848/620022]    Loss: 0.009708   Batch Acc: 70.31
[Train] Epoch: 0 [406912/620022]    Loss: 0.010853   Batch Acc: 70.31
[Train] Epoch: 0 [406976/620022]    Loss: 0.009551   Batch Acc: 76.56
[Train] Epoch: 0 [407040/620022]    Loss: 0.008020   Batch Acc: 81.25
[Train] Epoch: 0 [407104/620022]    Loss: 0.011868   Batch Acc: 62.50
[Train] Epoch: 0 [407168/620022]    Loss: 0.010370   Batch Acc: 65.62
[Train] Epoch: 0 [407232/620022]    Loss: 0.008586   Batch Acc: 79.69
[Train] Epoch: 0 [407296/620022]    Loss: 0.008496   Batch Acc: 76.56
[Train] Epoch: 0 [407360/620022]    Loss: 0.010683   Batch Acc: 75.00
[Train] Epoch: 0 [407424/620022]    Loss: 0.007688   Batch Acc: 75.00
[Train] Epoch: 0 [407488/620022]    Loss: 0.009690   Batch Acc: 75.00
[Train] Epoch: 0 [407552/620022]    Loss: 0.007352   Batch Acc: 85.94
[Train] Epoch: 0 [407616/620022]    Loss: 0.008792   Batch Acc: 78.12
[Train] Epoch: 0 [407680/620022]    Loss: 0.008985   Batch Acc: 76.56
[Train] Epoch: 0 [407744/620022]    Loss: 0.008785   Batch Acc: 73.44
[Train] Epoch: 0 [407808/620022]    Loss: 0.009241   Batch Acc: 75.00
[Train] Epoch: 0 [407872/620022]    Loss: 0.009476   Batch Acc: 73.44
[Train] Epoch: 0 [407936/620022]    Loss: 0.008680   Batch Acc: 79.69
[Train] Epoch: 0 [408000/620022]    Loss: 0.009464   Batch Acc: 78.12
[Train] Epoch: 0 [408064/620022]    Loss: 0.008822   Batch Acc: 82.81
[Train] Epoch: 0 [408128/620022]    Loss: 0.011466   Batch Acc: 73.44
[Train] Epoch: 0 [408192/620022]    Loss: 0.008247   Batch Acc: 78.12
[Train] Epoch: 0 [408256/620022]    Loss: 0.007776   Batch Acc: 82.81
[Train] Epoch: 0 [408320/620022]    Loss: 0.007950   Batch Acc: 81.25
[Train] Epoch: 0 [408384/620022]    Loss: 0.008257   Batch Acc: 84.38
[Train] Epoch: 0 [408448/620022]    Loss: 0.009669   Batch Acc: 78.12
[Train] Epoch: 0 [408512/620022]    Loss: 0.010528   Batch Acc: 76.56
[Train] Epoch: 0 [408576/620022]    Loss: 0.009938   Batch Acc: 70.31
[Train] Epoch: 0 [408640/620022]    Loss: 0.008842   Batch Acc: 82.81
[Train] Epoch: 0 [408704/620022]    Loss: 0.009435   Batch Acc: 78.12
[Train] Epoch: 0 [408768/620022]    Loss: 0.008321   Batch Acc: 75.00
[Train] Epoch: 0 [408832/620022]    Loss: 0.009863   Batch Acc: 76.56
[Train] Epoch: 0 [408896/620022]    Loss: 0.008186   Batch Acc: 78.12
[Train] Epoch: 0 [408960/620022]    Loss: 0.006902   Batch Acc: 85.94
[Train] Epoch: 0 [409024/620022]    Loss: 0.009001   Batch Acc: 73.44
[Train] Epoch: 0 [409088/620022]    Loss: 0.008731   Batch Acc: 79.69
[Train] Epoch: 0 [409152/620022]    Loss: 0.012272   Batch Acc: 71.88
[Train] Epoch: 0 [409216/620022]    Loss: 0.008031   Batch Acc: 81.25
[Train] Epoch: 0 [409280/620022]    Loss: 0.011984   Batch Acc: 62.50
[Train] Epoch: 0 [409344/620022]    Loss: 0.010812   Batch Acc: 71.88
[Train] Epoch: 0 [409408/620022]    Loss: 0.008186   Batch Acc: 81.25
[Train] Epoch: 0 [409472/620022]    Loss: 0.008509   Batch Acc: 76.56
[Train] Epoch: 0 [409536/620022]    Loss: 0.008029   Batch Acc: 82.81
[Train] Epoch: 0 [409600/620022]    Loss: 0.010461   Batch Acc: 68.75
[Train] Epoch: 0 [409664/620022]    Loss: 0.008535   Batch Acc: 73.44
[Train] Epoch: 0 [409728/620022]    Loss: 0.008362   Batch Acc: 82.81
[Train] Epoch: 0 [409792/620022]    Loss: 0.008708   Batch Acc: 78.12
[Train] Epoch: 0 [409856/620022]    Loss: 0.008881   Batch Acc: 76.56
[Train] Epoch: 0 [409920/620022]    Loss: 0.010008   Batch Acc: 68.75
[Train] Epoch: 0 [409984/620022]    Loss: 0.010773   Batch Acc: 60.94
[Train] Epoch: 0 [410048/620022]    Loss: 0.011159   Batch Acc: 67.19
[Train] Epoch: 0 [410112/620022]    Loss: 0.010498   Batch Acc: 70.31
[Train] Epoch: 0 [410176/620022]    Loss: 0.011015   Batch Acc: 65.62
[Train] Epoch: 0 [410240/620022]    Loss: 0.008425   Batch Acc: 78.12
[Train] Epoch: 0 [410304/620022]    Loss: 0.009479   Batch Acc: 76.56
[Train] Epoch: 0 [410368/620022]    Loss: 0.007916   Batch Acc: 78.12
[Train] Epoch: 0 [410432/620022]    Loss: 0.008723   Batch Acc: 73.44
[Train] Epoch: 0 [410496/620022]    Loss: 0.008542   Batch Acc: 82.81
[Train] Epoch: 0 [410560/620022]    Loss: 0.009422   Batch Acc: 76.56
[Train] Epoch: 0 [410624/620022]    Loss: 0.008654   Batch Acc: 81.25
[Train] Epoch: 0 [410688/620022]    Loss: 0.010104   Batch Acc: 73.44
[Train] Epoch: 0 [410752/620022]    Loss: 0.009644   Batch Acc: 76.56
[Train] Epoch: 0 [410816/620022]    Loss: 0.008205   Batch Acc: 78.12
[Train] Epoch: 0 [410880/620022]    Loss: 0.008543   Batch Acc: 76.56
[Train] Epoch: 0 [410944/620022]    Loss: 0.007442   Batch Acc: 84.38
[Train] Epoch: 0 [411008/620022]    Loss: 0.007593   Batch Acc: 82.81
[Train] Epoch: 0 [411072/620022]    Loss: 0.009403   Batch Acc: 70.31
[Train] Epoch: 0 [411136/620022]    Loss: 0.008580   Batch Acc: 75.00
[Train] Epoch: 0 [411200/620022]    Loss: 0.008434   Batch Acc: 81.25
[Train] Epoch: 0 [411264/620022]    Loss: 0.006603   Batch Acc: 85.94
[Train] Epoch: 0 [411328/620022]    Loss: 0.007233   Batch Acc: 82.81
[Train] Epoch: 0 [411392/620022]    Loss: 0.010225   Batch Acc: 71.88
[Train] Epoch: 0 [411456/620022]    Loss: 0.010033   Batch Acc: 76.56
[Train] Epoch: 0 [411520/620022]    Loss: 0.008511   Batch Acc: 81.25
[Train] Epoch: 0 [411584/620022]    Loss: 0.010193   Batch Acc: 68.75
[Train] Epoch: 0 [411648/620022]    Loss: 0.008042   Batch Acc: 79.69
[Train] Epoch: 0 [411712/620022]    Loss: 0.010358   Batch Acc: 76.56
[Train] Epoch: 0 [411776/620022]    Loss: 0.011891   Batch Acc: 67.19
[Train] Epoch: 0 [411840/620022]    Loss: 0.007885   Batch Acc: 82.81
[Train] Epoch: 0 [411904/620022]    Loss: 0.008404   Batch Acc: 82.81
[Train] Epoch: 0 [411968/620022]    Loss: 0.008081   Batch Acc: 76.56
[Train] Epoch: 0 [412032/620022]    Loss: 0.007101   Batch Acc: 81.25
[Train] Epoch: 0 [412096/620022]    Loss: 0.009387   Batch Acc: 71.88
[Train] Epoch: 0 [412160/620022]    Loss: 0.007346   Batch Acc: 76.56
[Train] Epoch: 0 [412224/620022]    Loss: 0.010305   Batch Acc: 73.44
[Train] Epoch: 0 [412288/620022]    Loss: 0.009896   Batch Acc: 71.88
[Train] Epoch: 0 [412352/620022]    Loss: 0.008939   Batch Acc: 82.81
[Train] Epoch: 0 [412416/620022]    Loss: 0.008839   Batch Acc: 78.12
[Train] Epoch: 0 [412480/620022]    Loss: 0.010054   Batch Acc: 68.75
[Train] Epoch: 0 [412544/620022]    Loss: 0.011401   Batch Acc: 67.19
[Train] Epoch: 0 [412608/620022]    Loss: 0.009154   Batch Acc: 76.56
[Train] Epoch: 0 [412672/620022]    Loss: 0.008341   Batch Acc: 78.12
[Train] Epoch: 0 [412736/620022]    Loss: 0.009082   Batch Acc: 79.69
[Train] Epoch: 0 [412800/620022]    Loss: 0.007147   Batch Acc: 84.38
[Train] Epoch: 0 [412864/620022]    Loss: 0.011757   Batch Acc: 68.75
[Train] Epoch: 0 [412928/620022]    Loss: 0.006603   Batch Acc: 85.94
[Train] Epoch: 0 [412992/620022]    Loss: 0.007705   Batch Acc: 85.94
[Train] Epoch: 0 [413056/620022]    Loss: 0.011264   Batch Acc: 70.31
[Train] Epoch: 0 [413120/620022]    Loss: 0.011668   Batch Acc: 71.88
[Train] Epoch: 0 [413184/620022]    Loss: 0.009846   Batch Acc: 73.44
[Train] Epoch: 0 [413248/620022]    Loss: 0.008002   Batch Acc: 75.00
[Train] Epoch: 0 [413312/620022]    Loss: 0.010831   Batch Acc: 68.75
[Train] Epoch: 0 [413376/620022]    Loss: 0.009404   Batch Acc: 73.44
[Train] Epoch: 0 [413440/620022]    Loss: 0.010421   Batch Acc: 76.56
[Train] Epoch: 0 [413504/620022]    Loss: 0.008988   Batch Acc: 79.69
[Train] Epoch: 0 [413568/620022]    Loss: 0.009373   Batch Acc: 79.69
[Train] Epoch: 0 [413632/620022]    Loss: 0.009531   Batch Acc: 75.00
[Train] Epoch: 0 [413696/620022]    Loss: 0.010614   Batch Acc: 68.75
[Train] Epoch: 0 [413760/620022]    Loss: 0.008786   Batch Acc: 79.69
[Train] Epoch: 0 [413824/620022]    Loss: 0.010457   Batch Acc: 71.88
[Train] Epoch: 0 [413888/620022]    Loss: 0.009564   Batch Acc: 71.88
[Train] Epoch: 0 [413952/620022]    Loss: 0.007672   Batch Acc: 76.56
[Train] Epoch: 0 [414016/620022]    Loss: 0.009772   Batch Acc: 75.00
[Train] Epoch: 0 [414080/620022]    Loss: 0.007623   Batch Acc: 78.12
[Train] Epoch: 0 [414144/620022]    Loss: 0.008047   Batch Acc: 81.25
[Train] Epoch: 0 [414208/620022]    Loss: 0.011111   Batch Acc: 70.31
[Train] Epoch: 0 [414272/620022]    Loss: 0.009884   Batch Acc: 75.00
[Train] Epoch: 0 [414336/620022]    Loss: 0.008647   Batch Acc: 79.69
[Train] Epoch: 0 [414400/620022]    Loss: 0.009215   Batch Acc: 79.69
[Train] Epoch: 0 [414464/620022]    Loss: 0.008255   Batch Acc: 75.00
[Train] Epoch: 0 [414528/620022]    Loss: 0.009932   Batch Acc: 73.44
[Train] Epoch: 0 [414592/620022]    Loss: 0.009042   Batch Acc: 73.44
[Train] Epoch: 0 [414656/620022]    Loss: 0.009913   Batch Acc: 82.81
[Train] Epoch: 0 [414720/620022]    Loss: 0.007550   Batch Acc: 78.12
[Train] Epoch: 0 [414784/620022]    Loss: 0.006742   Batch Acc: 85.94
[Train] Epoch: 0 [414848/620022]    Loss: 0.008754   Batch Acc: 78.12
[Train] Epoch: 0 [414912/620022]    Loss: 0.009971   Batch Acc: 75.00
[Train] Epoch: 0 [414976/620022]    Loss: 0.007302   Batch Acc: 84.38
[Train] Epoch: 0 [415040/620022]    Loss: 0.010296   Batch Acc: 67.19
[Train] Epoch: 0 [415104/620022]    Loss: 0.008795   Batch Acc: 76.56
[Train] Epoch: 0 [415168/620022]    Loss: 0.007591   Batch Acc: 85.94
[Train] Epoch: 0 [415232/620022]    Loss: 0.009139   Batch Acc: 73.44
[Train] Epoch: 0 [415296/620022]    Loss: 0.011755   Batch Acc: 70.31
[Train] Epoch: 0 [415360/620022]    Loss: 0.009620   Batch Acc: 70.31
[Train] Epoch: 0 [415424/620022]    Loss: 0.007917   Batch Acc: 81.25
[Train] Epoch: 0 [415488/620022]    Loss: 0.010107   Batch Acc: 71.88
[Train] Epoch: 0 [415552/620022]    Loss: 0.010659   Batch Acc: 73.44
[Train] Epoch: 0 [415616/620022]    Loss: 0.005877   Batch Acc: 89.06
[Train] Epoch: 0 [415680/620022]    Loss: 0.010203   Batch Acc: 70.31
[Train] Epoch: 0 [415744/620022]    Loss: 0.009384   Batch Acc: 75.00
[Train] Epoch: 0 [415808/620022]    Loss: 0.008367   Batch Acc: 78.12
[Train] Epoch: 0 [415872/620022]    Loss: 0.008852   Batch Acc: 76.56
[Train] Epoch: 0 [415936/620022]    Loss: 0.009877   Batch Acc: 78.12
[Train] Epoch: 0 [416000/620022]    Loss: 0.009318   Batch Acc: 71.88
[Train] Epoch: 0 [416064/620022]    Loss: 0.009123   Batch Acc: 73.44
[Train] Epoch: 0 [416128/620022]    Loss: 0.009516   Batch Acc: 73.44
[Train] Epoch: 0 [416192/620022]    Loss: 0.008678   Batch Acc: 76.56
[Train] Epoch: 0 [416256/620022]    Loss: 0.009484   Batch Acc: 71.88
[Train] Epoch: 0 [416320/620022]    Loss: 0.008471   Batch Acc: 73.44
[Train] Epoch: 0 [416384/620022]    Loss: 0.008088   Batch Acc: 78.12
[Train] Epoch: 0 [416448/620022]    Loss: 0.009496   Batch Acc: 71.88
[Train] Epoch: 0 [416512/620022]    Loss: 0.010198   Batch Acc: 73.44
[Train] Epoch: 0 [416576/620022]    Loss: 0.008981   Batch Acc: 75.00
[Train] Epoch: 0 [416640/620022]    Loss: 0.008589   Batch Acc: 78.12
[Train] Epoch: 0 [416704/620022]    Loss: 0.008409   Batch Acc: 76.56
[Train] Epoch: 0 [416768/620022]    Loss: 0.010986   Batch Acc: 78.12
[Train] Epoch: 0 [416832/620022]    Loss: 0.007837   Batch Acc: 81.25
[Train] Epoch: 0 [416896/620022]    Loss: 0.009726   Batch Acc: 71.88
[Train] Epoch: 0 [416960/620022]    Loss: 0.011027   Batch Acc: 71.88
[Train] Epoch: 0 [417024/620022]    Loss: 0.008400   Batch Acc: 73.44
[Train] Epoch: 0 [417088/620022]    Loss: 0.010260   Batch Acc: 71.88
[Train] Epoch: 0 [417152/620022]    Loss: 0.008919   Batch Acc: 79.69
[Train] Epoch: 0 [417216/620022]    Loss: 0.012085   Batch Acc: 75.00
[Train] Epoch: 0 [417280/620022]    Loss: 0.009181   Batch Acc: 76.56
[Train] Epoch: 0 [417344/620022]    Loss: 0.007954   Batch Acc: 81.25
[Train] Epoch: 0 [417408/620022]    Loss: 0.011496   Batch Acc: 71.88
[Train] Epoch: 0 [417472/620022]    Loss: 0.007089   Batch Acc: 82.81
[Train] Epoch: 0 [417536/620022]    Loss: 0.009710   Batch Acc: 78.12
[Train] Epoch: 0 [417600/620022]    Loss: 0.008478   Batch Acc: 76.56
[Train] Epoch: 0 [417664/620022]    Loss: 0.011901   Batch Acc: 64.06
[Train] Epoch: 0 [417728/620022]    Loss: 0.011110   Batch Acc: 73.44
[Train] Epoch: 0 [417792/620022]    Loss: 0.010087   Batch Acc: 68.75
[Train] Epoch: 0 [417856/620022]    Loss: 0.010273   Batch Acc: 73.44
[Train] Epoch: 0 [417920/620022]    Loss: 0.008423   Batch Acc: 76.56
[Train] Epoch: 0 [417984/620022]    Loss: 0.008378   Batch Acc: 75.00
[Train] Epoch: 0 [418048/620022]    Loss: 0.009668   Batch Acc: 76.56
[Train] Epoch: 0 [418112/620022]    Loss: 0.010552   Batch Acc: 68.75
[Train] Epoch: 0 [418176/620022]    Loss: 0.007673   Batch Acc: 84.38
[Train] Epoch: 0 [418240/620022]    Loss: 0.011121   Batch Acc: 70.31
[Train] Epoch: 0 [418304/620022]    Loss: 0.008531   Batch Acc: 81.25
[Train] Epoch: 0 [418368/620022]    Loss: 0.008961   Batch Acc: 75.00
[Train] Epoch: 0 [418432/620022]    Loss: 0.010718   Batch Acc: 71.88
[Train] Epoch: 0 [418496/620022]    Loss: 0.008716   Batch Acc: 81.25
[Train] Epoch: 0 [418560/620022]    Loss: 0.009253   Batch Acc: 79.69
[Train] Epoch: 0 [418624/620022]    Loss: 0.010808   Batch Acc: 67.19
[Train] Epoch: 0 [418688/620022]    Loss: 0.010017   Batch Acc: 70.31
[Train] Epoch: 0 [418752/620022]    Loss: 0.006365   Batch Acc: 90.62
[Train] Epoch: 0 [418816/620022]    Loss: 0.009673   Batch Acc: 75.00
[Train] Epoch: 0 [418880/620022]    Loss: 0.009320   Batch Acc: 75.00
[Train] Epoch: 0 [418944/620022]    Loss: 0.008730   Batch Acc: 75.00
[Train] Epoch: 0 [419008/620022]    Loss: 0.007999   Batch Acc: 82.81
[Train] Epoch: 0 [419072/620022]    Loss: 0.009398   Batch Acc: 78.12
[Train] Epoch: 0 [419136/620022]    Loss: 0.008167   Batch Acc: 79.69
[Train] Epoch: 0 [419200/620022]    Loss: 0.006517   Batch Acc: 84.38
[Train] Epoch: 0 [419264/620022]    Loss: 0.009242   Batch Acc: 73.44
[Train] Epoch: 0 [419328/620022]    Loss: 0.008624   Batch Acc: 76.56
[Train] Epoch: 0 [419392/620022]    Loss: 0.009076   Batch Acc: 81.25
[Train] Epoch: 0 [419456/620022]    Loss: 0.009239   Batch Acc: 82.81
[Train] Epoch: 0 [419520/620022]    Loss: 0.008685   Batch Acc: 78.12
[Train] Epoch: 0 [419584/620022]    Loss: 0.011078   Batch Acc: 64.06
[Train] Epoch: 0 [419648/620022]    Loss: 0.007813   Batch Acc: 85.94
[Train] Epoch: 0 [419712/620022]    Loss: 0.008886   Batch Acc: 76.56
[Train] Epoch: 0 [419776/620022]    Loss: 0.009169   Batch Acc: 81.25
[Train] Epoch: 0 [419840/620022]    Loss: 0.009478   Batch Acc: 75.00
[Train] Epoch: 0 [419904/620022]    Loss: 0.008741   Batch Acc: 81.25
[Train] Epoch: 0 [419968/620022]    Loss: 0.009563   Batch Acc: 78.12
[Train] Epoch: 0 [420032/620022]    Loss: 0.010787   Batch Acc: 70.31
[Train] Epoch: 0 [420096/620022]    Loss: 0.011399   Batch Acc: 65.62
[Train] Epoch: 0 [420160/620022]    Loss: 0.006867   Batch Acc: 85.94
[Train] Epoch: 0 [420224/620022]    Loss: 0.010682   Batch Acc: 67.19
[Train] Epoch: 0 [420288/620022]    Loss: 0.010597   Batch Acc: 71.88
[Train] Epoch: 0 [420352/620022]    Loss: 0.008927   Batch Acc: 75.00
[Train] Epoch: 0 [420416/620022]    Loss: 0.007549   Batch Acc: 82.81
[Train] Epoch: 0 [420480/620022]    Loss: 0.006138   Batch Acc: 82.81
[Train] Epoch: 0 [420544/620022]    Loss: 0.006953   Batch Acc: 85.94
[Train] Epoch: 0 [420608/620022]    Loss: 0.011003   Batch Acc: 73.44
[Train] Epoch: 0 [420672/620022]    Loss: 0.008956   Batch Acc: 79.69
[Train] Epoch: 0 [420736/620022]    Loss: 0.009333   Batch Acc: 75.00
[Train] Epoch: 0 [420800/620022]    Loss: 0.008121   Batch Acc: 75.00
[Train] Epoch: 0 [420864/620022]    Loss: 0.007182   Batch Acc: 89.06
[Train] Epoch: 0 [420928/620022]    Loss: 0.007662   Batch Acc: 81.25
[Train] Epoch: 0 [420992/620022]    Loss: 0.010955   Batch Acc: 70.31
[Train] Epoch: 0 [421056/620022]    Loss: 0.007563   Batch Acc: 85.94
[Train] Epoch: 0 [421120/620022]    Loss: 0.009434   Batch Acc: 78.12
[Train] Epoch: 0 [421184/620022]    Loss: 0.013364   Batch Acc: 65.62
[Train] Epoch: 0 [421248/620022]    Loss: 0.007819   Batch Acc: 82.81
[Train] Epoch: 0 [421312/620022]    Loss: 0.008193   Batch Acc: 79.69
[Train] Epoch: 0 [421376/620022]    Loss: 0.008358   Batch Acc: 78.12
[Train] Epoch: 0 [421440/620022]    Loss: 0.007583   Batch Acc: 78.12
[Train] Epoch: 0 [421504/620022]    Loss: 0.009689   Batch Acc: 70.31
[Train] Epoch: 0 [421568/620022]    Loss: 0.008773   Batch Acc: 78.12
[Train] Epoch: 0 [421632/620022]    Loss: 0.008944   Batch Acc: 78.12
[Train] Epoch: 0 [421696/620022]    Loss: 0.009878   Batch Acc: 71.88
[Train] Epoch: 0 [421760/620022]    Loss: 0.008020   Batch Acc: 84.38
[Train] Epoch: 0 [421824/620022]    Loss: 0.008190   Batch Acc: 79.69
[Train] Epoch: 0 [421888/620022]    Loss: 0.006443   Batch Acc: 85.94
[Train] Epoch: 0 [421952/620022]    Loss: 0.008829   Batch Acc: 75.00
[Train] Epoch: 0 [422016/620022]    Loss: 0.007736   Batch Acc: 85.94
[Train] Epoch: 0 [422080/620022]    Loss: 0.008725   Batch Acc: 76.56
[Train] Epoch: 0 [422144/620022]    Loss: 0.007794   Batch Acc: 81.25
[Train] Epoch: 0 [422208/620022]    Loss: 0.011024   Batch Acc: 79.69
[Train] Epoch: 0 [422272/620022]    Loss: 0.007921   Batch Acc: 82.81
[Train] Epoch: 0 [422336/620022]    Loss: 0.010911   Batch Acc: 68.75
[Train] Epoch: 0 [422400/620022]    Loss: 0.007820   Batch Acc: 79.69
[Train] Epoch: 0 [422464/620022]    Loss: 0.009925   Batch Acc: 68.75
[Train] Epoch: 0 [422528/620022]    Loss: 0.008749   Batch Acc: 81.25
[Train] Epoch: 0 [422592/620022]    Loss: 0.011835   Batch Acc: 65.62
[Train] Epoch: 0 [422656/620022]    Loss: 0.008890   Batch Acc: 75.00
[Train] Epoch: 0 [422720/620022]    Loss: 0.007682   Batch Acc: 84.38
[Train] Epoch: 0 [422784/620022]    Loss: 0.007602   Batch Acc: 81.25
[Train] Epoch: 0 [422848/620022]    Loss: 0.009315   Batch Acc: 76.56
[Train] Epoch: 0 [422912/620022]    Loss: 0.008176   Batch Acc: 82.81
[Train] Epoch: 0 [422976/620022]    Loss: 0.008818   Batch Acc: 76.56
[Train] Epoch: 0 [423040/620022]    Loss: 0.009337   Batch Acc: 73.44
[Train] Epoch: 0 [423104/620022]    Loss: 0.010029   Batch Acc: 70.31
[Train] Epoch: 0 [423168/620022]    Loss: 0.007640   Batch Acc: 79.69
[Train] Epoch: 0 [423232/620022]    Loss: 0.009282   Batch Acc: 68.75
[Train] Epoch: 0 [423296/620022]    Loss: 0.009287   Batch Acc: 75.00
[Train] Epoch: 0 [423360/620022]    Loss: 0.010434   Batch Acc: 73.44
[Train] Epoch: 0 [423424/620022]    Loss: 0.009269   Batch Acc: 71.88
[Train] Epoch: 0 [423488/620022]    Loss: 0.008581   Batch Acc: 75.00
[Train] Epoch: 0 [423552/620022]    Loss: 0.008914   Batch Acc: 75.00
[Train] Epoch: 0 [423616/620022]    Loss: 0.010522   Batch Acc: 71.88
[Train] Epoch: 0 [423680/620022]    Loss: 0.010452   Batch Acc: 73.44
[Train] Epoch: 0 [423744/620022]    Loss: 0.007160   Batch Acc: 82.81
[Train] Epoch: 0 [423808/620022]    Loss: 0.009371   Batch Acc: 76.56
[Train] Epoch: 0 [423872/620022]    Loss: 0.008015   Batch Acc: 84.38
[Train] Epoch: 0 [423936/620022]    Loss: 0.007648   Batch Acc: 79.69
[Train] Epoch: 0 [424000/620022]    Loss: 0.012855   Batch Acc: 64.06
[Train] Epoch: 0 [424064/620022]    Loss: 0.008959   Batch Acc: 79.69
[Train] Epoch: 0 [424128/620022]    Loss: 0.008007   Batch Acc: 81.25
[Train] Epoch: 0 [424192/620022]    Loss: 0.008625   Batch Acc: 76.56
[Train] Epoch: 0 [424256/620022]    Loss: 0.008715   Batch Acc: 71.88
[Train] Epoch: 0 [424320/620022]    Loss: 0.008681   Batch Acc: 81.25
[Train] Epoch: 0 [424384/620022]    Loss: 0.007773   Batch Acc: 84.38
[Train] Epoch: 0 [424448/620022]    Loss: 0.009271   Batch Acc: 79.69
[Train] Epoch: 0 [424512/620022]    Loss: 0.008101   Batch Acc: 79.69
[Train] Epoch: 0 [424576/620022]    Loss: 0.009242   Batch Acc: 70.31
[Train] Epoch: 0 [424640/620022]    Loss: 0.011677   Batch Acc: 67.19
[Train] Epoch: 0 [424704/620022]    Loss: 0.009400   Batch Acc: 76.56
[Train] Epoch: 0 [424768/620022]    Loss: 0.007572   Batch Acc: 81.25
[Train] Epoch: 0 [424832/620022]    Loss: 0.008050   Batch Acc: 81.25
[Train] Epoch: 0 [424896/620022]    Loss: 0.010597   Batch Acc: 73.44
[Train] Epoch: 0 [424960/620022]    Loss: 0.010467   Batch Acc: 76.56
[Train] Epoch: 0 [425024/620022]    Loss: 0.007027   Batch Acc: 82.81
[Train] Epoch: 0 [425088/620022]    Loss: 0.009444   Batch Acc: 76.56
[Train] Epoch: 0 [425152/620022]    Loss: 0.008132   Batch Acc: 78.12
[Train] Epoch: 0 [425216/620022]    Loss: 0.009063   Batch Acc: 73.44
[Train] Epoch: 0 [425280/620022]    Loss: 0.006875   Batch Acc: 84.38
[Train] Epoch: 0 [425344/620022]    Loss: 0.007143   Batch Acc: 84.38
[Train] Epoch: 0 [425408/620022]    Loss: 0.008023   Batch Acc: 81.25
[Train] Epoch: 0 [425472/620022]    Loss: 0.009610   Batch Acc: 79.69
[Train] Epoch: 0 [425536/620022]    Loss: 0.008065   Batch Acc: 79.69
[Train] Epoch: 0 [425600/620022]    Loss: 0.008710   Batch Acc: 75.00
[Train] Epoch: 0 [425664/620022]    Loss: 0.011968   Batch Acc: 73.44
[Train] Epoch: 0 [425728/620022]    Loss: 0.009051   Batch Acc: 78.12
[Train] Epoch: 0 [425792/620022]    Loss: 0.010474   Batch Acc: 78.12
[Train] Epoch: 0 [425856/620022]    Loss: 0.009314   Batch Acc: 75.00
[Train] Epoch: 0 [425920/620022]    Loss: 0.007463   Batch Acc: 76.56
[Train] Epoch: 0 [425984/620022]    Loss: 0.006939   Batch Acc: 82.81
[Train] Epoch: 0 [426048/620022]    Loss: 0.007617   Batch Acc: 78.12
[Train] Epoch: 0 [426112/620022]    Loss: 0.007981   Batch Acc: 82.81
[Train] Epoch: 0 [426176/620022]    Loss: 0.009732   Batch Acc: 76.56
[Train] Epoch: 0 [426240/620022]    Loss: 0.008345   Batch Acc: 79.69
[Train] Epoch: 0 [426304/620022]    Loss: 0.008111   Batch Acc: 79.69
[Train] Epoch: 0 [426368/620022]    Loss: 0.008342   Batch Acc: 76.56
[Train] Epoch: 0 [426432/620022]    Loss: 0.009926   Batch Acc: 73.44
[Train] Epoch: 0 [426496/620022]    Loss: 0.007227   Batch Acc: 85.94
[Train] Epoch: 0 [426560/620022]    Loss: 0.008327   Batch Acc: 82.81
[Train] Epoch: 0 [426624/620022]    Loss: 0.009201   Batch Acc: 79.69
[Train] Epoch: 0 [426688/620022]    Loss: 0.011260   Batch Acc: 70.31
[Train] Epoch: 0 [426752/620022]    Loss: 0.007914   Batch Acc: 81.25
[Train] Epoch: 0 [426816/620022]    Loss: 0.007399   Batch Acc: 84.38
[Train] Epoch: 0 [426880/620022]    Loss: 0.010542   Batch Acc: 75.00
[Train] Epoch: 0 [426944/620022]    Loss: 0.009648   Batch Acc: 79.69
[Train] Epoch: 0 [427008/620022]    Loss: 0.009329   Batch Acc: 76.56
[Train] Epoch: 0 [427072/620022]    Loss: 0.007960   Batch Acc: 82.81
[Train] Epoch: 0 [427136/620022]    Loss: 0.008306   Batch Acc: 82.81
[Train] Epoch: 0 [427200/620022]    Loss: 0.009866   Batch Acc: 76.56
[Train] Epoch: 0 [427264/620022]    Loss: 0.008290   Batch Acc: 84.38
[Train] Epoch: 0 [427328/620022]    Loss: 0.007841   Batch Acc: 79.69
[Train] Epoch: 0 [427392/620022]    Loss: 0.008940   Batch Acc: 71.88
[Train] Epoch: 0 [427456/620022]    Loss: 0.009140   Batch Acc: 78.12
[Train] Epoch: 0 [427520/620022]    Loss: 0.008415   Batch Acc: 79.69
[Train] Epoch: 0 [427584/620022]    Loss: 0.008348   Batch Acc: 79.69
[Train] Epoch: 0 [427648/620022]    Loss: 0.007743   Batch Acc: 82.81
[Train] Epoch: 0 [427712/620022]    Loss: 0.008524   Batch Acc: 79.69
[Train] Epoch: 0 [427776/620022]    Loss: 0.009372   Batch Acc: 75.00
[Train] Epoch: 0 [427840/620022]    Loss: 0.009382   Batch Acc: 75.00
[Train] Epoch: 0 [427904/620022]    Loss: 0.010015   Batch Acc: 73.44
[Train] Epoch: 0 [427968/620022]    Loss: 0.009312   Batch Acc: 75.00
[Train] Epoch: 0 [428032/620022]    Loss: 0.009502   Batch Acc: 75.00
[Train] Epoch: 0 [428096/620022]    Loss: 0.008810   Batch Acc: 79.69
[Train] Epoch: 0 [428160/620022]    Loss: 0.008149   Batch Acc: 81.25
[Train] Epoch: 0 [428224/620022]    Loss: 0.011153   Batch Acc: 70.31
[Train] Epoch: 0 [428288/620022]    Loss: 0.010552   Batch Acc: 76.56
[Train] Epoch: 0 [428352/620022]    Loss: 0.007617   Batch Acc: 84.38
[Train] Epoch: 0 [428416/620022]    Loss: 0.006518   Batch Acc: 81.25
[Train] Epoch: 0 [428480/620022]    Loss: 0.008746   Batch Acc: 76.56
[Train] Epoch: 0 [428544/620022]    Loss: 0.007688   Batch Acc: 85.94
[Train] Epoch: 0 [428608/620022]    Loss: 0.008873   Batch Acc: 75.00
[Train] Epoch: 0 [428672/620022]    Loss: 0.009018   Batch Acc: 73.44
[Train] Epoch: 0 [428736/620022]    Loss: 0.007871   Batch Acc: 82.81
[Train] Epoch: 0 [428800/620022]    Loss: 0.006756   Batch Acc: 84.38
[Train] Epoch: 0 [428864/620022]    Loss: 0.008019   Batch Acc: 84.38
[Train] Epoch: 0 [428928/620022]    Loss: 0.007393   Batch Acc: 84.38
[Train] Epoch: 0 [428992/620022]    Loss: 0.009277   Batch Acc: 73.44
[Train] Epoch: 0 [429056/620022]    Loss: 0.007802   Batch Acc: 81.25
[Train] Epoch: 0 [429120/620022]    Loss: 0.008807   Batch Acc: 73.44
[Train] Epoch: 0 [429184/620022]    Loss: 0.007214   Batch Acc: 82.81
[Train] Epoch: 0 [429248/620022]    Loss: 0.007846   Batch Acc: 82.81
[Train] Epoch: 0 [429312/620022]    Loss: 0.008379   Batch Acc: 79.69
[Train] Epoch: 0 [429376/620022]    Loss: 0.009131   Batch Acc: 78.12
[Train] Epoch: 0 [429440/620022]    Loss: 0.009758   Batch Acc: 70.31
[Train] Epoch: 0 [429504/620022]    Loss: 0.009331   Batch Acc: 76.56
[Train] Epoch: 0 [429568/620022]    Loss: 0.009044   Batch Acc: 78.12
[Train] Epoch: 0 [429632/620022]    Loss: 0.007756   Batch Acc: 85.94
[Train] Epoch: 0 [429696/620022]    Loss: 0.008164   Batch Acc: 75.00
[Train] Epoch: 0 [429760/620022]    Loss: 0.008846   Batch Acc: 81.25
[Train] Epoch: 0 [429824/620022]    Loss: 0.008955   Batch Acc: 82.81
[Train] Epoch: 0 [429888/620022]    Loss: 0.008538   Batch Acc: 76.56
[Train] Epoch: 0 [429952/620022]    Loss: 0.009544   Batch Acc: 79.69
[Train] Epoch: 0 [430016/620022]    Loss: 0.007765   Batch Acc: 82.81
[Train] Epoch: 0 [430080/620022]    Loss: 0.010008   Batch Acc: 75.00
[Train] Epoch: 0 [430144/620022]    Loss: 0.008084   Batch Acc: 81.25
[Train] Epoch: 0 [430208/620022]    Loss: 0.008808   Batch Acc: 71.88
[Train] Epoch: 0 [430272/620022]    Loss: 0.009472   Batch Acc: 78.12
[Train] Epoch: 0 [430336/620022]    Loss: 0.009914   Batch Acc: 73.44
[Train] Epoch: 0 [430400/620022]    Loss: 0.006204   Batch Acc: 89.06
[Train] Epoch: 0 [430464/620022]    Loss: 0.008431   Batch Acc: 78.12
[Train] Epoch: 0 [430528/620022]    Loss: 0.009600   Batch Acc: 73.44
[Train] Epoch: 0 [430592/620022]    Loss: 0.008262   Batch Acc: 79.69
[Train] Epoch: 0 [430656/620022]    Loss: 0.007476   Batch Acc: 81.25
[Train] Epoch: 0 [430720/620022]    Loss: 0.007402   Batch Acc: 84.38
[Train] Epoch: 0 [430784/620022]    Loss: 0.008731   Batch Acc: 79.69
[Train] Epoch: 0 [430848/620022]    Loss: 0.006822   Batch Acc: 81.25
[Train] Epoch: 0 [430912/620022]    Loss: 0.009047   Batch Acc: 73.44
[Train] Epoch: 0 [430976/620022]    Loss: 0.009433   Batch Acc: 78.12
[Train] Epoch: 0 [431040/620022]    Loss: 0.008487   Batch Acc: 81.25
[Train] Epoch: 0 [431104/620022]    Loss: 0.007895   Batch Acc: 84.38
[Train] Epoch: 0 [431168/620022]    Loss: 0.007908   Batch Acc: 78.12
[Train] Epoch: 0 [431232/620022]    Loss: 0.006848   Batch Acc: 89.06
[Train] Epoch: 0 [431296/620022]    Loss: 0.006964   Batch Acc: 84.38
[Train] Epoch: 0 [431360/620022]    Loss: 0.011186   Batch Acc: 67.19
[Train] Epoch: 0 [431424/620022]    Loss: 0.006921   Batch Acc: 81.25
[Train] Epoch: 0 [431488/620022]    Loss: 0.009195   Batch Acc: 71.88
[Train] Epoch: 0 [431552/620022]    Loss: 0.009200   Batch Acc: 70.31
[Train] Epoch: 0 [431616/620022]    Loss: 0.007743   Batch Acc: 81.25
[Train] Epoch: 0 [431680/620022]    Loss: 0.009307   Batch Acc: 76.56
[Train] Epoch: 0 [431744/620022]    Loss: 0.009007   Batch Acc: 76.56
[Train] Epoch: 0 [431808/620022]    Loss: 0.010301   Batch Acc: 75.00
[Train] Epoch: 0 [431872/620022]    Loss: 0.008607   Batch Acc: 78.12
[Train] Epoch: 0 [431936/620022]    Loss: 0.009184   Batch Acc: 75.00
[Train] Epoch: 0 [432000/620022]    Loss: 0.008601   Batch Acc: 73.44
[Train] Epoch: 0 [432064/620022]    Loss: 0.008952   Batch Acc: 75.00
[Train] Epoch: 0 [432128/620022]    Loss: 0.006502   Batch Acc: 87.50
[Train] Epoch: 0 [432192/620022]    Loss: 0.009152   Batch Acc: 78.12
[Train] Epoch: 0 [432256/620022]    Loss: 0.007898   Batch Acc: 81.25
[Train] Epoch: 0 [432320/620022]    Loss: 0.007641   Batch Acc: 73.44
[Train] Epoch: 0 [432384/620022]    Loss: 0.009307   Batch Acc: 65.62
[Train] Epoch: 0 [432448/620022]    Loss: 0.008328   Batch Acc: 76.56
[Train] Epoch: 0 [432512/620022]    Loss: 0.010056   Batch Acc: 78.12
[Train] Epoch: 0 [432576/620022]    Loss: 0.007505   Batch Acc: 81.25
[Train] Epoch: 0 [432640/620022]    Loss: 0.006163   Batch Acc: 89.06
[Train] Epoch: 0 [432704/620022]    Loss: 0.012102   Batch Acc: 71.88
[Train] Epoch: 0 [432768/620022]    Loss: 0.010142   Batch Acc: 71.88
[Train] Epoch: 0 [432832/620022]    Loss: 0.007688   Batch Acc: 81.25
[Train] Epoch: 0 [432896/620022]    Loss: 0.008898   Batch Acc: 78.12
[Train] Epoch: 0 [432960/620022]    Loss: 0.011548   Batch Acc: 75.00
[Train] Epoch: 0 [433024/620022]    Loss: 0.006735   Batch Acc: 81.25
[Train] Epoch: 0 [433088/620022]    Loss: 0.008665   Batch Acc: 78.12
[Train] Epoch: 0 [433152/620022]    Loss: 0.008582   Batch Acc: 79.69
[Train] Epoch: 0 [433216/620022]    Loss: 0.009308   Batch Acc: 75.00
[Train] Epoch: 0 [433280/620022]    Loss: 0.007573   Batch Acc: 81.25
[Train] Epoch: 0 [433344/620022]    Loss: 0.007547   Batch Acc: 82.81
[Train] Epoch: 0 [433408/620022]    Loss: 0.008471   Batch Acc: 76.56
[Train] Epoch: 0 [433472/620022]    Loss: 0.010216   Batch Acc: 70.31
[Train] Epoch: 0 [433536/620022]    Loss: 0.009166   Batch Acc: 71.88
[Train] Epoch: 0 [433600/620022]    Loss: 0.012051   Batch Acc: 67.19
[Train] Epoch: 0 [433664/620022]    Loss: 0.012734   Batch Acc: 64.06
[Train] Epoch: 0 [433728/620022]    Loss: 0.009510   Batch Acc: 75.00
[Train] Epoch: 0 [433792/620022]    Loss: 0.011798   Batch Acc: 70.31
[Train] Epoch: 0 [433856/620022]    Loss: 0.009513   Batch Acc: 71.88
[Train] Epoch: 0 [433920/620022]    Loss: 0.007650   Batch Acc: 78.12
[Train] Epoch: 0 [433984/620022]    Loss: 0.009985   Batch Acc: 70.31
[Train] Epoch: 0 [434048/620022]    Loss: 0.011253   Batch Acc: 79.69
[Train] Epoch: 0 [434112/620022]    Loss: 0.008391   Batch Acc: 76.56
[Train] Epoch: 0 [434176/620022]    Loss: 0.008546   Batch Acc: 78.12
[Train] Epoch: 0 [434240/620022]    Loss: 0.010373   Batch Acc: 78.12
[Train] Epoch: 0 [434304/620022]    Loss: 0.008752   Batch Acc: 78.12
[Train] Epoch: 0 [434368/620022]    Loss: 0.009003   Batch Acc: 75.00
[Train] Epoch: 0 [434432/620022]    Loss: 0.007794   Batch Acc: 82.81
[Train] Epoch: 0 [434496/620022]    Loss: 0.008820   Batch Acc: 73.44
[Train] Epoch: 0 [434560/620022]    Loss: 0.009057   Batch Acc: 81.25
[Train] Epoch: 0 [434624/620022]    Loss: 0.007698   Batch Acc: 81.25
[Train] Epoch: 0 [434688/620022]    Loss: 0.007702   Batch Acc: 85.94
[Train] Epoch: 0 [434752/620022]    Loss: 0.007827   Batch Acc: 76.56
[Train] Epoch: 0 [434816/620022]    Loss: 0.007558   Batch Acc: 78.12
[Train] Epoch: 0 [434880/620022]    Loss: 0.007532   Batch Acc: 84.38
[Train] Epoch: 0 [434944/620022]    Loss: 0.007670   Batch Acc: 78.12
[Train] Epoch: 0 [435008/620022]    Loss: 0.011372   Batch Acc: 62.50
[Train] Epoch: 0 [435072/620022]    Loss: 0.010444   Batch Acc: 73.44
[Train] Epoch: 0 [435136/620022]    Loss: 0.010456   Batch Acc: 70.31
[Train] Epoch: 0 [435200/620022]    Loss: 0.007988   Batch Acc: 81.25
[Train] Epoch: 0 [435264/620022]    Loss: 0.009085   Batch Acc: 73.44
[Train] Epoch: 0 [435328/620022]    Loss: 0.011797   Batch Acc: 68.75
[Train] Epoch: 0 [435392/620022]    Loss: 0.009405   Batch Acc: 76.56
[Train] Epoch: 0 [435456/620022]    Loss: 0.007324   Batch Acc: 81.25
[Train] Epoch: 0 [435520/620022]    Loss: 0.009804   Batch Acc: 78.12
[Train] Epoch: 0 [435584/620022]    Loss: 0.008392   Batch Acc: 75.00
[Train] Epoch: 0 [435648/620022]    Loss: 0.007459   Batch Acc: 84.38
[Train] Epoch: 0 [435712/620022]    Loss: 0.008033   Batch Acc: 78.12
[Train] Epoch: 0 [435776/620022]    Loss: 0.008116   Batch Acc: 79.69
[Train] Epoch: 0 [435840/620022]    Loss: 0.009193   Batch Acc: 78.12
[Train] Epoch: 0 [435904/620022]    Loss: 0.008784   Batch Acc: 78.12
[Train] Epoch: 0 [435968/620022]    Loss: 0.010569   Batch Acc: 70.31
[Train] Epoch: 0 [436032/620022]    Loss: 0.007263   Batch Acc: 81.25
[Train] Epoch: 0 [436096/620022]    Loss: 0.010590   Batch Acc: 71.88
[Train] Epoch: 0 [436160/620022]    Loss: 0.009429   Batch Acc: 78.12
[Train] Epoch: 0 [436224/620022]    Loss: 0.010290   Batch Acc: 67.19
[Train] Epoch: 0 [436288/620022]    Loss: 0.008650   Batch Acc: 81.25
[Train] Epoch: 0 [436352/620022]    Loss: 0.009345   Batch Acc: 78.12
[Train] Epoch: 0 [436416/620022]    Loss: 0.008590   Batch Acc: 79.69
[Train] Epoch: 0 [436480/620022]    Loss: 0.010115   Batch Acc: 78.12
[Train] Epoch: 0 [436544/620022]    Loss: 0.009558   Batch Acc: 71.88
[Train] Epoch: 0 [436608/620022]    Loss: 0.010769   Batch Acc: 67.19
[Train] Epoch: 0 [436672/620022]    Loss: 0.011741   Batch Acc: 65.62
[Train] Epoch: 0 [436736/620022]    Loss: 0.009148   Batch Acc: 75.00
[Train] Epoch: 0 [436800/620022]    Loss: 0.006408   Batch Acc: 85.94
[Train] Epoch: 0 [436864/620022]    Loss: 0.009865   Batch Acc: 75.00
[Train] Epoch: 0 [436928/620022]    Loss: 0.006788   Batch Acc: 87.50
[Train] Epoch: 0 [436992/620022]    Loss: 0.009839   Batch Acc: 73.44
[Train] Epoch: 0 [437056/620022]    Loss: 0.008130   Batch Acc: 81.25
[Train] Epoch: 0 [437120/620022]    Loss: 0.009931   Batch Acc: 73.44
[Train] Epoch: 0 [437184/620022]    Loss: 0.010051   Batch Acc: 75.00
[Train] Epoch: 0 [437248/620022]    Loss: 0.008822   Batch Acc: 73.44
[Train] Epoch: 0 [437312/620022]    Loss: 0.006039   Batch Acc: 90.62
[Train] Epoch: 0 [437376/620022]    Loss: 0.008165   Batch Acc: 79.69
[Train] Epoch: 0 [437440/620022]    Loss: 0.009636   Batch Acc: 76.56
[Train] Epoch: 0 [437504/620022]    Loss: 0.008520   Batch Acc: 73.44
[Train] Epoch: 0 [437568/620022]    Loss: 0.007269   Batch Acc: 84.38
[Train] Epoch: 0 [437632/620022]    Loss: 0.009881   Batch Acc: 70.31
[Train] Epoch: 0 [437696/620022]    Loss: 0.010348   Batch Acc: 75.00
[Train] Epoch: 0 [437760/620022]    Loss: 0.009116   Batch Acc: 78.12
[Train] Epoch: 0 [437824/620022]    Loss: 0.009956   Batch Acc: 73.44
[Train] Epoch: 0 [437888/620022]    Loss: 0.009290   Batch Acc: 76.56
[Train] Epoch: 0 [437952/620022]    Loss: 0.007845   Batch Acc: 81.25
[Train] Epoch: 0 [438016/620022]    Loss: 0.008015   Batch Acc: 78.12
[Train] Epoch: 0 [438080/620022]    Loss: 0.008594   Batch Acc: 81.25
[Train] Epoch: 0 [438144/620022]    Loss: 0.008681   Batch Acc: 78.12
[Train] Epoch: 0 [438208/620022]    Loss: 0.008253   Batch Acc: 76.56
[Train] Epoch: 0 [438272/620022]    Loss: 0.008002   Batch Acc: 78.12
[Train] Epoch: 0 [438336/620022]    Loss: 0.008321   Batch Acc: 81.25
[Train] Epoch: 0 [438400/620022]    Loss: 0.008944   Batch Acc: 79.69
[Train] Epoch: 0 [438464/620022]    Loss: 0.007254   Batch Acc: 81.25
[Train] Epoch: 0 [438528/620022]    Loss: 0.010099   Batch Acc: 75.00
[Train] Epoch: 0 [438592/620022]    Loss: 0.008039   Batch Acc: 78.12
[Train] Epoch: 0 [438656/620022]    Loss: 0.008287   Batch Acc: 82.81
[Train] Epoch: 0 [438720/620022]    Loss: 0.008120   Batch Acc: 79.69
[Train] Epoch: 0 [438784/620022]    Loss: 0.010400   Batch Acc: 71.88
[Train] Epoch: 0 [438848/620022]    Loss: 0.010542   Batch Acc: 75.00
[Train] Epoch: 0 [438912/620022]    Loss: 0.008614   Batch Acc: 78.12
[Train] Epoch: 0 [438976/620022]    Loss: 0.011959   Batch Acc: 60.94
[Train] Epoch: 0 [439040/620022]    Loss: 0.006759   Batch Acc: 85.94
[Train] Epoch: 0 [439104/620022]    Loss: 0.008113   Batch Acc: 84.38
[Train] Epoch: 0 [439168/620022]    Loss: 0.009135   Batch Acc: 78.12
[Train] Epoch: 0 [439232/620022]    Loss: 0.010815   Batch Acc: 70.31
[Train] Epoch: 0 [439296/620022]    Loss: 0.007555   Batch Acc: 78.12
[Train] Epoch: 0 [439360/620022]    Loss: 0.008318   Batch Acc: 81.25
[Train] Epoch: 0 [439424/620022]    Loss: 0.007801   Batch Acc: 78.12
[Train] Epoch: 0 [439488/620022]    Loss: 0.008818   Batch Acc: 75.00
[Train] Epoch: 0 [439552/620022]    Loss: 0.010249   Batch Acc: 79.69
[Train] Epoch: 0 [439616/620022]    Loss: 0.008768   Batch Acc: 76.56
[Train] Epoch: 0 [439680/620022]    Loss: 0.009014   Batch Acc: 75.00
[Train] Epoch: 0 [439744/620022]    Loss: 0.008471   Batch Acc: 76.56
[Train] Epoch: 0 [439808/620022]    Loss: 0.009124   Batch Acc: 79.69
[Train] Epoch: 0 [439872/620022]    Loss: 0.009140   Batch Acc: 78.12
[Train] Epoch: 0 [439936/620022]    Loss: 0.008580   Batch Acc: 82.81
[Train] Epoch: 0 [440000/620022]    Loss: 0.009164   Batch Acc: 78.12
[Train] Epoch: 0 [440064/620022]    Loss: 0.009200   Batch Acc: 78.12
[Train] Epoch: 0 [440128/620022]    Loss: 0.005976   Batch Acc: 85.94
[Train] Epoch: 0 [440192/620022]    Loss: 0.008976   Batch Acc: 78.12
[Train] Epoch: 0 [440256/620022]    Loss: 0.008357   Batch Acc: 71.88
[Train] Epoch: 0 [440320/620022]    Loss: 0.009054   Batch Acc: 75.00
[Train] Epoch: 0 [440384/620022]    Loss: 0.006355   Batch Acc: 89.06
[Train] Epoch: 0 [440448/620022]    Loss: 0.006087   Batch Acc: 87.50
[Train] Epoch: 0 [440512/620022]    Loss: 0.009188   Batch Acc: 75.00
[Train] Epoch: 0 [440576/620022]    Loss: 0.009195   Batch Acc: 79.69
[Train] Epoch: 0 [440640/620022]    Loss: 0.011157   Batch Acc: 70.31
[Train] Epoch: 0 [440704/620022]    Loss: 0.008230   Batch Acc: 82.81
[Train] Epoch: 0 [440768/620022]    Loss: 0.008909   Batch Acc: 81.25
[Train] Epoch: 0 [440832/620022]    Loss: 0.008843   Batch Acc: 82.81
[Train] Epoch: 0 [440896/620022]    Loss: 0.007089   Batch Acc: 82.81
[Train] Epoch: 0 [440960/620022]    Loss: 0.007066   Batch Acc: 84.38
[Train] Epoch: 0 [441024/620022]    Loss: 0.007813   Batch Acc: 81.25
[Train] Epoch: 0 [441088/620022]    Loss: 0.008554   Batch Acc: 75.00
[Train] Epoch: 0 [441152/620022]    Loss: 0.007818   Batch Acc: 79.69
[Train] Epoch: 0 [441216/620022]    Loss: 0.008831   Batch Acc: 79.69
[Train] Epoch: 0 [441280/620022]    Loss: 0.010079   Batch Acc: 68.75
[Train] Epoch: 0 [441344/620022]    Loss: 0.009216   Batch Acc: 73.44
[Train] Epoch: 0 [441408/620022]    Loss: 0.009585   Batch Acc: 67.19
[Train] Epoch: 0 [441472/620022]    Loss: 0.010654   Batch Acc: 70.31
[Train] Epoch: 0 [441536/620022]    Loss: 0.009568   Batch Acc: 73.44
[Train] Epoch: 0 [441600/620022]    Loss: 0.010690   Batch Acc: 76.56
[Train] Epoch: 0 [441664/620022]    Loss: 0.007372   Batch Acc: 79.69
[Train] Epoch: 0 [441728/620022]    Loss: 0.008391   Batch Acc: 73.44
[Train] Epoch: 0 [441792/620022]    Loss: 0.010252   Batch Acc: 75.00
[Train] Epoch: 0 [441856/620022]    Loss: 0.008913   Batch Acc: 76.56
[Train] Epoch: 0 [441920/620022]    Loss: 0.008380   Batch Acc: 78.12
[Train] Epoch: 0 [441984/620022]    Loss: 0.011923   Batch Acc: 64.06
[Train] Epoch: 0 [442048/620022]    Loss: 0.009747   Batch Acc: 75.00
[Train] Epoch: 0 [442112/620022]    Loss: 0.009017   Batch Acc: 76.56
[Train] Epoch: 0 [442176/620022]    Loss: 0.009574   Batch Acc: 68.75
[Train] Epoch: 0 [442240/620022]    Loss: 0.007921   Batch Acc: 84.38
[Train] Epoch: 0 [442304/620022]    Loss: 0.009516   Batch Acc: 78.12
[Train] Epoch: 0 [442368/620022]    Loss: 0.009416   Batch Acc: 68.75
[Train] Epoch: 0 [442432/620022]    Loss: 0.010764   Batch Acc: 67.19
[Train] Epoch: 0 [442496/620022]    Loss: 0.009489   Batch Acc: 81.25
[Train] Epoch: 0 [442560/620022]    Loss: 0.006568   Batch Acc: 90.62
[Train] Epoch: 0 [442624/620022]    Loss: 0.007231   Batch Acc: 81.25
[Train] Epoch: 0 [442688/620022]    Loss: 0.012317   Batch Acc: 68.75
[Train] Epoch: 0 [442752/620022]    Loss: 0.008973   Batch Acc: 75.00
[Train] Epoch: 0 [442816/620022]    Loss: 0.008225   Batch Acc: 79.69
[Train] Epoch: 0 [442880/620022]    Loss: 0.009586   Batch Acc: 73.44
[Train] Epoch: 0 [442944/620022]    Loss: 0.009950   Batch Acc: 76.56
[Train] Epoch: 0 [443008/620022]    Loss: 0.010909   Batch Acc: 68.75
[Train] Epoch: 0 [443072/620022]    Loss: 0.009252   Batch Acc: 78.12
[Train] Epoch: 0 [443136/620022]    Loss: 0.008805   Batch Acc: 73.44
[Train] Epoch: 0 [443200/620022]    Loss: 0.008066   Batch Acc: 79.69
[Train] Epoch: 0 [443264/620022]    Loss: 0.008105   Batch Acc: 81.25
[Train] Epoch: 0 [443328/620022]    Loss: 0.010396   Batch Acc: 73.44
[Train] Epoch: 0 [443392/620022]    Loss: 0.009995   Batch Acc: 70.31
[Train] Epoch: 0 [443456/620022]    Loss: 0.007881   Batch Acc: 82.81
[Train] Epoch: 0 [443520/620022]    Loss: 0.006878   Batch Acc: 82.81
[Train] Epoch: 0 [443584/620022]    Loss: 0.009101   Batch Acc: 78.12
[Train] Epoch: 0 [443648/620022]    Loss: 0.009067   Batch Acc: 81.25
[Train] Epoch: 0 [443712/620022]    Loss: 0.009753   Batch Acc: 76.56
[Train] Epoch: 0 [443776/620022]    Loss: 0.009978   Batch Acc: 71.88
[Train] Epoch: 0 [443840/620022]    Loss: 0.009382   Batch Acc: 73.44
[Train] Epoch: 0 [443904/620022]    Loss: 0.009485   Batch Acc: 71.88
[Train] Epoch: 0 [443968/620022]    Loss: 0.007969   Batch Acc: 79.69
[Train] Epoch: 0 [444032/620022]    Loss: 0.007878   Batch Acc: 78.12
[Train] Epoch: 0 [444096/620022]    Loss: 0.009950   Batch Acc: 79.69
[Train] Epoch: 0 [444160/620022]    Loss: 0.008301   Batch Acc: 78.12
[Train] Epoch: 0 [444224/620022]    Loss: 0.009057   Batch Acc: 71.88
[Train] Epoch: 0 [444288/620022]    Loss: 0.008060   Batch Acc: 71.88
[Train] Epoch: 0 [444352/620022]    Loss: 0.008484   Batch Acc: 73.44
[Train] Epoch: 0 [444416/620022]    Loss: 0.009354   Batch Acc: 70.31
[Train] Epoch: 0 [444480/620022]    Loss: 0.008089   Batch Acc: 79.69
[Train] Epoch: 0 [444544/620022]    Loss: 0.008843   Batch Acc: 81.25
[Train] Epoch: 0 [444608/620022]    Loss: 0.009109   Batch Acc: 76.56
[Train] Epoch: 0 [444672/620022]    Loss: 0.008902   Batch Acc: 71.88
[Train] Epoch: 0 [444736/620022]    Loss: 0.009561   Batch Acc: 71.88
[Train] Epoch: 0 [444800/620022]    Loss: 0.010730   Batch Acc: 70.31
[Train] Epoch: 0 [444864/620022]    Loss: 0.009756   Batch Acc: 75.00
[Train] Epoch: 0 [444928/620022]    Loss: 0.007026   Batch Acc: 82.81
[Train] Epoch: 0 [444992/620022]    Loss: 0.008448   Batch Acc: 76.56
[Train] Epoch: 0 [445056/620022]    Loss: 0.007437   Batch Acc: 82.81
[Train] Epoch: 0 [445120/620022]    Loss: 0.010331   Batch Acc: 78.12
[Train] Epoch: 0 [445184/620022]    Loss: 0.010092   Batch Acc: 71.88
[Train] Epoch: 0 [445248/620022]    Loss: 0.009059   Batch Acc: 79.69
[Train] Epoch: 0 [445312/620022]    Loss: 0.008140   Batch Acc: 84.38
[Train] Epoch: 0 [445376/620022]    Loss: 0.006590   Batch Acc: 84.38
[Train] Epoch: 0 [445440/620022]    Loss: 0.009797   Batch Acc: 76.56
[Train] Epoch: 0 [445504/620022]    Loss: 0.009261   Batch Acc: 79.69
[Train] Epoch: 0 [445568/620022]    Loss: 0.006907   Batch Acc: 85.94
[Train] Epoch: 0 [445632/620022]    Loss: 0.007132   Batch Acc: 87.50
[Train] Epoch: 0 [445696/620022]    Loss: 0.009791   Batch Acc: 73.44
[Train] Epoch: 0 [445760/620022]    Loss: 0.007998   Batch Acc: 81.25
[Train] Epoch: 0 [445824/620022]    Loss: 0.011529   Batch Acc: 70.31
[Train] Epoch: 0 [445888/620022]    Loss: 0.009644   Batch Acc: 70.31
[Train] Epoch: 0 [445952/620022]    Loss: 0.007899   Batch Acc: 82.81
[Train] Epoch: 0 [446016/620022]    Loss: 0.008106   Batch Acc: 78.12
[Train] Epoch: 0 [446080/620022]    Loss: 0.007887   Batch Acc: 81.25
[Train] Epoch: 0 [446144/620022]    Loss: 0.008894   Batch Acc: 75.00
[Train] Epoch: 0 [446208/620022]    Loss: 0.008165   Batch Acc: 79.69
[Train] Epoch: 0 [446272/620022]    Loss: 0.008194   Batch Acc: 82.81
[Train] Epoch: 0 [446336/620022]    Loss: 0.008576   Batch Acc: 78.12
[Train] Epoch: 0 [446400/620022]    Loss: 0.007957   Batch Acc: 75.00
[Train] Epoch: 0 [446464/620022]    Loss: 0.007669   Batch Acc: 84.38
[Train] Epoch: 0 [446528/620022]    Loss: 0.011336   Batch Acc: 65.62
[Train] Epoch: 0 [446592/620022]    Loss: 0.008848   Batch Acc: 79.69
[Train] Epoch: 0 [446656/620022]    Loss: 0.008876   Batch Acc: 79.69
[Train] Epoch: 0 [446720/620022]    Loss: 0.011053   Batch Acc: 71.88
[Train] Epoch: 0 [446784/620022]    Loss: 0.011032   Batch Acc: 70.31
[Train] Epoch: 0 [446848/620022]    Loss: 0.009555   Batch Acc: 79.69
[Train] Epoch: 0 [446912/620022]    Loss: 0.007432   Batch Acc: 79.69
[Train] Epoch: 0 [446976/620022]    Loss: 0.009426   Batch Acc: 71.88
[Train] Epoch: 0 [447040/620022]    Loss: 0.007854   Batch Acc: 81.25
[Train] Epoch: 0 [447104/620022]    Loss: 0.008950   Batch Acc: 78.12
[Train] Epoch: 0 [447168/620022]    Loss: 0.008428   Batch Acc: 73.44
[Train] Epoch: 0 [447232/620022]    Loss: 0.009461   Batch Acc: 78.12
[Train] Epoch: 0 [447296/620022]    Loss: 0.006469   Batch Acc: 87.50
[Train] Epoch: 0 [447360/620022]    Loss: 0.006638   Batch Acc: 81.25
[Train] Epoch: 0 [447424/620022]    Loss: 0.007883   Batch Acc: 84.38
[Train] Epoch: 0 [447488/620022]    Loss: 0.008460   Batch Acc: 78.12
[Train] Epoch: 0 [447552/620022]    Loss: 0.009697   Batch Acc: 71.88
[Train] Epoch: 0 [447616/620022]    Loss: 0.009930   Batch Acc: 70.31
[Train] Epoch: 0 [447680/620022]    Loss: 0.010425   Batch Acc: 73.44
[Train] Epoch: 0 [447744/620022]    Loss: 0.007035   Batch Acc: 79.69
[Train] Epoch: 0 [447808/620022]    Loss: 0.007694   Batch Acc: 82.81
[Train] Epoch: 0 [447872/620022]    Loss: 0.007363   Batch Acc: 78.12
[Train] Epoch: 0 [447936/620022]    Loss: 0.010208   Batch Acc: 75.00
[Train] Epoch: 0 [448000/620022]    Loss: 0.010827   Batch Acc: 68.75
[Train] Epoch: 0 [448064/620022]    Loss: 0.008892   Batch Acc: 76.56
[Train] Epoch: 0 [448128/620022]    Loss: 0.007939   Batch Acc: 78.12
[Train] Epoch: 0 [448192/620022]    Loss: 0.008348   Batch Acc: 76.56
[Train] Epoch: 0 [448256/620022]    Loss: 0.009502   Batch Acc: 76.56
[Train] Epoch: 0 [448320/620022]    Loss: 0.007877   Batch Acc: 79.69
[Train] Epoch: 0 [448384/620022]    Loss: 0.008509   Batch Acc: 75.00
[Train] Epoch: 0 [448448/620022]    Loss: 0.009016   Batch Acc: 75.00
[Train] Epoch: 0 [448512/620022]    Loss: 0.008376   Batch Acc: 76.56
[Train] Epoch: 0 [448576/620022]    Loss: 0.011115   Batch Acc: 78.12
[Train] Epoch: 0 [448640/620022]    Loss: 0.007537   Batch Acc: 79.69
[Train] Epoch: 0 [448704/620022]    Loss: 0.009534   Batch Acc: 75.00
[Train] Epoch: 0 [448768/620022]    Loss: 0.009283   Batch Acc: 81.25
[Train] Epoch: 0 [448832/620022]    Loss: 0.010976   Batch Acc: 71.88
[Train] Epoch: 0 [448896/620022]    Loss: 0.006601   Batch Acc: 87.50
[Train] Epoch: 0 [448960/620022]    Loss: 0.009752   Batch Acc: 73.44
[Train] Epoch: 0 [449024/620022]    Loss: 0.007253   Batch Acc: 81.25
[Train] Epoch: 0 [449088/620022]    Loss: 0.008070   Batch Acc: 81.25
[Train] Epoch: 0 [449152/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 0 [449216/620022]    Loss: 0.007780   Batch Acc: 78.12
[Train] Epoch: 0 [449280/620022]    Loss: 0.008409   Batch Acc: 78.12
[Train] Epoch: 0 [449344/620022]    Loss: 0.009487   Batch Acc: 70.31
[Train] Epoch: 0 [449408/620022]    Loss: 0.009147   Batch Acc: 78.12
[Train] Epoch: 0 [449472/620022]    Loss: 0.010041   Batch Acc: 76.56
[Train] Epoch: 0 [449536/620022]    Loss: 0.008546   Batch Acc: 76.56
[Train] Epoch: 0 [449600/620022]    Loss: 0.008152   Batch Acc: 75.00
[Train] Epoch: 0 [449664/620022]    Loss: 0.009947   Batch Acc: 73.44
[Train] Epoch: 0 [449728/620022]    Loss: 0.010573   Batch Acc: 65.62
[Train] Epoch: 0 [449792/620022]    Loss: 0.009814   Batch Acc: 73.44
[Train] Epoch: 0 [449856/620022]    Loss: 0.007512   Batch Acc: 89.06
[Train] Epoch: 0 [449920/620022]    Loss: 0.007911   Batch Acc: 73.44
[Train] Epoch: 0 [449984/620022]    Loss: 0.008858   Batch Acc: 73.44
[Train] Epoch: 0 [450048/620022]    Loss: 0.009653   Batch Acc: 75.00
[Train] Epoch: 0 [450112/620022]    Loss: 0.009517   Batch Acc: 73.44
[Train] Epoch: 0 [450176/620022]    Loss: 0.006311   Batch Acc: 82.81
[Train] Epoch: 0 [450240/620022]    Loss: 0.008680   Batch Acc: 84.38
[Train] Epoch: 0 [450304/620022]    Loss: 0.009099   Batch Acc: 78.12
[Train] Epoch: 0 [450368/620022]    Loss: 0.007641   Batch Acc: 82.81
[Train] Epoch: 0 [450432/620022]    Loss: 0.006924   Batch Acc: 82.81
[Train] Epoch: 0 [450496/620022]    Loss: 0.010049   Batch Acc: 73.44
[Train] Epoch: 0 [450560/620022]    Loss: 0.009794   Batch Acc: 76.56
[Train] Epoch: 0 [450624/620022]    Loss: 0.009764   Batch Acc: 78.12
[Train] Epoch: 0 [450688/620022]    Loss: 0.007444   Batch Acc: 81.25
[Train] Epoch: 0 [450752/620022]    Loss: 0.008021   Batch Acc: 85.94
[Train] Epoch: 0 [450816/620022]    Loss: 0.008235   Batch Acc: 79.69
[Train] Epoch: 0 [450880/620022]    Loss: 0.007593   Batch Acc: 79.69
[Train] Epoch: 0 [450944/620022]    Loss: 0.008628   Batch Acc: 73.44
[Train] Epoch: 0 [451008/620022]    Loss: 0.010024   Batch Acc: 79.69
[Train] Epoch: 0 [451072/620022]    Loss: 0.010143   Batch Acc: 71.88
[Train] Epoch: 0 [451136/620022]    Loss: 0.009373   Batch Acc: 73.44
[Train] Epoch: 0 [451200/620022]    Loss: 0.009201   Batch Acc: 76.56
[Train] Epoch: 0 [451264/620022]    Loss: 0.009645   Batch Acc: 75.00
[Train] Epoch: 0 [451328/620022]    Loss: 0.010226   Batch Acc: 76.56
[Train] Epoch: 0 [451392/620022]    Loss: 0.007321   Batch Acc: 85.94
[Train] Epoch: 0 [451456/620022]    Loss: 0.009055   Batch Acc: 79.69
[Train] Epoch: 0 [451520/620022]    Loss: 0.006932   Batch Acc: 87.50
[Train] Epoch: 0 [451584/620022]    Loss: 0.008638   Batch Acc: 78.12
[Train] Epoch: 0 [451648/620022]    Loss: 0.006969   Batch Acc: 85.94
[Train] Epoch: 0 [451712/620022]    Loss: 0.012016   Batch Acc: 68.75
[Train] Epoch: 0 [451776/620022]    Loss: 0.008625   Batch Acc: 82.81
[Train] Epoch: 0 [451840/620022]    Loss: 0.007279   Batch Acc: 79.69
[Train] Epoch: 0 [451904/620022]    Loss: 0.009296   Batch Acc: 78.12
[Train] Epoch: 0 [451968/620022]    Loss: 0.010211   Batch Acc: 78.12
[Train] Epoch: 0 [452032/620022]    Loss: 0.008623   Batch Acc: 73.44
[Train] Epoch: 0 [452096/620022]    Loss: 0.009368   Batch Acc: 73.44
[Train] Epoch: 0 [452160/620022]    Loss: 0.010067   Batch Acc: 76.56
[Train] Epoch: 0 [452224/620022]    Loss: 0.009372   Batch Acc: 73.44
[Train] Epoch: 0 [452288/620022]    Loss: 0.007330   Batch Acc: 87.50
[Train] Epoch: 0 [452352/620022]    Loss: 0.009206   Batch Acc: 78.12
[Train] Epoch: 0 [452416/620022]    Loss: 0.008264   Batch Acc: 76.56
[Train] Epoch: 0 [452480/620022]    Loss: 0.007180   Batch Acc: 85.94
[Train] Epoch: 0 [452544/620022]    Loss: 0.010357   Batch Acc: 76.56
[Train] Epoch: 0 [452608/620022]    Loss: 0.006968   Batch Acc: 87.50
[Train] Epoch: 0 [452672/620022]    Loss: 0.007860   Batch Acc: 78.12
[Train] Epoch: 0 [452736/620022]    Loss: 0.009143   Batch Acc: 73.44
[Train] Epoch: 0 [452800/620022]    Loss: 0.008490   Batch Acc: 82.81
[Train] Epoch: 0 [452864/620022]    Loss: 0.009748   Batch Acc: 73.44
[Train] Epoch: 0 [452928/620022]    Loss: 0.008112   Batch Acc: 76.56
[Train] Epoch: 0 [452992/620022]    Loss: 0.009238   Batch Acc: 71.88
[Train] Epoch: 0 [453056/620022]    Loss: 0.008655   Batch Acc: 78.12
[Train] Epoch: 0 [453120/620022]    Loss: 0.008164   Batch Acc: 82.81
[Train] Epoch: 0 [453184/620022]    Loss: 0.009636   Batch Acc: 76.56
[Train] Epoch: 0 [453248/620022]    Loss: 0.008640   Batch Acc: 73.44
[Train] Epoch: 0 [453312/620022]    Loss: 0.007874   Batch Acc: 82.81
[Train] Epoch: 0 [453376/620022]    Loss: 0.008324   Batch Acc: 79.69
[Train] Epoch: 0 [453440/620022]    Loss: 0.008170   Batch Acc: 81.25
[Train] Epoch: 0 [453504/620022]    Loss: 0.006523   Batch Acc: 82.81
[Train] Epoch: 0 [453568/620022]    Loss: 0.007281   Batch Acc: 82.81
[Train] Epoch: 0 [453632/620022]    Loss: 0.008735   Batch Acc: 75.00
[Train] Epoch: 0 [453696/620022]    Loss: 0.008086   Batch Acc: 79.69
[Train] Epoch: 0 [453760/620022]    Loss: 0.006903   Batch Acc: 85.94
[Train] Epoch: 0 [453824/620022]    Loss: 0.008271   Batch Acc: 79.69
[Train] Epoch: 0 [453888/620022]    Loss: 0.006794   Batch Acc: 85.94
[Train] Epoch: 0 [453952/620022]    Loss: 0.008347   Batch Acc: 81.25
[Train] Epoch: 0 [454016/620022]    Loss: 0.008409   Batch Acc: 79.69
[Train] Epoch: 0 [454080/620022]    Loss: 0.008866   Batch Acc: 78.12
[Train] Epoch: 0 [454144/620022]    Loss: 0.007074   Batch Acc: 84.38
[Train] Epoch: 0 [454208/620022]    Loss: 0.009484   Batch Acc: 75.00
[Train] Epoch: 0 [454272/620022]    Loss: 0.009485   Batch Acc: 71.88
[Train] Epoch: 0 [454336/620022]    Loss: 0.012266   Batch Acc: 65.62
[Train] Epoch: 0 [454400/620022]    Loss: 0.006560   Batch Acc: 87.50
[Train] Epoch: 0 [454464/620022]    Loss: 0.009033   Batch Acc: 75.00
[Train] Epoch: 0 [454528/620022]    Loss: 0.010673   Batch Acc: 70.31
[Train] Epoch: 0 [454592/620022]    Loss: 0.008244   Batch Acc: 76.56
[Train] Epoch: 0 [454656/620022]    Loss: 0.007818   Batch Acc: 81.25
[Train] Epoch: 0 [454720/620022]    Loss: 0.010056   Batch Acc: 78.12
[Train] Epoch: 0 [454784/620022]    Loss: 0.007329   Batch Acc: 81.25
[Train] Epoch: 0 [454848/620022]    Loss: 0.008927   Batch Acc: 76.56
[Train] Epoch: 0 [454912/620022]    Loss: 0.010181   Batch Acc: 75.00
[Train] Epoch: 0 [454976/620022]    Loss: 0.008962   Batch Acc: 76.56
[Train] Epoch: 0 [455040/620022]    Loss: 0.012844   Batch Acc: 65.62
[Train] Epoch: 0 [455104/620022]    Loss: 0.006229   Batch Acc: 87.50
[Train] Epoch: 0 [455168/620022]    Loss: 0.010596   Batch Acc: 70.31
[Train] Epoch: 0 [455232/620022]    Loss: 0.010246   Batch Acc: 78.12
[Train] Epoch: 0 [455296/620022]    Loss: 0.008331   Batch Acc: 82.81
[Train] Epoch: 0 [455360/620022]    Loss: 0.009769   Batch Acc: 75.00
[Train] Epoch: 0 [455424/620022]    Loss: 0.007242   Batch Acc: 89.06
[Train] Epoch: 0 [455488/620022]    Loss: 0.007455   Batch Acc: 79.69
[Train] Epoch: 0 [455552/620022]    Loss: 0.007698   Batch Acc: 84.38
[Train] Epoch: 0 [455616/620022]    Loss: 0.009756   Batch Acc: 71.88
[Train] Epoch: 0 [455680/620022]    Loss: 0.011289   Batch Acc: 68.75
[Train] Epoch: 0 [455744/620022]    Loss: 0.010398   Batch Acc: 75.00
[Train] Epoch: 0 [455808/620022]    Loss: 0.010176   Batch Acc: 78.12
[Train] Epoch: 0 [455872/620022]    Loss: 0.008372   Batch Acc: 81.25
[Train] Epoch: 0 [455936/620022]    Loss: 0.011631   Batch Acc: 70.31
[Train] Epoch: 0 [456000/620022]    Loss: 0.009926   Batch Acc: 73.44
[Train] Epoch: 0 [456064/620022]    Loss: 0.008855   Batch Acc: 79.69
[Train] Epoch: 0 [456128/620022]    Loss: 0.008893   Batch Acc: 79.69
[Train] Epoch: 0 [456192/620022]    Loss: 0.009646   Batch Acc: 73.44
[Train] Epoch: 0 [456256/620022]    Loss: 0.005997   Batch Acc: 84.38
[Train] Epoch: 0 [456320/620022]    Loss: 0.009976   Batch Acc: 78.12
[Train] Epoch: 0 [456384/620022]    Loss: 0.009687   Batch Acc: 75.00
[Train] Epoch: 0 [456448/620022]    Loss: 0.008759   Batch Acc: 79.69
[Train] Epoch: 0 [456512/620022]    Loss: 0.008502   Batch Acc: 79.69
[Train] Epoch: 0 [456576/620022]    Loss: 0.012483   Batch Acc: 70.31
[Train] Epoch: 0 [456640/620022]    Loss: 0.008782   Batch Acc: 76.56
[Train] Epoch: 0 [456704/620022]    Loss: 0.007514   Batch Acc: 82.81
[Train] Epoch: 0 [456768/620022]    Loss: 0.010381   Batch Acc: 78.12
[Train] Epoch: 0 [456832/620022]    Loss: 0.007977   Batch Acc: 81.25
[Train] Epoch: 0 [456896/620022]    Loss: 0.007948   Batch Acc: 81.25
[Train] Epoch: 0 [456960/620022]    Loss: 0.010729   Batch Acc: 71.88
[Train] Epoch: 0 [457024/620022]    Loss: 0.008411   Batch Acc: 81.25
[Train] Epoch: 0 [457088/620022]    Loss: 0.008035   Batch Acc: 79.69
[Train] Epoch: 0 [457152/620022]    Loss: 0.008512   Batch Acc: 78.12
[Train] Epoch: 0 [457216/620022]    Loss: 0.008222   Batch Acc: 76.56
[Train] Epoch: 0 [457280/620022]    Loss: 0.006629   Batch Acc: 85.94
[Train] Epoch: 0 [457344/620022]    Loss: 0.008275   Batch Acc: 81.25
[Train] Epoch: 0 [457408/620022]    Loss: 0.008257   Batch Acc: 76.56
[Train] Epoch: 0 [457472/620022]    Loss: 0.008083   Batch Acc: 81.25
[Train] Epoch: 0 [457536/620022]    Loss: 0.009984   Batch Acc: 78.12
[Train] Epoch: 0 [457600/620022]    Loss: 0.010589   Batch Acc: 73.44
[Train] Epoch: 0 [457664/620022]    Loss: 0.007806   Batch Acc: 78.12
[Train] Epoch: 0 [457728/620022]    Loss: 0.007606   Batch Acc: 78.12
[Train] Epoch: 0 [457792/620022]    Loss: 0.009851   Batch Acc: 78.12
[Train] Epoch: 0 [457856/620022]    Loss: 0.008547   Batch Acc: 75.00
[Train] Epoch: 0 [457920/620022]    Loss: 0.010243   Batch Acc: 73.44
[Train] Epoch: 0 [457984/620022]    Loss: 0.010819   Batch Acc: 68.75
[Train] Epoch: 0 [458048/620022]    Loss: 0.010215   Batch Acc: 75.00
[Train] Epoch: 0 [458112/620022]    Loss: 0.007798   Batch Acc: 82.81
[Train] Epoch: 0 [458176/620022]    Loss: 0.012177   Batch Acc: 68.75
[Train] Epoch: 0 [458240/620022]    Loss: 0.011244   Batch Acc: 70.31
[Train] Epoch: 0 [458304/620022]    Loss: 0.007315   Batch Acc: 81.25
[Train] Epoch: 0 [458368/620022]    Loss: 0.010081   Batch Acc: 67.19
[Train] Epoch: 0 [458432/620022]    Loss: 0.008589   Batch Acc: 76.56
[Train] Epoch: 0 [458496/620022]    Loss: 0.009673   Batch Acc: 68.75
[Train] Epoch: 0 [458560/620022]    Loss: 0.010089   Batch Acc: 73.44
[Train] Epoch: 0 [458624/620022]    Loss: 0.007491   Batch Acc: 73.44
[Train] Epoch: 0 [458688/620022]    Loss: 0.008987   Batch Acc: 84.38
[Train] Epoch: 0 [458752/620022]    Loss: 0.008935   Batch Acc: 76.56
[Train] Epoch: 0 [458816/620022]    Loss: 0.010271   Batch Acc: 75.00
[Train] Epoch: 0 [458880/620022]    Loss: 0.008347   Batch Acc: 79.69
[Train] Epoch: 0 [458944/620022]    Loss: 0.011509   Batch Acc: 70.31
[Train] Epoch: 0 [459008/620022]    Loss: 0.008271   Batch Acc: 79.69
[Train] Epoch: 0 [459072/620022]    Loss: 0.010498   Batch Acc: 71.88
[Train] Epoch: 0 [459136/620022]    Loss: 0.010362   Batch Acc: 65.62
[Train] Epoch: 0 [459200/620022]    Loss: 0.007350   Batch Acc: 79.69
[Train] Epoch: 0 [459264/620022]    Loss: 0.009080   Batch Acc: 76.56
[Train] Epoch: 0 [459328/620022]    Loss: 0.008672   Batch Acc: 76.56
[Train] Epoch: 0 [459392/620022]    Loss: 0.008959   Batch Acc: 76.56
[Train] Epoch: 0 [459456/620022]    Loss: 0.009388   Batch Acc: 75.00
[Train] Epoch: 0 [459520/620022]    Loss: 0.007806   Batch Acc: 79.69
[Train] Epoch: 0 [459584/620022]    Loss: 0.008892   Batch Acc: 71.88
[Train] Epoch: 0 [459648/620022]    Loss: 0.008497   Batch Acc: 78.12
[Train] Epoch: 0 [459712/620022]    Loss: 0.008619   Batch Acc: 76.56
[Train] Epoch: 0 [459776/620022]    Loss: 0.008783   Batch Acc: 75.00
[Train] Epoch: 0 [459840/620022]    Loss: 0.009943   Batch Acc: 70.31
[Train] Epoch: 0 [459904/620022]    Loss: 0.009786   Batch Acc: 75.00
[Train] Epoch: 0 [459968/620022]    Loss: 0.008399   Batch Acc: 75.00
[Train] Epoch: 0 [460032/620022]    Loss: 0.009447   Batch Acc: 81.25
[Train] Epoch: 0 [460096/620022]    Loss: 0.007203   Batch Acc: 87.50
[Train] Epoch: 0 [460160/620022]    Loss: 0.008201   Batch Acc: 82.81
[Train] Epoch: 0 [460224/620022]    Loss: 0.008984   Batch Acc: 81.25
[Train] Epoch: 0 [460288/620022]    Loss: 0.007765   Batch Acc: 79.69
[Train] Epoch: 0 [460352/620022]    Loss: 0.009293   Batch Acc: 75.00
[Train] Epoch: 0 [460416/620022]    Loss: 0.007923   Batch Acc: 79.69
[Train] Epoch: 0 [460480/620022]    Loss: 0.009395   Batch Acc: 76.56
[Train] Epoch: 0 [460544/620022]    Loss: 0.009803   Batch Acc: 75.00
[Train] Epoch: 0 [460608/620022]    Loss: 0.011091   Batch Acc: 68.75
[Train] Epoch: 0 [460672/620022]    Loss: 0.006839   Batch Acc: 89.06
[Train] Epoch: 0 [460736/620022]    Loss: 0.010235   Batch Acc: 75.00
[Train] Epoch: 0 [460800/620022]    Loss: 0.008622   Batch Acc: 76.56
[Train] Epoch: 0 [460864/620022]    Loss: 0.010022   Batch Acc: 76.56
[Train] Epoch: 0 [460928/620022]    Loss: 0.009015   Batch Acc: 78.12
[Train] Epoch: 0 [460992/620022]    Loss: 0.010245   Batch Acc: 70.31
[Train] Epoch: 0 [461056/620022]    Loss: 0.008089   Batch Acc: 71.88
[Train] Epoch: 0 [461120/620022]    Loss: 0.009321   Batch Acc: 73.44
[Train] Epoch: 0 [461184/620022]    Loss: 0.008887   Batch Acc: 84.38
[Train] Epoch: 0 [461248/620022]    Loss: 0.008222   Batch Acc: 85.94
[Train] Epoch: 0 [461312/620022]    Loss: 0.009858   Batch Acc: 79.69
[Train] Epoch: 0 [461376/620022]    Loss: 0.009310   Batch Acc: 76.56
[Train] Epoch: 0 [461440/620022]    Loss: 0.011597   Batch Acc: 70.31
[Train] Epoch: 0 [461504/620022]    Loss: 0.009368   Batch Acc: 75.00
[Train] Epoch: 0 [461568/620022]    Loss: 0.009160   Batch Acc: 82.81
[Train] Epoch: 0 [461632/620022]    Loss: 0.010622   Batch Acc: 78.12
[Train] Epoch: 0 [461696/620022]    Loss: 0.008521   Batch Acc: 76.56
[Train] Epoch: 0 [461760/620022]    Loss: 0.009901   Batch Acc: 73.44
[Train] Epoch: 0 [461824/620022]    Loss: 0.010034   Batch Acc: 73.44
[Train] Epoch: 0 [461888/620022]    Loss: 0.011023   Batch Acc: 70.31
[Train] Epoch: 0 [461952/620022]    Loss: 0.011612   Batch Acc: 70.31
[Train] Epoch: 0 [462016/620022]    Loss: 0.010779   Batch Acc: 71.88
[Train] Epoch: 0 [462080/620022]    Loss: 0.008198   Batch Acc: 78.12
[Train] Epoch: 0 [462144/620022]    Loss: 0.008789   Batch Acc: 81.25
[Train] Epoch: 0 [462208/620022]    Loss: 0.008159   Batch Acc: 82.81
[Train] Epoch: 0 [462272/620022]    Loss: 0.007238   Batch Acc: 82.81
[Train] Epoch: 0 [462336/620022]    Loss: 0.006455   Batch Acc: 87.50
[Train] Epoch: 0 [462400/620022]    Loss: 0.009536   Batch Acc: 73.44
[Train] Epoch: 0 [462464/620022]    Loss: 0.007913   Batch Acc: 79.69
[Train] Epoch: 0 [462528/620022]    Loss: 0.008611   Batch Acc: 76.56
[Train] Epoch: 0 [462592/620022]    Loss: 0.009331   Batch Acc: 79.69
[Train] Epoch: 0 [462656/620022]    Loss: 0.009311   Batch Acc: 81.25
[Train] Epoch: 0 [462720/620022]    Loss: 0.008878   Batch Acc: 76.56
[Train] Epoch: 0 [462784/620022]    Loss: 0.009800   Batch Acc: 68.75
[Train] Epoch: 0 [462848/620022]    Loss: 0.008334   Batch Acc: 73.44
[Train] Epoch: 0 [462912/620022]    Loss: 0.010660   Batch Acc: 68.75
[Train] Epoch: 0 [462976/620022]    Loss: 0.007711   Batch Acc: 78.12
[Train] Epoch: 0 [463040/620022]    Loss: 0.007962   Batch Acc: 79.69
[Train] Epoch: 0 [463104/620022]    Loss: 0.009461   Batch Acc: 79.69
[Train] Epoch: 0 [463168/620022]    Loss: 0.006780   Batch Acc: 87.50
[Train] Epoch: 0 [463232/620022]    Loss: 0.009275   Batch Acc: 79.69
[Train] Epoch: 0 [463296/620022]    Loss: 0.007483   Batch Acc: 81.25
[Train] Epoch: 0 [463360/620022]    Loss: 0.009210   Batch Acc: 75.00
[Train] Epoch: 0 [463424/620022]    Loss: 0.009157   Batch Acc: 73.44
[Train] Epoch: 0 [463488/620022]    Loss: 0.008808   Batch Acc: 81.25
[Train] Epoch: 0 [463552/620022]    Loss: 0.011758   Batch Acc: 70.31
[Train] Epoch: 0 [463616/620022]    Loss: 0.007726   Batch Acc: 85.94
[Train] Epoch: 0 [463680/620022]    Loss: 0.007563   Batch Acc: 79.69
[Train] Epoch: 0 [463744/620022]    Loss: 0.009774   Batch Acc: 73.44
[Train] Epoch: 0 [463808/620022]    Loss: 0.010711   Batch Acc: 70.31
[Train] Epoch: 0 [463872/620022]    Loss: 0.011452   Batch Acc: 70.31
[Train] Epoch: 0 [463936/620022]    Loss: 0.009327   Batch Acc: 79.69
[Train] Epoch: 0 [464000/620022]    Loss: 0.009421   Batch Acc: 73.44
[Train] Epoch: 0 [464064/620022]    Loss: 0.008768   Batch Acc: 76.56
[Train] Epoch: 0 [464128/620022]    Loss: 0.008014   Batch Acc: 78.12
[Train] Epoch: 0 [464192/620022]    Loss: 0.007970   Batch Acc: 76.56
[Train] Epoch: 0 [464256/620022]    Loss: 0.008469   Batch Acc: 81.25
[Train] Epoch: 0 [464320/620022]    Loss: 0.007859   Batch Acc: 76.56
[Train] Epoch: 0 [464384/620022]    Loss: 0.007988   Batch Acc: 82.81
[Train] Epoch: 0 [464448/620022]    Loss: 0.007520   Batch Acc: 79.69
[Train] Epoch: 0 [464512/620022]    Loss: 0.007989   Batch Acc: 79.69
[Train] Epoch: 0 [464576/620022]    Loss: 0.009017   Batch Acc: 78.12
[Train] Epoch: 0 [464640/620022]    Loss: 0.008452   Batch Acc: 81.25
[Train] Epoch: 0 [464704/620022]    Loss: 0.006523   Batch Acc: 82.81
[Train] Epoch: 0 [464768/620022]    Loss: 0.009598   Batch Acc: 76.56
[Train] Epoch: 0 [464832/620022]    Loss: 0.010424   Batch Acc: 65.62
[Train] Epoch: 0 [464896/620022]    Loss: 0.010196   Batch Acc: 68.75
[Train] Epoch: 0 [464960/620022]    Loss: 0.007283   Batch Acc: 85.94
[Train] Epoch: 0 [465024/620022]    Loss: 0.010988   Batch Acc: 64.06
[Train] Epoch: 0 [465088/620022]    Loss: 0.008450   Batch Acc: 81.25
[Train] Epoch: 0 [465152/620022]    Loss: 0.007977   Batch Acc: 79.69
[Train] Epoch: 0 [465216/620022]    Loss: 0.007848   Batch Acc: 82.81
[Train] Epoch: 0 [465280/620022]    Loss: 0.008696   Batch Acc: 76.56
[Train] Epoch: 0 [465344/620022]    Loss: 0.009447   Batch Acc: 82.81
[Train] Epoch: 0 [465408/620022]    Loss: 0.010580   Batch Acc: 73.44
[Train] Epoch: 0 [465472/620022]    Loss: 0.010296   Batch Acc: 71.88
[Train] Epoch: 0 [465536/620022]    Loss: 0.008014   Batch Acc: 79.69
[Train] Epoch: 0 [465600/620022]    Loss: 0.009434   Batch Acc: 71.88
[Train] Epoch: 0 [465664/620022]    Loss: 0.008372   Batch Acc: 76.56
[Train] Epoch: 0 [465728/620022]    Loss: 0.009329   Batch Acc: 78.12
[Train] Epoch: 0 [465792/620022]    Loss: 0.008687   Batch Acc: 81.25
[Train] Epoch: 0 [465856/620022]    Loss: 0.006220   Batch Acc: 89.06
[Train] Epoch: 0 [465920/620022]    Loss: 0.008670   Batch Acc: 79.69
[Train] Epoch: 0 [465984/620022]    Loss: 0.011484   Batch Acc: 73.44
[Train] Epoch: 0 [466048/620022]    Loss: 0.009801   Batch Acc: 73.44
[Train] Epoch: 0 [466112/620022]    Loss: 0.009856   Batch Acc: 75.00
[Train] Epoch: 0 [466176/620022]    Loss: 0.010385   Batch Acc: 70.31
[Train] Epoch: 0 [466240/620022]    Loss: 0.008457   Batch Acc: 81.25
[Train] Epoch: 0 [466304/620022]    Loss: 0.007381   Batch Acc: 85.94
[Train] Epoch: 0 [466368/620022]    Loss: 0.008892   Batch Acc: 81.25
[Train] Epoch: 0 [466432/620022]    Loss: 0.006781   Batch Acc: 85.94
[Train] Epoch: 0 [466496/620022]    Loss: 0.011720   Batch Acc: 71.88
[Train] Epoch: 0 [466560/620022]    Loss: 0.008008   Batch Acc: 79.69
[Train] Epoch: 0 [466624/620022]    Loss: 0.008205   Batch Acc: 82.81
[Train] Epoch: 0 [466688/620022]    Loss: 0.009135   Batch Acc: 75.00
[Train] Epoch: 0 [466752/620022]    Loss: 0.008579   Batch Acc: 76.56
[Train] Epoch: 0 [466816/620022]    Loss: 0.010447   Batch Acc: 78.12
[Train] Epoch: 0 [466880/620022]    Loss: 0.009011   Batch Acc: 76.56
[Train] Epoch: 0 [466944/620022]    Loss: 0.009024   Batch Acc: 76.56
[Train] Epoch: 0 [467008/620022]    Loss: 0.007793   Batch Acc: 85.94
[Train] Epoch: 0 [467072/620022]    Loss: 0.009970   Batch Acc: 78.12
[Train] Epoch: 0 [467136/620022]    Loss: 0.006599   Batch Acc: 84.38
[Train] Epoch: 0 [467200/620022]    Loss: 0.010820   Batch Acc: 70.31
[Train] Epoch: 0 [467264/620022]    Loss: 0.006668   Batch Acc: 85.94
[Train] Epoch: 0 [467328/620022]    Loss: 0.008710   Batch Acc: 78.12
[Train] Epoch: 0 [467392/620022]    Loss: 0.009391   Batch Acc: 73.44
[Train] Epoch: 0 [467456/620022]    Loss: 0.008314   Batch Acc: 78.12
[Train] Epoch: 0 [467520/620022]    Loss: 0.008139   Batch Acc: 76.56
[Train] Epoch: 0 [467584/620022]    Loss: 0.013706   Batch Acc: 67.19
[Train] Epoch: 0 [467648/620022]    Loss: 0.009374   Batch Acc: 76.56
[Train] Epoch: 0 [467712/620022]    Loss: 0.007697   Batch Acc: 81.25
[Train] Epoch: 0 [467776/620022]    Loss: 0.012337   Batch Acc: 57.81
[Train] Epoch: 0 [467840/620022]    Loss: 0.008193   Batch Acc: 78.12
[Train] Epoch: 0 [467904/620022]    Loss: 0.008370   Batch Acc: 78.12
[Train] Epoch: 0 [467968/620022]    Loss: 0.008942   Batch Acc: 76.56
[Train] Epoch: 0 [468032/620022]    Loss: 0.008470   Batch Acc: 78.12
[Train] Epoch: 0 [468096/620022]    Loss: 0.008016   Batch Acc: 79.69
[Train] Epoch: 0 [468160/620022]    Loss: 0.007678   Batch Acc: 79.69
[Train] Epoch: 0 [468224/620022]    Loss: 0.006768   Batch Acc: 79.69
[Train] Epoch: 0 [468288/620022]    Loss: 0.007215   Batch Acc: 85.94
[Train] Epoch: 0 [468352/620022]    Loss: 0.008619   Batch Acc: 75.00
[Train] Epoch: 0 [468416/620022]    Loss: 0.007772   Batch Acc: 82.81
[Train] Epoch: 0 [468480/620022]    Loss: 0.007377   Batch Acc: 84.38
[Train] Epoch: 0 [468544/620022]    Loss: 0.007643   Batch Acc: 79.69
[Train] Epoch: 0 [468608/620022]    Loss: 0.008056   Batch Acc: 84.38
[Train] Epoch: 0 [468672/620022]    Loss: 0.009290   Batch Acc: 85.94
[Train] Epoch: 0 [468736/620022]    Loss: 0.009908   Batch Acc: 75.00
[Train] Epoch: 0 [468800/620022]    Loss: 0.009528   Batch Acc: 81.25
[Train] Epoch: 0 [468864/620022]    Loss: 0.009875   Batch Acc: 76.56
[Train] Epoch: 0 [468928/620022]    Loss: 0.008960   Batch Acc: 73.44
[Train] Epoch: 0 [468992/620022]    Loss: 0.009491   Batch Acc: 79.69
[Train] Epoch: 0 [469056/620022]    Loss: 0.007432   Batch Acc: 81.25
[Train] Epoch: 0 [469120/620022]    Loss: 0.006537   Batch Acc: 85.94
[Train] Epoch: 0 [469184/620022]    Loss: 0.008833   Batch Acc: 78.12
[Train] Epoch: 0 [469248/620022]    Loss: 0.008521   Batch Acc: 75.00
[Train] Epoch: 0 [469312/620022]    Loss: 0.008540   Batch Acc: 78.12
[Train] Epoch: 0 [469376/620022]    Loss: 0.008538   Batch Acc: 79.69
[Train] Epoch: 0 [469440/620022]    Loss: 0.009337   Batch Acc: 73.44
[Train] Epoch: 0 [469504/620022]    Loss: 0.008206   Batch Acc: 81.25
[Train] Epoch: 0 [469568/620022]    Loss: 0.010955   Batch Acc: 62.50
[Train] Epoch: 0 [469632/620022]    Loss: 0.009286   Batch Acc: 75.00
[Train] Epoch: 0 [469696/620022]    Loss: 0.008998   Batch Acc: 75.00
[Train] Epoch: 0 [469760/620022]    Loss: 0.012839   Batch Acc: 75.00
[Train] Epoch: 0 [469824/620022]    Loss: 0.011385   Batch Acc: 65.62
[Train] Epoch: 0 [469888/620022]    Loss: 0.009606   Batch Acc: 81.25
[Train] Epoch: 0 [469952/620022]    Loss: 0.010017   Batch Acc: 71.88
[Train] Epoch: 0 [470016/620022]    Loss: 0.009718   Batch Acc: 75.00
[Train] Epoch: 0 [470080/620022]    Loss: 0.006717   Batch Acc: 85.94
[Train] Epoch: 0 [470144/620022]    Loss: 0.009208   Batch Acc: 75.00
[Train] Epoch: 0 [470208/620022]    Loss: 0.010437   Batch Acc: 73.44
[Train] Epoch: 0 [470272/620022]    Loss: 0.009868   Batch Acc: 76.56
[Train] Epoch: 0 [470336/620022]    Loss: 0.010200   Batch Acc: 71.88
[Train] Epoch: 0 [470400/620022]    Loss: 0.011256   Batch Acc: 71.88
[Train] Epoch: 0 [470464/620022]    Loss: 0.007913   Batch Acc: 84.38
[Train] Epoch: 0 [470528/620022]    Loss: 0.010833   Batch Acc: 65.62
[Train] Epoch: 0 [470592/620022]    Loss: 0.007488   Batch Acc: 85.94
[Train] Epoch: 0 [470656/620022]    Loss: 0.006743   Batch Acc: 85.94
[Train] Epoch: 0 [470720/620022]    Loss: 0.006031   Batch Acc: 85.94
[Train] Epoch: 0 [470784/620022]    Loss: 0.009572   Batch Acc: 71.88
[Train] Epoch: 0 [470848/620022]    Loss: 0.010051   Batch Acc: 70.31
[Train] Epoch: 0 [470912/620022]    Loss: 0.009722   Batch Acc: 71.88
[Train] Epoch: 0 [470976/620022]    Loss: 0.008762   Batch Acc: 79.69
[Train] Epoch: 0 [471040/620022]    Loss: 0.008982   Batch Acc: 78.12
[Train] Epoch: 0 [471104/620022]    Loss: 0.008339   Batch Acc: 79.69
[Train] Epoch: 0 [471168/620022]    Loss: 0.009209   Batch Acc: 75.00
[Train] Epoch: 0 [471232/620022]    Loss: 0.009260   Batch Acc: 78.12
[Train] Epoch: 0 [471296/620022]    Loss: 0.010905   Batch Acc: 70.31
[Train] Epoch: 0 [471360/620022]    Loss: 0.010051   Batch Acc: 73.44
[Train] Epoch: 0 [471424/620022]    Loss: 0.009193   Batch Acc: 75.00
[Train] Epoch: 0 [471488/620022]    Loss: 0.012648   Batch Acc: 67.19
[Train] Epoch: 0 [471552/620022]    Loss: 0.007852   Batch Acc: 89.06
[Train] Epoch: 0 [471616/620022]    Loss: 0.008873   Batch Acc: 78.12
[Train] Epoch: 0 [471680/620022]    Loss: 0.008938   Batch Acc: 78.12
[Train] Epoch: 0 [471744/620022]    Loss: 0.010118   Batch Acc: 73.44
[Train] Epoch: 0 [471808/620022]    Loss: 0.010566   Batch Acc: 71.88
[Train] Epoch: 0 [471872/620022]    Loss: 0.007030   Batch Acc: 84.38
[Train] Epoch: 0 [471936/620022]    Loss: 0.007396   Batch Acc: 76.56
[Train] Epoch: 0 [472000/620022]    Loss: 0.009647   Batch Acc: 75.00
[Train] Epoch: 0 [472064/620022]    Loss: 0.008101   Batch Acc: 73.44
[Train] Epoch: 0 [472128/620022]    Loss: 0.009172   Batch Acc: 78.12
[Train] Epoch: 0 [472192/620022]    Loss: 0.010072   Batch Acc: 73.44
[Train] Epoch: 0 [472256/620022]    Loss: 0.010059   Batch Acc: 71.88
[Train] Epoch: 0 [472320/620022]    Loss: 0.008206   Batch Acc: 78.12
[Train] Epoch: 0 [472384/620022]    Loss: 0.008317   Batch Acc: 84.38
[Train] Epoch: 0 [472448/620022]    Loss: 0.008777   Batch Acc: 70.31
[Train] Epoch: 0 [472512/620022]    Loss: 0.007660   Batch Acc: 82.81
[Train] Epoch: 0 [472576/620022]    Loss: 0.008531   Batch Acc: 79.69
[Train] Epoch: 0 [472640/620022]    Loss: 0.010882   Batch Acc: 68.75
[Train] Epoch: 0 [472704/620022]    Loss: 0.009683   Batch Acc: 71.88
[Train] Epoch: 0 [472768/620022]    Loss: 0.007509   Batch Acc: 84.38
[Train] Epoch: 0 [472832/620022]    Loss: 0.008576   Batch Acc: 79.69
[Train] Epoch: 0 [472896/620022]    Loss: 0.009230   Batch Acc: 79.69
[Train] Epoch: 0 [472960/620022]    Loss: 0.009726   Batch Acc: 75.00
[Train] Epoch: 0 [473024/620022]    Loss: 0.011926   Batch Acc: 62.50
[Train] Epoch: 0 [473088/620022]    Loss: 0.011031   Batch Acc: 71.88
[Train] Epoch: 0 [473152/620022]    Loss: 0.007807   Batch Acc: 79.69
[Train] Epoch: 0 [473216/620022]    Loss: 0.008905   Batch Acc: 76.56
[Train] Epoch: 0 [473280/620022]    Loss: 0.008996   Batch Acc: 78.12
[Train] Epoch: 0 [473344/620022]    Loss: 0.008611   Batch Acc: 73.44
[Train] Epoch: 0 [473408/620022]    Loss: 0.005950   Batch Acc: 87.50
[Train] Epoch: 0 [473472/620022]    Loss: 0.011233   Batch Acc: 68.75
[Train] Epoch: 0 [473536/620022]    Loss: 0.009558   Batch Acc: 76.56
[Train] Epoch: 0 [473600/620022]    Loss: 0.011062   Batch Acc: 70.31
[Train] Epoch: 0 [473664/620022]    Loss: 0.010062   Batch Acc: 73.44
[Train] Epoch: 0 [473728/620022]    Loss: 0.008491   Batch Acc: 73.44
[Train] Epoch: 0 [473792/620022]    Loss: 0.008674   Batch Acc: 76.56
[Train] Epoch: 0 [473856/620022]    Loss: 0.007108   Batch Acc: 85.94
[Train] Epoch: 0 [473920/620022]    Loss: 0.009026   Batch Acc: 76.56
[Train] Epoch: 0 [473984/620022]    Loss: 0.007513   Batch Acc: 82.81
[Train] Epoch: 0 [474048/620022]    Loss: 0.009365   Batch Acc: 76.56
[Train] Epoch: 0 [474112/620022]    Loss: 0.009333   Batch Acc: 78.12
[Train] Epoch: 0 [474176/620022]    Loss: 0.010443   Batch Acc: 78.12
[Train] Epoch: 0 [474240/620022]    Loss: 0.009603   Batch Acc: 79.69
[Train] Epoch: 0 [474304/620022]    Loss: 0.009377   Batch Acc: 75.00
[Train] Epoch: 0 [474368/620022]    Loss: 0.008476   Batch Acc: 73.44
[Train] Epoch: 0 [474432/620022]    Loss: 0.008714   Batch Acc: 84.38
[Train] Epoch: 0 [474496/620022]    Loss: 0.009444   Batch Acc: 85.94
[Train] Epoch: 0 [474560/620022]    Loss: 0.010326   Batch Acc: 70.31
[Train] Epoch: 0 [474624/620022]    Loss: 0.010538   Batch Acc: 71.88
[Train] Epoch: 0 [474688/620022]    Loss: 0.007898   Batch Acc: 85.94
[Train] Epoch: 0 [474752/620022]    Loss: 0.009623   Batch Acc: 73.44
[Train] Epoch: 0 [474816/620022]    Loss: 0.011645   Batch Acc: 71.88
[Train] Epoch: 0 [474880/620022]    Loss: 0.007707   Batch Acc: 81.25
[Train] Epoch: 0 [474944/620022]    Loss: 0.008872   Batch Acc: 75.00
[Train] Epoch: 0 [475008/620022]    Loss: 0.009369   Batch Acc: 75.00
[Train] Epoch: 0 [475072/620022]    Loss: 0.010690   Batch Acc: 70.31
[Train] Epoch: 0 [475136/620022]    Loss: 0.008324   Batch Acc: 75.00
[Train] Epoch: 0 [475200/620022]    Loss: 0.009634   Batch Acc: 68.75
[Train] Epoch: 0 [475264/620022]    Loss: 0.007917   Batch Acc: 78.12
[Train] Epoch: 0 [475328/620022]    Loss: 0.009201   Batch Acc: 76.56
[Train] Epoch: 0 [475392/620022]    Loss: 0.008877   Batch Acc: 73.44
[Train] Epoch: 0 [475456/620022]    Loss: 0.010415   Batch Acc: 73.44
[Train] Epoch: 0 [475520/620022]    Loss: 0.010385   Batch Acc: 81.25
[Train] Epoch: 0 [475584/620022]    Loss: 0.010267   Batch Acc: 70.31
[Train] Epoch: 0 [475648/620022]    Loss: 0.009840   Batch Acc: 71.88
[Train] Epoch: 0 [475712/620022]    Loss: 0.008189   Batch Acc: 82.81
[Train] Epoch: 0 [475776/620022]    Loss: 0.010794   Batch Acc: 67.19
[Train] Epoch: 0 [475840/620022]    Loss: 0.007923   Batch Acc: 79.69
[Train] Epoch: 0 [475904/620022]    Loss: 0.005569   Batch Acc: 93.75
[Train] Epoch: 0 [475968/620022]    Loss: 0.007024   Batch Acc: 84.38
[Train] Epoch: 0 [476032/620022]    Loss: 0.009032   Batch Acc: 79.69
[Train] Epoch: 0 [476096/620022]    Loss: 0.010433   Batch Acc: 68.75
[Train] Epoch: 0 [476160/620022]    Loss: 0.008686   Batch Acc: 79.69
[Train] Epoch: 0 [476224/620022]    Loss: 0.007806   Batch Acc: 84.38
[Train] Epoch: 0 [476288/620022]    Loss: 0.007940   Batch Acc: 76.56
[Train] Epoch: 0 [476352/620022]    Loss: 0.010893   Batch Acc: 68.75
[Train] Epoch: 0 [476416/620022]    Loss: 0.008140   Batch Acc: 82.81
[Train] Epoch: 0 [476480/620022]    Loss: 0.007939   Batch Acc: 82.81
[Train] Epoch: 0 [476544/620022]    Loss: 0.009818   Batch Acc: 71.88
[Train] Epoch: 0 [476608/620022]    Loss: 0.008753   Batch Acc: 71.88
[Train] Epoch: 0 [476672/620022]    Loss: 0.007222   Batch Acc: 82.81
[Train] Epoch: 0 [476736/620022]    Loss: 0.010557   Batch Acc: 73.44
[Train] Epoch: 0 [476800/620022]    Loss: 0.012855   Batch Acc: 68.75
[Train] Epoch: 0 [476864/620022]    Loss: 0.008102   Batch Acc: 79.69
[Train] Epoch: 0 [476928/620022]    Loss: 0.008072   Batch Acc: 75.00
[Train] Epoch: 0 [476992/620022]    Loss: 0.007838   Batch Acc: 79.69
[Train] Epoch: 0 [477056/620022]    Loss: 0.006921   Batch Acc: 81.25
[Train] Epoch: 0 [477120/620022]    Loss: 0.007162   Batch Acc: 76.56
[Train] Epoch: 0 [477184/620022]    Loss: 0.008641   Batch Acc: 78.12
[Train] Epoch: 0 [477248/620022]    Loss: 0.008478   Batch Acc: 76.56
[Train] Epoch: 0 [477312/620022]    Loss: 0.008775   Batch Acc: 71.88
[Train] Epoch: 0 [477376/620022]    Loss: 0.009879   Batch Acc: 81.25
[Train] Epoch: 0 [477440/620022]    Loss: 0.009076   Batch Acc: 75.00
[Train] Epoch: 0 [477504/620022]    Loss: 0.007272   Batch Acc: 84.38
[Train] Epoch: 0 [477568/620022]    Loss: 0.011183   Batch Acc: 67.19
[Train] Epoch: 0 [477632/620022]    Loss: 0.007536   Batch Acc: 84.38
[Train] Epoch: 0 [477696/620022]    Loss: 0.010276   Batch Acc: 71.88
[Train] Epoch: 0 [477760/620022]    Loss: 0.009295   Batch Acc: 76.56
[Train] Epoch: 0 [477824/620022]    Loss: 0.009944   Batch Acc: 71.88
[Train] Epoch: 0 [477888/620022]    Loss: 0.007860   Batch Acc: 84.38
[Train] Epoch: 0 [477952/620022]    Loss: 0.005655   Batch Acc: 92.19
[Train] Epoch: 0 [478016/620022]    Loss: 0.009959   Batch Acc: 73.44
[Train] Epoch: 0 [478080/620022]    Loss: 0.012286   Batch Acc: 65.62
[Train] Epoch: 0 [478144/620022]    Loss: 0.009792   Batch Acc: 75.00
[Train] Epoch: 0 [478208/620022]    Loss: 0.007200   Batch Acc: 84.38
[Train] Epoch: 0 [478272/620022]    Loss: 0.009978   Batch Acc: 82.81
[Train] Epoch: 0 [478336/620022]    Loss: 0.010615   Batch Acc: 76.56
[Train] Epoch: 0 [478400/620022]    Loss: 0.009550   Batch Acc: 78.12
[Train] Epoch: 0 [478464/620022]    Loss: 0.008611   Batch Acc: 75.00
[Train] Epoch: 0 [478528/620022]    Loss: 0.009785   Batch Acc: 71.88
[Train] Epoch: 0 [478592/620022]    Loss: 0.009524   Batch Acc: 75.00
[Train] Epoch: 0 [478656/620022]    Loss: 0.007367   Batch Acc: 79.69
[Train] Epoch: 0 [478720/620022]    Loss: 0.009563   Batch Acc: 73.44
[Train] Epoch: 0 [478784/620022]    Loss: 0.007726   Batch Acc: 85.94
[Train] Epoch: 0 [478848/620022]    Loss: 0.009928   Batch Acc: 73.44
[Train] Epoch: 0 [478912/620022]    Loss: 0.008480   Batch Acc: 82.81
[Train] Epoch: 0 [478976/620022]    Loss: 0.009132   Batch Acc: 76.56
[Train] Epoch: 0 [479040/620022]    Loss: 0.009155   Batch Acc: 78.12
[Train] Epoch: 0 [479104/620022]    Loss: 0.007647   Batch Acc: 81.25
[Train] Epoch: 0 [479168/620022]    Loss: 0.008967   Batch Acc: 78.12
[Train] Epoch: 0 [479232/620022]    Loss: 0.008191   Batch Acc: 79.69
[Train] Epoch: 0 [479296/620022]    Loss: 0.009161   Batch Acc: 75.00
[Train] Epoch: 0 [479360/620022]    Loss: 0.008310   Batch Acc: 78.12
[Train] Epoch: 0 [479424/620022]    Loss: 0.008300   Batch Acc: 79.69
[Train] Epoch: 0 [479488/620022]    Loss: 0.009014   Batch Acc: 75.00
[Train] Epoch: 0 [479552/620022]    Loss: 0.008409   Batch Acc: 82.81
[Train] Epoch: 0 [479616/620022]    Loss: 0.008652   Batch Acc: 76.56
[Train] Epoch: 0 [479680/620022]    Loss: 0.008748   Batch Acc: 75.00
[Train] Epoch: 0 [479744/620022]    Loss: 0.009094   Batch Acc: 78.12
[Train] Epoch: 0 [479808/620022]    Loss: 0.009487   Batch Acc: 73.44
[Train] Epoch: 0 [479872/620022]    Loss: 0.011164   Batch Acc: 68.75
[Train] Epoch: 0 [479936/620022]    Loss: 0.009593   Batch Acc: 75.00
[Train] Epoch: 0 [480000/620022]    Loss: 0.009543   Batch Acc: 75.00
[Train] Epoch: 0 [480064/620022]    Loss: 0.009779   Batch Acc: 75.00
[Train] Epoch: 0 [480128/620022]    Loss: 0.007796   Batch Acc: 81.25
[Train] Epoch: 0 [480192/620022]    Loss: 0.010283   Batch Acc: 71.88
[Train] Epoch: 0 [480256/620022]    Loss: 0.009664   Batch Acc: 73.44
[Train] Epoch: 0 [480320/620022]    Loss: 0.008119   Batch Acc: 82.81
[Train] Epoch: 0 [480384/620022]    Loss: 0.006047   Batch Acc: 90.62
[Train] Epoch: 0 [480448/620022]    Loss: 0.009662   Batch Acc: 71.88
[Train] Epoch: 0 [480512/620022]    Loss: 0.009438   Batch Acc: 71.88
[Train] Epoch: 0 [480576/620022]    Loss: 0.008255   Batch Acc: 76.56
[Train] Epoch: 0 [480640/620022]    Loss: 0.009991   Batch Acc: 75.00
[Train] Epoch: 0 [480704/620022]    Loss: 0.007933   Batch Acc: 78.12
[Train] Epoch: 0 [480768/620022]    Loss: 0.009309   Batch Acc: 78.12
[Train] Epoch: 0 [480832/620022]    Loss: 0.009324   Batch Acc: 78.12
[Train] Epoch: 0 [480896/620022]    Loss: 0.008277   Batch Acc: 79.69
[Train] Epoch: 0 [480960/620022]    Loss: 0.007532   Batch Acc: 79.69
[Train] Epoch: 0 [481024/620022]    Loss: 0.009213   Batch Acc: 73.44
[Train] Epoch: 0 [481088/620022]    Loss: 0.009533   Batch Acc: 67.19
[Train] Epoch: 0 [481152/620022]    Loss: 0.007531   Batch Acc: 78.12
[Train] Epoch: 0 [481216/620022]    Loss: 0.008054   Batch Acc: 82.81
[Train] Epoch: 0 [481280/620022]    Loss: 0.009575   Batch Acc: 78.12
[Train] Epoch: 0 [481344/620022]    Loss: 0.009334   Batch Acc: 75.00
[Train] Epoch: 0 [481408/620022]    Loss: 0.007192   Batch Acc: 79.69
[Train] Epoch: 0 [481472/620022]    Loss: 0.010235   Batch Acc: 64.06
[Train] Epoch: 0 [481536/620022]    Loss: 0.007658   Batch Acc: 76.56
[Train] Epoch: 0 [481600/620022]    Loss: 0.007596   Batch Acc: 81.25
[Train] Epoch: 0 [481664/620022]    Loss: 0.008357   Batch Acc: 76.56
[Train] Epoch: 0 [481728/620022]    Loss: 0.009198   Batch Acc: 79.69
[Train] Epoch: 0 [481792/620022]    Loss: 0.007816   Batch Acc: 84.38
[Train] Epoch: 0 [481856/620022]    Loss: 0.008339   Batch Acc: 81.25
[Train] Epoch: 0 [481920/620022]    Loss: 0.010227   Batch Acc: 73.44
[Train] Epoch: 0 [481984/620022]    Loss: 0.006505   Batch Acc: 87.50
[Train] Epoch: 0 [482048/620022]    Loss: 0.008498   Batch Acc: 75.00
[Train] Epoch: 0 [482112/620022]    Loss: 0.008875   Batch Acc: 79.69
[Train] Epoch: 0 [482176/620022]    Loss: 0.007096   Batch Acc: 79.69
[Train] Epoch: 0 [482240/620022]    Loss: 0.006348   Batch Acc: 85.94
[Train] Epoch: 0 [482304/620022]    Loss: 0.010419   Batch Acc: 68.75
[Train] Epoch: 0 [482368/620022]    Loss: 0.009488   Batch Acc: 76.56
[Train] Epoch: 0 [482432/620022]    Loss: 0.008740   Batch Acc: 82.81
[Train] Epoch: 0 [482496/620022]    Loss: 0.009070   Batch Acc: 75.00
[Train] Epoch: 0 [482560/620022]    Loss: 0.007257   Batch Acc: 82.81
[Train] Epoch: 0 [482624/620022]    Loss: 0.010414   Batch Acc: 62.50
[Train] Epoch: 0 [482688/620022]    Loss: 0.009466   Batch Acc: 75.00
[Train] Epoch: 0 [482752/620022]    Loss: 0.007923   Batch Acc: 81.25
[Train] Epoch: 0 [482816/620022]    Loss: 0.010432   Batch Acc: 73.44
[Train] Epoch: 0 [482880/620022]    Loss: 0.008786   Batch Acc: 79.69
[Train] Epoch: 0 [482944/620022]    Loss: 0.011058   Batch Acc: 71.88
[Train] Epoch: 0 [483008/620022]    Loss: 0.009722   Batch Acc: 71.88
[Train] Epoch: 0 [483072/620022]    Loss: 0.008214   Batch Acc: 81.25
[Train] Epoch: 0 [483136/620022]    Loss: 0.010131   Batch Acc: 75.00
[Train] Epoch: 0 [483200/620022]    Loss: 0.008493   Batch Acc: 82.81
[Train] Epoch: 0 [483264/620022]    Loss: 0.008027   Batch Acc: 75.00
[Train] Epoch: 0 [483328/620022]    Loss: 0.005423   Batch Acc: 87.50
[Train] Epoch: 0 [483392/620022]    Loss: 0.010181   Batch Acc: 67.19
[Train] Epoch: 0 [483456/620022]    Loss: 0.010199   Batch Acc: 67.19
[Train] Epoch: 0 [483520/620022]    Loss: 0.008559   Batch Acc: 79.69
[Train] Epoch: 0 [483584/620022]    Loss: 0.009806   Batch Acc: 68.75
[Train] Epoch: 0 [483648/620022]    Loss: 0.010955   Batch Acc: 76.56
[Train] Epoch: 0 [483712/620022]    Loss: 0.007776   Batch Acc: 82.81
[Train] Epoch: 0 [483776/620022]    Loss: 0.007616   Batch Acc: 79.69
[Train] Epoch: 0 [483840/620022]    Loss: 0.008203   Batch Acc: 79.69
[Train] Epoch: 0 [483904/620022]    Loss: 0.007008   Batch Acc: 81.25
[Train] Epoch: 0 [483968/620022]    Loss: 0.006236   Batch Acc: 82.81
[Train] Epoch: 0 [484032/620022]    Loss: 0.009937   Batch Acc: 75.00
[Train] Epoch: 0 [484096/620022]    Loss: 0.010401   Batch Acc: 75.00
[Train] Epoch: 0 [484160/620022]    Loss: 0.007738   Batch Acc: 81.25
[Train] Epoch: 0 [484224/620022]    Loss: 0.009877   Batch Acc: 75.00
[Train] Epoch: 0 [484288/620022]    Loss: 0.010115   Batch Acc: 71.88
[Train] Epoch: 0 [484352/620022]    Loss: 0.008448   Batch Acc: 75.00
[Train] Epoch: 0 [484416/620022]    Loss: 0.012138   Batch Acc: 75.00
[Train] Epoch: 0 [484480/620022]    Loss: 0.007404   Batch Acc: 79.69
[Train] Epoch: 0 [484544/620022]    Loss: 0.008974   Batch Acc: 75.00
[Train] Epoch: 0 [484608/620022]    Loss: 0.008441   Batch Acc: 81.25
[Train] Epoch: 0 [484672/620022]    Loss: 0.008677   Batch Acc: 81.25
[Train] Epoch: 0 [484736/620022]    Loss: 0.009220   Batch Acc: 68.75
[Train] Epoch: 0 [484800/620022]    Loss: 0.008509   Batch Acc: 71.88
[Train] Epoch: 0 [484864/620022]    Loss: 0.008657   Batch Acc: 79.69
[Train] Epoch: 0 [484928/620022]    Loss: 0.007569   Batch Acc: 81.25
[Train] Epoch: 0 [484992/620022]    Loss: 0.007980   Batch Acc: 82.81
[Train] Epoch: 0 [485056/620022]    Loss: 0.007791   Batch Acc: 78.12
[Train] Epoch: 0 [485120/620022]    Loss: 0.007644   Batch Acc: 84.38
[Train] Epoch: 0 [485184/620022]    Loss: 0.007629   Batch Acc: 79.69
[Train] Epoch: 0 [485248/620022]    Loss: 0.007172   Batch Acc: 89.06
[Train] Epoch: 0 [485312/620022]    Loss: 0.008745   Batch Acc: 73.44
[Train] Epoch: 0 [485376/620022]    Loss: 0.007125   Batch Acc: 82.81
[Train] Epoch: 0 [485440/620022]    Loss: 0.008421   Batch Acc: 76.56
[Train] Epoch: 0 [485504/620022]    Loss: 0.010388   Batch Acc: 70.31
[Train] Epoch: 0 [485568/620022]    Loss: 0.007903   Batch Acc: 76.56
[Train] Epoch: 0 [485632/620022]    Loss: 0.010660   Batch Acc: 70.31
[Train] Epoch: 0 [485696/620022]    Loss: 0.008653   Batch Acc: 78.12
[Train] Epoch: 0 [485760/620022]    Loss: 0.006939   Batch Acc: 79.69
[Train] Epoch: 0 [485824/620022]    Loss: 0.010056   Batch Acc: 73.44
[Train] Epoch: 0 [485888/620022]    Loss: 0.008329   Batch Acc: 78.12
[Train] Epoch: 0 [485952/620022]    Loss: 0.007868   Batch Acc: 79.69
[Train] Epoch: 0 [486016/620022]    Loss: 0.008263   Batch Acc: 76.56
[Train] Epoch: 0 [486080/620022]    Loss: 0.008517   Batch Acc: 82.81
[Train] Epoch: 0 [486144/620022]    Loss: 0.007912   Batch Acc: 85.94
[Train] Epoch: 0 [486208/620022]    Loss: 0.009254   Batch Acc: 78.12
[Train] Epoch: 0 [486272/620022]    Loss: 0.009920   Batch Acc: 76.56
[Train] Epoch: 0 [486336/620022]    Loss: 0.011238   Batch Acc: 73.44
[Train] Epoch: 0 [486400/620022]    Loss: 0.007176   Batch Acc: 85.94
[Train] Epoch: 0 [486464/620022]    Loss: 0.009392   Batch Acc: 79.69
[Train] Epoch: 0 [486528/620022]    Loss: 0.009142   Batch Acc: 75.00
[Train] Epoch: 0 [486592/620022]    Loss: 0.008811   Batch Acc: 79.69
[Train] Epoch: 0 [486656/620022]    Loss: 0.010711   Batch Acc: 65.62
[Train] Epoch: 0 [486720/620022]    Loss: 0.011055   Batch Acc: 73.44
[Train] Epoch: 0 [486784/620022]    Loss: 0.007936   Batch Acc: 81.25
[Train] Epoch: 0 [486848/620022]    Loss: 0.007527   Batch Acc: 84.38
[Train] Epoch: 0 [486912/620022]    Loss: 0.009190   Batch Acc: 75.00
[Train] Epoch: 0 [486976/620022]    Loss: 0.008093   Batch Acc: 78.12
[Train] Epoch: 0 [487040/620022]    Loss: 0.009141   Batch Acc: 75.00
[Train] Epoch: 0 [487104/620022]    Loss: 0.009205   Batch Acc: 73.44
[Train] Epoch: 0 [487168/620022]    Loss: 0.008526   Batch Acc: 81.25
[Train] Epoch: 0 [487232/620022]    Loss: 0.007764   Batch Acc: 78.12
[Train] Epoch: 0 [487296/620022]    Loss: 0.007709   Batch Acc: 78.12
[Train] Epoch: 0 [487360/620022]    Loss: 0.010460   Batch Acc: 70.31
[Train] Epoch: 0 [487424/620022]    Loss: 0.008740   Batch Acc: 78.12
[Train] Epoch: 0 [487488/620022]    Loss: 0.009383   Batch Acc: 76.56
[Train] Epoch: 0 [487552/620022]    Loss: 0.008247   Batch Acc: 78.12
[Train] Epoch: 0 [487616/620022]    Loss: 0.007326   Batch Acc: 79.69
[Train] Epoch: 0 [487680/620022]    Loss: 0.012267   Batch Acc: 75.00
[Train] Epoch: 0 [487744/620022]    Loss: 0.008821   Batch Acc: 78.12
[Train] Epoch: 0 [487808/620022]    Loss: 0.009560   Batch Acc: 73.44
[Train] Epoch: 0 [487872/620022]    Loss: 0.007122   Batch Acc: 79.69
[Train] Epoch: 0 [487936/620022]    Loss: 0.008448   Batch Acc: 75.00
[Train] Epoch: 0 [488000/620022]    Loss: 0.008766   Batch Acc: 78.12
[Train] Epoch: 0 [488064/620022]    Loss: 0.009651   Batch Acc: 70.31
[Train] Epoch: 0 [488128/620022]    Loss: 0.009025   Batch Acc: 79.69
[Train] Epoch: 0 [488192/620022]    Loss: 0.007899   Batch Acc: 79.69
[Train] Epoch: 0 [488256/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 0 [488320/620022]    Loss: 0.009033   Batch Acc: 75.00
[Train] Epoch: 0 [488384/620022]    Loss: 0.007763   Batch Acc: 79.69
[Train] Epoch: 0 [488448/620022]    Loss: 0.009031   Batch Acc: 78.12
[Train] Epoch: 0 [488512/620022]    Loss: 0.009306   Batch Acc: 79.69
[Train] Epoch: 0 [488576/620022]    Loss: 0.010574   Batch Acc: 78.12
[Train] Epoch: 0 [488640/620022]    Loss: 0.008898   Batch Acc: 78.12
[Train] Epoch: 0 [488704/620022]    Loss: 0.008243   Batch Acc: 75.00
[Train] Epoch: 0 [488768/620022]    Loss: 0.010724   Batch Acc: 73.44
[Train] Epoch: 0 [488832/620022]    Loss: 0.009598   Batch Acc: 73.44
[Train] Epoch: 0 [488896/620022]    Loss: 0.010470   Batch Acc: 75.00
[Train] Epoch: 0 [488960/620022]    Loss: 0.007877   Batch Acc: 82.81
[Train] Epoch: 0 [489024/620022]    Loss: 0.009773   Batch Acc: 75.00
[Train] Epoch: 0 [489088/620022]    Loss: 0.008009   Batch Acc: 79.69
[Train] Epoch: 0 [489152/620022]    Loss: 0.010399   Batch Acc: 71.88
[Train] Epoch: 0 [489216/620022]    Loss: 0.006666   Batch Acc: 87.50
[Train] Epoch: 0 [489280/620022]    Loss: 0.008019   Batch Acc: 81.25
[Train] Epoch: 0 [489344/620022]    Loss: 0.007942   Batch Acc: 79.69
[Train] Epoch: 0 [489408/620022]    Loss: 0.008655   Batch Acc: 76.56
[Train] Epoch: 0 [489472/620022]    Loss: 0.008878   Batch Acc: 76.56
[Train] Epoch: 0 [489536/620022]    Loss: 0.007950   Batch Acc: 81.25
[Train] Epoch: 0 [489600/620022]    Loss: 0.009203   Batch Acc: 75.00
[Train] Epoch: 0 [489664/620022]    Loss: 0.009153   Batch Acc: 78.12
[Train] Epoch: 0 [489728/620022]    Loss: 0.008988   Batch Acc: 75.00
[Train] Epoch: 0 [489792/620022]    Loss: 0.007641   Batch Acc: 79.69
[Train] Epoch: 0 [489856/620022]    Loss: 0.009039   Batch Acc: 76.56
[Train] Epoch: 0 [489920/620022]    Loss: 0.009533   Batch Acc: 70.31
[Train] Epoch: 0 [489984/620022]    Loss: 0.009310   Batch Acc: 70.31
[Train] Epoch: 0 [490048/620022]    Loss: 0.008843   Batch Acc: 73.44
[Train] Epoch: 0 [490112/620022]    Loss: 0.008120   Batch Acc: 82.81
[Train] Epoch: 0 [490176/620022]    Loss: 0.008240   Batch Acc: 76.56
[Train] Epoch: 0 [490240/620022]    Loss: 0.009794   Batch Acc: 76.56
[Train] Epoch: 0 [490304/620022]    Loss: 0.007964   Batch Acc: 81.25
[Train] Epoch: 0 [490368/620022]    Loss: 0.011358   Batch Acc: 68.75
[Train] Epoch: 0 [490432/620022]    Loss: 0.007906   Batch Acc: 76.56
[Train] Epoch: 0 [490496/620022]    Loss: 0.010135   Batch Acc: 75.00
[Train] Epoch: 0 [490560/620022]    Loss: 0.008842   Batch Acc: 78.12
[Train] Epoch: 0 [490624/620022]    Loss: 0.008131   Batch Acc: 78.12
[Train] Epoch: 0 [490688/620022]    Loss: 0.008994   Batch Acc: 79.69
[Train] Epoch: 0 [490752/620022]    Loss: 0.011399   Batch Acc: 71.88
[Train] Epoch: 0 [490816/620022]    Loss: 0.009275   Batch Acc: 75.00
[Train] Epoch: 0 [490880/620022]    Loss: 0.008207   Batch Acc: 79.69
[Train] Epoch: 0 [490944/620022]    Loss: 0.008853   Batch Acc: 76.56
[Train] Epoch: 0 [491008/620022]    Loss: 0.007719   Batch Acc: 82.81
[Train] Epoch: 0 [491072/620022]    Loss: 0.008953   Batch Acc: 81.25
[Train] Epoch: 0 [491136/620022]    Loss: 0.008911   Batch Acc: 79.69
[Train] Epoch: 0 [491200/620022]    Loss: 0.008867   Batch Acc: 79.69
[Train] Epoch: 0 [491264/620022]    Loss: 0.008577   Batch Acc: 76.56
[Train] Epoch: 0 [491328/620022]    Loss: 0.007526   Batch Acc: 78.12
[Train] Epoch: 0 [491392/620022]    Loss: 0.007268   Batch Acc: 82.81
[Train] Epoch: 0 [491456/620022]    Loss: 0.008970   Batch Acc: 73.44
[Train] Epoch: 0 [491520/620022]    Loss: 0.009926   Batch Acc: 75.00
[Train] Epoch: 0 [491584/620022]    Loss: 0.010532   Batch Acc: 71.88
[Train] Epoch: 0 [491648/620022]    Loss: 0.009188   Batch Acc: 71.88
[Train] Epoch: 0 [491712/620022]    Loss: 0.008861   Batch Acc: 75.00
[Train] Epoch: 0 [491776/620022]    Loss: 0.008315   Batch Acc: 76.56
[Train] Epoch: 0 [491840/620022]    Loss: 0.007500   Batch Acc: 84.38
[Train] Epoch: 0 [491904/620022]    Loss: 0.009823   Batch Acc: 73.44
[Train] Epoch: 0 [491968/620022]    Loss: 0.007009   Batch Acc: 82.81
[Train] Epoch: 0 [492032/620022]    Loss: 0.009313   Batch Acc: 70.31
[Train] Epoch: 0 [492096/620022]    Loss: 0.009700   Batch Acc: 73.44
[Train] Epoch: 0 [492160/620022]    Loss: 0.008064   Batch Acc: 81.25
[Train] Epoch: 0 [492224/620022]    Loss: 0.012854   Batch Acc: 65.62
[Train] Epoch: 0 [492288/620022]    Loss: 0.009278   Batch Acc: 81.25
[Train] Epoch: 0 [492352/620022]    Loss: 0.006711   Batch Acc: 84.38
[Train] Epoch: 0 [492416/620022]    Loss: 0.010736   Batch Acc: 71.88
[Train] Epoch: 0 [492480/620022]    Loss: 0.010874   Batch Acc: 71.88
[Train] Epoch: 0 [492544/620022]    Loss: 0.011125   Batch Acc: 67.19
[Train] Epoch: 0 [492608/620022]    Loss: 0.009381   Batch Acc: 71.88
[Train] Epoch: 0 [492672/620022]    Loss: 0.007797   Batch Acc: 79.69
[Train] Epoch: 0 [492736/620022]    Loss: 0.011767   Batch Acc: 79.69
[Train] Epoch: 0 [492800/620022]    Loss: 0.008004   Batch Acc: 81.25
[Train] Epoch: 0 [492864/620022]    Loss: 0.009929   Batch Acc: 75.00
[Train] Epoch: 0 [492928/620022]    Loss: 0.008445   Batch Acc: 70.31
[Train] Epoch: 0 [492992/620022]    Loss: 0.008574   Batch Acc: 75.00
[Train] Epoch: 0 [493056/620022]    Loss: 0.008300   Batch Acc: 81.25
[Train] Epoch: 0 [493120/620022]    Loss: 0.007444   Batch Acc: 82.81
[Train] Epoch: 0 [493184/620022]    Loss: 0.009790   Batch Acc: 70.31
[Train] Epoch: 0 [493248/620022]    Loss: 0.008183   Batch Acc: 85.94
[Train] Epoch: 0 [493312/620022]    Loss: 0.008341   Batch Acc: 81.25
[Train] Epoch: 0 [493376/620022]    Loss: 0.007288   Batch Acc: 82.81
[Train] Epoch: 0 [493440/620022]    Loss: 0.008339   Batch Acc: 75.00
[Train] Epoch: 0 [493504/620022]    Loss: 0.009886   Batch Acc: 71.88
[Train] Epoch: 0 [493568/620022]    Loss: 0.008482   Batch Acc: 73.44
[Train] Epoch: 0 [493632/620022]    Loss: 0.009252   Batch Acc: 79.69
[Train] Epoch: 0 [493696/620022]    Loss: 0.009712   Batch Acc: 70.31
[Train] Epoch: 0 [493760/620022]    Loss: 0.007565   Batch Acc: 78.12
[Train] Epoch: 0 [493824/620022]    Loss: 0.009841   Batch Acc: 71.88
[Train] Epoch: 0 [493888/620022]    Loss: 0.008798   Batch Acc: 81.25
[Train] Epoch: 0 [493952/620022]    Loss: 0.010293   Batch Acc: 71.88
[Train] Epoch: 0 [494016/620022]    Loss: 0.008557   Batch Acc: 78.12
[Train] Epoch: 0 [494080/620022]    Loss: 0.009388   Batch Acc: 79.69
[Train] Epoch: 0 [494144/620022]    Loss: 0.009932   Batch Acc: 70.31
[Train] Epoch: 0 [494208/620022]    Loss: 0.009337   Batch Acc: 73.44
[Train] Epoch: 0 [494272/620022]    Loss: 0.010330   Batch Acc: 71.88
[Train] Epoch: 0 [494336/620022]    Loss: 0.009743   Batch Acc: 71.88
[Train] Epoch: 0 [494400/620022]    Loss: 0.009075   Batch Acc: 78.12
[Train] Epoch: 0 [494464/620022]    Loss: 0.007204   Batch Acc: 82.81
[Train] Epoch: 0 [494528/620022]    Loss: 0.008288   Batch Acc: 76.56
[Train] Epoch: 0 [494592/620022]    Loss: 0.009832   Batch Acc: 70.31
[Train] Epoch: 0 [494656/620022]    Loss: 0.008542   Batch Acc: 76.56
[Train] Epoch: 0 [494720/620022]    Loss: 0.008640   Batch Acc: 87.50
[Train] Epoch: 0 [494784/620022]    Loss: 0.010514   Batch Acc: 71.88
[Train] Epoch: 0 [494848/620022]    Loss: 0.010957   Batch Acc: 73.44
[Train] Epoch: 0 [494912/620022]    Loss: 0.007505   Batch Acc: 84.38
[Train] Epoch: 0 [494976/620022]    Loss: 0.009451   Batch Acc: 71.88
[Train] Epoch: 0 [495040/620022]    Loss: 0.009518   Batch Acc: 75.00
[Train] Epoch: 0 [495104/620022]    Loss: 0.008986   Batch Acc: 71.88
[Train] Epoch: 0 [495168/620022]    Loss: 0.008522   Batch Acc: 78.12
[Train] Epoch: 0 [495232/620022]    Loss: 0.007888   Batch Acc: 81.25
[Train] Epoch: 0 [495296/620022]    Loss: 0.008040   Batch Acc: 79.69
[Train] Epoch: 0 [495360/620022]    Loss: 0.008445   Batch Acc: 78.12
[Train] Epoch: 0 [495424/620022]    Loss: 0.008989   Batch Acc: 76.56
[Train] Epoch: 0 [495488/620022]    Loss: 0.009529   Batch Acc: 78.12
[Train] Epoch: 0 [495552/620022]    Loss: 0.008055   Batch Acc: 79.69
[Train] Epoch: 0 [495616/620022]    Loss: 0.009393   Batch Acc: 68.75
[Train] Epoch: 0 [495680/620022]    Loss: 0.008903   Batch Acc: 82.81
[Train] Epoch: 0 [495744/620022]    Loss: 0.008405   Batch Acc: 85.94
[Train] Epoch: 0 [495808/620022]    Loss: 0.008560   Batch Acc: 79.69
[Train] Epoch: 0 [495872/620022]    Loss: 0.006861   Batch Acc: 84.38
[Train] Epoch: 0 [495936/620022]    Loss: 0.007825   Batch Acc: 78.12
[Train] Epoch: 0 [496000/620022]    Loss: 0.009090   Batch Acc: 75.00
[Train] Epoch: 0 [496064/620022]    Loss: 0.007841   Batch Acc: 85.94
[Train] Epoch: 0 [496128/620022]    Loss: 0.009710   Batch Acc: 73.44
[Train] Epoch: 0 [496192/620022]    Loss: 0.007878   Batch Acc: 82.81
[Train] Epoch: 0 [496256/620022]    Loss: 0.006637   Batch Acc: 89.06
[Train] Epoch: 0 [496320/620022]    Loss: 0.009816   Batch Acc: 78.12
[Train] Epoch: 0 [496384/620022]    Loss: 0.010135   Batch Acc: 75.00
[Train] Epoch: 0 [496448/620022]    Loss: 0.009798   Batch Acc: 73.44
[Train] Epoch: 0 [496512/620022]    Loss: 0.008655   Batch Acc: 81.25
[Train] Epoch: 0 [496576/620022]    Loss: 0.007863   Batch Acc: 76.56
[Train] Epoch: 0 [496640/620022]    Loss: 0.009552   Batch Acc: 76.56
[Train] Epoch: 0 [496704/620022]    Loss: 0.007271   Batch Acc: 81.25
[Train] Epoch: 0 [496768/620022]    Loss: 0.006733   Batch Acc: 89.06
[Train] Epoch: 0 [496832/620022]    Loss: 0.007501   Batch Acc: 82.81
[Train] Epoch: 0 [496896/620022]    Loss: 0.010017   Batch Acc: 78.12
[Train] Epoch: 0 [496960/620022]    Loss: 0.008185   Batch Acc: 82.81
[Train] Epoch: 0 [497024/620022]    Loss: 0.009166   Batch Acc: 76.56
[Train] Epoch: 0 [497088/620022]    Loss: 0.008254   Batch Acc: 75.00
[Train] Epoch: 0 [497152/620022]    Loss: 0.011723   Batch Acc: 70.31
[Train] Epoch: 0 [497216/620022]    Loss: 0.009957   Batch Acc: 71.88
[Train] Epoch: 0 [497280/620022]    Loss: 0.008793   Batch Acc: 70.31
[Train] Epoch: 0 [497344/620022]    Loss: 0.009529   Batch Acc: 71.88
[Train] Epoch: 0 [497408/620022]    Loss: 0.010760   Batch Acc: 73.44
[Train] Epoch: 0 [497472/620022]    Loss: 0.009645   Batch Acc: 73.44
[Train] Epoch: 0 [497536/620022]    Loss: 0.008081   Batch Acc: 82.81
[Train] Epoch: 0 [497600/620022]    Loss: 0.010042   Batch Acc: 75.00
[Train] Epoch: 0 [497664/620022]    Loss: 0.008743   Batch Acc: 78.12
[Train] Epoch: 0 [497728/620022]    Loss: 0.009146   Batch Acc: 79.69
[Train] Epoch: 0 [497792/620022]    Loss: 0.008863   Batch Acc: 81.25
[Train] Epoch: 0 [497856/620022]    Loss: 0.006654   Batch Acc: 84.38
[Train] Epoch: 0 [497920/620022]    Loss: 0.006439   Batch Acc: 82.81
[Train] Epoch: 0 [497984/620022]    Loss: 0.009211   Batch Acc: 78.12
[Train] Epoch: 0 [498048/620022]    Loss: 0.009895   Batch Acc: 78.12
[Train] Epoch: 0 [498112/620022]    Loss: 0.007023   Batch Acc: 84.38
[Train] Epoch: 0 [498176/620022]    Loss: 0.007759   Batch Acc: 87.50
[Train] Epoch: 0 [498240/620022]    Loss: 0.008093   Batch Acc: 84.38
[Train] Epoch: 0 [498304/620022]    Loss: 0.007954   Batch Acc: 79.69
[Train] Epoch: 0 [498368/620022]    Loss: 0.007294   Batch Acc: 81.25
[Train] Epoch: 0 [498432/620022]    Loss: 0.008863   Batch Acc: 70.31
[Train] Epoch: 0 [498496/620022]    Loss: 0.010651   Batch Acc: 70.31
[Train] Epoch: 0 [498560/620022]    Loss: 0.009825   Batch Acc: 70.31
[Train] Epoch: 0 [498624/620022]    Loss: 0.009190   Batch Acc: 75.00
[Train] Epoch: 0 [498688/620022]    Loss: 0.009639   Batch Acc: 68.75
[Train] Epoch: 0 [498752/620022]    Loss: 0.010093   Batch Acc: 75.00
[Train] Epoch: 0 [498816/620022]    Loss: 0.009284   Batch Acc: 73.44
[Train] Epoch: 0 [498880/620022]    Loss: 0.009809   Batch Acc: 73.44
[Train] Epoch: 0 [498944/620022]    Loss: 0.006002   Batch Acc: 84.38
[Train] Epoch: 0 [499008/620022]    Loss: 0.007451   Batch Acc: 84.38
[Train] Epoch: 0 [499072/620022]    Loss: 0.009708   Batch Acc: 76.56
[Train] Epoch: 0 [499136/620022]    Loss: 0.007821   Batch Acc: 79.69
[Train] Epoch: 0 [499200/620022]    Loss: 0.009358   Batch Acc: 71.88
[Train] Epoch: 0 [499264/620022]    Loss: 0.009764   Batch Acc: 76.56
[Train] Epoch: 0 [499328/620022]    Loss: 0.010854   Batch Acc: 73.44
[Train] Epoch: 0 [499392/620022]    Loss: 0.009334   Batch Acc: 75.00
[Train] Epoch: 0 [499456/620022]    Loss: 0.007956   Batch Acc: 79.69
[Train] Epoch: 0 [499520/620022]    Loss: 0.011557   Batch Acc: 67.19
[Train] Epoch: 0 [499584/620022]    Loss: 0.008354   Batch Acc: 76.56
[Train] Epoch: 0 [499648/620022]    Loss: 0.008149   Batch Acc: 75.00
[Train] Epoch: 0 [499712/620022]    Loss: 0.009695   Batch Acc: 76.56
[Train] Epoch: 0 [499776/620022]    Loss: 0.007407   Batch Acc: 89.06
[Train] Epoch: 0 [499840/620022]    Loss: 0.010689   Batch Acc: 65.62
[Train] Epoch: 0 [499904/620022]    Loss: 0.008451   Batch Acc: 78.12
[Train] Epoch: 0 [499968/620022]    Loss: 0.007576   Batch Acc: 82.81
[Train] Epoch: 0 [500032/620022]    Loss: 0.007384   Batch Acc: 81.25
[Train] Epoch: 0 [500096/620022]    Loss: 0.005957   Batch Acc: 82.81
[Train] Epoch: 0 [500160/620022]    Loss: 0.010970   Batch Acc: 73.44
[Train] Epoch: 0 [500224/620022]    Loss: 0.008601   Batch Acc: 71.88
[Train] Epoch: 0 [500288/620022]    Loss: 0.010406   Batch Acc: 70.31
[Train] Epoch: 0 [500352/620022]    Loss: 0.008844   Batch Acc: 76.56
[Train] Epoch: 0 [500416/620022]    Loss: 0.008311   Batch Acc: 76.56
[Train] Epoch: 0 [500480/620022]    Loss: 0.008799   Batch Acc: 85.94
[Train] Epoch: 0 [500544/620022]    Loss: 0.007015   Batch Acc: 84.38
[Train] Epoch: 0 [500608/620022]    Loss: 0.009082   Batch Acc: 76.56
[Train] Epoch: 0 [500672/620022]    Loss: 0.009651   Batch Acc: 70.31
[Train] Epoch: 0 [500736/620022]    Loss: 0.006467   Batch Acc: 82.81
[Train] Epoch: 0 [500800/620022]    Loss: 0.011113   Batch Acc: 73.44
[Train] Epoch: 0 [500864/620022]    Loss: 0.009600   Batch Acc: 76.56
[Train] Epoch: 0 [500928/620022]    Loss: 0.007293   Batch Acc: 81.25
[Train] Epoch: 0 [500992/620022]    Loss: 0.009128   Batch Acc: 71.88
[Train] Epoch: 0 [501056/620022]    Loss: 0.010011   Batch Acc: 73.44
[Train] Epoch: 0 [501120/620022]    Loss: 0.007387   Batch Acc: 84.38
[Train] Epoch: 0 [501184/620022]    Loss: 0.009785   Batch Acc: 75.00
[Train] Epoch: 0 [501248/620022]    Loss: 0.007905   Batch Acc: 78.12
[Train] Epoch: 0 [501312/620022]    Loss: 0.007961   Batch Acc: 79.69
[Train] Epoch: 0 [501376/620022]    Loss: 0.008208   Batch Acc: 85.94
[Train] Epoch: 0 [501440/620022]    Loss: 0.008590   Batch Acc: 75.00
[Train] Epoch: 0 [501504/620022]    Loss: 0.009138   Batch Acc: 84.38
[Train] Epoch: 0 [501568/620022]    Loss: 0.007304   Batch Acc: 81.25
[Train] Epoch: 0 [501632/620022]    Loss: 0.007486   Batch Acc: 82.81
[Train] Epoch: 0 [501696/620022]    Loss: 0.007891   Batch Acc: 79.69
[Train] Epoch: 0 [501760/620022]    Loss: 0.009919   Batch Acc: 71.88
[Train] Epoch: 0 [501824/620022]    Loss: 0.007857   Batch Acc: 78.12
[Train] Epoch: 0 [501888/620022]    Loss: 0.008900   Batch Acc: 73.44
[Train] Epoch: 0 [501952/620022]    Loss: 0.007442   Batch Acc: 73.44
[Train] Epoch: 0 [502016/620022]    Loss: 0.010668   Batch Acc: 70.31
[Train] Epoch: 0 [502080/620022]    Loss: 0.008411   Batch Acc: 76.56
[Train] Epoch: 0 [502144/620022]    Loss: 0.011993   Batch Acc: 64.06
[Train] Epoch: 0 [502208/620022]    Loss: 0.010143   Batch Acc: 75.00
[Train] Epoch: 0 [502272/620022]    Loss: 0.008860   Batch Acc: 79.69
[Train] Epoch: 0 [502336/620022]    Loss: 0.009456   Batch Acc: 73.44
[Train] Epoch: 0 [502400/620022]    Loss: 0.010781   Batch Acc: 65.62
[Train] Epoch: 0 [502464/620022]    Loss: 0.007693   Batch Acc: 79.69
[Train] Epoch: 0 [502528/620022]    Loss: 0.009986   Batch Acc: 73.44
[Train] Epoch: 0 [502592/620022]    Loss: 0.008498   Batch Acc: 79.69
[Train] Epoch: 0 [502656/620022]    Loss: 0.009534   Batch Acc: 73.44
[Train] Epoch: 0 [502720/620022]    Loss: 0.008683   Batch Acc: 75.00
[Train] Epoch: 0 [502784/620022]    Loss: 0.010767   Batch Acc: 70.31
[Train] Epoch: 0 [502848/620022]    Loss: 0.010394   Batch Acc: 68.75
[Train] Epoch: 0 [502912/620022]    Loss: 0.007955   Batch Acc: 81.25
[Train] Epoch: 0 [502976/620022]    Loss: 0.008755   Batch Acc: 81.25
[Train] Epoch: 0 [503040/620022]    Loss: 0.009035   Batch Acc: 75.00
[Train] Epoch: 0 [503104/620022]    Loss: 0.008594   Batch Acc: 76.56
[Train] Epoch: 0 [503168/620022]    Loss: 0.009432   Batch Acc: 75.00
[Train] Epoch: 0 [503232/620022]    Loss: 0.007687   Batch Acc: 78.12
[Train] Epoch: 0 [503296/620022]    Loss: 0.009068   Batch Acc: 84.38
[Train] Epoch: 0 [503360/620022]    Loss: 0.008649   Batch Acc: 75.00
[Train] Epoch: 0 [503424/620022]    Loss: 0.011857   Batch Acc: 67.19
[Train] Epoch: 0 [503488/620022]    Loss: 0.012633   Batch Acc: 62.50
[Train] Epoch: 0 [503552/620022]    Loss: 0.008982   Batch Acc: 76.56
[Train] Epoch: 0 [503616/620022]    Loss: 0.007096   Batch Acc: 81.25
[Train] Epoch: 0 [503680/620022]    Loss: 0.008666   Batch Acc: 81.25
[Train] Epoch: 0 [503744/620022]    Loss: 0.008940   Batch Acc: 76.56
[Train] Epoch: 0 [503808/620022]    Loss: 0.006340   Batch Acc: 81.25
[Train] Epoch: 0 [503872/620022]    Loss: 0.008772   Batch Acc: 81.25
[Train] Epoch: 0 [503936/620022]    Loss: 0.009204   Batch Acc: 78.12
[Train] Epoch: 0 [504000/620022]    Loss: 0.011899   Batch Acc: 71.88
[Train] Epoch: 0 [504064/620022]    Loss: 0.009482   Batch Acc: 70.31
[Train] Epoch: 0 [504128/620022]    Loss: 0.008855   Batch Acc: 78.12
[Train] Epoch: 0 [504192/620022]    Loss: 0.009532   Batch Acc: 76.56
[Train] Epoch: 0 [504256/620022]    Loss: 0.009707   Batch Acc: 78.12
[Train] Epoch: 0 [504320/620022]    Loss: 0.006981   Batch Acc: 87.50
[Train] Epoch: 0 [504384/620022]    Loss: 0.010365   Batch Acc: 78.12
[Train] Epoch: 0 [504448/620022]    Loss: 0.009011   Batch Acc: 78.12
[Train] Epoch: 0 [504512/620022]    Loss: 0.008661   Batch Acc: 79.69
[Train] Epoch: 0 [504576/620022]    Loss: 0.008031   Batch Acc: 81.25
[Train] Epoch: 0 [504640/620022]    Loss: 0.009926   Batch Acc: 71.88
[Train] Epoch: 0 [504704/620022]    Loss: 0.009039   Batch Acc: 79.69
[Train] Epoch: 0 [504768/620022]    Loss: 0.007793   Batch Acc: 81.25
[Train] Epoch: 0 [504832/620022]    Loss: 0.007715   Batch Acc: 81.25
[Train] Epoch: 0 [504896/620022]    Loss: 0.006933   Batch Acc: 81.25
[Train] Epoch: 0 [504960/620022]    Loss: 0.009679   Batch Acc: 76.56
[Train] Epoch: 0 [505024/620022]    Loss: 0.008293   Batch Acc: 75.00
[Train] Epoch: 0 [505088/620022]    Loss: 0.009241   Batch Acc: 75.00
[Train] Epoch: 0 [505152/620022]    Loss: 0.009336   Batch Acc: 71.88
[Train] Epoch: 0 [505216/620022]    Loss: 0.010151   Batch Acc: 73.44
[Train] Epoch: 0 [505280/620022]    Loss: 0.008230   Batch Acc: 78.12
[Train] Epoch: 0 [505344/620022]    Loss: 0.008221   Batch Acc: 76.56
[Train] Epoch: 0 [505408/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 0 [505472/620022]    Loss: 0.007424   Batch Acc: 84.38
[Train] Epoch: 0 [505536/620022]    Loss: 0.007949   Batch Acc: 81.25
[Train] Epoch: 0 [505600/620022]    Loss: 0.007619   Batch Acc: 79.69
[Train] Epoch: 0 [505664/620022]    Loss: 0.009391   Batch Acc: 71.88
[Train] Epoch: 0 [505728/620022]    Loss: 0.011117   Batch Acc: 70.31
[Train] Epoch: 0 [505792/620022]    Loss: 0.010534   Batch Acc: 75.00
[Train] Epoch: 0 [505856/620022]    Loss: 0.008729   Batch Acc: 81.25
[Train] Epoch: 0 [505920/620022]    Loss: 0.009238   Batch Acc: 76.56
[Train] Epoch: 0 [505984/620022]    Loss: 0.009754   Batch Acc: 79.69
[Train] Epoch: 0 [506048/620022]    Loss: 0.007782   Batch Acc: 82.81
[Train] Epoch: 0 [506112/620022]    Loss: 0.008797   Batch Acc: 79.69
[Train] Epoch: 0 [506176/620022]    Loss: 0.008364   Batch Acc: 76.56
[Train] Epoch: 0 [506240/620022]    Loss: 0.009272   Batch Acc: 78.12
[Train] Epoch: 0 [506304/620022]    Loss: 0.006381   Batch Acc: 87.50
[Train] Epoch: 0 [506368/620022]    Loss: 0.008567   Batch Acc: 78.12
[Train] Epoch: 0 [506432/620022]    Loss: 0.010563   Batch Acc: 70.31
[Train] Epoch: 0 [506496/620022]    Loss: 0.008359   Batch Acc: 79.69
[Train] Epoch: 0 [506560/620022]    Loss: 0.007882   Batch Acc: 84.38
[Train] Epoch: 0 [506624/620022]    Loss: 0.008790   Batch Acc: 78.12
[Train] Epoch: 0 [506688/620022]    Loss: 0.010018   Batch Acc: 75.00
[Train] Epoch: 0 [506752/620022]    Loss: 0.010827   Batch Acc: 70.31
[Train] Epoch: 0 [506816/620022]    Loss: 0.008771   Batch Acc: 75.00
[Train] Epoch: 0 [506880/620022]    Loss: 0.011796   Batch Acc: 70.31
[Train] Epoch: 0 [506944/620022]    Loss: 0.008466   Batch Acc: 78.12
[Train] Epoch: 0 [507008/620022]    Loss: 0.007704   Batch Acc: 79.69
[Train] Epoch: 0 [507072/620022]    Loss: 0.009848   Batch Acc: 76.56
[Train] Epoch: 0 [507136/620022]    Loss: 0.010511   Batch Acc: 70.31
[Train] Epoch: 0 [507200/620022]    Loss: 0.008254   Batch Acc: 81.25
[Train] Epoch: 0 [507264/620022]    Loss: 0.008058   Batch Acc: 79.69
[Train] Epoch: 0 [507328/620022]    Loss: 0.009018   Batch Acc: 73.44
[Train] Epoch: 0 [507392/620022]    Loss: 0.007958   Batch Acc: 78.12
[Train] Epoch: 0 [507456/620022]    Loss: 0.010331   Batch Acc: 75.00
[Train] Epoch: 0 [507520/620022]    Loss: 0.006736   Batch Acc: 85.94
[Train] Epoch: 0 [507584/620022]    Loss: 0.006799   Batch Acc: 81.25
[Train] Epoch: 0 [507648/620022]    Loss: 0.010467   Batch Acc: 64.06
[Train] Epoch: 0 [507712/620022]    Loss: 0.011654   Batch Acc: 64.06
[Train] Epoch: 0 [507776/620022]    Loss: 0.008915   Batch Acc: 73.44
[Train] Epoch: 0 [507840/620022]    Loss: 0.009667   Batch Acc: 79.69
[Train] Epoch: 0 [507904/620022]    Loss: 0.010307   Batch Acc: 71.88
[Train] Epoch: 0 [507968/620022]    Loss: 0.009310   Batch Acc: 75.00
[Train] Epoch: 0 [508032/620022]    Loss: 0.010610   Batch Acc: 75.00
[Train] Epoch: 0 [508096/620022]    Loss: 0.008900   Batch Acc: 76.56
[Train] Epoch: 0 [508160/620022]    Loss: 0.008874   Batch Acc: 73.44
[Train] Epoch: 0 [508224/620022]    Loss: 0.006797   Batch Acc: 89.06
[Train] Epoch: 0 [508288/620022]    Loss: 0.008644   Batch Acc: 75.00
[Train] Epoch: 0 [508352/620022]    Loss: 0.010690   Batch Acc: 70.31
[Train] Epoch: 0 [508416/620022]    Loss: 0.010771   Batch Acc: 65.62
[Train] Epoch: 0 [508480/620022]    Loss: 0.007708   Batch Acc: 78.12
[Train] Epoch: 0 [508544/620022]    Loss: 0.009369   Batch Acc: 75.00
[Train] Epoch: 0 [508608/620022]    Loss: 0.009221   Batch Acc: 75.00
[Train] Epoch: 0 [508672/620022]    Loss: 0.011640   Batch Acc: 62.50
[Train] Epoch: 0 [508736/620022]    Loss: 0.008541   Batch Acc: 79.69
[Train] Epoch: 0 [508800/620022]    Loss: 0.007814   Batch Acc: 82.81
[Train] Epoch: 0 [508864/620022]    Loss: 0.010136   Batch Acc: 75.00
[Train] Epoch: 0 [508928/620022]    Loss: 0.008634   Batch Acc: 79.69
[Train] Epoch: 0 [508992/620022]    Loss: 0.008775   Batch Acc: 76.56
[Train] Epoch: 0 [509056/620022]    Loss: 0.009724   Batch Acc: 75.00
[Train] Epoch: 0 [509120/620022]    Loss: 0.009341   Batch Acc: 71.88
[Train] Epoch: 0 [509184/620022]    Loss: 0.008692   Batch Acc: 79.69
[Train] Epoch: 0 [509248/620022]    Loss: 0.006479   Batch Acc: 84.38
[Train] Epoch: 0 [509312/620022]    Loss: 0.010348   Batch Acc: 75.00
[Train] Epoch: 0 [509376/620022]    Loss: 0.010232   Batch Acc: 67.19
[Train] Epoch: 0 [509440/620022]    Loss: 0.010834   Batch Acc: 71.88
[Train] Epoch: 0 [509504/620022]    Loss: 0.009244   Batch Acc: 73.44
[Train] Epoch: 0 [509568/620022]    Loss: 0.009314   Batch Acc: 78.12
[Train] Epoch: 0 [509632/620022]    Loss: 0.008776   Batch Acc: 81.25
[Train] Epoch: 0 [509696/620022]    Loss: 0.009575   Batch Acc: 73.44
[Train] Epoch: 0 [509760/620022]    Loss: 0.009149   Batch Acc: 79.69
[Train] Epoch: 0 [509824/620022]    Loss: 0.008236   Batch Acc: 76.56
[Train] Epoch: 0 [509888/620022]    Loss: 0.009193   Batch Acc: 73.44
[Train] Epoch: 0 [509952/620022]    Loss: 0.007456   Batch Acc: 79.69
[Train] Epoch: 0 [510016/620022]    Loss: 0.007673   Batch Acc: 79.69
[Train] Epoch: 0 [510080/620022]    Loss: 0.008212   Batch Acc: 81.25
[Train] Epoch: 0 [510144/620022]    Loss: 0.009249   Batch Acc: 76.56
[Train] Epoch: 0 [510208/620022]    Loss: 0.007424   Batch Acc: 79.69
[Train] Epoch: 0 [510272/620022]    Loss: 0.008399   Batch Acc: 76.56
[Train] Epoch: 0 [510336/620022]    Loss: 0.007707   Batch Acc: 78.12
[Train] Epoch: 0 [510400/620022]    Loss: 0.008029   Batch Acc: 81.25
[Train] Epoch: 0 [510464/620022]    Loss: 0.009464   Batch Acc: 76.56
[Train] Epoch: 0 [510528/620022]    Loss: 0.010045   Batch Acc: 71.88
[Train] Epoch: 0 [510592/620022]    Loss: 0.008238   Batch Acc: 82.81
[Train] Epoch: 0 [510656/620022]    Loss: 0.009523   Batch Acc: 75.00
[Train] Epoch: 0 [510720/620022]    Loss: 0.008403   Batch Acc: 84.38
[Train] Epoch: 0 [510784/620022]    Loss: 0.008460   Batch Acc: 76.56
[Train] Epoch: 0 [510848/620022]    Loss: 0.010631   Batch Acc: 75.00
[Train] Epoch: 0 [510912/620022]    Loss: 0.007515   Batch Acc: 84.38
[Train] Epoch: 0 [510976/620022]    Loss: 0.008889   Batch Acc: 82.81
[Train] Epoch: 0 [511040/620022]    Loss: 0.007379   Batch Acc: 84.38
[Train] Epoch: 0 [511104/620022]    Loss: 0.009142   Batch Acc: 81.25
[Train] Epoch: 0 [511168/620022]    Loss: 0.008038   Batch Acc: 78.12
[Train] Epoch: 0 [511232/620022]    Loss: 0.010041   Batch Acc: 70.31
[Train] Epoch: 0 [511296/620022]    Loss: 0.009094   Batch Acc: 82.81
[Train] Epoch: 0 [511360/620022]    Loss: 0.008611   Batch Acc: 75.00
[Train] Epoch: 0 [511424/620022]    Loss: 0.008427   Batch Acc: 76.56
[Train] Epoch: 0 [511488/620022]    Loss: 0.009302   Batch Acc: 71.88
[Train] Epoch: 0 [511552/620022]    Loss: 0.009769   Batch Acc: 73.44
[Train] Epoch: 0 [511616/620022]    Loss: 0.008569   Batch Acc: 79.69
[Train] Epoch: 0 [511680/620022]    Loss: 0.008405   Batch Acc: 81.25
[Train] Epoch: 0 [511744/620022]    Loss: 0.009440   Batch Acc: 76.56
[Train] Epoch: 0 [511808/620022]    Loss: 0.009112   Batch Acc: 78.12
[Train] Epoch: 0 [511872/620022]    Loss: 0.009568   Batch Acc: 71.88
[Train] Epoch: 0 [511936/620022]    Loss: 0.010997   Batch Acc: 71.88
[Train] Epoch: 0 [512000/620022]    Loss: 0.008574   Batch Acc: 78.12
[Train] Epoch: 0 [512064/620022]    Loss: 0.008240   Batch Acc: 85.94
[Train] Epoch: 0 [512128/620022]    Loss: 0.008672   Batch Acc: 79.69
[Train] Epoch: 0 [512192/620022]    Loss: 0.011662   Batch Acc: 73.44
[Train] Epoch: 0 [512256/620022]    Loss: 0.009866   Batch Acc: 75.00
[Train] Epoch: 0 [512320/620022]    Loss: 0.009379   Batch Acc: 76.56
[Train] Epoch: 0 [512384/620022]    Loss: 0.008746   Batch Acc: 75.00
[Train] Epoch: 0 [512448/620022]    Loss: 0.006458   Batch Acc: 85.94
[Train] Epoch: 0 [512512/620022]    Loss: 0.007158   Batch Acc: 85.94
[Train] Epoch: 0 [512576/620022]    Loss: 0.007946   Batch Acc: 82.81
[Train] Epoch: 0 [512640/620022]    Loss: 0.008735   Batch Acc: 75.00
[Train] Epoch: 0 [512704/620022]    Loss: 0.010390   Batch Acc: 71.88
[Train] Epoch: 0 [512768/620022]    Loss: 0.010625   Batch Acc: 67.19
[Train] Epoch: 0 [512832/620022]    Loss: 0.008326   Batch Acc: 78.12
[Train] Epoch: 0 [512896/620022]    Loss: 0.008671   Batch Acc: 75.00
[Train] Epoch: 0 [512960/620022]    Loss: 0.009594   Batch Acc: 75.00
[Train] Epoch: 0 [513024/620022]    Loss: 0.010087   Batch Acc: 73.44
[Train] Epoch: 0 [513088/620022]    Loss: 0.009073   Batch Acc: 81.25
[Train] Epoch: 0 [513152/620022]    Loss: 0.010728   Batch Acc: 73.44
[Train] Epoch: 0 [513216/620022]    Loss: 0.009009   Batch Acc: 81.25
[Train] Epoch: 0 [513280/620022]    Loss: 0.010123   Batch Acc: 75.00
[Train] Epoch: 0 [513344/620022]    Loss: 0.008210   Batch Acc: 75.00
[Train] Epoch: 0 [513408/620022]    Loss: 0.009236   Batch Acc: 73.44
[Train] Epoch: 0 [513472/620022]    Loss: 0.010564   Batch Acc: 78.12
[Train] Epoch: 0 [513536/620022]    Loss: 0.008148   Batch Acc: 81.25
[Train] Epoch: 0 [513600/620022]    Loss: 0.006799   Batch Acc: 82.81
[Train] Epoch: 0 [513664/620022]    Loss: 0.008115   Batch Acc: 79.69
[Train] Epoch: 0 [513728/620022]    Loss: 0.008450   Batch Acc: 75.00
[Train] Epoch: 0 [513792/620022]    Loss: 0.006718   Batch Acc: 79.69
[Train] Epoch: 0 [513856/620022]    Loss: 0.010877   Batch Acc: 68.75
[Train] Epoch: 0 [513920/620022]    Loss: 0.008050   Batch Acc: 79.69
[Train] Epoch: 0 [513984/620022]    Loss: 0.008883   Batch Acc: 81.25
[Train] Epoch: 0 [514048/620022]    Loss: 0.008649   Batch Acc: 76.56
[Train] Epoch: 0 [514112/620022]    Loss: 0.009886   Batch Acc: 73.44
[Train] Epoch: 0 [514176/620022]    Loss: 0.010131   Batch Acc: 73.44
[Train] Epoch: 0 [514240/620022]    Loss: 0.010068   Batch Acc: 76.56
[Train] Epoch: 0 [514304/620022]    Loss: 0.008754   Batch Acc: 76.56
[Train] Epoch: 0 [514368/620022]    Loss: 0.006249   Batch Acc: 89.06
[Train] Epoch: 0 [514432/620022]    Loss: 0.008130   Batch Acc: 81.25
[Train] Epoch: 0 [514496/620022]    Loss: 0.009146   Batch Acc: 79.69
[Train] Epoch: 0 [514560/620022]    Loss: 0.010759   Batch Acc: 67.19
[Train] Epoch: 0 [514624/620022]    Loss: 0.008189   Batch Acc: 79.69
[Train] Epoch: 0 [514688/620022]    Loss: 0.008890   Batch Acc: 79.69
[Train] Epoch: 0 [514752/620022]    Loss: 0.009153   Batch Acc: 75.00
[Train] Epoch: 0 [514816/620022]    Loss: 0.007576   Batch Acc: 79.69
[Train] Epoch: 0 [514880/620022]    Loss: 0.010515   Batch Acc: 68.75
[Train] Epoch: 0 [514944/620022]    Loss: 0.008104   Batch Acc: 79.69
[Train] Epoch: 0 [515008/620022]    Loss: 0.011837   Batch Acc: 68.75
[Train] Epoch: 0 [515072/620022]    Loss: 0.009278   Batch Acc: 81.25
[Train] Epoch: 0 [515136/620022]    Loss: 0.008895   Batch Acc: 78.12
[Train] Epoch: 0 [515200/620022]    Loss: 0.009223   Batch Acc: 81.25
[Train] Epoch: 0 [515264/620022]    Loss: 0.011544   Batch Acc: 75.00
[Train] Epoch: 0 [515328/620022]    Loss: 0.008879   Batch Acc: 81.25
[Train] Epoch: 0 [515392/620022]    Loss: 0.011041   Batch Acc: 73.44
[Train] Epoch: 0 [515456/620022]    Loss: 0.008531   Batch Acc: 78.12
[Train] Epoch: 0 [515520/620022]    Loss: 0.010022   Batch Acc: 71.88
[Train] Epoch: 0 [515584/620022]    Loss: 0.010854   Batch Acc: 68.75
[Train] Epoch: 0 [515648/620022]    Loss: 0.009178   Batch Acc: 73.44
[Train] Epoch: 0 [515712/620022]    Loss: 0.009333   Batch Acc: 75.00
[Train] Epoch: 0 [515776/620022]    Loss: 0.007558   Batch Acc: 81.25
[Train] Epoch: 0 [515840/620022]    Loss: 0.008677   Batch Acc: 75.00
[Train] Epoch: 0 [515904/620022]    Loss: 0.007286   Batch Acc: 85.94
[Train] Epoch: 0 [515968/620022]    Loss: 0.008027   Batch Acc: 76.56
[Train] Epoch: 0 [516032/620022]    Loss: 0.008951   Batch Acc: 78.12
[Train] Epoch: 0 [516096/620022]    Loss: 0.009806   Batch Acc: 73.44
[Train] Epoch: 0 [516160/620022]    Loss: 0.009816   Batch Acc: 73.44
[Train] Epoch: 0 [516224/620022]    Loss: 0.009588   Batch Acc: 81.25
[Train] Epoch: 0 [516288/620022]    Loss: 0.010361   Batch Acc: 68.75
[Train] Epoch: 0 [516352/620022]    Loss: 0.010191   Batch Acc: 71.88
[Train] Epoch: 0 [516416/620022]    Loss: 0.008364   Batch Acc: 81.25
[Train] Epoch: 0 [516480/620022]    Loss: 0.010429   Batch Acc: 71.88
[Train] Epoch: 0 [516544/620022]    Loss: 0.011043   Batch Acc: 67.19
[Train] Epoch: 0 [516608/620022]    Loss: 0.008345   Batch Acc: 76.56
[Train] Epoch: 0 [516672/620022]    Loss: 0.009132   Batch Acc: 73.44
[Train] Epoch: 0 [516736/620022]    Loss: 0.007971   Batch Acc: 75.00
[Train] Epoch: 0 [516800/620022]    Loss: 0.008953   Batch Acc: 75.00
[Train] Epoch: 0 [516864/620022]    Loss: 0.008561   Batch Acc: 82.81
[Train] Epoch: 0 [516928/620022]    Loss: 0.008458   Batch Acc: 75.00
[Train] Epoch: 0 [516992/620022]    Loss: 0.008521   Batch Acc: 81.25
[Train] Epoch: 0 [517056/620022]    Loss: 0.006280   Batch Acc: 87.50
[Train] Epoch: 0 [517120/620022]    Loss: 0.009905   Batch Acc: 75.00
[Train] Epoch: 0 [517184/620022]    Loss: 0.008578   Batch Acc: 75.00
[Train] Epoch: 0 [517248/620022]    Loss: 0.007590   Batch Acc: 78.12
[Train] Epoch: 0 [517312/620022]    Loss: 0.010876   Batch Acc: 79.69
[Train] Epoch: 0 [517376/620022]    Loss: 0.008308   Batch Acc: 75.00
[Train] Epoch: 0 [517440/620022]    Loss: 0.008646   Batch Acc: 78.12
[Train] Epoch: 0 [517504/620022]    Loss: 0.007475   Batch Acc: 79.69
[Train] Epoch: 0 [517568/620022]    Loss: 0.006788   Batch Acc: 84.38
[Train] Epoch: 0 [517632/620022]    Loss: 0.008649   Batch Acc: 81.25
[Train] Epoch: 0 [517696/620022]    Loss: 0.006985   Batch Acc: 85.94
[Train] Epoch: 0 [517760/620022]    Loss: 0.006792   Batch Acc: 82.81
[Train] Epoch: 0 [517824/620022]    Loss: 0.008518   Batch Acc: 76.56
[Train] Epoch: 0 [517888/620022]    Loss: 0.008654   Batch Acc: 81.25
[Train] Epoch: 0 [517952/620022]    Loss: 0.007812   Batch Acc: 81.25
[Train] Epoch: 0 [518016/620022]    Loss: 0.009066   Batch Acc: 71.88
[Train] Epoch: 0 [518080/620022]    Loss: 0.006986   Batch Acc: 84.38
[Train] Epoch: 0 [518144/620022]    Loss: 0.010735   Batch Acc: 68.75
[Train] Epoch: 0 [518208/620022]    Loss: 0.006391   Batch Acc: 84.38
[Train] Epoch: 0 [518272/620022]    Loss: 0.007399   Batch Acc: 81.25
[Train] Epoch: 0 [518336/620022]    Loss: 0.006943   Batch Acc: 82.81
[Train] Epoch: 0 [518400/620022]    Loss: 0.007634   Batch Acc: 82.81
[Train] Epoch: 0 [518464/620022]    Loss: 0.009078   Batch Acc: 78.12
[Train] Epoch: 0 [518528/620022]    Loss: 0.010334   Batch Acc: 76.56
[Train] Epoch: 0 [518592/620022]    Loss: 0.010136   Batch Acc: 76.56
[Train] Epoch: 0 [518656/620022]    Loss: 0.007608   Batch Acc: 81.25
[Train] Epoch: 0 [518720/620022]    Loss: 0.010025   Batch Acc: 71.88
[Train] Epoch: 0 [518784/620022]    Loss: 0.010257   Batch Acc: 73.44
[Train] Epoch: 0 [518848/620022]    Loss: 0.010710   Batch Acc: 70.31
[Train] Epoch: 0 [518912/620022]    Loss: 0.007274   Batch Acc: 84.38
[Train] Epoch: 0 [518976/620022]    Loss: 0.009159   Batch Acc: 75.00
[Train] Epoch: 0 [519040/620022]    Loss: 0.008939   Batch Acc: 79.69
[Train] Epoch: 0 [519104/620022]    Loss: 0.008301   Batch Acc: 75.00
[Train] Epoch: 0 [519168/620022]    Loss: 0.007623   Batch Acc: 81.25
[Train] Epoch: 0 [519232/620022]    Loss: 0.006200   Batch Acc: 84.38
[Train] Epoch: 0 [519296/620022]    Loss: 0.007737   Batch Acc: 78.12
[Train] Epoch: 0 [519360/620022]    Loss: 0.007359   Batch Acc: 76.56
[Train] Epoch: 0 [519424/620022]    Loss: 0.009006   Batch Acc: 73.44
[Train] Epoch: 0 [519488/620022]    Loss: 0.006893   Batch Acc: 82.81
[Train] Epoch: 0 [519552/620022]    Loss: 0.008089   Batch Acc: 81.25
[Train] Epoch: 0 [519616/620022]    Loss: 0.009655   Batch Acc: 70.31
[Train] Epoch: 0 [519680/620022]    Loss: 0.010050   Batch Acc: 68.75
[Train] Epoch: 0 [519744/620022]    Loss: 0.010076   Batch Acc: 73.44
[Train] Epoch: 0 [519808/620022]    Loss: 0.009202   Batch Acc: 73.44
[Train] Epoch: 0 [519872/620022]    Loss: 0.008846   Batch Acc: 76.56
[Train] Epoch: 0 [519936/620022]    Loss: 0.007905   Batch Acc: 78.12
[Train] Epoch: 0 [520000/620022]    Loss: 0.010537   Batch Acc: 71.88
[Train] Epoch: 0 [520064/620022]    Loss: 0.007567   Batch Acc: 81.25
[Train] Epoch: 0 [520128/620022]    Loss: 0.011715   Batch Acc: 64.06
[Train] Epoch: 0 [520192/620022]    Loss: 0.007471   Batch Acc: 79.69
[Train] Epoch: 0 [520256/620022]    Loss: 0.007579   Batch Acc: 81.25
[Train] Epoch: 0 [520320/620022]    Loss: 0.008713   Batch Acc: 79.69
[Train] Epoch: 0 [520384/620022]    Loss: 0.006992   Batch Acc: 79.69
[Train] Epoch: 0 [520448/620022]    Loss: 0.010953   Batch Acc: 68.75
[Train] Epoch: 0 [520512/620022]    Loss: 0.008351   Batch Acc: 79.69
[Train] Epoch: 0 [520576/620022]    Loss: 0.008062   Batch Acc: 73.44
[Train] Epoch: 0 [520640/620022]    Loss: 0.008431   Batch Acc: 78.12
[Train] Epoch: 0 [520704/620022]    Loss: 0.008136   Batch Acc: 82.81
[Train] Epoch: 0 [520768/620022]    Loss: 0.011921   Batch Acc: 68.75
[Train] Epoch: 0 [520832/620022]    Loss: 0.006921   Batch Acc: 85.94
[Train] Epoch: 0 [520896/620022]    Loss: 0.010704   Batch Acc: 71.88
[Train] Epoch: 0 [520960/620022]    Loss: 0.006689   Batch Acc: 84.38
[Train] Epoch: 0 [521024/620022]    Loss: 0.008269   Batch Acc: 82.81
[Train] Epoch: 0 [521088/620022]    Loss: 0.008156   Batch Acc: 78.12
[Train] Epoch: 0 [521152/620022]    Loss: 0.009246   Batch Acc: 81.25
[Train] Epoch: 0 [521216/620022]    Loss: 0.008277   Batch Acc: 78.12
[Train] Epoch: 0 [521280/620022]    Loss: 0.008906   Batch Acc: 73.44
[Train] Epoch: 0 [521344/620022]    Loss: 0.009660   Batch Acc: 76.56
[Train] Epoch: 0 [521408/620022]    Loss: 0.010490   Batch Acc: 70.31
[Train] Epoch: 0 [521472/620022]    Loss: 0.008717   Batch Acc: 75.00
[Train] Epoch: 0 [521536/620022]    Loss: 0.009382   Batch Acc: 71.88
[Train] Epoch: 0 [521600/620022]    Loss: 0.010521   Batch Acc: 70.31
[Train] Epoch: 0 [521664/620022]    Loss: 0.010448   Batch Acc: 71.88
[Train] Epoch: 0 [521728/620022]    Loss: 0.008675   Batch Acc: 84.38
[Train] Epoch: 0 [521792/620022]    Loss: 0.009536   Batch Acc: 73.44
[Train] Epoch: 0 [521856/620022]    Loss: 0.007038   Batch Acc: 82.81
[Train] Epoch: 0 [521920/620022]    Loss: 0.008100   Batch Acc: 79.69
[Train] Epoch: 0 [521984/620022]    Loss: 0.009876   Batch Acc: 78.12
[Train] Epoch: 0 [522048/620022]    Loss: 0.009878   Batch Acc: 78.12
[Train] Epoch: 0 [522112/620022]    Loss: 0.009373   Batch Acc: 75.00
[Train] Epoch: 0 [522176/620022]    Loss: 0.010326   Batch Acc: 65.62
[Train] Epoch: 0 [522240/620022]    Loss: 0.009693   Batch Acc: 76.56
[Train] Epoch: 0 [522304/620022]    Loss: 0.010109   Batch Acc: 75.00
[Train] Epoch: 0 [522368/620022]    Loss: 0.008692   Batch Acc: 75.00
[Train] Epoch: 0 [522432/620022]    Loss: 0.007133   Batch Acc: 84.38
[Train] Epoch: 0 [522496/620022]    Loss: 0.010752   Batch Acc: 70.31
[Train] Epoch: 0 [522560/620022]    Loss: 0.009574   Batch Acc: 73.44
[Train] Epoch: 0 [522624/620022]    Loss: 0.009563   Batch Acc: 73.44
[Train] Epoch: 0 [522688/620022]    Loss: 0.007758   Batch Acc: 81.25
[Train] Epoch: 0 [522752/620022]    Loss: 0.005898   Batch Acc: 89.06
[Train] Epoch: 0 [522816/620022]    Loss: 0.010706   Batch Acc: 65.62
[Train] Epoch: 0 [522880/620022]    Loss: 0.007671   Batch Acc: 84.38
[Train] Epoch: 0 [522944/620022]    Loss: 0.008892   Batch Acc: 75.00
[Train] Epoch: 0 [523008/620022]    Loss: 0.009383   Batch Acc: 75.00
[Train] Epoch: 0 [523072/620022]    Loss: 0.009657   Batch Acc: 75.00
[Train] Epoch: 0 [523136/620022]    Loss: 0.010394   Batch Acc: 71.88
[Train] Epoch: 0 [523200/620022]    Loss: 0.006534   Batch Acc: 84.38
[Train] Epoch: 0 [523264/620022]    Loss: 0.009115   Batch Acc: 73.44
[Train] Epoch: 0 [523328/620022]    Loss: 0.008977   Batch Acc: 70.31
[Train] Epoch: 0 [523392/620022]    Loss: 0.007007   Batch Acc: 84.38
[Train] Epoch: 0 [523456/620022]    Loss: 0.007658   Batch Acc: 81.25
[Train] Epoch: 0 [523520/620022]    Loss: 0.007427   Batch Acc: 85.94
[Train] Epoch: 0 [523584/620022]    Loss: 0.009431   Batch Acc: 73.44
[Train] Epoch: 0 [523648/620022]    Loss: 0.009619   Batch Acc: 75.00
[Train] Epoch: 0 [523712/620022]    Loss: 0.009008   Batch Acc: 76.56
[Train] Epoch: 0 [523776/620022]    Loss: 0.010360   Batch Acc: 73.44
[Train] Epoch: 0 [523840/620022]    Loss: 0.009199   Batch Acc: 75.00
[Train] Epoch: 0 [523904/620022]    Loss: 0.006963   Batch Acc: 85.94
[Train] Epoch: 0 [523968/620022]    Loss: 0.009696   Batch Acc: 75.00
[Train] Epoch: 0 [524032/620022]    Loss: 0.010432   Batch Acc: 71.88
[Train] Epoch: 0 [524096/620022]    Loss: 0.011993   Batch Acc: 64.06
[Train] Epoch: 0 [524160/620022]    Loss: 0.007784   Batch Acc: 84.38
[Train] Epoch: 0 [524224/620022]    Loss: 0.007500   Batch Acc: 81.25
[Train] Epoch: 0 [524288/620022]    Loss: 0.007649   Batch Acc: 84.38
[Train] Epoch: 0 [524352/620022]    Loss: 0.008756   Batch Acc: 81.25
[Train] Epoch: 0 [524416/620022]    Loss: 0.009440   Batch Acc: 75.00
[Train] Epoch: 0 [524480/620022]    Loss: 0.008340   Batch Acc: 78.12
[Train] Epoch: 0 [524544/620022]    Loss: 0.007348   Batch Acc: 84.38
[Train] Epoch: 0 [524608/620022]    Loss: 0.008920   Batch Acc: 76.56
[Train] Epoch: 0 [524672/620022]    Loss: 0.008737   Batch Acc: 76.56
[Train] Epoch: 0 [524736/620022]    Loss: 0.008095   Batch Acc: 73.44
[Train] Epoch: 0 [524800/620022]    Loss: 0.009607   Batch Acc: 81.25
[Train] Epoch: 0 [524864/620022]    Loss: 0.009634   Batch Acc: 76.56
[Train] Epoch: 0 [524928/620022]    Loss: 0.008058   Batch Acc: 78.12
[Train] Epoch: 0 [524992/620022]    Loss: 0.006170   Batch Acc: 85.94
[Train] Epoch: 0 [525056/620022]    Loss: 0.009597   Batch Acc: 76.56
[Train] Epoch: 0 [525120/620022]    Loss: 0.007570   Batch Acc: 82.81
[Train] Epoch: 0 [525184/620022]    Loss: 0.007901   Batch Acc: 76.56
[Train] Epoch: 0 [525248/620022]    Loss: 0.009308   Batch Acc: 75.00
[Train] Epoch: 0 [525312/620022]    Loss: 0.008144   Batch Acc: 75.00
[Train] Epoch: 0 [525376/620022]    Loss: 0.008134   Batch Acc: 76.56
[Train] Epoch: 0 [525440/620022]    Loss: 0.009260   Batch Acc: 79.69
[Train] Epoch: 0 [525504/620022]    Loss: 0.011521   Batch Acc: 67.19
[Train] Epoch: 0 [525568/620022]    Loss: 0.007798   Batch Acc: 76.56
[Train] Epoch: 0 [525632/620022]    Loss: 0.008644   Batch Acc: 79.69
[Train] Epoch: 0 [525696/620022]    Loss: 0.007625   Batch Acc: 85.94
[Train] Epoch: 0 [525760/620022]    Loss: 0.007966   Batch Acc: 81.25
[Train] Epoch: 0 [525824/620022]    Loss: 0.012237   Batch Acc: 64.06
[Train] Epoch: 0 [525888/620022]    Loss: 0.008171   Batch Acc: 87.50
[Train] Epoch: 0 [525952/620022]    Loss: 0.007417   Batch Acc: 81.25
[Train] Epoch: 0 [526016/620022]    Loss: 0.008949   Batch Acc: 78.12
[Train] Epoch: 0 [526080/620022]    Loss: 0.009218   Batch Acc: 71.88
[Train] Epoch: 0 [526144/620022]    Loss: 0.006803   Batch Acc: 82.81
[Train] Epoch: 0 [526208/620022]    Loss: 0.008599   Batch Acc: 79.69
[Train] Epoch: 0 [526272/620022]    Loss: 0.006833   Batch Acc: 85.94
[Train] Epoch: 0 [526336/620022]    Loss: 0.008303   Batch Acc: 79.69
[Train] Epoch: 0 [526400/620022]    Loss: 0.008682   Batch Acc: 73.44
[Train] Epoch: 0 [526464/620022]    Loss: 0.008760   Batch Acc: 79.69
[Train] Epoch: 0 [526528/620022]    Loss: 0.009627   Batch Acc: 73.44
[Train] Epoch: 0 [526592/620022]    Loss: 0.008500   Batch Acc: 79.69
[Train] Epoch: 0 [526656/620022]    Loss: 0.008949   Batch Acc: 78.12
[Train] Epoch: 0 [526720/620022]    Loss: 0.011065   Batch Acc: 67.19
[Train] Epoch: 0 [526784/620022]    Loss: 0.009084   Batch Acc: 75.00
[Train] Epoch: 0 [526848/620022]    Loss: 0.009154   Batch Acc: 79.69
[Train] Epoch: 0 [526912/620022]    Loss: 0.009309   Batch Acc: 75.00
[Train] Epoch: 0 [526976/620022]    Loss: 0.010018   Batch Acc: 68.75
[Train] Epoch: 0 [527040/620022]    Loss: 0.008501   Batch Acc: 71.88
[Train] Epoch: 0 [527104/620022]    Loss: 0.008502   Batch Acc: 78.12
[Train] Epoch: 0 [527168/620022]    Loss: 0.011390   Batch Acc: 67.19
[Train] Epoch: 0 [527232/620022]    Loss: 0.010371   Batch Acc: 73.44
[Train] Epoch: 0 [527296/620022]    Loss: 0.009296   Batch Acc: 73.44
[Train] Epoch: 0 [527360/620022]    Loss: 0.008718   Batch Acc: 79.69
[Train] Epoch: 0 [527424/620022]    Loss: 0.009017   Batch Acc: 73.44
[Train] Epoch: 0 [527488/620022]    Loss: 0.009084   Batch Acc: 78.12
[Train] Epoch: 0 [527552/620022]    Loss: 0.010324   Batch Acc: 73.44
[Train] Epoch: 0 [527616/620022]    Loss: 0.007213   Batch Acc: 81.25
[Train] Epoch: 0 [527680/620022]    Loss: 0.009066   Batch Acc: 78.12
[Train] Epoch: 0 [527744/620022]    Loss: 0.007774   Batch Acc: 82.81
[Train] Epoch: 0 [527808/620022]    Loss: 0.008476   Batch Acc: 75.00
[Train] Epoch: 0 [527872/620022]    Loss: 0.008365   Batch Acc: 78.12
[Train] Epoch: 0 [527936/620022]    Loss: 0.007830   Batch Acc: 82.81
[Train] Epoch: 0 [528000/620022]    Loss: 0.009719   Batch Acc: 79.69
[Train] Epoch: 0 [528064/620022]    Loss: 0.009191   Batch Acc: 75.00
[Train] Epoch: 0 [528128/620022]    Loss: 0.007298   Batch Acc: 79.69
[Train] Epoch: 0 [528192/620022]    Loss: 0.008607   Batch Acc: 75.00
[Train] Epoch: 0 [528256/620022]    Loss: 0.009248   Batch Acc: 78.12
[Train] Epoch: 0 [528320/620022]    Loss: 0.007764   Batch Acc: 76.56
[Train] Epoch: 0 [528384/620022]    Loss: 0.006429   Batch Acc: 85.94
[Train] Epoch: 0 [528448/620022]    Loss: 0.009566   Batch Acc: 71.88
[Train] Epoch: 0 [528512/620022]    Loss: 0.009293   Batch Acc: 75.00
[Train] Epoch: 0 [528576/620022]    Loss: 0.008344   Batch Acc: 76.56
[Train] Epoch: 0 [528640/620022]    Loss: 0.010899   Batch Acc: 75.00
[Train] Epoch: 0 [528704/620022]    Loss: 0.009023   Batch Acc: 75.00
[Train] Epoch: 0 [528768/620022]    Loss: 0.008154   Batch Acc: 78.12
[Train] Epoch: 0 [528832/620022]    Loss: 0.008221   Batch Acc: 81.25
[Train] Epoch: 0 [528896/620022]    Loss: 0.010585   Batch Acc: 70.31
[Train] Epoch: 0 [528960/620022]    Loss: 0.007769   Batch Acc: 81.25
[Train] Epoch: 0 [529024/620022]    Loss: 0.012663   Batch Acc: 71.88
[Train] Epoch: 0 [529088/620022]    Loss: 0.009939   Batch Acc: 75.00
[Train] Epoch: 0 [529152/620022]    Loss: 0.007723   Batch Acc: 82.81
[Train] Epoch: 0 [529216/620022]    Loss: 0.009668   Batch Acc: 78.12
[Train] Epoch: 0 [529280/620022]    Loss: 0.009618   Batch Acc: 76.56
[Train] Epoch: 0 [529344/620022]    Loss: 0.009189   Batch Acc: 73.44
[Train] Epoch: 0 [529408/620022]    Loss: 0.008649   Batch Acc: 78.12
[Train] Epoch: 0 [529472/620022]    Loss: 0.008118   Batch Acc: 78.12
[Train] Epoch: 0 [529536/620022]    Loss: 0.010785   Batch Acc: 68.75
[Train] Epoch: 0 [529600/620022]    Loss: 0.007216   Batch Acc: 82.81
[Train] Epoch: 0 [529664/620022]    Loss: 0.009069   Batch Acc: 76.56
[Train] Epoch: 0 [529728/620022]    Loss: 0.008938   Batch Acc: 84.38
[Train] Epoch: 0 [529792/620022]    Loss: 0.010888   Batch Acc: 67.19
[Train] Epoch: 0 [529856/620022]    Loss: 0.010092   Batch Acc: 78.12
[Train] Epoch: 0 [529920/620022]    Loss: 0.008627   Batch Acc: 79.69
[Train] Epoch: 0 [529984/620022]    Loss: 0.009726   Batch Acc: 76.56
[Train] Epoch: 0 [530048/620022]    Loss: 0.008732   Batch Acc: 76.56
[Train] Epoch: 0 [530112/620022]    Loss: 0.008610   Batch Acc: 81.25
[Train] Epoch: 0 [530176/620022]    Loss: 0.011222   Batch Acc: 67.19
[Train] Epoch: 0 [530240/620022]    Loss: 0.010283   Batch Acc: 68.75
[Train] Epoch: 0 [530304/620022]    Loss: 0.008890   Batch Acc: 82.81
[Train] Epoch: 0 [530368/620022]    Loss: 0.006174   Batch Acc: 82.81
[Train] Epoch: 0 [530432/620022]    Loss: 0.010713   Batch Acc: 64.06
[Train] Epoch: 0 [530496/620022]    Loss: 0.010240   Batch Acc: 73.44
[Train] Epoch: 0 [530560/620022]    Loss: 0.010105   Batch Acc: 75.00
[Train] Epoch: 0 [530624/620022]    Loss: 0.007917   Batch Acc: 75.00
[Train] Epoch: 0 [530688/620022]    Loss: 0.008691   Batch Acc: 75.00
[Train] Epoch: 0 [530752/620022]    Loss: 0.006765   Batch Acc: 89.06
[Train] Epoch: 0 [530816/620022]    Loss: 0.007955   Batch Acc: 76.56
[Train] Epoch: 0 [530880/620022]    Loss: 0.010268   Batch Acc: 71.88
[Train] Epoch: 0 [530944/620022]    Loss: 0.007738   Batch Acc: 78.12
[Train] Epoch: 0 [531008/620022]    Loss: 0.006888   Batch Acc: 82.81
[Train] Epoch: 0 [531072/620022]    Loss: 0.008438   Batch Acc: 78.12
[Train] Epoch: 0 [531136/620022]    Loss: 0.009698   Batch Acc: 73.44
[Train] Epoch: 0 [531200/620022]    Loss: 0.007940   Batch Acc: 84.38
[Train] Epoch: 0 [531264/620022]    Loss: 0.011902   Batch Acc: 64.06
[Train] Epoch: 0 [531328/620022]    Loss: 0.008778   Batch Acc: 73.44
[Train] Epoch: 0 [531392/620022]    Loss: 0.008166   Batch Acc: 78.12
[Train] Epoch: 0 [531456/620022]    Loss: 0.009398   Batch Acc: 78.12
[Train] Epoch: 0 [531520/620022]    Loss: 0.009999   Batch Acc: 70.31
[Train] Epoch: 0 [531584/620022]    Loss: 0.007232   Batch Acc: 82.81
[Train] Epoch: 0 [531648/620022]    Loss: 0.009884   Batch Acc: 78.12
[Train] Epoch: 0 [531712/620022]    Loss: 0.008452   Batch Acc: 79.69
[Train] Epoch: 0 [531776/620022]    Loss: 0.009210   Batch Acc: 73.44
[Train] Epoch: 0 [531840/620022]    Loss: 0.010086   Batch Acc: 73.44
[Train] Epoch: 0 [531904/620022]    Loss: 0.009179   Batch Acc: 76.56
[Train] Epoch: 0 [531968/620022]    Loss: 0.008379   Batch Acc: 76.56
[Train] Epoch: 0 [532032/620022]    Loss: 0.009940   Batch Acc: 79.69
[Train] Epoch: 0 [532096/620022]    Loss: 0.009304   Batch Acc: 75.00
[Train] Epoch: 0 [532160/620022]    Loss: 0.009780   Batch Acc: 68.75
[Train] Epoch: 0 [532224/620022]    Loss: 0.008187   Batch Acc: 78.12
[Train] Epoch: 0 [532288/620022]    Loss: 0.006824   Batch Acc: 84.38
[Train] Epoch: 0 [532352/620022]    Loss: 0.009045   Batch Acc: 76.56
[Train] Epoch: 0 [532416/620022]    Loss: 0.007319   Batch Acc: 87.50
[Train] Epoch: 0 [532480/620022]    Loss: 0.008517   Batch Acc: 79.69
[Train] Epoch: 0 [532544/620022]    Loss: 0.009823   Batch Acc: 84.38
[Train] Epoch: 0 [532608/620022]    Loss: 0.008168   Batch Acc: 73.44
[Train] Epoch: 0 [532672/620022]    Loss: 0.008057   Batch Acc: 78.12
[Train] Epoch: 0 [532736/620022]    Loss: 0.009572   Batch Acc: 71.88
[Train] Epoch: 0 [532800/620022]    Loss: 0.011372   Batch Acc: 68.75
[Train] Epoch: 0 [532864/620022]    Loss: 0.009417   Batch Acc: 73.44
[Train] Epoch: 0 [532928/620022]    Loss: 0.011031   Batch Acc: 68.75
[Train] Epoch: 0 [532992/620022]    Loss: 0.008573   Batch Acc: 82.81
[Train] Epoch: 0 [533056/620022]    Loss: 0.010935   Batch Acc: 71.88
[Train] Epoch: 0 [533120/620022]    Loss: 0.009328   Batch Acc: 71.88
[Train] Epoch: 0 [533184/620022]    Loss: 0.008274   Batch Acc: 75.00
[Train] Epoch: 0 [533248/620022]    Loss: 0.008402   Batch Acc: 81.25
[Train] Epoch: 0 [533312/620022]    Loss: 0.008590   Batch Acc: 76.56
[Train] Epoch: 0 [533376/620022]    Loss: 0.009204   Batch Acc: 76.56
[Train] Epoch: 0 [533440/620022]    Loss: 0.011015   Batch Acc: 67.19
[Train] Epoch: 0 [533504/620022]    Loss: 0.009567   Batch Acc: 71.88
[Train] Epoch: 0 [533568/620022]    Loss: 0.009865   Batch Acc: 68.75
[Train] Epoch: 0 [533632/620022]    Loss: 0.007960   Batch Acc: 79.69
[Train] Epoch: 0 [533696/620022]    Loss: 0.009209   Batch Acc: 78.12
[Train] Epoch: 0 [533760/620022]    Loss: 0.006942   Batch Acc: 85.94
[Train] Epoch: 0 [533824/620022]    Loss: 0.009430   Batch Acc: 75.00
[Train] Epoch: 0 [533888/620022]    Loss: 0.008810   Batch Acc: 79.69
[Train] Epoch: 0 [533952/620022]    Loss: 0.008557   Batch Acc: 79.69
[Train] Epoch: 0 [534016/620022]    Loss: 0.010013   Batch Acc: 75.00
[Train] Epoch: 0 [534080/620022]    Loss: 0.007376   Batch Acc: 81.25
[Train] Epoch: 0 [534144/620022]    Loss: 0.007251   Batch Acc: 84.38
[Train] Epoch: 0 [534208/620022]    Loss: 0.010800   Batch Acc: 70.31
[Train] Epoch: 0 [534272/620022]    Loss: 0.007660   Batch Acc: 75.00
[Train] Epoch: 0 [534336/620022]    Loss: 0.010349   Batch Acc: 65.62
[Train] Epoch: 0 [534400/620022]    Loss: 0.007675   Batch Acc: 81.25
[Train] Epoch: 0 [534464/620022]    Loss: 0.008554   Batch Acc: 76.56
[Train] Epoch: 0 [534528/620022]    Loss: 0.010507   Batch Acc: 78.12
[Train] Epoch: 0 [534592/620022]    Loss: 0.009583   Batch Acc: 71.88
[Train] Epoch: 0 [534656/620022]    Loss: 0.009813   Batch Acc: 75.00
[Train] Epoch: 0 [534720/620022]    Loss: 0.009636   Batch Acc: 75.00
[Train] Epoch: 0 [534784/620022]    Loss: 0.007514   Batch Acc: 82.81
[Train] Epoch: 0 [534848/620022]    Loss: 0.008248   Batch Acc: 78.12
[Train] Epoch: 0 [534912/620022]    Loss: 0.008296   Batch Acc: 71.88
[Train] Epoch: 0 [534976/620022]    Loss: 0.008853   Batch Acc: 75.00
[Train] Epoch: 0 [535040/620022]    Loss: 0.008448   Batch Acc: 81.25
[Train] Epoch: 0 [535104/620022]    Loss: 0.009580   Batch Acc: 73.44
[Train] Epoch: 0 [535168/620022]    Loss: 0.012115   Batch Acc: 68.75
[Train] Epoch: 0 [535232/620022]    Loss: 0.007852   Batch Acc: 81.25
[Train] Epoch: 0 [535296/620022]    Loss: 0.008630   Batch Acc: 84.38
[Train] Epoch: 0 [535360/620022]    Loss: 0.006488   Batch Acc: 84.38
[Train] Epoch: 0 [535424/620022]    Loss: 0.008639   Batch Acc: 73.44
[Train] Epoch: 0 [535488/620022]    Loss: 0.006451   Batch Acc: 89.06
[Train] Epoch: 0 [535552/620022]    Loss: 0.010358   Batch Acc: 75.00
[Train] Epoch: 0 [535616/620022]    Loss: 0.008802   Batch Acc: 75.00
[Train] Epoch: 0 [535680/620022]    Loss: 0.009174   Batch Acc: 76.56
[Train] Epoch: 0 [535744/620022]    Loss: 0.008163   Batch Acc: 84.38
[Train] Epoch: 0 [535808/620022]    Loss: 0.008837   Batch Acc: 81.25
[Train] Epoch: 0 [535872/620022]    Loss: 0.007945   Batch Acc: 84.38
[Train] Epoch: 0 [535936/620022]    Loss: 0.008862   Batch Acc: 76.56
[Train] Epoch: 0 [536000/620022]    Loss: 0.008646   Batch Acc: 79.69
[Train] Epoch: 0 [536064/620022]    Loss: 0.006300   Batch Acc: 87.50
[Train] Epoch: 0 [536128/620022]    Loss: 0.008336   Batch Acc: 79.69
[Train] Epoch: 0 [536192/620022]    Loss: 0.009032   Batch Acc: 76.56
[Train] Epoch: 0 [536256/620022]    Loss: 0.008675   Batch Acc: 76.56
[Train] Epoch: 0 [536320/620022]    Loss: 0.009501   Batch Acc: 78.12
[Train] Epoch: 0 [536384/620022]    Loss: 0.010639   Batch Acc: 71.88
[Train] Epoch: 0 [536448/620022]    Loss: 0.009856   Batch Acc: 71.88
[Train] Epoch: 0 [536512/620022]    Loss: 0.007437   Batch Acc: 85.94
[Train] Epoch: 0 [536576/620022]    Loss: 0.012638   Batch Acc: 68.75
[Train] Epoch: 0 [536640/620022]    Loss: 0.009054   Batch Acc: 79.69
[Train] Epoch: 0 [536704/620022]    Loss: 0.011674   Batch Acc: 65.62
[Train] Epoch: 0 [536768/620022]    Loss: 0.008743   Batch Acc: 79.69
[Train] Epoch: 0 [536832/620022]    Loss: 0.009894   Batch Acc: 73.44
[Train] Epoch: 0 [536896/620022]    Loss: 0.010308   Batch Acc: 70.31
[Train] Epoch: 0 [536960/620022]    Loss: 0.010074   Batch Acc: 81.25
[Train] Epoch: 0 [537024/620022]    Loss: 0.007062   Batch Acc: 84.38
[Train] Epoch: 0 [537088/620022]    Loss: 0.009370   Batch Acc: 78.12
[Train] Epoch: 0 [537152/620022]    Loss: 0.008358   Batch Acc: 71.88
[Train] Epoch: 0 [537216/620022]    Loss: 0.008799   Batch Acc: 75.00
[Train] Epoch: 0 [537280/620022]    Loss: 0.008909   Batch Acc: 79.69
[Train] Epoch: 0 [537344/620022]    Loss: 0.007709   Batch Acc: 84.38
[Train] Epoch: 0 [537408/620022]    Loss: 0.009059   Batch Acc: 78.12
[Train] Epoch: 0 [537472/620022]    Loss: 0.007780   Batch Acc: 79.69
[Train] Epoch: 0 [537536/620022]    Loss: 0.009663   Batch Acc: 76.56
[Train] Epoch: 0 [537600/620022]    Loss: 0.010926   Batch Acc: 73.44
[Train] Epoch: 0 [537664/620022]    Loss: 0.006823   Batch Acc: 87.50
[Train] Epoch: 0 [537728/620022]    Loss: 0.008661   Batch Acc: 71.88
[Train] Epoch: 0 [537792/620022]    Loss: 0.008186   Batch Acc: 81.25
[Train] Epoch: 0 [537856/620022]    Loss: 0.008823   Batch Acc: 79.69
[Train] Epoch: 0 [537920/620022]    Loss: 0.009807   Batch Acc: 70.31
[Train] Epoch: 0 [537984/620022]    Loss: 0.009440   Batch Acc: 71.88
[Train] Epoch: 0 [538048/620022]    Loss: 0.007916   Batch Acc: 82.81
[Train] Epoch: 0 [538112/620022]    Loss: 0.010478   Batch Acc: 71.88
[Train] Epoch: 0 [538176/620022]    Loss: 0.006860   Batch Acc: 85.94
[Train] Epoch: 0 [538240/620022]    Loss: 0.008130   Batch Acc: 79.69
[Train] Epoch: 0 [538304/620022]    Loss: 0.008737   Batch Acc: 81.25
[Train] Epoch: 0 [538368/620022]    Loss: 0.008042   Batch Acc: 81.25
[Train] Epoch: 0 [538432/620022]    Loss: 0.009083   Batch Acc: 81.25
[Train] Epoch: 0 [538496/620022]    Loss: 0.008094   Batch Acc: 84.38
[Train] Epoch: 0 [538560/620022]    Loss: 0.008055   Batch Acc: 79.69
[Train] Epoch: 0 [538624/620022]    Loss: 0.010036   Batch Acc: 71.88
[Train] Epoch: 0 [538688/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 0 [538752/620022]    Loss: 0.009950   Batch Acc: 76.56
[Train] Epoch: 0 [538816/620022]    Loss: 0.009019   Batch Acc: 75.00
[Train] Epoch: 0 [538880/620022]    Loss: 0.007915   Batch Acc: 82.81
[Train] Epoch: 0 [538944/620022]    Loss: 0.009762   Batch Acc: 73.44
[Train] Epoch: 0 [539008/620022]    Loss: 0.008916   Batch Acc: 75.00
[Train] Epoch: 0 [539072/620022]    Loss: 0.007294   Batch Acc: 82.81
[Train] Epoch: 0 [539136/620022]    Loss: 0.008307   Batch Acc: 79.69
[Train] Epoch: 0 [539200/620022]    Loss: 0.008284   Batch Acc: 78.12
[Train] Epoch: 0 [539264/620022]    Loss: 0.008965   Batch Acc: 81.25
[Train] Epoch: 0 [539328/620022]    Loss: 0.006043   Batch Acc: 89.06
[Train] Epoch: 0 [539392/620022]    Loss: 0.010536   Batch Acc: 76.56
[Train] Epoch: 0 [539456/620022]    Loss: 0.008916   Batch Acc: 78.12
[Train] Epoch: 0 [539520/620022]    Loss: 0.011505   Batch Acc: 67.19
[Train] Epoch: 0 [539584/620022]    Loss: 0.009108   Batch Acc: 81.25
[Train] Epoch: 0 [539648/620022]    Loss: 0.010080   Batch Acc: 76.56
[Train] Epoch: 0 [539712/620022]    Loss: 0.009980   Batch Acc: 79.69
[Train] Epoch: 0 [539776/620022]    Loss: 0.009784   Batch Acc: 76.56
[Train] Epoch: 0 [539840/620022]    Loss: 0.007971   Batch Acc: 75.00
[Train] Epoch: 0 [539904/620022]    Loss: 0.011447   Batch Acc: 70.31
[Train] Epoch: 0 [539968/620022]    Loss: 0.008955   Batch Acc: 76.56
[Train] Epoch: 0 [540032/620022]    Loss: 0.009402   Batch Acc: 76.56
[Train] Epoch: 0 [540096/620022]    Loss: 0.006742   Batch Acc: 87.50
[Train] Epoch: 0 [540160/620022]    Loss: 0.008858   Batch Acc: 76.56
[Train] Epoch: 0 [540224/620022]    Loss: 0.009021   Batch Acc: 73.44
[Train] Epoch: 0 [540288/620022]    Loss: 0.006377   Batch Acc: 84.38
[Train] Epoch: 0 [540352/620022]    Loss: 0.009595   Batch Acc: 75.00
[Train] Epoch: 0 [540416/620022]    Loss: 0.010158   Batch Acc: 68.75
[Train] Epoch: 0 [540480/620022]    Loss: 0.009958   Batch Acc: 78.12
[Train] Epoch: 0 [540544/620022]    Loss: 0.011724   Batch Acc: 67.19
[Train] Epoch: 0 [540608/620022]    Loss: 0.010139   Batch Acc: 73.44
[Train] Epoch: 0 [540672/620022]    Loss: 0.008766   Batch Acc: 76.56
[Train] Epoch: 0 [540736/620022]    Loss: 0.008380   Batch Acc: 76.56
[Train] Epoch: 0 [540800/620022]    Loss: 0.008756   Batch Acc: 76.56
[Train] Epoch: 0 [540864/620022]    Loss: 0.008413   Batch Acc: 76.56
[Train] Epoch: 0 [540928/620022]    Loss: 0.008276   Batch Acc: 78.12
[Train] Epoch: 0 [540992/620022]    Loss: 0.006555   Batch Acc: 87.50
[Train] Epoch: 0 [541056/620022]    Loss: 0.007920   Batch Acc: 81.25
[Train] Epoch: 0 [541120/620022]    Loss: 0.006244   Batch Acc: 84.38
[Train] Epoch: 0 [541184/620022]    Loss: 0.007974   Batch Acc: 75.00
[Train] Epoch: 0 [541248/620022]    Loss: 0.010427   Batch Acc: 67.19
[Train] Epoch: 0 [541312/620022]    Loss: 0.006853   Batch Acc: 82.81
[Train] Epoch: 0 [541376/620022]    Loss: 0.007885   Batch Acc: 78.12
[Train] Epoch: 0 [541440/620022]    Loss: 0.008432   Batch Acc: 81.25
[Train] Epoch: 0 [541504/620022]    Loss: 0.009504   Batch Acc: 75.00
[Train] Epoch: 0 [541568/620022]    Loss: 0.009786   Batch Acc: 79.69
[Train] Epoch: 0 [541632/620022]    Loss: 0.007811   Batch Acc: 79.69
[Train] Epoch: 0 [541696/620022]    Loss: 0.011131   Batch Acc: 60.94
[Train] Epoch: 0 [541760/620022]    Loss: 0.009491   Batch Acc: 75.00
[Train] Epoch: 0 [541824/620022]    Loss: 0.007628   Batch Acc: 79.69
[Train] Epoch: 0 [541888/620022]    Loss: 0.007772   Batch Acc: 82.81
[Train] Epoch: 0 [541952/620022]    Loss: 0.008967   Batch Acc: 73.44
[Train] Epoch: 0 [542016/620022]    Loss: 0.008844   Batch Acc: 75.00
[Train] Epoch: 0 [542080/620022]    Loss: 0.009086   Batch Acc: 76.56
[Train] Epoch: 0 [542144/620022]    Loss: 0.008792   Batch Acc: 78.12
[Train] Epoch: 0 [542208/620022]    Loss: 0.008587   Batch Acc: 82.81
[Train] Epoch: 0 [542272/620022]    Loss: 0.006188   Batch Acc: 85.94
[Train] Epoch: 0 [542336/620022]    Loss: 0.008676   Batch Acc: 76.56
[Train] Epoch: 0 [542400/620022]    Loss: 0.009378   Batch Acc: 75.00
[Train] Epoch: 0 [542464/620022]    Loss: 0.009373   Batch Acc: 76.56
[Train] Epoch: 0 [542528/620022]    Loss: 0.010819   Batch Acc: 68.75
[Train] Epoch: 0 [542592/620022]    Loss: 0.010964   Batch Acc: 60.94
[Train] Epoch: 0 [542656/620022]    Loss: 0.009712   Batch Acc: 70.31
[Train] Epoch: 0 [542720/620022]    Loss: 0.010889   Batch Acc: 68.75
[Train] Epoch: 0 [542784/620022]    Loss: 0.009222   Batch Acc: 71.88
[Train] Epoch: 0 [542848/620022]    Loss: 0.007993   Batch Acc: 75.00
[Train] Epoch: 0 [542912/620022]    Loss: 0.007810   Batch Acc: 85.94
[Train] Epoch: 0 [542976/620022]    Loss: 0.008055   Batch Acc: 76.56
[Train] Epoch: 0 [543040/620022]    Loss: 0.011115   Batch Acc: 75.00
[Train] Epoch: 0 [543104/620022]    Loss: 0.009134   Batch Acc: 78.12
[Train] Epoch: 0 [543168/620022]    Loss: 0.009109   Batch Acc: 73.44
[Train] Epoch: 0 [543232/620022]    Loss: 0.008475   Batch Acc: 81.25
[Train] Epoch: 0 [543296/620022]    Loss: 0.007366   Batch Acc: 76.56
[Train] Epoch: 0 [543360/620022]    Loss: 0.010212   Batch Acc: 75.00
[Train] Epoch: 0 [543424/620022]    Loss: 0.009087   Batch Acc: 78.12
[Train] Epoch: 0 [543488/620022]    Loss: 0.007283   Batch Acc: 82.81
[Train] Epoch: 0 [543552/620022]    Loss: 0.008748   Batch Acc: 78.12
[Train] Epoch: 0 [543616/620022]    Loss: 0.008355   Batch Acc: 73.44
[Train] Epoch: 0 [543680/620022]    Loss: 0.007448   Batch Acc: 79.69
[Train] Epoch: 0 [543744/620022]    Loss: 0.009816   Batch Acc: 79.69
[Train] Epoch: 0 [543808/620022]    Loss: 0.010415   Batch Acc: 70.31
[Train] Epoch: 0 [543872/620022]    Loss: 0.006668   Batch Acc: 84.38
[Train] Epoch: 0 [543936/620022]    Loss: 0.009347   Batch Acc: 78.12
[Train] Epoch: 0 [544000/620022]    Loss: 0.010798   Batch Acc: 75.00
[Train] Epoch: 0 [544064/620022]    Loss: 0.010209   Batch Acc: 70.31
[Train] Epoch: 0 [544128/620022]    Loss: 0.007745   Batch Acc: 82.81
[Train] Epoch: 0 [544192/620022]    Loss: 0.007131   Batch Acc: 89.06
[Train] Epoch: 0 [544256/620022]    Loss: 0.008768   Batch Acc: 79.69
[Train] Epoch: 0 [544320/620022]    Loss: 0.007456   Batch Acc: 81.25
[Train] Epoch: 0 [544384/620022]    Loss: 0.007932   Batch Acc: 81.25
[Train] Epoch: 0 [544448/620022]    Loss: 0.008958   Batch Acc: 78.12
[Train] Epoch: 0 [544512/620022]    Loss: 0.009041   Batch Acc: 79.69
[Train] Epoch: 0 [544576/620022]    Loss: 0.008965   Batch Acc: 78.12
[Train] Epoch: 0 [544640/620022]    Loss: 0.008611   Batch Acc: 78.12
[Train] Epoch: 0 [544704/620022]    Loss: 0.008580   Batch Acc: 78.12
[Train] Epoch: 0 [544768/620022]    Loss: 0.009251   Batch Acc: 73.44
[Train] Epoch: 0 [544832/620022]    Loss: 0.011441   Batch Acc: 76.56
[Train] Epoch: 0 [544896/620022]    Loss: 0.008513   Batch Acc: 76.56
[Train] Epoch: 0 [544960/620022]    Loss: 0.006782   Batch Acc: 84.38
[Train] Epoch: 0 [545024/620022]    Loss: 0.010339   Batch Acc: 75.00
[Train] Epoch: 0 [545088/620022]    Loss: 0.010242   Batch Acc: 75.00
[Train] Epoch: 0 [545152/620022]    Loss: 0.008560   Batch Acc: 81.25
[Train] Epoch: 0 [545216/620022]    Loss: 0.007861   Batch Acc: 81.25
[Train] Epoch: 0 [545280/620022]    Loss: 0.006705   Batch Acc: 87.50
[Train] Epoch: 0 [545344/620022]    Loss: 0.010103   Batch Acc: 70.31
[Train] Epoch: 0 [545408/620022]    Loss: 0.007090   Batch Acc: 84.38
[Train] Epoch: 0 [545472/620022]    Loss: 0.007996   Batch Acc: 78.12
[Train] Epoch: 0 [545536/620022]    Loss: 0.006565   Batch Acc: 84.38
[Train] Epoch: 0 [545600/620022]    Loss: 0.008065   Batch Acc: 81.25
[Train] Epoch: 0 [545664/620022]    Loss: 0.008407   Batch Acc: 79.69
[Train] Epoch: 0 [545728/620022]    Loss: 0.010340   Batch Acc: 79.69
[Train] Epoch: 0 [545792/620022]    Loss: 0.009132   Batch Acc: 76.56
[Train] Epoch: 0 [545856/620022]    Loss: 0.010140   Batch Acc: 78.12
[Train] Epoch: 0 [545920/620022]    Loss: 0.010892   Batch Acc: 70.31
[Train] Epoch: 0 [545984/620022]    Loss: 0.009845   Batch Acc: 68.75
[Train] Epoch: 0 [546048/620022]    Loss: 0.008811   Batch Acc: 79.69
[Train] Epoch: 0 [546112/620022]    Loss: 0.008149   Batch Acc: 78.12
[Train] Epoch: 0 [546176/620022]    Loss: 0.008524   Batch Acc: 75.00
[Train] Epoch: 0 [546240/620022]    Loss: 0.010233   Batch Acc: 68.75
[Train] Epoch: 0 [546304/620022]    Loss: 0.008014   Batch Acc: 76.56
[Train] Epoch: 0 [546368/620022]    Loss: 0.006363   Batch Acc: 82.81
[Train] Epoch: 0 [546432/620022]    Loss: 0.010711   Batch Acc: 76.56
[Train] Epoch: 0 [546496/620022]    Loss: 0.007779   Batch Acc: 82.81
[Train] Epoch: 0 [546560/620022]    Loss: 0.008948   Batch Acc: 78.12
[Train] Epoch: 0 [546624/620022]    Loss: 0.007531   Batch Acc: 82.81
[Train] Epoch: 0 [546688/620022]    Loss: 0.006555   Batch Acc: 82.81
[Train] Epoch: 0 [546752/620022]    Loss: 0.010709   Batch Acc: 70.31
[Train] Epoch: 0 [546816/620022]    Loss: 0.006141   Batch Acc: 85.94
[Train] Epoch: 0 [546880/620022]    Loss: 0.009337   Batch Acc: 79.69
[Train] Epoch: 0 [546944/620022]    Loss: 0.007044   Batch Acc: 82.81
[Train] Epoch: 0 [547008/620022]    Loss: 0.007973   Batch Acc: 82.81
[Train] Epoch: 0 [547072/620022]    Loss: 0.008165   Batch Acc: 78.12
[Train] Epoch: 0 [547136/620022]    Loss: 0.010229   Batch Acc: 71.88
[Train] Epoch: 0 [547200/620022]    Loss: 0.011086   Batch Acc: 65.62
[Train] Epoch: 0 [547264/620022]    Loss: 0.010586   Batch Acc: 71.88
[Train] Epoch: 0 [547328/620022]    Loss: 0.008129   Batch Acc: 82.81
[Train] Epoch: 0 [547392/620022]    Loss: 0.008102   Batch Acc: 81.25
[Train] Epoch: 0 [547456/620022]    Loss: 0.008051   Batch Acc: 76.56
[Train] Epoch: 0 [547520/620022]    Loss: 0.008357   Batch Acc: 75.00
[Train] Epoch: 0 [547584/620022]    Loss: 0.009329   Batch Acc: 75.00
[Train] Epoch: 0 [547648/620022]    Loss: 0.007747   Batch Acc: 82.81
[Train] Epoch: 0 [547712/620022]    Loss: 0.009126   Batch Acc: 71.88
[Train] Epoch: 0 [547776/620022]    Loss: 0.010319   Batch Acc: 75.00
[Train] Epoch: 0 [547840/620022]    Loss: 0.009831   Batch Acc: 73.44
[Train] Epoch: 0 [547904/620022]    Loss: 0.008446   Batch Acc: 78.12
[Train] Epoch: 0 [547968/620022]    Loss: 0.009268   Batch Acc: 84.38
[Train] Epoch: 0 [548032/620022]    Loss: 0.007211   Batch Acc: 82.81
[Train] Epoch: 0 [548096/620022]    Loss: 0.008060   Batch Acc: 81.25
[Train] Epoch: 0 [548160/620022]    Loss: 0.010146   Batch Acc: 67.19
[Train] Epoch: 0 [548224/620022]    Loss: 0.009943   Batch Acc: 70.31
[Train] Epoch: 0 [548288/620022]    Loss: 0.009000   Batch Acc: 79.69
[Train] Epoch: 0 [548352/620022]    Loss: 0.009068   Batch Acc: 76.56
[Train] Epoch: 0 [548416/620022]    Loss: 0.009902   Batch Acc: 75.00
[Train] Epoch: 0 [548480/620022]    Loss: 0.009013   Batch Acc: 78.12
[Train] Epoch: 0 [548544/620022]    Loss: 0.007097   Batch Acc: 81.25
[Train] Epoch: 0 [548608/620022]    Loss: 0.008989   Batch Acc: 78.12
[Train] Epoch: 0 [548672/620022]    Loss: 0.009795   Batch Acc: 71.88
[Train] Epoch: 0 [548736/620022]    Loss: 0.008925   Batch Acc: 76.56
[Train] Epoch: 0 [548800/620022]    Loss: 0.006844   Batch Acc: 85.94
[Train] Epoch: 0 [548864/620022]    Loss: 0.008011   Batch Acc: 84.38
[Train] Epoch: 0 [548928/620022]    Loss: 0.010221   Batch Acc: 70.31
[Train] Epoch: 0 [548992/620022]    Loss: 0.008741   Batch Acc: 82.81
[Train] Epoch: 0 [549056/620022]    Loss: 0.009476   Batch Acc: 76.56
[Train] Epoch: 0 [549120/620022]    Loss: 0.009787   Batch Acc: 75.00
[Train] Epoch: 0 [549184/620022]    Loss: 0.009606   Batch Acc: 67.19
[Train] Epoch: 0 [549248/620022]    Loss: 0.007946   Batch Acc: 76.56
[Train] Epoch: 0 [549312/620022]    Loss: 0.007799   Batch Acc: 82.81
[Train] Epoch: 0 [549376/620022]    Loss: 0.006923   Batch Acc: 76.56
[Train] Epoch: 0 [549440/620022]    Loss: 0.008616   Batch Acc: 79.69
[Train] Epoch: 0 [549504/620022]    Loss: 0.009165   Batch Acc: 79.69
[Train] Epoch: 0 [549568/620022]    Loss: 0.009847   Batch Acc: 75.00
[Train] Epoch: 0 [549632/620022]    Loss: 0.010882   Batch Acc: 71.88
[Train] Epoch: 0 [549696/620022]    Loss: 0.011265   Batch Acc: 67.19
[Train] Epoch: 0 [549760/620022]    Loss: 0.007909   Batch Acc: 81.25
[Train] Epoch: 0 [549824/620022]    Loss: 0.009106   Batch Acc: 68.75
[Train] Epoch: 0 [549888/620022]    Loss: 0.010380   Batch Acc: 73.44
[Train] Epoch: 0 [549952/620022]    Loss: 0.008276   Batch Acc: 78.12
[Train] Epoch: 0 [550016/620022]    Loss: 0.008260   Batch Acc: 79.69
[Train] Epoch: 0 [550080/620022]    Loss: 0.010370   Batch Acc: 71.88
[Train] Epoch: 0 [550144/620022]    Loss: 0.008496   Batch Acc: 78.12
[Train] Epoch: 0 [550208/620022]    Loss: 0.009819   Batch Acc: 67.19
[Train] Epoch: 0 [550272/620022]    Loss: 0.010221   Batch Acc: 68.75
[Train] Epoch: 0 [550336/620022]    Loss: 0.008533   Batch Acc: 81.25
[Train] Epoch: 0 [550400/620022]    Loss: 0.010372   Batch Acc: 68.75
[Train] Epoch: 0 [550464/620022]    Loss: 0.007842   Batch Acc: 81.25
[Train] Epoch: 0 [550528/620022]    Loss: 0.008572   Batch Acc: 81.25
[Train] Epoch: 0 [550592/620022]    Loss: 0.009863   Batch Acc: 78.12
[Train] Epoch: 0 [550656/620022]    Loss: 0.008200   Batch Acc: 76.56
[Train] Epoch: 0 [550720/620022]    Loss: 0.009796   Batch Acc: 75.00
[Train] Epoch: 0 [550784/620022]    Loss: 0.008536   Batch Acc: 76.56
[Train] Epoch: 0 [550848/620022]    Loss: 0.006445   Batch Acc: 82.81
[Train] Epoch: 0 [550912/620022]    Loss: 0.007228   Batch Acc: 79.69
[Train] Epoch: 0 [550976/620022]    Loss: 0.007812   Batch Acc: 79.69
[Train] Epoch: 0 [551040/620022]    Loss: 0.010878   Batch Acc: 70.31
[Train] Epoch: 0 [551104/620022]    Loss: 0.008830   Batch Acc: 76.56
[Train] Epoch: 0 [551168/620022]    Loss: 0.007430   Batch Acc: 76.56
[Train] Epoch: 0 [551232/620022]    Loss: 0.006961   Batch Acc: 85.94
[Train] Epoch: 0 [551296/620022]    Loss: 0.010477   Batch Acc: 76.56
[Train] Epoch: 0 [551360/620022]    Loss: 0.008105   Batch Acc: 78.12
[Train] Epoch: 0 [551424/620022]    Loss: 0.008630   Batch Acc: 81.25
[Train] Epoch: 0 [551488/620022]    Loss: 0.008003   Batch Acc: 84.38
[Train] Epoch: 0 [551552/620022]    Loss: 0.010902   Batch Acc: 70.31
[Train] Epoch: 0 [551616/620022]    Loss: 0.008528   Batch Acc: 78.12
[Train] Epoch: 0 [551680/620022]    Loss: 0.007978   Batch Acc: 81.25
[Train] Epoch: 0 [551744/620022]    Loss: 0.010509   Batch Acc: 76.56
[Train] Epoch: 0 [551808/620022]    Loss: 0.006787   Batch Acc: 82.81
[Train] Epoch: 0 [551872/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 0 [551936/620022]    Loss: 0.007559   Batch Acc: 81.25
[Train] Epoch: 0 [552000/620022]    Loss: 0.008267   Batch Acc: 78.12
[Train] Epoch: 0 [552064/620022]    Loss: 0.009514   Batch Acc: 75.00
[Train] Epoch: 0 [552128/620022]    Loss: 0.010168   Batch Acc: 73.44
[Train] Epoch: 0 [552192/620022]    Loss: 0.008030   Batch Acc: 79.69
[Train] Epoch: 0 [552256/620022]    Loss: 0.007576   Batch Acc: 81.25
[Train] Epoch: 0 [552320/620022]    Loss: 0.007967   Batch Acc: 82.81
[Train] Epoch: 0 [552384/620022]    Loss: 0.007616   Batch Acc: 78.12
[Train] Epoch: 0 [552448/620022]    Loss: 0.008154   Batch Acc: 78.12
[Train] Epoch: 0 [552512/620022]    Loss: 0.007505   Batch Acc: 82.81
[Train] Epoch: 0 [552576/620022]    Loss: 0.007716   Batch Acc: 81.25
[Train] Epoch: 0 [552640/620022]    Loss: 0.007040   Batch Acc: 84.38
[Train] Epoch: 0 [552704/620022]    Loss: 0.008896   Batch Acc: 76.56
[Train] Epoch: 0 [552768/620022]    Loss: 0.007274   Batch Acc: 82.81
[Train] Epoch: 0 [552832/620022]    Loss: 0.009557   Batch Acc: 79.69
[Train] Epoch: 0 [552896/620022]    Loss: 0.011034   Batch Acc: 68.75
[Train] Epoch: 0 [552960/620022]    Loss: 0.008511   Batch Acc: 81.25
[Train] Epoch: 0 [553024/620022]    Loss: 0.009659   Batch Acc: 73.44
[Train] Epoch: 0 [553088/620022]    Loss: 0.009079   Batch Acc: 81.25
[Train] Epoch: 0 [553152/620022]    Loss: 0.008017   Batch Acc: 82.81
[Train] Epoch: 0 [553216/620022]    Loss: 0.008776   Batch Acc: 76.56
[Train] Epoch: 0 [553280/620022]    Loss: 0.008878   Batch Acc: 73.44
[Train] Epoch: 0 [553344/620022]    Loss: 0.007804   Batch Acc: 79.69
[Train] Epoch: 0 [553408/620022]    Loss: 0.009298   Batch Acc: 76.56
[Train] Epoch: 0 [553472/620022]    Loss: 0.009806   Batch Acc: 75.00
[Train] Epoch: 0 [553536/620022]    Loss: 0.006710   Batch Acc: 84.38
[Train] Epoch: 0 [553600/620022]    Loss: 0.010898   Batch Acc: 65.62
[Train] Epoch: 0 [553664/620022]    Loss: 0.007474   Batch Acc: 90.62
[Train] Epoch: 0 [553728/620022]    Loss: 0.010617   Batch Acc: 68.75
[Train] Epoch: 0 [553792/620022]    Loss: 0.008270   Batch Acc: 85.94
[Train] Epoch: 0 [553856/620022]    Loss: 0.008032   Batch Acc: 85.94
[Train] Epoch: 0 [553920/620022]    Loss: 0.008536   Batch Acc: 81.25
[Train] Epoch: 0 [553984/620022]    Loss: 0.009756   Batch Acc: 78.12
[Train] Epoch: 0 [554048/620022]    Loss: 0.008097   Batch Acc: 79.69
[Train] Epoch: 0 [554112/620022]    Loss: 0.008471   Batch Acc: 76.56
[Train] Epoch: 0 [554176/620022]    Loss: 0.007303   Batch Acc: 82.81
[Train] Epoch: 0 [554240/620022]    Loss: 0.009424   Batch Acc: 78.12
[Train] Epoch: 0 [554304/620022]    Loss: 0.009397   Batch Acc: 75.00
[Train] Epoch: 0 [554368/620022]    Loss: 0.008545   Batch Acc: 71.88
[Train] Epoch: 0 [554432/620022]    Loss: 0.008975   Batch Acc: 73.44
[Train] Epoch: 0 [554496/620022]    Loss: 0.007516   Batch Acc: 82.81
[Train] Epoch: 0 [554560/620022]    Loss: 0.008334   Batch Acc: 81.25
[Train] Epoch: 0 [554624/620022]    Loss: 0.007242   Batch Acc: 87.50
[Train] Epoch: 0 [554688/620022]    Loss: 0.008106   Batch Acc: 78.12
[Train] Epoch: 0 [554752/620022]    Loss: 0.010922   Batch Acc: 70.31
[Train] Epoch: 0 [554816/620022]    Loss: 0.008031   Batch Acc: 79.69
[Train] Epoch: 0 [554880/620022]    Loss: 0.007905   Batch Acc: 79.69
[Train] Epoch: 0 [554944/620022]    Loss: 0.009812   Batch Acc: 78.12
[Train] Epoch: 0 [555008/620022]    Loss: 0.010380   Batch Acc: 70.31
[Train] Epoch: 0 [555072/620022]    Loss: 0.007828   Batch Acc: 85.94
[Train] Epoch: 0 [555136/620022]    Loss: 0.008519   Batch Acc: 79.69
[Train] Epoch: 0 [555200/620022]    Loss: 0.008917   Batch Acc: 76.56
[Train] Epoch: 0 [555264/620022]    Loss: 0.010440   Batch Acc: 65.62
[Train] Epoch: 0 [555328/620022]    Loss: 0.009271   Batch Acc: 68.75
[Train] Epoch: 0 [555392/620022]    Loss: 0.010127   Batch Acc: 71.88
[Train] Epoch: 0 [555456/620022]    Loss: 0.007975   Batch Acc: 76.56
[Train] Epoch: 0 [555520/620022]    Loss: 0.008237   Batch Acc: 82.81
[Train] Epoch: 0 [555584/620022]    Loss: 0.007969   Batch Acc: 82.81
[Train] Epoch: 0 [555648/620022]    Loss: 0.007919   Batch Acc: 78.12
[Train] Epoch: 0 [555712/620022]    Loss: 0.007655   Batch Acc: 81.25
[Train] Epoch: 0 [555776/620022]    Loss: 0.009554   Batch Acc: 71.88
[Train] Epoch: 0 [555840/620022]    Loss: 0.009209   Batch Acc: 75.00
[Train] Epoch: 0 [555904/620022]    Loss: 0.009030   Batch Acc: 78.12
[Train] Epoch: 0 [555968/620022]    Loss: 0.011940   Batch Acc: 62.50
[Train] Epoch: 0 [556032/620022]    Loss: 0.010688   Batch Acc: 71.88
[Train] Epoch: 0 [556096/620022]    Loss: 0.010026   Batch Acc: 79.69
[Train] Epoch: 0 [556160/620022]    Loss: 0.009407   Batch Acc: 78.12
[Train] Epoch: 0 [556224/620022]    Loss: 0.011150   Batch Acc: 67.19
[Train] Epoch: 0 [556288/620022]    Loss: 0.010819   Batch Acc: 71.88
[Train] Epoch: 0 [556352/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 0 [556416/620022]    Loss: 0.007285   Batch Acc: 81.25
[Train] Epoch: 0 [556480/620022]    Loss: 0.009003   Batch Acc: 73.44
[Train] Epoch: 0 [556544/620022]    Loss: 0.007689   Batch Acc: 82.81
[Train] Epoch: 0 [556608/620022]    Loss: 0.009246   Batch Acc: 76.56
[Train] Epoch: 0 [556672/620022]    Loss: 0.009298   Batch Acc: 79.69
[Train] Epoch: 0 [556736/620022]    Loss: 0.009688   Batch Acc: 75.00
[Train] Epoch: 0 [556800/620022]    Loss: 0.009412   Batch Acc: 73.44
[Train] Epoch: 0 [556864/620022]    Loss: 0.009628   Batch Acc: 73.44
[Train] Epoch: 0 [556928/620022]    Loss: 0.007819   Batch Acc: 82.81
[Train] Epoch: 0 [556992/620022]    Loss: 0.008199   Batch Acc: 79.69
[Train] Epoch: 0 [557056/620022]    Loss: 0.008844   Batch Acc: 75.00
[Train] Epoch: 0 [557120/620022]    Loss: 0.009240   Batch Acc: 75.00
[Train] Epoch: 0 [557184/620022]    Loss: 0.009827   Batch Acc: 75.00
[Train] Epoch: 0 [557248/620022]    Loss: 0.009767   Batch Acc: 75.00
[Train] Epoch: 0 [557312/620022]    Loss: 0.008829   Batch Acc: 79.69
[Train] Epoch: 0 [557376/620022]    Loss: 0.008117   Batch Acc: 82.81
[Train] Epoch: 0 [557440/620022]    Loss: 0.008426   Batch Acc: 81.25
[Train] Epoch: 0 [557504/620022]    Loss: 0.010823   Batch Acc: 70.31
[Train] Epoch: 0 [557568/620022]    Loss: 0.010376   Batch Acc: 73.44
[Train] Epoch: 0 [557632/620022]    Loss: 0.006803   Batch Acc: 82.81
[Train] Epoch: 0 [557696/620022]    Loss: 0.008317   Batch Acc: 79.69
[Train] Epoch: 0 [557760/620022]    Loss: 0.009695   Batch Acc: 76.56
[Train] Epoch: 0 [557824/620022]    Loss: 0.009499   Batch Acc: 75.00
[Train] Epoch: 0 [557888/620022]    Loss: 0.010820   Batch Acc: 70.31
[Train] Epoch: 0 [557952/620022]    Loss: 0.009899   Batch Acc: 76.56
[Train] Epoch: 0 [558016/620022]    Loss: 0.010295   Batch Acc: 76.56
[Train] Epoch: 0 [558080/620022]    Loss: 0.007520   Batch Acc: 82.81
[Train] Epoch: 0 [558144/620022]    Loss: 0.009336   Batch Acc: 73.44
[Train] Epoch: 0 [558208/620022]    Loss: 0.010103   Batch Acc: 68.75
[Train] Epoch: 0 [558272/620022]    Loss: 0.007316   Batch Acc: 84.38
[Train] Epoch: 0 [558336/620022]    Loss: 0.007528   Batch Acc: 81.25
[Train] Epoch: 0 [558400/620022]    Loss: 0.008014   Batch Acc: 81.25
[Train] Epoch: 0 [558464/620022]    Loss: 0.009348   Batch Acc: 70.31
[Train] Epoch: 0 [558528/620022]    Loss: 0.009167   Batch Acc: 73.44
[Train] Epoch: 0 [558592/620022]    Loss: 0.007128   Batch Acc: 79.69
[Train] Epoch: 0 [558656/620022]    Loss: 0.008205   Batch Acc: 81.25
[Train] Epoch: 0 [558720/620022]    Loss: 0.006246   Batch Acc: 87.50
[Train] Epoch: 0 [558784/620022]    Loss: 0.012005   Batch Acc: 71.88
[Train] Epoch: 0 [558848/620022]    Loss: 0.009177   Batch Acc: 76.56
[Train] Epoch: 0 [558912/620022]    Loss: 0.010649   Batch Acc: 71.88
[Train] Epoch: 0 [558976/620022]    Loss: 0.008508   Batch Acc: 75.00
[Train] Epoch: 0 [559040/620022]    Loss: 0.010422   Batch Acc: 71.88
[Train] Epoch: 0 [559104/620022]    Loss: 0.007773   Batch Acc: 82.81
[Train] Epoch: 0 [559168/620022]    Loss: 0.009327   Batch Acc: 78.12
[Train] Epoch: 0 [559232/620022]    Loss: 0.009012   Batch Acc: 71.88
[Train] Epoch: 0 [559296/620022]    Loss: 0.009997   Batch Acc: 75.00
[Train] Epoch: 0 [559360/620022]    Loss: 0.009710   Batch Acc: 81.25
[Train] Epoch: 0 [559424/620022]    Loss: 0.008527   Batch Acc: 79.69
[Train] Epoch: 0 [559488/620022]    Loss: 0.008254   Batch Acc: 81.25
[Train] Epoch: 0 [559552/620022]    Loss: 0.008278   Batch Acc: 78.12
[Train] Epoch: 0 [559616/620022]    Loss: 0.009599   Batch Acc: 70.31
[Train] Epoch: 0 [559680/620022]    Loss: 0.007532   Batch Acc: 79.69
[Train] Epoch: 0 [559744/620022]    Loss: 0.010220   Batch Acc: 73.44
[Train] Epoch: 0 [559808/620022]    Loss: 0.009125   Batch Acc: 76.56
[Train] Epoch: 0 [559872/620022]    Loss: 0.010426   Batch Acc: 70.31
[Train] Epoch: 0 [559936/620022]    Loss: 0.007456   Batch Acc: 79.69
[Train] Epoch: 0 [560000/620022]    Loss: 0.007765   Batch Acc: 85.94
[Train] Epoch: 0 [560064/620022]    Loss: 0.008710   Batch Acc: 78.12
[Train] Epoch: 0 [560128/620022]    Loss: 0.006512   Batch Acc: 82.81
[Train] Epoch: 0 [560192/620022]    Loss: 0.008041   Batch Acc: 81.25
[Train] Epoch: 0 [560256/620022]    Loss: 0.007826   Batch Acc: 82.81
[Train] Epoch: 0 [560320/620022]    Loss: 0.007709   Batch Acc: 81.25
[Train] Epoch: 0 [560384/620022]    Loss: 0.011608   Batch Acc: 65.62
[Train] Epoch: 0 [560448/620022]    Loss: 0.007405   Batch Acc: 81.25
[Train] Epoch: 0 [560512/620022]    Loss: 0.010247   Batch Acc: 68.75
[Train] Epoch: 0 [560576/620022]    Loss: 0.009765   Batch Acc: 79.69
[Train] Epoch: 0 [560640/620022]    Loss: 0.008838   Batch Acc: 76.56
[Train] Epoch: 0 [560704/620022]    Loss: 0.009064   Batch Acc: 71.88
[Train] Epoch: 0 [560768/620022]    Loss: 0.010668   Batch Acc: 73.44
[Train] Epoch: 0 [560832/620022]    Loss: 0.007761   Batch Acc: 82.81
[Train] Epoch: 0 [560896/620022]    Loss: 0.008940   Batch Acc: 81.25
[Train] Epoch: 0 [560960/620022]    Loss: 0.009024   Batch Acc: 79.69
[Train] Epoch: 0 [561024/620022]    Loss: 0.007409   Batch Acc: 85.94
[Train] Epoch: 0 [561088/620022]    Loss: 0.009870   Batch Acc: 70.31
[Train] Epoch: 0 [561152/620022]    Loss: 0.011965   Batch Acc: 67.19
[Train] Epoch: 0 [561216/620022]    Loss: 0.007586   Batch Acc: 78.12
[Train] Epoch: 0 [561280/620022]    Loss: 0.007566   Batch Acc: 79.69
[Train] Epoch: 0 [561344/620022]    Loss: 0.007762   Batch Acc: 82.81
[Train] Epoch: 0 [561408/620022]    Loss: 0.011858   Batch Acc: 70.31
[Train] Epoch: 0 [561472/620022]    Loss: 0.007744   Batch Acc: 82.81
[Train] Epoch: 0 [561536/620022]    Loss: 0.009094   Batch Acc: 78.12
[Train] Epoch: 0 [561600/620022]    Loss: 0.007082   Batch Acc: 81.25
[Train] Epoch: 0 [561664/620022]    Loss: 0.008359   Batch Acc: 73.44
[Train] Epoch: 0 [561728/620022]    Loss: 0.009884   Batch Acc: 70.31
[Train] Epoch: 0 [561792/620022]    Loss: 0.010236   Batch Acc: 75.00
[Train] Epoch: 0 [561856/620022]    Loss: 0.012785   Batch Acc: 67.19
[Train] Epoch: 0 [561920/620022]    Loss: 0.007868   Batch Acc: 82.81
[Train] Epoch: 0 [561984/620022]    Loss: 0.009782   Batch Acc: 68.75
[Train] Epoch: 0 [562048/620022]    Loss: 0.009414   Batch Acc: 71.88
[Train] Epoch: 0 [562112/620022]    Loss: 0.007020   Batch Acc: 81.25
[Train] Epoch: 0 [562176/620022]    Loss: 0.009262   Batch Acc: 79.69
[Train] Epoch: 0 [562240/620022]    Loss: 0.009365   Batch Acc: 79.69
[Train] Epoch: 0 [562304/620022]    Loss: 0.008023   Batch Acc: 81.25
[Train] Epoch: 0 [562368/620022]    Loss: 0.007618   Batch Acc: 79.69
[Train] Epoch: 0 [562432/620022]    Loss: 0.006863   Batch Acc: 85.94
[Train] Epoch: 0 [562496/620022]    Loss: 0.009636   Batch Acc: 70.31
[Train] Epoch: 0 [562560/620022]    Loss: 0.009774   Batch Acc: 76.56
[Train] Epoch: 0 [562624/620022]    Loss: 0.009933   Batch Acc: 73.44
[Train] Epoch: 0 [562688/620022]    Loss: 0.009813   Batch Acc: 73.44
[Train] Epoch: 0 [562752/620022]    Loss: 0.012320   Batch Acc: 68.75
[Train] Epoch: 0 [562816/620022]    Loss: 0.010337   Batch Acc: 68.75
[Train] Epoch: 0 [562880/620022]    Loss: 0.007292   Batch Acc: 81.25
[Train] Epoch: 0 [562944/620022]    Loss: 0.009146   Batch Acc: 76.56
[Train] Epoch: 0 [563008/620022]    Loss: 0.008541   Batch Acc: 79.69
[Train] Epoch: 0 [563072/620022]    Loss: 0.009511   Batch Acc: 76.56
[Train] Epoch: 0 [563136/620022]    Loss: 0.010291   Batch Acc: 71.88
[Train] Epoch: 0 [563200/620022]    Loss: 0.008127   Batch Acc: 85.94
[Train] Epoch: 0 [563264/620022]    Loss: 0.009739   Batch Acc: 71.88
[Train] Epoch: 0 [563328/620022]    Loss: 0.009111   Batch Acc: 73.44
[Train] Epoch: 0 [563392/620022]    Loss: 0.009029   Batch Acc: 75.00
[Train] Epoch: 0 [563456/620022]    Loss: 0.008402   Batch Acc: 76.56
[Train] Epoch: 0 [563520/620022]    Loss: 0.009558   Batch Acc: 78.12
[Train] Epoch: 0 [563584/620022]    Loss: 0.008755   Batch Acc: 71.88
[Train] Epoch: 0 [563648/620022]    Loss: 0.007063   Batch Acc: 82.81
[Train] Epoch: 0 [563712/620022]    Loss: 0.009428   Batch Acc: 71.88
[Train] Epoch: 0 [563776/620022]    Loss: 0.009242   Batch Acc: 70.31
[Train] Epoch: 0 [563840/620022]    Loss: 0.009979   Batch Acc: 78.12
[Train] Epoch: 0 [563904/620022]    Loss: 0.009222   Batch Acc: 75.00
[Train] Epoch: 0 [563968/620022]    Loss: 0.008130   Batch Acc: 81.25
[Train] Epoch: 0 [564032/620022]    Loss: 0.009315   Batch Acc: 78.12
[Train] Epoch: 0 [564096/620022]    Loss: 0.007444   Batch Acc: 82.81
[Train] Epoch: 0 [564160/620022]    Loss: 0.006930   Batch Acc: 79.69
[Train] Epoch: 0 [564224/620022]    Loss: 0.008613   Batch Acc: 73.44
[Train] Epoch: 0 [564288/620022]    Loss: 0.008096   Batch Acc: 84.38
[Train] Epoch: 0 [564352/620022]    Loss: 0.007961   Batch Acc: 76.56
[Train] Epoch: 0 [564416/620022]    Loss: 0.009356   Batch Acc: 76.56
[Train] Epoch: 0 [564480/620022]    Loss: 0.008565   Batch Acc: 81.25
[Train] Epoch: 0 [564544/620022]    Loss: 0.011630   Batch Acc: 67.19
[Train] Epoch: 0 [564608/620022]    Loss: 0.007726   Batch Acc: 81.25
[Train] Epoch: 0 [564672/620022]    Loss: 0.008004   Batch Acc: 75.00
[Train] Epoch: 0 [564736/620022]    Loss: 0.007760   Batch Acc: 82.81
[Train] Epoch: 0 [564800/620022]    Loss: 0.007250   Batch Acc: 87.50
[Train] Epoch: 0 [564864/620022]    Loss: 0.005688   Batch Acc: 89.06
[Train] Epoch: 0 [564928/620022]    Loss: 0.008545   Batch Acc: 79.69
[Train] Epoch: 0 [564992/620022]    Loss: 0.010413   Batch Acc: 78.12
[Train] Epoch: 0 [565056/620022]    Loss: 0.011239   Batch Acc: 75.00
[Train] Epoch: 0 [565120/620022]    Loss: 0.009304   Batch Acc: 73.44
[Train] Epoch: 0 [565184/620022]    Loss: 0.006904   Batch Acc: 84.38
[Train] Epoch: 0 [565248/620022]    Loss: 0.007768   Batch Acc: 81.25
[Train] Epoch: 0 [565312/620022]    Loss: 0.009506   Batch Acc: 75.00
[Train] Epoch: 0 [565376/620022]    Loss: 0.006349   Batch Acc: 84.38
[Train] Epoch: 0 [565440/620022]    Loss: 0.006875   Batch Acc: 85.94
[Train] Epoch: 0 [565504/620022]    Loss: 0.009066   Batch Acc: 75.00
[Train] Epoch: 0 [565568/620022]    Loss: 0.009325   Batch Acc: 71.88
[Train] Epoch: 0 [565632/620022]    Loss: 0.009432   Batch Acc: 76.56
[Train] Epoch: 0 [565696/620022]    Loss: 0.006482   Batch Acc: 87.50
[Train] Epoch: 0 [565760/620022]    Loss: 0.008507   Batch Acc: 76.56
[Train] Epoch: 0 [565824/620022]    Loss: 0.008189   Batch Acc: 81.25
[Train] Epoch: 0 [565888/620022]    Loss: 0.012013   Batch Acc: 71.88
[Train] Epoch: 0 [565952/620022]    Loss: 0.009261   Batch Acc: 76.56
[Train] Epoch: 0 [566016/620022]    Loss: 0.009306   Batch Acc: 71.88
[Train] Epoch: 0 [566080/620022]    Loss: 0.010164   Batch Acc: 73.44
[Train] Epoch: 0 [566144/620022]    Loss: 0.007193   Batch Acc: 81.25
[Train] Epoch: 0 [566208/620022]    Loss: 0.010765   Batch Acc: 68.75
[Train] Epoch: 0 [566272/620022]    Loss: 0.009019   Batch Acc: 81.25
[Train] Epoch: 0 [566336/620022]    Loss: 0.009899   Batch Acc: 71.88
[Train] Epoch: 0 [566400/620022]    Loss: 0.007865   Batch Acc: 78.12
[Train] Epoch: 0 [566464/620022]    Loss: 0.007145   Batch Acc: 84.38
[Train] Epoch: 0 [566528/620022]    Loss: 0.009703   Batch Acc: 73.44
[Train] Epoch: 0 [566592/620022]    Loss: 0.009484   Batch Acc: 75.00
[Train] Epoch: 0 [566656/620022]    Loss: 0.009223   Batch Acc: 81.25
[Train] Epoch: 0 [566720/620022]    Loss: 0.007314   Batch Acc: 85.94
[Train] Epoch: 0 [566784/620022]    Loss: 0.008319   Batch Acc: 81.25
[Train] Epoch: 0 [566848/620022]    Loss: 0.010712   Batch Acc: 60.94
[Train] Epoch: 0 [566912/620022]    Loss: 0.008039   Batch Acc: 78.12
[Train] Epoch: 0 [566976/620022]    Loss: 0.008307   Batch Acc: 71.88
[Train] Epoch: 0 [567040/620022]    Loss: 0.010911   Batch Acc: 62.50
[Train] Epoch: 0 [567104/620022]    Loss: 0.010104   Batch Acc: 75.00
[Train] Epoch: 0 [567168/620022]    Loss: 0.008777   Batch Acc: 81.25
[Train] Epoch: 0 [567232/620022]    Loss: 0.009418   Batch Acc: 76.56
[Train] Epoch: 0 [567296/620022]    Loss: 0.010299   Batch Acc: 76.56
[Train] Epoch: 0 [567360/620022]    Loss: 0.006899   Batch Acc: 84.38
[Train] Epoch: 0 [567424/620022]    Loss: 0.009474   Batch Acc: 73.44
[Train] Epoch: 0 [567488/620022]    Loss: 0.011449   Batch Acc: 70.31
[Train] Epoch: 0 [567552/620022]    Loss: 0.010188   Batch Acc: 71.88
[Train] Epoch: 0 [567616/620022]    Loss: 0.009167   Batch Acc: 75.00
[Train] Epoch: 0 [567680/620022]    Loss: 0.007805   Batch Acc: 76.56
[Train] Epoch: 0 [567744/620022]    Loss: 0.007376   Batch Acc: 81.25
[Train] Epoch: 0 [567808/620022]    Loss: 0.008025   Batch Acc: 78.12
[Train] Epoch: 0 [567872/620022]    Loss: 0.008337   Batch Acc: 78.12
[Train] Epoch: 0 [567936/620022]    Loss: 0.009075   Batch Acc: 78.12
[Train] Epoch: 0 [568000/620022]    Loss: 0.008420   Batch Acc: 82.81
[Train] Epoch: 0 [568064/620022]    Loss: 0.008345   Batch Acc: 79.69
[Train] Epoch: 0 [568128/620022]    Loss: 0.010393   Batch Acc: 73.44
[Train] Epoch: 0 [568192/620022]    Loss: 0.008461   Batch Acc: 71.88
[Train] Epoch: 0 [568256/620022]    Loss: 0.008236   Batch Acc: 81.25
[Train] Epoch: 0 [568320/620022]    Loss: 0.009679   Batch Acc: 76.56
[Train] Epoch: 0 [568384/620022]    Loss: 0.008451   Batch Acc: 79.69
[Train] Epoch: 0 [568448/620022]    Loss: 0.010701   Batch Acc: 68.75
[Train] Epoch: 0 [568512/620022]    Loss: 0.007644   Batch Acc: 87.50
[Train] Epoch: 0 [568576/620022]    Loss: 0.008905   Batch Acc: 73.44
[Train] Epoch: 0 [568640/620022]    Loss: 0.008146   Batch Acc: 81.25
[Train] Epoch: 0 [568704/620022]    Loss: 0.012294   Batch Acc: 71.88
[Train] Epoch: 0 [568768/620022]    Loss: 0.005716   Batch Acc: 89.06
[Train] Epoch: 0 [568832/620022]    Loss: 0.010131   Batch Acc: 70.31
[Train] Epoch: 0 [568896/620022]    Loss: 0.008349   Batch Acc: 78.12
[Train] Epoch: 0 [568960/620022]    Loss: 0.009572   Batch Acc: 76.56
[Train] Epoch: 0 [569024/620022]    Loss: 0.010457   Batch Acc: 71.88
[Train] Epoch: 0 [569088/620022]    Loss: 0.009621   Batch Acc: 76.56
[Train] Epoch: 0 [569152/620022]    Loss: 0.010044   Batch Acc: 75.00
[Train] Epoch: 0 [569216/620022]    Loss: 0.009933   Batch Acc: 75.00
[Train] Epoch: 0 [569280/620022]    Loss: 0.011124   Batch Acc: 67.19
[Train] Epoch: 0 [569344/620022]    Loss: 0.009032   Batch Acc: 78.12
[Train] Epoch: 0 [569408/620022]    Loss: 0.008756   Batch Acc: 78.12
[Train] Epoch: 0 [569472/620022]    Loss: 0.007287   Batch Acc: 84.38
[Train] Epoch: 0 [569536/620022]    Loss: 0.008915   Batch Acc: 78.12
[Train] Epoch: 0 [569600/620022]    Loss: 0.008349   Batch Acc: 78.12
[Train] Epoch: 0 [569664/620022]    Loss: 0.008975   Batch Acc: 73.44
[Train] Epoch: 0 [569728/620022]    Loss: 0.009051   Batch Acc: 81.25
[Train] Epoch: 0 [569792/620022]    Loss: 0.007618   Batch Acc: 79.69
[Train] Epoch: 0 [569856/620022]    Loss: 0.010060   Batch Acc: 71.88
[Train] Epoch: 0 [569920/620022]    Loss: 0.010493   Batch Acc: 67.19
[Train] Epoch: 0 [569984/620022]    Loss: 0.006727   Batch Acc: 89.06
[Train] Epoch: 0 [570048/620022]    Loss: 0.009829   Batch Acc: 73.44
[Train] Epoch: 0 [570112/620022]    Loss: 0.010632   Batch Acc: 73.44
[Train] Epoch: 0 [570176/620022]    Loss: 0.009086   Batch Acc: 79.69
[Train] Epoch: 0 [570240/620022]    Loss: 0.012139   Batch Acc: 71.88
[Train] Epoch: 0 [570304/620022]    Loss: 0.008984   Batch Acc: 78.12
[Train] Epoch: 0 [570368/620022]    Loss: 0.008167   Batch Acc: 82.81
[Train] Epoch: 0 [570432/620022]    Loss: 0.011860   Batch Acc: 67.19
[Train] Epoch: 0 [570496/620022]    Loss: 0.006988   Batch Acc: 85.94
[Train] Epoch: 0 [570560/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 0 [570624/620022]    Loss: 0.009984   Batch Acc: 70.31
[Train] Epoch: 0 [570688/620022]    Loss: 0.007585   Batch Acc: 84.38
[Train] Epoch: 0 [570752/620022]    Loss: 0.007424   Batch Acc: 84.38
[Train] Epoch: 0 [570816/620022]    Loss: 0.007613   Batch Acc: 81.25
[Train] Epoch: 0 [570880/620022]    Loss: 0.008544   Batch Acc: 79.69
[Train] Epoch: 0 [570944/620022]    Loss: 0.010082   Batch Acc: 75.00
[Train] Epoch: 0 [571008/620022]    Loss: 0.008077   Batch Acc: 78.12
[Train] Epoch: 0 [571072/620022]    Loss: 0.009776   Batch Acc: 71.88
[Train] Epoch: 0 [571136/620022]    Loss: 0.010622   Batch Acc: 67.19
[Train] Epoch: 0 [571200/620022]    Loss: 0.008246   Batch Acc: 81.25
[Train] Epoch: 0 [571264/620022]    Loss: 0.009124   Batch Acc: 75.00
[Train] Epoch: 0 [571328/620022]    Loss: 0.009574   Batch Acc: 73.44
[Train] Epoch: 0 [571392/620022]    Loss: 0.007756   Batch Acc: 84.38
[Train] Epoch: 0 [571456/620022]    Loss: 0.008859   Batch Acc: 78.12
[Train] Epoch: 0 [571520/620022]    Loss: 0.007400   Batch Acc: 82.81
[Train] Epoch: 0 [571584/620022]    Loss: 0.010777   Batch Acc: 73.44
[Train] Epoch: 0 [571648/620022]    Loss: 0.005408   Batch Acc: 85.94
[Train] Epoch: 0 [571712/620022]    Loss: 0.007609   Batch Acc: 78.12
[Train] Epoch: 0 [571776/620022]    Loss: 0.006324   Batch Acc: 89.06
[Train] Epoch: 0 [571840/620022]    Loss: 0.009587   Batch Acc: 81.25
[Train] Epoch: 0 [571904/620022]    Loss: 0.010742   Batch Acc: 75.00
[Train] Epoch: 0 [571968/620022]    Loss: 0.007449   Batch Acc: 87.50
[Train] Epoch: 0 [572032/620022]    Loss: 0.008907   Batch Acc: 79.69
[Train] Epoch: 0 [572096/620022]    Loss: 0.009766   Batch Acc: 78.12
[Train] Epoch: 0 [572160/620022]    Loss: 0.005655   Batch Acc: 90.62
[Train] Epoch: 0 [572224/620022]    Loss: 0.010901   Batch Acc: 68.75
[Train] Epoch: 0 [572288/620022]    Loss: 0.008644   Batch Acc: 81.25
[Train] Epoch: 0 [572352/620022]    Loss: 0.007233   Batch Acc: 85.94
[Train] Epoch: 0 [572416/620022]    Loss: 0.008114   Batch Acc: 76.56
[Train] Epoch: 0 [572480/620022]    Loss: 0.006216   Batch Acc: 84.38
[Train] Epoch: 0 [572544/620022]    Loss: 0.006550   Batch Acc: 89.06
[Train] Epoch: 0 [572608/620022]    Loss: 0.010377   Batch Acc: 71.88
[Train] Epoch: 0 [572672/620022]    Loss: 0.009881   Batch Acc: 79.69
[Train] Epoch: 0 [572736/620022]    Loss: 0.007882   Batch Acc: 82.81
[Train] Epoch: 0 [572800/620022]    Loss: 0.011102   Batch Acc: 64.06
[Train] Epoch: 0 [572864/620022]    Loss: 0.009116   Batch Acc: 71.88
[Train] Epoch: 0 [572928/620022]    Loss: 0.012593   Batch Acc: 67.19
[Train] Epoch: 0 [572992/620022]    Loss: 0.008663   Batch Acc: 84.38
[Train] Epoch: 0 [573056/620022]    Loss: 0.006557   Batch Acc: 82.81
[Train] Epoch: 0 [573120/620022]    Loss: 0.008574   Batch Acc: 81.25
[Train] Epoch: 0 [573184/620022]    Loss: 0.008089   Batch Acc: 76.56
[Train] Epoch: 0 [573248/620022]    Loss: 0.008088   Batch Acc: 79.69
[Train] Epoch: 0 [573312/620022]    Loss: 0.008423   Batch Acc: 79.69
[Train] Epoch: 0 [573376/620022]    Loss: 0.008459   Batch Acc: 78.12
[Train] Epoch: 0 [573440/620022]    Loss: 0.009428   Batch Acc: 73.44
[Train] Epoch: 0 [573504/620022]    Loss: 0.009587   Batch Acc: 79.69
[Train] Epoch: 0 [573568/620022]    Loss: 0.008099   Batch Acc: 76.56
[Train] Epoch: 0 [573632/620022]    Loss: 0.009830   Batch Acc: 73.44
[Train] Epoch: 0 [573696/620022]    Loss: 0.011126   Batch Acc: 68.75
[Train] Epoch: 0 [573760/620022]    Loss: 0.007731   Batch Acc: 73.44
[Train] Epoch: 0 [573824/620022]    Loss: 0.010569   Batch Acc: 71.88
[Train] Epoch: 0 [573888/620022]    Loss: 0.008086   Batch Acc: 81.25
[Train] Epoch: 0 [573952/620022]    Loss: 0.008372   Batch Acc: 76.56
[Train] Epoch: 0 [574016/620022]    Loss: 0.008808   Batch Acc: 82.81
[Train] Epoch: 0 [574080/620022]    Loss: 0.008631   Batch Acc: 73.44
[Train] Epoch: 0 [574144/620022]    Loss: 0.007144   Batch Acc: 85.94
[Train] Epoch: 0 [574208/620022]    Loss: 0.007760   Batch Acc: 85.94
[Train] Epoch: 0 [574272/620022]    Loss: 0.008132   Batch Acc: 79.69
[Train] Epoch: 0 [574336/620022]    Loss: 0.008467   Batch Acc: 78.12
[Train] Epoch: 0 [574400/620022]    Loss: 0.008058   Batch Acc: 76.56
[Train] Epoch: 0 [574464/620022]    Loss: 0.009152   Batch Acc: 71.88
[Train] Epoch: 0 [574528/620022]    Loss: 0.010333   Batch Acc: 68.75
[Train] Epoch: 0 [574592/620022]    Loss: 0.008300   Batch Acc: 85.94
[Train] Epoch: 0 [574656/620022]    Loss: 0.007358   Batch Acc: 78.12
[Train] Epoch: 0 [574720/620022]    Loss: 0.009173   Batch Acc: 75.00
[Train] Epoch: 0 [574784/620022]    Loss: 0.008927   Batch Acc: 75.00
[Train] Epoch: 0 [574848/620022]    Loss: 0.008197   Batch Acc: 78.12
[Train] Epoch: 0 [574912/620022]    Loss: 0.007618   Batch Acc: 87.50
[Train] Epoch: 0 [574976/620022]    Loss: 0.008757   Batch Acc: 81.25
[Train] Epoch: 0 [575040/620022]    Loss: 0.007714   Batch Acc: 89.06
[Train] Epoch: 0 [575104/620022]    Loss: 0.008439   Batch Acc: 79.69
[Train] Epoch: 0 [575168/620022]    Loss: 0.007786   Batch Acc: 75.00
[Train] Epoch: 0 [575232/620022]    Loss: 0.009463   Batch Acc: 76.56
[Train] Epoch: 0 [575296/620022]    Loss: 0.008456   Batch Acc: 78.12
[Train] Epoch: 0 [575360/620022]    Loss: 0.007621   Batch Acc: 84.38
[Train] Epoch: 0 [575424/620022]    Loss: 0.007256   Batch Acc: 79.69
[Train] Epoch: 0 [575488/620022]    Loss: 0.006559   Batch Acc: 89.06
[Train] Epoch: 0 [575552/620022]    Loss: 0.009008   Batch Acc: 82.81
[Train] Epoch: 0 [575616/620022]    Loss: 0.007683   Batch Acc: 81.25
[Train] Epoch: 0 [575680/620022]    Loss: 0.010425   Batch Acc: 75.00
[Train] Epoch: 0 [575744/620022]    Loss: 0.009705   Batch Acc: 73.44
[Train] Epoch: 0 [575808/620022]    Loss: 0.009732   Batch Acc: 73.44
[Train] Epoch: 0 [575872/620022]    Loss: 0.007327   Batch Acc: 79.69
[Train] Epoch: 0 [575936/620022]    Loss: 0.009104   Batch Acc: 76.56
[Train] Epoch: 0 [576000/620022]    Loss: 0.006606   Batch Acc: 84.38
[Train] Epoch: 0 [576064/620022]    Loss: 0.007995   Batch Acc: 81.25
[Train] Epoch: 0 [576128/620022]    Loss: 0.009835   Batch Acc: 71.88
[Train] Epoch: 0 [576192/620022]    Loss: 0.009189   Batch Acc: 75.00
[Train] Epoch: 0 [576256/620022]    Loss: 0.008450   Batch Acc: 73.44
[Train] Epoch: 0 [576320/620022]    Loss: 0.010432   Batch Acc: 76.56
[Train] Epoch: 0 [576384/620022]    Loss: 0.007775   Batch Acc: 81.25
[Train] Epoch: 0 [576448/620022]    Loss: 0.009318   Batch Acc: 76.56
[Train] Epoch: 0 [576512/620022]    Loss: 0.009144   Batch Acc: 79.69
[Train] Epoch: 0 [576576/620022]    Loss: 0.007140   Batch Acc: 85.94
[Train] Epoch: 0 [576640/620022]    Loss: 0.008447   Batch Acc: 81.25
[Train] Epoch: 0 [576704/620022]    Loss: 0.006672   Batch Acc: 82.81
[Train] Epoch: 0 [576768/620022]    Loss: 0.006456   Batch Acc: 85.94
[Train] Epoch: 0 [576832/620022]    Loss: 0.007928   Batch Acc: 79.69
[Train] Epoch: 0 [576896/620022]    Loss: 0.009103   Batch Acc: 75.00
[Train] Epoch: 0 [576960/620022]    Loss: 0.008935   Batch Acc: 73.44
[Train] Epoch: 0 [577024/620022]    Loss: 0.011953   Batch Acc: 73.44
[Train] Epoch: 0 [577088/620022]    Loss: 0.008529   Batch Acc: 85.94
[Train] Epoch: 0 [577152/620022]    Loss: 0.008209   Batch Acc: 81.25
[Train] Epoch: 0 [577216/620022]    Loss: 0.008801   Batch Acc: 81.25
[Train] Epoch: 0 [577280/620022]    Loss: 0.007981   Batch Acc: 78.12
[Train] Epoch: 0 [577344/620022]    Loss: 0.008151   Batch Acc: 76.56
[Train] Epoch: 0 [577408/620022]    Loss: 0.008252   Batch Acc: 78.12
[Train] Epoch: 0 [577472/620022]    Loss: 0.007322   Batch Acc: 79.69
[Train] Epoch: 0 [577536/620022]    Loss: 0.008707   Batch Acc: 75.00
[Train] Epoch: 0 [577600/620022]    Loss: 0.009498   Batch Acc: 73.44
[Train] Epoch: 0 [577664/620022]    Loss: 0.008151   Batch Acc: 79.69
[Train] Epoch: 0 [577728/620022]    Loss: 0.011695   Batch Acc: 68.75
[Train] Epoch: 0 [577792/620022]    Loss: 0.008449   Batch Acc: 79.69
[Train] Epoch: 0 [577856/620022]    Loss: 0.007769   Batch Acc: 84.38
[Train] Epoch: 0 [577920/620022]    Loss: 0.008473   Batch Acc: 82.81
[Train] Epoch: 0 [577984/620022]    Loss: 0.010223   Batch Acc: 70.31
[Train] Epoch: 0 [578048/620022]    Loss: 0.006865   Batch Acc: 84.38
[Train] Epoch: 0 [578112/620022]    Loss: 0.010134   Batch Acc: 70.31
[Train] Epoch: 0 [578176/620022]    Loss: 0.007110   Batch Acc: 85.94
[Train] Epoch: 0 [578240/620022]    Loss: 0.010283   Batch Acc: 71.88
[Train] Epoch: 0 [578304/620022]    Loss: 0.010408   Batch Acc: 71.88
[Train] Epoch: 0 [578368/620022]    Loss: 0.008532   Batch Acc: 78.12
[Train] Epoch: 0 [578432/620022]    Loss: 0.010253   Batch Acc: 76.56
[Train] Epoch: 0 [578496/620022]    Loss: 0.010122   Batch Acc: 78.12
[Train] Epoch: 0 [578560/620022]    Loss: 0.009714   Batch Acc: 67.19
[Train] Epoch: 0 [578624/620022]    Loss: 0.008348   Batch Acc: 84.38
[Train] Epoch: 0 [578688/620022]    Loss: 0.007021   Batch Acc: 81.25
[Train] Epoch: 0 [578752/620022]    Loss: 0.010721   Batch Acc: 81.25
[Train] Epoch: 0 [578816/620022]    Loss: 0.010353   Batch Acc: 75.00
[Train] Epoch: 0 [578880/620022]    Loss: 0.008197   Batch Acc: 78.12
[Train] Epoch: 0 [578944/620022]    Loss: 0.010517   Batch Acc: 75.00
[Train] Epoch: 0 [579008/620022]    Loss: 0.008834   Batch Acc: 73.44
[Train] Epoch: 0 [579072/620022]    Loss: 0.012376   Batch Acc: 68.75
[Train] Epoch: 0 [579136/620022]    Loss: 0.006352   Batch Acc: 85.94
[Train] Epoch: 0 [579200/620022]    Loss: 0.008569   Batch Acc: 79.69
[Train] Epoch: 0 [579264/620022]    Loss: 0.008429   Batch Acc: 81.25
[Train] Epoch: 0 [579328/620022]    Loss: 0.010022   Batch Acc: 75.00
[Train] Epoch: 0 [579392/620022]    Loss: 0.008708   Batch Acc: 79.69
[Train] Epoch: 0 [579456/620022]    Loss: 0.007172   Batch Acc: 82.81
[Train] Epoch: 0 [579520/620022]    Loss: 0.008485   Batch Acc: 79.69
[Train] Epoch: 0 [579584/620022]    Loss: 0.008389   Batch Acc: 78.12
[Train] Epoch: 0 [579648/620022]    Loss: 0.007623   Batch Acc: 82.81
[Train] Epoch: 0 [579712/620022]    Loss: 0.007934   Batch Acc: 78.12
[Train] Epoch: 0 [579776/620022]    Loss: 0.007733   Batch Acc: 81.25
[Train] Epoch: 0 [579840/620022]    Loss: 0.008930   Batch Acc: 81.25
[Train] Epoch: 0 [579904/620022]    Loss: 0.009881   Batch Acc: 71.88
[Train] Epoch: 0 [579968/620022]    Loss: 0.007888   Batch Acc: 84.38
[Train] Epoch: 0 [580032/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 0 [580096/620022]    Loss: 0.008001   Batch Acc: 85.94
[Train] Epoch: 0 [580160/620022]    Loss: 0.008412   Batch Acc: 75.00
[Train] Epoch: 0 [580224/620022]    Loss: 0.010376   Batch Acc: 70.31
[Train] Epoch: 0 [580288/620022]    Loss: 0.007797   Batch Acc: 75.00
[Train] Epoch: 0 [580352/620022]    Loss: 0.006891   Batch Acc: 84.38
[Train] Epoch: 0 [580416/620022]    Loss: 0.008513   Batch Acc: 79.69
[Train] Epoch: 0 [580480/620022]    Loss: 0.008026   Batch Acc: 79.69
[Train] Epoch: 0 [580544/620022]    Loss: 0.008927   Batch Acc: 81.25
[Train] Epoch: 0 [580608/620022]    Loss: 0.008170   Batch Acc: 79.69
[Train] Epoch: 0 [580672/620022]    Loss: 0.010331   Batch Acc: 71.88
[Train] Epoch: 0 [580736/620022]    Loss: 0.009782   Batch Acc: 73.44
[Train] Epoch: 0 [580800/620022]    Loss: 0.009862   Batch Acc: 70.31
[Train] Epoch: 0 [580864/620022]    Loss: 0.008851   Batch Acc: 81.25
[Train] Epoch: 0 [580928/620022]    Loss: 0.007200   Batch Acc: 84.38
[Train] Epoch: 0 [580992/620022]    Loss: 0.008704   Batch Acc: 78.12
[Train] Epoch: 0 [581056/620022]    Loss: 0.010551   Batch Acc: 71.88
[Train] Epoch: 0 [581120/620022]    Loss: 0.010160   Batch Acc: 73.44
[Train] Epoch: 0 [581184/620022]    Loss: 0.008248   Batch Acc: 78.12
[Train] Epoch: 0 [581248/620022]    Loss: 0.007542   Batch Acc: 82.81
[Train] Epoch: 0 [581312/620022]    Loss: 0.008620   Batch Acc: 82.81
[Train] Epoch: 0 [581376/620022]    Loss: 0.007766   Batch Acc: 78.12
[Train] Epoch: 0 [581440/620022]    Loss: 0.007595   Batch Acc: 81.25
[Train] Epoch: 0 [581504/620022]    Loss: 0.009616   Batch Acc: 73.44
[Train] Epoch: 0 [581568/620022]    Loss: 0.010268   Batch Acc: 71.88
[Train] Epoch: 0 [581632/620022]    Loss: 0.010650   Batch Acc: 75.00
[Train] Epoch: 0 [581696/620022]    Loss: 0.008194   Batch Acc: 73.44
[Train] Epoch: 0 [581760/620022]    Loss: 0.008954   Batch Acc: 76.56
[Train] Epoch: 0 [581824/620022]    Loss: 0.007416   Batch Acc: 78.12
[Train] Epoch: 0 [581888/620022]    Loss: 0.009496   Batch Acc: 73.44
[Train] Epoch: 0 [581952/620022]    Loss: 0.008038   Batch Acc: 78.12
[Train] Epoch: 0 [582016/620022]    Loss: 0.007774   Batch Acc: 79.69
[Train] Epoch: 0 [582080/620022]    Loss: 0.007402   Batch Acc: 82.81
[Train] Epoch: 0 [582144/620022]    Loss: 0.008085   Batch Acc: 79.69
[Train] Epoch: 0 [582208/620022]    Loss: 0.009128   Batch Acc: 79.69
[Train] Epoch: 0 [582272/620022]    Loss: 0.007922   Batch Acc: 79.69
[Train] Epoch: 0 [582336/620022]    Loss: 0.009704   Batch Acc: 75.00
[Train] Epoch: 0 [582400/620022]    Loss: 0.008477   Batch Acc: 78.12
[Train] Epoch: 0 [582464/620022]    Loss: 0.007444   Batch Acc: 81.25
[Train] Epoch: 0 [582528/620022]    Loss: 0.009262   Batch Acc: 75.00
[Train] Epoch: 0 [582592/620022]    Loss: 0.007986   Batch Acc: 79.69
[Train] Epoch: 0 [582656/620022]    Loss: 0.008768   Batch Acc: 78.12
[Train] Epoch: 0 [582720/620022]    Loss: 0.008305   Batch Acc: 79.69
[Train] Epoch: 0 [582784/620022]    Loss: 0.006665   Batch Acc: 84.38
[Train] Epoch: 0 [582848/620022]    Loss: 0.008831   Batch Acc: 85.94
[Train] Epoch: 0 [582912/620022]    Loss: 0.008314   Batch Acc: 85.94
[Train] Epoch: 0 [582976/620022]    Loss: 0.009654   Batch Acc: 70.31
[Train] Epoch: 0 [583040/620022]    Loss: 0.009918   Batch Acc: 73.44
[Train] Epoch: 0 [583104/620022]    Loss: 0.010258   Batch Acc: 68.75
[Train] Epoch: 0 [583168/620022]    Loss: 0.009575   Batch Acc: 76.56
[Train] Epoch: 0 [583232/620022]    Loss: 0.007454   Batch Acc: 84.38
[Train] Epoch: 0 [583296/620022]    Loss: 0.009303   Batch Acc: 76.56
[Train] Epoch: 0 [583360/620022]    Loss: 0.007871   Batch Acc: 82.81
[Train] Epoch: 0 [583424/620022]    Loss: 0.006623   Batch Acc: 84.38
[Train] Epoch: 0 [583488/620022]    Loss: 0.007869   Batch Acc: 78.12
[Train] Epoch: 0 [583552/620022]    Loss: 0.008422   Batch Acc: 75.00
[Train] Epoch: 0 [583616/620022]    Loss: 0.006336   Batch Acc: 81.25
[Train] Epoch: 0 [583680/620022]    Loss: 0.010513   Batch Acc: 75.00
[Train] Epoch: 0 [583744/620022]    Loss: 0.008144   Batch Acc: 73.44
[Train] Epoch: 0 [583808/620022]    Loss: 0.009762   Batch Acc: 75.00
[Train] Epoch: 0 [583872/620022]    Loss: 0.010037   Batch Acc: 75.00
[Train] Epoch: 0 [583936/620022]    Loss: 0.009395   Batch Acc: 82.81
[Train] Epoch: 0 [584000/620022]    Loss: 0.010759   Batch Acc: 73.44
[Train] Epoch: 0 [584064/620022]    Loss: 0.009163   Batch Acc: 75.00
[Train] Epoch: 0 [584128/620022]    Loss: 0.005924   Batch Acc: 89.06
[Train] Epoch: 0 [584192/620022]    Loss: 0.010545   Batch Acc: 73.44
[Train] Epoch: 0 [584256/620022]    Loss: 0.007508   Batch Acc: 82.81
[Train] Epoch: 0 [584320/620022]    Loss: 0.007298   Batch Acc: 82.81
[Train] Epoch: 0 [584384/620022]    Loss: 0.009214   Batch Acc: 75.00
[Train] Epoch: 0 [584448/620022]    Loss: 0.008414   Batch Acc: 70.31
[Train] Epoch: 0 [584512/620022]    Loss: 0.008818   Batch Acc: 73.44
[Train] Epoch: 0 [584576/620022]    Loss: 0.008676   Batch Acc: 73.44
[Train] Epoch: 0 [584640/620022]    Loss: 0.008713   Batch Acc: 81.25
[Train] Epoch: 0 [584704/620022]    Loss: 0.008440   Batch Acc: 81.25
[Train] Epoch: 0 [584768/620022]    Loss: 0.006711   Batch Acc: 84.38
[Train] Epoch: 0 [584832/620022]    Loss: 0.008524   Batch Acc: 82.81
[Train] Epoch: 0 [584896/620022]    Loss: 0.010569   Batch Acc: 75.00
[Train] Epoch: 0 [584960/620022]    Loss: 0.008508   Batch Acc: 75.00
[Train] Epoch: 0 [585024/620022]    Loss: 0.009815   Batch Acc: 73.44
[Train] Epoch: 0 [585088/620022]    Loss: 0.008015   Batch Acc: 82.81
[Train] Epoch: 0 [585152/620022]    Loss: 0.009391   Batch Acc: 79.69
[Train] Epoch: 0 [585216/620022]    Loss: 0.008588   Batch Acc: 76.56
[Train] Epoch: 0 [585280/620022]    Loss: 0.008175   Batch Acc: 81.25
[Train] Epoch: 0 [585344/620022]    Loss: 0.008814   Batch Acc: 75.00
[Train] Epoch: 0 [585408/620022]    Loss: 0.008905   Batch Acc: 76.56
[Train] Epoch: 0 [585472/620022]    Loss: 0.006956   Batch Acc: 85.94
[Train] Epoch: 0 [585536/620022]    Loss: 0.008294   Batch Acc: 76.56
[Train] Epoch: 0 [585600/620022]    Loss: 0.009057   Batch Acc: 75.00
[Train] Epoch: 0 [585664/620022]    Loss: 0.007017   Batch Acc: 85.94
[Train] Epoch: 0 [585728/620022]    Loss: 0.007775   Batch Acc: 81.25
[Train] Epoch: 0 [585792/620022]    Loss: 0.008388   Batch Acc: 79.69
[Train] Epoch: 0 [585856/620022]    Loss: 0.008928   Batch Acc: 76.56
[Train] Epoch: 0 [585920/620022]    Loss: 0.008108   Batch Acc: 81.25
[Train] Epoch: 0 [585984/620022]    Loss: 0.007910   Batch Acc: 75.00
[Train] Epoch: 0 [586048/620022]    Loss: 0.007315   Batch Acc: 81.25
[Train] Epoch: 0 [586112/620022]    Loss: 0.009743   Batch Acc: 73.44
[Train] Epoch: 0 [586176/620022]    Loss: 0.008357   Batch Acc: 81.25
[Train] Epoch: 0 [586240/620022]    Loss: 0.008027   Batch Acc: 84.38
[Train] Epoch: 0 [586304/620022]    Loss: 0.008788   Batch Acc: 71.88
[Train] Epoch: 0 [586368/620022]    Loss: 0.010887   Batch Acc: 67.19
[Train] Epoch: 0 [586432/620022]    Loss: 0.010066   Batch Acc: 68.75
[Train] Epoch: 0 [586496/620022]    Loss: 0.008282   Batch Acc: 81.25
[Train] Epoch: 0 [586560/620022]    Loss: 0.008375   Batch Acc: 76.56
[Train] Epoch: 0 [586624/620022]    Loss: 0.008951   Batch Acc: 79.69
[Train] Epoch: 0 [586688/620022]    Loss: 0.006788   Batch Acc: 84.38
[Train] Epoch: 0 [586752/620022]    Loss: 0.008790   Batch Acc: 79.69
[Train] Epoch: 0 [586816/620022]    Loss: 0.008736   Batch Acc: 79.69
[Train] Epoch: 0 [586880/620022]    Loss: 0.007476   Batch Acc: 89.06
[Train] Epoch: 0 [586944/620022]    Loss: 0.008816   Batch Acc: 79.69
[Train] Epoch: 0 [587008/620022]    Loss: 0.007793   Batch Acc: 76.56
[Train] Epoch: 0 [587072/620022]    Loss: 0.010075   Batch Acc: 70.31
[Train] Epoch: 0 [587136/620022]    Loss: 0.007371   Batch Acc: 87.50
[Train] Epoch: 0 [587200/620022]    Loss: 0.007813   Batch Acc: 75.00
[Train] Epoch: 0 [587264/620022]    Loss: 0.009059   Batch Acc: 79.69
[Train] Epoch: 0 [587328/620022]    Loss: 0.011996   Batch Acc: 65.62
[Train] Epoch: 0 [587392/620022]    Loss: 0.007173   Batch Acc: 81.25
[Train] Epoch: 0 [587456/620022]    Loss: 0.007668   Batch Acc: 84.38
[Train] Epoch: 0 [587520/620022]    Loss: 0.008294   Batch Acc: 82.81
[Train] Epoch: 0 [587584/620022]    Loss: 0.008213   Batch Acc: 76.56
[Train] Epoch: 0 [587648/620022]    Loss: 0.008186   Batch Acc: 79.69
[Train] Epoch: 0 [587712/620022]    Loss: 0.009892   Batch Acc: 68.75
[Train] Epoch: 0 [587776/620022]    Loss: 0.009537   Batch Acc: 78.12
[Train] Epoch: 0 [587840/620022]    Loss: 0.007407   Batch Acc: 81.25
[Train] Epoch: 0 [587904/620022]    Loss: 0.006962   Batch Acc: 82.81
[Train] Epoch: 0 [587968/620022]    Loss: 0.009904   Batch Acc: 73.44
[Train] Epoch: 0 [588032/620022]    Loss: 0.010864   Batch Acc: 71.88
[Train] Epoch: 0 [588096/620022]    Loss: 0.008758   Batch Acc: 75.00
[Train] Epoch: 0 [588160/620022]    Loss: 0.009414   Batch Acc: 81.25
[Train] Epoch: 0 [588224/620022]    Loss: 0.008542   Batch Acc: 76.56
[Train] Epoch: 0 [588288/620022]    Loss: 0.009114   Batch Acc: 70.31
[Train] Epoch: 0 [588352/620022]    Loss: 0.009973   Batch Acc: 70.31
[Train] Epoch: 0 [588416/620022]    Loss: 0.010598   Batch Acc: 75.00
[Train] Epoch: 0 [588480/620022]    Loss: 0.009424   Batch Acc: 73.44
[Train] Epoch: 0 [588544/620022]    Loss: 0.011614   Batch Acc: 67.19
[Train] Epoch: 0 [588608/620022]    Loss: 0.010761   Batch Acc: 67.19
[Train] Epoch: 0 [588672/620022]    Loss: 0.010553   Batch Acc: 73.44
[Train] Epoch: 0 [588736/620022]    Loss: 0.009513   Batch Acc: 76.56
[Train] Epoch: 0 [588800/620022]    Loss: 0.008041   Batch Acc: 78.12
[Train] Epoch: 0 [588864/620022]    Loss: 0.008580   Batch Acc: 73.44
[Train] Epoch: 0 [588928/620022]    Loss: 0.006769   Batch Acc: 84.38
[Train] Epoch: 0 [588992/620022]    Loss: 0.008912   Batch Acc: 76.56
[Train] Epoch: 0 [589056/620022]    Loss: 0.007758   Batch Acc: 79.69
[Train] Epoch: 0 [589120/620022]    Loss: 0.006166   Batch Acc: 87.50
[Train] Epoch: 0 [589184/620022]    Loss: 0.008101   Batch Acc: 82.81
[Train] Epoch: 0 [589248/620022]    Loss: 0.007693   Batch Acc: 82.81
[Train] Epoch: 0 [589312/620022]    Loss: 0.010267   Batch Acc: 73.44
[Train] Epoch: 0 [589376/620022]    Loss: 0.008416   Batch Acc: 81.25
[Train] Epoch: 0 [589440/620022]    Loss: 0.008113   Batch Acc: 82.81
[Train] Epoch: 0 [589504/620022]    Loss: 0.010813   Batch Acc: 70.31
[Train] Epoch: 0 [589568/620022]    Loss: 0.008815   Batch Acc: 71.88
[Train] Epoch: 0 [589632/620022]    Loss: 0.008998   Batch Acc: 78.12
[Train] Epoch: 0 [589696/620022]    Loss: 0.008616   Batch Acc: 81.25
[Train] Epoch: 0 [589760/620022]    Loss: 0.008319   Batch Acc: 78.12
[Train] Epoch: 0 [589824/620022]    Loss: 0.009681   Batch Acc: 78.12
[Train] Epoch: 0 [589888/620022]    Loss: 0.008537   Batch Acc: 82.81
[Train] Epoch: 0 [589952/620022]    Loss: 0.006290   Batch Acc: 87.50
[Train] Epoch: 0 [590016/620022]    Loss: 0.008463   Batch Acc: 75.00
[Train] Epoch: 0 [590080/620022]    Loss: 0.007030   Batch Acc: 84.38
[Train] Epoch: 0 [590144/620022]    Loss: 0.009232   Batch Acc: 78.12
[Train] Epoch: 0 [590208/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 0 [590272/620022]    Loss: 0.008149   Batch Acc: 84.38
[Train] Epoch: 0 [590336/620022]    Loss: 0.010442   Batch Acc: 75.00
[Train] Epoch: 0 [590400/620022]    Loss: 0.009284   Batch Acc: 78.12
[Train] Epoch: 0 [590464/620022]    Loss: 0.008076   Batch Acc: 82.81
[Train] Epoch: 0 [590528/620022]    Loss: 0.011363   Batch Acc: 75.00
[Train] Epoch: 0 [590592/620022]    Loss: 0.008638   Batch Acc: 79.69
[Train] Epoch: 0 [590656/620022]    Loss: 0.008558   Batch Acc: 79.69
[Train] Epoch: 0 [590720/620022]    Loss: 0.010372   Batch Acc: 75.00
[Train] Epoch: 0 [590784/620022]    Loss: 0.008289   Batch Acc: 76.56
[Train] Epoch: 0 [590848/620022]    Loss: 0.007233   Batch Acc: 81.25
[Train] Epoch: 0 [590912/620022]    Loss: 0.008640   Batch Acc: 76.56
[Train] Epoch: 0 [590976/620022]    Loss: 0.009447   Batch Acc: 78.12
[Train] Epoch: 0 [591040/620022]    Loss: 0.007548   Batch Acc: 81.25
[Train] Epoch: 0 [591104/620022]    Loss: 0.010296   Batch Acc: 71.88
[Train] Epoch: 0 [591168/620022]    Loss: 0.009968   Batch Acc: 76.56
[Train] Epoch: 0 [591232/620022]    Loss: 0.007633   Batch Acc: 82.81
[Train] Epoch: 0 [591296/620022]    Loss: 0.008056   Batch Acc: 81.25
[Train] Epoch: 0 [591360/620022]    Loss: 0.006104   Batch Acc: 81.25
[Train] Epoch: 0 [591424/620022]    Loss: 0.009217   Batch Acc: 76.56
[Train] Epoch: 0 [591488/620022]    Loss: 0.010829   Batch Acc: 65.62
[Train] Epoch: 0 [591552/620022]    Loss: 0.010584   Batch Acc: 75.00
[Train] Epoch: 0 [591616/620022]    Loss: 0.007540   Batch Acc: 78.12
[Train] Epoch: 0 [591680/620022]    Loss: 0.008099   Batch Acc: 82.81
[Train] Epoch: 0 [591744/620022]    Loss: 0.008411   Batch Acc: 82.81
[Train] Epoch: 0 [591808/620022]    Loss: 0.008059   Batch Acc: 82.81
[Train] Epoch: 0 [591872/620022]    Loss: 0.008642   Batch Acc: 76.56
[Train] Epoch: 0 [591936/620022]    Loss: 0.009601   Batch Acc: 71.88
[Train] Epoch: 0 [592000/620022]    Loss: 0.009302   Batch Acc: 79.69
[Train] Epoch: 0 [592064/620022]    Loss: 0.007053   Batch Acc: 84.38
[Train] Epoch: 0 [592128/620022]    Loss: 0.008031   Batch Acc: 82.81
[Train] Epoch: 0 [592192/620022]    Loss: 0.007394   Batch Acc: 79.69
[Train] Epoch: 0 [592256/620022]    Loss: 0.007816   Batch Acc: 79.69
[Train] Epoch: 0 [592320/620022]    Loss: 0.009181   Batch Acc: 81.25
[Train] Epoch: 0 [592384/620022]    Loss: 0.007485   Batch Acc: 79.69
[Train] Epoch: 0 [592448/620022]    Loss: 0.009379   Batch Acc: 76.56
[Train] Epoch: 0 [592512/620022]    Loss: 0.008541   Batch Acc: 76.56
[Train] Epoch: 0 [592576/620022]    Loss: 0.007144   Batch Acc: 84.38
[Train] Epoch: 0 [592640/620022]    Loss: 0.009445   Batch Acc: 76.56
[Train] Epoch: 0 [592704/620022]    Loss: 0.008961   Batch Acc: 76.56
[Train] Epoch: 0 [592768/620022]    Loss: 0.007384   Batch Acc: 79.69
[Train] Epoch: 0 [592832/620022]    Loss: 0.009653   Batch Acc: 73.44
[Train] Epoch: 0 [592896/620022]    Loss: 0.010481   Batch Acc: 68.75
[Train] Epoch: 0 [592960/620022]    Loss: 0.011624   Batch Acc: 67.19
[Train] Epoch: 0 [593024/620022]    Loss: 0.010911   Batch Acc: 73.44
[Train] Epoch: 0 [593088/620022]    Loss: 0.007362   Batch Acc: 84.38
[Train] Epoch: 0 [593152/620022]    Loss: 0.009760   Batch Acc: 75.00
[Train] Epoch: 0 [593216/620022]    Loss: 0.008777   Batch Acc: 81.25
[Train] Epoch: 0 [593280/620022]    Loss: 0.009848   Batch Acc: 73.44
[Train] Epoch: 0 [593344/620022]    Loss: 0.008572   Batch Acc: 81.25
[Train] Epoch: 0 [593408/620022]    Loss: 0.009036   Batch Acc: 84.38
[Train] Epoch: 0 [593472/620022]    Loss: 0.008447   Batch Acc: 76.56
[Train] Epoch: 0 [593536/620022]    Loss: 0.010627   Batch Acc: 65.62
[Train] Epoch: 0 [593600/620022]    Loss: 0.009433   Batch Acc: 81.25
[Train] Epoch: 0 [593664/620022]    Loss: 0.008938   Batch Acc: 78.12
[Train] Epoch: 0 [593728/620022]    Loss: 0.010214   Batch Acc: 73.44
[Train] Epoch: 0 [593792/620022]    Loss: 0.007505   Batch Acc: 79.69
[Train] Epoch: 0 [593856/620022]    Loss: 0.009548   Batch Acc: 73.44
[Train] Epoch: 0 [593920/620022]    Loss: 0.008310   Batch Acc: 79.69
[Train] Epoch: 0 [593984/620022]    Loss: 0.008712   Batch Acc: 76.56
[Train] Epoch: 0 [594048/620022]    Loss: 0.007874   Batch Acc: 78.12
[Train] Epoch: 0 [594112/620022]    Loss: 0.009339   Batch Acc: 75.00
[Train] Epoch: 0 [594176/620022]    Loss: 0.009121   Batch Acc: 71.88
[Train] Epoch: 0 [594240/620022]    Loss: 0.007411   Batch Acc: 82.81
[Train] Epoch: 0 [594304/620022]    Loss: 0.009587   Batch Acc: 71.88
[Train] Epoch: 0 [594368/620022]    Loss: 0.008489   Batch Acc: 82.81
[Train] Epoch: 0 [594432/620022]    Loss: 0.008207   Batch Acc: 78.12
[Train] Epoch: 0 [594496/620022]    Loss: 0.009357   Batch Acc: 76.56
[Train] Epoch: 0 [594560/620022]    Loss: 0.009631   Batch Acc: 71.88
[Train] Epoch: 0 [594624/620022]    Loss: 0.006737   Batch Acc: 84.38
[Train] Epoch: 0 [594688/620022]    Loss: 0.008214   Batch Acc: 84.38
[Train] Epoch: 0 [594752/620022]    Loss: 0.007977   Batch Acc: 81.25
[Train] Epoch: 0 [594816/620022]    Loss: 0.007894   Batch Acc: 85.94
[Train] Epoch: 0 [594880/620022]    Loss: 0.008488   Batch Acc: 84.38
[Train] Epoch: 0 [594944/620022]    Loss: 0.008587   Batch Acc: 79.69
[Train] Epoch: 0 [595008/620022]    Loss: 0.007636   Batch Acc: 76.56
[Train] Epoch: 0 [595072/620022]    Loss: 0.007456   Batch Acc: 81.25
[Train] Epoch: 0 [595136/620022]    Loss: 0.008124   Batch Acc: 79.69
[Train] Epoch: 0 [595200/620022]    Loss: 0.007690   Batch Acc: 81.25
[Train] Epoch: 0 [595264/620022]    Loss: 0.009259   Batch Acc: 78.12
[Train] Epoch: 0 [595328/620022]    Loss: 0.008897   Batch Acc: 76.56
[Train] Epoch: 0 [595392/620022]    Loss: 0.009391   Batch Acc: 75.00
[Train] Epoch: 0 [595456/620022]    Loss: 0.011078   Batch Acc: 70.31
[Train] Epoch: 0 [595520/620022]    Loss: 0.008195   Batch Acc: 79.69
[Train] Epoch: 0 [595584/620022]    Loss: 0.007260   Batch Acc: 81.25
[Train] Epoch: 0 [595648/620022]    Loss: 0.010206   Batch Acc: 71.88
[Train] Epoch: 0 [595712/620022]    Loss: 0.009681   Batch Acc: 75.00
[Train] Epoch: 0 [595776/620022]    Loss: 0.009835   Batch Acc: 71.88
[Train] Epoch: 0 [595840/620022]    Loss: 0.006481   Batch Acc: 85.94
[Train] Epoch: 0 [595904/620022]    Loss: 0.007942   Batch Acc: 76.56
[Train] Epoch: 0 [595968/620022]    Loss: 0.009192   Batch Acc: 75.00
[Train] Epoch: 0 [596032/620022]    Loss: 0.007825   Batch Acc: 78.12
[Train] Epoch: 0 [596096/620022]    Loss: 0.009497   Batch Acc: 73.44
[Train] Epoch: 0 [596160/620022]    Loss: 0.006868   Batch Acc: 84.38
[Train] Epoch: 0 [596224/620022]    Loss: 0.008632   Batch Acc: 78.12
[Train] Epoch: 0 [596288/620022]    Loss: 0.006614   Batch Acc: 84.38
[Train] Epoch: 0 [596352/620022]    Loss: 0.010503   Batch Acc: 70.31
[Train] Epoch: 0 [596416/620022]    Loss: 0.009465   Batch Acc: 75.00
[Train] Epoch: 0 [596480/620022]    Loss: 0.008709   Batch Acc: 79.69
[Train] Epoch: 0 [596544/620022]    Loss: 0.007932   Batch Acc: 82.81
[Train] Epoch: 0 [596608/620022]    Loss: 0.012910   Batch Acc: 68.75
[Train] Epoch: 0 [596672/620022]    Loss: 0.007386   Batch Acc: 82.81
[Train] Epoch: 0 [596736/620022]    Loss: 0.009824   Batch Acc: 71.88
[Train] Epoch: 0 [596800/620022]    Loss: 0.008910   Batch Acc: 79.69
[Train] Epoch: 0 [596864/620022]    Loss: 0.012415   Batch Acc: 62.50
[Train] Epoch: 0 [596928/620022]    Loss: 0.010491   Batch Acc: 75.00
[Train] Epoch: 0 [596992/620022]    Loss: 0.010276   Batch Acc: 73.44
[Train] Epoch: 0 [597056/620022]    Loss: 0.007822   Batch Acc: 82.81
[Train] Epoch: 0 [597120/620022]    Loss: 0.010200   Batch Acc: 71.88
[Train] Epoch: 0 [597184/620022]    Loss: 0.006092   Batch Acc: 85.94
[Train] Epoch: 0 [597248/620022]    Loss: 0.007885   Batch Acc: 79.69
[Train] Epoch: 0 [597312/620022]    Loss: 0.008136   Batch Acc: 78.12
[Train] Epoch: 0 [597376/620022]    Loss: 0.008928   Batch Acc: 76.56
[Train] Epoch: 0 [597440/620022]    Loss: 0.009301   Batch Acc: 79.69
[Train] Epoch: 0 [597504/620022]    Loss: 0.008945   Batch Acc: 76.56
[Train] Epoch: 0 [597568/620022]    Loss: 0.009966   Batch Acc: 75.00
[Train] Epoch: 0 [597632/620022]    Loss: 0.006546   Batch Acc: 87.50
[Train] Epoch: 0 [597696/620022]    Loss: 0.008349   Batch Acc: 78.12
[Train] Epoch: 0 [597760/620022]    Loss: 0.005946   Batch Acc: 87.50
[Train] Epoch: 0 [597824/620022]    Loss: 0.007345   Batch Acc: 82.81
[Train] Epoch: 0 [597888/620022]    Loss: 0.008898   Batch Acc: 73.44
[Train] Epoch: 0 [597952/620022]    Loss: 0.009173   Batch Acc: 78.12
[Train] Epoch: 0 [598016/620022]    Loss: 0.008984   Batch Acc: 76.56
[Train] Epoch: 0 [598080/620022]    Loss: 0.012249   Batch Acc: 67.19
[Train] Epoch: 0 [598144/620022]    Loss: 0.008554   Batch Acc: 76.56
[Train] Epoch: 0 [598208/620022]    Loss: 0.009187   Batch Acc: 82.81
[Train] Epoch: 0 [598272/620022]    Loss: 0.008473   Batch Acc: 81.25
[Train] Epoch: 0 [598336/620022]    Loss: 0.011162   Batch Acc: 73.44
[Train] Epoch: 0 [598400/620022]    Loss: 0.007582   Batch Acc: 82.81
[Train] Epoch: 0 [598464/620022]    Loss: 0.008309   Batch Acc: 76.56
[Train] Epoch: 0 [598528/620022]    Loss: 0.008538   Batch Acc: 76.56
[Train] Epoch: 0 [598592/620022]    Loss: 0.009321   Batch Acc: 78.12
[Train] Epoch: 0 [598656/620022]    Loss: 0.010782   Batch Acc: 62.50
[Train] Epoch: 0 [598720/620022]    Loss: 0.009048   Batch Acc: 78.12
[Train] Epoch: 0 [598784/620022]    Loss: 0.005105   Batch Acc: 92.19
[Train] Epoch: 0 [598848/620022]    Loss: 0.010190   Batch Acc: 71.88
[Train] Epoch: 0 [598912/620022]    Loss: 0.007838   Batch Acc: 81.25
[Train] Epoch: 0 [598976/620022]    Loss: 0.009826   Batch Acc: 76.56
[Train] Epoch: 0 [599040/620022]    Loss: 0.007914   Batch Acc: 79.69
[Train] Epoch: 0 [599104/620022]    Loss: 0.006899   Batch Acc: 84.38
[Train] Epoch: 0 [599168/620022]    Loss: 0.010758   Batch Acc: 68.75
[Train] Epoch: 0 [599232/620022]    Loss: 0.007912   Batch Acc: 79.69
[Train] Epoch: 0 [599296/620022]    Loss: 0.007470   Batch Acc: 79.69
[Train] Epoch: 0 [599360/620022]    Loss: 0.007306   Batch Acc: 82.81
[Train] Epoch: 0 [599424/620022]    Loss: 0.007015   Batch Acc: 84.38
[Train] Epoch: 0 [599488/620022]    Loss: 0.009506   Batch Acc: 75.00
[Train] Epoch: 0 [599552/620022]    Loss: 0.005831   Batch Acc: 90.62
[Train] Epoch: 0 [599616/620022]    Loss: 0.007350   Batch Acc: 81.25
[Train] Epoch: 0 [599680/620022]    Loss: 0.010030   Batch Acc: 76.56
[Train] Epoch: 0 [599744/620022]    Loss: 0.008961   Batch Acc: 79.69
[Train] Epoch: 0 [599808/620022]    Loss: 0.010452   Batch Acc: 79.69
[Train] Epoch: 0 [599872/620022]    Loss: 0.008050   Batch Acc: 79.69
[Train] Epoch: 0 [599936/620022]    Loss: 0.008579   Batch Acc: 79.69
[Train] Epoch: 0 [600000/620022]    Loss: 0.009837   Batch Acc: 68.75
[Train] Epoch: 0 [600064/620022]    Loss: 0.008170   Batch Acc: 81.25
[Train] Epoch: 0 [600128/620022]    Loss: 0.007092   Batch Acc: 85.94
[Train] Epoch: 0 [600192/620022]    Loss: 0.010051   Batch Acc: 73.44
[Train] Epoch: 0 [600256/620022]    Loss: 0.007547   Batch Acc: 81.25
[Train] Epoch: 0 [600320/620022]    Loss: 0.008733   Batch Acc: 76.56
[Train] Epoch: 0 [600384/620022]    Loss: 0.010301   Batch Acc: 71.88
[Train] Epoch: 0 [600448/620022]    Loss: 0.009186   Batch Acc: 71.88
[Train] Epoch: 0 [600512/620022]    Loss: 0.008286   Batch Acc: 79.69
[Train] Epoch: 0 [600576/620022]    Loss: 0.010389   Batch Acc: 78.12
[Train] Epoch: 0 [600640/620022]    Loss: 0.009034   Batch Acc: 76.56
[Train] Epoch: 0 [600704/620022]    Loss: 0.011286   Batch Acc: 68.75
[Train] Epoch: 0 [600768/620022]    Loss: 0.010686   Batch Acc: 68.75
[Train] Epoch: 0 [600832/620022]    Loss: 0.008421   Batch Acc: 76.56
[Train] Epoch: 0 [600896/620022]    Loss: 0.007134   Batch Acc: 85.94
[Train] Epoch: 0 [600960/620022]    Loss: 0.007633   Batch Acc: 85.94
[Train] Epoch: 0 [601024/620022]    Loss: 0.007218   Batch Acc: 87.50
[Train] Epoch: 0 [601088/620022]    Loss: 0.008591   Batch Acc: 81.25
[Train] Epoch: 0 [601152/620022]    Loss: 0.008532   Batch Acc: 82.81
[Train] Epoch: 0 [601216/620022]    Loss: 0.009185   Batch Acc: 79.69
[Train] Epoch: 0 [601280/620022]    Loss: 0.009388   Batch Acc: 73.44
[Train] Epoch: 0 [601344/620022]    Loss: 0.009697   Batch Acc: 75.00
[Train] Epoch: 0 [601408/620022]    Loss: 0.008866   Batch Acc: 76.56
[Train] Epoch: 0 [601472/620022]    Loss: 0.008427   Batch Acc: 76.56
[Train] Epoch: 0 [601536/620022]    Loss: 0.008532   Batch Acc: 82.81
[Train] Epoch: 0 [601600/620022]    Loss: 0.009185   Batch Acc: 76.56
[Train] Epoch: 0 [601664/620022]    Loss: 0.007844   Batch Acc: 82.81
[Train] Epoch: 0 [601728/620022]    Loss: 0.009046   Batch Acc: 76.56
[Train] Epoch: 0 [601792/620022]    Loss: 0.010317   Batch Acc: 71.88
[Train] Epoch: 0 [601856/620022]    Loss: 0.010092   Batch Acc: 76.56
[Train] Epoch: 0 [601920/620022]    Loss: 0.010611   Batch Acc: 73.44
[Train] Epoch: 0 [601984/620022]    Loss: 0.008544   Batch Acc: 82.81
[Train] Epoch: 0 [602048/620022]    Loss: 0.009522   Batch Acc: 68.75
[Train] Epoch: 0 [602112/620022]    Loss: 0.010668   Batch Acc: 76.56
[Train] Epoch: 0 [602176/620022]    Loss: 0.008340   Batch Acc: 81.25
[Train] Epoch: 0 [602240/620022]    Loss: 0.008363   Batch Acc: 81.25
[Train] Epoch: 0 [602304/620022]    Loss: 0.008715   Batch Acc: 79.69
[Train] Epoch: 0 [602368/620022]    Loss: 0.007554   Batch Acc: 82.81
[Train] Epoch: 0 [602432/620022]    Loss: 0.008247   Batch Acc: 81.25
[Train] Epoch: 0 [602496/620022]    Loss: 0.010516   Batch Acc: 71.88
[Train] Epoch: 0 [602560/620022]    Loss: 0.007642   Batch Acc: 76.56
[Train] Epoch: 0 [602624/620022]    Loss: 0.008162   Batch Acc: 84.38
[Train] Epoch: 0 [602688/620022]    Loss: 0.008552   Batch Acc: 79.69
[Train] Epoch: 0 [602752/620022]    Loss: 0.009007   Batch Acc: 71.88
[Train] Epoch: 0 [602816/620022]    Loss: 0.008990   Batch Acc: 78.12
[Train] Epoch: 0 [602880/620022]    Loss: 0.008064   Batch Acc: 81.25
[Train] Epoch: 0 [602944/620022]    Loss: 0.008349   Batch Acc: 75.00
[Train] Epoch: 0 [603008/620022]    Loss: 0.007716   Batch Acc: 85.94
[Train] Epoch: 0 [603072/620022]    Loss: 0.007478   Batch Acc: 84.38
[Train] Epoch: 0 [603136/620022]    Loss: 0.009004   Batch Acc: 75.00
[Train] Epoch: 0 [603200/620022]    Loss: 0.008581   Batch Acc: 75.00
[Train] Epoch: 0 [603264/620022]    Loss: 0.010826   Batch Acc: 65.62
[Train] Epoch: 0 [603328/620022]    Loss: 0.009633   Batch Acc: 84.38
[Train] Epoch: 0 [603392/620022]    Loss: 0.008175   Batch Acc: 76.56
[Train] Epoch: 0 [603456/620022]    Loss: 0.009099   Batch Acc: 67.19
[Train] Epoch: 0 [603520/620022]    Loss: 0.007096   Batch Acc: 85.94
[Train] Epoch: 0 [603584/620022]    Loss: 0.006635   Batch Acc: 87.50
[Train] Epoch: 0 [603648/620022]    Loss: 0.008307   Batch Acc: 78.12
[Train] Epoch: 0 [603712/620022]    Loss: 0.008899   Batch Acc: 81.25
[Train] Epoch: 0 [603776/620022]    Loss: 0.008512   Batch Acc: 79.69
[Train] Epoch: 0 [603840/620022]    Loss: 0.007291   Batch Acc: 79.69
[Train] Epoch: 0 [603904/620022]    Loss: 0.008623   Batch Acc: 78.12
[Train] Epoch: 0 [603968/620022]    Loss: 0.008076   Batch Acc: 75.00
[Train] Epoch: 0 [604032/620022]    Loss: 0.008870   Batch Acc: 81.25
[Train] Epoch: 0 [604096/620022]    Loss: 0.009526   Batch Acc: 71.88
[Train] Epoch: 0 [604160/620022]    Loss: 0.010281   Batch Acc: 71.88
[Train] Epoch: 0 [604224/620022]    Loss: 0.008059   Batch Acc: 84.38
[Train] Epoch: 0 [604288/620022]    Loss: 0.008332   Batch Acc: 78.12
[Train] Epoch: 0 [604352/620022]    Loss: 0.007922   Batch Acc: 79.69
[Train] Epoch: 0 [604416/620022]    Loss: 0.007180   Batch Acc: 79.69
[Train] Epoch: 0 [604480/620022]    Loss: 0.007009   Batch Acc: 84.38
[Train] Epoch: 0 [604544/620022]    Loss: 0.010457   Batch Acc: 79.69
[Train] Epoch: 0 [604608/620022]    Loss: 0.007105   Batch Acc: 85.94
[Train] Epoch: 0 [604672/620022]    Loss: 0.006383   Batch Acc: 87.50
[Train] Epoch: 0 [604736/620022]    Loss: 0.008517   Batch Acc: 81.25
[Train] Epoch: 0 [604800/620022]    Loss: 0.010027   Batch Acc: 70.31
[Train] Epoch: 0 [604864/620022]    Loss: 0.011471   Batch Acc: 70.31
[Train] Epoch: 0 [604928/620022]    Loss: 0.007724   Batch Acc: 81.25
[Train] Epoch: 0 [604992/620022]    Loss: 0.008580   Batch Acc: 75.00
[Train] Epoch: 0 [605056/620022]    Loss: 0.009708   Batch Acc: 73.44
[Train] Epoch: 0 [605120/620022]    Loss: 0.008830   Batch Acc: 78.12
[Train] Epoch: 0 [605184/620022]    Loss: 0.008209   Batch Acc: 79.69
[Train] Epoch: 0 [605248/620022]    Loss: 0.009524   Batch Acc: 76.56
[Train] Epoch: 0 [605312/620022]    Loss: 0.010521   Batch Acc: 68.75
[Train] Epoch: 0 [605376/620022]    Loss: 0.009880   Batch Acc: 75.00
[Train] Epoch: 0 [605440/620022]    Loss: 0.010675   Batch Acc: 65.62
[Train] Epoch: 0 [605504/620022]    Loss: 0.011852   Batch Acc: 73.44
[Train] Epoch: 0 [605568/620022]    Loss: 0.006270   Batch Acc: 87.50
[Train] Epoch: 0 [605632/620022]    Loss: 0.008943   Batch Acc: 82.81
[Train] Epoch: 0 [605696/620022]    Loss: 0.008352   Batch Acc: 78.12
[Train] Epoch: 0 [605760/620022]    Loss: 0.007904   Batch Acc: 75.00
[Train] Epoch: 0 [605824/620022]    Loss: 0.007825   Batch Acc: 78.12
[Train] Epoch: 0 [605888/620022]    Loss: 0.010028   Batch Acc: 73.44
[Train] Epoch: 0 [605952/620022]    Loss: 0.008920   Batch Acc: 81.25
[Train] Epoch: 0 [606016/620022]    Loss: 0.009422   Batch Acc: 71.88
[Train] Epoch: 0 [606080/620022]    Loss: 0.011048   Batch Acc: 68.75
[Train] Epoch: 0 [606144/620022]    Loss: 0.008489   Batch Acc: 78.12
[Train] Epoch: 0 [606208/620022]    Loss: 0.007897   Batch Acc: 78.12
[Train] Epoch: 0 [606272/620022]    Loss: 0.008580   Batch Acc: 79.69
[Train] Epoch: 0 [606336/620022]    Loss: 0.009102   Batch Acc: 76.56
[Train] Epoch: 0 [606400/620022]    Loss: 0.009710   Batch Acc: 81.25
[Train] Epoch: 0 [606464/620022]    Loss: 0.011835   Batch Acc: 75.00
[Train] Epoch: 0 [606528/620022]    Loss: 0.010396   Batch Acc: 70.31
[Train] Epoch: 0 [606592/620022]    Loss: 0.007846   Batch Acc: 82.81
[Train] Epoch: 0 [606656/620022]    Loss: 0.009229   Batch Acc: 76.56
[Train] Epoch: 0 [606720/620022]    Loss: 0.010742   Batch Acc: 76.56
[Train] Epoch: 0 [606784/620022]    Loss: 0.010516   Batch Acc: 75.00
[Train] Epoch: 0 [606848/620022]    Loss: 0.011456   Batch Acc: 70.31
[Train] Epoch: 0 [606912/620022]    Loss: 0.007644   Batch Acc: 84.38
[Train] Epoch: 0 [606976/620022]    Loss: 0.011577   Batch Acc: 67.19
[Train] Epoch: 0 [607040/620022]    Loss: 0.008063   Batch Acc: 81.25
[Train] Epoch: 0 [607104/620022]    Loss: 0.006738   Batch Acc: 84.38
[Train] Epoch: 0 [607168/620022]    Loss: 0.007324   Batch Acc: 81.25
[Train] Epoch: 0 [607232/620022]    Loss: 0.007544   Batch Acc: 81.25
[Train] Epoch: 0 [607296/620022]    Loss: 0.006278   Batch Acc: 90.62
[Train] Epoch: 0 [607360/620022]    Loss: 0.007805   Batch Acc: 79.69
[Train] Epoch: 0 [607424/620022]    Loss: 0.009259   Batch Acc: 71.88
[Train] Epoch: 0 [607488/620022]    Loss: 0.006336   Batch Acc: 85.94
[Train] Epoch: 0 [607552/620022]    Loss: 0.007650   Batch Acc: 81.25
[Train] Epoch: 0 [607616/620022]    Loss: 0.007976   Batch Acc: 79.69
[Train] Epoch: 0 [607680/620022]    Loss: 0.008181   Batch Acc: 75.00
[Train] Epoch: 0 [607744/620022]    Loss: 0.009878   Batch Acc: 73.44
[Train] Epoch: 0 [607808/620022]    Loss: 0.009499   Batch Acc: 75.00
[Train] Epoch: 0 [607872/620022]    Loss: 0.008795   Batch Acc: 75.00
[Train] Epoch: 0 [607936/620022]    Loss: 0.007971   Batch Acc: 82.81
[Train] Epoch: 0 [608000/620022]    Loss: 0.010198   Batch Acc: 71.88
[Train] Epoch: 0 [608064/620022]    Loss: 0.008004   Batch Acc: 82.81
[Train] Epoch: 0 [608128/620022]    Loss: 0.011805   Batch Acc: 67.19
[Train] Epoch: 0 [608192/620022]    Loss: 0.007877   Batch Acc: 82.81
[Train] Epoch: 0 [608256/620022]    Loss: 0.008667   Batch Acc: 79.69
[Train] Epoch: 0 [608320/620022]    Loss: 0.008020   Batch Acc: 85.94
[Train] Epoch: 0 [608384/620022]    Loss: 0.010062   Batch Acc: 70.31
[Train] Epoch: 0 [608448/620022]    Loss: 0.008440   Batch Acc: 76.56
[Train] Epoch: 0 [608512/620022]    Loss: 0.008626   Batch Acc: 78.12
[Train] Epoch: 0 [608576/620022]    Loss: 0.009790   Batch Acc: 73.44
[Train] Epoch: 0 [608640/620022]    Loss: 0.008030   Batch Acc: 79.69
[Train] Epoch: 0 [608704/620022]    Loss: 0.007413   Batch Acc: 85.94
[Train] Epoch: 0 [608768/620022]    Loss: 0.008073   Batch Acc: 85.94
[Train] Epoch: 0 [608832/620022]    Loss: 0.009457   Batch Acc: 81.25
[Train] Epoch: 0 [608896/620022]    Loss: 0.006538   Batch Acc: 84.38
[Train] Epoch: 0 [608960/620022]    Loss: 0.011419   Batch Acc: 75.00
[Train] Epoch: 0 [609024/620022]    Loss: 0.007909   Batch Acc: 76.56
[Train] Epoch: 0 [609088/620022]    Loss: 0.008587   Batch Acc: 73.44
[Train] Epoch: 0 [609152/620022]    Loss: 0.009390   Batch Acc: 76.56
[Train] Epoch: 0 [609216/620022]    Loss: 0.007976   Batch Acc: 79.69
[Train] Epoch: 0 [609280/620022]    Loss: 0.009154   Batch Acc: 75.00
[Train] Epoch: 0 [609344/620022]    Loss: 0.007434   Batch Acc: 76.56
[Train] Epoch: 0 [609408/620022]    Loss: 0.006878   Batch Acc: 84.38
[Train] Epoch: 0 [609472/620022]    Loss: 0.009579   Batch Acc: 73.44
[Train] Epoch: 0 [609536/620022]    Loss: 0.007517   Batch Acc: 76.56
[Train] Epoch: 0 [609600/620022]    Loss: 0.008297   Batch Acc: 84.38
[Train] Epoch: 0 [609664/620022]    Loss: 0.007889   Batch Acc: 78.12
[Train] Epoch: 0 [609728/620022]    Loss: 0.008259   Batch Acc: 79.69
[Train] Epoch: 0 [609792/620022]    Loss: 0.008343   Batch Acc: 79.69
[Train] Epoch: 0 [609856/620022]    Loss: 0.008189   Batch Acc: 81.25
[Train] Epoch: 0 [609920/620022]    Loss: 0.010596   Batch Acc: 73.44
[Train] Epoch: 0 [609984/620022]    Loss: 0.010495   Batch Acc: 71.88
[Train] Epoch: 0 [610048/620022]    Loss: 0.008116   Batch Acc: 75.00
[Train] Epoch: 0 [610112/620022]    Loss: 0.009762   Batch Acc: 78.12
[Train] Epoch: 0 [610176/620022]    Loss: 0.009129   Batch Acc: 79.69
[Train] Epoch: 0 [610240/620022]    Loss: 0.009977   Batch Acc: 71.88
[Train] Epoch: 0 [610304/620022]    Loss: 0.009684   Batch Acc: 81.25
[Train] Epoch: 0 [610368/620022]    Loss: 0.007959   Batch Acc: 82.81
[Train] Epoch: 0 [610432/620022]    Loss: 0.009796   Batch Acc: 75.00
[Train] Epoch: 0 [610496/620022]    Loss: 0.007898   Batch Acc: 81.25
[Train] Epoch: 0 [610560/620022]    Loss: 0.010554   Batch Acc: 73.44
[Train] Epoch: 0 [610624/620022]    Loss: 0.011186   Batch Acc: 68.75
[Train] Epoch: 0 [610688/620022]    Loss: 0.008287   Batch Acc: 79.69
[Train] Epoch: 0 [610752/620022]    Loss: 0.007423   Batch Acc: 78.12
[Train] Epoch: 0 [610816/620022]    Loss: 0.010513   Batch Acc: 76.56
[Train] Epoch: 0 [610880/620022]    Loss: 0.007321   Batch Acc: 82.81
[Train] Epoch: 0 [610944/620022]    Loss: 0.008847   Batch Acc: 75.00
[Train] Epoch: 0 [611008/620022]    Loss: 0.009026   Batch Acc: 76.56
[Train] Epoch: 0 [611072/620022]    Loss: 0.010242   Batch Acc: 76.56
[Train] Epoch: 0 [611136/620022]    Loss: 0.007218   Batch Acc: 85.94
[Train] Epoch: 0 [611200/620022]    Loss: 0.009171   Batch Acc: 73.44
[Train] Epoch: 0 [611264/620022]    Loss: 0.009254   Batch Acc: 78.12
[Train] Epoch: 0 [611328/620022]    Loss: 0.008653   Batch Acc: 82.81
[Train] Epoch: 0 [611392/620022]    Loss: 0.007689   Batch Acc: 78.12
[Train] Epoch: 0 [611456/620022]    Loss: 0.010505   Batch Acc: 73.44
[Train] Epoch: 0 [611520/620022]    Loss: 0.008799   Batch Acc: 75.00
[Train] Epoch: 0 [611584/620022]    Loss: 0.009962   Batch Acc: 79.69
[Train] Epoch: 0 [611648/620022]    Loss: 0.009079   Batch Acc: 75.00
[Train] Epoch: 0 [611712/620022]    Loss: 0.009853   Batch Acc: 76.56
[Train] Epoch: 0 [611776/620022]    Loss: 0.007830   Batch Acc: 81.25
[Train] Epoch: 0 [611840/620022]    Loss: 0.010352   Batch Acc: 73.44
[Train] Epoch: 0 [611904/620022]    Loss: 0.010482   Batch Acc: 79.69
[Train] Epoch: 0 [611968/620022]    Loss: 0.009406   Batch Acc: 75.00
[Train] Epoch: 0 [612032/620022]    Loss: 0.007115   Batch Acc: 82.81
[Train] Epoch: 0 [612096/620022]    Loss: 0.011240   Batch Acc: 70.31
[Train] Epoch: 0 [612160/620022]    Loss: 0.008436   Batch Acc: 78.12
[Train] Epoch: 0 [612224/620022]    Loss: 0.008858   Batch Acc: 81.25
[Train] Epoch: 0 [612288/620022]    Loss: 0.010880   Batch Acc: 68.75
[Train] Epoch: 0 [612352/620022]    Loss: 0.009787   Batch Acc: 71.88
[Train] Epoch: 0 [612416/620022]    Loss: 0.009177   Batch Acc: 78.12
[Train] Epoch: 0 [612480/620022]    Loss: 0.010036   Batch Acc: 73.44
[Train] Epoch: 0 [612544/620022]    Loss: 0.008033   Batch Acc: 78.12
[Train] Epoch: 0 [612608/620022]    Loss: 0.007883   Batch Acc: 79.69
[Train] Epoch: 0 [612672/620022]    Loss: 0.008187   Batch Acc: 85.94
[Train] Epoch: 0 [612736/620022]    Loss: 0.010467   Batch Acc: 75.00
[Train] Epoch: 0 [612800/620022]    Loss: 0.010531   Batch Acc: 73.44
[Train] Epoch: 0 [612864/620022]    Loss: 0.009342   Batch Acc: 79.69
[Train] Epoch: 0 [612928/620022]    Loss: 0.007848   Batch Acc: 79.69
[Train] Epoch: 0 [612992/620022]    Loss: 0.009120   Batch Acc: 76.56
[Train] Epoch: 0 [613056/620022]    Loss: 0.009442   Batch Acc: 78.12
[Train] Epoch: 0 [613120/620022]    Loss: 0.007846   Batch Acc: 79.69
[Train] Epoch: 0 [613184/620022]    Loss: 0.011472   Batch Acc: 67.19
[Train] Epoch: 0 [613248/620022]    Loss: 0.009466   Batch Acc: 65.62
[Train] Epoch: 0 [613312/620022]    Loss: 0.009482   Batch Acc: 75.00
[Train] Epoch: 0 [613376/620022]    Loss: 0.009383   Batch Acc: 75.00
[Train] Epoch: 0 [613440/620022]    Loss: 0.009800   Batch Acc: 73.44
[Train] Epoch: 0 [613504/620022]    Loss: 0.010049   Batch Acc: 76.56
[Train] Epoch: 0 [613568/620022]    Loss: 0.007817   Batch Acc: 82.81
[Train] Epoch: 0 [613632/620022]    Loss: 0.007915   Batch Acc: 82.81
[Train] Epoch: 0 [613696/620022]    Loss: 0.008445   Batch Acc: 81.25
[Train] Epoch: 0 [613760/620022]    Loss: 0.007772   Batch Acc: 81.25
[Train] Epoch: 0 [613824/620022]    Loss: 0.010975   Batch Acc: 73.44
[Train] Epoch: 0 [613888/620022]    Loss: 0.008865   Batch Acc: 73.44
[Train] Epoch: 0 [613952/620022]    Loss: 0.009860   Batch Acc: 73.44
[Train] Epoch: 0 [614016/620022]    Loss: 0.008871   Batch Acc: 73.44
[Train] Epoch: 0 [614080/620022]    Loss: 0.010398   Batch Acc: 73.44
[Train] Epoch: 0 [614144/620022]    Loss: 0.009552   Batch Acc: 75.00
[Train] Epoch: 0 [614208/620022]    Loss: 0.011898   Batch Acc: 75.00
[Train] Epoch: 0 [614272/620022]    Loss: 0.007189   Batch Acc: 84.38
[Train] Epoch: 0 [614336/620022]    Loss: 0.007627   Batch Acc: 81.25
[Train] Epoch: 0 [614400/620022]    Loss: 0.009930   Batch Acc: 75.00
[Train] Epoch: 0 [614464/620022]    Loss: 0.011069   Batch Acc: 73.44
[Train] Epoch: 0 [614528/620022]    Loss: 0.007741   Batch Acc: 84.38
[Train] Epoch: 0 [614592/620022]    Loss: 0.008377   Batch Acc: 73.44
[Train] Epoch: 0 [614656/620022]    Loss: 0.009384   Batch Acc: 75.00
[Train] Epoch: 0 [614720/620022]    Loss: 0.009827   Batch Acc: 71.88
[Train] Epoch: 0 [614784/620022]    Loss: 0.009220   Batch Acc: 76.56
[Train] Epoch: 0 [614848/620022]    Loss: 0.010114   Batch Acc: 76.56
[Train] Epoch: 0 [614912/620022]    Loss: 0.008816   Batch Acc: 76.56
[Train] Epoch: 0 [614976/620022]    Loss: 0.010126   Batch Acc: 75.00
[Train] Epoch: 0 [615040/620022]    Loss: 0.009382   Batch Acc: 71.88
[Train] Epoch: 0 [615104/620022]    Loss: 0.008696   Batch Acc: 71.88
[Train] Epoch: 0 [615168/620022]    Loss: 0.009414   Batch Acc: 67.19
[Train] Epoch: 0 [615232/620022]    Loss: 0.010899   Batch Acc: 70.31
[Train] Epoch: 0 [615296/620022]    Loss: 0.009576   Batch Acc: 71.88
[Train] Epoch: 0 [615360/620022]    Loss: 0.007006   Batch Acc: 82.81
[Train] Epoch: 0 [615424/620022]    Loss: 0.009083   Batch Acc: 70.31
[Train] Epoch: 0 [615488/620022]    Loss: 0.008970   Batch Acc: 73.44
[Train] Epoch: 0 [615552/620022]    Loss: 0.010351   Batch Acc: 67.19
[Train] Epoch: 0 [615616/620022]    Loss: 0.006962   Batch Acc: 84.38
[Train] Epoch: 0 [615680/620022]    Loss: 0.009004   Batch Acc: 76.56
[Train] Epoch: 0 [615744/620022]    Loss: 0.007702   Batch Acc: 79.69
[Train] Epoch: 0 [615808/620022]    Loss: 0.011228   Batch Acc: 75.00
[Train] Epoch: 0 [615872/620022]    Loss: 0.008594   Batch Acc: 76.56
[Train] Epoch: 0 [615936/620022]    Loss: 0.008853   Batch Acc: 82.81
[Train] Epoch: 0 [616000/620022]    Loss: 0.008388   Batch Acc: 78.12
[Train] Epoch: 0 [616064/620022]    Loss: 0.011565   Batch Acc: 70.31
[Train] Epoch: 0 [616128/620022]    Loss: 0.009198   Batch Acc: 71.88
[Train] Epoch: 0 [616192/620022]    Loss: 0.007240   Batch Acc: 78.12
[Train] Epoch: 0 [616256/620022]    Loss: 0.008426   Batch Acc: 79.69
[Train] Epoch: 0 [616320/620022]    Loss: 0.010433   Batch Acc: 70.31
[Train] Epoch: 0 [616384/620022]    Loss: 0.008540   Batch Acc: 73.44
[Train] Epoch: 0 [616448/620022]    Loss: 0.008275   Batch Acc: 79.69
[Train] Epoch: 0 [616512/620022]    Loss: 0.007839   Batch Acc: 79.69
[Train] Epoch: 0 [616576/620022]    Loss: 0.010771   Batch Acc: 70.31
[Train] Epoch: 0 [616640/620022]    Loss: 0.010639   Batch Acc: 65.62
[Train] Epoch: 0 [616704/620022]    Loss: 0.010800   Batch Acc: 70.31
[Train] Epoch: 0 [616768/620022]    Loss: 0.008500   Batch Acc: 81.25
[Train] Epoch: 0 [616832/620022]    Loss: 0.008278   Batch Acc: 76.56
[Train] Epoch: 0 [616896/620022]    Loss: 0.008114   Batch Acc: 78.12
[Train] Epoch: 0 [616960/620022]    Loss: 0.008637   Batch Acc: 79.69
[Train] Epoch: 0 [617024/620022]    Loss: 0.006801   Batch Acc: 82.81
[Train] Epoch: 0 [617088/620022]    Loss: 0.009039   Batch Acc: 73.44
[Train] Epoch: 0 [617152/620022]    Loss: 0.008879   Batch Acc: 76.56
[Train] Epoch: 0 [617216/620022]    Loss: 0.010943   Batch Acc: 70.31
[Train] Epoch: 0 [617280/620022]    Loss: 0.007307   Batch Acc: 81.25
[Train] Epoch: 0 [617344/620022]    Loss: 0.011132   Batch Acc: 67.19
[Train] Epoch: 0 [617408/620022]    Loss: 0.009776   Batch Acc: 73.44
[Train] Epoch: 0 [617472/620022]    Loss: 0.009742   Batch Acc: 75.00
[Train] Epoch: 0 [617536/620022]    Loss: 0.008682   Batch Acc: 75.00
[Train] Epoch: 0 [617600/620022]    Loss: 0.011350   Batch Acc: 70.31
[Train] Epoch: 0 [617664/620022]    Loss: 0.007301   Batch Acc: 81.25
[Train] Epoch: 0 [617728/620022]    Loss: 0.011042   Batch Acc: 68.75
[Train] Epoch: 0 [617792/620022]    Loss: 0.010095   Batch Acc: 73.44
[Train] Epoch: 0 [617856/620022]    Loss: 0.007408   Batch Acc: 76.56
[Train] Epoch: 0 [617920/620022]    Loss: 0.007570   Batch Acc: 82.81
[Train] Epoch: 0 [617984/620022]    Loss: 0.010194   Batch Acc: 75.00
[Train] Epoch: 0 [618048/620022]    Loss: 0.007667   Batch Acc: 79.69
[Train] Epoch: 0 [618112/620022]    Loss: 0.010038   Batch Acc: 73.44
[Train] Epoch: 0 [618176/620022]    Loss: 0.009917   Batch Acc: 79.69
[Train] Epoch: 0 [618240/620022]    Loss: 0.010975   Batch Acc: 67.19
[Train] Epoch: 0 [618304/620022]    Loss: 0.007462   Batch Acc: 81.25
[Train] Epoch: 0 [618368/620022]    Loss: 0.008288   Batch Acc: 78.12
[Train] Epoch: 0 [618432/620022]    Loss: 0.008531   Batch Acc: 75.00
[Train] Epoch: 0 [618496/620022]    Loss: 0.009356   Batch Acc: 73.44
[Train] Epoch: 0 [618560/620022]    Loss: 0.008138   Batch Acc: 76.56
[Train] Epoch: 0 [618624/620022]    Loss: 0.010009   Batch Acc: 76.56
[Train] Epoch: 0 [618688/620022]    Loss: 0.010811   Batch Acc: 73.44
[Train] Epoch: 0 [618752/620022]    Loss: 0.008768   Batch Acc: 79.69
[Train] Epoch: 0 [618816/620022]    Loss: 0.009425   Batch Acc: 75.00
[Train] Epoch: 0 [618880/620022]    Loss: 0.008854   Batch Acc: 84.38
[Train] Epoch: 0 [618944/620022]    Loss: 0.009376   Batch Acc: 78.12
[Train] Epoch: 0 [619008/620022]    Loss: 0.012238   Batch Acc: 60.94
[Train] Epoch: 0 [619072/620022]    Loss: 0.010110   Batch Acc: 76.56
[Train] Epoch: 0 [619136/620022]    Loss: 0.009315   Batch Acc: 78.12
[Train] Epoch: 0 [619200/620022]    Loss: 0.011715   Batch Acc: 67.19
[Train] Epoch: 0 [619264/620022]    Loss: 0.010489   Batch Acc: 76.56
[Train] Epoch: 0 [619328/620022]    Loss: 0.007248   Batch Acc: 79.69
[Train] Epoch: 0 [619392/620022]    Loss: 0.010312   Batch Acc: 65.62
[Train] Epoch: 0 [619456/620022]    Loss: 0.012463   Batch Acc: 68.75
[Train] Epoch: 0 [619520/620022]    Loss: 0.007028   Batch Acc: 84.38
[Train] Epoch: 0 [619584/620022]    Loss: 0.009622   Batch Acc: 70.31
[Train] Epoch: 0 [619648/620022]    Loss: 0.006831   Batch Acc: 89.06
[Train] Epoch: 0 [619712/620022]    Loss: 0.009909   Batch Acc: 71.88
[Train] Epoch: 0 [619776/620022]    Loss: 0.007440   Batch Acc: 81.25
[Train] Epoch: 0 [619840/620022]    Loss: 0.007589   Batch Acc: 75.00
[Train] Epoch: 0 [619904/620022]    Loss: 0.010332   Batch Acc: 75.00
[Train] Epoch: 0 [619968/620022]    Loss: 0.009428   Batch Acc: 78.12
[Train] Epoch: 0 [523152/620022]    Loss: 0.012359   Batch Acc: 72.22
Validation Done: [64/154214]
Validation Done: [128/154214]
Validation Done: [192/154214]
Validation Done: [256/154214]
Validation Done: [320/154214]
Validation Done: [384/154214]
Validation Done: [448/154214]
Validation Done: [512/154214]
Validation Done: [576/154214]
Validation Done: [640/154214]
Validation Done: [704/154214]
Validation Done: [768/154214]
Validation Done: [832/154214]
Validation Done: [896/154214]
Validation Done: [960/154214]
Validation Done: [1024/154214]
Validation Done: [1088/154214]
Validation Done: [1152/154214]
Validation Done: [1216/154214]
Validation Done: [1280/154214]
Validation Done: [1344/154214]
Validation Done: [1408/154214]
Validation Done: [1472/154214]
Validation Done: [1536/154214]
Validation Done: [1600/154214]
Validation Done: [1664/154214]
Validation Done: [1728/154214]
Validation Done: [1792/154214]
Validation Done: [1856/154214]
Validation Done: [1920/154214]
Validation Done: [1984/154214]
Validation Done: [2048/154214]
Validation Done: [2112/154214]
Validation Done: [2176/154214]
Validation Done: [2240/154214]
Validation Done: [2304/154214]
Validation Done: [2368/154214]
Validation Done: [2432/154214]
Validation Done: [2496/154214]
Validation Done: [2560/154214]
Validation Done: [2624/154214]
Validation Done: [2688/154214]
Validation Done: [2752/154214]
Validation Done: [2816/154214]
Validation Done: [2880/154214]
Validation Done: [2944/154214]
Validation Done: [3008/154214]
Validation Done: [3072/154214]
Validation Done: [3136/154214]
Validation Done: [3200/154214]
Validation Done: [3264/154214]
Validation Done: [3328/154214]
Validation Done: [3392/154214]
Validation Done: [3456/154214]
Validation Done: [3520/154214]
Validation Done: [3584/154214]
Validation Done: [3648/154214]
Validation Done: [3712/154214]
Validation Done: [3776/154214]
Validation Done: [3840/154214]
Validation Done: [3904/154214]
Validation Done: [3968/154214]
Validation Done: [4032/154214]
Validation Done: [4096/154214]
Validation Done: [4160/154214]
Validation Done: [4224/154214]
Validation Done: [4288/154214]
Validation Done: [4352/154214]
Validation Done: [4416/154214]
Validation Done: [4480/154214]
Validation Done: [4544/154214]
Validation Done: [4608/154214]
Validation Done: [4672/154214]
Validation Done: [4736/154214]
Validation Done: [4800/154214]
Validation Done: [4864/154214]
Validation Done: [4928/154214]
Validation Done: [4992/154214]
Validation Done: [5056/154214]
Validation Done: [5120/154214]
Validation Done: [5184/154214]
Validation Done: [5248/154214]
Validation Done: [5312/154214]
Validation Done: [5376/154214]
Validation Done: [5440/154214]
Validation Done: [5504/154214]
Validation Done: [5568/154214]
Validation Done: [5632/154214]
Validation Done: [5696/154214]
Validation Done: [5760/154214]
Validation Done: [5824/154214]
Validation Done: [5888/154214]
Validation Done: [5952/154214]
Validation Done: [6016/154214]
Validation Done: [6080/154214]
Validation Done: [6144/154214]
Validation Done: [6208/154214]
Validation Done: [6272/154214]
Validation Done: [6336/154214]
Validation Done: [6400/154214]
Validation Done: [6464/154214]
Validation Done: [6528/154214]
Validation Done: [6592/154214]
Validation Done: [6656/154214]
Validation Done: [6720/154214]
Validation Done: [6784/154214]
Validation Done: [6848/154214]
Validation Done: [6912/154214]
Validation Done: [6976/154214]
Validation Done: [7040/154214]
Validation Done: [7104/154214]
Validation Done: [7168/154214]
Validation Done: [7232/154214]
Validation Done: [7296/154214]
Validation Done: [7360/154214]
Validation Done: [7424/154214]
Validation Done: [7488/154214]
Validation Done: [7552/154214]
Validation Done: [7616/154214]
Validation Done: [7680/154214]
Validation Done: [7744/154214]
Validation Done: [7808/154214]
Validation Done: [7872/154214]
Validation Done: [7936/154214]
Validation Done: [8000/154214]
Validation Done: [8064/154214]
Validation Done: [8128/154214]
Validation Done: [8192/154214]
Validation Done: [8256/154214]
Validation Done: [8320/154214]
Validation Done: [8384/154214]
Validation Done: [8448/154214]
Validation Done: [8512/154214]
Validation Done: [8576/154214]
Validation Done: [8640/154214]
Validation Done: [8704/154214]
Validation Done: [8768/154214]
Validation Done: [8832/154214]
Validation Done: [8896/154214]
Validation Done: [8960/154214]
Validation Done: [9024/154214]
Validation Done: [9088/154214]
Validation Done: [9152/154214]
Validation Done: [9216/154214]
Validation Done: [9280/154214]
Validation Done: [9344/154214]
Validation Done: [9408/154214]
Validation Done: [9472/154214]
Validation Done: [9536/154214]
Validation Done: [9600/154214]
Validation Done: [9664/154214]
Validation Done: [9728/154214]
Validation Done: [9792/154214]
Validation Done: [9856/154214]
Validation Done: [9920/154214]
Validation Done: [9984/154214]
Validation Done: [10048/154214]
Validation Done: [10112/154214]
Validation Done: [10176/154214]
Validation Done: [10240/154214]
Validation Done: [10304/154214]
Validation Done: [10368/154214]
Validation Done: [10432/154214]
Validation Done: [10496/154214]
Validation Done: [10560/154214]
Validation Done: [10624/154214]
Validation Done: [10688/154214]
Validation Done: [10752/154214]
Validation Done: [10816/154214]
Validation Done: [10880/154214]
Validation Done: [10944/154214]
Validation Done: [11008/154214]
Validation Done: [11072/154214]
Validation Done: [11136/154214]
Validation Done: [11200/154214]
Validation Done: [11264/154214]
Validation Done: [11328/154214]
Validation Done: [11392/154214]
Validation Done: [11456/154214]
Validation Done: [11520/154214]
Validation Done: [11584/154214]
Validation Done: [11648/154214]
Validation Done: [11712/154214]
Validation Done: [11776/154214]
Validation Done: [11840/154214]
Validation Done: [11904/154214]
Validation Done: [11968/154214]
Validation Done: [12032/154214]
Validation Done: [12096/154214]
Validation Done: [12160/154214]
Validation Done: [12224/154214]
Validation Done: [12288/154214]
Validation Done: [12352/154214]
Validation Done: [12416/154214]
Validation Done: [12480/154214]
Validation Done: [12544/154214]
Validation Done: [12608/154214]
Validation Done: [12672/154214]
Validation Done: [12736/154214]
Validation Done: [12800/154214]
Validation Done: [12864/154214]
Validation Done: [12928/154214]
Validation Done: [12992/154214]
Validation Done: [13056/154214]
Validation Done: [13120/154214]
Validation Done: [13184/154214]
Validation Done: [13248/154214]
Validation Done: [13312/154214]
Validation Done: [13376/154214]
Validation Done: [13440/154214]
Validation Done: [13504/154214]
Validation Done: [13568/154214]
Validation Done: [13632/154214]
Validation Done: [13696/154214]
Validation Done: [13760/154214]
Validation Done: [13824/154214]
Validation Done: [13888/154214]
Validation Done: [13952/154214]
Validation Done: [14016/154214]
Validation Done: [14080/154214]
Validation Done: [14144/154214]
Validation Done: [14208/154214]
Validation Done: [14272/154214]
Validation Done: [14336/154214]
Validation Done: [14400/154214]
Validation Done: [14464/154214]
Validation Done: [14528/154214]
Validation Done: [14592/154214]
Validation Done: [14656/154214]
Validation Done: [14720/154214]
Validation Done: [14784/154214]
Validation Done: [14848/154214]
Validation Done: [14912/154214]
Validation Done: [14976/154214]
Validation Done: [15040/154214]
Validation Done: [15104/154214]
Validation Done: [15168/154214]
Validation Done: [15232/154214]
Validation Done: [15296/154214]
Validation Done: [15360/154214]
Validation Done: [15424/154214]
Validation Done: [15488/154214]
Validation Done: [15552/154214]
Validation Done: [15616/154214]
Validation Done: [15680/154214]
Validation Done: [15744/154214]
Validation Done: [15808/154214]
Validation Done: [15872/154214]
Validation Done: [15936/154214]
Validation Done: [16000/154214]
Validation Done: [16064/154214]
Validation Done: [16128/154214]
Validation Done: [16192/154214]
Validation Done: [16256/154214]
Validation Done: [16320/154214]
Validation Done: [16384/154214]
Validation Done: [16448/154214]
Validation Done: [16512/154214]
Validation Done: [16576/154214]
Validation Done: [16640/154214]
Validation Done: [16704/154214]
Validation Done: [16768/154214]
Validation Done: [16832/154214]
Validation Done: [16896/154214]
Validation Done: [16960/154214]
Validation Done: [17024/154214]
Validation Done: [17088/154214]
Validation Done: [17152/154214]
Validation Done: [17216/154214]
Validation Done: [17280/154214]
Validation Done: [17344/154214]
Validation Done: [17408/154214]
Validation Done: [17472/154214]
Validation Done: [17536/154214]
Validation Done: [17600/154214]
Validation Done: [17664/154214]
Validation Done: [17728/154214]
Validation Done: [17792/154214]
Validation Done: [17856/154214]
Validation Done: [17920/154214]
Validation Done: [17984/154214]
Validation Done: [18048/154214]
Validation Done: [18112/154214]
Validation Done: [18176/154214]
Validation Done: [18240/154214]
Validation Done: [18304/154214]
Validation Done: [18368/154214]
Validation Done: [18432/154214]
Validation Done: [18496/154214]
Validation Done: [18560/154214]
Validation Done: [18624/154214]
Validation Done: [18688/154214]
Validation Done: [18752/154214]
Validation Done: [18816/154214]
Validation Done: [18880/154214]
Validation Done: [18944/154214]
Validation Done: [19008/154214]
Validation Done: [19072/154214]
Validation Done: [19136/154214]
Validation Done: [19200/154214]
Validation Done: [19264/154214]
Validation Done: [19328/154214]
Validation Done: [19392/154214]
Validation Done: [19456/154214]
Validation Done: [19520/154214]
Validation Done: [19584/154214]
Validation Done: [19648/154214]
Validation Done: [19712/154214]
Validation Done: [19776/154214]
Validation Done: [19840/154214]
Validation Done: [19904/154214]
Validation Done: [19968/154214]
Validation Done: [20032/154214]
Validation Done: [20096/154214]
Validation Done: [20160/154214]
Validation Done: [20224/154214]
Validation Done: [20288/154214]
Validation Done: [20352/154214]
Validation Done: [20416/154214]
Validation Done: [20480/154214]
Validation Done: [20544/154214]
Validation Done: [20608/154214]
Validation Done: [20672/154214]
Validation Done: [20736/154214]
Validation Done: [20800/154214]
Validation Done: [20864/154214]
Validation Done: [20928/154214]
Validation Done: [20992/154214]
Validation Done: [21056/154214]
Validation Done: [21120/154214]
Validation Done: [21184/154214]
Validation Done: [21248/154214]
Validation Done: [21312/154214]
Validation Done: [21376/154214]
Validation Done: [21440/154214]
Validation Done: [21504/154214]
Validation Done: [21568/154214]
Validation Done: [21632/154214]
Validation Done: [21696/154214]
Validation Done: [21760/154214]
Validation Done: [21824/154214]
Validation Done: [21888/154214]
Validation Done: [21952/154214]
Validation Done: [22016/154214]
Validation Done: [22080/154214]
Validation Done: [22144/154214]
Validation Done: [22208/154214]
Validation Done: [22272/154214]
Validation Done: [22336/154214]
Validation Done: [22400/154214]
Validation Done: [22464/154214]
Validation Done: [22528/154214]
Validation Done: [22592/154214]
Validation Done: [22656/154214]
Validation Done: [22720/154214]
Validation Done: [22784/154214]
Validation Done: [22848/154214]
Validation Done: [22912/154214]
Validation Done: [22976/154214]
Validation Done: [23040/154214]
Validation Done: [23104/154214]
Validation Done: [23168/154214]
Validation Done: [23232/154214]
Validation Done: [23296/154214]
Validation Done: [23360/154214]
Validation Done: [23424/154214]
Validation Done: [23488/154214]
Validation Done: [23552/154214]
Validation Done: [23616/154214]
Validation Done: [23680/154214]
Validation Done: [23744/154214]
Validation Done: [23808/154214]
Validation Done: [23872/154214]
Validation Done: [23936/154214]
Validation Done: [24000/154214]
Validation Done: [24064/154214]
Validation Done: [24128/154214]
Validation Done: [24192/154214]
Validation Done: [24256/154214]
Validation Done: [24320/154214]
Validation Done: [24384/154214]
Validation Done: [24448/154214]
Validation Done: [24512/154214]
Validation Done: [24576/154214]
Validation Done: [24640/154214]
Validation Done: [24704/154214]
Validation Done: [24768/154214]
Validation Done: [24832/154214]
Validation Done: [24896/154214]
Validation Done: [24960/154214]
Validation Done: [25024/154214]
Validation Done: [25088/154214]
Validation Done: [25152/154214]
Validation Done: [25216/154214]
Validation Done: [25280/154214]
Validation Done: [25344/154214]
Validation Done: [25408/154214]
Validation Done: [25472/154214]
Validation Done: [25536/154214]
Validation Done: [25600/154214]
Validation Done: [25664/154214]
Validation Done: [25728/154214]
Validation Done: [25792/154214]
Validation Done: [25856/154214]
Validation Done: [25920/154214]
Validation Done: [25984/154214]
Validation Done: [26048/154214]
Validation Done: [26112/154214]
Validation Done: [26176/154214]
Validation Done: [26240/154214]
Validation Done: [26304/154214]
Validation Done: [26368/154214]
Validation Done: [26432/154214]
Validation Done: [26496/154214]
Validation Done: [26560/154214]
Validation Done: [26624/154214]
Validation Done: [26688/154214]
Validation Done: [26752/154214]
Validation Done: [26816/154214]
Validation Done: [26880/154214]
Validation Done: [26944/154214]
Validation Done: [27008/154214]
Validation Done: [27072/154214]
Validation Done: [27136/154214]
Validation Done: [27200/154214]
Validation Done: [27264/154214]
Validation Done: [27328/154214]
Validation Done: [27392/154214]
Validation Done: [27456/154214]
Validation Done: [27520/154214]
Validation Done: [27584/154214]
Validation Done: [27648/154214]
Validation Done: [27712/154214]
Validation Done: [27776/154214]
Validation Done: [27840/154214]
Validation Done: [27904/154214]
Validation Done: [27968/154214]
Validation Done: [28032/154214]
Validation Done: [28096/154214]
Validation Done: [28160/154214]
Validation Done: [28224/154214]
Validation Done: [28288/154214]
Validation Done: [28352/154214]
Validation Done: [28416/154214]
Validation Done: [28480/154214]
Validation Done: [28544/154214]
Validation Done: [28608/154214]
Validation Done: [28672/154214]
Validation Done: [28736/154214]
Validation Done: [28800/154214]
Validation Done: [28864/154214]
Validation Done: [28928/154214]
Validation Done: [28992/154214]
Validation Done: [29056/154214]
Validation Done: [29120/154214]
Validation Done: [29184/154214]
Validation Done: [29248/154214]
Validation Done: [29312/154214]
Validation Done: [29376/154214]
Validation Done: [29440/154214]
Validation Done: [29504/154214]
Validation Done: [29568/154214]
Validation Done: [29632/154214]
Validation Done: [29696/154214]
Validation Done: [29760/154214]
Validation Done: [29824/154214]
Validation Done: [29888/154214]
Validation Done: [29952/154214]
Validation Done: [30016/154214]
Validation Done: [30080/154214]
Validation Done: [30144/154214]
Validation Done: [30208/154214]
Validation Done: [30272/154214]
Validation Done: [30336/154214]
Validation Done: [30400/154214]
Validation Done: [30464/154214]
Validation Done: [30528/154214]
Validation Done: [30592/154214]
Validation Done: [30656/154214]
Validation Done: [30720/154214]
Validation Done: [30784/154214]
Validation Done: [30848/154214]
Validation Done: [30912/154214]
Validation Done: [30976/154214]
Validation Done: [31040/154214]
Validation Done: [31104/154214]
Validation Done: [31168/154214]
Validation Done: [31232/154214]
Validation Done: [31296/154214]
Validation Done: [31360/154214]
Validation Done: [31424/154214]
Validation Done: [31488/154214]
Validation Done: [31552/154214]
Validation Done: [31616/154214]
Validation Done: [31680/154214]
Validation Done: [31744/154214]
Validation Done: [31808/154214]
Validation Done: [31872/154214]
Validation Done: [31936/154214]
Validation Done: [32000/154214]
Validation Done: [32064/154214]
Validation Done: [32128/154214]
Validation Done: [32192/154214]
Validation Done: [32256/154214]
Validation Done: [32320/154214]
Validation Done: [32384/154214]
Validation Done: [32448/154214]
Validation Done: [32512/154214]
Validation Done: [32576/154214]
Validation Done: [32640/154214]
Validation Done: [32704/154214]
Validation Done: [32768/154214]
Validation Done: [32832/154214]
Validation Done: [32896/154214]
Validation Done: [32960/154214]
Validation Done: [33024/154214]
Validation Done: [33088/154214]
Validation Done: [33152/154214]
Validation Done: [33216/154214]
Validation Done: [33280/154214]
Validation Done: [33344/154214]
Validation Done: [33408/154214]
Validation Done: [33472/154214]
Validation Done: [33536/154214]
Validation Done: [33600/154214]
Validation Done: [33664/154214]
Validation Done: [33728/154214]
Validation Done: [33792/154214]
Validation Done: [33856/154214]
Validation Done: [33920/154214]
Validation Done: [33984/154214]
Validation Done: [34048/154214]
Validation Done: [34112/154214]
Validation Done: [34176/154214]
Validation Done: [34240/154214]
Validation Done: [34304/154214]
Validation Done: [34368/154214]
Validation Done: [34432/154214]
Validation Done: [34496/154214]
Validation Done: [34560/154214]
Validation Done: [34624/154214]
Validation Done: [34688/154214]
Validation Done: [34752/154214]
Validation Done: [34816/154214]
Validation Done: [34880/154214]
Validation Done: [34944/154214]
Validation Done: [35008/154214]
Validation Done: [35072/154214]
Validation Done: [35136/154214]
Validation Done: [35200/154214]
Validation Done: [35264/154214]
Validation Done: [35328/154214]
Validation Done: [35392/154214]
Validation Done: [35456/154214]
Validation Done: [35520/154214]
Validation Done: [35584/154214]
Validation Done: [35648/154214]
Validation Done: [35712/154214]
Validation Done: [35776/154214]
Validation Done: [35840/154214]
Validation Done: [35904/154214]
Validation Done: [35968/154214]
Validation Done: [36032/154214]
Validation Done: [36096/154214]
Validation Done: [36160/154214]
Validation Done: [36224/154214]
Validation Done: [36288/154214]
Validation Done: [36352/154214]
Validation Done: [36416/154214]
Validation Done: [36480/154214]
Validation Done: [36544/154214]
Validation Done: [36608/154214]
Validation Done: [36672/154214]
Validation Done: [36736/154214]
Validation Done: [36800/154214]
Validation Done: [36864/154214]
Validation Done: [36928/154214]
Validation Done: [36992/154214]
Validation Done: [37056/154214]
Validation Done: [37120/154214]
Validation Done: [37184/154214]
Validation Done: [37248/154214]
Validation Done: [37312/154214]
Validation Done: [37376/154214]
Validation Done: [37440/154214]
Validation Done: [37504/154214]
Validation Done: [37568/154214]
Validation Done: [37632/154214]
Validation Done: [37696/154214]
Validation Done: [37760/154214]
Validation Done: [37824/154214]
Validation Done: [37888/154214]
Validation Done: [37952/154214]
Validation Done: [38016/154214]
Validation Done: [38080/154214]
Validation Done: [38144/154214]
Validation Done: [38208/154214]
Validation Done: [38272/154214]
Validation Done: [38336/154214]
Validation Done: [38400/154214]
Validation Done: [38464/154214]
Validation Done: [38528/154214]
Validation Done: [38592/154214]
Validation Done: [38656/154214]
Validation Done: [38720/154214]
Validation Done: [38784/154214]
Validation Done: [38848/154214]
Validation Done: [38912/154214]
Validation Done: [38976/154214]
Validation Done: [39040/154214]
Validation Done: [39104/154214]
Validation Done: [39168/154214]
Validation Done: [39232/154214]
Validation Done: [39296/154214]
Validation Done: [39360/154214]
Validation Done: [39424/154214]
Validation Done: [39488/154214]
Validation Done: [39552/154214]
Validation Done: [39616/154214]
Validation Done: [39680/154214]
Validation Done: [39744/154214]
Validation Done: [39808/154214]
Validation Done: [39872/154214]
Validation Done: [39936/154214]
Validation Done: [40000/154214]
Validation Done: [40064/154214]
Validation Done: [40128/154214]
Validation Done: [40192/154214]
Validation Done: [40256/154214]
Validation Done: [40320/154214]
Validation Done: [40384/154214]
Validation Done: [40448/154214]
Validation Done: [40512/154214]
Validation Done: [40576/154214]
Validation Done: [40640/154214]
Validation Done: [40704/154214]
Validation Done: [40768/154214]
Validation Done: [40832/154214]
Validation Done: [40896/154214]
Validation Done: [40960/154214]
Validation Done: [41024/154214]
Validation Done: [41088/154214]
Validation Done: [41152/154214]
Validation Done: [41216/154214]
Validation Done: [41280/154214]
Validation Done: [41344/154214]
Validation Done: [41408/154214]
Validation Done: [41472/154214]
Validation Done: [41536/154214]
Validation Done: [41600/154214]
Validation Done: [41664/154214]
Validation Done: [41728/154214]
Validation Done: [41792/154214]
Validation Done: [41856/154214]
Validation Done: [41920/154214]
Validation Done: [41984/154214]
Validation Done: [42048/154214]
Validation Done: [42112/154214]
Validation Done: [42176/154214]
Validation Done: [42240/154214]
Validation Done: [42304/154214]
Validation Done: [42368/154214]
Validation Done: [42432/154214]
Validation Done: [42496/154214]
Validation Done: [42560/154214]
Validation Done: [42624/154214]
Validation Done: [42688/154214]
Validation Done: [42752/154214]
Validation Done: [42816/154214]
Validation Done: [42880/154214]
Validation Done: [42944/154214]
Validation Done: [43008/154214]
Validation Done: [43072/154214]
Validation Done: [43136/154214]
Validation Done: [43200/154214]
Validation Done: [43264/154214]
Validation Done: [43328/154214]
Validation Done: [43392/154214]
Validation Done: [43456/154214]
Validation Done: [43520/154214]
Validation Done: [43584/154214]
Validation Done: [43648/154214]
Validation Done: [43712/154214]
Validation Done: [43776/154214]
Validation Done: [43840/154214]
Validation Done: [43904/154214]
Validation Done: [43968/154214]
Validation Done: [44032/154214]
Validation Done: [44096/154214]
Validation Done: [44160/154214]
Validation Done: [44224/154214]
Validation Done: [44288/154214]
Validation Done: [44352/154214]
Validation Done: [44416/154214]
Validation Done: [44480/154214]
Validation Done: [44544/154214]
Validation Done: [44608/154214]
Validation Done: [44672/154214]
Validation Done: [44736/154214]
Validation Done: [44800/154214]
Validation Done: [44864/154214]
Validation Done: [44928/154214]
Validation Done: [44992/154214]
Validation Done: [45056/154214]
Validation Done: [45120/154214]
Validation Done: [45184/154214]
Validation Done: [45248/154214]
Validation Done: [45312/154214]
Validation Done: [45376/154214]
Validation Done: [45440/154214]
Validation Done: [45504/154214]
Validation Done: [45568/154214]
Validation Done: [45632/154214]
Validation Done: [45696/154214]
Validation Done: [45760/154214]
Validation Done: [45824/154214]
Validation Done: [45888/154214]
Validation Done: [45952/154214]
Validation Done: [46016/154214]
Validation Done: [46080/154214]
Validation Done: [46144/154214]
Validation Done: [46208/154214]
Validation Done: [46272/154214]
Validation Done: [46336/154214]
Validation Done: [46400/154214]
Validation Done: [46464/154214]
Validation Done: [46528/154214]
Validation Done: [46592/154214]
Validation Done: [46656/154214]
Validation Done: [46720/154214]
Validation Done: [46784/154214]
Validation Done: [46848/154214]
Validation Done: [46912/154214]
Validation Done: [46976/154214]
Validation Done: [47040/154214]
Validation Done: [47104/154214]
Validation Done: [47168/154214]
Validation Done: [47232/154214]
Validation Done: [47296/154214]
Validation Done: [47360/154214]
Validation Done: [47424/154214]
Validation Done: [47488/154214]
Validation Done: [47552/154214]
Validation Done: [47616/154214]
Validation Done: [47680/154214]
Validation Done: [47744/154214]
Validation Done: [47808/154214]
Validation Done: [47872/154214]
Validation Done: [47936/154214]
Validation Done: [48000/154214]
Validation Done: [48064/154214]
Validation Done: [48128/154214]
Validation Done: [48192/154214]
Validation Done: [48256/154214]
Validation Done: [48320/154214]
Validation Done: [48384/154214]
Validation Done: [48448/154214]
Validation Done: [48512/154214]
Validation Done: [48576/154214]
Validation Done: [48640/154214]
Validation Done: [48704/154214]
Validation Done: [48768/154214]
Validation Done: [48832/154214]
Validation Done: [48896/154214]
Validation Done: [48960/154214]
Validation Done: [49024/154214]
Validation Done: [49088/154214]
Validation Done: [49152/154214]
Validation Done: [49216/154214]
Validation Done: [49280/154214]
Validation Done: [49344/154214]
Validation Done: [49408/154214]
Validation Done: [49472/154214]
Validation Done: [49536/154214]
Validation Done: [49600/154214]
Validation Done: [49664/154214]
Validation Done: [49728/154214]
Validation Done: [49792/154214]
Validation Done: [49856/154214]
Validation Done: [49920/154214]
Validation Done: [49984/154214]
Validation Done: [50048/154214]
Validation Done: [50112/154214]
Validation Done: [50176/154214]
Validation Done: [50240/154214]
Validation Done: [50304/154214]
Validation Done: [50368/154214]
Validation Done: [50432/154214]
Validation Done: [50496/154214]
Validation Done: [50560/154214]
Validation Done: [50624/154214]
Validation Done: [50688/154214]
Validation Done: [50752/154214]
Validation Done: [50816/154214]
Validation Done: [50880/154214]
Validation Done: [50944/154214]
Validation Done: [51008/154214]
Validation Done: [51072/154214]
Validation Done: [51136/154214]
Validation Done: [51200/154214]
Validation Done: [51264/154214]
Validation Done: [51328/154214]
Validation Done: [51392/154214]
Validation Done: [51456/154214]
Validation Done: [51520/154214]
Validation Done: [51584/154214]
Validation Done: [51648/154214]
Validation Done: [51712/154214]
Validation Done: [51776/154214]
Validation Done: [51840/154214]
Validation Done: [51904/154214]
Validation Done: [51968/154214]
Validation Done: [52032/154214]
Validation Done: [52096/154214]
Validation Done: [52160/154214]
Validation Done: [52224/154214]
Validation Done: [52288/154214]
Validation Done: [52352/154214]
Validation Done: [52416/154214]
Validation Done: [52480/154214]
Validation Done: [52544/154214]
Validation Done: [52608/154214]
Validation Done: [52672/154214]
Validation Done: [52736/154214]
Validation Done: [52800/154214]
Validation Done: [52864/154214]
Validation Done: [52928/154214]
Validation Done: [52992/154214]
Validation Done: [53056/154214]
Validation Done: [53120/154214]
Validation Done: [53184/154214]
Validation Done: [53248/154214]
Validation Done: [53312/154214]
Validation Done: [53376/154214]
Validation Done: [53440/154214]
Validation Done: [53504/154214]
Validation Done: [53568/154214]
Validation Done: [53632/154214]
Validation Done: [53696/154214]
Validation Done: [53760/154214]
Validation Done: [53824/154214]
Validation Done: [53888/154214]
Validation Done: [53952/154214]
Validation Done: [54016/154214]
Validation Done: [54080/154214]
Validation Done: [54144/154214]
Validation Done: [54208/154214]
Validation Done: [54272/154214]
Validation Done: [54336/154214]
Validation Done: [54400/154214]
Validation Done: [54464/154214]
Validation Done: [54528/154214]
Validation Done: [54592/154214]
Validation Done: [54656/154214]
Validation Done: [54720/154214]
Validation Done: [54784/154214]
Validation Done: [54848/154214]
Validation Done: [54912/154214]
Validation Done: [54976/154214]
Validation Done: [55040/154214]
Validation Done: [55104/154214]
Validation Done: [55168/154214]
Validation Done: [55232/154214]
Validation Done: [55296/154214]
Validation Done: [55360/154214]
Validation Done: [55424/154214]
Validation Done: [55488/154214]
Validation Done: [55552/154214]
Validation Done: [55616/154214]
Validation Done: [55680/154214]
Validation Done: [55744/154214]
Validation Done: [55808/154214]
Validation Done: [55872/154214]
Validation Done: [55936/154214]
Validation Done: [56000/154214]
Validation Done: [56064/154214]
Validation Done: [56128/154214]
Validation Done: [56192/154214]
Validation Done: [56256/154214]
Validation Done: [56320/154214]
Validation Done: [56384/154214]
Validation Done: [56448/154214]
Validation Done: [56512/154214]
Validation Done: [56576/154214]
Validation Done: [56640/154214]
Validation Done: [56704/154214]
Validation Done: [56768/154214]
Validation Done: [56832/154214]
Validation Done: [56896/154214]
Validation Done: [56960/154214]
Validation Done: [57024/154214]
Validation Done: [57088/154214]
Validation Done: [57152/154214]
Validation Done: [57216/154214]
Validation Done: [57280/154214]
Validation Done: [57344/154214]
Validation Done: [57408/154214]
Validation Done: [57472/154214]
Validation Done: [57536/154214]
Validation Done: [57600/154214]
Validation Done: [57664/154214]
Validation Done: [57728/154214]
Validation Done: [57792/154214]
Validation Done: [57856/154214]
Validation Done: [57920/154214]
Validation Done: [57984/154214]
Validation Done: [58048/154214]
Validation Done: [58112/154214]
Validation Done: [58176/154214]
Validation Done: [58240/154214]
Validation Done: [58304/154214]
Validation Done: [58368/154214]
Validation Done: [58432/154214]
Validation Done: [58496/154214]
Validation Done: [58560/154214]
Validation Done: [58624/154214]
Validation Done: [58688/154214]
Validation Done: [58752/154214]
Validation Done: [58816/154214]
Validation Done: [58880/154214]
Validation Done: [58944/154214]
Validation Done: [59008/154214]
Validation Done: [59072/154214]
Validation Done: [59136/154214]
Validation Done: [59200/154214]
Validation Done: [59264/154214]
Validation Done: [59328/154214]
Validation Done: [59392/154214]
Validation Done: [59456/154214]
Validation Done: [59520/154214]
Validation Done: [59584/154214]
Validation Done: [59648/154214]
Validation Done: [59712/154214]
Validation Done: [59776/154214]
Validation Done: [59840/154214]
Validation Done: [59904/154214]
Validation Done: [59968/154214]
Validation Done: [60032/154214]
Validation Done: [60096/154214]
Validation Done: [60160/154214]
Validation Done: [60224/154214]
Validation Done: [60288/154214]
Validation Done: [60352/154214]
Validation Done: [60416/154214]
Validation Done: [60480/154214]
Validation Done: [60544/154214]
Validation Done: [60608/154214]
Validation Done: [60672/154214]
Validation Done: [60736/154214]
Validation Done: [60800/154214]
Validation Done: [60864/154214]
Validation Done: [60928/154214]
Validation Done: [60992/154214]
Validation Done: [61056/154214]
Validation Done: [61120/154214]
Validation Done: [61184/154214]
Validation Done: [61248/154214]
Validation Done: [61312/154214]
Validation Done: [61376/154214]
Validation Done: [61440/154214]
Validation Done: [61504/154214]
Validation Done: [61568/154214]
Validation Done: [61632/154214]
Validation Done: [61696/154214]
Validation Done: [61760/154214]
Validation Done: [61824/154214]
Validation Done: [61888/154214]
Validation Done: [61952/154214]
Validation Done: [62016/154214]
Validation Done: [62080/154214]
Validation Done: [62144/154214]
Validation Done: [62208/154214]
Validation Done: [62272/154214]
Validation Done: [62336/154214]
Validation Done: [62400/154214]
Validation Done: [62464/154214]
Validation Done: [62528/154214]
Validation Done: [62592/154214]
Validation Done: [62656/154214]
Validation Done: [62720/154214]
Validation Done: [62784/154214]
Validation Done: [62848/154214]
Validation Done: [62912/154214]
Validation Done: [62976/154214]
Validation Done: [63040/154214]
Validation Done: [63104/154214]
Validation Done: [63168/154214]
Validation Done: [63232/154214]
Validation Done: [63296/154214]
Validation Done: [63360/154214]
Validation Done: [63424/154214]
Validation Done: [63488/154214]
Validation Done: [63552/154214]
Validation Done: [63616/154214]
Validation Done: [63680/154214]
Validation Done: [63744/154214]
Validation Done: [63808/154214]
Validation Done: [63872/154214]
Validation Done: [63936/154214]
Validation Done: [64000/154214]
Validation Done: [64064/154214]
Validation Done: [64128/154214]
Validation Done: [64192/154214]
Validation Done: [64256/154214]
Validation Done: [64320/154214]
Validation Done: [64384/154214]
Validation Done: [64448/154214]
Validation Done: [64512/154214]
Validation Done: [64576/154214]
Validation Done: [64640/154214]
Validation Done: [64704/154214]
Validation Done: [64768/154214]
Validation Done: [64832/154214]
Validation Done: [64896/154214]
Validation Done: [64960/154214]
Validation Done: [65024/154214]
Validation Done: [65088/154214]
Validation Done: [65152/154214]
Validation Done: [65216/154214]
Validation Done: [65280/154214]
Validation Done: [65344/154214]
Validation Done: [65408/154214]
Validation Done: [65472/154214]
Validation Done: [65536/154214]
Validation Done: [65600/154214]
Validation Done: [65664/154214]
Validation Done: [65728/154214]
Validation Done: [65792/154214]
Validation Done: [65856/154214]
Validation Done: [65920/154214]
Validation Done: [65984/154214]
Validation Done: [66048/154214]
Validation Done: [66112/154214]
Validation Done: [66176/154214]
Validation Done: [66240/154214]
Validation Done: [66304/154214]
Validation Done: [66368/154214]
Validation Done: [66432/154214]
Validation Done: [66496/154214]
Validation Done: [66560/154214]
Validation Done: [66624/154214]
Validation Done: [66688/154214]
Validation Done: [66752/154214]
Validation Done: [66816/154214]
Validation Done: [66880/154214]
Validation Done: [66944/154214]
Validation Done: [67008/154214]
Validation Done: [67072/154214]
Validation Done: [67136/154214]
Validation Done: [67200/154214]
Validation Done: [67264/154214]
Validation Done: [67328/154214]
Validation Done: [67392/154214]
Validation Done: [67456/154214]
Validation Done: [67520/154214]
Validation Done: [67584/154214]
Validation Done: [67648/154214]
Validation Done: [67712/154214]
Validation Done: [67776/154214]
Validation Done: [67840/154214]
Validation Done: [67904/154214]
Validation Done: [67968/154214]
Validation Done: [68032/154214]
Validation Done: [68096/154214]
Validation Done: [68160/154214]
Validation Done: [68224/154214]
Validation Done: [68288/154214]
Validation Done: [68352/154214]
Validation Done: [68416/154214]
Validation Done: [68480/154214]
Validation Done: [68544/154214]
Validation Done: [68608/154214]
Validation Done: [68672/154214]
Validation Done: [68736/154214]
Validation Done: [68800/154214]
Validation Done: [68864/154214]
Validation Done: [68928/154214]
Validation Done: [68992/154214]
Validation Done: [69056/154214]
Validation Done: [69120/154214]
Validation Done: [69184/154214]
Validation Done: [69248/154214]
Validation Done: [69312/154214]
Validation Done: [69376/154214]
Validation Done: [69440/154214]
Validation Done: [69504/154214]
Validation Done: [69568/154214]
Validation Done: [69632/154214]
Validation Done: [69696/154214]
Validation Done: [69760/154214]
Validation Done: [69824/154214]
Validation Done: [69888/154214]
Validation Done: [69952/154214]
Validation Done: [70016/154214]
Validation Done: [70080/154214]
Validation Done: [70144/154214]
Validation Done: [70208/154214]
Validation Done: [70272/154214]
Validation Done: [70336/154214]
Validation Done: [70400/154214]
Validation Done: [70464/154214]
Validation Done: [70528/154214]
Validation Done: [70592/154214]
Validation Done: [70656/154214]
Validation Done: [70720/154214]
Validation Done: [70784/154214]
Validation Done: [70848/154214]
Validation Done: [70912/154214]
Validation Done: [70976/154214]
Validation Done: [71040/154214]
Validation Done: [71104/154214]
Validation Done: [71168/154214]
Validation Done: [71232/154214]
Validation Done: [71296/154214]
Validation Done: [71360/154214]
Validation Done: [71424/154214]
Validation Done: [71488/154214]
Validation Done: [71552/154214]
Validation Done: [71616/154214]
Validation Done: [71680/154214]
Validation Done: [71744/154214]
Validation Done: [71808/154214]
Validation Done: [71872/154214]
Validation Done: [71936/154214]
Validation Done: [72000/154214]
Validation Done: [72064/154214]
Validation Done: [72128/154214]
Validation Done: [72192/154214]
Validation Done: [72256/154214]
Validation Done: [72320/154214]
Validation Done: [72384/154214]
Validation Done: [72448/154214]
Validation Done: [72512/154214]
Validation Done: [72576/154214]
Validation Done: [72640/154214]
Validation Done: [72704/154214]
Validation Done: [72768/154214]
Validation Done: [72832/154214]
Validation Done: [72896/154214]
Validation Done: [72960/154214]
Validation Done: [73024/154214]
Validation Done: [73088/154214]
Validation Done: [73152/154214]
Validation Done: [73216/154214]
Validation Done: [73280/154214]
Validation Done: [73344/154214]
Validation Done: [73408/154214]
Validation Done: [73472/154214]
Validation Done: [73536/154214]
Validation Done: [73600/154214]
Validation Done: [73664/154214]
Validation Done: [73728/154214]
Validation Done: [73792/154214]
Validation Done: [73856/154214]
Validation Done: [73920/154214]
Validation Done: [73984/154214]
Validation Done: [74048/154214]
Validation Done: [74112/154214]
Validation Done: [74176/154214]
Validation Done: [74240/154214]
Validation Done: [74304/154214]
Validation Done: [74368/154214]
Validation Done: [74432/154214]
Validation Done: [74496/154214]
Validation Done: [74560/154214]
Validation Done: [74624/154214]
Validation Done: [74688/154214]
Validation Done: [74752/154214]
Validation Done: [74816/154214]
Validation Done: [74880/154214]
Validation Done: [74944/154214]
Validation Done: [75008/154214]
Validation Done: [75072/154214]
Validation Done: [75136/154214]
Validation Done: [75200/154214]
Validation Done: [75264/154214]
Validation Done: [75328/154214]
Validation Done: [75392/154214]
Validation Done: [75456/154214]
Validation Done: [75520/154214]
Validation Done: [75584/154214]
Validation Done: [75648/154214]
Validation Done: [75712/154214]
Validation Done: [75776/154214]
Validation Done: [75840/154214]
Validation Done: [75904/154214]
Validation Done: [75968/154214]
Validation Done: [76032/154214]
Validation Done: [76096/154214]
Validation Done: [76160/154214]
Validation Done: [76224/154214]
Validation Done: [76288/154214]
Validation Done: [76352/154214]
Validation Done: [76416/154214]
Validation Done: [76480/154214]
Validation Done: [76544/154214]
Validation Done: [76608/154214]
Validation Done: [76672/154214]
Validation Done: [76736/154214]
Validation Done: [76800/154214]
Validation Done: [76864/154214]
Validation Done: [76928/154214]
Validation Done: [76992/154214]
Validation Done: [77056/154214]
Validation Done: [77120/154214]
Validation Done: [77184/154214]
Validation Done: [77248/154214]
Validation Done: [77312/154214]
Validation Done: [77376/154214]
Validation Done: [77440/154214]
Validation Done: [77504/154214]
Validation Done: [77568/154214]
Validation Done: [77632/154214]
Validation Done: [77696/154214]
Validation Done: [77760/154214]
Validation Done: [77824/154214]
Validation Done: [77888/154214]
Validation Done: [77952/154214]
Validation Done: [78016/154214]
Validation Done: [78080/154214]
Validation Done: [78144/154214]
Validation Done: [78208/154214]
Validation Done: [78272/154214]
Validation Done: [78336/154214]
Validation Done: [78400/154214]
Validation Done: [78464/154214]
Validation Done: [78528/154214]
Validation Done: [78592/154214]
Validation Done: [78656/154214]
Validation Done: [78720/154214]
Validation Done: [78784/154214]
Validation Done: [78848/154214]
Validation Done: [78912/154214]
Validation Done: [78976/154214]
Validation Done: [79040/154214]
Validation Done: [79104/154214]
Validation Done: [79168/154214]
Validation Done: [79232/154214]
Validation Done: [79296/154214]
Validation Done: [79360/154214]
Validation Done: [79424/154214]
Validation Done: [79488/154214]
Validation Done: [79552/154214]
Validation Done: [79616/154214]
Validation Done: [79680/154214]
Validation Done: [79744/154214]
Validation Done: [79808/154214]
Validation Done: [79872/154214]
Validation Done: [79936/154214]
Validation Done: [80000/154214]
Validation Done: [80064/154214]
Validation Done: [80128/154214]
Validation Done: [80192/154214]
Validation Done: [80256/154214]
Validation Done: [80320/154214]
Validation Done: [80384/154214]
Validation Done: [80448/154214]
Validation Done: [80512/154214]
Validation Done: [80576/154214]
Validation Done: [80640/154214]
Validation Done: [80704/154214]
Validation Done: [80768/154214]
Validation Done: [80832/154214]
Validation Done: [80896/154214]
Validation Done: [80960/154214]
Validation Done: [81024/154214]
Validation Done: [81088/154214]
Validation Done: [81152/154214]
Validation Done: [81216/154214]
Validation Done: [81280/154214]
Validation Done: [81344/154214]
Validation Done: [81408/154214]
Validation Done: [81472/154214]
Validation Done: [81536/154214]
Validation Done: [81600/154214]
Validation Done: [81664/154214]
Validation Done: [81728/154214]
Validation Done: [81792/154214]
Validation Done: [81856/154214]
Validation Done: [81920/154214]
Validation Done: [81984/154214]
Validation Done: [82048/154214]
Validation Done: [82112/154214]
Validation Done: [82176/154214]
Validation Done: [82240/154214]
Validation Done: [82304/154214]
Validation Done: [82368/154214]
Validation Done: [82432/154214]
Validation Done: [82496/154214]
Validation Done: [82560/154214]
Validation Done: [82624/154214]
Validation Done: [82688/154214]
Validation Done: [82752/154214]
Validation Done: [82816/154214]
Validation Done: [82880/154214]
Validation Done: [82944/154214]
Validation Done: [83008/154214]
Validation Done: [83072/154214]
Validation Done: [83136/154214]
Validation Done: [83200/154214]
Validation Done: [83264/154214]
Validation Done: [83328/154214]
Validation Done: [83392/154214]
Validation Done: [83456/154214]
Validation Done: [83520/154214]
Validation Done: [83584/154214]
Validation Done: [83648/154214]
Validation Done: [83712/154214]
Validation Done: [83776/154214]
Validation Done: [83840/154214]
Validation Done: [83904/154214]
Validation Done: [83968/154214]
Validation Done: [84032/154214]
Validation Done: [84096/154214]
Validation Done: [84160/154214]
Validation Done: [84224/154214]
Validation Done: [84288/154214]
Validation Done: [84352/154214]
Validation Done: [84416/154214]
Validation Done: [84480/154214]
Validation Done: [84544/154214]
Validation Done: [84608/154214]
Validation Done: [84672/154214]
Validation Done: [84736/154214]
Validation Done: [84800/154214]
Validation Done: [84864/154214]
Validation Done: [84928/154214]
Validation Done: [84992/154214]
Validation Done: [85056/154214]
Validation Done: [85120/154214]
Validation Done: [85184/154214]
Validation Done: [85248/154214]
Validation Done: [85312/154214]
Validation Done: [85376/154214]
Validation Done: [85440/154214]
Validation Done: [85504/154214]
Validation Done: [85568/154214]
Validation Done: [85632/154214]
Validation Done: [85696/154214]
Validation Done: [85760/154214]
Validation Done: [85824/154214]
Validation Done: [85888/154214]
Validation Done: [85952/154214]
Validation Done: [86016/154214]
Validation Done: [86080/154214]
Validation Done: [86144/154214]
Validation Done: [86208/154214]
Validation Done: [86272/154214]
Validation Done: [86336/154214]
Validation Done: [86400/154214]
Validation Done: [86464/154214]
Validation Done: [86528/154214]
Validation Done: [86592/154214]
Validation Done: [86656/154214]
Validation Done: [86720/154214]
Validation Done: [86784/154214]
Validation Done: [86848/154214]
Validation Done: [86912/154214]
Validation Done: [86976/154214]
Validation Done: [87040/154214]
Validation Done: [87104/154214]
Validation Done: [87168/154214]
Validation Done: [87232/154214]
Validation Done: [87296/154214]
Validation Done: [87360/154214]
Validation Done: [87424/154214]
Validation Done: [87488/154214]
Validation Done: [87552/154214]
Validation Done: [87616/154214]
Validation Done: [87680/154214]
Validation Done: [87744/154214]
Validation Done: [87808/154214]
Validation Done: [87872/154214]
Validation Done: [87936/154214]
Validation Done: [88000/154214]
Validation Done: [88064/154214]
Validation Done: [88128/154214]
Validation Done: [88192/154214]
Validation Done: [88256/154214]
Validation Done: [88320/154214]
Validation Done: [88384/154214]
Validation Done: [88448/154214]
Validation Done: [88512/154214]
Validation Done: [88576/154214]
Validation Done: [88640/154214]
Validation Done: [88704/154214]
Validation Done: [88768/154214]
Validation Done: [88832/154214]
Validation Done: [88896/154214]
Validation Done: [88960/154214]
Validation Done: [89024/154214]
Validation Done: [89088/154214]
Validation Done: [89152/154214]
Validation Done: [89216/154214]
Validation Done: [89280/154214]
Validation Done: [89344/154214]
Validation Done: [89408/154214]
Validation Done: [89472/154214]
Validation Done: [89536/154214]
Validation Done: [89600/154214]
Validation Done: [89664/154214]
Validation Done: [89728/154214]
Validation Done: [89792/154214]
Validation Done: [89856/154214]
Validation Done: [89920/154214]
Validation Done: [89984/154214]
Validation Done: [90048/154214]
Validation Done: [90112/154214]
Validation Done: [90176/154214]
Validation Done: [90240/154214]
Validation Done: [90304/154214]
Validation Done: [90368/154214]
Validation Done: [90432/154214]
Validation Done: [90496/154214]
Validation Done: [90560/154214]
Validation Done: [90624/154214]
Validation Done: [90688/154214]
Validation Done: [90752/154214]
Validation Done: [90816/154214]
Validation Done: [90880/154214]
Validation Done: [90944/154214]
Validation Done: [91008/154214]
Validation Done: [91072/154214]
Validation Done: [91136/154214]
Validation Done: [91200/154214]
Validation Done: [91264/154214]
Validation Done: [91328/154214]
Validation Done: [91392/154214]
Validation Done: [91456/154214]
Validation Done: [91520/154214]
Validation Done: [91584/154214]
Validation Done: [91648/154214]
Validation Done: [91712/154214]
Validation Done: [91776/154214]
Validation Done: [91840/154214]
Validation Done: [91904/154214]
Validation Done: [91968/154214]
Validation Done: [92032/154214]
Validation Done: [92096/154214]
Validation Done: [92160/154214]
Validation Done: [92224/154214]
Validation Done: [92288/154214]
Validation Done: [92352/154214]
Validation Done: [92416/154214]
Validation Done: [92480/154214]
Validation Done: [92544/154214]
Validation Done: [92608/154214]
Validation Done: [92672/154214]
Validation Done: [92736/154214]
Validation Done: [92800/154214]
Validation Done: [92864/154214]
Validation Done: [92928/154214]
Validation Done: [92992/154214]
Validation Done: [93056/154214]
Validation Done: [93120/154214]
Validation Done: [93184/154214]
Validation Done: [93248/154214]
Validation Done: [93312/154214]
Validation Done: [93376/154214]
Validation Done: [93440/154214]
Validation Done: [93504/154214]
Validation Done: [93568/154214]
Validation Done: [93632/154214]
Validation Done: [93696/154214]
Validation Done: [93760/154214]
Validation Done: [93824/154214]
Validation Done: [93888/154214]
Validation Done: [93952/154214]
Validation Done: [94016/154214]
Validation Done: [94080/154214]
Validation Done: [94144/154214]
Validation Done: [94208/154214]
Validation Done: [94272/154214]
Validation Done: [94336/154214]
Validation Done: [94400/154214]
Validation Done: [94464/154214]
Validation Done: [94528/154214]
Validation Done: [94592/154214]
Validation Done: [94656/154214]
Validation Done: [94720/154214]
Validation Done: [94784/154214]
Validation Done: [94848/154214]
Validation Done: [94912/154214]
Validation Done: [94976/154214]
Validation Done: [95040/154214]
Validation Done: [95104/154214]
Validation Done: [95168/154214]
Validation Done: [95232/154214]
Validation Done: [95296/154214]
Validation Done: [95360/154214]
Validation Done: [95424/154214]
Validation Done: [95488/154214]
Validation Done: [95552/154214]
Validation Done: [95616/154214]
Validation Done: [95680/154214]
Validation Done: [95744/154214]
Validation Done: [95808/154214]
Validation Done: [95872/154214]
Validation Done: [95936/154214]
Validation Done: [96000/154214]
Validation Done: [96064/154214]
Validation Done: [96128/154214]
Validation Done: [96192/154214]
Validation Done: [96256/154214]
Validation Done: [96320/154214]
Validation Done: [96384/154214]
Validation Done: [96448/154214]
Validation Done: [96512/154214]
Validation Done: [96576/154214]
Validation Done: [96640/154214]
Validation Done: [96704/154214]
Validation Done: [96768/154214]
Validation Done: [96832/154214]
Validation Done: [96896/154214]
Validation Done: [96960/154214]
Validation Done: [97024/154214]
Validation Done: [97088/154214]
Validation Done: [97152/154214]
Validation Done: [97216/154214]
Validation Done: [97280/154214]
Validation Done: [97344/154214]
Validation Done: [97408/154214]
Validation Done: [97472/154214]
Validation Done: [97536/154214]
Validation Done: [97600/154214]
Validation Done: [97664/154214]
Validation Done: [97728/154214]
Validation Done: [97792/154214]
Validation Done: [97856/154214]
Validation Done: [97920/154214]
Validation Done: [97984/154214]
Validation Done: [98048/154214]
Validation Done: [98112/154214]
Validation Done: [98176/154214]
Validation Done: [98240/154214]
Validation Done: [98304/154214]
Validation Done: [98368/154214]
Validation Done: [98432/154214]
Validation Done: [98496/154214]
Validation Done: [98560/154214]
Validation Done: [98624/154214]
Validation Done: [98688/154214]
Validation Done: [98752/154214]
Validation Done: [98816/154214]
Validation Done: [98880/154214]
Validation Done: [98944/154214]
Validation Done: [99008/154214]
Validation Done: [99072/154214]
Validation Done: [99136/154214]
Validation Done: [99200/154214]
Validation Done: [99264/154214]
Validation Done: [99328/154214]
Validation Done: [99392/154214]
Validation Done: [99456/154214]
Validation Done: [99520/154214]
Validation Done: [99584/154214]
Validation Done: [99648/154214]
Validation Done: [99712/154214]
Validation Done: [99776/154214]
Validation Done: [99840/154214]
Validation Done: [99904/154214]
Validation Done: [99968/154214]
Validation Done: [100032/154214]
Validation Done: [100096/154214]
Validation Done: [100160/154214]
Validation Done: [100224/154214]
Validation Done: [100288/154214]
Validation Done: [100352/154214]
Validation Done: [100416/154214]
Validation Done: [100480/154214]
Validation Done: [100544/154214]
Validation Done: [100608/154214]
Validation Done: [100672/154214]
Validation Done: [100736/154214]
Validation Done: [100800/154214]
Validation Done: [100864/154214]
Validation Done: [100928/154214]
Validation Done: [100992/154214]
Validation Done: [101056/154214]
Validation Done: [101120/154214]
Validation Done: [101184/154214]
Validation Done: [101248/154214]
Validation Done: [101312/154214]
Validation Done: [101376/154214]
Validation Done: [101440/154214]
Validation Done: [101504/154214]
Validation Done: [101568/154214]
Validation Done: [101632/154214]
Validation Done: [101696/154214]
Validation Done: [101760/154214]
Validation Done: [101824/154214]
Validation Done: [101888/154214]
Validation Done: [101952/154214]
Validation Done: [102016/154214]
Validation Done: [102080/154214]
Validation Done: [102144/154214]
Validation Done: [102208/154214]
Validation Done: [102272/154214]
Validation Done: [102336/154214]
Validation Done: [102400/154214]
Validation Done: [102464/154214]
Validation Done: [102528/154214]
Validation Done: [102592/154214]
Validation Done: [102656/154214]
Validation Done: [102720/154214]
Validation Done: [102784/154214]
Validation Done: [102848/154214]
Validation Done: [102912/154214]
Validation Done: [102976/154214]
Validation Done: [103040/154214]
Validation Done: [103104/154214]
Validation Done: [103168/154214]
Validation Done: [103232/154214]
Validation Done: [103296/154214]
Validation Done: [103360/154214]
Validation Done: [103424/154214]
Validation Done: [103488/154214]
Validation Done: [103552/154214]
Validation Done: [103616/154214]
Validation Done: [103680/154214]
Validation Done: [103744/154214]
Validation Done: [103808/154214]
Validation Done: [103872/154214]
Validation Done: [103936/154214]
Validation Done: [104000/154214]
Validation Done: [104064/154214]
Validation Done: [104128/154214]
Validation Done: [104192/154214]
Validation Done: [104256/154214]
Validation Done: [104320/154214]
Validation Done: [104384/154214]
Validation Done: [104448/154214]
Validation Done: [104512/154214]
Validation Done: [104576/154214]
Validation Done: [104640/154214]
Validation Done: [104704/154214]
Validation Done: [104768/154214]
Validation Done: [104832/154214]
Validation Done: [104896/154214]
Validation Done: [104960/154214]
Validation Done: [105024/154214]
Validation Done: [105088/154214]
Validation Done: [105152/154214]
Validation Done: [105216/154214]
Validation Done: [105280/154214]
Validation Done: [105344/154214]
Validation Done: [105408/154214]
Validation Done: [105472/154214]
Validation Done: [105536/154214]
Validation Done: [105600/154214]
Validation Done: [105664/154214]
Validation Done: [105728/154214]
Validation Done: [105792/154214]
Validation Done: [105856/154214]
Validation Done: [105920/154214]
Validation Done: [105984/154214]
Validation Done: [106048/154214]
Validation Done: [106112/154214]
Validation Done: [106176/154214]
Validation Done: [106240/154214]
Validation Done: [106304/154214]
Validation Done: [106368/154214]
Validation Done: [106432/154214]
Validation Done: [106496/154214]
Validation Done: [106560/154214]
Validation Done: [106624/154214]
Validation Done: [106688/154214]
Validation Done: [106752/154214]
Validation Done: [106816/154214]
Validation Done: [106880/154214]
Validation Done: [106944/154214]
Validation Done: [107008/154214]
Validation Done: [107072/154214]
Validation Done: [107136/154214]
Validation Done: [107200/154214]
Validation Done: [107264/154214]
Validation Done: [107328/154214]
Validation Done: [107392/154214]
Validation Done: [107456/154214]
Validation Done: [107520/154214]
Validation Done: [107584/154214]
Validation Done: [107648/154214]
Validation Done: [107712/154214]
Validation Done: [107776/154214]
Validation Done: [107840/154214]
Validation Done: [107904/154214]
Validation Done: [107968/154214]
Validation Done: [108032/154214]
Validation Done: [108096/154214]
Validation Done: [108160/154214]
Validation Done: [108224/154214]
Validation Done: [108288/154214]
Validation Done: [108352/154214]
Validation Done: [108416/154214]
Validation Done: [108480/154214]
Validation Done: [108544/154214]
Validation Done: [108608/154214]
Validation Done: [108672/154214]
Validation Done: [108736/154214]
Validation Done: [108800/154214]
Validation Done: [108864/154214]
Validation Done: [108928/154214]
Validation Done: [108992/154214]
Validation Done: [109056/154214]
Validation Done: [109120/154214]
Validation Done: [109184/154214]
Validation Done: [109248/154214]
Validation Done: [109312/154214]
Validation Done: [109376/154214]
Validation Done: [109440/154214]
Validation Done: [109504/154214]
Validation Done: [109568/154214]
Validation Done: [109632/154214]
Validation Done: [109696/154214]
Validation Done: [109760/154214]
Validation Done: [109824/154214]
Validation Done: [109888/154214]
Validation Done: [109952/154214]
Validation Done: [110016/154214]
Validation Done: [110080/154214]
Validation Done: [110144/154214]
Validation Done: [110208/154214]
Validation Done: [110272/154214]
Validation Done: [110336/154214]
Validation Done: [110400/154214]
Validation Done: [110464/154214]
Validation Done: [110528/154214]
Validation Done: [110592/154214]
Validation Done: [110656/154214]
Validation Done: [110720/154214]
Validation Done: [110784/154214]
Validation Done: [110848/154214]
Validation Done: [110912/154214]
Validation Done: [110976/154214]
Validation Done: [111040/154214]
Validation Done: [111104/154214]
Validation Done: [111168/154214]
Validation Done: [111232/154214]
Validation Done: [111296/154214]
Validation Done: [111360/154214]
Validation Done: [111424/154214]
Validation Done: [111488/154214]
Validation Done: [111552/154214]
Validation Done: [111616/154214]
Validation Done: [111680/154214]
Validation Done: [111744/154214]
Validation Done: [111808/154214]
Validation Done: [111872/154214]
Validation Done: [111936/154214]
Validation Done: [112000/154214]
Validation Done: [112064/154214]
Validation Done: [112128/154214]
Validation Done: [112192/154214]
Validation Done: [112256/154214]
Validation Done: [112320/154214]
Validation Done: [112384/154214]
Validation Done: [112448/154214]
Validation Done: [112512/154214]
Validation Done: [112576/154214]
Validation Done: [112640/154214]
Validation Done: [112704/154214]
Validation Done: [112768/154214]
Validation Done: [112832/154214]
Validation Done: [112896/154214]
Validation Done: [112960/154214]
Validation Done: [113024/154214]
Validation Done: [113088/154214]
Validation Done: [113152/154214]
Validation Done: [113216/154214]
Validation Done: [113280/154214]
Validation Done: [113344/154214]
Validation Done: [113408/154214]
Validation Done: [113472/154214]
Validation Done: [113536/154214]
Validation Done: [113600/154214]
Validation Done: [113664/154214]
Validation Done: [113728/154214]
Validation Done: [113792/154214]
Validation Done: [113856/154214]
Validation Done: [113920/154214]
Validation Done: [113984/154214]
Validation Done: [114048/154214]
Validation Done: [114112/154214]
Validation Done: [114176/154214]
Validation Done: [114240/154214]
Validation Done: [114304/154214]
Validation Done: [114368/154214]
Validation Done: [114432/154214]
Validation Done: [114496/154214]
Validation Done: [114560/154214]
Validation Done: [114624/154214]
Validation Done: [114688/154214]
Validation Done: [114752/154214]
Validation Done: [114816/154214]
Validation Done: [114880/154214]
Validation Done: [114944/154214]
Validation Done: [115008/154214]
Validation Done: [115072/154214]
Validation Done: [115136/154214]
Validation Done: [115200/154214]
Validation Done: [115264/154214]
Validation Done: [115328/154214]
Validation Done: [115392/154214]
Validation Done: [115456/154214]
Validation Done: [115520/154214]
Validation Done: [115584/154214]
Validation Done: [115648/154214]
Validation Done: [115712/154214]
Validation Done: [115776/154214]
Validation Done: [115840/154214]
Validation Done: [115904/154214]
Validation Done: [115968/154214]
Validation Done: [116032/154214]
Validation Done: [116096/154214]
Validation Done: [116160/154214]
Validation Done: [116224/154214]
Validation Done: [116288/154214]
Validation Done: [116352/154214]
Validation Done: [116416/154214]
Validation Done: [116480/154214]
Validation Done: [116544/154214]
Validation Done: [116608/154214]
Validation Done: [116672/154214]
Validation Done: [116736/154214]
Validation Done: [116800/154214]
Validation Done: [116864/154214]
Validation Done: [116928/154214]
Validation Done: [116992/154214]
Validation Done: [117056/154214]
Validation Done: [117120/154214]
Validation Done: [117184/154214]
Validation Done: [117248/154214]
Validation Done: [117312/154214]
Validation Done: [117376/154214]
Validation Done: [117440/154214]
Validation Done: [117504/154214]
Validation Done: [117568/154214]
Validation Done: [117632/154214]
Validation Done: [117696/154214]
Validation Done: [117760/154214]
Validation Done: [117824/154214]
Validation Done: [117888/154214]
Validation Done: [117952/154214]
Validation Done: [118016/154214]
Validation Done: [118080/154214]
Validation Done: [118144/154214]
Validation Done: [118208/154214]
Validation Done: [118272/154214]
Validation Done: [118336/154214]
Validation Done: [118400/154214]
Validation Done: [118464/154214]
Validation Done: [118528/154214]
Validation Done: [118592/154214]
Validation Done: [118656/154214]
Validation Done: [118720/154214]
Validation Done: [118784/154214]
Validation Done: [118848/154214]
Validation Done: [118912/154214]
Validation Done: [118976/154214]
Validation Done: [119040/154214]
Validation Done: [119104/154214]
Validation Done: [119168/154214]
Validation Done: [119232/154214]
Validation Done: [119296/154214]
Validation Done: [119360/154214]
Validation Done: [119424/154214]
Validation Done: [119488/154214]
Validation Done: [119552/154214]
Validation Done: [119616/154214]
Validation Done: [119680/154214]
Validation Done: [119744/154214]
Validation Done: [119808/154214]
Validation Done: [119872/154214]
Validation Done: [119936/154214]
Validation Done: [120000/154214]
Validation Done: [120064/154214]
Validation Done: [120128/154214]
Validation Done: [120192/154214]
Validation Done: [120256/154214]
Validation Done: [120320/154214]
Validation Done: [120384/154214]
Validation Done: [120448/154214]
Validation Done: [120512/154214]
Validation Done: [120576/154214]
Validation Done: [120640/154214]
Validation Done: [120704/154214]
Validation Done: [120768/154214]
Validation Done: [120832/154214]
Validation Done: [120896/154214]
Validation Done: [120960/154214]
Validation Done: [121024/154214]
Validation Done: [121088/154214]
Validation Done: [121152/154214]
Validation Done: [121216/154214]
Validation Done: [121280/154214]
Validation Done: [121344/154214]
Validation Done: [121408/154214]
Validation Done: [121472/154214]
Validation Done: [121536/154214]
Validation Done: [121600/154214]
Validation Done: [121664/154214]
Validation Done: [121728/154214]
Validation Done: [121792/154214]
Validation Done: [121856/154214]
Validation Done: [121920/154214]
Validation Done: [121984/154214]
Validation Done: [122048/154214]
Validation Done: [122112/154214]
Validation Done: [122176/154214]
Validation Done: [122240/154214]
Validation Done: [122304/154214]
Validation Done: [122368/154214]
Validation Done: [122432/154214]
Validation Done: [122496/154214]
Validation Done: [122560/154214]
Validation Done: [122624/154214]
Validation Done: [122688/154214]
Validation Done: [122752/154214]
Validation Done: [122816/154214]
Validation Done: [122880/154214]
Validation Done: [122944/154214]
Validation Done: [123008/154214]
Validation Done: [123072/154214]
Validation Done: [123136/154214]
Validation Done: [123200/154214]
Validation Done: [123264/154214]
Validation Done: [123328/154214]
Validation Done: [123392/154214]
Validation Done: [123456/154214]
Validation Done: [123520/154214]
Validation Done: [123584/154214]
Validation Done: [123648/154214]
Validation Done: [123712/154214]
Validation Done: [123776/154214]
Validation Done: [123840/154214]
Validation Done: [123904/154214]
Validation Done: [123968/154214]
Validation Done: [124032/154214]
Validation Done: [124096/154214]
Validation Done: [124160/154214]
Validation Done: [124224/154214]
Validation Done: [124288/154214]
Validation Done: [124352/154214]
Validation Done: [124416/154214]
Validation Done: [124480/154214]
Validation Done: [124544/154214]
Validation Done: [124608/154214]
Validation Done: [124672/154214]
Validation Done: [124736/154214]
Validation Done: [124800/154214]
Validation Done: [124864/154214]
Validation Done: [124928/154214]
Validation Done: [124992/154214]
Validation Done: [125056/154214]
Validation Done: [125120/154214]
Validation Done: [125184/154214]
Validation Done: [125248/154214]
Validation Done: [125312/154214]
Validation Done: [125376/154214]
Validation Done: [125440/154214]
Validation Done: [125504/154214]
Validation Done: [125568/154214]
Validation Done: [125632/154214]
Validation Done: [125696/154214]
Validation Done: [125760/154214]
Validation Done: [125824/154214]
Validation Done: [125888/154214]
Validation Done: [125952/154214]
Validation Done: [126016/154214]
Validation Done: [126080/154214]
Validation Done: [126144/154214]
Validation Done: [126208/154214]
Validation Done: [126272/154214]
Validation Done: [126336/154214]
Validation Done: [126400/154214]
Validation Done: [126464/154214]
Validation Done: [126528/154214]
Validation Done: [126592/154214]
Validation Done: [126656/154214]
Validation Done: [126720/154214]
Validation Done: [126784/154214]
Validation Done: [126848/154214]
Validation Done: [126912/154214]
Validation Done: [126976/154214]
Validation Done: [127040/154214]
Validation Done: [127104/154214]
Validation Done: [127168/154214]
Validation Done: [127232/154214]
Validation Done: [127296/154214]
Validation Done: [127360/154214]
Validation Done: [127424/154214]
Validation Done: [127488/154214]
Validation Done: [127552/154214]
Validation Done: [127616/154214]
Validation Done: [127680/154214]
Validation Done: [127744/154214]
Validation Done: [127808/154214]
Validation Done: [127872/154214]
Validation Done: [127936/154214]
Validation Done: [128000/154214]
Validation Done: [128064/154214]
Validation Done: [128128/154214]
Validation Done: [128192/154214]
Validation Done: [128256/154214]
Validation Done: [128320/154214]
Validation Done: [128384/154214]
Validation Done: [128448/154214]
Validation Done: [128512/154214]
Validation Done: [128576/154214]
Validation Done: [128640/154214]
Validation Done: [128704/154214]
Validation Done: [128768/154214]
Validation Done: [128832/154214]
Validation Done: [128896/154214]
Validation Done: [128960/154214]
Validation Done: [129024/154214]
Validation Done: [129088/154214]
Validation Done: [129152/154214]
Validation Done: [129216/154214]
Validation Done: [129280/154214]
Validation Done: [129344/154214]
Validation Done: [129408/154214]
Validation Done: [129472/154214]
Validation Done: [129536/154214]
Validation Done: [129600/154214]
Validation Done: [129664/154214]
Validation Done: [129728/154214]
Validation Done: [129792/154214]
Validation Done: [129856/154214]
Validation Done: [129920/154214]
Validation Done: [129984/154214]
Validation Done: [130048/154214]
Validation Done: [130112/154214]
Validation Done: [130176/154214]
Validation Done: [130240/154214]
Validation Done: [130304/154214]
Validation Done: [130368/154214]
Validation Done: [130432/154214]
Validation Done: [130496/154214]
Validation Done: [130560/154214]
Validation Done: [130624/154214]
Validation Done: [130688/154214]
Validation Done: [130752/154214]
Validation Done: [130816/154214]
Validation Done: [130880/154214]
Validation Done: [130944/154214]
Validation Done: [131008/154214]
Validation Done: [131072/154214]
Validation Done: [131136/154214]
Validation Done: [131200/154214]
Validation Done: [131264/154214]
Validation Done: [131328/154214]
Validation Done: [131392/154214]
Validation Done: [131456/154214]
Validation Done: [131520/154214]
Validation Done: [131584/154214]
Validation Done: [131648/154214]
Validation Done: [131712/154214]
Validation Done: [131776/154214]
Validation Done: [131840/154214]
Validation Done: [131904/154214]
Validation Done: [131968/154214]
Validation Done: [132032/154214]
Validation Done: [132096/154214]
Validation Done: [132160/154214]
Validation Done: [132224/154214]
Validation Done: [132288/154214]
Validation Done: [132352/154214]
Validation Done: [132416/154214]
Validation Done: [132480/154214]
Validation Done: [132544/154214]
Validation Done: [132608/154214]
Validation Done: [132672/154214]
Validation Done: [132736/154214]
Validation Done: [132800/154214]
Validation Done: [132864/154214]
Validation Done: [132928/154214]
Validation Done: [132992/154214]
Validation Done: [133056/154214]
Validation Done: [133120/154214]
Validation Done: [133184/154214]
Validation Done: [133248/154214]
Validation Done: [133312/154214]
Validation Done: [133376/154214]
Validation Done: [133440/154214]
Validation Done: [133504/154214]
Validation Done: [133568/154214]
Validation Done: [133632/154214]
Validation Done: [133696/154214]
Validation Done: [133760/154214]
Validation Done: [133824/154214]
Validation Done: [133888/154214]
Validation Done: [133952/154214]
Validation Done: [134016/154214]
Validation Done: [134080/154214]
Validation Done: [134144/154214]
Validation Done: [134208/154214]
Validation Done: [134272/154214]
Validation Done: [134336/154214]
Validation Done: [134400/154214]
Validation Done: [134464/154214]
Validation Done: [134528/154214]
Validation Done: [134592/154214]
Validation Done: [134656/154214]
Validation Done: [134720/154214]
Validation Done: [134784/154214]
Validation Done: [134848/154214]
Validation Done: [134912/154214]
Validation Done: [134976/154214]
Validation Done: [135040/154214]
Validation Done: [135104/154214]
Validation Done: [135168/154214]
Validation Done: [135232/154214]
Validation Done: [135296/154214]
Validation Done: [135360/154214]
Validation Done: [135424/154214]
Validation Done: [135488/154214]
Validation Done: [135552/154214]
Validation Done: [135616/154214]
Validation Done: [135680/154214]
Validation Done: [135744/154214]
Validation Done: [135808/154214]
Validation Done: [135872/154214]
Validation Done: [135936/154214]
Validation Done: [136000/154214]
Validation Done: [136064/154214]
Validation Done: [136128/154214]
Validation Done: [136192/154214]
Validation Done: [136256/154214]
Validation Done: [136320/154214]
Validation Done: [136384/154214]
Validation Done: [136448/154214]
Validation Done: [136512/154214]
Validation Done: [136576/154214]
Validation Done: [136640/154214]
Validation Done: [136704/154214]
Validation Done: [136768/154214]
Validation Done: [136832/154214]
Validation Done: [136896/154214]
Validation Done: [136960/154214]
Validation Done: [137024/154214]
Validation Done: [137088/154214]
Validation Done: [137152/154214]
Validation Done: [137216/154214]
Validation Done: [137280/154214]
Validation Done: [137344/154214]
Validation Done: [137408/154214]
Validation Done: [137472/154214]
Validation Done: [137536/154214]
Validation Done: [137600/154214]
Validation Done: [137664/154214]
Validation Done: [137728/154214]
Validation Done: [137792/154214]
Validation Done: [137856/154214]
Validation Done: [137920/154214]
Validation Done: [137984/154214]
Validation Done: [138048/154214]
Validation Done: [138112/154214]
Validation Done: [138176/154214]
Validation Done: [138240/154214]
Validation Done: [138304/154214]
Validation Done: [138368/154214]
Validation Done: [138432/154214]
Validation Done: [138496/154214]
Validation Done: [138560/154214]
Validation Done: [138624/154214]
Validation Done: [138688/154214]
Validation Done: [138752/154214]
Validation Done: [138816/154214]
Validation Done: [138880/154214]
Validation Done: [138944/154214]
Validation Done: [139008/154214]
Validation Done: [139072/154214]
Validation Done: [139136/154214]
Validation Done: [139200/154214]
Validation Done: [139264/154214]
Validation Done: [139328/154214]
Validation Done: [139392/154214]
Validation Done: [139456/154214]
Validation Done: [139520/154214]
Validation Done: [139584/154214]
Validation Done: [139648/154214]
Validation Done: [139712/154214]
Validation Done: [139776/154214]
Validation Done: [139840/154214]
Validation Done: [139904/154214]
Validation Done: [139968/154214]
Validation Done: [140032/154214]
Validation Done: [140096/154214]
Validation Done: [140160/154214]
Validation Done: [140224/154214]
Validation Done: [140288/154214]
Validation Done: [140352/154214]
Validation Done: [140416/154214]
Validation Done: [140480/154214]
Validation Done: [140544/154214]
Validation Done: [140608/154214]
Validation Done: [140672/154214]
Validation Done: [140736/154214]
Validation Done: [140800/154214]
Validation Done: [140864/154214]
Validation Done: [140928/154214]
Validation Done: [140992/154214]
Validation Done: [141056/154214]
Validation Done: [141120/154214]
Validation Done: [141184/154214]
Validation Done: [141248/154214]
Validation Done: [141312/154214]
Validation Done: [141376/154214]
Validation Done: [141440/154214]
Validation Done: [141504/154214]
Validation Done: [141568/154214]
Validation Done: [141632/154214]
Validation Done: [141696/154214]
Validation Done: [141760/154214]
Validation Done: [141824/154214]
Validation Done: [141888/154214]
Validation Done: [141952/154214]
Validation Done: [142016/154214]
Validation Done: [142080/154214]
Validation Done: [142144/154214]
Validation Done: [142208/154214]
Validation Done: [142272/154214]
Validation Done: [142336/154214]
Validation Done: [142400/154214]
Validation Done: [142464/154214]
Validation Done: [142528/154214]
Validation Done: [142592/154214]
Validation Done: [142656/154214]
Validation Done: [142720/154214]
Validation Done: [142784/154214]
Validation Done: [142848/154214]
Validation Done: [142912/154214]
Validation Done: [142976/154214]
Validation Done: [143040/154214]
Validation Done: [143104/154214]
Validation Done: [143168/154214]
Validation Done: [143232/154214]
Validation Done: [143296/154214]
Validation Done: [143360/154214]
Validation Done: [143424/154214]
Validation Done: [143488/154214]
Validation Done: [143552/154214]
Validation Done: [143616/154214]
Validation Done: [143680/154214]
Validation Done: [143744/154214]
Validation Done: [143808/154214]
Validation Done: [143872/154214]
Validation Done: [143936/154214]
Validation Done: [144000/154214]
Validation Done: [144064/154214]
Validation Done: [144128/154214]
Validation Done: [144192/154214]
Validation Done: [144256/154214]
Validation Done: [144320/154214]
Validation Done: [144384/154214]
Validation Done: [144448/154214]
Validation Done: [144512/154214]
Validation Done: [144576/154214]
Validation Done: [144640/154214]
Validation Done: [144704/154214]
Validation Done: [144768/154214]
Validation Done: [144832/154214]
Validation Done: [144896/154214]
Validation Done: [144960/154214]
Validation Done: [145024/154214]
Validation Done: [145088/154214]
Validation Done: [145152/154214]
Validation Done: [145216/154214]
Validation Done: [145280/154214]
Validation Done: [145344/154214]
Validation Done: [145408/154214]
Validation Done: [145472/154214]
Validation Done: [145536/154214]
Validation Done: [145600/154214]
Validation Done: [145664/154214]
Validation Done: [145728/154214]
Validation Done: [145792/154214]
Validation Done: [145856/154214]
Validation Done: [145920/154214]
Validation Done: [145984/154214]
Validation Done: [146048/154214]
Validation Done: [146112/154214]
Validation Done: [146176/154214]
Validation Done: [146240/154214]
Validation Done: [146304/154214]
Validation Done: [146368/154214]
Validation Done: [146432/154214]
Validation Done: [146496/154214]
Validation Done: [146560/154214]
Validation Done: [146624/154214]
Validation Done: [146688/154214]
Validation Done: [146752/154214]
Validation Done: [146816/154214]
Validation Done: [146880/154214]
Validation Done: [146944/154214]
Validation Done: [147008/154214]
Validation Done: [147072/154214]
Validation Done: [147136/154214]
Validation Done: [147200/154214]
Validation Done: [147264/154214]
Validation Done: [147328/154214]
Validation Done: [147392/154214]
Validation Done: [147456/154214]
Validation Done: [147520/154214]
Validation Done: [147584/154214]
Validation Done: [147648/154214]
Validation Done: [147712/154214]
Validation Done: [147776/154214]
Validation Done: [147840/154214]
Validation Done: [147904/154214]
Validation Done: [147968/154214]
Validation Done: [148032/154214]
Validation Done: [148096/154214]
Validation Done: [148160/154214]
Validation Done: [148224/154214]
Validation Done: [148288/154214]
Validation Done: [148352/154214]
Validation Done: [148416/154214]
Validation Done: [148480/154214]
Validation Done: [148544/154214]
Validation Done: [148608/154214]
Validation Done: [148672/154214]
Validation Done: [148736/154214]
Validation Done: [148800/154214]
Validation Done: [148864/154214]
Validation Done: [148928/154214]
Validation Done: [148992/154214]
Validation Done: [149056/154214]
Validation Done: [149120/154214]
Validation Done: [149184/154214]
Validation Done: [149248/154214]
Validation Done: [149312/154214]
Validation Done: [149376/154214]
Validation Done: [149440/154214]
Validation Done: [149504/154214]
Validation Done: [149568/154214]
Validation Done: [149632/154214]
Validation Done: [149696/154214]
Validation Done: [149760/154214]
Validation Done: [149824/154214]
Validation Done: [149888/154214]
Validation Done: [149952/154214]
Validation Done: [150016/154214]
Validation Done: [150080/154214]
Validation Done: [150144/154214]
Validation Done: [150208/154214]
Validation Done: [150272/154214]
Validation Done: [150336/154214]
Validation Done: [150400/154214]
Validation Done: [150464/154214]
Validation Done: [150528/154214]
Validation Done: [150592/154214]
Validation Done: [150656/154214]
Validation Done: [150720/154214]
Validation Done: [150784/154214]
Validation Done: [150848/154214]
Validation Done: [150912/154214]
Validation Done: [150976/154214]
Validation Done: [151040/154214]
Validation Done: [151104/154214]
Validation Done: [151168/154214]
Validation Done: [151232/154214]
Validation Done: [151296/154214]
Validation Done: [151360/154214]
Validation Done: [151424/154214]
Validation Done: [151488/154214]
Validation Done: [151552/154214]
Validation Done: [151616/154214]
Validation Done: [151680/154214]
Validation Done: [151744/154214]
Validation Done: [151808/154214]
Validation Done: [151872/154214]
Validation Done: [151936/154214]
Validation Done: [152000/154214]
Validation Done: [152064/154214]
Validation Done: [152128/154214]
Validation Done: [152192/154214]
Validation Done: [152256/154214]
Validation Done: [152320/154214]
Validation Done: [152384/154214]
Validation Done: [152448/154214]
Validation Done: [152512/154214]
Validation Done: [152576/154214]
Validation Done: [152640/154214]
Validation Done: [152704/154214]
Validation Done: [152768/154214]
Validation Done: [152832/154214]
Validation Done: [152896/154214]
Validation Done: [152960/154214]
Validation Done: [153024/154214]
Validation Done: [153088/154214]
Validation Done: [153152/154214]
Validation Done: [153216/154214]
Validation Done: [153280/154214]
Validation Done: [153344/154214]
Validation Done: [153408/154214]
Validation Done: [153472/154214]
Validation Done: [153536/154214]
Validation Done: [153600/154214]
Validation Done: [153664/154214]
Validation Done: [153728/154214]
Validation Done: [153792/154214]
Validation Done: [153856/154214]
Validation Done: [153920/154214]
Validation Done: [153984/154214]
Validation Done: [154048/154214]
Validation Done: [154112/154214]
Validation Done: [154176/154214]
Validation Done: [91580/154214]
[Test] Epoch: 0 Test set: Average loss: 0.0088, Accuracy: 118923/154214 (77.12%)
{'KIRC': {'recall': 0.8812762534632228, 'support': 55945, 'precision': 0.7225153140478912, 'f1-score': 0.794037831265149}, 'weighted avg': {'recall': 0.7711556668006796, 'support': 154214, 'precision': 0.7830267829256383, 'f1-score': 0.7702899837714541}, 'KICH': {'recall': 0.6930140748369379, 'support': 58260, 'precision': 0.874012338997727, 'f1-score': 0.7730601694509598}, 'accuracy': 0.7711556668006796, 'macro avg': {'recall': 0.7684169540600125, 'support': 154214, 'precision': 0.7772258663332389, 'f1-score': 0.7667157516695422}, 'KIRP': {'recall': 0.730960533879877, 'support': 40009, 'precision': 0.7351499459540987, 'f1-score': 0.7330492542925178}}
[Train] Epoch: 1 [64/620022]    Loss: 0.008364   Batch Acc: 82.81
[Train] Epoch: 1 [128/620022]    Loss: 0.009389   Batch Acc: 70.31
[Train] Epoch: 1 [192/620022]    Loss: 0.007397   Batch Acc: 90.62
[Train] Epoch: 1 [256/620022]    Loss: 0.009889   Batch Acc: 71.88
[Train] Epoch: 1 [320/620022]    Loss: 0.008951   Batch Acc: 78.12
[Train] Epoch: 1 [384/620022]    Loss: 0.008462   Batch Acc: 79.69
[Train] Epoch: 1 [448/620022]    Loss: 0.009041   Batch Acc: 75.00
[Train] Epoch: 1 [512/620022]    Loss: 0.009284   Batch Acc: 76.56
[Train] Epoch: 1 [576/620022]    Loss: 0.008845   Batch Acc: 78.12
[Train] Epoch: 1 [640/620022]    Loss: 0.009403   Batch Acc: 78.12
[Train] Epoch: 1 [704/620022]    Loss: 0.008487   Batch Acc: 68.75
[Train] Epoch: 1 [768/620022]    Loss: 0.011738   Batch Acc: 71.88
[Train] Epoch: 1 [832/620022]    Loss: 0.009037   Batch Acc: 82.81
[Train] Epoch: 1 [896/620022]    Loss: 0.007100   Batch Acc: 84.38
[Train] Epoch: 1 [960/620022]    Loss: 0.007070   Batch Acc: 82.81
[Train] Epoch: 1 [1024/620022]    Loss: 0.012199   Batch Acc: 67.19
[Train] Epoch: 1 [1088/620022]    Loss: 0.008719   Batch Acc: 79.69
[Train] Epoch: 1 [1152/620022]    Loss: 0.007696   Batch Acc: 78.12
[Train] Epoch: 1 [1216/620022]    Loss: 0.011800   Batch Acc: 71.88
[Train] Epoch: 1 [1280/620022]    Loss: 0.009314   Batch Acc: 78.12
[Train] Epoch: 1 [1344/620022]    Loss: 0.009498   Batch Acc: 71.88
[Train] Epoch: 1 [1408/620022]    Loss: 0.010421   Batch Acc: 73.44
[Train] Epoch: 1 [1472/620022]    Loss: 0.009121   Batch Acc: 78.12
[Train] Epoch: 1 [1536/620022]    Loss: 0.010275   Batch Acc: 75.00
[Train] Epoch: 1 [1600/620022]    Loss: 0.009106   Batch Acc: 76.56
[Train] Epoch: 1 [1664/620022]    Loss: 0.008616   Batch Acc: 76.56
[Train] Epoch: 1 [1728/620022]    Loss: 0.008687   Batch Acc: 81.25
[Train] Epoch: 1 [1792/620022]    Loss: 0.008165   Batch Acc: 79.69
[Train] Epoch: 1 [1856/620022]    Loss: 0.010249   Batch Acc: 76.56
[Train] Epoch: 1 [1920/620022]    Loss: 0.010622   Batch Acc: 73.44
[Train] Epoch: 1 [1984/620022]    Loss: 0.008758   Batch Acc: 78.12
[Train] Epoch: 1 [2048/620022]    Loss: 0.008576   Batch Acc: 75.00
[Train] Epoch: 1 [2112/620022]    Loss: 0.011275   Batch Acc: 71.88
[Train] Epoch: 1 [2176/620022]    Loss: 0.008904   Batch Acc: 75.00
[Train] Epoch: 1 [2240/620022]    Loss: 0.010602   Batch Acc: 71.88
[Train] Epoch: 1 [2304/620022]    Loss: 0.009480   Batch Acc: 73.44
[Train] Epoch: 1 [2368/620022]    Loss: 0.008822   Batch Acc: 79.69
[Train] Epoch: 1 [2432/620022]    Loss: 0.010204   Batch Acc: 68.75
[Train] Epoch: 1 [2496/620022]    Loss: 0.006945   Batch Acc: 82.81
[Train] Epoch: 1 [2560/620022]    Loss: 0.008408   Batch Acc: 76.56
[Train] Epoch: 1 [2624/620022]    Loss: 0.009351   Batch Acc: 73.44
[Train] Epoch: 1 [2688/620022]    Loss: 0.007626   Batch Acc: 82.81
[Train] Epoch: 1 [2752/620022]    Loss: 0.007962   Batch Acc: 82.81
[Train] Epoch: 1 [2816/620022]    Loss: 0.008171   Batch Acc: 78.12
[Train] Epoch: 1 [2880/620022]    Loss: 0.008440   Batch Acc: 78.12
[Train] Epoch: 1 [2944/620022]    Loss: 0.009384   Batch Acc: 76.56
[Train] Epoch: 1 [3008/620022]    Loss: 0.007227   Batch Acc: 85.94
[Train] Epoch: 1 [3072/620022]    Loss: 0.008521   Batch Acc: 73.44
[Train] Epoch: 1 [3136/620022]    Loss: 0.009822   Batch Acc: 71.88
[Train] Epoch: 1 [3200/620022]    Loss: 0.009037   Batch Acc: 79.69
[Train] Epoch: 1 [3264/620022]    Loss: 0.006196   Batch Acc: 87.50
[Train] Epoch: 1 [3328/620022]    Loss: 0.007026   Batch Acc: 85.94
[Train] Epoch: 1 [3392/620022]    Loss: 0.006864   Batch Acc: 82.81
[Train] Epoch: 1 [3456/620022]    Loss: 0.010074   Batch Acc: 78.12
[Train] Epoch: 1 [3520/620022]    Loss: 0.007282   Batch Acc: 79.69
[Train] Epoch: 1 [3584/620022]    Loss: 0.010393   Batch Acc: 68.75
[Train] Epoch: 1 [3648/620022]    Loss: 0.006870   Batch Acc: 85.94
[Train] Epoch: 1 [3712/620022]    Loss: 0.010743   Batch Acc: 71.88
[Train] Epoch: 1 [3776/620022]    Loss: 0.010998   Batch Acc: 70.31
[Train] Epoch: 1 [3840/620022]    Loss: 0.010301   Batch Acc: 68.75
[Train] Epoch: 1 [3904/620022]    Loss: 0.008025   Batch Acc: 79.69
[Train] Epoch: 1 [3968/620022]    Loss: 0.010897   Batch Acc: 67.19
[Train] Epoch: 1 [4032/620022]    Loss: 0.008550   Batch Acc: 79.69
[Train] Epoch: 1 [4096/620022]    Loss: 0.008318   Batch Acc: 75.00
[Train] Epoch: 1 [4160/620022]    Loss: 0.010168   Batch Acc: 73.44
[Train] Epoch: 1 [4224/620022]    Loss: 0.009739   Batch Acc: 70.31
[Train] Epoch: 1 [4288/620022]    Loss: 0.007056   Batch Acc: 81.25
[Train] Epoch: 1 [4352/620022]    Loss: 0.009076   Batch Acc: 70.31
[Train] Epoch: 1 [4416/620022]    Loss: 0.008317   Batch Acc: 79.69
[Train] Epoch: 1 [4480/620022]    Loss: 0.009693   Batch Acc: 75.00
[Train] Epoch: 1 [4544/620022]    Loss: 0.011478   Batch Acc: 71.88
[Train] Epoch: 1 [4608/620022]    Loss: 0.007927   Batch Acc: 76.56
[Train] Epoch: 1 [4672/620022]    Loss: 0.007603   Batch Acc: 79.69
[Train] Epoch: 1 [4736/620022]    Loss: 0.008648   Batch Acc: 79.69
[Train] Epoch: 1 [4800/620022]    Loss: 0.007892   Batch Acc: 76.56
[Train] Epoch: 1 [4864/620022]    Loss: 0.010374   Batch Acc: 70.31
[Train] Epoch: 1 [4928/620022]    Loss: 0.009210   Batch Acc: 82.81
[Train] Epoch: 1 [4992/620022]    Loss: 0.007025   Batch Acc: 84.38
[Train] Epoch: 1 [5056/620022]    Loss: 0.006721   Batch Acc: 87.50
[Train] Epoch: 1 [5120/620022]    Loss: 0.008662   Batch Acc: 73.44
[Train] Epoch: 1 [5184/620022]    Loss: 0.009021   Batch Acc: 71.88
[Train] Epoch: 1 [5248/620022]    Loss: 0.009563   Batch Acc: 75.00
[Train] Epoch: 1 [5312/620022]    Loss: 0.009949   Batch Acc: 78.12
[Train] Epoch: 1 [5376/620022]    Loss: 0.006586   Batch Acc: 85.94
[Train] Epoch: 1 [5440/620022]    Loss: 0.008438   Batch Acc: 82.81
[Train] Epoch: 1 [5504/620022]    Loss: 0.008284   Batch Acc: 82.81
[Train] Epoch: 1 [5568/620022]    Loss: 0.008063   Batch Acc: 81.25
[Train] Epoch: 1 [5632/620022]    Loss: 0.012307   Batch Acc: 67.19
[Train] Epoch: 1 [5696/620022]    Loss: 0.009172   Batch Acc: 75.00
[Train] Epoch: 1 [5760/620022]    Loss: 0.006920   Batch Acc: 89.06
[Train] Epoch: 1 [5824/620022]    Loss: 0.008460   Batch Acc: 79.69
[Train] Epoch: 1 [5888/620022]    Loss: 0.007621   Batch Acc: 78.12
[Train] Epoch: 1 [5952/620022]    Loss: 0.008380   Batch Acc: 79.69
[Train] Epoch: 1 [6016/620022]    Loss: 0.008942   Batch Acc: 78.12
[Train] Epoch: 1 [6080/620022]    Loss: 0.010838   Batch Acc: 68.75
[Train] Epoch: 1 [6144/620022]    Loss: 0.007573   Batch Acc: 82.81
[Train] Epoch: 1 [6208/620022]    Loss: 0.008620   Batch Acc: 78.12
[Train] Epoch: 1 [6272/620022]    Loss: 0.011807   Batch Acc: 64.06
[Train] Epoch: 1 [6336/620022]    Loss: 0.009803   Batch Acc: 76.56
[Train] Epoch: 1 [6400/620022]    Loss: 0.007863   Batch Acc: 82.81
[Train] Epoch: 1 [6464/620022]    Loss: 0.007741   Batch Acc: 76.56
[Train] Epoch: 1 [6528/620022]    Loss: 0.011523   Batch Acc: 71.88
[Train] Epoch: 1 [6592/620022]    Loss: 0.010977   Batch Acc: 70.31
[Train] Epoch: 1 [6656/620022]    Loss: 0.008676   Batch Acc: 76.56
[Train] Epoch: 1 [6720/620022]    Loss: 0.007024   Batch Acc: 79.69
[Train] Epoch: 1 [6784/620022]    Loss: 0.011603   Batch Acc: 70.31
[Train] Epoch: 1 [6848/620022]    Loss: 0.011696   Batch Acc: 67.19
[Train] Epoch: 1 [6912/620022]    Loss: 0.012852   Batch Acc: 65.62
[Train] Epoch: 1 [6976/620022]    Loss: 0.011717   Batch Acc: 70.31
[Train] Epoch: 1 [7040/620022]    Loss: 0.008612   Batch Acc: 78.12
[Train] Epoch: 1 [7104/620022]    Loss: 0.008413   Batch Acc: 81.25
[Train] Epoch: 1 [7168/620022]    Loss: 0.007507   Batch Acc: 82.81
[Train] Epoch: 1 [7232/620022]    Loss: 0.008815   Batch Acc: 79.69
[Train] Epoch: 1 [7296/620022]    Loss: 0.009626   Batch Acc: 75.00
[Train] Epoch: 1 [7360/620022]    Loss: 0.006020   Batch Acc: 87.50
[Train] Epoch: 1 [7424/620022]    Loss: 0.009376   Batch Acc: 76.56
[Train] Epoch: 1 [7488/620022]    Loss: 0.008030   Batch Acc: 76.56
[Train] Epoch: 1 [7552/620022]    Loss: 0.010911   Batch Acc: 65.62
[Train] Epoch: 1 [7616/620022]    Loss: 0.008312   Batch Acc: 76.56
[Train] Epoch: 1 [7680/620022]    Loss: 0.008856   Batch Acc: 78.12
[Train] Epoch: 1 [7744/620022]    Loss: 0.007735   Batch Acc: 84.38
[Train] Epoch: 1 [7808/620022]    Loss: 0.007421   Batch Acc: 81.25
[Train] Epoch: 1 [7872/620022]    Loss: 0.008148   Batch Acc: 81.25
[Train] Epoch: 1 [7936/620022]    Loss: 0.009027   Batch Acc: 76.56
[Train] Epoch: 1 [8000/620022]    Loss: 0.007996   Batch Acc: 81.25
[Train] Epoch: 1 [8064/620022]    Loss: 0.009165   Batch Acc: 76.56
[Train] Epoch: 1 [8128/620022]    Loss: 0.007540   Batch Acc: 76.56
[Train] Epoch: 1 [8192/620022]    Loss: 0.007219   Batch Acc: 82.81
[Train] Epoch: 1 [8256/620022]    Loss: 0.009690   Batch Acc: 78.12
[Train] Epoch: 1 [8320/620022]    Loss: 0.009297   Batch Acc: 75.00
[Train] Epoch: 1 [8384/620022]    Loss: 0.008732   Batch Acc: 75.00
[Train] Epoch: 1 [8448/620022]    Loss: 0.010734   Batch Acc: 71.88
[Train] Epoch: 1 [8512/620022]    Loss: 0.007418   Batch Acc: 78.12
[Train] Epoch: 1 [8576/620022]    Loss: 0.007912   Batch Acc: 81.25
[Train] Epoch: 1 [8640/620022]    Loss: 0.008663   Batch Acc: 82.81
[Train] Epoch: 1 [8704/620022]    Loss: 0.008084   Batch Acc: 76.56
[Train] Epoch: 1 [8768/620022]    Loss: 0.007269   Batch Acc: 79.69
[Train] Epoch: 1 [8832/620022]    Loss: 0.009586   Batch Acc: 71.88
[Train] Epoch: 1 [8896/620022]    Loss: 0.008685   Batch Acc: 73.44
[Train] Epoch: 1 [8960/620022]    Loss: 0.009326   Batch Acc: 71.88
[Train] Epoch: 1 [9024/620022]    Loss: 0.007064   Batch Acc: 82.81
[Train] Epoch: 1 [9088/620022]    Loss: 0.011448   Batch Acc: 75.00
[Train] Epoch: 1 [9152/620022]    Loss: 0.008563   Batch Acc: 79.69
[Train] Epoch: 1 [9216/620022]    Loss: 0.006910   Batch Acc: 89.06
[Train] Epoch: 1 [9280/620022]    Loss: 0.007575   Batch Acc: 81.25
[Train] Epoch: 1 [9344/620022]    Loss: 0.009928   Batch Acc: 75.00
[Train] Epoch: 1 [9408/620022]    Loss: 0.009211   Batch Acc: 73.44
[Train] Epoch: 1 [9472/620022]    Loss: 0.009628   Batch Acc: 76.56
[Train] Epoch: 1 [9536/620022]    Loss: 0.008394   Batch Acc: 76.56
[Train] Epoch: 1 [9600/620022]    Loss: 0.008109   Batch Acc: 75.00
[Train] Epoch: 1 [9664/620022]    Loss: 0.012169   Batch Acc: 68.75
[Train] Epoch: 1 [9728/620022]    Loss: 0.007649   Batch Acc: 75.00
[Train] Epoch: 1 [9792/620022]    Loss: 0.008878   Batch Acc: 78.12
[Train] Epoch: 1 [9856/620022]    Loss: 0.008384   Batch Acc: 82.81
[Train] Epoch: 1 [9920/620022]    Loss: 0.009669   Batch Acc: 71.88
[Train] Epoch: 1 [9984/620022]    Loss: 0.007771   Batch Acc: 85.94
[Train] Epoch: 1 [10048/620022]    Loss: 0.008036   Batch Acc: 79.69
[Train] Epoch: 1 [10112/620022]    Loss: 0.011528   Batch Acc: 65.62
[Train] Epoch: 1 [10176/620022]    Loss: 0.006087   Batch Acc: 84.38
[Train] Epoch: 1 [10240/620022]    Loss: 0.010956   Batch Acc: 70.31
[Train] Epoch: 1 [10304/620022]    Loss: 0.009115   Batch Acc: 73.44
[Train] Epoch: 1 [10368/620022]    Loss: 0.009036   Batch Acc: 79.69
[Train] Epoch: 1 [10432/620022]    Loss: 0.010275   Batch Acc: 78.12
[Train] Epoch: 1 [10496/620022]    Loss: 0.008679   Batch Acc: 73.44
[Train] Epoch: 1 [10560/620022]    Loss: 0.008401   Batch Acc: 79.69
[Train] Epoch: 1 [10624/620022]    Loss: 0.007372   Batch Acc: 78.12
[Train] Epoch: 1 [10688/620022]    Loss: 0.007600   Batch Acc: 84.38
[Train] Epoch: 1 [10752/620022]    Loss: 0.010097   Batch Acc: 71.88
[Train] Epoch: 1 [10816/620022]    Loss: 0.009645   Batch Acc: 75.00
[Train] Epoch: 1 [10880/620022]    Loss: 0.011629   Batch Acc: 62.50
[Train] Epoch: 1 [10944/620022]    Loss: 0.009919   Batch Acc: 75.00
[Train] Epoch: 1 [11008/620022]    Loss: 0.008824   Batch Acc: 78.12
[Train] Epoch: 1 [11072/620022]    Loss: 0.010098   Batch Acc: 73.44
[Train] Epoch: 1 [11136/620022]    Loss: 0.010913   Batch Acc: 68.75
[Train] Epoch: 1 [11200/620022]    Loss: 0.008166   Batch Acc: 75.00
[Train] Epoch: 1 [11264/620022]    Loss: 0.009804   Batch Acc: 70.31
[Train] Epoch: 1 [11328/620022]    Loss: 0.009452   Batch Acc: 78.12
[Train] Epoch: 1 [11392/620022]    Loss: 0.009232   Batch Acc: 78.12
[Train] Epoch: 1 [11456/620022]    Loss: 0.008823   Batch Acc: 84.38
[Train] Epoch: 1 [11520/620022]    Loss: 0.008435   Batch Acc: 76.56
[Train] Epoch: 1 [11584/620022]    Loss: 0.009556   Batch Acc: 67.19
[Train] Epoch: 1 [11648/620022]    Loss: 0.006888   Batch Acc: 85.94
[Train] Epoch: 1 [11712/620022]    Loss: 0.010375   Batch Acc: 68.75
[Train] Epoch: 1 [11776/620022]    Loss: 0.006957   Batch Acc: 84.38
[Train] Epoch: 1 [11840/620022]    Loss: 0.007455   Batch Acc: 79.69
[Train] Epoch: 1 [11904/620022]    Loss: 0.008186   Batch Acc: 78.12
[Train] Epoch: 1 [11968/620022]    Loss: 0.008477   Batch Acc: 79.69
[Train] Epoch: 1 [12032/620022]    Loss: 0.008475   Batch Acc: 76.56
[Train] Epoch: 1 [12096/620022]    Loss: 0.007684   Batch Acc: 76.56
[Train] Epoch: 1 [12160/620022]    Loss: 0.009664   Batch Acc: 70.31
[Train] Epoch: 1 [12224/620022]    Loss: 0.008407   Batch Acc: 81.25
[Train] Epoch: 1 [12288/620022]    Loss: 0.010165   Batch Acc: 71.88
[Train] Epoch: 1 [12352/620022]    Loss: 0.009006   Batch Acc: 75.00
[Train] Epoch: 1 [12416/620022]    Loss: 0.006915   Batch Acc: 87.50
[Train] Epoch: 1 [12480/620022]    Loss: 0.009868   Batch Acc: 71.88
[Train] Epoch: 1 [12544/620022]    Loss: 0.009628   Batch Acc: 81.25
[Train] Epoch: 1 [12608/620022]    Loss: 0.009968   Batch Acc: 75.00
[Train] Epoch: 1 [12672/620022]    Loss: 0.010377   Batch Acc: 71.88
[Train] Epoch: 1 [12736/620022]    Loss: 0.008029   Batch Acc: 82.81
[Train] Epoch: 1 [12800/620022]    Loss: 0.009583   Batch Acc: 73.44
[Train] Epoch: 1 [12864/620022]    Loss: 0.009962   Batch Acc: 76.56
[Train] Epoch: 1 [12928/620022]    Loss: 0.009346   Batch Acc: 75.00
[Train] Epoch: 1 [12992/620022]    Loss: 0.008728   Batch Acc: 79.69
[Train] Epoch: 1 [13056/620022]    Loss: 0.008742   Batch Acc: 68.75
[Train] Epoch: 1 [13120/620022]    Loss: 0.007884   Batch Acc: 78.12
[Train] Epoch: 1 [13184/620022]    Loss: 0.009410   Batch Acc: 70.31
[Train] Epoch: 1 [13248/620022]    Loss: 0.009539   Batch Acc: 73.44
[Train] Epoch: 1 [13312/620022]    Loss: 0.007604   Batch Acc: 79.69
[Train] Epoch: 1 [13376/620022]    Loss: 0.009026   Batch Acc: 84.38
[Train] Epoch: 1 [13440/620022]    Loss: 0.009197   Batch Acc: 75.00
[Train] Epoch: 1 [13504/620022]    Loss: 0.006934   Batch Acc: 82.81
[Train] Epoch: 1 [13568/620022]    Loss: 0.008883   Batch Acc: 70.31
[Train] Epoch: 1 [13632/620022]    Loss: 0.008831   Batch Acc: 78.12
[Train] Epoch: 1 [13696/620022]    Loss: 0.007515   Batch Acc: 82.81
[Train] Epoch: 1 [13760/620022]    Loss: 0.009246   Batch Acc: 79.69
[Train] Epoch: 1 [13824/620022]    Loss: 0.009515   Batch Acc: 78.12
[Train] Epoch: 1 [13888/620022]    Loss: 0.011786   Batch Acc: 67.19
[Train] Epoch: 1 [13952/620022]    Loss: 0.009957   Batch Acc: 75.00
[Train] Epoch: 1 [14016/620022]    Loss: 0.007910   Batch Acc: 84.38
[Train] Epoch: 1 [14080/620022]    Loss: 0.008544   Batch Acc: 82.81
[Train] Epoch: 1 [14144/620022]    Loss: 0.008760   Batch Acc: 79.69
[Train] Epoch: 1 [14208/620022]    Loss: 0.009973   Batch Acc: 75.00
[Train] Epoch: 1 [14272/620022]    Loss: 0.008702   Batch Acc: 76.56
[Train] Epoch: 1 [14336/620022]    Loss: 0.008384   Batch Acc: 81.25
[Train] Epoch: 1 [14400/620022]    Loss: 0.010901   Batch Acc: 71.88
[Train] Epoch: 1 [14464/620022]    Loss: 0.010902   Batch Acc: 75.00
[Train] Epoch: 1 [14528/620022]    Loss: 0.008895   Batch Acc: 76.56
[Train] Epoch: 1 [14592/620022]    Loss: 0.009254   Batch Acc: 75.00
[Train] Epoch: 1 [14656/620022]    Loss: 0.007756   Batch Acc: 81.25
[Train] Epoch: 1 [14720/620022]    Loss: 0.009082   Batch Acc: 73.44
[Train] Epoch: 1 [14784/620022]    Loss: 0.006965   Batch Acc: 85.94
[Train] Epoch: 1 [14848/620022]    Loss: 0.011511   Batch Acc: 70.31
[Train] Epoch: 1 [14912/620022]    Loss: 0.007647   Batch Acc: 79.69
[Train] Epoch: 1 [14976/620022]    Loss: 0.011458   Batch Acc: 70.31
[Train] Epoch: 1 [15040/620022]    Loss: 0.009291   Batch Acc: 79.69
[Train] Epoch: 1 [15104/620022]    Loss: 0.009407   Batch Acc: 78.12
[Train] Epoch: 1 [15168/620022]    Loss: 0.008032   Batch Acc: 81.25
[Train] Epoch: 1 [15232/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 1 [15296/620022]    Loss: 0.007912   Batch Acc: 79.69
[Train] Epoch: 1 [15360/620022]    Loss: 0.010124   Batch Acc: 75.00
[Train] Epoch: 1 [15424/620022]    Loss: 0.009725   Batch Acc: 78.12
[Train] Epoch: 1 [15488/620022]    Loss: 0.005876   Batch Acc: 89.06
[Train] Epoch: 1 [15552/620022]    Loss: 0.007964   Batch Acc: 76.56
[Train] Epoch: 1 [15616/620022]    Loss: 0.008104   Batch Acc: 81.25
[Train] Epoch: 1 [15680/620022]    Loss: 0.008056   Batch Acc: 79.69
[Train] Epoch: 1 [15744/620022]    Loss: 0.008085   Batch Acc: 82.81
[Train] Epoch: 1 [15808/620022]    Loss: 0.009194   Batch Acc: 79.69
[Train] Epoch: 1 [15872/620022]    Loss: 0.009903   Batch Acc: 78.12
[Train] Epoch: 1 [15936/620022]    Loss: 0.007900   Batch Acc: 76.56
[Train] Epoch: 1 [16000/620022]    Loss: 0.008947   Batch Acc: 73.44
[Train] Epoch: 1 [16064/620022]    Loss: 0.009660   Batch Acc: 78.12
[Train] Epoch: 1 [16128/620022]    Loss: 0.008527   Batch Acc: 81.25
[Train] Epoch: 1 [16192/620022]    Loss: 0.009259   Batch Acc: 76.56
[Train] Epoch: 1 [16256/620022]    Loss: 0.007763   Batch Acc: 84.38
[Train] Epoch: 1 [16320/620022]    Loss: 0.008481   Batch Acc: 79.69
[Train] Epoch: 1 [16384/620022]    Loss: 0.008574   Batch Acc: 75.00
[Train] Epoch: 1 [16448/620022]    Loss: 0.007310   Batch Acc: 78.12
[Train] Epoch: 1 [16512/620022]    Loss: 0.010084   Batch Acc: 70.31
[Train] Epoch: 1 [16576/620022]    Loss: 0.008526   Batch Acc: 76.56
[Train] Epoch: 1 [16640/620022]    Loss: 0.009946   Batch Acc: 73.44
[Train] Epoch: 1 [16704/620022]    Loss: 0.009842   Batch Acc: 70.31
[Train] Epoch: 1 [16768/620022]    Loss: 0.010585   Batch Acc: 70.31
[Train] Epoch: 1 [16832/620022]    Loss: 0.008326   Batch Acc: 78.12
[Train] Epoch: 1 [16896/620022]    Loss: 0.009062   Batch Acc: 75.00
[Train] Epoch: 1 [16960/620022]    Loss: 0.009872   Batch Acc: 82.81
[Train] Epoch: 1 [17024/620022]    Loss: 0.008991   Batch Acc: 76.56
[Train] Epoch: 1 [17088/620022]    Loss: 0.008083   Batch Acc: 84.38
[Train] Epoch: 1 [17152/620022]    Loss: 0.006518   Batch Acc: 85.94
[Train] Epoch: 1 [17216/620022]    Loss: 0.008623   Batch Acc: 76.56
[Train] Epoch: 1 [17280/620022]    Loss: 0.008131   Batch Acc: 78.12
[Train] Epoch: 1 [17344/620022]    Loss: 0.008702   Batch Acc: 78.12
[Train] Epoch: 1 [17408/620022]    Loss: 0.009749   Batch Acc: 78.12
[Train] Epoch: 1 [17472/620022]    Loss: 0.007509   Batch Acc: 79.69
[Train] Epoch: 1 [17536/620022]    Loss: 0.007797   Batch Acc: 85.94
[Train] Epoch: 1 [17600/620022]    Loss: 0.008536   Batch Acc: 78.12
[Train] Epoch: 1 [17664/620022]    Loss: 0.007645   Batch Acc: 79.69
[Train] Epoch: 1 [17728/620022]    Loss: 0.009174   Batch Acc: 76.56
[Train] Epoch: 1 [17792/620022]    Loss: 0.007862   Batch Acc: 81.25
[Train] Epoch: 1 [17856/620022]    Loss: 0.010909   Batch Acc: 73.44
[Train] Epoch: 1 [17920/620022]    Loss: 0.010124   Batch Acc: 78.12
[Train] Epoch: 1 [17984/620022]    Loss: 0.008079   Batch Acc: 78.12
[Train] Epoch: 1 [18048/620022]    Loss: 0.009038   Batch Acc: 84.38
[Train] Epoch: 1 [18112/620022]    Loss: 0.012873   Batch Acc: 60.94
[Train] Epoch: 1 [18176/620022]    Loss: 0.007312   Batch Acc: 79.69
[Train] Epoch: 1 [18240/620022]    Loss: 0.008767   Batch Acc: 75.00
[Train] Epoch: 1 [18304/620022]    Loss: 0.007208   Batch Acc: 82.81
[Train] Epoch: 1 [18368/620022]    Loss: 0.007208   Batch Acc: 81.25
[Train] Epoch: 1 [18432/620022]    Loss: 0.009451   Batch Acc: 71.88
[Train] Epoch: 1 [18496/620022]    Loss: 0.006430   Batch Acc: 82.81
[Train] Epoch: 1 [18560/620022]    Loss: 0.009092   Batch Acc: 68.75
[Train] Epoch: 1 [18624/620022]    Loss: 0.008793   Batch Acc: 76.56
[Train] Epoch: 1 [18688/620022]    Loss: 0.006811   Batch Acc: 81.25
[Train] Epoch: 1 [18752/620022]    Loss: 0.006921   Batch Acc: 87.50
[Train] Epoch: 1 [18816/620022]    Loss: 0.007014   Batch Acc: 82.81
[Train] Epoch: 1 [18880/620022]    Loss: 0.010448   Batch Acc: 71.88
[Train] Epoch: 1 [18944/620022]    Loss: 0.010447   Batch Acc: 78.12
[Train] Epoch: 1 [19008/620022]    Loss: 0.007395   Batch Acc: 81.25
[Train] Epoch: 1 [19072/620022]    Loss: 0.008375   Batch Acc: 84.38
[Train] Epoch: 1 [19136/620022]    Loss: 0.010635   Batch Acc: 68.75
[Train] Epoch: 1 [19200/620022]    Loss: 0.008105   Batch Acc: 81.25
[Train] Epoch: 1 [19264/620022]    Loss: 0.008741   Batch Acc: 84.38
[Train] Epoch: 1 [19328/620022]    Loss: 0.007166   Batch Acc: 82.81
[Train] Epoch: 1 [19392/620022]    Loss: 0.006892   Batch Acc: 85.94
[Train] Epoch: 1 [19456/620022]    Loss: 0.010946   Batch Acc: 71.88
[Train] Epoch: 1 [19520/620022]    Loss: 0.011645   Batch Acc: 62.50
[Train] Epoch: 1 [19584/620022]    Loss: 0.010013   Batch Acc: 75.00
[Train] Epoch: 1 [19648/620022]    Loss: 0.010393   Batch Acc: 75.00
[Train] Epoch: 1 [19712/620022]    Loss: 0.007884   Batch Acc: 84.38
[Train] Epoch: 1 [19776/620022]    Loss: 0.010364   Batch Acc: 70.31
[Train] Epoch: 1 [19840/620022]    Loss: 0.008113   Batch Acc: 73.44
[Train] Epoch: 1 [19904/620022]    Loss: 0.007906   Batch Acc: 81.25
[Train] Epoch: 1 [19968/620022]    Loss: 0.008960   Batch Acc: 70.31
[Train] Epoch: 1 [20032/620022]    Loss: 0.009051   Batch Acc: 76.56
[Train] Epoch: 1 [20096/620022]    Loss: 0.011112   Batch Acc: 67.19
[Train] Epoch: 1 [20160/620022]    Loss: 0.007572   Batch Acc: 79.69
[Train] Epoch: 1 [20224/620022]    Loss: 0.006902   Batch Acc: 85.94
[Train] Epoch: 1 [20288/620022]    Loss: 0.010234   Batch Acc: 73.44
[Train] Epoch: 1 [20352/620022]    Loss: 0.007191   Batch Acc: 82.81
[Train] Epoch: 1 [20416/620022]    Loss: 0.010372   Batch Acc: 70.31
[Train] Epoch: 1 [20480/620022]    Loss: 0.009412   Batch Acc: 78.12
[Train] Epoch: 1 [20544/620022]    Loss: 0.010857   Batch Acc: 68.75
[Train] Epoch: 1 [20608/620022]    Loss: 0.008353   Batch Acc: 79.69
[Train] Epoch: 1 [20672/620022]    Loss: 0.010188   Batch Acc: 81.25
[Train] Epoch: 1 [20736/620022]    Loss: 0.009935   Batch Acc: 79.69
[Train] Epoch: 1 [20800/620022]    Loss: 0.009054   Batch Acc: 78.12
[Train] Epoch: 1 [20864/620022]    Loss: 0.008680   Batch Acc: 79.69
[Train] Epoch: 1 [20928/620022]    Loss: 0.009039   Batch Acc: 73.44
[Train] Epoch: 1 [20992/620022]    Loss: 0.011518   Batch Acc: 64.06
[Train] Epoch: 1 [21056/620022]    Loss: 0.009228   Batch Acc: 75.00
[Train] Epoch: 1 [21120/620022]    Loss: 0.009942   Batch Acc: 65.62
[Train] Epoch: 1 [21184/620022]    Loss: 0.008598   Batch Acc: 78.12
[Train] Epoch: 1 [21248/620022]    Loss: 0.008407   Batch Acc: 79.69
[Train] Epoch: 1 [21312/620022]    Loss: 0.007433   Batch Acc: 81.25
[Train] Epoch: 1 [21376/620022]    Loss: 0.009558   Batch Acc: 76.56
[Train] Epoch: 1 [21440/620022]    Loss: 0.007152   Batch Acc: 84.38
[Train] Epoch: 1 [21504/620022]    Loss: 0.008690   Batch Acc: 78.12
[Train] Epoch: 1 [21568/620022]    Loss: 0.008841   Batch Acc: 76.56
[Train] Epoch: 1 [21632/620022]    Loss: 0.007878   Batch Acc: 82.81
[Train] Epoch: 1 [21696/620022]    Loss: 0.009250   Batch Acc: 73.44
[Train] Epoch: 1 [21760/620022]    Loss: 0.011654   Batch Acc: 68.75
[Train] Epoch: 1 [21824/620022]    Loss: 0.007515   Batch Acc: 76.56
[Train] Epoch: 1 [21888/620022]    Loss: 0.008903   Batch Acc: 71.88
[Train] Epoch: 1 [21952/620022]    Loss: 0.010319   Batch Acc: 75.00
[Train] Epoch: 1 [22016/620022]    Loss: 0.008251   Batch Acc: 82.81
[Train] Epoch: 1 [22080/620022]    Loss: 0.010531   Batch Acc: 73.44
[Train] Epoch: 1 [22144/620022]    Loss: 0.009974   Batch Acc: 71.88
[Train] Epoch: 1 [22208/620022]    Loss: 0.007882   Batch Acc: 81.25
[Train] Epoch: 1 [22272/620022]    Loss: 0.009948   Batch Acc: 75.00
[Train] Epoch: 1 [22336/620022]    Loss: 0.011783   Batch Acc: 62.50
[Train] Epoch: 1 [22400/620022]    Loss: 0.009356   Batch Acc: 75.00
[Train] Epoch: 1 [22464/620022]    Loss: 0.011739   Batch Acc: 57.81
[Train] Epoch: 1 [22528/620022]    Loss: 0.007227   Batch Acc: 84.38
[Train] Epoch: 1 [22592/620022]    Loss: 0.006635   Batch Acc: 84.38
[Train] Epoch: 1 [22656/620022]    Loss: 0.007205   Batch Acc: 82.81
[Train] Epoch: 1 [22720/620022]    Loss: 0.008200   Batch Acc: 75.00
[Train] Epoch: 1 [22784/620022]    Loss: 0.009113   Batch Acc: 71.88
[Train] Epoch: 1 [22848/620022]    Loss: 0.009757   Batch Acc: 67.19
[Train] Epoch: 1 [22912/620022]    Loss: 0.008839   Batch Acc: 79.69
[Train] Epoch: 1 [22976/620022]    Loss: 0.010101   Batch Acc: 78.12
[Train] Epoch: 1 [23040/620022]    Loss: 0.008263   Batch Acc: 79.69
[Train] Epoch: 1 [23104/620022]    Loss: 0.008457   Batch Acc: 84.38
[Train] Epoch: 1 [23168/620022]    Loss: 0.006889   Batch Acc: 82.81
[Train] Epoch: 1 [23232/620022]    Loss: 0.007660   Batch Acc: 81.25
[Train] Epoch: 1 [23296/620022]    Loss: 0.010666   Batch Acc: 71.88
[Train] Epoch: 1 [23360/620022]    Loss: 0.008786   Batch Acc: 79.69
[Train] Epoch: 1 [23424/620022]    Loss: 0.008666   Batch Acc: 79.69
[Train] Epoch: 1 [23488/620022]    Loss: 0.011093   Batch Acc: 73.44
[Train] Epoch: 1 [23552/620022]    Loss: 0.008705   Batch Acc: 75.00
[Train] Epoch: 1 [23616/620022]    Loss: 0.009554   Batch Acc: 75.00
[Train] Epoch: 1 [23680/620022]    Loss: 0.009033   Batch Acc: 76.56
[Train] Epoch: 1 [23744/620022]    Loss: 0.010873   Batch Acc: 73.44
[Train] Epoch: 1 [23808/620022]    Loss: 0.010071   Batch Acc: 75.00
[Train] Epoch: 1 [23872/620022]    Loss: 0.008526   Batch Acc: 76.56
[Train] Epoch: 1 [23936/620022]    Loss: 0.007757   Batch Acc: 78.12
[Train] Epoch: 1 [24000/620022]    Loss: 0.007213   Batch Acc: 85.94
[Train] Epoch: 1 [24064/620022]    Loss: 0.007854   Batch Acc: 81.25
[Train] Epoch: 1 [24128/620022]    Loss: 0.007879   Batch Acc: 84.38
[Train] Epoch: 1 [24192/620022]    Loss: 0.009287   Batch Acc: 73.44
[Train] Epoch: 1 [24256/620022]    Loss: 0.009616   Batch Acc: 73.44
[Train] Epoch: 1 [24320/620022]    Loss: 0.006974   Batch Acc: 81.25
[Train] Epoch: 1 [24384/620022]    Loss: 0.008429   Batch Acc: 76.56
[Train] Epoch: 1 [24448/620022]    Loss: 0.007180   Batch Acc: 81.25
[Train] Epoch: 1 [24512/620022]    Loss: 0.009940   Batch Acc: 76.56
[Train] Epoch: 1 [24576/620022]    Loss: 0.007263   Batch Acc: 82.81
[Train] Epoch: 1 [24640/620022]    Loss: 0.007945   Batch Acc: 84.38
[Train] Epoch: 1 [24704/620022]    Loss: 0.010769   Batch Acc: 71.88
[Train] Epoch: 1 [24768/620022]    Loss: 0.006609   Batch Acc: 90.62
[Train] Epoch: 1 [24832/620022]    Loss: 0.008140   Batch Acc: 78.12
[Train] Epoch: 1 [24896/620022]    Loss: 0.007935   Batch Acc: 82.81
[Train] Epoch: 1 [24960/620022]    Loss: 0.009317   Batch Acc: 75.00
[Train] Epoch: 1 [25024/620022]    Loss: 0.009994   Batch Acc: 71.88
[Train] Epoch: 1 [25088/620022]    Loss: 0.009258   Batch Acc: 70.31
[Train] Epoch: 1 [25152/620022]    Loss: 0.009982   Batch Acc: 71.88
[Train] Epoch: 1 [25216/620022]    Loss: 0.007981   Batch Acc: 82.81
[Train] Epoch: 1 [25280/620022]    Loss: 0.009307   Batch Acc: 78.12
[Train] Epoch: 1 [25344/620022]    Loss: 0.009791   Batch Acc: 71.88
[Train] Epoch: 1 [25408/620022]    Loss: 0.007670   Batch Acc: 78.12
[Train] Epoch: 1 [25472/620022]    Loss: 0.011153   Batch Acc: 70.31
[Train] Epoch: 1 [25536/620022]    Loss: 0.008204   Batch Acc: 81.25
[Train] Epoch: 1 [25600/620022]    Loss: 0.007122   Batch Acc: 84.38
[Train] Epoch: 1 [25664/620022]    Loss: 0.008835   Batch Acc: 76.56
[Train] Epoch: 1 [25728/620022]    Loss: 0.010360   Batch Acc: 71.88
[Train] Epoch: 1 [25792/620022]    Loss: 0.007353   Batch Acc: 81.25
[Train] Epoch: 1 [25856/620022]    Loss: 0.007392   Batch Acc: 84.38
[Train] Epoch: 1 [25920/620022]    Loss: 0.008593   Batch Acc: 75.00
[Train] Epoch: 1 [25984/620022]    Loss: 0.006865   Batch Acc: 87.50
[Train] Epoch: 1 [26048/620022]    Loss: 0.009099   Batch Acc: 75.00
[Train] Epoch: 1 [26112/620022]    Loss: 0.006527   Batch Acc: 81.25
[Train] Epoch: 1 [26176/620022]    Loss: 0.008527   Batch Acc: 73.44
[Train] Epoch: 1 [26240/620022]    Loss: 0.008844   Batch Acc: 76.56
[Train] Epoch: 1 [26304/620022]    Loss: 0.007542   Batch Acc: 81.25
[Train] Epoch: 1 [26368/620022]    Loss: 0.008297   Batch Acc: 78.12
[Train] Epoch: 1 [26432/620022]    Loss: 0.008739   Batch Acc: 78.12
[Train] Epoch: 1 [26496/620022]    Loss: 0.008272   Batch Acc: 81.25
[Train] Epoch: 1 [26560/620022]    Loss: 0.008010   Batch Acc: 84.38
[Train] Epoch: 1 [26624/620022]    Loss: 0.011299   Batch Acc: 68.75
[Train] Epoch: 1 [26688/620022]    Loss: 0.006180   Batch Acc: 89.06
[Train] Epoch: 1 [26752/620022]    Loss: 0.011218   Batch Acc: 73.44
[Train] Epoch: 1 [26816/620022]    Loss: 0.010414   Batch Acc: 73.44
[Train] Epoch: 1 [26880/620022]    Loss: 0.009036   Batch Acc: 81.25
[Train] Epoch: 1 [26944/620022]    Loss: 0.009891   Batch Acc: 73.44
[Train] Epoch: 1 [27008/620022]    Loss: 0.009402   Batch Acc: 76.56
[Train] Epoch: 1 [27072/620022]    Loss: 0.007019   Batch Acc: 85.94
[Train] Epoch: 1 [27136/620022]    Loss: 0.008101   Batch Acc: 75.00
[Train] Epoch: 1 [27200/620022]    Loss: 0.008311   Batch Acc: 73.44
[Train] Epoch: 1 [27264/620022]    Loss: 0.009722   Batch Acc: 76.56
[Train] Epoch: 1 [27328/620022]    Loss: 0.008873   Batch Acc: 79.69
[Train] Epoch: 1 [27392/620022]    Loss: 0.009354   Batch Acc: 78.12
[Train] Epoch: 1 [27456/620022]    Loss: 0.011020   Batch Acc: 62.50
[Train] Epoch: 1 [27520/620022]    Loss: 0.008753   Batch Acc: 81.25
[Train] Epoch: 1 [27584/620022]    Loss: 0.010604   Batch Acc: 70.31
[Train] Epoch: 1 [27648/620022]    Loss: 0.010530   Batch Acc: 76.56
[Train] Epoch: 1 [27712/620022]    Loss: 0.008173   Batch Acc: 78.12
[Train] Epoch: 1 [27776/620022]    Loss: 0.008785   Batch Acc: 79.69
[Train] Epoch: 1 [27840/620022]    Loss: 0.007087   Batch Acc: 78.12
[Train] Epoch: 1 [27904/620022]    Loss: 0.008274   Batch Acc: 81.25
[Train] Epoch: 1 [27968/620022]    Loss: 0.008006   Batch Acc: 76.56
[Train] Epoch: 1 [28032/620022]    Loss: 0.007282   Batch Acc: 78.12
[Train] Epoch: 1 [28096/620022]    Loss: 0.009671   Batch Acc: 75.00
[Train] Epoch: 1 [28160/620022]    Loss: 0.009074   Batch Acc: 81.25
[Train] Epoch: 1 [28224/620022]    Loss: 0.009009   Batch Acc: 76.56
[Train] Epoch: 1 [28288/620022]    Loss: 0.008783   Batch Acc: 79.69
[Train] Epoch: 1 [28352/620022]    Loss: 0.008939   Batch Acc: 76.56
[Train] Epoch: 1 [28416/620022]    Loss: 0.010607   Batch Acc: 64.06
[Train] Epoch: 1 [28480/620022]    Loss: 0.007683   Batch Acc: 82.81
[Train] Epoch: 1 [28544/620022]    Loss: 0.008232   Batch Acc: 79.69
[Train] Epoch: 1 [28608/620022]    Loss: 0.007435   Batch Acc: 81.25
[Train] Epoch: 1 [28672/620022]    Loss: 0.007414   Batch Acc: 82.81
[Train] Epoch: 1 [28736/620022]    Loss: 0.009426   Batch Acc: 76.56
[Train] Epoch: 1 [28800/620022]    Loss: 0.009239   Batch Acc: 75.00
[Train] Epoch: 1 [28864/620022]    Loss: 0.010031   Batch Acc: 78.12
[Train] Epoch: 1 [28928/620022]    Loss: 0.006336   Batch Acc: 82.81
[Train] Epoch: 1 [28992/620022]    Loss: 0.007606   Batch Acc: 81.25
[Train] Epoch: 1 [29056/620022]    Loss: 0.006796   Batch Acc: 84.38
[Train] Epoch: 1 [29120/620022]    Loss: 0.010004   Batch Acc: 73.44
[Train] Epoch: 1 [29184/620022]    Loss: 0.007988   Batch Acc: 75.00
[Train] Epoch: 1 [29248/620022]    Loss: 0.009005   Batch Acc: 79.69
[Train] Epoch: 1 [29312/620022]    Loss: 0.007991   Batch Acc: 81.25
[Train] Epoch: 1 [29376/620022]    Loss: 0.008725   Batch Acc: 78.12
[Train] Epoch: 1 [29440/620022]    Loss: 0.008743   Batch Acc: 78.12
[Train] Epoch: 1 [29504/620022]    Loss: 0.005626   Batch Acc: 90.62
[Train] Epoch: 1 [29568/620022]    Loss: 0.010837   Batch Acc: 71.88
[Train] Epoch: 1 [29632/620022]    Loss: 0.009336   Batch Acc: 79.69
[Train] Epoch: 1 [29696/620022]    Loss: 0.009984   Batch Acc: 68.75
[Train] Epoch: 1 [29760/620022]    Loss: 0.010325   Batch Acc: 73.44
[Train] Epoch: 1 [29824/620022]    Loss: 0.008859   Batch Acc: 75.00
[Train] Epoch: 1 [29888/620022]    Loss: 0.008667   Batch Acc: 78.12
[Train] Epoch: 1 [29952/620022]    Loss: 0.010860   Batch Acc: 67.19
[Train] Epoch: 1 [30016/620022]    Loss: 0.007784   Batch Acc: 78.12
[Train] Epoch: 1 [30080/620022]    Loss: 0.010877   Batch Acc: 70.31
[Train] Epoch: 1 [30144/620022]    Loss: 0.008545   Batch Acc: 76.56
[Train] Epoch: 1 [30208/620022]    Loss: 0.007607   Batch Acc: 81.25
[Train] Epoch: 1 [30272/620022]    Loss: 0.010558   Batch Acc: 65.62
[Train] Epoch: 1 [30336/620022]    Loss: 0.009914   Batch Acc: 71.88
[Train] Epoch: 1 [30400/620022]    Loss: 0.010572   Batch Acc: 75.00
[Train] Epoch: 1 [30464/620022]    Loss: 0.006884   Batch Acc: 85.94
[Train] Epoch: 1 [30528/620022]    Loss: 0.008697   Batch Acc: 76.56
[Train] Epoch: 1 [30592/620022]    Loss: 0.009048   Batch Acc: 84.38
[Train] Epoch: 1 [30656/620022]    Loss: 0.008087   Batch Acc: 76.56
[Train] Epoch: 1 [30720/620022]    Loss: 0.008362   Batch Acc: 75.00
[Train] Epoch: 1 [30784/620022]    Loss: 0.009161   Batch Acc: 82.81
[Train] Epoch: 1 [30848/620022]    Loss: 0.009517   Batch Acc: 76.56
[Train] Epoch: 1 [30912/620022]    Loss: 0.008859   Batch Acc: 75.00
[Train] Epoch: 1 [30976/620022]    Loss: 0.010469   Batch Acc: 73.44
[Train] Epoch: 1 [31040/620022]    Loss: 0.011023   Batch Acc: 75.00
[Train] Epoch: 1 [31104/620022]    Loss: 0.008445   Batch Acc: 78.12
[Train] Epoch: 1 [31168/620022]    Loss: 0.007451   Batch Acc: 81.25
[Train] Epoch: 1 [31232/620022]    Loss: 0.009204   Batch Acc: 78.12
[Train] Epoch: 1 [31296/620022]    Loss: 0.008867   Batch Acc: 76.56
[Train] Epoch: 1 [31360/620022]    Loss: 0.009711   Batch Acc: 75.00
[Train] Epoch: 1 [31424/620022]    Loss: 0.008929   Batch Acc: 71.88
[Train] Epoch: 1 [31488/620022]    Loss: 0.009309   Batch Acc: 73.44
[Train] Epoch: 1 [31552/620022]    Loss: 0.007201   Batch Acc: 87.50
[Train] Epoch: 1 [31616/620022]    Loss: 0.009244   Batch Acc: 73.44
[Train] Epoch: 1 [31680/620022]    Loss: 0.008413   Batch Acc: 76.56
[Train] Epoch: 1 [31744/620022]    Loss: 0.009798   Batch Acc: 71.88
[Train] Epoch: 1 [31808/620022]    Loss: 0.008031   Batch Acc: 81.25
[Train] Epoch: 1 [31872/620022]    Loss: 0.010536   Batch Acc: 71.88
[Train] Epoch: 1 [31936/620022]    Loss: 0.007879   Batch Acc: 78.12
[Train] Epoch: 1 [32000/620022]    Loss: 0.008764   Batch Acc: 71.88
[Train] Epoch: 1 [32064/620022]    Loss: 0.007733   Batch Acc: 79.69
[Train] Epoch: 1 [32128/620022]    Loss: 0.010051   Batch Acc: 68.75
[Train] Epoch: 1 [32192/620022]    Loss: 0.008053   Batch Acc: 79.69
[Train] Epoch: 1 [32256/620022]    Loss: 0.008988   Batch Acc: 75.00
[Train] Epoch: 1 [32320/620022]    Loss: 0.008222   Batch Acc: 82.81
[Train] Epoch: 1 [32384/620022]    Loss: 0.008320   Batch Acc: 75.00
[Train] Epoch: 1 [32448/620022]    Loss: 0.008244   Batch Acc: 78.12
[Train] Epoch: 1 [32512/620022]    Loss: 0.007106   Batch Acc: 84.38
[Train] Epoch: 1 [32576/620022]    Loss: 0.010938   Batch Acc: 65.62
[Train] Epoch: 1 [32640/620022]    Loss: 0.009533   Batch Acc: 75.00
[Train] Epoch: 1 [32704/620022]    Loss: 0.006993   Batch Acc: 85.94
[Train] Epoch: 1 [32768/620022]    Loss: 0.007490   Batch Acc: 84.38
[Train] Epoch: 1 [32832/620022]    Loss: 0.009543   Batch Acc: 78.12
[Train] Epoch: 1 [32896/620022]    Loss: 0.007463   Batch Acc: 81.25
[Train] Epoch: 1 [32960/620022]    Loss: 0.010266   Batch Acc: 71.88
[Train] Epoch: 1 [33024/620022]    Loss: 0.010607   Batch Acc: 75.00
[Train] Epoch: 1 [33088/620022]    Loss: 0.008989   Batch Acc: 79.69
[Train] Epoch: 1 [33152/620022]    Loss: 0.009379   Batch Acc: 76.56
[Train] Epoch: 1 [33216/620022]    Loss: 0.009347   Batch Acc: 71.88
[Train] Epoch: 1 [33280/620022]    Loss: 0.006129   Batch Acc: 84.38
[Train] Epoch: 1 [33344/620022]    Loss: 0.006343   Batch Acc: 85.94
[Train] Epoch: 1 [33408/620022]    Loss: 0.009630   Batch Acc: 76.56
[Train] Epoch: 1 [33472/620022]    Loss: 0.008110   Batch Acc: 75.00
[Train] Epoch: 1 [33536/620022]    Loss: 0.007743   Batch Acc: 79.69
[Train] Epoch: 1 [33600/620022]    Loss: 0.011132   Batch Acc: 75.00
[Train] Epoch: 1 [33664/620022]    Loss: 0.010727   Batch Acc: 78.12
[Train] Epoch: 1 [33728/620022]    Loss: 0.008114   Batch Acc: 78.12
[Train] Epoch: 1 [33792/620022]    Loss: 0.009367   Batch Acc: 73.44
[Train] Epoch: 1 [33856/620022]    Loss: 0.008230   Batch Acc: 79.69
[Train] Epoch: 1 [33920/620022]    Loss: 0.008043   Batch Acc: 78.12
[Train] Epoch: 1 [33984/620022]    Loss: 0.008722   Batch Acc: 78.12
[Train] Epoch: 1 [34048/620022]    Loss: 0.010828   Batch Acc: 70.31
[Train] Epoch: 1 [34112/620022]    Loss: 0.006707   Batch Acc: 85.94
[Train] Epoch: 1 [34176/620022]    Loss: 0.007402   Batch Acc: 85.94
[Train] Epoch: 1 [34240/620022]    Loss: 0.008600   Batch Acc: 73.44
[Train] Epoch: 1 [34304/620022]    Loss: 0.008522   Batch Acc: 75.00
[Train] Epoch: 1 [34368/620022]    Loss: 0.010150   Batch Acc: 71.88
[Train] Epoch: 1 [34432/620022]    Loss: 0.010185   Batch Acc: 75.00
[Train] Epoch: 1 [34496/620022]    Loss: 0.012177   Batch Acc: 60.94
[Train] Epoch: 1 [34560/620022]    Loss: 0.008121   Batch Acc: 79.69
[Train] Epoch: 1 [34624/620022]    Loss: 0.007647   Batch Acc: 82.81
[Train] Epoch: 1 [34688/620022]    Loss: 0.009389   Batch Acc: 76.56
[Train] Epoch: 1 [34752/620022]    Loss: 0.008792   Batch Acc: 76.56
[Train] Epoch: 1 [34816/620022]    Loss: 0.007555   Batch Acc: 85.94
[Train] Epoch: 1 [34880/620022]    Loss: 0.009018   Batch Acc: 71.88
[Train] Epoch: 1 [34944/620022]    Loss: 0.008825   Batch Acc: 71.88
[Train] Epoch: 1 [35008/620022]    Loss: 0.009090   Batch Acc: 75.00
[Train] Epoch: 1 [35072/620022]    Loss: 0.007009   Batch Acc: 81.25
[Train] Epoch: 1 [35136/620022]    Loss: 0.009799   Batch Acc: 75.00
[Train] Epoch: 1 [35200/620022]    Loss: 0.007486   Batch Acc: 82.81
[Train] Epoch: 1 [35264/620022]    Loss: 0.011589   Batch Acc: 67.19
[Train] Epoch: 1 [35328/620022]    Loss: 0.011180   Batch Acc: 70.31
[Train] Epoch: 1 [35392/620022]    Loss: 0.007695   Batch Acc: 82.81
[Train] Epoch: 1 [35456/620022]    Loss: 0.011036   Batch Acc: 70.31
[Train] Epoch: 1 [35520/620022]    Loss: 0.009296   Batch Acc: 76.56
[Train] Epoch: 1 [35584/620022]    Loss: 0.008014   Batch Acc: 78.12
[Train] Epoch: 1 [35648/620022]    Loss: 0.008004   Batch Acc: 78.12
[Train] Epoch: 1 [35712/620022]    Loss: 0.007662   Batch Acc: 78.12
[Train] Epoch: 1 [35776/620022]    Loss: 0.009148   Batch Acc: 75.00
[Train] Epoch: 1 [35840/620022]    Loss: 0.009208   Batch Acc: 71.88
[Train] Epoch: 1 [35904/620022]    Loss: 0.006552   Batch Acc: 87.50
[Train] Epoch: 1 [35968/620022]    Loss: 0.007821   Batch Acc: 78.12
[Train] Epoch: 1 [36032/620022]    Loss: 0.009051   Batch Acc: 81.25
[Train] Epoch: 1 [36096/620022]    Loss: 0.008755   Batch Acc: 78.12
[Train] Epoch: 1 [36160/620022]    Loss: 0.009341   Batch Acc: 67.19
[Train] Epoch: 1 [36224/620022]    Loss: 0.008729   Batch Acc: 78.12
[Train] Epoch: 1 [36288/620022]    Loss: 0.007934   Batch Acc: 81.25
[Train] Epoch: 1 [36352/620022]    Loss: 0.009012   Batch Acc: 78.12
[Train] Epoch: 1 [36416/620022]    Loss: 0.008392   Batch Acc: 84.38
[Train] Epoch: 1 [36480/620022]    Loss: 0.007630   Batch Acc: 81.25
[Train] Epoch: 1 [36544/620022]    Loss: 0.008232   Batch Acc: 78.12
[Train] Epoch: 1 [36608/620022]    Loss: 0.008405   Batch Acc: 79.69
[Train] Epoch: 1 [36672/620022]    Loss: 0.010413   Batch Acc: 68.75
[Train] Epoch: 1 [36736/620022]    Loss: 0.008157   Batch Acc: 82.81
[Train] Epoch: 1 [36800/620022]    Loss: 0.008997   Batch Acc: 76.56
[Train] Epoch: 1 [36864/620022]    Loss: 0.007569   Batch Acc: 82.81
[Train] Epoch: 1 [36928/620022]    Loss: 0.007907   Batch Acc: 75.00
[Train] Epoch: 1 [36992/620022]    Loss: 0.008726   Batch Acc: 73.44
[Train] Epoch: 1 [37056/620022]    Loss: 0.009868   Batch Acc: 70.31
[Train] Epoch: 1 [37120/620022]    Loss: 0.008893   Batch Acc: 73.44
[Train] Epoch: 1 [37184/620022]    Loss: 0.008692   Batch Acc: 76.56
[Train] Epoch: 1 [37248/620022]    Loss: 0.008146   Batch Acc: 76.56
[Train] Epoch: 1 [37312/620022]    Loss: 0.008456   Batch Acc: 78.12
[Train] Epoch: 1 [37376/620022]    Loss: 0.009929   Batch Acc: 75.00
[Train] Epoch: 1 [37440/620022]    Loss: 0.007821   Batch Acc: 78.12
[Train] Epoch: 1 [37504/620022]    Loss: 0.010733   Batch Acc: 68.75
[Train] Epoch: 1 [37568/620022]    Loss: 0.008110   Batch Acc: 78.12
[Train] Epoch: 1 [37632/620022]    Loss: 0.007741   Batch Acc: 81.25
[Train] Epoch: 1 [37696/620022]    Loss: 0.009632   Batch Acc: 68.75
[Train] Epoch: 1 [37760/620022]    Loss: 0.008954   Batch Acc: 75.00
[Train] Epoch: 1 [37824/620022]    Loss: 0.009729   Batch Acc: 73.44
[Train] Epoch: 1 [37888/620022]    Loss: 0.007886   Batch Acc: 81.25
[Train] Epoch: 1 [37952/620022]    Loss: 0.007999   Batch Acc: 82.81
[Train] Epoch: 1 [38016/620022]    Loss: 0.009520   Batch Acc: 78.12
[Train] Epoch: 1 [38080/620022]    Loss: 0.010558   Batch Acc: 73.44
[Train] Epoch: 1 [38144/620022]    Loss: 0.009160   Batch Acc: 73.44
[Train] Epoch: 1 [38208/620022]    Loss: 0.010746   Batch Acc: 73.44
[Train] Epoch: 1 [38272/620022]    Loss: 0.008417   Batch Acc: 81.25
[Train] Epoch: 1 [38336/620022]    Loss: 0.007001   Batch Acc: 84.38
[Train] Epoch: 1 [38400/620022]    Loss: 0.007238   Batch Acc: 78.12
[Train] Epoch: 1 [38464/620022]    Loss: 0.010282   Batch Acc: 68.75
[Train] Epoch: 1 [38528/620022]    Loss: 0.008734   Batch Acc: 76.56
[Train] Epoch: 1 [38592/620022]    Loss: 0.008279   Batch Acc: 81.25
[Train] Epoch: 1 [38656/620022]    Loss: 0.010007   Batch Acc: 76.56
[Train] Epoch: 1 [38720/620022]    Loss: 0.008165   Batch Acc: 81.25
[Train] Epoch: 1 [38784/620022]    Loss: 0.008842   Batch Acc: 76.56
[Train] Epoch: 1 [38848/620022]    Loss: 0.009258   Batch Acc: 75.00
[Train] Epoch: 1 [38912/620022]    Loss: 0.007928   Batch Acc: 82.81
[Train] Epoch: 1 [38976/620022]    Loss: 0.009208   Batch Acc: 78.12
[Train] Epoch: 1 [39040/620022]    Loss: 0.009422   Batch Acc: 68.75
[Train] Epoch: 1 [39104/620022]    Loss: 0.009199   Batch Acc: 78.12
[Train] Epoch: 1 [39168/620022]    Loss: 0.008987   Batch Acc: 78.12
[Train] Epoch: 1 [39232/620022]    Loss: 0.007421   Batch Acc: 79.69
[Train] Epoch: 1 [39296/620022]    Loss: 0.007577   Batch Acc: 79.69
[Train] Epoch: 1 [39360/620022]    Loss: 0.009462   Batch Acc: 75.00
[Train] Epoch: 1 [39424/620022]    Loss: 0.009189   Batch Acc: 75.00
[Train] Epoch: 1 [39488/620022]    Loss: 0.008726   Batch Acc: 78.12
[Train] Epoch: 1 [39552/620022]    Loss: 0.007886   Batch Acc: 78.12
[Train] Epoch: 1 [39616/620022]    Loss: 0.009262   Batch Acc: 68.75
[Train] Epoch: 1 [39680/620022]    Loss: 0.011693   Batch Acc: 64.06
[Train] Epoch: 1 [39744/620022]    Loss: 0.006900   Batch Acc: 79.69
[Train] Epoch: 1 [39808/620022]    Loss: 0.007249   Batch Acc: 81.25
[Train] Epoch: 1 [39872/620022]    Loss: 0.009430   Batch Acc: 71.88
[Train] Epoch: 1 [39936/620022]    Loss: 0.008603   Batch Acc: 76.56
[Train] Epoch: 1 [40000/620022]    Loss: 0.008848   Batch Acc: 78.12
[Train] Epoch: 1 [40064/620022]    Loss: 0.010041   Batch Acc: 75.00
[Train] Epoch: 1 [40128/620022]    Loss: 0.009866   Batch Acc: 78.12
[Train] Epoch: 1 [40192/620022]    Loss: 0.011413   Batch Acc: 68.75
[Train] Epoch: 1 [40256/620022]    Loss: 0.008159   Batch Acc: 79.69
[Train] Epoch: 1 [40320/620022]    Loss: 0.007338   Batch Acc: 81.25
[Train] Epoch: 1 [40384/620022]    Loss: 0.007390   Batch Acc: 79.69
[Train] Epoch: 1 [40448/620022]    Loss: 0.008438   Batch Acc: 78.12
[Train] Epoch: 1 [40512/620022]    Loss: 0.009971   Batch Acc: 71.88
[Train] Epoch: 1 [40576/620022]    Loss: 0.008534   Batch Acc: 75.00
[Train] Epoch: 1 [40640/620022]    Loss: 0.009977   Batch Acc: 73.44
[Train] Epoch: 1 [40704/620022]    Loss: 0.009939   Batch Acc: 71.88
[Train] Epoch: 1 [40768/620022]    Loss: 0.007011   Batch Acc: 87.50
[Train] Epoch: 1 [40832/620022]    Loss: 0.007898   Batch Acc: 79.69
[Train] Epoch: 1 [40896/620022]    Loss: 0.007825   Batch Acc: 81.25
[Train] Epoch: 1 [40960/620022]    Loss: 0.007094   Batch Acc: 82.81
[Train] Epoch: 1 [41024/620022]    Loss: 0.009310   Batch Acc: 78.12
[Train] Epoch: 1 [41088/620022]    Loss: 0.008337   Batch Acc: 75.00
[Train] Epoch: 1 [41152/620022]    Loss: 0.010865   Batch Acc: 76.56
[Train] Epoch: 1 [41216/620022]    Loss: 0.008512   Batch Acc: 75.00
[Train] Epoch: 1 [41280/620022]    Loss: 0.008928   Batch Acc: 78.12
[Train] Epoch: 1 [41344/620022]    Loss: 0.007613   Batch Acc: 79.69
[Train] Epoch: 1 [41408/620022]    Loss: 0.009250   Batch Acc: 81.25
[Train] Epoch: 1 [41472/620022]    Loss: 0.008668   Batch Acc: 79.69
[Train] Epoch: 1 [41536/620022]    Loss: 0.007990   Batch Acc: 84.38
[Train] Epoch: 1 [41600/620022]    Loss: 0.008839   Batch Acc: 81.25
[Train] Epoch: 1 [41664/620022]    Loss: 0.008227   Batch Acc: 81.25
[Train] Epoch: 1 [41728/620022]    Loss: 0.009505   Batch Acc: 73.44
[Train] Epoch: 1 [41792/620022]    Loss: 0.008580   Batch Acc: 79.69
[Train] Epoch: 1 [41856/620022]    Loss: 0.007923   Batch Acc: 84.38
[Train] Epoch: 1 [41920/620022]    Loss: 0.007956   Batch Acc: 76.56
[Train] Epoch: 1 [41984/620022]    Loss: 0.009715   Batch Acc: 71.88
[Train] Epoch: 1 [42048/620022]    Loss: 0.007525   Batch Acc: 81.25
[Train] Epoch: 1 [42112/620022]    Loss: 0.010367   Batch Acc: 68.75
[Train] Epoch: 1 [42176/620022]    Loss: 0.009505   Batch Acc: 75.00
[Train] Epoch: 1 [42240/620022]    Loss: 0.007403   Batch Acc: 85.94
[Train] Epoch: 1 [42304/620022]    Loss: 0.008918   Batch Acc: 78.12
[Train] Epoch: 1 [42368/620022]    Loss: 0.008745   Batch Acc: 75.00
[Train] Epoch: 1 [42432/620022]    Loss: 0.013588   Batch Acc: 67.19
[Train] Epoch: 1 [42496/620022]    Loss: 0.007145   Batch Acc: 81.25
[Train] Epoch: 1 [42560/620022]    Loss: 0.008378   Batch Acc: 78.12
[Train] Epoch: 1 [42624/620022]    Loss: 0.008855   Batch Acc: 81.25
[Train] Epoch: 1 [42688/620022]    Loss: 0.007574   Batch Acc: 79.69
[Train] Epoch: 1 [42752/620022]    Loss: 0.009113   Batch Acc: 75.00
[Train] Epoch: 1 [42816/620022]    Loss: 0.007090   Batch Acc: 82.81
[Train] Epoch: 1 [42880/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 1 [42944/620022]    Loss: 0.009661   Batch Acc: 75.00
[Train] Epoch: 1 [43008/620022]    Loss: 0.008894   Batch Acc: 78.12
[Train] Epoch: 1 [43072/620022]    Loss: 0.007789   Batch Acc: 76.56
[Train] Epoch: 1 [43136/620022]    Loss: 0.008901   Batch Acc: 75.00
[Train] Epoch: 1 [43200/620022]    Loss: 0.010485   Batch Acc: 73.44
[Train] Epoch: 1 [43264/620022]    Loss: 0.007249   Batch Acc: 82.81
[Train] Epoch: 1 [43328/620022]    Loss: 0.008870   Batch Acc: 76.56
[Train] Epoch: 1 [43392/620022]    Loss: 0.009550   Batch Acc: 73.44
[Train] Epoch: 1 [43456/620022]    Loss: 0.008787   Batch Acc: 71.88
[Train] Epoch: 1 [43520/620022]    Loss: 0.008661   Batch Acc: 78.12
[Train] Epoch: 1 [43584/620022]    Loss: 0.008515   Batch Acc: 79.69
[Train] Epoch: 1 [43648/620022]    Loss: 0.008824   Batch Acc: 68.75
[Train] Epoch: 1 [43712/620022]    Loss: 0.006862   Batch Acc: 85.94
[Train] Epoch: 1 [43776/620022]    Loss: 0.007756   Batch Acc: 79.69
[Train] Epoch: 1 [43840/620022]    Loss: 0.009837   Batch Acc: 67.19
[Train] Epoch: 1 [43904/620022]    Loss: 0.006914   Batch Acc: 82.81
[Train] Epoch: 1 [43968/620022]    Loss: 0.010881   Batch Acc: 71.88
[Train] Epoch: 1 [44032/620022]    Loss: 0.008205   Batch Acc: 76.56
[Train] Epoch: 1 [44096/620022]    Loss: 0.008942   Batch Acc: 76.56
[Train] Epoch: 1 [44160/620022]    Loss: 0.006385   Batch Acc: 85.94
[Train] Epoch: 1 [44224/620022]    Loss: 0.008228   Batch Acc: 78.12
[Train] Epoch: 1 [44288/620022]    Loss: 0.007959   Batch Acc: 79.69
[Train] Epoch: 1 [44352/620022]    Loss: 0.007149   Batch Acc: 82.81
[Train] Epoch: 1 [44416/620022]    Loss: 0.007702   Batch Acc: 78.12
[Train] Epoch: 1 [44480/620022]    Loss: 0.010177   Batch Acc: 70.31
[Train] Epoch: 1 [44544/620022]    Loss: 0.007460   Batch Acc: 81.25
[Train] Epoch: 1 [44608/620022]    Loss: 0.008441   Batch Acc: 79.69
[Train] Epoch: 1 [44672/620022]    Loss: 0.008238   Batch Acc: 78.12
[Train] Epoch: 1 [44736/620022]    Loss: 0.007058   Batch Acc: 85.94
[Train] Epoch: 1 [44800/620022]    Loss: 0.013554   Batch Acc: 71.88
[Train] Epoch: 1 [44864/620022]    Loss: 0.009055   Batch Acc: 71.88
[Train] Epoch: 1 [44928/620022]    Loss: 0.007048   Batch Acc: 87.50
[Train] Epoch: 1 [44992/620022]    Loss: 0.010377   Batch Acc: 71.88
[Train] Epoch: 1 [45056/620022]    Loss: 0.006938   Batch Acc: 82.81
[Train] Epoch: 1 [45120/620022]    Loss: 0.008921   Batch Acc: 75.00
[Train] Epoch: 1 [45184/620022]    Loss: 0.009080   Batch Acc: 78.12
[Train] Epoch: 1 [45248/620022]    Loss: 0.010184   Batch Acc: 68.75
[Train] Epoch: 1 [45312/620022]    Loss: 0.009804   Batch Acc: 73.44
[Train] Epoch: 1 [45376/620022]    Loss: 0.005696   Batch Acc: 89.06
[Train] Epoch: 1 [45440/620022]    Loss: 0.009723   Batch Acc: 75.00
[Train] Epoch: 1 [45504/620022]    Loss: 0.010452   Batch Acc: 68.75
[Train] Epoch: 1 [45568/620022]    Loss: 0.008697   Batch Acc: 84.38
[Train] Epoch: 1 [45632/620022]    Loss: 0.009175   Batch Acc: 76.56
[Train] Epoch: 1 [45696/620022]    Loss: 0.005695   Batch Acc: 84.38
[Train] Epoch: 1 [45760/620022]    Loss: 0.008286   Batch Acc: 81.25
[Train] Epoch: 1 [45824/620022]    Loss: 0.007432   Batch Acc: 82.81
[Train] Epoch: 1 [45888/620022]    Loss: 0.008583   Batch Acc: 79.69
[Train] Epoch: 1 [45952/620022]    Loss: 0.008994   Batch Acc: 79.69
[Train] Epoch: 1 [46016/620022]    Loss: 0.010750   Batch Acc: 65.62
[Train] Epoch: 1 [46080/620022]    Loss: 0.007238   Batch Acc: 82.81
[Train] Epoch: 1 [46144/620022]    Loss: 0.010924   Batch Acc: 76.56
[Train] Epoch: 1 [46208/620022]    Loss: 0.009653   Batch Acc: 76.56
[Train] Epoch: 1 [46272/620022]    Loss: 0.007924   Batch Acc: 81.25
[Train] Epoch: 1 [46336/620022]    Loss: 0.009501   Batch Acc: 67.19
[Train] Epoch: 1 [46400/620022]    Loss: 0.010885   Batch Acc: 75.00
[Train] Epoch: 1 [46464/620022]    Loss: 0.010450   Batch Acc: 71.88
[Train] Epoch: 1 [46528/620022]    Loss: 0.008408   Batch Acc: 78.12
[Train] Epoch: 1 [46592/620022]    Loss: 0.010341   Batch Acc: 71.88
[Train] Epoch: 1 [46656/620022]    Loss: 0.012708   Batch Acc: 65.62
[Train] Epoch: 1 [46720/620022]    Loss: 0.006486   Batch Acc: 87.50
[Train] Epoch: 1 [46784/620022]    Loss: 0.008261   Batch Acc: 81.25
[Train] Epoch: 1 [46848/620022]    Loss: 0.007716   Batch Acc: 84.38
[Train] Epoch: 1 [46912/620022]    Loss: 0.007569   Batch Acc: 84.38
[Train] Epoch: 1 [46976/620022]    Loss: 0.010740   Batch Acc: 67.19
[Train] Epoch: 1 [47040/620022]    Loss: 0.007835   Batch Acc: 81.25
[Train] Epoch: 1 [47104/620022]    Loss: 0.009848   Batch Acc: 71.88
[Train] Epoch: 1 [47168/620022]    Loss: 0.010093   Batch Acc: 70.31
[Train] Epoch: 1 [47232/620022]    Loss: 0.008194   Batch Acc: 81.25
[Train] Epoch: 1 [47296/620022]    Loss: 0.010943   Batch Acc: 70.31
[Train] Epoch: 1 [47360/620022]    Loss: 0.006775   Batch Acc: 85.94
[Train] Epoch: 1 [47424/620022]    Loss: 0.009210   Batch Acc: 81.25
[Train] Epoch: 1 [47488/620022]    Loss: 0.009492   Batch Acc: 71.88
[Train] Epoch: 1 [47552/620022]    Loss: 0.008495   Batch Acc: 76.56
[Train] Epoch: 1 [47616/620022]    Loss: 0.009217   Batch Acc: 79.69
[Train] Epoch: 1 [47680/620022]    Loss: 0.008730   Batch Acc: 82.81
[Train] Epoch: 1 [47744/620022]    Loss: 0.010105   Batch Acc: 71.88
[Train] Epoch: 1 [47808/620022]    Loss: 0.007946   Batch Acc: 78.12
[Train] Epoch: 1 [47872/620022]    Loss: 0.008326   Batch Acc: 81.25
[Train] Epoch: 1 [47936/620022]    Loss: 0.007195   Batch Acc: 82.81
[Train] Epoch: 1 [48000/620022]    Loss: 0.008364   Batch Acc: 78.12
[Train] Epoch: 1 [48064/620022]    Loss: 0.009130   Batch Acc: 76.56
[Train] Epoch: 1 [48128/620022]    Loss: 0.009630   Batch Acc: 75.00
[Train] Epoch: 1 [48192/620022]    Loss: 0.010613   Batch Acc: 70.31
[Train] Epoch: 1 [48256/620022]    Loss: 0.009251   Batch Acc: 75.00
[Train] Epoch: 1 [48320/620022]    Loss: 0.012913   Batch Acc: 68.75
[Train] Epoch: 1 [48384/620022]    Loss: 0.007146   Batch Acc: 82.81
[Train] Epoch: 1 [48448/620022]    Loss: 0.009785   Batch Acc: 70.31
[Train] Epoch: 1 [48512/620022]    Loss: 0.010078   Batch Acc: 75.00
[Train] Epoch: 1 [48576/620022]    Loss: 0.006352   Batch Acc: 87.50
[Train] Epoch: 1 [48640/620022]    Loss: 0.006425   Batch Acc: 85.94
[Train] Epoch: 1 [48704/620022]    Loss: 0.007607   Batch Acc: 76.56
[Train] Epoch: 1 [48768/620022]    Loss: 0.008985   Batch Acc: 78.12
[Train] Epoch: 1 [48832/620022]    Loss: 0.007357   Batch Acc: 81.25
[Train] Epoch: 1 [48896/620022]    Loss: 0.006106   Batch Acc: 85.94
[Train] Epoch: 1 [48960/620022]    Loss: 0.008477   Batch Acc: 84.38
[Train] Epoch: 1 [49024/620022]    Loss: 0.010122   Batch Acc: 73.44
[Train] Epoch: 1 [49088/620022]    Loss: 0.010234   Batch Acc: 67.19
[Train] Epoch: 1 [49152/620022]    Loss: 0.007533   Batch Acc: 81.25
[Train] Epoch: 1 [49216/620022]    Loss: 0.008006   Batch Acc: 81.25
[Train] Epoch: 1 [49280/620022]    Loss: 0.007545   Batch Acc: 81.25
[Train] Epoch: 1 [49344/620022]    Loss: 0.009585   Batch Acc: 78.12
[Train] Epoch: 1 [49408/620022]    Loss: 0.007889   Batch Acc: 81.25
[Train] Epoch: 1 [49472/620022]    Loss: 0.008707   Batch Acc: 81.25
[Train] Epoch: 1 [49536/620022]    Loss: 0.010303   Batch Acc: 73.44
[Train] Epoch: 1 [49600/620022]    Loss: 0.006793   Batch Acc: 84.38
[Train] Epoch: 1 [49664/620022]    Loss: 0.010965   Batch Acc: 71.88
[Train] Epoch: 1 [49728/620022]    Loss: 0.009027   Batch Acc: 75.00
[Train] Epoch: 1 [49792/620022]    Loss: 0.007713   Batch Acc: 82.81
[Train] Epoch: 1 [49856/620022]    Loss: 0.008032   Batch Acc: 78.12
[Train] Epoch: 1 [49920/620022]    Loss: 0.009179   Batch Acc: 65.62
[Train] Epoch: 1 [49984/620022]    Loss: 0.008651   Batch Acc: 79.69
[Train] Epoch: 1 [50048/620022]    Loss: 0.009823   Batch Acc: 78.12
[Train] Epoch: 1 [50112/620022]    Loss: 0.009724   Batch Acc: 73.44
[Train] Epoch: 1 [50176/620022]    Loss: 0.009290   Batch Acc: 78.12
[Train] Epoch: 1 [50240/620022]    Loss: 0.010463   Batch Acc: 67.19
[Train] Epoch: 1 [50304/620022]    Loss: 0.008721   Batch Acc: 79.69
[Train] Epoch: 1 [50368/620022]    Loss: 0.010222   Batch Acc: 76.56
[Train] Epoch: 1 [50432/620022]    Loss: 0.010383   Batch Acc: 76.56
[Train] Epoch: 1 [50496/620022]    Loss: 0.008822   Batch Acc: 79.69
[Train] Epoch: 1 [50560/620022]    Loss: 0.009192   Batch Acc: 71.88
[Train] Epoch: 1 [50624/620022]    Loss: 0.010374   Batch Acc: 73.44
[Train] Epoch: 1 [50688/620022]    Loss: 0.009459   Batch Acc: 73.44
[Train] Epoch: 1 [50752/620022]    Loss: 0.008686   Batch Acc: 78.12
[Train] Epoch: 1 [50816/620022]    Loss: 0.007946   Batch Acc: 84.38
[Train] Epoch: 1 [50880/620022]    Loss: 0.010719   Batch Acc: 71.88
[Train] Epoch: 1 [50944/620022]    Loss: 0.007018   Batch Acc: 81.25
[Train] Epoch: 1 [51008/620022]    Loss: 0.007545   Batch Acc: 79.69
[Train] Epoch: 1 [51072/620022]    Loss: 0.009135   Batch Acc: 78.12
[Train] Epoch: 1 [51136/620022]    Loss: 0.008753   Batch Acc: 76.56
[Train] Epoch: 1 [51200/620022]    Loss: 0.008065   Batch Acc: 87.50
[Train] Epoch: 1 [51264/620022]    Loss: 0.009087   Batch Acc: 78.12
[Train] Epoch: 1 [51328/620022]    Loss: 0.009258   Batch Acc: 78.12
[Train] Epoch: 1 [51392/620022]    Loss: 0.008382   Batch Acc: 79.69
[Train] Epoch: 1 [51456/620022]    Loss: 0.008721   Batch Acc: 81.25
[Train] Epoch: 1 [51520/620022]    Loss: 0.007652   Batch Acc: 82.81
[Train] Epoch: 1 [51584/620022]    Loss: 0.008687   Batch Acc: 81.25
[Train] Epoch: 1 [51648/620022]    Loss: 0.010432   Batch Acc: 73.44
[Train] Epoch: 1 [51712/620022]    Loss: 0.009746   Batch Acc: 70.31
[Train] Epoch: 1 [51776/620022]    Loss: 0.009162   Batch Acc: 73.44
[Train] Epoch: 1 [51840/620022]    Loss: 0.009817   Batch Acc: 71.88
[Train] Epoch: 1 [51904/620022]    Loss: 0.009501   Batch Acc: 78.12
[Train] Epoch: 1 [51968/620022]    Loss: 0.008113   Batch Acc: 81.25
[Train] Epoch: 1 [52032/620022]    Loss: 0.007261   Batch Acc: 79.69
[Train] Epoch: 1 [52096/620022]    Loss: 0.007870   Batch Acc: 76.56
[Train] Epoch: 1 [52160/620022]    Loss: 0.008303   Batch Acc: 79.69
[Train] Epoch: 1 [52224/620022]    Loss: 0.006853   Batch Acc: 84.38
[Train] Epoch: 1 [52288/620022]    Loss: 0.006519   Batch Acc: 87.50
[Train] Epoch: 1 [52352/620022]    Loss: 0.008618   Batch Acc: 73.44
[Train] Epoch: 1 [52416/620022]    Loss: 0.008582   Batch Acc: 76.56
[Train] Epoch: 1 [52480/620022]    Loss: 0.007325   Batch Acc: 84.38
[Train] Epoch: 1 [52544/620022]    Loss: 0.008915   Batch Acc: 75.00
[Train] Epoch: 1 [52608/620022]    Loss: 0.009187   Batch Acc: 76.56
[Train] Epoch: 1 [52672/620022]    Loss: 0.008762   Batch Acc: 81.25
[Train] Epoch: 1 [52736/620022]    Loss: 0.008412   Batch Acc: 76.56
[Train] Epoch: 1 [52800/620022]    Loss: 0.006626   Batch Acc: 87.50
[Train] Epoch: 1 [52864/620022]    Loss: 0.010665   Batch Acc: 70.31
[Train] Epoch: 1 [52928/620022]    Loss: 0.009677   Batch Acc: 76.56
[Train] Epoch: 1 [52992/620022]    Loss: 0.008280   Batch Acc: 76.56
[Train] Epoch: 1 [53056/620022]    Loss: 0.010581   Batch Acc: 76.56
[Train] Epoch: 1 [53120/620022]    Loss: 0.008120   Batch Acc: 78.12
[Train] Epoch: 1 [53184/620022]    Loss: 0.006526   Batch Acc: 81.25
[Train] Epoch: 1 [53248/620022]    Loss: 0.007239   Batch Acc: 85.94
[Train] Epoch: 1 [53312/620022]    Loss: 0.008328   Batch Acc: 79.69
[Train] Epoch: 1 [53376/620022]    Loss: 0.007828   Batch Acc: 81.25
[Train] Epoch: 1 [53440/620022]    Loss: 0.006585   Batch Acc: 87.50
[Train] Epoch: 1 [53504/620022]    Loss: 0.010269   Batch Acc: 70.31
[Train] Epoch: 1 [53568/620022]    Loss: 0.010119   Batch Acc: 73.44
[Train] Epoch: 1 [53632/620022]    Loss: 0.008963   Batch Acc: 79.69
[Train] Epoch: 1 [53696/620022]    Loss: 0.010747   Batch Acc: 68.75
[Train] Epoch: 1 [53760/620022]    Loss: 0.008941   Batch Acc: 79.69
[Train] Epoch: 1 [53824/620022]    Loss: 0.010229   Batch Acc: 71.88
[Train] Epoch: 1 [53888/620022]    Loss: 0.010150   Batch Acc: 76.56
[Train] Epoch: 1 [53952/620022]    Loss: 0.007152   Batch Acc: 81.25
[Train] Epoch: 1 [54016/620022]    Loss: 0.008928   Batch Acc: 70.31
[Train] Epoch: 1 [54080/620022]    Loss: 0.009139   Batch Acc: 68.75
[Train] Epoch: 1 [54144/620022]    Loss: 0.008796   Batch Acc: 79.69
[Train] Epoch: 1 [54208/620022]    Loss: 0.008009   Batch Acc: 84.38
[Train] Epoch: 1 [54272/620022]    Loss: 0.009901   Batch Acc: 73.44
[Train] Epoch: 1 [54336/620022]    Loss: 0.009251   Batch Acc: 73.44
[Train] Epoch: 1 [54400/620022]    Loss: 0.007810   Batch Acc: 78.12
[Train] Epoch: 1 [54464/620022]    Loss: 0.008804   Batch Acc: 75.00
[Train] Epoch: 1 [54528/620022]    Loss: 0.007539   Batch Acc: 78.12
[Train] Epoch: 1 [54592/620022]    Loss: 0.008472   Batch Acc: 78.12
[Train] Epoch: 1 [54656/620022]    Loss: 0.010462   Batch Acc: 78.12
[Train] Epoch: 1 [54720/620022]    Loss: 0.010897   Batch Acc: 68.75
[Train] Epoch: 1 [54784/620022]    Loss: 0.006822   Batch Acc: 84.38
[Train] Epoch: 1 [54848/620022]    Loss: 0.008197   Batch Acc: 78.12
[Train] Epoch: 1 [54912/620022]    Loss: 0.007041   Batch Acc: 84.38
[Train] Epoch: 1 [54976/620022]    Loss: 0.007265   Batch Acc: 75.00
[Train] Epoch: 1 [55040/620022]    Loss: 0.008652   Batch Acc: 73.44
[Train] Epoch: 1 [55104/620022]    Loss: 0.008248   Batch Acc: 78.12
[Train] Epoch: 1 [55168/620022]    Loss: 0.011134   Batch Acc: 70.31
[Train] Epoch: 1 [55232/620022]    Loss: 0.010402   Batch Acc: 70.31
[Train] Epoch: 1 [55296/620022]    Loss: 0.009227   Batch Acc: 78.12
[Train] Epoch: 1 [55360/620022]    Loss: 0.009372   Batch Acc: 73.44
[Train] Epoch: 1 [55424/620022]    Loss: 0.006940   Batch Acc: 82.81
[Train] Epoch: 1 [55488/620022]    Loss: 0.008584   Batch Acc: 73.44
[Train] Epoch: 1 [55552/620022]    Loss: 0.006183   Batch Acc: 89.06
[Train] Epoch: 1 [55616/620022]    Loss: 0.008434   Batch Acc: 84.38
[Train] Epoch: 1 [55680/620022]    Loss: 0.006011   Batch Acc: 85.94
[Train] Epoch: 1 [55744/620022]    Loss: 0.008448   Batch Acc: 79.69
[Train] Epoch: 1 [55808/620022]    Loss: 0.009966   Batch Acc: 73.44
[Train] Epoch: 1 [55872/620022]    Loss: 0.008973   Batch Acc: 76.56
[Train] Epoch: 1 [55936/620022]    Loss: 0.007389   Batch Acc: 81.25
[Train] Epoch: 1 [56000/620022]    Loss: 0.007967   Batch Acc: 81.25
[Train] Epoch: 1 [56064/620022]    Loss: 0.007394   Batch Acc: 81.25
[Train] Epoch: 1 [56128/620022]    Loss: 0.008955   Batch Acc: 76.56
[Train] Epoch: 1 [56192/620022]    Loss: 0.008367   Batch Acc: 75.00
[Train] Epoch: 1 [56256/620022]    Loss: 0.008583   Batch Acc: 81.25
[Train] Epoch: 1 [56320/620022]    Loss: 0.009351   Batch Acc: 71.88
[Train] Epoch: 1 [56384/620022]    Loss: 0.010991   Batch Acc: 68.75
[Train] Epoch: 1 [56448/620022]    Loss: 0.009081   Batch Acc: 82.81
[Train] Epoch: 1 [56512/620022]    Loss: 0.010119   Batch Acc: 73.44
[Train] Epoch: 1 [56576/620022]    Loss: 0.010447   Batch Acc: 73.44
[Train] Epoch: 1 [56640/620022]    Loss: 0.009432   Batch Acc: 75.00
[Train] Epoch: 1 [56704/620022]    Loss: 0.010577   Batch Acc: 71.88
[Train] Epoch: 1 [56768/620022]    Loss: 0.009333   Batch Acc: 76.56
[Train] Epoch: 1 [56832/620022]    Loss: 0.008696   Batch Acc: 78.12
[Train] Epoch: 1 [56896/620022]    Loss: 0.007043   Batch Acc: 84.38
[Train] Epoch: 1 [56960/620022]    Loss: 0.007587   Batch Acc: 82.81
[Train] Epoch: 1 [57024/620022]    Loss: 0.008377   Batch Acc: 78.12
[Train] Epoch: 1 [57088/620022]    Loss: 0.008780   Batch Acc: 78.12
[Train] Epoch: 1 [57152/620022]    Loss: 0.008718   Batch Acc: 75.00
[Train] Epoch: 1 [57216/620022]    Loss: 0.008245   Batch Acc: 78.12
[Train] Epoch: 1 [57280/620022]    Loss: 0.006369   Batch Acc: 87.50
[Train] Epoch: 1 [57344/620022]    Loss: 0.010528   Batch Acc: 68.75
[Train] Epoch: 1 [57408/620022]    Loss: 0.008722   Batch Acc: 75.00
[Train] Epoch: 1 [57472/620022]    Loss: 0.009131   Batch Acc: 75.00
[Train] Epoch: 1 [57536/620022]    Loss: 0.008509   Batch Acc: 73.44
[Train] Epoch: 1 [57600/620022]    Loss: 0.006026   Batch Acc: 84.38
[Train] Epoch: 1 [57664/620022]    Loss: 0.007805   Batch Acc: 84.38
[Train] Epoch: 1 [57728/620022]    Loss: 0.009370   Batch Acc: 76.56
[Train] Epoch: 1 [57792/620022]    Loss: 0.008170   Batch Acc: 78.12
[Train] Epoch: 1 [57856/620022]    Loss: 0.006730   Batch Acc: 81.25
[Train] Epoch: 1 [57920/620022]    Loss: 0.007302   Batch Acc: 90.62
[Train] Epoch: 1 [57984/620022]    Loss: 0.007360   Batch Acc: 78.12
[Train] Epoch: 1 [58048/620022]    Loss: 0.007085   Batch Acc: 79.69
[Train] Epoch: 1 [58112/620022]    Loss: 0.007438   Batch Acc: 82.81
[Train] Epoch: 1 [58176/620022]    Loss: 0.008963   Batch Acc: 76.56
[Train] Epoch: 1 [58240/620022]    Loss: 0.008632   Batch Acc: 79.69
[Train] Epoch: 1 [58304/620022]    Loss: 0.009363   Batch Acc: 79.69
[Train] Epoch: 1 [58368/620022]    Loss: 0.006318   Batch Acc: 82.81
[Train] Epoch: 1 [58432/620022]    Loss: 0.011140   Batch Acc: 78.12
[Train] Epoch: 1 [58496/620022]    Loss: 0.010536   Batch Acc: 73.44
[Train] Epoch: 1 [58560/620022]    Loss: 0.011567   Batch Acc: 73.44
[Train] Epoch: 1 [58624/620022]    Loss: 0.009018   Batch Acc: 73.44
[Train] Epoch: 1 [58688/620022]    Loss: 0.006316   Batch Acc: 87.50
[Train] Epoch: 1 [58752/620022]    Loss: 0.005154   Batch Acc: 93.75
[Train] Epoch: 1 [58816/620022]    Loss: 0.008950   Batch Acc: 76.56
[Train] Epoch: 1 [58880/620022]    Loss: 0.009063   Batch Acc: 75.00
[Train] Epoch: 1 [58944/620022]    Loss: 0.006800   Batch Acc: 84.38
[Train] Epoch: 1 [59008/620022]    Loss: 0.011421   Batch Acc: 73.44
[Train] Epoch: 1 [59072/620022]    Loss: 0.008392   Batch Acc: 75.00
[Train] Epoch: 1 [59136/620022]    Loss: 0.009474   Batch Acc: 79.69
[Train] Epoch: 1 [59200/620022]    Loss: 0.008564   Batch Acc: 78.12
[Train] Epoch: 1 [59264/620022]    Loss: 0.006065   Batch Acc: 89.06
[Train] Epoch: 1 [59328/620022]    Loss: 0.009895   Batch Acc: 68.75
[Train] Epoch: 1 [59392/620022]    Loss: 0.009173   Batch Acc: 75.00
[Train] Epoch: 1 [59456/620022]    Loss: 0.009239   Batch Acc: 71.88
[Train] Epoch: 1 [59520/620022]    Loss: 0.010790   Batch Acc: 67.19
[Train] Epoch: 1 [59584/620022]    Loss: 0.008864   Batch Acc: 75.00
[Train] Epoch: 1 [59648/620022]    Loss: 0.007431   Batch Acc: 82.81
[Train] Epoch: 1 [59712/620022]    Loss: 0.006341   Batch Acc: 87.50
[Train] Epoch: 1 [59776/620022]    Loss: 0.010554   Batch Acc: 71.88
[Train] Epoch: 1 [59840/620022]    Loss: 0.008662   Batch Acc: 73.44
[Train] Epoch: 1 [59904/620022]    Loss: 0.010806   Batch Acc: 68.75
[Train] Epoch: 1 [59968/620022]    Loss: 0.008841   Batch Acc: 75.00
[Train] Epoch: 1 [60032/620022]    Loss: 0.008441   Batch Acc: 78.12
[Train] Epoch: 1 [60096/620022]    Loss: 0.006727   Batch Acc: 82.81
[Train] Epoch: 1 [60160/620022]    Loss: 0.008780   Batch Acc: 75.00
[Train] Epoch: 1 [60224/620022]    Loss: 0.011592   Batch Acc: 65.62
[Train] Epoch: 1 [60288/620022]    Loss: 0.009744   Batch Acc: 75.00
[Train] Epoch: 1 [60352/620022]    Loss: 0.008316   Batch Acc: 76.56
[Train] Epoch: 1 [60416/620022]    Loss: 0.009941   Batch Acc: 68.75
[Train] Epoch: 1 [60480/620022]    Loss: 0.009301   Batch Acc: 78.12
[Train] Epoch: 1 [60544/620022]    Loss: 0.006201   Batch Acc: 84.38
[Train] Epoch: 1 [60608/620022]    Loss: 0.007881   Batch Acc: 82.81
[Train] Epoch: 1 [60672/620022]    Loss: 0.007236   Batch Acc: 84.38
[Train] Epoch: 1 [60736/620022]    Loss: 0.008765   Batch Acc: 79.69
[Train] Epoch: 1 [60800/620022]    Loss: 0.007864   Batch Acc: 82.81
[Train] Epoch: 1 [60864/620022]    Loss: 0.009435   Batch Acc: 76.56
[Train] Epoch: 1 [60928/620022]    Loss: 0.008518   Batch Acc: 78.12
[Train] Epoch: 1 [60992/620022]    Loss: 0.007412   Batch Acc: 78.12
[Train] Epoch: 1 [61056/620022]    Loss: 0.008645   Batch Acc: 78.12
[Train] Epoch: 1 [61120/620022]    Loss: 0.007079   Batch Acc: 82.81
[Train] Epoch: 1 [61184/620022]    Loss: 0.006592   Batch Acc: 90.62
[Train] Epoch: 1 [61248/620022]    Loss: 0.009315   Batch Acc: 75.00
[Train] Epoch: 1 [61312/620022]    Loss: 0.007361   Batch Acc: 81.25
[Train] Epoch: 1 [61376/620022]    Loss: 0.011165   Batch Acc: 70.31
[Train] Epoch: 1 [61440/620022]    Loss: 0.011255   Batch Acc: 60.94
[Train] Epoch: 1 [61504/620022]    Loss: 0.007326   Batch Acc: 79.69
[Train] Epoch: 1 [61568/620022]    Loss: 0.007599   Batch Acc: 81.25
[Train] Epoch: 1 [61632/620022]    Loss: 0.008393   Batch Acc: 82.81
[Train] Epoch: 1 [61696/620022]    Loss: 0.009561   Batch Acc: 75.00
[Train] Epoch: 1 [61760/620022]    Loss: 0.009322   Batch Acc: 76.56
[Train] Epoch: 1 [61824/620022]    Loss: 0.010031   Batch Acc: 67.19
[Train] Epoch: 1 [61888/620022]    Loss: 0.013110   Batch Acc: 71.88
[Train] Epoch: 1 [61952/620022]    Loss: 0.008562   Batch Acc: 78.12
[Train] Epoch: 1 [62016/620022]    Loss: 0.008447   Batch Acc: 75.00
[Train] Epoch: 1 [62080/620022]    Loss: 0.008274   Batch Acc: 76.56
[Train] Epoch: 1 [62144/620022]    Loss: 0.009693   Batch Acc: 79.69
[Train] Epoch: 1 [62208/620022]    Loss: 0.009087   Batch Acc: 79.69
[Train] Epoch: 1 [62272/620022]    Loss: 0.009264   Batch Acc: 79.69
[Train] Epoch: 1 [62336/620022]    Loss: 0.008232   Batch Acc: 84.38
[Train] Epoch: 1 [62400/620022]    Loss: 0.008018   Batch Acc: 73.44
[Train] Epoch: 1 [62464/620022]    Loss: 0.009848   Batch Acc: 75.00
[Train] Epoch: 1 [62528/620022]    Loss: 0.008734   Batch Acc: 81.25
[Train] Epoch: 1 [62592/620022]    Loss: 0.007852   Batch Acc: 82.81
[Train] Epoch: 1 [62656/620022]    Loss: 0.009697   Batch Acc: 71.88
[Train] Epoch: 1 [62720/620022]    Loss: 0.007856   Batch Acc: 82.81
[Train] Epoch: 1 [62784/620022]    Loss: 0.009755   Batch Acc: 78.12
[Train] Epoch: 1 [62848/620022]    Loss: 0.009918   Batch Acc: 73.44
[Train] Epoch: 1 [62912/620022]    Loss: 0.008769   Batch Acc: 78.12
[Train] Epoch: 1 [62976/620022]    Loss: 0.008450   Batch Acc: 79.69
[Train] Epoch: 1 [63040/620022]    Loss: 0.005731   Batch Acc: 84.38
[Train] Epoch: 1 [63104/620022]    Loss: 0.010295   Batch Acc: 67.19
[Train] Epoch: 1 [63168/620022]    Loss: 0.007361   Batch Acc: 85.94
[Train] Epoch: 1 [63232/620022]    Loss: 0.009547   Batch Acc: 70.31
[Train] Epoch: 1 [63296/620022]    Loss: 0.009712   Batch Acc: 73.44
[Train] Epoch: 1 [63360/620022]    Loss: 0.010758   Batch Acc: 64.06
[Train] Epoch: 1 [63424/620022]    Loss: 0.008022   Batch Acc: 78.12
[Train] Epoch: 1 [63488/620022]    Loss: 0.010445   Batch Acc: 76.56
[Train] Epoch: 1 [63552/620022]    Loss: 0.008486   Batch Acc: 68.75
[Train] Epoch: 1 [63616/620022]    Loss: 0.007170   Batch Acc: 85.94
[Train] Epoch: 1 [63680/620022]    Loss: 0.008368   Batch Acc: 78.12
[Train] Epoch: 1 [63744/620022]    Loss: 0.008221   Batch Acc: 78.12
[Train] Epoch: 1 [63808/620022]    Loss: 0.008047   Batch Acc: 76.56
[Train] Epoch: 1 [63872/620022]    Loss: 0.011046   Batch Acc: 70.31
[Train] Epoch: 1 [63936/620022]    Loss: 0.008128   Batch Acc: 79.69
[Train] Epoch: 1 [64000/620022]    Loss: 0.008522   Batch Acc: 78.12
[Train] Epoch: 1 [64064/620022]    Loss: 0.008565   Batch Acc: 78.12
[Train] Epoch: 1 [64128/620022]    Loss: 0.008494   Batch Acc: 79.69
[Train] Epoch: 1 [64192/620022]    Loss: 0.009904   Batch Acc: 79.69
[Train] Epoch: 1 [64256/620022]    Loss: 0.009003   Batch Acc: 76.56
[Train] Epoch: 1 [64320/620022]    Loss: 0.008284   Batch Acc: 78.12
[Train] Epoch: 1 [64384/620022]    Loss: 0.010454   Batch Acc: 70.31
[Train] Epoch: 1 [64448/620022]    Loss: 0.006484   Batch Acc: 87.50
[Train] Epoch: 1 [64512/620022]    Loss: 0.009673   Batch Acc: 75.00
[Train] Epoch: 1 [64576/620022]    Loss: 0.011203   Batch Acc: 67.19
[Train] Epoch: 1 [64640/620022]    Loss: 0.008262   Batch Acc: 78.12
[Train] Epoch: 1 [64704/620022]    Loss: 0.011196   Batch Acc: 73.44
[Train] Epoch: 1 [64768/620022]    Loss: 0.009078   Batch Acc: 76.56
[Train] Epoch: 1 [64832/620022]    Loss: 0.008321   Batch Acc: 73.44
[Train] Epoch: 1 [64896/620022]    Loss: 0.010754   Batch Acc: 68.75
[Train] Epoch: 1 [64960/620022]    Loss: 0.008119   Batch Acc: 79.69
[Train] Epoch: 1 [65024/620022]    Loss: 0.008528   Batch Acc: 78.12
[Train] Epoch: 1 [65088/620022]    Loss: 0.007935   Batch Acc: 79.69
[Train] Epoch: 1 [65152/620022]    Loss: 0.009165   Batch Acc: 78.12
[Train] Epoch: 1 [65216/620022]    Loss: 0.009987   Batch Acc: 78.12
[Train] Epoch: 1 [65280/620022]    Loss: 0.010652   Batch Acc: 70.31
[Train] Epoch: 1 [65344/620022]    Loss: 0.010862   Batch Acc: 81.25
[Train] Epoch: 1 [65408/620022]    Loss: 0.008126   Batch Acc: 75.00
[Train] Epoch: 1 [65472/620022]    Loss: 0.008400   Batch Acc: 79.69
[Train] Epoch: 1 [65536/620022]    Loss: 0.010909   Batch Acc: 64.06
[Train] Epoch: 1 [65600/620022]    Loss: 0.007601   Batch Acc: 82.81
[Train] Epoch: 1 [65664/620022]    Loss: 0.008840   Batch Acc: 81.25
[Train] Epoch: 1 [65728/620022]    Loss: 0.009536   Batch Acc: 71.88
[Train] Epoch: 1 [65792/620022]    Loss: 0.007966   Batch Acc: 81.25
[Train] Epoch: 1 [65856/620022]    Loss: 0.009933   Batch Acc: 73.44
[Train] Epoch: 1 [65920/620022]    Loss: 0.009264   Batch Acc: 76.56
[Train] Epoch: 1 [65984/620022]    Loss: 0.009093   Batch Acc: 82.81
[Train] Epoch: 1 [66048/620022]    Loss: 0.009256   Batch Acc: 71.88
[Train] Epoch: 1 [66112/620022]    Loss: 0.010131   Batch Acc: 71.88
[Train] Epoch: 1 [66176/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 1 [66240/620022]    Loss: 0.008046   Batch Acc: 79.69
[Train] Epoch: 1 [66304/620022]    Loss: 0.010695   Batch Acc: 78.12
[Train] Epoch: 1 [66368/620022]    Loss: 0.008405   Batch Acc: 78.12
[Train] Epoch: 1 [66432/620022]    Loss: 0.009835   Batch Acc: 75.00
[Train] Epoch: 1 [66496/620022]    Loss: 0.006056   Batch Acc: 85.94
[Train] Epoch: 1 [66560/620022]    Loss: 0.008498   Batch Acc: 81.25
[Train] Epoch: 1 [66624/620022]    Loss: 0.008885   Batch Acc: 79.69
[Train] Epoch: 1 [66688/620022]    Loss: 0.006596   Batch Acc: 84.38
[Train] Epoch: 1 [66752/620022]    Loss: 0.009557   Batch Acc: 81.25
[Train] Epoch: 1 [66816/620022]    Loss: 0.009682   Batch Acc: 76.56
[Train] Epoch: 1 [66880/620022]    Loss: 0.010685   Batch Acc: 73.44
[Train] Epoch: 1 [66944/620022]    Loss: 0.007886   Batch Acc: 78.12
[Train] Epoch: 1 [67008/620022]    Loss: 0.008347   Batch Acc: 84.38
[Train] Epoch: 1 [67072/620022]    Loss: 0.007007   Batch Acc: 85.94
[Train] Epoch: 1 [67136/620022]    Loss: 0.009874   Batch Acc: 75.00
[Train] Epoch: 1 [67200/620022]    Loss: 0.008690   Batch Acc: 81.25
[Train] Epoch: 1 [67264/620022]    Loss: 0.008688   Batch Acc: 73.44
[Train] Epoch: 1 [67328/620022]    Loss: 0.007302   Batch Acc: 79.69
[Train] Epoch: 1 [67392/620022]    Loss: 0.010253   Batch Acc: 70.31
[Train] Epoch: 1 [67456/620022]    Loss: 0.009920   Batch Acc: 76.56
[Train] Epoch: 1 [67520/620022]    Loss: 0.008035   Batch Acc: 81.25
[Train] Epoch: 1 [67584/620022]    Loss: 0.006710   Batch Acc: 87.50
[Train] Epoch: 1 [67648/620022]    Loss: 0.008244   Batch Acc: 79.69
[Train] Epoch: 1 [67712/620022]    Loss: 0.009352   Batch Acc: 75.00
[Train] Epoch: 1 [67776/620022]    Loss: 0.008566   Batch Acc: 70.31
[Train] Epoch: 1 [67840/620022]    Loss: 0.010632   Batch Acc: 71.88
[Train] Epoch: 1 [67904/620022]    Loss: 0.010439   Batch Acc: 70.31
[Train] Epoch: 1 [67968/620022]    Loss: 0.008620   Batch Acc: 76.56
[Train] Epoch: 1 [68032/620022]    Loss: 0.009187   Batch Acc: 75.00
[Train] Epoch: 1 [68096/620022]    Loss: 0.007956   Batch Acc: 78.12
[Train] Epoch: 1 [68160/620022]    Loss: 0.008433   Batch Acc: 81.25
[Train] Epoch: 1 [68224/620022]    Loss: 0.012328   Batch Acc: 71.88
[Train] Epoch: 1 [68288/620022]    Loss: 0.007998   Batch Acc: 79.69
[Train] Epoch: 1 [68352/620022]    Loss: 0.010342   Batch Acc: 75.00
[Train] Epoch: 1 [68416/620022]    Loss: 0.008620   Batch Acc: 78.12
[Train] Epoch: 1 [68480/620022]    Loss: 0.007580   Batch Acc: 82.81
[Train] Epoch: 1 [68544/620022]    Loss: 0.008391   Batch Acc: 75.00
[Train] Epoch: 1 [68608/620022]    Loss: 0.009235   Batch Acc: 73.44
[Train] Epoch: 1 [68672/620022]    Loss: 0.006244   Batch Acc: 81.25
[Train] Epoch: 1 [68736/620022]    Loss: 0.007713   Batch Acc: 78.12
[Train] Epoch: 1 [68800/620022]    Loss: 0.007891   Batch Acc: 81.25
[Train] Epoch: 1 [68864/620022]    Loss: 0.012304   Batch Acc: 67.19
[Train] Epoch: 1 [68928/620022]    Loss: 0.010498   Batch Acc: 73.44
[Train] Epoch: 1 [68992/620022]    Loss: 0.008932   Batch Acc: 75.00
[Train] Epoch: 1 [69056/620022]    Loss: 0.008551   Batch Acc: 76.56
[Train] Epoch: 1 [69120/620022]    Loss: 0.009733   Batch Acc: 73.44
[Train] Epoch: 1 [69184/620022]    Loss: 0.007973   Batch Acc: 84.38
[Train] Epoch: 1 [69248/620022]    Loss: 0.011487   Batch Acc: 65.62
[Train] Epoch: 1 [69312/620022]    Loss: 0.011928   Batch Acc: 68.75
[Train] Epoch: 1 [69376/620022]    Loss: 0.008326   Batch Acc: 78.12
[Train] Epoch: 1 [69440/620022]    Loss: 0.008660   Batch Acc: 71.88
[Train] Epoch: 1 [69504/620022]    Loss: 0.007616   Batch Acc: 75.00
[Train] Epoch: 1 [69568/620022]    Loss: 0.010720   Batch Acc: 76.56
[Train] Epoch: 1 [69632/620022]    Loss: 0.010316   Batch Acc: 73.44
[Train] Epoch: 1 [69696/620022]    Loss: 0.009104   Batch Acc: 73.44
[Train] Epoch: 1 [69760/620022]    Loss: 0.008778   Batch Acc: 76.56
[Train] Epoch: 1 [69824/620022]    Loss: 0.007861   Batch Acc: 81.25
[Train] Epoch: 1 [69888/620022]    Loss: 0.010144   Batch Acc: 81.25
[Train] Epoch: 1 [69952/620022]    Loss: 0.009859   Batch Acc: 76.56
[Train] Epoch: 1 [70016/620022]    Loss: 0.007842   Batch Acc: 79.69
[Train] Epoch: 1 [70080/620022]    Loss: 0.009258   Batch Acc: 78.12
[Train] Epoch: 1 [70144/620022]    Loss: 0.008365   Batch Acc: 76.56
[Train] Epoch: 1 [70208/620022]    Loss: 0.009815   Batch Acc: 73.44
[Train] Epoch: 1 [70272/620022]    Loss: 0.009463   Batch Acc: 78.12
[Train] Epoch: 1 [70336/620022]    Loss: 0.010728   Batch Acc: 73.44
[Train] Epoch: 1 [70400/620022]    Loss: 0.007869   Batch Acc: 85.94
[Train] Epoch: 1 [70464/620022]    Loss: 0.012538   Batch Acc: 64.06
[Train] Epoch: 1 [70528/620022]    Loss: 0.007612   Batch Acc: 82.81
[Train] Epoch: 1 [70592/620022]    Loss: 0.010899   Batch Acc: 70.31
[Train] Epoch: 1 [70656/620022]    Loss: 0.009723   Batch Acc: 70.31
[Train] Epoch: 1 [70720/620022]    Loss: 0.007963   Batch Acc: 87.50
[Train] Epoch: 1 [70784/620022]    Loss: 0.008602   Batch Acc: 79.69
[Train] Epoch: 1 [70848/620022]    Loss: 0.008673   Batch Acc: 73.44
[Train] Epoch: 1 [70912/620022]    Loss: 0.011551   Batch Acc: 73.44
[Train] Epoch: 1 [70976/620022]    Loss: 0.010015   Batch Acc: 65.62
[Train] Epoch: 1 [71040/620022]    Loss: 0.009575   Batch Acc: 75.00
[Train] Epoch: 1 [71104/620022]    Loss: 0.008497   Batch Acc: 76.56
[Train] Epoch: 1 [71168/620022]    Loss: 0.010002   Batch Acc: 76.56
[Train] Epoch: 1 [71232/620022]    Loss: 0.008834   Batch Acc: 82.81
[Train] Epoch: 1 [71296/620022]    Loss: 0.009926   Batch Acc: 73.44
[Train] Epoch: 1 [71360/620022]    Loss: 0.007098   Batch Acc: 82.81
[Train] Epoch: 1 [71424/620022]    Loss: 0.009112   Batch Acc: 76.56
[Train] Epoch: 1 [71488/620022]    Loss: 0.009225   Batch Acc: 73.44
[Train] Epoch: 1 [71552/620022]    Loss: 0.009389   Batch Acc: 76.56
[Train] Epoch: 1 [71616/620022]    Loss: 0.010694   Batch Acc: 73.44
[Train] Epoch: 1 [71680/620022]    Loss: 0.009298   Batch Acc: 76.56
[Train] Epoch: 1 [71744/620022]    Loss: 0.008128   Batch Acc: 84.38
[Train] Epoch: 1 [71808/620022]    Loss: 0.008552   Batch Acc: 79.69
[Train] Epoch: 1 [71872/620022]    Loss: 0.006864   Batch Acc: 81.25
[Train] Epoch: 1 [71936/620022]    Loss: 0.007735   Batch Acc: 82.81
[Train] Epoch: 1 [72000/620022]    Loss: 0.008405   Batch Acc: 81.25
[Train] Epoch: 1 [72064/620022]    Loss: 0.008732   Batch Acc: 79.69
[Train] Epoch: 1 [72128/620022]    Loss: 0.008887   Batch Acc: 78.12
[Train] Epoch: 1 [72192/620022]    Loss: 0.009505   Batch Acc: 78.12
[Train] Epoch: 1 [72256/620022]    Loss: 0.010180   Batch Acc: 76.56
[Train] Epoch: 1 [72320/620022]    Loss: 0.006759   Batch Acc: 85.94
[Train] Epoch: 1 [72384/620022]    Loss: 0.010109   Batch Acc: 71.88
[Train] Epoch: 1 [72448/620022]    Loss: 0.007491   Batch Acc: 79.69
[Train] Epoch: 1 [72512/620022]    Loss: 0.009519   Batch Acc: 71.88
[Train] Epoch: 1 [72576/620022]    Loss: 0.010778   Batch Acc: 70.31
[Train] Epoch: 1 [72640/620022]    Loss: 0.007739   Batch Acc: 79.69
[Train] Epoch: 1 [72704/620022]    Loss: 0.012902   Batch Acc: 62.50
[Train] Epoch: 1 [72768/620022]    Loss: 0.008045   Batch Acc: 81.25
[Train] Epoch: 1 [72832/620022]    Loss: 0.009645   Batch Acc: 70.31
[Train] Epoch: 1 [72896/620022]    Loss: 0.006964   Batch Acc: 81.25
[Train] Epoch: 1 [72960/620022]    Loss: 0.011653   Batch Acc: 62.50
[Train] Epoch: 1 [73024/620022]    Loss: 0.006945   Batch Acc: 79.69
[Train] Epoch: 1 [73088/620022]    Loss: 0.007100   Batch Acc: 85.94
[Train] Epoch: 1 [73152/620022]    Loss: 0.009080   Batch Acc: 79.69
[Train] Epoch: 1 [73216/620022]    Loss: 0.008306   Batch Acc: 79.69
[Train] Epoch: 1 [73280/620022]    Loss: 0.008008   Batch Acc: 81.25
[Train] Epoch: 1 [73344/620022]    Loss: 0.007268   Batch Acc: 82.81
[Train] Epoch: 1 [73408/620022]    Loss: 0.007439   Batch Acc: 82.81
[Train] Epoch: 1 [73472/620022]    Loss: 0.008204   Batch Acc: 78.12
[Train] Epoch: 1 [73536/620022]    Loss: 0.008128   Batch Acc: 79.69
[Train] Epoch: 1 [73600/620022]    Loss: 0.008754   Batch Acc: 81.25
[Train] Epoch: 1 [73664/620022]    Loss: 0.008447   Batch Acc: 78.12
[Train] Epoch: 1 [73728/620022]    Loss: 0.011255   Batch Acc: 68.75
[Train] Epoch: 1 [73792/620022]    Loss: 0.008259   Batch Acc: 73.44
[Train] Epoch: 1 [73856/620022]    Loss: 0.008305   Batch Acc: 78.12
[Train] Epoch: 1 [73920/620022]    Loss: 0.006543   Batch Acc: 84.38
[Train] Epoch: 1 [73984/620022]    Loss: 0.009630   Batch Acc: 76.56
[Train] Epoch: 1 [74048/620022]    Loss: 0.010797   Batch Acc: 73.44
[Train] Epoch: 1 [74112/620022]    Loss: 0.009791   Batch Acc: 78.12
[Train] Epoch: 1 [74176/620022]    Loss: 0.009515   Batch Acc: 78.12
[Train] Epoch: 1 [74240/620022]    Loss: 0.008415   Batch Acc: 71.88
[Train] Epoch: 1 [74304/620022]    Loss: 0.008841   Batch Acc: 76.56
[Train] Epoch: 1 [74368/620022]    Loss: 0.010585   Batch Acc: 73.44
[Train] Epoch: 1 [74432/620022]    Loss: 0.009112   Batch Acc: 78.12
[Train] Epoch: 1 [74496/620022]    Loss: 0.009074   Batch Acc: 76.56
[Train] Epoch: 1 [74560/620022]    Loss: 0.009957   Batch Acc: 78.12
[Train] Epoch: 1 [74624/620022]    Loss: 0.008079   Batch Acc: 76.56
[Train] Epoch: 1 [74688/620022]    Loss: 0.008954   Batch Acc: 81.25
[Train] Epoch: 1 [74752/620022]    Loss: 0.007281   Batch Acc: 79.69
[Train] Epoch: 1 [74816/620022]    Loss: 0.007358   Batch Acc: 89.06
[Train] Epoch: 1 [74880/620022]    Loss: 0.010347   Batch Acc: 76.56
[Train] Epoch: 1 [74944/620022]    Loss: 0.008744   Batch Acc: 75.00
[Train] Epoch: 1 [75008/620022]    Loss: 0.009744   Batch Acc: 76.56
[Train] Epoch: 1 [75072/620022]    Loss: 0.009823   Batch Acc: 76.56
[Train] Epoch: 1 [75136/620022]    Loss: 0.007514   Batch Acc: 84.38
[Train] Epoch: 1 [75200/620022]    Loss: 0.008771   Batch Acc: 75.00
[Train] Epoch: 1 [75264/620022]    Loss: 0.008127   Batch Acc: 79.69
[Train] Epoch: 1 [75328/620022]    Loss: 0.009035   Batch Acc: 75.00
[Train] Epoch: 1 [75392/620022]    Loss: 0.009223   Batch Acc: 71.88
[Train] Epoch: 1 [75456/620022]    Loss: 0.006820   Batch Acc: 84.38
[Train] Epoch: 1 [75520/620022]    Loss: 0.009517   Batch Acc: 78.12
[Train] Epoch: 1 [75584/620022]    Loss: 0.008099   Batch Acc: 82.81
[Train] Epoch: 1 [75648/620022]    Loss: 0.009840   Batch Acc: 70.31
[Train] Epoch: 1 [75712/620022]    Loss: 0.007589   Batch Acc: 79.69
[Train] Epoch: 1 [75776/620022]    Loss: 0.007900   Batch Acc: 81.25
[Train] Epoch: 1 [75840/620022]    Loss: 0.009460   Batch Acc: 75.00
[Train] Epoch: 1 [75904/620022]    Loss: 0.007532   Batch Acc: 81.25
[Train] Epoch: 1 [75968/620022]    Loss: 0.010772   Batch Acc: 75.00
[Train] Epoch: 1 [76032/620022]    Loss: 0.009059   Batch Acc: 75.00
[Train] Epoch: 1 [76096/620022]    Loss: 0.009793   Batch Acc: 75.00
[Train] Epoch: 1 [76160/620022]    Loss: 0.006847   Batch Acc: 89.06
[Train] Epoch: 1 [76224/620022]    Loss: 0.008525   Batch Acc: 76.56
[Train] Epoch: 1 [76288/620022]    Loss: 0.007520   Batch Acc: 82.81
[Train] Epoch: 1 [76352/620022]    Loss: 0.009272   Batch Acc: 76.56
[Train] Epoch: 1 [76416/620022]    Loss: 0.008450   Batch Acc: 79.69
[Train] Epoch: 1 [76480/620022]    Loss: 0.009400   Batch Acc: 75.00
[Train] Epoch: 1 [76544/620022]    Loss: 0.007326   Batch Acc: 81.25
[Train] Epoch: 1 [76608/620022]    Loss: 0.007630   Batch Acc: 82.81
[Train] Epoch: 1 [76672/620022]    Loss: 0.007474   Batch Acc: 78.12
[Train] Epoch: 1 [76736/620022]    Loss: 0.008897   Batch Acc: 76.56
[Train] Epoch: 1 [76800/620022]    Loss: 0.009500   Batch Acc: 73.44
[Train] Epoch: 1 [76864/620022]    Loss: 0.009336   Batch Acc: 71.88
[Train] Epoch: 1 [76928/620022]    Loss: 0.008432   Batch Acc: 71.88
[Train] Epoch: 1 [76992/620022]    Loss: 0.009487   Batch Acc: 76.56
[Train] Epoch: 1 [77056/620022]    Loss: 0.008770   Batch Acc: 70.31
[Train] Epoch: 1 [77120/620022]    Loss: 0.007917   Batch Acc: 78.12
[Train] Epoch: 1 [77184/620022]    Loss: 0.007276   Batch Acc: 84.38
[Train] Epoch: 1 [77248/620022]    Loss: 0.010127   Batch Acc: 68.75
[Train] Epoch: 1 [77312/620022]    Loss: 0.007879   Batch Acc: 78.12
[Train] Epoch: 1 [77376/620022]    Loss: 0.006858   Batch Acc: 82.81
[Train] Epoch: 1 [77440/620022]    Loss: 0.008694   Batch Acc: 78.12
[Train] Epoch: 1 [77504/620022]    Loss: 0.008804   Batch Acc: 73.44
[Train] Epoch: 1 [77568/620022]    Loss: 0.009350   Batch Acc: 76.56
[Train] Epoch: 1 [77632/620022]    Loss: 0.009472   Batch Acc: 73.44
[Train] Epoch: 1 [77696/620022]    Loss: 0.007994   Batch Acc: 78.12
[Train] Epoch: 1 [77760/620022]    Loss: 0.009551   Batch Acc: 73.44
[Train] Epoch: 1 [77824/620022]    Loss: 0.009384   Batch Acc: 75.00
[Train] Epoch: 1 [77888/620022]    Loss: 0.011555   Batch Acc: 70.31
[Train] Epoch: 1 [77952/620022]    Loss: 0.008601   Batch Acc: 73.44
[Train] Epoch: 1 [78016/620022]    Loss: 0.008920   Batch Acc: 81.25
[Train] Epoch: 1 [78080/620022]    Loss: 0.006555   Batch Acc: 90.62
[Train] Epoch: 1 [78144/620022]    Loss: 0.009918   Batch Acc: 76.56
[Train] Epoch: 1 [78208/620022]    Loss: 0.006795   Batch Acc: 82.81
[Train] Epoch: 1 [78272/620022]    Loss: 0.011321   Batch Acc: 68.75
[Train] Epoch: 1 [78336/620022]    Loss: 0.005836   Batch Acc: 87.50
[Train] Epoch: 1 [78400/620022]    Loss: 0.011818   Batch Acc: 67.19
[Train] Epoch: 1 [78464/620022]    Loss: 0.011011   Batch Acc: 73.44
[Train] Epoch: 1 [78528/620022]    Loss: 0.009249   Batch Acc: 67.19
[Train] Epoch: 1 [78592/620022]    Loss: 0.010596   Batch Acc: 75.00
[Train] Epoch: 1 [78656/620022]    Loss: 0.007215   Batch Acc: 82.81
[Train] Epoch: 1 [78720/620022]    Loss: 0.008293   Batch Acc: 76.56
[Train] Epoch: 1 [78784/620022]    Loss: 0.008359   Batch Acc: 78.12
[Train] Epoch: 1 [78848/620022]    Loss: 0.010495   Batch Acc: 68.75
[Train] Epoch: 1 [78912/620022]    Loss: 0.007472   Batch Acc: 78.12
[Train] Epoch: 1 [78976/620022]    Loss: 0.007605   Batch Acc: 79.69
[Train] Epoch: 1 [79040/620022]    Loss: 0.008113   Batch Acc: 78.12
[Train] Epoch: 1 [79104/620022]    Loss: 0.006588   Batch Acc: 85.94
[Train] Epoch: 1 [79168/620022]    Loss: 0.011023   Batch Acc: 65.62
[Train] Epoch: 1 [79232/620022]    Loss: 0.007981   Batch Acc: 79.69
[Train] Epoch: 1 [79296/620022]    Loss: 0.010375   Batch Acc: 78.12
[Train] Epoch: 1 [79360/620022]    Loss: 0.009386   Batch Acc: 75.00
[Train] Epoch: 1 [79424/620022]    Loss: 0.009521   Batch Acc: 76.56
[Train] Epoch: 1 [79488/620022]    Loss: 0.007394   Batch Acc: 84.38
[Train] Epoch: 1 [79552/620022]    Loss: 0.007374   Batch Acc: 85.94
[Train] Epoch: 1 [79616/620022]    Loss: 0.010254   Batch Acc: 79.69
[Train] Epoch: 1 [79680/620022]    Loss: 0.010464   Batch Acc: 68.75
[Train] Epoch: 1 [79744/620022]    Loss: 0.008976   Batch Acc: 76.56
[Train] Epoch: 1 [79808/620022]    Loss: 0.007904   Batch Acc: 81.25
[Train] Epoch: 1 [79872/620022]    Loss: 0.009592   Batch Acc: 78.12
[Train] Epoch: 1 [79936/620022]    Loss: 0.010652   Batch Acc: 70.31
[Train] Epoch: 1 [80000/620022]    Loss: 0.010631   Batch Acc: 68.75
[Train] Epoch: 1 [80064/620022]    Loss: 0.006733   Batch Acc: 84.38
[Train] Epoch: 1 [80128/620022]    Loss: 0.006174   Batch Acc: 85.94
[Train] Epoch: 1 [80192/620022]    Loss: 0.007160   Batch Acc: 81.25
[Train] Epoch: 1 [80256/620022]    Loss: 0.009456   Batch Acc: 78.12
[Train] Epoch: 1 [80320/620022]    Loss: 0.008103   Batch Acc: 82.81
[Train] Epoch: 1 [80384/620022]    Loss: 0.009028   Batch Acc: 73.44
[Train] Epoch: 1 [80448/620022]    Loss: 0.006972   Batch Acc: 81.25
[Train] Epoch: 1 [80512/620022]    Loss: 0.007980   Batch Acc: 79.69
[Train] Epoch: 1 [80576/620022]    Loss: 0.010072   Batch Acc: 70.31
[Train] Epoch: 1 [80640/620022]    Loss: 0.009448   Batch Acc: 75.00
[Train] Epoch: 1 [80704/620022]    Loss: 0.011252   Batch Acc: 65.62
[Train] Epoch: 1 [80768/620022]    Loss: 0.010078   Batch Acc: 73.44
[Train] Epoch: 1 [80832/620022]    Loss: 0.008059   Batch Acc: 81.25
[Train] Epoch: 1 [80896/620022]    Loss: 0.008048   Batch Acc: 84.38
[Train] Epoch: 1 [80960/620022]    Loss: 0.008057   Batch Acc: 81.25
[Train] Epoch: 1 [81024/620022]    Loss: 0.006162   Batch Acc: 87.50
[Train] Epoch: 1 [81088/620022]    Loss: 0.009113   Batch Acc: 79.69
[Train] Epoch: 1 [81152/620022]    Loss: 0.006918   Batch Acc: 84.38
[Train] Epoch: 1 [81216/620022]    Loss: 0.009032   Batch Acc: 71.88
[Train] Epoch: 1 [81280/620022]    Loss: 0.007853   Batch Acc: 78.12
[Train] Epoch: 1 [81344/620022]    Loss: 0.008879   Batch Acc: 81.25
[Train] Epoch: 1 [81408/620022]    Loss: 0.009548   Batch Acc: 75.00
[Train] Epoch: 1 [81472/620022]    Loss: 0.008684   Batch Acc: 76.56
[Train] Epoch: 1 [81536/620022]    Loss: 0.009473   Batch Acc: 82.81
[Train] Epoch: 1 [81600/620022]    Loss: 0.010214   Batch Acc: 75.00
[Train] Epoch: 1 [81664/620022]    Loss: 0.008738   Batch Acc: 79.69
[Train] Epoch: 1 [81728/620022]    Loss: 0.007206   Batch Acc: 85.94
[Train] Epoch: 1 [81792/620022]    Loss: 0.009284   Batch Acc: 76.56
[Train] Epoch: 1 [81856/620022]    Loss: 0.008712   Batch Acc: 76.56
[Train] Epoch: 1 [81920/620022]    Loss: 0.011935   Batch Acc: 68.75
[Train] Epoch: 1 [81984/620022]    Loss: 0.007263   Batch Acc: 79.69
[Train] Epoch: 1 [82048/620022]    Loss: 0.009426   Batch Acc: 76.56
[Train] Epoch: 1 [82112/620022]    Loss: 0.007269   Batch Acc: 84.38
[Train] Epoch: 1 [82176/620022]    Loss: 0.007986   Batch Acc: 79.69
[Train] Epoch: 1 [82240/620022]    Loss: 0.008338   Batch Acc: 79.69
[Train] Epoch: 1 [82304/620022]    Loss: 0.008960   Batch Acc: 76.56
[Train] Epoch: 1 [82368/620022]    Loss: 0.009470   Batch Acc: 79.69
[Train] Epoch: 1 [82432/620022]    Loss: 0.008967   Batch Acc: 78.12
[Train] Epoch: 1 [82496/620022]    Loss: 0.009036   Batch Acc: 76.56
[Train] Epoch: 1 [82560/620022]    Loss: 0.009326   Batch Acc: 78.12
[Train] Epoch: 1 [82624/620022]    Loss: 0.007479   Batch Acc: 84.38
[Train] Epoch: 1 [82688/620022]    Loss: 0.007637   Batch Acc: 81.25
[Train] Epoch: 1 [82752/620022]    Loss: 0.008293   Batch Acc: 76.56
[Train] Epoch: 1 [82816/620022]    Loss: 0.009631   Batch Acc: 71.88
[Train] Epoch: 1 [82880/620022]    Loss: 0.009698   Batch Acc: 73.44
[Train] Epoch: 1 [82944/620022]    Loss: 0.006689   Batch Acc: 84.38
[Train] Epoch: 1 [83008/620022]    Loss: 0.007146   Batch Acc: 82.81
[Train] Epoch: 1 [83072/620022]    Loss: 0.007621   Batch Acc: 81.25
[Train] Epoch: 1 [83136/620022]    Loss: 0.009740   Batch Acc: 79.69
[Train] Epoch: 1 [83200/620022]    Loss: 0.009422   Batch Acc: 67.19
[Train] Epoch: 1 [83264/620022]    Loss: 0.007482   Batch Acc: 84.38
[Train] Epoch: 1 [83328/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 1 [83392/620022]    Loss: 0.009029   Batch Acc: 70.31
[Train] Epoch: 1 [83456/620022]    Loss: 0.009194   Batch Acc: 76.56
[Train] Epoch: 1 [83520/620022]    Loss: 0.007687   Batch Acc: 85.94
[Train] Epoch: 1 [83584/620022]    Loss: 0.009031   Batch Acc: 78.12
[Train] Epoch: 1 [83648/620022]    Loss: 0.009198   Batch Acc: 78.12
[Train] Epoch: 1 [83712/620022]    Loss: 0.005390   Batch Acc: 90.62
[Train] Epoch: 1 [83776/620022]    Loss: 0.008312   Batch Acc: 78.12
[Train] Epoch: 1 [83840/620022]    Loss: 0.010199   Batch Acc: 75.00
[Train] Epoch: 1 [83904/620022]    Loss: 0.008647   Batch Acc: 76.56
[Train] Epoch: 1 [83968/620022]    Loss: 0.009891   Batch Acc: 68.75
[Train] Epoch: 1 [84032/620022]    Loss: 0.007149   Batch Acc: 82.81
[Train] Epoch: 1 [84096/620022]    Loss: 0.009936   Batch Acc: 73.44
[Train] Epoch: 1 [84160/620022]    Loss: 0.009649   Batch Acc: 82.81
[Train] Epoch: 1 [84224/620022]    Loss: 0.008819   Batch Acc: 75.00
[Train] Epoch: 1 [84288/620022]    Loss: 0.005646   Batch Acc: 89.06
[Train] Epoch: 1 [84352/620022]    Loss: 0.009524   Batch Acc: 76.56
[Train] Epoch: 1 [84416/620022]    Loss: 0.008574   Batch Acc: 79.69
[Train] Epoch: 1 [84480/620022]    Loss: 0.009539   Batch Acc: 75.00
[Train] Epoch: 1 [84544/620022]    Loss: 0.007879   Batch Acc: 81.25
[Train] Epoch: 1 [84608/620022]    Loss: 0.007522   Batch Acc: 85.94
[Train] Epoch: 1 [84672/620022]    Loss: 0.008319   Batch Acc: 79.69
[Train] Epoch: 1 [84736/620022]    Loss: 0.008513   Batch Acc: 75.00
[Train] Epoch: 1 [84800/620022]    Loss: 0.007617   Batch Acc: 76.56
[Train] Epoch: 1 [84864/620022]    Loss: 0.009701   Batch Acc: 76.56
[Train] Epoch: 1 [84928/620022]    Loss: 0.007752   Batch Acc: 79.69
[Train] Epoch: 1 [84992/620022]    Loss: 0.007087   Batch Acc: 85.94
[Train] Epoch: 1 [85056/620022]    Loss: 0.009489   Batch Acc: 73.44
[Train] Epoch: 1 [85120/620022]    Loss: 0.008326   Batch Acc: 78.12
[Train] Epoch: 1 [85184/620022]    Loss: 0.007024   Batch Acc: 79.69
[Train] Epoch: 1 [85248/620022]    Loss: 0.007868   Batch Acc: 79.69
[Train] Epoch: 1 [85312/620022]    Loss: 0.009464   Batch Acc: 73.44
[Train] Epoch: 1 [85376/620022]    Loss: 0.010710   Batch Acc: 71.88
[Train] Epoch: 1 [85440/620022]    Loss: 0.011243   Batch Acc: 65.62
[Train] Epoch: 1 [85504/620022]    Loss: 0.009702   Batch Acc: 76.56
[Train] Epoch: 1 [85568/620022]    Loss: 0.009551   Batch Acc: 76.56
[Train] Epoch: 1 [85632/620022]    Loss: 0.007690   Batch Acc: 78.12
[Train] Epoch: 1 [85696/620022]    Loss: 0.007096   Batch Acc: 81.25
[Train] Epoch: 1 [85760/620022]    Loss: 0.010080   Batch Acc: 67.19
[Train] Epoch: 1 [85824/620022]    Loss: 0.009138   Batch Acc: 73.44
[Train] Epoch: 1 [85888/620022]    Loss: 0.009909   Batch Acc: 75.00
[Train] Epoch: 1 [85952/620022]    Loss: 0.006208   Batch Acc: 87.50
[Train] Epoch: 1 [86016/620022]    Loss: 0.008317   Batch Acc: 71.88
[Train] Epoch: 1 [86080/620022]    Loss: 0.010295   Batch Acc: 73.44
[Train] Epoch: 1 [86144/620022]    Loss: 0.010279   Batch Acc: 78.12
[Train] Epoch: 1 [86208/620022]    Loss: 0.008726   Batch Acc: 81.25
[Train] Epoch: 1 [86272/620022]    Loss: 0.006706   Batch Acc: 84.38
[Train] Epoch: 1 [86336/620022]    Loss: 0.008542   Batch Acc: 79.69
[Train] Epoch: 1 [86400/620022]    Loss: 0.010517   Batch Acc: 70.31
[Train] Epoch: 1 [86464/620022]    Loss: 0.008464   Batch Acc: 81.25
[Train] Epoch: 1 [86528/620022]    Loss: 0.008205   Batch Acc: 82.81
[Train] Epoch: 1 [86592/620022]    Loss: 0.011307   Batch Acc: 70.31
[Train] Epoch: 1 [86656/620022]    Loss: 0.007357   Batch Acc: 76.56
[Train] Epoch: 1 [86720/620022]    Loss: 0.007581   Batch Acc: 79.69
[Train] Epoch: 1 [86784/620022]    Loss: 0.010653   Batch Acc: 67.19
[Train] Epoch: 1 [86848/620022]    Loss: 0.007697   Batch Acc: 79.69
[Train] Epoch: 1 [86912/620022]    Loss: 0.009636   Batch Acc: 71.88
[Train] Epoch: 1 [86976/620022]    Loss: 0.007476   Batch Acc: 87.50
[Train] Epoch: 1 [87040/620022]    Loss: 0.010772   Batch Acc: 70.31
[Train] Epoch: 1 [87104/620022]    Loss: 0.010936   Batch Acc: 75.00
[Train] Epoch: 1 [87168/620022]    Loss: 0.007660   Batch Acc: 82.81
[Train] Epoch: 1 [87232/620022]    Loss: 0.007151   Batch Acc: 79.69
[Train] Epoch: 1 [87296/620022]    Loss: 0.007620   Batch Acc: 79.69
[Train] Epoch: 1 [87360/620022]    Loss: 0.009490   Batch Acc: 76.56
[Train] Epoch: 1 [87424/620022]    Loss: 0.007353   Batch Acc: 82.81
[Train] Epoch: 1 [87488/620022]    Loss: 0.009647   Batch Acc: 71.88
[Train] Epoch: 1 [87552/620022]    Loss: 0.007676   Batch Acc: 82.81
[Train] Epoch: 1 [87616/620022]    Loss: 0.009506   Batch Acc: 75.00
[Train] Epoch: 1 [87680/620022]    Loss: 0.007863   Batch Acc: 82.81
[Train] Epoch: 1 [87744/620022]    Loss: 0.007609   Batch Acc: 85.94
[Train] Epoch: 1 [87808/620022]    Loss: 0.008317   Batch Acc: 75.00
[Train] Epoch: 1 [87872/620022]    Loss: 0.010588   Batch Acc: 68.75
[Train] Epoch: 1 [87936/620022]    Loss: 0.007798   Batch Acc: 79.69
[Train] Epoch: 1 [88000/620022]    Loss: 0.009408   Batch Acc: 73.44
[Train] Epoch: 1 [88064/620022]    Loss: 0.009291   Batch Acc: 71.88
[Train] Epoch: 1 [88128/620022]    Loss: 0.007513   Batch Acc: 84.38
[Train] Epoch: 1 [88192/620022]    Loss: 0.010460   Batch Acc: 71.88
[Train] Epoch: 1 [88256/620022]    Loss: 0.007961   Batch Acc: 81.25
[Train] Epoch: 1 [88320/620022]    Loss: 0.008582   Batch Acc: 78.12
[Train] Epoch: 1 [88384/620022]    Loss: 0.007125   Batch Acc: 78.12
[Train] Epoch: 1 [88448/620022]    Loss: 0.008504   Batch Acc: 73.44
[Train] Epoch: 1 [88512/620022]    Loss: 0.008590   Batch Acc: 78.12
[Train] Epoch: 1 [88576/620022]    Loss: 0.011014   Batch Acc: 73.44
[Train] Epoch: 1 [88640/620022]    Loss: 0.011568   Batch Acc: 71.88
[Train] Epoch: 1 [88704/620022]    Loss: 0.009031   Batch Acc: 78.12
[Train] Epoch: 1 [88768/620022]    Loss: 0.006544   Batch Acc: 84.38
[Train] Epoch: 1 [88832/620022]    Loss: 0.009415   Batch Acc: 76.56
[Train] Epoch: 1 [88896/620022]    Loss: 0.008196   Batch Acc: 78.12
[Train] Epoch: 1 [88960/620022]    Loss: 0.007202   Batch Acc: 82.81
[Train] Epoch: 1 [89024/620022]    Loss: 0.010204   Batch Acc: 68.75
[Train] Epoch: 1 [89088/620022]    Loss: 0.007885   Batch Acc: 84.38
[Train] Epoch: 1 [89152/620022]    Loss: 0.009728   Batch Acc: 76.56
[Train] Epoch: 1 [89216/620022]    Loss: 0.010971   Batch Acc: 73.44
[Train] Epoch: 1 [89280/620022]    Loss: 0.008980   Batch Acc: 78.12
[Train] Epoch: 1 [89344/620022]    Loss: 0.010709   Batch Acc: 71.88
[Train] Epoch: 1 [89408/620022]    Loss: 0.012254   Batch Acc: 68.75
[Train] Epoch: 1 [89472/620022]    Loss: 0.010666   Batch Acc: 68.75
[Train] Epoch: 1 [89536/620022]    Loss: 0.008918   Batch Acc: 76.56
[Train] Epoch: 1 [89600/620022]    Loss: 0.009136   Batch Acc: 76.56
[Train] Epoch: 1 [89664/620022]    Loss: 0.006061   Batch Acc: 84.38
[Train] Epoch: 1 [89728/620022]    Loss: 0.006868   Batch Acc: 84.38
[Train] Epoch: 1 [89792/620022]    Loss: 0.008739   Batch Acc: 75.00
[Train] Epoch: 1 [89856/620022]    Loss: 0.009067   Batch Acc: 76.56
[Train] Epoch: 1 [89920/620022]    Loss: 0.008859   Batch Acc: 79.69
[Train] Epoch: 1 [89984/620022]    Loss: 0.009648   Batch Acc: 75.00
[Train] Epoch: 1 [90048/620022]    Loss: 0.007964   Batch Acc: 78.12
[Train] Epoch: 1 [90112/620022]    Loss: 0.008228   Batch Acc: 82.81
[Train] Epoch: 1 [90176/620022]    Loss: 0.007438   Batch Acc: 89.06
[Train] Epoch: 1 [90240/620022]    Loss: 0.007867   Batch Acc: 84.38
[Train] Epoch: 1 [90304/620022]    Loss: 0.008902   Batch Acc: 75.00
[Train] Epoch: 1 [90368/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 1 [90432/620022]    Loss: 0.008318   Batch Acc: 79.69
[Train] Epoch: 1 [90496/620022]    Loss: 0.007253   Batch Acc: 82.81
[Train] Epoch: 1 [90560/620022]    Loss: 0.008000   Batch Acc: 75.00
[Train] Epoch: 1 [90624/620022]    Loss: 0.010126   Batch Acc: 76.56
[Train] Epoch: 1 [90688/620022]    Loss: 0.007056   Batch Acc: 85.94
[Train] Epoch: 1 [90752/620022]    Loss: 0.008409   Batch Acc: 79.69
[Train] Epoch: 1 [90816/620022]    Loss: 0.009138   Batch Acc: 73.44
[Train] Epoch: 1 [90880/620022]    Loss: 0.008439   Batch Acc: 78.12
[Train] Epoch: 1 [90944/620022]    Loss: 0.005123   Batch Acc: 87.50
[Train] Epoch: 1 [91008/620022]    Loss: 0.008734   Batch Acc: 78.12
[Train] Epoch: 1 [91072/620022]    Loss: 0.011939   Batch Acc: 68.75
[Train] Epoch: 1 [91136/620022]    Loss: 0.006393   Batch Acc: 92.19
[Train] Epoch: 1 [91200/620022]    Loss: 0.008928   Batch Acc: 70.31
[Train] Epoch: 1 [91264/620022]    Loss: 0.009089   Batch Acc: 79.69
[Train] Epoch: 1 [91328/620022]    Loss: 0.008742   Batch Acc: 81.25
[Train] Epoch: 1 [91392/620022]    Loss: 0.008429   Batch Acc: 78.12
[Train] Epoch: 1 [91456/620022]    Loss: 0.008781   Batch Acc: 73.44
[Train] Epoch: 1 [91520/620022]    Loss: 0.007622   Batch Acc: 84.38
[Train] Epoch: 1 [91584/620022]    Loss: 0.007745   Batch Acc: 79.69
[Train] Epoch: 1 [91648/620022]    Loss: 0.010040   Batch Acc: 75.00
[Train] Epoch: 1 [91712/620022]    Loss: 0.009420   Batch Acc: 78.12
[Train] Epoch: 1 [91776/620022]    Loss: 0.009551   Batch Acc: 73.44
[Train] Epoch: 1 [91840/620022]    Loss: 0.009475   Batch Acc: 81.25
[Train] Epoch: 1 [91904/620022]    Loss: 0.005984   Batch Acc: 84.38
[Train] Epoch: 1 [91968/620022]    Loss: 0.010867   Batch Acc: 70.31
[Train] Epoch: 1 [92032/620022]    Loss: 0.007234   Batch Acc: 82.81
[Train] Epoch: 1 [92096/620022]    Loss: 0.007740   Batch Acc: 82.81
[Train] Epoch: 1 [92160/620022]    Loss: 0.009033   Batch Acc: 73.44
[Train] Epoch: 1 [92224/620022]    Loss: 0.008083   Batch Acc: 78.12
[Train] Epoch: 1 [92288/620022]    Loss: 0.008286   Batch Acc: 79.69
[Train] Epoch: 1 [92352/620022]    Loss: 0.006629   Batch Acc: 90.62
[Train] Epoch: 1 [92416/620022]    Loss: 0.007672   Batch Acc: 78.12
[Train] Epoch: 1 [92480/620022]    Loss: 0.010991   Batch Acc: 68.75
[Train] Epoch: 1 [92544/620022]    Loss: 0.007690   Batch Acc: 82.81
[Train] Epoch: 1 [92608/620022]    Loss: 0.009287   Batch Acc: 73.44
[Train] Epoch: 1 [92672/620022]    Loss: 0.010283   Batch Acc: 68.75
[Train] Epoch: 1 [92736/620022]    Loss: 0.007173   Batch Acc: 84.38
[Train] Epoch: 1 [92800/620022]    Loss: 0.009575   Batch Acc: 73.44
[Train] Epoch: 1 [92864/620022]    Loss: 0.010770   Batch Acc: 70.31
[Train] Epoch: 1 [92928/620022]    Loss: 0.009615   Batch Acc: 75.00
[Train] Epoch: 1 [92992/620022]    Loss: 0.008741   Batch Acc: 76.56
[Train] Epoch: 1 [93056/620022]    Loss: 0.009336   Batch Acc: 70.31
[Train] Epoch: 1 [93120/620022]    Loss: 0.008519   Batch Acc: 76.56
[Train] Epoch: 1 [93184/620022]    Loss: 0.006946   Batch Acc: 84.38
[Train] Epoch: 1 [93248/620022]    Loss: 0.008311   Batch Acc: 79.69
[Train] Epoch: 1 [93312/620022]    Loss: 0.011198   Batch Acc: 73.44
[Train] Epoch: 1 [93376/620022]    Loss: 0.008042   Batch Acc: 81.25
[Train] Epoch: 1 [93440/620022]    Loss: 0.010141   Batch Acc: 78.12
[Train] Epoch: 1 [93504/620022]    Loss: 0.008738   Batch Acc: 73.44
[Train] Epoch: 1 [93568/620022]    Loss: 0.008454   Batch Acc: 79.69
[Train] Epoch: 1 [93632/620022]    Loss: 0.010855   Batch Acc: 71.88
[Train] Epoch: 1 [93696/620022]    Loss: 0.007792   Batch Acc: 81.25
[Train] Epoch: 1 [93760/620022]    Loss: 0.006447   Batch Acc: 89.06
[Train] Epoch: 1 [93824/620022]    Loss: 0.008806   Batch Acc: 76.56
[Train] Epoch: 1 [93888/620022]    Loss: 0.008440   Batch Acc: 78.12
[Train] Epoch: 1 [93952/620022]    Loss: 0.009853   Batch Acc: 73.44
[Train] Epoch: 1 [94016/620022]    Loss: 0.007846   Batch Acc: 81.25
[Train] Epoch: 1 [94080/620022]    Loss: 0.011400   Batch Acc: 78.12
[Train] Epoch: 1 [94144/620022]    Loss: 0.008704   Batch Acc: 78.12
[Train] Epoch: 1 [94208/620022]    Loss: 0.007190   Batch Acc: 76.56
[Train] Epoch: 1 [94272/620022]    Loss: 0.009147   Batch Acc: 78.12
[Train] Epoch: 1 [94336/620022]    Loss: 0.006805   Batch Acc: 85.94
[Train] Epoch: 1 [94400/620022]    Loss: 0.008690   Batch Acc: 73.44
[Train] Epoch: 1 [94464/620022]    Loss: 0.010138   Batch Acc: 71.88
[Train] Epoch: 1 [94528/620022]    Loss: 0.009325   Batch Acc: 79.69
[Train] Epoch: 1 [94592/620022]    Loss: 0.009630   Batch Acc: 78.12
[Train] Epoch: 1 [94656/620022]    Loss: 0.008746   Batch Acc: 78.12
[Train] Epoch: 1 [94720/620022]    Loss: 0.011092   Batch Acc: 75.00
[Train] Epoch: 1 [94784/620022]    Loss: 0.008648   Batch Acc: 81.25
[Train] Epoch: 1 [94848/620022]    Loss: 0.010553   Batch Acc: 76.56
[Train] Epoch: 1 [94912/620022]    Loss: 0.007962   Batch Acc: 82.81
[Train] Epoch: 1 [94976/620022]    Loss: 0.008631   Batch Acc: 78.12
[Train] Epoch: 1 [95040/620022]    Loss: 0.009936   Batch Acc: 65.62
[Train] Epoch: 1 [95104/620022]    Loss: 0.009365   Batch Acc: 78.12
[Train] Epoch: 1 [95168/620022]    Loss: 0.008899   Batch Acc: 79.69
[Train] Epoch: 1 [95232/620022]    Loss: 0.008951   Batch Acc: 70.31
[Train] Epoch: 1 [95296/620022]    Loss: 0.008635   Batch Acc: 76.56
[Train] Epoch: 1 [95360/620022]    Loss: 0.010178   Batch Acc: 68.75
[Train] Epoch: 1 [95424/620022]    Loss: 0.007534   Batch Acc: 79.69
[Train] Epoch: 1 [95488/620022]    Loss: 0.009373   Batch Acc: 73.44
[Train] Epoch: 1 [95552/620022]    Loss: 0.009486   Batch Acc: 68.75
[Train] Epoch: 1 [95616/620022]    Loss: 0.008423   Batch Acc: 79.69
[Train] Epoch: 1 [95680/620022]    Loss: 0.007987   Batch Acc: 78.12
[Train] Epoch: 1 [95744/620022]    Loss: 0.007751   Batch Acc: 78.12
[Train] Epoch: 1 [95808/620022]    Loss: 0.008335   Batch Acc: 85.94
[Train] Epoch: 1 [95872/620022]    Loss: 0.009275   Batch Acc: 79.69
[Train] Epoch: 1 [95936/620022]    Loss: 0.007962   Batch Acc: 84.38
[Train] Epoch: 1 [96000/620022]    Loss: 0.009946   Batch Acc: 75.00
[Train] Epoch: 1 [96064/620022]    Loss: 0.008192   Batch Acc: 79.69
[Train] Epoch: 1 [96128/620022]    Loss: 0.007091   Batch Acc: 87.50
[Train] Epoch: 1 [96192/620022]    Loss: 0.008272   Batch Acc: 81.25
[Train] Epoch: 1 [96256/620022]    Loss: 0.009270   Batch Acc: 75.00
[Train] Epoch: 1 [96320/620022]    Loss: 0.008907   Batch Acc: 76.56
[Train] Epoch: 1 [96384/620022]    Loss: 0.009325   Batch Acc: 76.56
[Train] Epoch: 1 [96448/620022]    Loss: 0.008954   Batch Acc: 79.69
[Train] Epoch: 1 [96512/620022]    Loss: 0.006381   Batch Acc: 87.50
[Train] Epoch: 1 [96576/620022]    Loss: 0.010056   Batch Acc: 71.88
[Train] Epoch: 1 [96640/620022]    Loss: 0.008426   Batch Acc: 82.81
[Train] Epoch: 1 [96704/620022]    Loss: 0.007275   Batch Acc: 81.25
[Train] Epoch: 1 [96768/620022]    Loss: 0.008809   Batch Acc: 79.69
[Train] Epoch: 1 [96832/620022]    Loss: 0.007674   Batch Acc: 79.69
[Train] Epoch: 1 [96896/620022]    Loss: 0.008711   Batch Acc: 78.12
[Train] Epoch: 1 [96960/620022]    Loss: 0.010142   Batch Acc: 73.44
[Train] Epoch: 1 [97024/620022]    Loss: 0.009408   Batch Acc: 76.56
[Train] Epoch: 1 [97088/620022]    Loss: 0.006796   Batch Acc: 79.69
[Train] Epoch: 1 [97152/620022]    Loss: 0.008171   Batch Acc: 79.69
[Train] Epoch: 1 [97216/620022]    Loss: 0.008687   Batch Acc: 76.56
[Train] Epoch: 1 [97280/620022]    Loss: 0.010076   Batch Acc: 67.19
[Train] Epoch: 1 [97344/620022]    Loss: 0.009986   Batch Acc: 71.88
[Train] Epoch: 1 [97408/620022]    Loss: 0.006345   Batch Acc: 87.50
[Train] Epoch: 1 [97472/620022]    Loss: 0.009349   Batch Acc: 78.12
[Train] Epoch: 1 [97536/620022]    Loss: 0.008339   Batch Acc: 78.12
[Train] Epoch: 1 [97600/620022]    Loss: 0.007317   Batch Acc: 75.00
[Train] Epoch: 1 [97664/620022]    Loss: 0.011116   Batch Acc: 71.88
[Train] Epoch: 1 [97728/620022]    Loss: 0.009478   Batch Acc: 73.44
[Train] Epoch: 1 [97792/620022]    Loss: 0.008176   Batch Acc: 78.12
[Train] Epoch: 1 [97856/620022]    Loss: 0.008279   Batch Acc: 84.38
[Train] Epoch: 1 [97920/620022]    Loss: 0.007762   Batch Acc: 75.00
[Train] Epoch: 1 [97984/620022]    Loss: 0.009313   Batch Acc: 73.44
[Train] Epoch: 1 [98048/620022]    Loss: 0.011640   Batch Acc: 71.88
[Train] Epoch: 1 [98112/620022]    Loss: 0.010691   Batch Acc: 70.31
[Train] Epoch: 1 [98176/620022]    Loss: 0.010466   Batch Acc: 71.88
[Train] Epoch: 1 [98240/620022]    Loss: 0.010305   Batch Acc: 73.44
[Train] Epoch: 1 [98304/620022]    Loss: 0.008959   Batch Acc: 76.56
[Train] Epoch: 1 [98368/620022]    Loss: 0.010992   Batch Acc: 70.31
[Train] Epoch: 1 [98432/620022]    Loss: 0.010627   Batch Acc: 65.62
[Train] Epoch: 1 [98496/620022]    Loss: 0.008541   Batch Acc: 81.25
[Train] Epoch: 1 [98560/620022]    Loss: 0.010066   Batch Acc: 68.75
[Train] Epoch: 1 [98624/620022]    Loss: 0.007376   Batch Acc: 79.69
[Train] Epoch: 1 [98688/620022]    Loss: 0.005816   Batch Acc: 85.94
[Train] Epoch: 1 [98752/620022]    Loss: 0.007765   Batch Acc: 76.56
[Train] Epoch: 1 [98816/620022]    Loss: 0.006104   Batch Acc: 89.06
[Train] Epoch: 1 [98880/620022]    Loss: 0.008764   Batch Acc: 78.12
[Train] Epoch: 1 [98944/620022]    Loss: 0.009017   Batch Acc: 76.56
[Train] Epoch: 1 [99008/620022]    Loss: 0.008174   Batch Acc: 85.94
[Train] Epoch: 1 [99072/620022]    Loss: 0.008503   Batch Acc: 78.12
[Train] Epoch: 1 [99136/620022]    Loss: 0.009314   Batch Acc: 76.56
[Train] Epoch: 1 [99200/620022]    Loss: 0.007243   Batch Acc: 81.25
[Train] Epoch: 1 [99264/620022]    Loss: 0.011000   Batch Acc: 75.00
[Train] Epoch: 1 [99328/620022]    Loss: 0.008434   Batch Acc: 75.00
[Train] Epoch: 1 [99392/620022]    Loss: 0.007454   Batch Acc: 84.38
[Train] Epoch: 1 [99456/620022]    Loss: 0.008253   Batch Acc: 76.56
[Train] Epoch: 1 [99520/620022]    Loss: 0.010016   Batch Acc: 76.56
[Train] Epoch: 1 [99584/620022]    Loss: 0.009823   Batch Acc: 75.00
[Train] Epoch: 1 [99648/620022]    Loss: 0.009163   Batch Acc: 78.12
[Train] Epoch: 1 [99712/620022]    Loss: 0.010655   Batch Acc: 68.75
[Train] Epoch: 1 [99776/620022]    Loss: 0.009943   Batch Acc: 73.44
[Train] Epoch: 1 [99840/620022]    Loss: 0.009693   Batch Acc: 76.56
[Train] Epoch: 1 [99904/620022]    Loss: 0.008492   Batch Acc: 76.56
[Train] Epoch: 1 [99968/620022]    Loss: 0.009318   Batch Acc: 73.44
[Train] Epoch: 1 [100032/620022]    Loss: 0.008117   Batch Acc: 73.44
[Train] Epoch: 1 [100096/620022]    Loss: 0.006229   Batch Acc: 89.06
[Train] Epoch: 1 [100160/620022]    Loss: 0.009128   Batch Acc: 71.88
[Train] Epoch: 1 [100224/620022]    Loss: 0.011379   Batch Acc: 68.75
[Train] Epoch: 1 [100288/620022]    Loss: 0.009032   Batch Acc: 76.56
[Train] Epoch: 1 [100352/620022]    Loss: 0.008406   Batch Acc: 78.12
[Train] Epoch: 1 [100416/620022]    Loss: 0.007657   Batch Acc: 76.56
[Train] Epoch: 1 [100480/620022]    Loss: 0.008408   Batch Acc: 78.12
[Train] Epoch: 1 [100544/620022]    Loss: 0.010808   Batch Acc: 70.31
[Train] Epoch: 1 [100608/620022]    Loss: 0.008172   Batch Acc: 84.38
[Train] Epoch: 1 [100672/620022]    Loss: 0.007782   Batch Acc: 82.81
[Train] Epoch: 1 [100736/620022]    Loss: 0.008397   Batch Acc: 81.25
[Train] Epoch: 1 [100800/620022]    Loss: 0.008795   Batch Acc: 79.69
[Train] Epoch: 1 [100864/620022]    Loss: 0.008572   Batch Acc: 81.25
[Train] Epoch: 1 [100928/620022]    Loss: 0.007892   Batch Acc: 71.88
[Train] Epoch: 1 [100992/620022]    Loss: 0.009452   Batch Acc: 75.00
[Train] Epoch: 1 [101056/620022]    Loss: 0.010387   Batch Acc: 73.44
[Train] Epoch: 1 [101120/620022]    Loss: 0.010548   Batch Acc: 75.00
[Train] Epoch: 1 [101184/620022]    Loss: 0.010470   Batch Acc: 71.88
[Train] Epoch: 1 [101248/620022]    Loss: 0.008413   Batch Acc: 82.81
[Train] Epoch: 1 [101312/620022]    Loss: 0.008018   Batch Acc: 78.12
[Train] Epoch: 1 [101376/620022]    Loss: 0.009218   Batch Acc: 73.44
[Train] Epoch: 1 [101440/620022]    Loss: 0.009273   Batch Acc: 78.12
[Train] Epoch: 1 [101504/620022]    Loss: 0.007713   Batch Acc: 76.56
[Train] Epoch: 1 [101568/620022]    Loss: 0.007898   Batch Acc: 81.25
[Train] Epoch: 1 [101632/620022]    Loss: 0.007762   Batch Acc: 75.00
[Train] Epoch: 1 [101696/620022]    Loss: 0.011491   Batch Acc: 68.75
[Train] Epoch: 1 [101760/620022]    Loss: 0.008788   Batch Acc: 79.69
[Train] Epoch: 1 [101824/620022]    Loss: 0.008799   Batch Acc: 75.00
[Train] Epoch: 1 [101888/620022]    Loss: 0.010715   Batch Acc: 71.88
[Train] Epoch: 1 [101952/620022]    Loss: 0.009823   Batch Acc: 73.44
[Train] Epoch: 1 [102016/620022]    Loss: 0.008552   Batch Acc: 78.12
[Train] Epoch: 1 [102080/620022]    Loss: 0.008098   Batch Acc: 81.25
[Train] Epoch: 1 [102144/620022]    Loss: 0.007817   Batch Acc: 82.81
[Train] Epoch: 1 [102208/620022]    Loss: 0.010487   Batch Acc: 75.00
[Train] Epoch: 1 [102272/620022]    Loss: 0.012173   Batch Acc: 59.38
[Train] Epoch: 1 [102336/620022]    Loss: 0.007331   Batch Acc: 79.69
[Train] Epoch: 1 [102400/620022]    Loss: 0.009589   Batch Acc: 78.12
[Train] Epoch: 1 [102464/620022]    Loss: 0.006435   Batch Acc: 85.94
[Train] Epoch: 1 [102528/620022]    Loss: 0.006202   Batch Acc: 85.94
[Train] Epoch: 1 [102592/620022]    Loss: 0.008196   Batch Acc: 78.12
[Train] Epoch: 1 [102656/620022]    Loss: 0.008672   Batch Acc: 73.44
[Train] Epoch: 1 [102720/620022]    Loss: 0.011164   Batch Acc: 70.31
[Train] Epoch: 1 [102784/620022]    Loss: 0.006527   Batch Acc: 85.94
[Train] Epoch: 1 [102848/620022]    Loss: 0.009911   Batch Acc: 68.75
[Train] Epoch: 1 [102912/620022]    Loss: 0.008368   Batch Acc: 84.38
[Train] Epoch: 1 [102976/620022]    Loss: 0.006950   Batch Acc: 85.94
[Train] Epoch: 1 [103040/620022]    Loss: 0.008990   Batch Acc: 70.31
[Train] Epoch: 1 [103104/620022]    Loss: 0.009194   Batch Acc: 78.12
[Train] Epoch: 1 [103168/620022]    Loss: 0.008169   Batch Acc: 79.69
[Train] Epoch: 1 [103232/620022]    Loss: 0.010296   Batch Acc: 73.44
[Train] Epoch: 1 [103296/620022]    Loss: 0.012549   Batch Acc: 67.19
[Train] Epoch: 1 [103360/620022]    Loss: 0.010348   Batch Acc: 81.25
[Train] Epoch: 1 [103424/620022]    Loss: 0.010473   Batch Acc: 73.44
[Train] Epoch: 1 [103488/620022]    Loss: 0.007397   Batch Acc: 78.12
[Train] Epoch: 1 [103552/620022]    Loss: 0.009994   Batch Acc: 70.31
[Train] Epoch: 1 [103616/620022]    Loss: 0.005707   Batch Acc: 89.06
[Train] Epoch: 1 [103680/620022]    Loss: 0.009099   Batch Acc: 79.69
[Train] Epoch: 1 [103744/620022]    Loss: 0.006724   Batch Acc: 87.50
[Train] Epoch: 1 [103808/620022]    Loss: 0.010010   Batch Acc: 76.56
[Train] Epoch: 1 [103872/620022]    Loss: 0.009466   Batch Acc: 75.00
[Train] Epoch: 1 [103936/620022]    Loss: 0.010300   Batch Acc: 68.75
[Train] Epoch: 1 [104000/620022]    Loss: 0.007142   Batch Acc: 85.94
[Train] Epoch: 1 [104064/620022]    Loss: 0.007983   Batch Acc: 81.25
[Train] Epoch: 1 [104128/620022]    Loss: 0.007768   Batch Acc: 73.44
[Train] Epoch: 1 [104192/620022]    Loss: 0.009118   Batch Acc: 75.00
[Train] Epoch: 1 [104256/620022]    Loss: 0.006689   Batch Acc: 85.94
[Train] Epoch: 1 [104320/620022]    Loss: 0.008843   Batch Acc: 76.56
[Train] Epoch: 1 [104384/620022]    Loss: 0.008678   Batch Acc: 82.81
[Train] Epoch: 1 [104448/620022]    Loss: 0.009654   Batch Acc: 73.44
[Train] Epoch: 1 [104512/620022]    Loss: 0.008103   Batch Acc: 81.25
[Train] Epoch: 1 [104576/620022]    Loss: 0.008378   Batch Acc: 78.12
[Train] Epoch: 1 [104640/620022]    Loss: 0.009598   Batch Acc: 79.69
[Train] Epoch: 1 [104704/620022]    Loss: 0.007793   Batch Acc: 81.25
[Train] Epoch: 1 [104768/620022]    Loss: 0.008788   Batch Acc: 81.25
[Train] Epoch: 1 [104832/620022]    Loss: 0.009718   Batch Acc: 70.31
[Train] Epoch: 1 [104896/620022]    Loss: 0.010088   Batch Acc: 81.25
[Train] Epoch: 1 [104960/620022]    Loss: 0.007451   Batch Acc: 78.12
[Train] Epoch: 1 [105024/620022]    Loss: 0.009790   Batch Acc: 71.88
[Train] Epoch: 1 [105088/620022]    Loss: 0.011382   Batch Acc: 68.75
[Train] Epoch: 1 [105152/620022]    Loss: 0.007943   Batch Acc: 75.00
[Train] Epoch: 1 [105216/620022]    Loss: 0.008335   Batch Acc: 81.25
[Train] Epoch: 1 [105280/620022]    Loss: 0.009917   Batch Acc: 71.88
[Train] Epoch: 1 [105344/620022]    Loss: 0.007518   Batch Acc: 81.25
[Train] Epoch: 1 [105408/620022]    Loss: 0.007915   Batch Acc: 81.25
[Train] Epoch: 1 [105472/620022]    Loss: 0.006896   Batch Acc: 84.38
[Train] Epoch: 1 [105536/620022]    Loss: 0.008450   Batch Acc: 81.25
[Train] Epoch: 1 [105600/620022]    Loss: 0.008930   Batch Acc: 71.88
[Train] Epoch: 1 [105664/620022]    Loss: 0.008844   Batch Acc: 81.25
[Train] Epoch: 1 [105728/620022]    Loss: 0.009300   Batch Acc: 71.88
[Train] Epoch: 1 [105792/620022]    Loss: 0.009071   Batch Acc: 76.56
[Train] Epoch: 1 [105856/620022]    Loss: 0.007105   Batch Acc: 82.81
[Train] Epoch: 1 [105920/620022]    Loss: 0.009360   Batch Acc: 73.44
[Train] Epoch: 1 [105984/620022]    Loss: 0.006621   Batch Acc: 82.81
[Train] Epoch: 1 [106048/620022]    Loss: 0.009679   Batch Acc: 71.88
[Train] Epoch: 1 [106112/620022]    Loss: 0.008119   Batch Acc: 78.12
[Train] Epoch: 1 [106176/620022]    Loss: 0.008261   Batch Acc: 82.81
[Train] Epoch: 1 [106240/620022]    Loss: 0.008188   Batch Acc: 78.12
[Train] Epoch: 1 [106304/620022]    Loss: 0.010306   Batch Acc: 75.00
[Train] Epoch: 1 [106368/620022]    Loss: 0.009525   Batch Acc: 73.44
[Train] Epoch: 1 [106432/620022]    Loss: 0.007194   Batch Acc: 81.25
[Train] Epoch: 1 [106496/620022]    Loss: 0.011191   Batch Acc: 75.00
[Train] Epoch: 1 [106560/620022]    Loss: 0.008176   Batch Acc: 82.81
[Train] Epoch: 1 [106624/620022]    Loss: 0.009857   Batch Acc: 78.12
[Train] Epoch: 1 [106688/620022]    Loss: 0.010315   Batch Acc: 70.31
[Train] Epoch: 1 [106752/620022]    Loss: 0.008327   Batch Acc: 79.69
[Train] Epoch: 1 [106816/620022]    Loss: 0.007596   Batch Acc: 79.69
[Train] Epoch: 1 [106880/620022]    Loss: 0.006216   Batch Acc: 85.94
[Train] Epoch: 1 [106944/620022]    Loss: 0.008873   Batch Acc: 76.56
[Train] Epoch: 1 [107008/620022]    Loss: 0.012280   Batch Acc: 67.19
[Train] Epoch: 1 [107072/620022]    Loss: 0.006916   Batch Acc: 85.94
[Train] Epoch: 1 [107136/620022]    Loss: 0.007537   Batch Acc: 78.12
[Train] Epoch: 1 [107200/620022]    Loss: 0.009381   Batch Acc: 75.00
[Train] Epoch: 1 [107264/620022]    Loss: 0.010396   Batch Acc: 75.00
[Train] Epoch: 1 [107328/620022]    Loss: 0.007042   Batch Acc: 82.81
[Train] Epoch: 1 [107392/620022]    Loss: 0.006104   Batch Acc: 84.38
[Train] Epoch: 1 [107456/620022]    Loss: 0.009010   Batch Acc: 79.69
[Train] Epoch: 1 [107520/620022]    Loss: 0.009289   Batch Acc: 75.00
[Train] Epoch: 1 [107584/620022]    Loss: 0.008004   Batch Acc: 79.69
[Train] Epoch: 1 [107648/620022]    Loss: 0.009168   Batch Acc: 73.44
[Train] Epoch: 1 [107712/620022]    Loss: 0.007506   Batch Acc: 81.25
[Train] Epoch: 1 [107776/620022]    Loss: 0.007845   Batch Acc: 76.56
[Train] Epoch: 1 [107840/620022]    Loss: 0.010589   Batch Acc: 75.00
[Train] Epoch: 1 [107904/620022]    Loss: 0.008634   Batch Acc: 78.12
[Train] Epoch: 1 [107968/620022]    Loss: 0.008661   Batch Acc: 79.69
[Train] Epoch: 1 [108032/620022]    Loss: 0.007193   Batch Acc: 85.94
[Train] Epoch: 1 [108096/620022]    Loss: 0.006396   Batch Acc: 87.50
[Train] Epoch: 1 [108160/620022]    Loss: 0.007963   Batch Acc: 82.81
[Train] Epoch: 1 [108224/620022]    Loss: 0.009627   Batch Acc: 76.56
[Train] Epoch: 1 [108288/620022]    Loss: 0.010231   Batch Acc: 76.56
[Train] Epoch: 1 [108352/620022]    Loss: 0.010686   Batch Acc: 67.19
[Train] Epoch: 1 [108416/620022]    Loss: 0.008890   Batch Acc: 73.44
[Train] Epoch: 1 [108480/620022]    Loss: 0.009827   Batch Acc: 73.44
[Train] Epoch: 1 [108544/620022]    Loss: 0.008046   Batch Acc: 76.56
[Train] Epoch: 1 [108608/620022]    Loss: 0.010228   Batch Acc: 70.31
[Train] Epoch: 1 [108672/620022]    Loss: 0.008260   Batch Acc: 76.56
[Train] Epoch: 1 [108736/620022]    Loss: 0.006475   Batch Acc: 85.94
[Train] Epoch: 1 [108800/620022]    Loss: 0.006838   Batch Acc: 81.25
[Train] Epoch: 1 [108864/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 1 [108928/620022]    Loss: 0.012440   Batch Acc: 73.44
[Train] Epoch: 1 [108992/620022]    Loss: 0.008276   Batch Acc: 75.00
[Train] Epoch: 1 [109056/620022]    Loss: 0.010852   Batch Acc: 67.19
[Train] Epoch: 1 [109120/620022]    Loss: 0.008142   Batch Acc: 79.69
[Train] Epoch: 1 [109184/620022]    Loss: 0.008894   Batch Acc: 78.12
[Train] Epoch: 1 [109248/620022]    Loss: 0.010334   Batch Acc: 76.56
[Train] Epoch: 1 [109312/620022]    Loss: 0.010258   Batch Acc: 70.31
[Train] Epoch: 1 [109376/620022]    Loss: 0.009239   Batch Acc: 68.75
[Train] Epoch: 1 [109440/620022]    Loss: 0.007706   Batch Acc: 81.25
[Train] Epoch: 1 [109504/620022]    Loss: 0.006700   Batch Acc: 84.38
[Train] Epoch: 1 [109568/620022]    Loss: 0.007559   Batch Acc: 78.12
[Train] Epoch: 1 [109632/620022]    Loss: 0.010262   Batch Acc: 71.88
[Train] Epoch: 1 [109696/620022]    Loss: 0.007061   Batch Acc: 82.81
[Train] Epoch: 1 [109760/620022]    Loss: 0.007569   Batch Acc: 85.94
[Train] Epoch: 1 [109824/620022]    Loss: 0.010142   Batch Acc: 75.00
[Train] Epoch: 1 [109888/620022]    Loss: 0.008560   Batch Acc: 78.12
[Train] Epoch: 1 [109952/620022]    Loss: 0.011696   Batch Acc: 68.75
[Train] Epoch: 1 [110016/620022]    Loss: 0.006627   Batch Acc: 87.50
[Train] Epoch: 1 [110080/620022]    Loss: 0.005935   Batch Acc: 85.94
[Train] Epoch: 1 [110144/620022]    Loss: 0.009170   Batch Acc: 73.44
[Train] Epoch: 1 [110208/620022]    Loss: 0.009916   Batch Acc: 70.31
[Train] Epoch: 1 [110272/620022]    Loss: 0.010546   Batch Acc: 70.31
[Train] Epoch: 1 [110336/620022]    Loss: 0.007903   Batch Acc: 81.25
[Train] Epoch: 1 [110400/620022]    Loss: 0.009959   Batch Acc: 62.50
[Train] Epoch: 1 [110464/620022]    Loss: 0.007967   Batch Acc: 75.00
[Train] Epoch: 1 [110528/620022]    Loss: 0.009854   Batch Acc: 73.44
[Train] Epoch: 1 [110592/620022]    Loss: 0.007405   Batch Acc: 85.94
[Train] Epoch: 1 [110656/620022]    Loss: 0.007698   Batch Acc: 81.25
[Train] Epoch: 1 [110720/620022]    Loss: 0.007879   Batch Acc: 76.56
[Train] Epoch: 1 [110784/620022]    Loss: 0.009891   Batch Acc: 70.31
[Train] Epoch: 1 [110848/620022]    Loss: 0.008737   Batch Acc: 76.56
[Train] Epoch: 1 [110912/620022]    Loss: 0.007060   Batch Acc: 84.38
[Train] Epoch: 1 [110976/620022]    Loss: 0.005953   Batch Acc: 87.50
[Train] Epoch: 1 [111040/620022]    Loss: 0.010304   Batch Acc: 78.12
[Train] Epoch: 1 [111104/620022]    Loss: 0.007346   Batch Acc: 84.38
[Train] Epoch: 1 [111168/620022]    Loss: 0.010057   Batch Acc: 78.12
[Train] Epoch: 1 [111232/620022]    Loss: 0.007627   Batch Acc: 75.00
[Train] Epoch: 1 [111296/620022]    Loss: 0.008185   Batch Acc: 81.25
[Train] Epoch: 1 [111360/620022]    Loss: 0.007980   Batch Acc: 82.81
[Train] Epoch: 1 [111424/620022]    Loss: 0.008126   Batch Acc: 71.88
[Train] Epoch: 1 [111488/620022]    Loss: 0.008125   Batch Acc: 81.25
[Train] Epoch: 1 [111552/620022]    Loss: 0.007391   Batch Acc: 84.38
[Train] Epoch: 1 [111616/620022]    Loss: 0.009095   Batch Acc: 76.56
[Train] Epoch: 1 [111680/620022]    Loss: 0.008126   Batch Acc: 75.00
[Train] Epoch: 1 [111744/620022]    Loss: 0.008520   Batch Acc: 76.56
[Train] Epoch: 1 [111808/620022]    Loss: 0.012267   Batch Acc: 70.31
[Train] Epoch: 1 [111872/620022]    Loss: 0.009650   Batch Acc: 75.00
[Train] Epoch: 1 [111936/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 1 [112000/620022]    Loss: 0.008787   Batch Acc: 73.44
[Train] Epoch: 1 [112064/620022]    Loss: 0.009929   Batch Acc: 70.31
[Train] Epoch: 1 [112128/620022]    Loss: 0.008470   Batch Acc: 75.00
[Train] Epoch: 1 [112192/620022]    Loss: 0.007323   Batch Acc: 79.69
[Train] Epoch: 1 [112256/620022]    Loss: 0.007210   Batch Acc: 82.81
[Train] Epoch: 1 [112320/620022]    Loss: 0.007841   Batch Acc: 85.94
[Train] Epoch: 1 [112384/620022]    Loss: 0.009860   Batch Acc: 71.88
[Train] Epoch: 1 [112448/620022]    Loss: 0.006309   Batch Acc: 84.38
[Train] Epoch: 1 [112512/620022]    Loss: 0.009424   Batch Acc: 73.44
[Train] Epoch: 1 [112576/620022]    Loss: 0.008193   Batch Acc: 81.25
[Train] Epoch: 1 [112640/620022]    Loss: 0.011121   Batch Acc: 70.31
[Train] Epoch: 1 [112704/620022]    Loss: 0.008126   Batch Acc: 82.81
[Train] Epoch: 1 [112768/620022]    Loss: 0.008290   Batch Acc: 79.69
[Train] Epoch: 1 [112832/620022]    Loss: 0.010490   Batch Acc: 65.62
[Train] Epoch: 1 [112896/620022]    Loss: 0.006141   Batch Acc: 87.50
[Train] Epoch: 1 [112960/620022]    Loss: 0.006200   Batch Acc: 85.94
[Train] Epoch: 1 [113024/620022]    Loss: 0.009478   Batch Acc: 70.31
[Train] Epoch: 1 [113088/620022]    Loss: 0.011173   Batch Acc: 73.44
[Train] Epoch: 1 [113152/620022]    Loss: 0.011151   Batch Acc: 64.06
[Train] Epoch: 1 [113216/620022]    Loss: 0.007768   Batch Acc: 85.94
[Train] Epoch: 1 [113280/620022]    Loss: 0.007510   Batch Acc: 76.56
[Train] Epoch: 1 [113344/620022]    Loss: 0.007229   Batch Acc: 79.69
[Train] Epoch: 1 [113408/620022]    Loss: 0.008083   Batch Acc: 75.00
[Train] Epoch: 1 [113472/620022]    Loss: 0.007362   Batch Acc: 82.81
[Train] Epoch: 1 [113536/620022]    Loss: 0.011116   Batch Acc: 76.56
[Train] Epoch: 1 [113600/620022]    Loss: 0.008449   Batch Acc: 75.00
[Train] Epoch: 1 [113664/620022]    Loss: 0.007435   Batch Acc: 81.25
[Train] Epoch: 1 [113728/620022]    Loss: 0.009305   Batch Acc: 71.88
[Train] Epoch: 1 [113792/620022]    Loss: 0.005643   Batch Acc: 87.50
[Train] Epoch: 1 [113856/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 1 [113920/620022]    Loss: 0.007943   Batch Acc: 82.81
[Train] Epoch: 1 [113984/620022]    Loss: 0.009773   Batch Acc: 70.31
[Train] Epoch: 1 [114048/620022]    Loss: 0.007107   Batch Acc: 79.69
[Train] Epoch: 1 [114112/620022]    Loss: 0.008394   Batch Acc: 84.38
[Train] Epoch: 1 [114176/620022]    Loss: 0.006568   Batch Acc: 82.81
[Train] Epoch: 1 [114240/620022]    Loss: 0.012044   Batch Acc: 65.62
[Train] Epoch: 1 [114304/620022]    Loss: 0.008059   Batch Acc: 82.81
[Train] Epoch: 1 [114368/620022]    Loss: 0.012686   Batch Acc: 60.94
[Train] Epoch: 1 [114432/620022]    Loss: 0.009548   Batch Acc: 76.56
[Train] Epoch: 1 [114496/620022]    Loss: 0.009541   Batch Acc: 76.56
[Train] Epoch: 1 [114560/620022]    Loss: 0.009139   Batch Acc: 78.12
[Train] Epoch: 1 [114624/620022]    Loss: 0.007838   Batch Acc: 81.25
[Train] Epoch: 1 [114688/620022]    Loss: 0.008462   Batch Acc: 81.25
[Train] Epoch: 1 [114752/620022]    Loss: 0.009003   Batch Acc: 76.56
[Train] Epoch: 1 [114816/620022]    Loss: 0.010247   Batch Acc: 71.88
[Train] Epoch: 1 [114880/620022]    Loss: 0.008945   Batch Acc: 78.12
[Train] Epoch: 1 [114944/620022]    Loss: 0.008226   Batch Acc: 81.25
[Train] Epoch: 1 [115008/620022]    Loss: 0.007057   Batch Acc: 82.81
[Train] Epoch: 1 [115072/620022]    Loss: 0.010835   Batch Acc: 70.31
[Train] Epoch: 1 [115136/620022]    Loss: 0.009082   Batch Acc: 82.81
[Train] Epoch: 1 [115200/620022]    Loss: 0.008931   Batch Acc: 76.56
[Train] Epoch: 1 [115264/620022]    Loss: 0.007742   Batch Acc: 76.56
[Train] Epoch: 1 [115328/620022]    Loss: 0.009880   Batch Acc: 70.31
[Train] Epoch: 1 [115392/620022]    Loss: 0.006926   Batch Acc: 85.94
[Train] Epoch: 1 [115456/620022]    Loss: 0.007627   Batch Acc: 84.38
[Train] Epoch: 1 [115520/620022]    Loss: 0.009998   Batch Acc: 68.75
[Train] Epoch: 1 [115584/620022]    Loss: 0.009567   Batch Acc: 82.81
[Train] Epoch: 1 [115648/620022]    Loss: 0.009503   Batch Acc: 76.56
[Train] Epoch: 1 [115712/620022]    Loss: 0.008012   Batch Acc: 82.81
[Train] Epoch: 1 [115776/620022]    Loss: 0.008388   Batch Acc: 82.81
[Train] Epoch: 1 [115840/620022]    Loss: 0.008440   Batch Acc: 71.88
[Train] Epoch: 1 [115904/620022]    Loss: 0.008262   Batch Acc: 73.44
[Train] Epoch: 1 [115968/620022]    Loss: 0.010964   Batch Acc: 68.75
[Train] Epoch: 1 [116032/620022]    Loss: 0.008557   Batch Acc: 78.12
[Train] Epoch: 1 [116096/620022]    Loss: 0.009793   Batch Acc: 75.00
[Train] Epoch: 1 [116160/620022]    Loss: 0.007302   Batch Acc: 84.38
[Train] Epoch: 1 [116224/620022]    Loss: 0.009286   Batch Acc: 78.12
[Train] Epoch: 1 [116288/620022]    Loss: 0.008284   Batch Acc: 79.69
[Train] Epoch: 1 [116352/620022]    Loss: 0.010022   Batch Acc: 73.44
[Train] Epoch: 1 [116416/620022]    Loss: 0.009521   Batch Acc: 71.88
[Train] Epoch: 1 [116480/620022]    Loss: 0.008562   Batch Acc: 76.56
[Train] Epoch: 1 [116544/620022]    Loss: 0.009805   Batch Acc: 75.00
[Train] Epoch: 1 [116608/620022]    Loss: 0.008250   Batch Acc: 84.38
[Train] Epoch: 1 [116672/620022]    Loss: 0.009901   Batch Acc: 71.88
[Train] Epoch: 1 [116736/620022]    Loss: 0.008578   Batch Acc: 76.56
[Train] Epoch: 1 [116800/620022]    Loss: 0.007151   Batch Acc: 82.81
[Train] Epoch: 1 [116864/620022]    Loss: 0.010919   Batch Acc: 65.62
[Train] Epoch: 1 [116928/620022]    Loss: 0.007119   Batch Acc: 82.81
[Train] Epoch: 1 [116992/620022]    Loss: 0.011544   Batch Acc: 67.19
[Train] Epoch: 1 [117056/620022]    Loss: 0.010927   Batch Acc: 75.00
[Train] Epoch: 1 [117120/620022]    Loss: 0.010111   Batch Acc: 78.12
[Train] Epoch: 1 [117184/620022]    Loss: 0.009031   Batch Acc: 76.56
[Train] Epoch: 1 [117248/620022]    Loss: 0.009592   Batch Acc: 78.12
[Train] Epoch: 1 [117312/620022]    Loss: 0.009514   Batch Acc: 73.44
[Train] Epoch: 1 [117376/620022]    Loss: 0.008206   Batch Acc: 82.81
[Train] Epoch: 1 [117440/620022]    Loss: 0.007668   Batch Acc: 79.69
[Train] Epoch: 1 [117504/620022]    Loss: 0.006940   Batch Acc: 84.38
[Train] Epoch: 1 [117568/620022]    Loss: 0.008492   Batch Acc: 78.12
[Train] Epoch: 1 [117632/620022]    Loss: 0.008321   Batch Acc: 73.44
[Train] Epoch: 1 [117696/620022]    Loss: 0.008696   Batch Acc: 76.56
[Train] Epoch: 1 [117760/620022]    Loss: 0.009518   Batch Acc: 75.00
[Train] Epoch: 1 [117824/620022]    Loss: 0.008914   Batch Acc: 73.44
[Train] Epoch: 1 [117888/620022]    Loss: 0.007591   Batch Acc: 82.81
[Train] Epoch: 1 [117952/620022]    Loss: 0.009056   Batch Acc: 76.56
[Train] Epoch: 1 [118016/620022]    Loss: 0.007979   Batch Acc: 78.12
[Train] Epoch: 1 [118080/620022]    Loss: 0.010903   Batch Acc: 73.44
[Train] Epoch: 1 [118144/620022]    Loss: 0.007160   Batch Acc: 82.81
[Train] Epoch: 1 [118208/620022]    Loss: 0.007255   Batch Acc: 82.81
[Train] Epoch: 1 [118272/620022]    Loss: 0.008359   Batch Acc: 82.81
[Train] Epoch: 1 [118336/620022]    Loss: 0.010447   Batch Acc: 71.88
[Train] Epoch: 1 [118400/620022]    Loss: 0.007633   Batch Acc: 78.12
[Train] Epoch: 1 [118464/620022]    Loss: 0.008402   Batch Acc: 79.69
[Train] Epoch: 1 [118528/620022]    Loss: 0.009871   Batch Acc: 75.00
[Train] Epoch: 1 [118592/620022]    Loss: 0.008754   Batch Acc: 78.12
[Train] Epoch: 1 [118656/620022]    Loss: 0.009838   Batch Acc: 75.00
[Train] Epoch: 1 [118720/620022]    Loss: 0.008327   Batch Acc: 79.69
[Train] Epoch: 1 [118784/620022]    Loss: 0.006682   Batch Acc: 87.50
[Train] Epoch: 1 [118848/620022]    Loss: 0.008286   Batch Acc: 84.38
[Train] Epoch: 1 [118912/620022]    Loss: 0.010277   Batch Acc: 73.44
[Train] Epoch: 1 [118976/620022]    Loss: 0.011308   Batch Acc: 68.75
[Train] Epoch: 1 [119040/620022]    Loss: 0.012214   Batch Acc: 64.06
[Train] Epoch: 1 [119104/620022]    Loss: 0.009233   Batch Acc: 79.69
[Train] Epoch: 1 [119168/620022]    Loss: 0.008292   Batch Acc: 78.12
[Train] Epoch: 1 [119232/620022]    Loss: 0.007976   Batch Acc: 76.56
[Train] Epoch: 1 [119296/620022]    Loss: 0.009892   Batch Acc: 71.88
[Train] Epoch: 1 [119360/620022]    Loss: 0.008257   Batch Acc: 79.69
[Train] Epoch: 1 [119424/620022]    Loss: 0.009534   Batch Acc: 76.56
[Train] Epoch: 1 [119488/620022]    Loss: 0.009115   Batch Acc: 75.00
[Train] Epoch: 1 [119552/620022]    Loss: 0.007792   Batch Acc: 82.81
[Train] Epoch: 1 [119616/620022]    Loss: 0.008496   Batch Acc: 81.25
[Train] Epoch: 1 [119680/620022]    Loss: 0.012943   Batch Acc: 62.50
[Train] Epoch: 1 [119744/620022]    Loss: 0.007290   Batch Acc: 84.38
[Train] Epoch: 1 [119808/620022]    Loss: 0.008450   Batch Acc: 76.56
[Train] Epoch: 1 [119872/620022]    Loss: 0.009444   Batch Acc: 78.12
[Train] Epoch: 1 [119936/620022]    Loss: 0.010450   Batch Acc: 68.75
[Train] Epoch: 1 [120000/620022]    Loss: 0.008227   Batch Acc: 79.69
[Train] Epoch: 1 [120064/620022]    Loss: 0.010822   Batch Acc: 70.31
[Train] Epoch: 1 [120128/620022]    Loss: 0.010968   Batch Acc: 73.44
[Train] Epoch: 1 [120192/620022]    Loss: 0.009916   Batch Acc: 75.00
[Train] Epoch: 1 [120256/620022]    Loss: 0.010108   Batch Acc: 68.75
[Train] Epoch: 1 [120320/620022]    Loss: 0.005590   Batch Acc: 90.62
[Train] Epoch: 1 [120384/620022]    Loss: 0.010896   Batch Acc: 76.56
[Train] Epoch: 1 [120448/620022]    Loss: 0.009041   Batch Acc: 76.56
[Train] Epoch: 1 [120512/620022]    Loss: 0.006662   Batch Acc: 84.38
[Train] Epoch: 1 [120576/620022]    Loss: 0.006747   Batch Acc: 84.38
[Train] Epoch: 1 [120640/620022]    Loss: 0.007342   Batch Acc: 82.81
[Train] Epoch: 1 [120704/620022]    Loss: 0.008920   Batch Acc: 81.25
[Train] Epoch: 1 [120768/620022]    Loss: 0.007355   Batch Acc: 85.94
[Train] Epoch: 1 [120832/620022]    Loss: 0.008578   Batch Acc: 75.00
[Train] Epoch: 1 [120896/620022]    Loss: 0.010614   Batch Acc: 75.00
[Train] Epoch: 1 [120960/620022]    Loss: 0.008832   Batch Acc: 79.69
[Train] Epoch: 1 [121024/620022]    Loss: 0.008944   Batch Acc: 76.56
[Train] Epoch: 1 [121088/620022]    Loss: 0.010033   Batch Acc: 68.75
[Train] Epoch: 1 [121152/620022]    Loss: 0.006233   Batch Acc: 85.94
[Train] Epoch: 1 [121216/620022]    Loss: 0.008475   Batch Acc: 82.81
[Train] Epoch: 1 [121280/620022]    Loss: 0.007415   Batch Acc: 87.50
[Train] Epoch: 1 [121344/620022]    Loss: 0.008760   Batch Acc: 79.69
[Train] Epoch: 1 [121408/620022]    Loss: 0.010160   Batch Acc: 70.31
[Train] Epoch: 1 [121472/620022]    Loss: 0.008579   Batch Acc: 79.69
[Train] Epoch: 1 [121536/620022]    Loss: 0.008239   Batch Acc: 79.69
[Train] Epoch: 1 [121600/620022]    Loss: 0.007994   Batch Acc: 78.12
[Train] Epoch: 1 [121664/620022]    Loss: 0.009473   Batch Acc: 78.12
[Train] Epoch: 1 [121728/620022]    Loss: 0.009171   Batch Acc: 75.00
[Train] Epoch: 1 [121792/620022]    Loss: 0.008556   Batch Acc: 73.44
[Train] Epoch: 1 [121856/620022]    Loss: 0.007972   Batch Acc: 84.38
[Train] Epoch: 1 [121920/620022]    Loss: 0.008601   Batch Acc: 79.69
[Train] Epoch: 1 [121984/620022]    Loss: 0.007652   Batch Acc: 79.69
[Train] Epoch: 1 [122048/620022]    Loss: 0.010176   Batch Acc: 73.44
[Train] Epoch: 1 [122112/620022]    Loss: 0.008786   Batch Acc: 76.56
[Train] Epoch: 1 [122176/620022]    Loss: 0.009619   Batch Acc: 73.44
[Train] Epoch: 1 [122240/620022]    Loss: 0.008868   Batch Acc: 75.00
[Train] Epoch: 1 [122304/620022]    Loss: 0.009274   Batch Acc: 73.44
[Train] Epoch: 1 [122368/620022]    Loss: 0.008213   Batch Acc: 82.81
[Train] Epoch: 1 [122432/620022]    Loss: 0.009077   Batch Acc: 75.00
[Train] Epoch: 1 [122496/620022]    Loss: 0.010572   Batch Acc: 73.44
[Train] Epoch: 1 [122560/620022]    Loss: 0.010721   Batch Acc: 76.56
[Train] Epoch: 1 [122624/620022]    Loss: 0.009687   Batch Acc: 75.00
[Train] Epoch: 1 [122688/620022]    Loss: 0.006798   Batch Acc: 89.06
[Train] Epoch: 1 [122752/620022]    Loss: 0.008113   Batch Acc: 81.25
[Train] Epoch: 1 [122816/620022]    Loss: 0.007741   Batch Acc: 79.69
[Train] Epoch: 1 [122880/620022]    Loss: 0.010188   Batch Acc: 71.88
[Train] Epoch: 1 [122944/620022]    Loss: 0.007568   Batch Acc: 82.81
[Train] Epoch: 1 [123008/620022]    Loss: 0.007655   Batch Acc: 84.38
[Train] Epoch: 1 [123072/620022]    Loss: 0.009431   Batch Acc: 73.44
[Train] Epoch: 1 [123136/620022]    Loss: 0.007569   Batch Acc: 79.69
[Train] Epoch: 1 [123200/620022]    Loss: 0.012497   Batch Acc: 62.50
[Train] Epoch: 1 [123264/620022]    Loss: 0.007680   Batch Acc: 81.25
[Train] Epoch: 1 [123328/620022]    Loss: 0.005762   Batch Acc: 89.06
[Train] Epoch: 1 [123392/620022]    Loss: 0.010105   Batch Acc: 76.56
[Train] Epoch: 1 [123456/620022]    Loss: 0.010230   Batch Acc: 71.88
[Train] Epoch: 1 [123520/620022]    Loss: 0.007903   Batch Acc: 78.12
[Train] Epoch: 1 [123584/620022]    Loss: 0.008623   Batch Acc: 75.00
[Train] Epoch: 1 [123648/620022]    Loss: 0.010486   Batch Acc: 68.75
[Train] Epoch: 1 [123712/620022]    Loss: 0.011461   Batch Acc: 70.31
[Train] Epoch: 1 [123776/620022]    Loss: 0.010949   Batch Acc: 68.75
[Train] Epoch: 1 [123840/620022]    Loss: 0.010703   Batch Acc: 73.44
[Train] Epoch: 1 [123904/620022]    Loss: 0.008637   Batch Acc: 76.56
[Train] Epoch: 1 [123968/620022]    Loss: 0.007352   Batch Acc: 81.25
[Train] Epoch: 1 [124032/620022]    Loss: 0.008307   Batch Acc: 76.56
[Train] Epoch: 1 [124096/620022]    Loss: 0.008749   Batch Acc: 82.81
[Train] Epoch: 1 [124160/620022]    Loss: 0.008534   Batch Acc: 85.94
[Train] Epoch: 1 [124224/620022]    Loss: 0.008738   Batch Acc: 78.12
[Train] Epoch: 1 [124288/620022]    Loss: 0.007878   Batch Acc: 78.12
[Train] Epoch: 1 [124352/620022]    Loss: 0.008298   Batch Acc: 78.12
[Train] Epoch: 1 [124416/620022]    Loss: 0.008611   Batch Acc: 82.81
[Train] Epoch: 1 [124480/620022]    Loss: 0.006955   Batch Acc: 79.69
[Train] Epoch: 1 [124544/620022]    Loss: 0.008090   Batch Acc: 79.69
[Train] Epoch: 1 [124608/620022]    Loss: 0.008196   Batch Acc: 79.69
[Train] Epoch: 1 [124672/620022]    Loss: 0.009110   Batch Acc: 70.31
[Train] Epoch: 1 [124736/620022]    Loss: 0.008663   Batch Acc: 71.88
[Train] Epoch: 1 [124800/620022]    Loss: 0.009686   Batch Acc: 73.44
[Train] Epoch: 1 [124864/620022]    Loss: 0.009772   Batch Acc: 68.75
[Train] Epoch: 1 [124928/620022]    Loss: 0.010237   Batch Acc: 75.00
[Train] Epoch: 1 [124992/620022]    Loss: 0.007491   Batch Acc: 84.38
[Train] Epoch: 1 [125056/620022]    Loss: 0.008139   Batch Acc: 79.69
[Train] Epoch: 1 [125120/620022]    Loss: 0.007699   Batch Acc: 79.69
[Train] Epoch: 1 [125184/620022]    Loss: 0.008266   Batch Acc: 75.00
[Train] Epoch: 1 [125248/620022]    Loss: 0.009204   Batch Acc: 75.00
[Train] Epoch: 1 [125312/620022]    Loss: 0.009121   Batch Acc: 81.25
[Train] Epoch: 1 [125376/620022]    Loss: 0.009219   Batch Acc: 75.00
[Train] Epoch: 1 [125440/620022]    Loss: 0.009146   Batch Acc: 75.00
[Train] Epoch: 1 [125504/620022]    Loss: 0.008193   Batch Acc: 82.81
[Train] Epoch: 1 [125568/620022]    Loss: 0.008595   Batch Acc: 75.00
[Train] Epoch: 1 [125632/620022]    Loss: 0.008913   Batch Acc: 75.00
[Train] Epoch: 1 [125696/620022]    Loss: 0.010197   Batch Acc: 76.56
[Train] Epoch: 1 [125760/620022]    Loss: 0.007944   Batch Acc: 79.69
[Train] Epoch: 1 [125824/620022]    Loss: 0.008521   Batch Acc: 75.00
[Train] Epoch: 1 [125888/620022]    Loss: 0.009027   Batch Acc: 76.56
[Train] Epoch: 1 [125952/620022]    Loss: 0.007090   Batch Acc: 84.38
[Train] Epoch: 1 [126016/620022]    Loss: 0.009531   Batch Acc: 76.56
[Train] Epoch: 1 [126080/620022]    Loss: 0.007619   Batch Acc: 85.94
[Train] Epoch: 1 [126144/620022]    Loss: 0.008836   Batch Acc: 78.12
[Train] Epoch: 1 [126208/620022]    Loss: 0.009025   Batch Acc: 73.44
[Train] Epoch: 1 [126272/620022]    Loss: 0.009129   Batch Acc: 78.12
[Train] Epoch: 1 [126336/620022]    Loss: 0.008004   Batch Acc: 81.25
[Train] Epoch: 1 [126400/620022]    Loss: 0.009947   Batch Acc: 71.88
[Train] Epoch: 1 [126464/620022]    Loss: 0.007174   Batch Acc: 82.81
[Train] Epoch: 1 [126528/620022]    Loss: 0.009843   Batch Acc: 76.56
[Train] Epoch: 1 [126592/620022]    Loss: 0.007490   Batch Acc: 78.12
[Train] Epoch: 1 [126656/620022]    Loss: 0.009833   Batch Acc: 73.44
[Train] Epoch: 1 [126720/620022]    Loss: 0.010112   Batch Acc: 73.44
[Train] Epoch: 1 [126784/620022]    Loss: 0.008991   Batch Acc: 76.56
[Train] Epoch: 1 [126848/620022]    Loss: 0.010368   Batch Acc: 75.00
[Train] Epoch: 1 [126912/620022]    Loss: 0.008068   Batch Acc: 81.25
[Train] Epoch: 1 [126976/620022]    Loss: 0.008541   Batch Acc: 78.12
[Train] Epoch: 1 [127040/620022]    Loss: 0.008677   Batch Acc: 81.25
[Train] Epoch: 1 [127104/620022]    Loss: 0.009684   Batch Acc: 76.56
[Train] Epoch: 1 [127168/620022]    Loss: 0.008401   Batch Acc: 79.69
[Train] Epoch: 1 [127232/620022]    Loss: 0.009801   Batch Acc: 79.69
[Train] Epoch: 1 [127296/620022]    Loss: 0.008752   Batch Acc: 78.12
[Train] Epoch: 1 [127360/620022]    Loss: 0.009500   Batch Acc: 73.44
[Train] Epoch: 1 [127424/620022]    Loss: 0.011621   Batch Acc: 64.06
[Train] Epoch: 1 [127488/620022]    Loss: 0.008108   Batch Acc: 82.81
[Train] Epoch: 1 [127552/620022]    Loss: 0.010162   Batch Acc: 71.88
[Train] Epoch: 1 [127616/620022]    Loss: 0.007314   Batch Acc: 82.81
[Train] Epoch: 1 [127680/620022]    Loss: 0.007143   Batch Acc: 84.38
[Train] Epoch: 1 [127744/620022]    Loss: 0.009550   Batch Acc: 76.56
[Train] Epoch: 1 [127808/620022]    Loss: 0.008773   Batch Acc: 75.00
[Train] Epoch: 1 [127872/620022]    Loss: 0.008972   Batch Acc: 71.88
[Train] Epoch: 1 [127936/620022]    Loss: 0.009857   Batch Acc: 75.00
[Train] Epoch: 1 [128000/620022]    Loss: 0.008253   Batch Acc: 79.69
[Train] Epoch: 1 [128064/620022]    Loss: 0.009418   Batch Acc: 79.69
[Train] Epoch: 1 [128128/620022]    Loss: 0.006067   Batch Acc: 89.06
[Train] Epoch: 1 [128192/620022]    Loss: 0.009539   Batch Acc: 75.00
[Train] Epoch: 1 [128256/620022]    Loss: 0.008249   Batch Acc: 79.69
[Train] Epoch: 1 [128320/620022]    Loss: 0.008436   Batch Acc: 81.25
[Train] Epoch: 1 [128384/620022]    Loss: 0.008472   Batch Acc: 81.25
[Train] Epoch: 1 [128448/620022]    Loss: 0.009207   Batch Acc: 73.44
[Train] Epoch: 1 [128512/620022]    Loss: 0.007612   Batch Acc: 79.69
[Train] Epoch: 1 [128576/620022]    Loss: 0.009337   Batch Acc: 75.00
[Train] Epoch: 1 [128640/620022]    Loss: 0.006740   Batch Acc: 85.94
[Train] Epoch: 1 [128704/620022]    Loss: 0.010059   Batch Acc: 78.12
[Train] Epoch: 1 [128768/620022]    Loss: 0.007466   Batch Acc: 79.69
[Train] Epoch: 1 [128832/620022]    Loss: 0.008112   Batch Acc: 79.69
[Train] Epoch: 1 [128896/620022]    Loss: 0.007757   Batch Acc: 82.81
[Train] Epoch: 1 [128960/620022]    Loss: 0.008477   Batch Acc: 76.56
[Train] Epoch: 1 [129024/620022]    Loss: 0.009752   Batch Acc: 76.56
[Train] Epoch: 1 [129088/620022]    Loss: 0.007777   Batch Acc: 79.69
[Train] Epoch: 1 [129152/620022]    Loss: 0.008655   Batch Acc: 79.69
[Train] Epoch: 1 [129216/620022]    Loss: 0.010304   Batch Acc: 71.88
[Train] Epoch: 1 [129280/620022]    Loss: 0.007569   Batch Acc: 76.56
[Train] Epoch: 1 [129344/620022]    Loss: 0.006905   Batch Acc: 82.81
[Train] Epoch: 1 [129408/620022]    Loss: 0.007767   Batch Acc: 78.12
[Train] Epoch: 1 [129472/620022]    Loss: 0.008714   Batch Acc: 81.25
[Train] Epoch: 1 [129536/620022]    Loss: 0.009414   Batch Acc: 75.00
[Train] Epoch: 1 [129600/620022]    Loss: 0.008396   Batch Acc: 78.12
[Train] Epoch: 1 [129664/620022]    Loss: 0.008848   Batch Acc: 78.12
[Train] Epoch: 1 [129728/620022]    Loss: 0.010090   Batch Acc: 71.88
[Train] Epoch: 1 [129792/620022]    Loss: 0.009908   Batch Acc: 70.31
[Train] Epoch: 1 [129856/620022]    Loss: 0.006643   Batch Acc: 87.50
[Train] Epoch: 1 [129920/620022]    Loss: 0.010878   Batch Acc: 73.44
[Train] Epoch: 1 [129984/620022]    Loss: 0.008019   Batch Acc: 81.25
[Train] Epoch: 1 [130048/620022]    Loss: 0.008480   Batch Acc: 76.56
[Train] Epoch: 1 [130112/620022]    Loss: 0.008333   Batch Acc: 79.69
[Train] Epoch: 1 [130176/620022]    Loss: 0.009001   Batch Acc: 81.25
[Train] Epoch: 1 [130240/620022]    Loss: 0.008290   Batch Acc: 84.38
[Train] Epoch: 1 [130304/620022]    Loss: 0.007777   Batch Acc: 84.38
[Train] Epoch: 1 [130368/620022]    Loss: 0.009776   Batch Acc: 78.12
[Train] Epoch: 1 [130432/620022]    Loss: 0.008160   Batch Acc: 82.81
[Train] Epoch: 1 [130496/620022]    Loss: 0.007401   Batch Acc: 79.69
[Train] Epoch: 1 [130560/620022]    Loss: 0.007678   Batch Acc: 78.12
[Train] Epoch: 1 [130624/620022]    Loss: 0.009938   Batch Acc: 75.00
[Train] Epoch: 1 [130688/620022]    Loss: 0.009723   Batch Acc: 76.56
[Train] Epoch: 1 [130752/620022]    Loss: 0.008243   Batch Acc: 79.69
[Train] Epoch: 1 [130816/620022]    Loss: 0.006085   Batch Acc: 84.38
[Train] Epoch: 1 [130880/620022]    Loss: 0.009004   Batch Acc: 76.56
[Train] Epoch: 1 [130944/620022]    Loss: 0.010362   Batch Acc: 75.00
[Train] Epoch: 1 [131008/620022]    Loss: 0.008139   Batch Acc: 78.12
[Train] Epoch: 1 [131072/620022]    Loss: 0.008930   Batch Acc: 82.81
[Train] Epoch: 1 [131136/620022]    Loss: 0.008975   Batch Acc: 73.44
[Train] Epoch: 1 [131200/620022]    Loss: 0.010445   Batch Acc: 65.62
[Train] Epoch: 1 [131264/620022]    Loss: 0.007982   Batch Acc: 84.38
[Train] Epoch: 1 [131328/620022]    Loss: 0.007533   Batch Acc: 82.81
[Train] Epoch: 1 [131392/620022]    Loss: 0.008408   Batch Acc: 82.81
[Train] Epoch: 1 [131456/620022]    Loss: 0.008105   Batch Acc: 79.69
[Train] Epoch: 1 [131520/620022]    Loss: 0.008955   Batch Acc: 78.12
[Train] Epoch: 1 [131584/620022]    Loss: 0.007733   Batch Acc: 82.81
[Train] Epoch: 1 [131648/620022]    Loss: 0.008752   Batch Acc: 81.25
[Train] Epoch: 1 [131712/620022]    Loss: 0.009455   Batch Acc: 68.75
[Train] Epoch: 1 [131776/620022]    Loss: 0.008355   Batch Acc: 84.38
[Train] Epoch: 1 [131840/620022]    Loss: 0.008547   Batch Acc: 78.12
[Train] Epoch: 1 [131904/620022]    Loss: 0.009456   Batch Acc: 73.44
[Train] Epoch: 1 [131968/620022]    Loss: 0.006931   Batch Acc: 87.50
[Train] Epoch: 1 [132032/620022]    Loss: 0.007715   Batch Acc: 76.56
[Train] Epoch: 1 [132096/620022]    Loss: 0.009713   Batch Acc: 71.88
[Train] Epoch: 1 [132160/620022]    Loss: 0.007722   Batch Acc: 81.25
[Train] Epoch: 1 [132224/620022]    Loss: 0.007974   Batch Acc: 78.12
[Train] Epoch: 1 [132288/620022]    Loss: 0.006933   Batch Acc: 82.81
[Train] Epoch: 1 [132352/620022]    Loss: 0.008914   Batch Acc: 75.00
[Train] Epoch: 1 [132416/620022]    Loss: 0.009677   Batch Acc: 73.44
[Train] Epoch: 1 [132480/620022]    Loss: 0.005764   Batch Acc: 87.50
[Train] Epoch: 1 [132544/620022]    Loss: 0.007104   Batch Acc: 79.69
[Train] Epoch: 1 [132608/620022]    Loss: 0.008579   Batch Acc: 81.25
[Train] Epoch: 1 [132672/620022]    Loss: 0.007561   Batch Acc: 78.12
[Train] Epoch: 1 [132736/620022]    Loss: 0.010146   Batch Acc: 75.00
[Train] Epoch: 1 [132800/620022]    Loss: 0.007471   Batch Acc: 81.25
[Train] Epoch: 1 [132864/620022]    Loss: 0.010096   Batch Acc: 73.44
[Train] Epoch: 1 [132928/620022]    Loss: 0.008734   Batch Acc: 76.56
[Train] Epoch: 1 [132992/620022]    Loss: 0.006260   Batch Acc: 90.62
[Train] Epoch: 1 [133056/620022]    Loss: 0.009501   Batch Acc: 71.88
[Train] Epoch: 1 [133120/620022]    Loss: 0.009562   Batch Acc: 78.12
[Train] Epoch: 1 [133184/620022]    Loss: 0.007578   Batch Acc: 79.69
[Train] Epoch: 1 [133248/620022]    Loss: 0.008192   Batch Acc: 78.12
[Train] Epoch: 1 [133312/620022]    Loss: 0.007567   Batch Acc: 82.81
[Train] Epoch: 1 [133376/620022]    Loss: 0.010399   Batch Acc: 68.75
[Train] Epoch: 1 [133440/620022]    Loss: 0.007916   Batch Acc: 84.38
[Train] Epoch: 1 [133504/620022]    Loss: 0.010235   Batch Acc: 73.44
[Train] Epoch: 1 [133568/620022]    Loss: 0.008867   Batch Acc: 78.12
[Train] Epoch: 1 [133632/620022]    Loss: 0.007341   Batch Acc: 79.69
[Train] Epoch: 1 [133696/620022]    Loss: 0.010197   Batch Acc: 71.88
[Train] Epoch: 1 [133760/620022]    Loss: 0.009635   Batch Acc: 75.00
[Train] Epoch: 1 [133824/620022]    Loss: 0.008286   Batch Acc: 78.12
[Train] Epoch: 1 [133888/620022]    Loss: 0.006895   Batch Acc: 82.81
[Train] Epoch: 1 [133952/620022]    Loss: 0.008501   Batch Acc: 75.00
[Train] Epoch: 1 [134016/620022]    Loss: 0.008110   Batch Acc: 81.25
[Train] Epoch: 1 [134080/620022]    Loss: 0.009926   Batch Acc: 75.00
[Train] Epoch: 1 [134144/620022]    Loss: 0.006652   Batch Acc: 82.81
[Train] Epoch: 1 [134208/620022]    Loss: 0.007949   Batch Acc: 87.50
[Train] Epoch: 1 [134272/620022]    Loss: 0.010724   Batch Acc: 70.31
[Train] Epoch: 1 [134336/620022]    Loss: 0.008753   Batch Acc: 78.12
[Train] Epoch: 1 [134400/620022]    Loss: 0.008995   Batch Acc: 76.56
[Train] Epoch: 1 [134464/620022]    Loss: 0.008450   Batch Acc: 82.81
[Train] Epoch: 1 [134528/620022]    Loss: 0.009254   Batch Acc: 76.56
[Train] Epoch: 1 [134592/620022]    Loss: 0.010220   Batch Acc: 73.44
[Train] Epoch: 1 [134656/620022]    Loss: 0.006002   Batch Acc: 82.81
[Train] Epoch: 1 [134720/620022]    Loss: 0.006664   Batch Acc: 81.25
[Train] Epoch: 1 [134784/620022]    Loss: 0.008849   Batch Acc: 79.69
[Train] Epoch: 1 [134848/620022]    Loss: 0.009407   Batch Acc: 70.31
[Train] Epoch: 1 [134912/620022]    Loss: 0.009869   Batch Acc: 70.31
[Train] Epoch: 1 [134976/620022]    Loss: 0.008476   Batch Acc: 79.69
[Train] Epoch: 1 [135040/620022]    Loss: 0.006896   Batch Acc: 81.25
[Train] Epoch: 1 [135104/620022]    Loss: 0.008103   Batch Acc: 78.12
[Train] Epoch: 1 [135168/620022]    Loss: 0.007620   Batch Acc: 78.12
[Train] Epoch: 1 [135232/620022]    Loss: 0.008890   Batch Acc: 85.94
[Train] Epoch: 1 [135296/620022]    Loss: 0.008211   Batch Acc: 79.69
[Train] Epoch: 1 [135360/620022]    Loss: 0.008734   Batch Acc: 76.56
[Train] Epoch: 1 [135424/620022]    Loss: 0.010152   Batch Acc: 78.12
[Train] Epoch: 1 [135488/620022]    Loss: 0.007696   Batch Acc: 78.12
[Train] Epoch: 1 [135552/620022]    Loss: 0.007686   Batch Acc: 81.25
[Train] Epoch: 1 [135616/620022]    Loss: 0.008805   Batch Acc: 76.56
[Train] Epoch: 1 [135680/620022]    Loss: 0.007716   Batch Acc: 79.69
[Train] Epoch: 1 [135744/620022]    Loss: 0.007908   Batch Acc: 82.81
[Train] Epoch: 1 [135808/620022]    Loss: 0.009535   Batch Acc: 76.56
[Train] Epoch: 1 [135872/620022]    Loss: 0.009136   Batch Acc: 78.12
[Train] Epoch: 1 [135936/620022]    Loss: 0.007895   Batch Acc: 81.25
[Train] Epoch: 1 [136000/620022]    Loss: 0.008605   Batch Acc: 79.69
[Train] Epoch: 1 [136064/620022]    Loss: 0.008050   Batch Acc: 78.12
[Train] Epoch: 1 [136128/620022]    Loss: 0.005319   Batch Acc: 92.19
[Train] Epoch: 1 [136192/620022]    Loss: 0.007870   Batch Acc: 82.81
[Train] Epoch: 1 [136256/620022]    Loss: 0.009584   Batch Acc: 71.88
[Train] Epoch: 1 [136320/620022]    Loss: 0.009066   Batch Acc: 76.56
[Train] Epoch: 1 [136384/620022]    Loss: 0.009300   Batch Acc: 81.25
[Train] Epoch: 1 [136448/620022]    Loss: 0.007977   Batch Acc: 79.69
[Train] Epoch: 1 [136512/620022]    Loss: 0.008261   Batch Acc: 78.12
[Train] Epoch: 1 [136576/620022]    Loss: 0.007614   Batch Acc: 81.25
[Train] Epoch: 1 [136640/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 1 [136704/620022]    Loss: 0.006891   Batch Acc: 81.25
[Train] Epoch: 1 [136768/620022]    Loss: 0.008936   Batch Acc: 70.31
[Train] Epoch: 1 [136832/620022]    Loss: 0.008467   Batch Acc: 81.25
[Train] Epoch: 1 [136896/620022]    Loss: 0.011689   Batch Acc: 68.75
[Train] Epoch: 1 [136960/620022]    Loss: 0.009166   Batch Acc: 81.25
[Train] Epoch: 1 [137024/620022]    Loss: 0.007858   Batch Acc: 85.94
[Train] Epoch: 1 [137088/620022]    Loss: 0.008681   Batch Acc: 78.12
[Train] Epoch: 1 [137152/620022]    Loss: 0.007741   Batch Acc: 78.12
[Train] Epoch: 1 [137216/620022]    Loss: 0.009097   Batch Acc: 73.44
[Train] Epoch: 1 [137280/620022]    Loss: 0.009067   Batch Acc: 76.56
[Train] Epoch: 1 [137344/620022]    Loss: 0.007439   Batch Acc: 82.81
[Train] Epoch: 1 [137408/620022]    Loss: 0.009029   Batch Acc: 75.00
[Train] Epoch: 1 [137472/620022]    Loss: 0.008124   Batch Acc: 73.44
[Train] Epoch: 1 [137536/620022]    Loss: 0.008306   Batch Acc: 82.81
[Train] Epoch: 1 [137600/620022]    Loss: 0.007270   Batch Acc: 84.38
[Train] Epoch: 1 [137664/620022]    Loss: 0.008359   Batch Acc: 78.12
[Train] Epoch: 1 [137728/620022]    Loss: 0.006969   Batch Acc: 84.38
[Train] Epoch: 1 [137792/620022]    Loss: 0.007764   Batch Acc: 76.56
[Train] Epoch: 1 [137856/620022]    Loss: 0.008459   Batch Acc: 82.81
[Train] Epoch: 1 [137920/620022]    Loss: 0.009293   Batch Acc: 78.12
[Train] Epoch: 1 [137984/620022]    Loss: 0.010515   Batch Acc: 65.62
[Train] Epoch: 1 [138048/620022]    Loss: 0.009206   Batch Acc: 75.00
[Train] Epoch: 1 [138112/620022]    Loss: 0.009955   Batch Acc: 76.56
[Train] Epoch: 1 [138176/620022]    Loss: 0.009027   Batch Acc: 75.00
[Train] Epoch: 1 [138240/620022]    Loss: 0.009835   Batch Acc: 75.00
[Train] Epoch: 1 [138304/620022]    Loss: 0.009318   Batch Acc: 76.56
[Train] Epoch: 1 [138368/620022]    Loss: 0.007282   Batch Acc: 81.25
[Train] Epoch: 1 [138432/620022]    Loss: 0.006589   Batch Acc: 84.38
[Train] Epoch: 1 [138496/620022]    Loss: 0.010551   Batch Acc: 68.75
[Train] Epoch: 1 [138560/620022]    Loss: 0.011768   Batch Acc: 67.19
[Train] Epoch: 1 [138624/620022]    Loss: 0.007841   Batch Acc: 78.12
[Train] Epoch: 1 [138688/620022]    Loss: 0.008625   Batch Acc: 82.81
[Train] Epoch: 1 [138752/620022]    Loss: 0.006700   Batch Acc: 90.62
[Train] Epoch: 1 [138816/620022]    Loss: 0.008731   Batch Acc: 75.00
[Train] Epoch: 1 [138880/620022]    Loss: 0.009569   Batch Acc: 73.44
[Train] Epoch: 1 [138944/620022]    Loss: 0.008816   Batch Acc: 81.25
[Train] Epoch: 1 [139008/620022]    Loss: 0.008685   Batch Acc: 84.38
[Train] Epoch: 1 [139072/620022]    Loss: 0.008691   Batch Acc: 75.00
[Train] Epoch: 1 [139136/620022]    Loss: 0.008735   Batch Acc: 75.00
[Train] Epoch: 1 [139200/620022]    Loss: 0.010238   Batch Acc: 75.00
[Train] Epoch: 1 [139264/620022]    Loss: 0.011769   Batch Acc: 67.19
[Train] Epoch: 1 [139328/620022]    Loss: 0.006731   Batch Acc: 84.38
[Train] Epoch: 1 [139392/620022]    Loss: 0.009351   Batch Acc: 75.00
[Train] Epoch: 1 [139456/620022]    Loss: 0.006445   Batch Acc: 87.50
[Train] Epoch: 1 [139520/620022]    Loss: 0.008378   Batch Acc: 75.00
[Train] Epoch: 1 [139584/620022]    Loss: 0.009864   Batch Acc: 71.88
[Train] Epoch: 1 [139648/620022]    Loss: 0.007796   Batch Acc: 76.56
[Train] Epoch: 1 [139712/620022]    Loss: 0.009078   Batch Acc: 76.56
[Train] Epoch: 1 [139776/620022]    Loss: 0.009617   Batch Acc: 79.69
[Train] Epoch: 1 [139840/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 1 [139904/620022]    Loss: 0.007858   Batch Acc: 78.12
[Train] Epoch: 1 [139968/620022]    Loss: 0.011312   Batch Acc: 64.06
[Train] Epoch: 1 [140032/620022]    Loss: 0.009694   Batch Acc: 70.31
[Train] Epoch: 1 [140096/620022]    Loss: 0.006422   Batch Acc: 87.50
[Train] Epoch: 1 [140160/620022]    Loss: 0.009129   Batch Acc: 70.31
[Train] Epoch: 1 [140224/620022]    Loss: 0.008833   Batch Acc: 82.81
[Train] Epoch: 1 [140288/620022]    Loss: 0.009668   Batch Acc: 70.31
[Train] Epoch: 1 [140352/620022]    Loss: 0.009226   Batch Acc: 82.81
[Train] Epoch: 1 [140416/620022]    Loss: 0.006247   Batch Acc: 84.38
[Train] Epoch: 1 [140480/620022]    Loss: 0.008328   Batch Acc: 85.94
[Train] Epoch: 1 [140544/620022]    Loss: 0.007979   Batch Acc: 81.25
[Train] Epoch: 1 [140608/620022]    Loss: 0.007758   Batch Acc: 76.56
[Train] Epoch: 1 [140672/620022]    Loss: 0.008681   Batch Acc: 78.12
[Train] Epoch: 1 [140736/620022]    Loss: 0.008279   Batch Acc: 73.44
[Train] Epoch: 1 [140800/620022]    Loss: 0.008327   Batch Acc: 82.81
[Train] Epoch: 1 [140864/620022]    Loss: 0.009777   Batch Acc: 73.44
[Train] Epoch: 1 [140928/620022]    Loss: 0.012344   Batch Acc: 67.19
[Train] Epoch: 1 [140992/620022]    Loss: 0.007186   Batch Acc: 82.81
[Train] Epoch: 1 [141056/620022]    Loss: 0.009986   Batch Acc: 71.88
[Train] Epoch: 1 [141120/620022]    Loss: 0.007805   Batch Acc: 78.12
[Train] Epoch: 1 [141184/620022]    Loss: 0.007891   Batch Acc: 81.25
[Train] Epoch: 1 [141248/620022]    Loss: 0.008755   Batch Acc: 71.88
[Train] Epoch: 1 [141312/620022]    Loss: 0.009710   Batch Acc: 75.00
[Train] Epoch: 1 [141376/620022]    Loss: 0.008990   Batch Acc: 75.00
[Train] Epoch: 1 [141440/620022]    Loss: 0.008509   Batch Acc: 81.25
[Train] Epoch: 1 [141504/620022]    Loss: 0.010718   Batch Acc: 73.44
[Train] Epoch: 1 [141568/620022]    Loss: 0.011473   Batch Acc: 70.31
[Train] Epoch: 1 [141632/620022]    Loss: 0.007808   Batch Acc: 84.38
[Train] Epoch: 1 [141696/620022]    Loss: 0.007808   Batch Acc: 79.69
[Train] Epoch: 1 [141760/620022]    Loss: 0.009785   Batch Acc: 75.00
[Train] Epoch: 1 [141824/620022]    Loss: 0.010328   Batch Acc: 73.44
[Train] Epoch: 1 [141888/620022]    Loss: 0.007276   Batch Acc: 81.25
[Train] Epoch: 1 [141952/620022]    Loss: 0.008116   Batch Acc: 75.00
[Train] Epoch: 1 [142016/620022]    Loss: 0.006588   Batch Acc: 85.94
[Train] Epoch: 1 [142080/620022]    Loss: 0.006459   Batch Acc: 82.81
[Train] Epoch: 1 [142144/620022]    Loss: 0.007721   Batch Acc: 81.25
[Train] Epoch: 1 [142208/620022]    Loss: 0.008255   Batch Acc: 75.00
[Train] Epoch: 1 [142272/620022]    Loss: 0.008463   Batch Acc: 79.69
[Train] Epoch: 1 [142336/620022]    Loss: 0.008897   Batch Acc: 68.75
[Train] Epoch: 1 [142400/620022]    Loss: 0.008904   Batch Acc: 78.12
[Train] Epoch: 1 [142464/620022]    Loss: 0.008032   Batch Acc: 79.69
[Train] Epoch: 1 [142528/620022]    Loss: 0.010521   Batch Acc: 73.44
[Train] Epoch: 1 [142592/620022]    Loss: 0.009662   Batch Acc: 70.31
[Train] Epoch: 1 [142656/620022]    Loss: 0.009792   Batch Acc: 76.56
[Train] Epoch: 1 [142720/620022]    Loss: 0.008989   Batch Acc: 76.56
[Train] Epoch: 1 [142784/620022]    Loss: 0.006393   Batch Acc: 82.81
[Train] Epoch: 1 [142848/620022]    Loss: 0.008886   Batch Acc: 79.69
[Train] Epoch: 1 [142912/620022]    Loss: 0.009553   Batch Acc: 79.69
[Train] Epoch: 1 [142976/620022]    Loss: 0.008656   Batch Acc: 82.81
[Train] Epoch: 1 [143040/620022]    Loss: 0.009610   Batch Acc: 75.00
[Train] Epoch: 1 [143104/620022]    Loss: 0.006202   Batch Acc: 87.50
[Train] Epoch: 1 [143168/620022]    Loss: 0.008482   Batch Acc: 79.69
[Train] Epoch: 1 [143232/620022]    Loss: 0.007904   Batch Acc: 84.38
[Train] Epoch: 1 [143296/620022]    Loss: 0.009654   Batch Acc: 70.31
[Train] Epoch: 1 [143360/620022]    Loss: 0.008558   Batch Acc: 78.12
[Train] Epoch: 1 [143424/620022]    Loss: 0.007640   Batch Acc: 79.69
[Train] Epoch: 1 [143488/620022]    Loss: 0.008479   Batch Acc: 78.12
[Train] Epoch: 1 [143552/620022]    Loss: 0.009916   Batch Acc: 71.88
[Train] Epoch: 1 [143616/620022]    Loss: 0.009073   Batch Acc: 76.56
[Train] Epoch: 1 [143680/620022]    Loss: 0.007734   Batch Acc: 78.12
[Train] Epoch: 1 [143744/620022]    Loss: 0.009481   Batch Acc: 76.56
[Train] Epoch: 1 [143808/620022]    Loss: 0.010499   Batch Acc: 71.88
[Train] Epoch: 1 [143872/620022]    Loss: 0.008311   Batch Acc: 73.44
[Train] Epoch: 1 [143936/620022]    Loss: 0.007348   Batch Acc: 79.69
[Train] Epoch: 1 [144000/620022]    Loss: 0.006692   Batch Acc: 84.38
[Train] Epoch: 1 [144064/620022]    Loss: 0.011097   Batch Acc: 71.88
[Train] Epoch: 1 [144128/620022]    Loss: 0.008011   Batch Acc: 81.25
[Train] Epoch: 1 [144192/620022]    Loss: 0.008233   Batch Acc: 76.56
[Train] Epoch: 1 [144256/620022]    Loss: 0.008046   Batch Acc: 81.25
[Train] Epoch: 1 [144320/620022]    Loss: 0.005888   Batch Acc: 85.94
[Train] Epoch: 1 [144384/620022]    Loss: 0.009677   Batch Acc: 76.56
[Train] Epoch: 1 [144448/620022]    Loss: 0.006507   Batch Acc: 85.94
[Train] Epoch: 1 [144512/620022]    Loss: 0.008702   Batch Acc: 75.00
[Train] Epoch: 1 [144576/620022]    Loss: 0.008188   Batch Acc: 81.25
[Train] Epoch: 1 [144640/620022]    Loss: 0.009092   Batch Acc: 82.81
[Train] Epoch: 1 [144704/620022]    Loss: 0.009469   Batch Acc: 75.00
[Train] Epoch: 1 [144768/620022]    Loss: 0.007245   Batch Acc: 81.25
[Train] Epoch: 1 [144832/620022]    Loss: 0.006805   Batch Acc: 84.38
[Train] Epoch: 1 [144896/620022]    Loss: 0.012815   Batch Acc: 64.06
[Train] Epoch: 1 [144960/620022]    Loss: 0.006103   Batch Acc: 87.50
[Train] Epoch: 1 [145024/620022]    Loss: 0.009185   Batch Acc: 73.44
[Train] Epoch: 1 [145088/620022]    Loss: 0.007270   Batch Acc: 84.38
[Train] Epoch: 1 [145152/620022]    Loss: 0.008871   Batch Acc: 81.25
[Train] Epoch: 1 [145216/620022]    Loss: 0.009238   Batch Acc: 71.88
[Train] Epoch: 1 [145280/620022]    Loss: 0.008462   Batch Acc: 82.81
[Train] Epoch: 1 [145344/620022]    Loss: 0.008758   Batch Acc: 79.69
[Train] Epoch: 1 [145408/620022]    Loss: 0.008417   Batch Acc: 78.12
[Train] Epoch: 1 [145472/620022]    Loss: 0.009427   Batch Acc: 76.56
[Train] Epoch: 1 [145536/620022]    Loss: 0.009892   Batch Acc: 68.75
[Train] Epoch: 1 [145600/620022]    Loss: 0.009846   Batch Acc: 73.44
[Train] Epoch: 1 [145664/620022]    Loss: 0.011920   Batch Acc: 73.44
[Train] Epoch: 1 [145728/620022]    Loss: 0.010894   Batch Acc: 73.44
[Train] Epoch: 1 [145792/620022]    Loss: 0.008338   Batch Acc: 84.38
[Train] Epoch: 1 [145856/620022]    Loss: 0.010349   Batch Acc: 68.75
[Train] Epoch: 1 [145920/620022]    Loss: 0.009606   Batch Acc: 70.31
[Train] Epoch: 1 [145984/620022]    Loss: 0.009730   Batch Acc: 71.88
[Train] Epoch: 1 [146048/620022]    Loss: 0.009574   Batch Acc: 76.56
[Train] Epoch: 1 [146112/620022]    Loss: 0.010178   Batch Acc: 68.75
[Train] Epoch: 1 [146176/620022]    Loss: 0.008411   Batch Acc: 79.69
[Train] Epoch: 1 [146240/620022]    Loss: 0.008537   Batch Acc: 79.69
[Train] Epoch: 1 [146304/620022]    Loss: 0.009812   Batch Acc: 71.88
[Train] Epoch: 1 [146368/620022]    Loss: 0.010815   Batch Acc: 68.75
[Train] Epoch: 1 [146432/620022]    Loss: 0.006680   Batch Acc: 87.50
[Train] Epoch: 1 [146496/620022]    Loss: 0.011087   Batch Acc: 71.88
[Train] Epoch: 1 [146560/620022]    Loss: 0.008828   Batch Acc: 81.25
[Train] Epoch: 1 [146624/620022]    Loss: 0.008491   Batch Acc: 79.69
[Train] Epoch: 1 [146688/620022]    Loss: 0.010885   Batch Acc: 70.31
[Train] Epoch: 1 [146752/620022]    Loss: 0.008220   Batch Acc: 78.12
[Train] Epoch: 1 [146816/620022]    Loss: 0.007929   Batch Acc: 82.81
[Train] Epoch: 1 [146880/620022]    Loss: 0.010169   Batch Acc: 73.44
[Train] Epoch: 1 [146944/620022]    Loss: 0.010829   Batch Acc: 65.62
[Train] Epoch: 1 [147008/620022]    Loss: 0.008399   Batch Acc: 78.12
[Train] Epoch: 1 [147072/620022]    Loss: 0.007745   Batch Acc: 81.25
[Train] Epoch: 1 [147136/620022]    Loss: 0.007662   Batch Acc: 81.25
[Train] Epoch: 1 [147200/620022]    Loss: 0.012304   Batch Acc: 64.06
[Train] Epoch: 1 [147264/620022]    Loss: 0.007089   Batch Acc: 81.25
[Train] Epoch: 1 [147328/620022]    Loss: 0.008158   Batch Acc: 84.38
[Train] Epoch: 1 [147392/620022]    Loss: 0.012149   Batch Acc: 76.56
[Train] Epoch: 1 [147456/620022]    Loss: 0.009727   Batch Acc: 78.12
[Train] Epoch: 1 [147520/620022]    Loss: 0.007623   Batch Acc: 75.00
[Train] Epoch: 1 [147584/620022]    Loss: 0.010659   Batch Acc: 71.88
[Train] Epoch: 1 [147648/620022]    Loss: 0.007875   Batch Acc: 79.69
[Train] Epoch: 1 [147712/620022]    Loss: 0.008207   Batch Acc: 78.12
[Train] Epoch: 1 [147776/620022]    Loss: 0.010656   Batch Acc: 71.88
[Train] Epoch: 1 [147840/620022]    Loss: 0.011054   Batch Acc: 76.56
[Train] Epoch: 1 [147904/620022]    Loss: 0.010806   Batch Acc: 70.31
[Train] Epoch: 1 [147968/620022]    Loss: 0.010297   Batch Acc: 75.00
[Train] Epoch: 1 [148032/620022]    Loss: 0.008546   Batch Acc: 73.44
[Train] Epoch: 1 [148096/620022]    Loss: 0.007897   Batch Acc: 81.25
[Train] Epoch: 1 [148160/620022]    Loss: 0.008854   Batch Acc: 75.00
[Train] Epoch: 1 [148224/620022]    Loss: 0.009483   Batch Acc: 70.31
[Train] Epoch: 1 [148288/620022]    Loss: 0.007191   Batch Acc: 81.25
[Train] Epoch: 1 [148352/620022]    Loss: 0.006404   Batch Acc: 82.81
[Train] Epoch: 1 [148416/620022]    Loss: 0.006952   Batch Acc: 84.38
[Train] Epoch: 1 [148480/620022]    Loss: 0.007945   Batch Acc: 79.69
[Train] Epoch: 1 [148544/620022]    Loss: 0.007865   Batch Acc: 79.69
[Train] Epoch: 1 [148608/620022]    Loss: 0.006748   Batch Acc: 82.81
[Train] Epoch: 1 [148672/620022]    Loss: 0.009984   Batch Acc: 70.31
[Train] Epoch: 1 [148736/620022]    Loss: 0.008279   Batch Acc: 78.12
[Train] Epoch: 1 [148800/620022]    Loss: 0.010062   Batch Acc: 73.44
[Train] Epoch: 1 [148864/620022]    Loss: 0.007570   Batch Acc: 78.12
[Train] Epoch: 1 [148928/620022]    Loss: 0.011388   Batch Acc: 67.19
[Train] Epoch: 1 [148992/620022]    Loss: 0.008937   Batch Acc: 82.81
[Train] Epoch: 1 [149056/620022]    Loss: 0.009477   Batch Acc: 73.44
[Train] Epoch: 1 [149120/620022]    Loss: 0.009213   Batch Acc: 73.44
[Train] Epoch: 1 [149184/620022]    Loss: 0.007840   Batch Acc: 82.81
[Train] Epoch: 1 [149248/620022]    Loss: 0.008264   Batch Acc: 75.00
[Train] Epoch: 1 [149312/620022]    Loss: 0.010778   Batch Acc: 70.31
[Train] Epoch: 1 [149376/620022]    Loss: 0.008286   Batch Acc: 79.69
[Train] Epoch: 1 [149440/620022]    Loss: 0.006489   Batch Acc: 82.81
[Train] Epoch: 1 [149504/620022]    Loss: 0.008319   Batch Acc: 73.44
[Train] Epoch: 1 [149568/620022]    Loss: 0.009076   Batch Acc: 75.00
[Train] Epoch: 1 [149632/620022]    Loss: 0.009183   Batch Acc: 79.69
[Train] Epoch: 1 [149696/620022]    Loss: 0.011773   Batch Acc: 68.75
[Train] Epoch: 1 [149760/620022]    Loss: 0.009680   Batch Acc: 75.00
[Train] Epoch: 1 [149824/620022]    Loss: 0.006028   Batch Acc: 87.50
[Train] Epoch: 1 [149888/620022]    Loss: 0.008153   Batch Acc: 78.12
[Train] Epoch: 1 [149952/620022]    Loss: 0.009629   Batch Acc: 76.56
[Train] Epoch: 1 [150016/620022]    Loss: 0.007351   Batch Acc: 85.94
[Train] Epoch: 1 [150080/620022]    Loss: 0.008489   Batch Acc: 78.12
[Train] Epoch: 1 [150144/620022]    Loss: 0.008861   Batch Acc: 79.69
[Train] Epoch: 1 [150208/620022]    Loss: 0.008762   Batch Acc: 76.56
[Train] Epoch: 1 [150272/620022]    Loss: 0.008668   Batch Acc: 75.00
[Train] Epoch: 1 [150336/620022]    Loss: 0.009373   Batch Acc: 68.75
[Train] Epoch: 1 [150400/620022]    Loss: 0.008175   Batch Acc: 76.56
[Train] Epoch: 1 [150464/620022]    Loss: 0.008058   Batch Acc: 82.81
[Train] Epoch: 1 [150528/620022]    Loss: 0.009487   Batch Acc: 76.56
[Train] Epoch: 1 [150592/620022]    Loss: 0.008745   Batch Acc: 82.81
[Train] Epoch: 1 [150656/620022]    Loss: 0.010273   Batch Acc: 76.56
[Train] Epoch: 1 [150720/620022]    Loss: 0.009297   Batch Acc: 79.69
[Train] Epoch: 1 [150784/620022]    Loss: 0.006998   Batch Acc: 82.81
[Train] Epoch: 1 [150848/620022]    Loss: 0.012350   Batch Acc: 70.31
[Train] Epoch: 1 [150912/620022]    Loss: 0.008294   Batch Acc: 82.81
[Train] Epoch: 1 [150976/620022]    Loss: 0.005999   Batch Acc: 89.06
[Train] Epoch: 1 [151040/620022]    Loss: 0.008221   Batch Acc: 79.69
[Train] Epoch: 1 [151104/620022]    Loss: 0.007454   Batch Acc: 81.25
[Train] Epoch: 1 [151168/620022]    Loss: 0.008683   Batch Acc: 79.69
[Train] Epoch: 1 [151232/620022]    Loss: 0.005948   Batch Acc: 87.50
[Train] Epoch: 1 [151296/620022]    Loss: 0.008810   Batch Acc: 82.81
[Train] Epoch: 1 [151360/620022]    Loss: 0.005422   Batch Acc: 90.62
[Train] Epoch: 1 [151424/620022]    Loss: 0.008713   Batch Acc: 84.38
[Train] Epoch: 1 [151488/620022]    Loss: 0.006568   Batch Acc: 84.38
[Train] Epoch: 1 [151552/620022]    Loss: 0.007227   Batch Acc: 82.81
[Train] Epoch: 1 [151616/620022]    Loss: 0.008822   Batch Acc: 84.38
[Train] Epoch: 1 [151680/620022]    Loss: 0.008125   Batch Acc: 79.69
[Train] Epoch: 1 [151744/620022]    Loss: 0.008916   Batch Acc: 79.69
[Train] Epoch: 1 [151808/620022]    Loss: 0.007914   Batch Acc: 81.25
[Train] Epoch: 1 [151872/620022]    Loss: 0.009489   Batch Acc: 75.00
[Train] Epoch: 1 [151936/620022]    Loss: 0.007212   Batch Acc: 84.38
[Train] Epoch: 1 [152000/620022]    Loss: 0.007828   Batch Acc: 81.25
[Train] Epoch: 1 [152064/620022]    Loss: 0.007980   Batch Acc: 75.00
[Train] Epoch: 1 [152128/620022]    Loss: 0.009715   Batch Acc: 75.00
[Train] Epoch: 1 [152192/620022]    Loss: 0.010773   Batch Acc: 76.56
[Train] Epoch: 1 [152256/620022]    Loss: 0.008542   Batch Acc: 82.81
[Train] Epoch: 1 [152320/620022]    Loss: 0.009402   Batch Acc: 81.25
[Train] Epoch: 1 [152384/620022]    Loss: 0.008281   Batch Acc: 81.25
[Train] Epoch: 1 [152448/620022]    Loss: 0.007514   Batch Acc: 78.12
[Train] Epoch: 1 [152512/620022]    Loss: 0.010745   Batch Acc: 67.19
[Train] Epoch: 1 [152576/620022]    Loss: 0.009922   Batch Acc: 76.56
[Train] Epoch: 1 [152640/620022]    Loss: 0.007392   Batch Acc: 78.12
[Train] Epoch: 1 [152704/620022]    Loss: 0.009661   Batch Acc: 75.00
[Train] Epoch: 1 [152768/620022]    Loss: 0.007418   Batch Acc: 82.81
[Train] Epoch: 1 [152832/620022]    Loss: 0.006562   Batch Acc: 85.94
[Train] Epoch: 1 [152896/620022]    Loss: 0.009368   Batch Acc: 71.88
[Train] Epoch: 1 [152960/620022]    Loss: 0.007654   Batch Acc: 78.12
[Train] Epoch: 1 [153024/620022]    Loss: 0.008548   Batch Acc: 76.56
[Train] Epoch: 1 [153088/620022]    Loss: 0.008126   Batch Acc: 76.56
[Train] Epoch: 1 [153152/620022]    Loss: 0.008342   Batch Acc: 78.12
[Train] Epoch: 1 [153216/620022]    Loss: 0.007365   Batch Acc: 81.25
[Train] Epoch: 1 [153280/620022]    Loss: 0.008504   Batch Acc: 78.12
[Train] Epoch: 1 [153344/620022]    Loss: 0.008579   Batch Acc: 73.44
[Train] Epoch: 1 [153408/620022]    Loss: 0.007857   Batch Acc: 81.25
[Train] Epoch: 1 [153472/620022]    Loss: 0.007646   Batch Acc: 84.38
[Train] Epoch: 1 [153536/620022]    Loss: 0.007186   Batch Acc: 78.12
[Train] Epoch: 1 [153600/620022]    Loss: 0.009359   Batch Acc: 76.56
[Train] Epoch: 1 [153664/620022]    Loss: 0.008855   Batch Acc: 85.94
[Train] Epoch: 1 [153728/620022]    Loss: 0.008036   Batch Acc: 81.25
[Train] Epoch: 1 [153792/620022]    Loss: 0.009445   Batch Acc: 73.44
[Train] Epoch: 1 [153856/620022]    Loss: 0.007616   Batch Acc: 85.94
[Train] Epoch: 1 [153920/620022]    Loss: 0.007015   Batch Acc: 84.38
[Train] Epoch: 1 [153984/620022]    Loss: 0.010363   Batch Acc: 68.75
[Train] Epoch: 1 [154048/620022]    Loss: 0.007575   Batch Acc: 82.81
[Train] Epoch: 1 [154112/620022]    Loss: 0.008674   Batch Acc: 79.69
[Train] Epoch: 1 [154176/620022]    Loss: 0.009326   Batch Acc: 75.00
[Train] Epoch: 1 [154240/620022]    Loss: 0.009699   Batch Acc: 73.44
[Train] Epoch: 1 [154304/620022]    Loss: 0.010366   Batch Acc: 71.88
[Train] Epoch: 1 [154368/620022]    Loss: 0.011910   Batch Acc: 75.00
[Train] Epoch: 1 [154432/620022]    Loss: 0.008959   Batch Acc: 75.00
[Train] Epoch: 1 [154496/620022]    Loss: 0.010150   Batch Acc: 76.56
[Train] Epoch: 1 [154560/620022]    Loss: 0.008318   Batch Acc: 76.56
[Train] Epoch: 1 [154624/620022]    Loss: 0.007715   Batch Acc: 79.69
[Train] Epoch: 1 [154688/620022]    Loss: 0.006793   Batch Acc: 81.25
[Train] Epoch: 1 [154752/620022]    Loss: 0.009792   Batch Acc: 78.12
[Train] Epoch: 1 [154816/620022]    Loss: 0.011304   Batch Acc: 70.31
[Train] Epoch: 1 [154880/620022]    Loss: 0.009915   Batch Acc: 76.56
[Train] Epoch: 1 [154944/620022]    Loss: 0.011248   Batch Acc: 67.19
[Train] Epoch: 1 [155008/620022]    Loss: 0.005751   Batch Acc: 85.94
[Train] Epoch: 1 [155072/620022]    Loss: 0.009578   Batch Acc: 76.56
[Train] Epoch: 1 [155136/620022]    Loss: 0.009196   Batch Acc: 75.00
[Train] Epoch: 1 [155200/620022]    Loss: 0.008144   Batch Acc: 81.25
[Train] Epoch: 1 [155264/620022]    Loss: 0.004697   Batch Acc: 89.06
[Train] Epoch: 1 [155328/620022]    Loss: 0.007292   Batch Acc: 81.25
[Train] Epoch: 1 [155392/620022]    Loss: 0.006790   Batch Acc: 84.38
[Train] Epoch: 1 [155456/620022]    Loss: 0.011623   Batch Acc: 73.44
[Train] Epoch: 1 [155520/620022]    Loss: 0.010796   Batch Acc: 68.75
[Train] Epoch: 1 [155584/620022]    Loss: 0.008142   Batch Acc: 78.12
[Train] Epoch: 1 [155648/620022]    Loss: 0.008142   Batch Acc: 73.44
[Train] Epoch: 1 [155712/620022]    Loss: 0.008283   Batch Acc: 84.38
[Train] Epoch: 1 [155776/620022]    Loss: 0.010927   Batch Acc: 71.88
[Train] Epoch: 1 [155840/620022]    Loss: 0.007513   Batch Acc: 78.12
[Train] Epoch: 1 [155904/620022]    Loss: 0.009386   Batch Acc: 70.31
[Train] Epoch: 1 [155968/620022]    Loss: 0.008550   Batch Acc: 84.38
[Train] Epoch: 1 [156032/620022]    Loss: 0.009672   Batch Acc: 79.69
[Train] Epoch: 1 [156096/620022]    Loss: 0.008600   Batch Acc: 78.12
[Train] Epoch: 1 [156160/620022]    Loss: 0.006909   Batch Acc: 87.50
[Train] Epoch: 1 [156224/620022]    Loss: 0.008254   Batch Acc: 78.12
[Train] Epoch: 1 [156288/620022]    Loss: 0.009257   Batch Acc: 76.56
[Train] Epoch: 1 [156352/620022]    Loss: 0.009175   Batch Acc: 75.00
[Train] Epoch: 1 [156416/620022]    Loss: 0.007989   Batch Acc: 85.94
[Train] Epoch: 1 [156480/620022]    Loss: 0.005763   Batch Acc: 89.06
[Train] Epoch: 1 [156544/620022]    Loss: 0.007400   Batch Acc: 84.38
[Train] Epoch: 1 [156608/620022]    Loss: 0.010262   Batch Acc: 73.44
[Train] Epoch: 1 [156672/620022]    Loss: 0.007746   Batch Acc: 84.38
[Train] Epoch: 1 [156736/620022]    Loss: 0.008852   Batch Acc: 73.44
[Train] Epoch: 1 [156800/620022]    Loss: 0.009142   Batch Acc: 79.69
[Train] Epoch: 1 [156864/620022]    Loss: 0.008658   Batch Acc: 79.69
[Train] Epoch: 1 [156928/620022]    Loss: 0.010058   Batch Acc: 70.31
[Train] Epoch: 1 [156992/620022]    Loss: 0.008656   Batch Acc: 79.69
[Train] Epoch: 1 [157056/620022]    Loss: 0.008704   Batch Acc: 78.12
[Train] Epoch: 1 [157120/620022]    Loss: 0.007325   Batch Acc: 81.25
[Train] Epoch: 1 [157184/620022]    Loss: 0.006722   Batch Acc: 84.38
[Train] Epoch: 1 [157248/620022]    Loss: 0.009036   Batch Acc: 75.00
[Train] Epoch: 1 [157312/620022]    Loss: 0.009177   Batch Acc: 73.44
[Train] Epoch: 1 [157376/620022]    Loss: 0.006894   Batch Acc: 82.81
[Train] Epoch: 1 [157440/620022]    Loss: 0.007505   Batch Acc: 82.81
[Train] Epoch: 1 [157504/620022]    Loss: 0.010926   Batch Acc: 68.75
[Train] Epoch: 1 [157568/620022]    Loss: 0.009032   Batch Acc: 71.88
[Train] Epoch: 1 [157632/620022]    Loss: 0.006735   Batch Acc: 82.81
[Train] Epoch: 1 [157696/620022]    Loss: 0.006577   Batch Acc: 82.81
[Train] Epoch: 1 [157760/620022]    Loss: 0.011386   Batch Acc: 70.31
[Train] Epoch: 1 [157824/620022]    Loss: 0.009947   Batch Acc: 75.00
[Train] Epoch: 1 [157888/620022]    Loss: 0.009910   Batch Acc: 73.44
[Train] Epoch: 1 [157952/620022]    Loss: 0.009312   Batch Acc: 73.44
[Train] Epoch: 1 [158016/620022]    Loss: 0.009160   Batch Acc: 68.75
[Train] Epoch: 1 [158080/620022]    Loss: 0.008407   Batch Acc: 82.81
[Train] Epoch: 1 [158144/620022]    Loss: 0.009124   Batch Acc: 78.12
[Train] Epoch: 1 [158208/620022]    Loss: 0.006985   Batch Acc: 81.25
[Train] Epoch: 1 [158272/620022]    Loss: 0.006382   Batch Acc: 93.75
[Train] Epoch: 1 [158336/620022]    Loss: 0.010494   Batch Acc: 71.88
[Train] Epoch: 1 [158400/620022]    Loss: 0.008536   Batch Acc: 75.00
[Train] Epoch: 1 [158464/620022]    Loss: 0.010454   Batch Acc: 70.31
[Train] Epoch: 1 [158528/620022]    Loss: 0.009559   Batch Acc: 71.88
[Train] Epoch: 1 [158592/620022]    Loss: 0.007987   Batch Acc: 85.94
[Train] Epoch: 1 [158656/620022]    Loss: 0.006474   Batch Acc: 82.81
[Train] Epoch: 1 [158720/620022]    Loss: 0.007004   Batch Acc: 78.12
[Train] Epoch: 1 [158784/620022]    Loss: 0.010744   Batch Acc: 70.31
[Train] Epoch: 1 [158848/620022]    Loss: 0.007229   Batch Acc: 78.12
[Train] Epoch: 1 [158912/620022]    Loss: 0.006068   Batch Acc: 89.06
[Train] Epoch: 1 [158976/620022]    Loss: 0.009272   Batch Acc: 82.81
[Train] Epoch: 1 [159040/620022]    Loss: 0.008669   Batch Acc: 75.00
[Train] Epoch: 1 [159104/620022]    Loss: 0.008703   Batch Acc: 78.12
[Train] Epoch: 1 [159168/620022]    Loss: 0.007247   Batch Acc: 82.81
[Train] Epoch: 1 [159232/620022]    Loss: 0.008861   Batch Acc: 75.00
[Train] Epoch: 1 [159296/620022]    Loss: 0.008629   Batch Acc: 76.56
[Train] Epoch: 1 [159360/620022]    Loss: 0.008745   Batch Acc: 76.56
[Train] Epoch: 1 [159424/620022]    Loss: 0.009884   Batch Acc: 70.31
[Train] Epoch: 1 [159488/620022]    Loss: 0.010711   Batch Acc: 70.31
[Train] Epoch: 1 [159552/620022]    Loss: 0.007990   Batch Acc: 79.69
[Train] Epoch: 1 [159616/620022]    Loss: 0.009459   Batch Acc: 75.00
[Train] Epoch: 1 [159680/620022]    Loss: 0.008914   Batch Acc: 79.69
[Train] Epoch: 1 [159744/620022]    Loss: 0.010238   Batch Acc: 75.00
[Train] Epoch: 1 [159808/620022]    Loss: 0.011735   Batch Acc: 64.06
[Train] Epoch: 1 [159872/620022]    Loss: 0.009133   Batch Acc: 75.00
[Train] Epoch: 1 [159936/620022]    Loss: 0.008567   Batch Acc: 81.25
[Train] Epoch: 1 [160000/620022]    Loss: 0.008464   Batch Acc: 71.88
[Train] Epoch: 1 [160064/620022]    Loss: 0.008214   Batch Acc: 78.12
[Train] Epoch: 1 [160128/620022]    Loss: 0.009700   Batch Acc: 75.00
[Train] Epoch: 1 [160192/620022]    Loss: 0.011598   Batch Acc: 71.88
[Train] Epoch: 1 [160256/620022]    Loss: 0.009338   Batch Acc: 76.56
[Train] Epoch: 1 [160320/620022]    Loss: 0.009302   Batch Acc: 73.44
[Train] Epoch: 1 [160384/620022]    Loss: 0.008916   Batch Acc: 78.12
[Train] Epoch: 1 [160448/620022]    Loss: 0.007546   Batch Acc: 79.69
[Train] Epoch: 1 [160512/620022]    Loss: 0.007399   Batch Acc: 78.12
[Train] Epoch: 1 [160576/620022]    Loss: 0.008129   Batch Acc: 75.00
[Train] Epoch: 1 [160640/620022]    Loss: 0.008179   Batch Acc: 78.12
[Train] Epoch: 1 [160704/620022]    Loss: 0.008158   Batch Acc: 84.38
[Train] Epoch: 1 [160768/620022]    Loss: 0.011378   Batch Acc: 75.00
[Train] Epoch: 1 [160832/620022]    Loss: 0.008603   Batch Acc: 81.25
[Train] Epoch: 1 [160896/620022]    Loss: 0.008849   Batch Acc: 78.12
[Train] Epoch: 1 [160960/620022]    Loss: 0.010237   Batch Acc: 75.00
[Train] Epoch: 1 [161024/620022]    Loss: 0.009067   Batch Acc: 78.12
[Train] Epoch: 1 [161088/620022]    Loss: 0.007386   Batch Acc: 81.25
[Train] Epoch: 1 [161152/620022]    Loss: 0.009338   Batch Acc: 78.12
[Train] Epoch: 1 [161216/620022]    Loss: 0.007741   Batch Acc: 75.00
[Train] Epoch: 1 [161280/620022]    Loss: 0.006815   Batch Acc: 81.25
[Train] Epoch: 1 [161344/620022]    Loss: 0.006606   Batch Acc: 81.25
[Train] Epoch: 1 [161408/620022]    Loss: 0.006927   Batch Acc: 82.81
[Train] Epoch: 1 [161472/620022]    Loss: 0.012519   Batch Acc: 65.62
[Train] Epoch: 1 [161536/620022]    Loss: 0.007059   Batch Acc: 84.38
[Train] Epoch: 1 [161600/620022]    Loss: 0.007912   Batch Acc: 75.00
[Train] Epoch: 1 [161664/620022]    Loss: 0.009212   Batch Acc: 70.31
[Train] Epoch: 1 [161728/620022]    Loss: 0.008439   Batch Acc: 78.12
[Train] Epoch: 1 [161792/620022]    Loss: 0.010412   Batch Acc: 73.44
[Train] Epoch: 1 [161856/620022]    Loss: 0.005986   Batch Acc: 87.50
[Train] Epoch: 1 [161920/620022]    Loss: 0.007955   Batch Acc: 76.56
[Train] Epoch: 1 [161984/620022]    Loss: 0.008139   Batch Acc: 73.44
[Train] Epoch: 1 [162048/620022]    Loss: 0.008796   Batch Acc: 76.56
[Train] Epoch: 1 [162112/620022]    Loss: 0.008420   Batch Acc: 81.25
[Train] Epoch: 1 [162176/620022]    Loss: 0.008484   Batch Acc: 78.12
[Train] Epoch: 1 [162240/620022]    Loss: 0.009919   Batch Acc: 73.44
[Train] Epoch: 1 [162304/620022]    Loss: 0.008756   Batch Acc: 76.56
[Train] Epoch: 1 [162368/620022]    Loss: 0.009453   Batch Acc: 78.12
[Train] Epoch: 1 [162432/620022]    Loss: 0.010470   Batch Acc: 71.88
[Train] Epoch: 1 [162496/620022]    Loss: 0.007474   Batch Acc: 82.81
[Train] Epoch: 1 [162560/620022]    Loss: 0.007336   Batch Acc: 82.81
[Train] Epoch: 1 [162624/620022]    Loss: 0.007390   Batch Acc: 81.25
[Train] Epoch: 1 [162688/620022]    Loss: 0.010335   Batch Acc: 73.44
[Train] Epoch: 1 [162752/620022]    Loss: 0.010227   Batch Acc: 78.12
[Train] Epoch: 1 [162816/620022]    Loss: 0.006501   Batch Acc: 87.50
[Train] Epoch: 1 [162880/620022]    Loss: 0.009944   Batch Acc: 73.44
[Train] Epoch: 1 [162944/620022]    Loss: 0.008532   Batch Acc: 76.56
[Train] Epoch: 1 [163008/620022]    Loss: 0.006533   Batch Acc: 89.06
[Train] Epoch: 1 [163072/620022]    Loss: 0.010718   Batch Acc: 68.75
[Train] Epoch: 1 [163136/620022]    Loss: 0.009614   Batch Acc: 71.88
[Train] Epoch: 1 [163200/620022]    Loss: 0.010145   Batch Acc: 76.56
[Train] Epoch: 1 [163264/620022]    Loss: 0.009773   Batch Acc: 75.00
[Train] Epoch: 1 [163328/620022]    Loss: 0.008975   Batch Acc: 81.25
[Train] Epoch: 1 [163392/620022]    Loss: 0.008953   Batch Acc: 76.56
[Train] Epoch: 1 [163456/620022]    Loss: 0.008537   Batch Acc: 78.12
[Train] Epoch: 1 [163520/620022]    Loss: 0.009482   Batch Acc: 75.00
[Train] Epoch: 1 [163584/620022]    Loss: 0.007665   Batch Acc: 87.50
[Train] Epoch: 1 [163648/620022]    Loss: 0.006984   Batch Acc: 87.50
[Train] Epoch: 1 [163712/620022]    Loss: 0.008378   Batch Acc: 78.12
[Train] Epoch: 1 [163776/620022]    Loss: 0.009822   Batch Acc: 73.44
[Train] Epoch: 1 [163840/620022]    Loss: 0.007323   Batch Acc: 82.81
[Train] Epoch: 1 [163904/620022]    Loss: 0.007866   Batch Acc: 76.56
[Train] Epoch: 1 [163968/620022]    Loss: 0.006557   Batch Acc: 84.38
[Train] Epoch: 1 [164032/620022]    Loss: 0.007717   Batch Acc: 79.69
[Train] Epoch: 1 [164096/620022]    Loss: 0.011666   Batch Acc: 73.44
[Train] Epoch: 1 [164160/620022]    Loss: 0.006868   Batch Acc: 82.81
[Train] Epoch: 1 [164224/620022]    Loss: 0.007816   Batch Acc: 82.81
[Train] Epoch: 1 [164288/620022]    Loss: 0.009350   Batch Acc: 71.88
[Train] Epoch: 1 [164352/620022]    Loss: 0.007163   Batch Acc: 81.25
[Train] Epoch: 1 [164416/620022]    Loss: 0.011042   Batch Acc: 75.00
[Train] Epoch: 1 [164480/620022]    Loss: 0.009575   Batch Acc: 73.44
[Train] Epoch: 1 [164544/620022]    Loss: 0.007892   Batch Acc: 79.69
[Train] Epoch: 1 [164608/620022]    Loss: 0.008080   Batch Acc: 81.25
[Train] Epoch: 1 [164672/620022]    Loss: 0.006838   Batch Acc: 89.06
[Train] Epoch: 1 [164736/620022]    Loss: 0.007158   Batch Acc: 84.38
[Train] Epoch: 1 [164800/620022]    Loss: 0.007540   Batch Acc: 79.69
[Train] Epoch: 1 [164864/620022]    Loss: 0.008734   Batch Acc: 82.81
[Train] Epoch: 1 [164928/620022]    Loss: 0.007833   Batch Acc: 84.38
[Train] Epoch: 1 [164992/620022]    Loss: 0.010024   Batch Acc: 71.88
[Train] Epoch: 1 [165056/620022]    Loss: 0.008120   Batch Acc: 78.12
[Train] Epoch: 1 [165120/620022]    Loss: 0.007051   Batch Acc: 87.50
[Train] Epoch: 1 [165184/620022]    Loss: 0.008641   Batch Acc: 81.25
[Train] Epoch: 1 [165248/620022]    Loss: 0.008010   Batch Acc: 79.69
[Train] Epoch: 1 [165312/620022]    Loss: 0.009157   Batch Acc: 76.56
[Train] Epoch: 1 [165376/620022]    Loss: 0.008486   Batch Acc: 75.00
[Train] Epoch: 1 [165440/620022]    Loss: 0.007837   Batch Acc: 81.25
[Train] Epoch: 1 [165504/620022]    Loss: 0.007942   Batch Acc: 81.25
[Train] Epoch: 1 [165568/620022]    Loss: 0.008623   Batch Acc: 78.12
[Train] Epoch: 1 [165632/620022]    Loss: 0.007987   Batch Acc: 75.00
[Train] Epoch: 1 [165696/620022]    Loss: 0.006644   Batch Acc: 85.94
[Train] Epoch: 1 [165760/620022]    Loss: 0.007205   Batch Acc: 81.25
[Train] Epoch: 1 [165824/620022]    Loss: 0.009343   Batch Acc: 76.56
[Train] Epoch: 1 [165888/620022]    Loss: 0.010205   Batch Acc: 73.44
[Train] Epoch: 1 [165952/620022]    Loss: 0.007175   Batch Acc: 76.56
[Train] Epoch: 1 [166016/620022]    Loss: 0.008139   Batch Acc: 82.81
[Train] Epoch: 1 [166080/620022]    Loss: 0.010109   Batch Acc: 70.31
[Train] Epoch: 1 [166144/620022]    Loss: 0.005809   Batch Acc: 89.06
[Train] Epoch: 1 [166208/620022]    Loss: 0.010055   Batch Acc: 71.88
[Train] Epoch: 1 [166272/620022]    Loss: 0.008629   Batch Acc: 75.00
[Train] Epoch: 1 [166336/620022]    Loss: 0.008430   Batch Acc: 78.12
[Train] Epoch: 1 [166400/620022]    Loss: 0.008104   Batch Acc: 81.25
[Train] Epoch: 1 [166464/620022]    Loss: 0.007757   Batch Acc: 84.38
[Train] Epoch: 1 [166528/620022]    Loss: 0.009093   Batch Acc: 76.56
[Train] Epoch: 1 [166592/620022]    Loss: 0.010898   Batch Acc: 73.44
[Train] Epoch: 1 [166656/620022]    Loss: 0.007689   Batch Acc: 84.38
[Train] Epoch: 1 [166720/620022]    Loss: 0.008412   Batch Acc: 75.00
[Train] Epoch: 1 [166784/620022]    Loss: 0.008228   Batch Acc: 84.38
[Train] Epoch: 1 [166848/620022]    Loss: 0.008309   Batch Acc: 76.56
[Train] Epoch: 1 [166912/620022]    Loss: 0.010072   Batch Acc: 68.75
[Train] Epoch: 1 [166976/620022]    Loss: 0.010222   Batch Acc: 73.44
[Train] Epoch: 1 [167040/620022]    Loss: 0.007340   Batch Acc: 85.94
[Train] Epoch: 1 [167104/620022]    Loss: 0.008188   Batch Acc: 81.25
[Train] Epoch: 1 [167168/620022]    Loss: 0.010261   Batch Acc: 76.56
[Train] Epoch: 1 [167232/620022]    Loss: 0.008722   Batch Acc: 73.44
[Train] Epoch: 1 [167296/620022]    Loss: 0.010286   Batch Acc: 70.31
[Train] Epoch: 1 [167360/620022]    Loss: 0.008463   Batch Acc: 73.44
[Train] Epoch: 1 [167424/620022]    Loss: 0.008264   Batch Acc: 75.00
[Train] Epoch: 1 [167488/620022]    Loss: 0.007039   Batch Acc: 82.81
[Train] Epoch: 1 [167552/620022]    Loss: 0.008389   Batch Acc: 79.69
[Train] Epoch: 1 [167616/620022]    Loss: 0.008234   Batch Acc: 81.25
[Train] Epoch: 1 [167680/620022]    Loss: 0.008232   Batch Acc: 79.69
[Train] Epoch: 1 [167744/620022]    Loss: 0.006793   Batch Acc: 81.25
[Train] Epoch: 1 [167808/620022]    Loss: 0.007827   Batch Acc: 84.38
[Train] Epoch: 1 [167872/620022]    Loss: 0.006112   Batch Acc: 92.19
[Train] Epoch: 1 [167936/620022]    Loss: 0.009296   Batch Acc: 73.44
[Train] Epoch: 1 [168000/620022]    Loss: 0.008748   Batch Acc: 78.12
[Train] Epoch: 1 [168064/620022]    Loss: 0.007053   Batch Acc: 82.81
[Train] Epoch: 1 [168128/620022]    Loss: 0.008373   Batch Acc: 75.00
[Train] Epoch: 1 [168192/620022]    Loss: 0.006640   Batch Acc: 85.94
[Train] Epoch: 1 [168256/620022]    Loss: 0.011704   Batch Acc: 65.62
[Train] Epoch: 1 [168320/620022]    Loss: 0.008718   Batch Acc: 76.56
[Train] Epoch: 1 [168384/620022]    Loss: 0.008230   Batch Acc: 79.69
[Train] Epoch: 1 [168448/620022]    Loss: 0.007803   Batch Acc: 84.38
[Train] Epoch: 1 [168512/620022]    Loss: 0.006639   Batch Acc: 82.81
[Train] Epoch: 1 [168576/620022]    Loss: 0.007485   Batch Acc: 81.25
[Train] Epoch: 1 [168640/620022]    Loss: 0.008385   Batch Acc: 75.00
[Train] Epoch: 1 [168704/620022]    Loss: 0.007253   Batch Acc: 81.25
[Train] Epoch: 1 [168768/620022]    Loss: 0.007703   Batch Acc: 81.25
[Train] Epoch: 1 [168832/620022]    Loss: 0.009795   Batch Acc: 76.56
[Train] Epoch: 1 [168896/620022]    Loss: 0.009161   Batch Acc: 78.12
[Train] Epoch: 1 [168960/620022]    Loss: 0.009257   Batch Acc: 67.19
[Train] Epoch: 1 [169024/620022]    Loss: 0.008519   Batch Acc: 81.25
[Train] Epoch: 1 [169088/620022]    Loss: 0.008472   Batch Acc: 82.81
[Train] Epoch: 1 [169152/620022]    Loss: 0.009035   Batch Acc: 76.56
[Train] Epoch: 1 [169216/620022]    Loss: 0.010637   Batch Acc: 76.56
[Train] Epoch: 1 [169280/620022]    Loss: 0.007446   Batch Acc: 84.38
[Train] Epoch: 1 [169344/620022]    Loss: 0.009079   Batch Acc: 78.12
[Train] Epoch: 1 [169408/620022]    Loss: 0.009290   Batch Acc: 76.56
[Train] Epoch: 1 [169472/620022]    Loss: 0.012102   Batch Acc: 64.06
[Train] Epoch: 1 [169536/620022]    Loss: 0.008419   Batch Acc: 76.56
[Train] Epoch: 1 [169600/620022]    Loss: 0.007829   Batch Acc: 78.12
[Train] Epoch: 1 [169664/620022]    Loss: 0.012424   Batch Acc: 71.88
[Train] Epoch: 1 [169728/620022]    Loss: 0.008431   Batch Acc: 71.88
[Train] Epoch: 1 [169792/620022]    Loss: 0.008711   Batch Acc: 75.00
[Train] Epoch: 1 [169856/620022]    Loss: 0.007898   Batch Acc: 78.12
[Train] Epoch: 1 [169920/620022]    Loss: 0.006987   Batch Acc: 85.94
[Train] Epoch: 1 [169984/620022]    Loss: 0.008922   Batch Acc: 78.12
[Train] Epoch: 1 [170048/620022]    Loss: 0.009804   Batch Acc: 73.44
[Train] Epoch: 1 [170112/620022]    Loss: 0.007993   Batch Acc: 79.69
[Train] Epoch: 1 [170176/620022]    Loss: 0.008160   Batch Acc: 78.12
[Train] Epoch: 1 [170240/620022]    Loss: 0.007258   Batch Acc: 79.69
[Train] Epoch: 1 [170304/620022]    Loss: 0.008366   Batch Acc: 75.00
[Train] Epoch: 1 [170368/620022]    Loss: 0.008577   Batch Acc: 81.25
[Train] Epoch: 1 [170432/620022]    Loss: 0.009649   Batch Acc: 73.44
[Train] Epoch: 1 [170496/620022]    Loss: 0.009320   Batch Acc: 73.44
[Train] Epoch: 1 [170560/620022]    Loss: 0.009221   Batch Acc: 78.12
[Train] Epoch: 1 [170624/620022]    Loss: 0.008170   Batch Acc: 82.81
[Train] Epoch: 1 [170688/620022]    Loss: 0.011358   Batch Acc: 67.19
[Train] Epoch: 1 [170752/620022]    Loss: 0.008458   Batch Acc: 82.81
[Train] Epoch: 1 [170816/620022]    Loss: 0.011026   Batch Acc: 68.75
[Train] Epoch: 1 [170880/620022]    Loss: 0.009026   Batch Acc: 81.25
[Train] Epoch: 1 [170944/620022]    Loss: 0.007869   Batch Acc: 81.25
[Train] Epoch: 1 [171008/620022]    Loss: 0.006383   Batch Acc: 82.81
[Train] Epoch: 1 [171072/620022]    Loss: 0.010500   Batch Acc: 67.19
[Train] Epoch: 1 [171136/620022]    Loss: 0.008996   Batch Acc: 76.56
[Train] Epoch: 1 [171200/620022]    Loss: 0.009891   Batch Acc: 73.44
[Train] Epoch: 1 [171264/620022]    Loss: 0.010220   Batch Acc: 75.00
[Train] Epoch: 1 [171328/620022]    Loss: 0.009351   Batch Acc: 76.56
[Train] Epoch: 1 [171392/620022]    Loss: 0.006217   Batch Acc: 87.50
[Train] Epoch: 1 [171456/620022]    Loss: 0.010606   Batch Acc: 71.88
[Train] Epoch: 1 [171520/620022]    Loss: 0.007885   Batch Acc: 79.69
[Train] Epoch: 1 [171584/620022]    Loss: 0.008643   Batch Acc: 73.44
[Train] Epoch: 1 [171648/620022]    Loss: 0.009223   Batch Acc: 73.44
[Train] Epoch: 1 [171712/620022]    Loss: 0.006793   Batch Acc: 84.38
[Train] Epoch: 1 [171776/620022]    Loss: 0.008327   Batch Acc: 78.12
[Train] Epoch: 1 [171840/620022]    Loss: 0.007097   Batch Acc: 82.81
[Train] Epoch: 1 [171904/620022]    Loss: 0.010728   Batch Acc: 71.88
[Train] Epoch: 1 [171968/620022]    Loss: 0.008705   Batch Acc: 73.44
[Train] Epoch: 1 [172032/620022]    Loss: 0.007994   Batch Acc: 81.25
[Train] Epoch: 1 [172096/620022]    Loss: 0.009865   Batch Acc: 68.75
[Train] Epoch: 1 [172160/620022]    Loss: 0.007007   Batch Acc: 90.62
[Train] Epoch: 1 [172224/620022]    Loss: 0.011437   Batch Acc: 73.44
[Train] Epoch: 1 [172288/620022]    Loss: 0.008947   Batch Acc: 79.69
[Train] Epoch: 1 [172352/620022]    Loss: 0.008296   Batch Acc: 79.69
[Train] Epoch: 1 [172416/620022]    Loss: 0.008673   Batch Acc: 73.44
[Train] Epoch: 1 [172480/620022]    Loss: 0.009496   Batch Acc: 70.31
[Train] Epoch: 1 [172544/620022]    Loss: 0.012016   Batch Acc: 70.31
[Train] Epoch: 1 [172608/620022]    Loss: 0.008980   Batch Acc: 81.25
[Train] Epoch: 1 [172672/620022]    Loss: 0.007859   Batch Acc: 82.81
[Train] Epoch: 1 [172736/620022]    Loss: 0.010334   Batch Acc: 73.44
[Train] Epoch: 1 [172800/620022]    Loss: 0.010220   Batch Acc: 70.31
[Train] Epoch: 1 [172864/620022]    Loss: 0.007396   Batch Acc: 81.25
[Train] Epoch: 1 [172928/620022]    Loss: 0.009360   Batch Acc: 81.25
[Train] Epoch: 1 [172992/620022]    Loss: 0.010345   Batch Acc: 71.88
[Train] Epoch: 1 [173056/620022]    Loss: 0.009010   Batch Acc: 76.56
[Train] Epoch: 1 [173120/620022]    Loss: 0.009685   Batch Acc: 73.44
[Train] Epoch: 1 [173184/620022]    Loss: 0.011857   Batch Acc: 64.06
[Train] Epoch: 1 [173248/620022]    Loss: 0.008668   Batch Acc: 78.12
[Train] Epoch: 1 [173312/620022]    Loss: 0.007788   Batch Acc: 79.69
[Train] Epoch: 1 [173376/620022]    Loss: 0.008892   Batch Acc: 79.69
[Train] Epoch: 1 [173440/620022]    Loss: 0.006776   Batch Acc: 87.50
[Train] Epoch: 1 [173504/620022]    Loss: 0.008620   Batch Acc: 75.00
[Train] Epoch: 1 [173568/620022]    Loss: 0.009486   Batch Acc: 78.12
[Train] Epoch: 1 [173632/620022]    Loss: 0.008132   Batch Acc: 78.12
[Train] Epoch: 1 [173696/620022]    Loss: 0.009990   Batch Acc: 73.44
[Train] Epoch: 1 [173760/620022]    Loss: 0.007524   Batch Acc: 79.69
[Train] Epoch: 1 [173824/620022]    Loss: 0.010159   Batch Acc: 75.00
[Train] Epoch: 1 [173888/620022]    Loss: 0.012429   Batch Acc: 70.31
[Train] Epoch: 1 [173952/620022]    Loss: 0.010384   Batch Acc: 68.75
[Train] Epoch: 1 [174016/620022]    Loss: 0.009272   Batch Acc: 73.44
[Train] Epoch: 1 [174080/620022]    Loss: 0.008685   Batch Acc: 81.25
[Train] Epoch: 1 [174144/620022]    Loss: 0.007927   Batch Acc: 78.12
[Train] Epoch: 1 [174208/620022]    Loss: 0.008741   Batch Acc: 81.25
[Train] Epoch: 1 [174272/620022]    Loss: 0.009459   Batch Acc: 78.12
[Train] Epoch: 1 [174336/620022]    Loss: 0.009894   Batch Acc: 76.56
[Train] Epoch: 1 [174400/620022]    Loss: 0.008200   Batch Acc: 78.12
[Train] Epoch: 1 [174464/620022]    Loss: 0.011453   Batch Acc: 67.19
[Train] Epoch: 1 [174528/620022]    Loss: 0.008196   Batch Acc: 79.69
[Train] Epoch: 1 [174592/620022]    Loss: 0.006519   Batch Acc: 85.94
[Train] Epoch: 1 [174656/620022]    Loss: 0.009727   Batch Acc: 70.31
[Train] Epoch: 1 [174720/620022]    Loss: 0.009177   Batch Acc: 76.56
[Train] Epoch: 1 [174784/620022]    Loss: 0.008918   Batch Acc: 75.00
[Train] Epoch: 1 [174848/620022]    Loss: 0.011356   Batch Acc: 71.88
[Train] Epoch: 1 [174912/620022]    Loss: 0.009651   Batch Acc: 71.88
[Train] Epoch: 1 [174976/620022]    Loss: 0.008599   Batch Acc: 75.00
[Train] Epoch: 1 [175040/620022]    Loss: 0.010817   Batch Acc: 70.31
[Train] Epoch: 1 [175104/620022]    Loss: 0.008902   Batch Acc: 75.00
[Train] Epoch: 1 [175168/620022]    Loss: 0.007907   Batch Acc: 82.81
[Train] Epoch: 1 [175232/620022]    Loss: 0.008114   Batch Acc: 79.69
[Train] Epoch: 1 [175296/620022]    Loss: 0.008180   Batch Acc: 82.81
[Train] Epoch: 1 [175360/620022]    Loss: 0.007919   Batch Acc: 82.81
[Train] Epoch: 1 [175424/620022]    Loss: 0.007777   Batch Acc: 82.81
[Train] Epoch: 1 [175488/620022]    Loss: 0.008246   Batch Acc: 78.12
[Train] Epoch: 1 [175552/620022]    Loss: 0.007112   Batch Acc: 87.50
[Train] Epoch: 1 [175616/620022]    Loss: 0.008174   Batch Acc: 79.69
[Train] Epoch: 1 [175680/620022]    Loss: 0.009810   Batch Acc: 73.44
[Train] Epoch: 1 [175744/620022]    Loss: 0.008691   Batch Acc: 75.00
[Train] Epoch: 1 [175808/620022]    Loss: 0.010166   Batch Acc: 70.31
[Train] Epoch: 1 [175872/620022]    Loss: 0.010288   Batch Acc: 76.56
[Train] Epoch: 1 [175936/620022]    Loss: 0.006952   Batch Acc: 82.81
[Train] Epoch: 1 [176000/620022]    Loss: 0.008191   Batch Acc: 76.56
[Train] Epoch: 1 [176064/620022]    Loss: 0.011043   Batch Acc: 73.44
[Train] Epoch: 1 [176128/620022]    Loss: 0.008426   Batch Acc: 78.12
[Train] Epoch: 1 [176192/620022]    Loss: 0.008075   Batch Acc: 82.81
[Train] Epoch: 1 [176256/620022]    Loss: 0.006819   Batch Acc: 84.38
[Train] Epoch: 1 [176320/620022]    Loss: 0.008565   Batch Acc: 78.12
[Train] Epoch: 1 [176384/620022]    Loss: 0.009034   Batch Acc: 76.56
[Train] Epoch: 1 [176448/620022]    Loss: 0.009126   Batch Acc: 79.69
[Train] Epoch: 1 [176512/620022]    Loss: 0.008126   Batch Acc: 75.00
[Train] Epoch: 1 [176576/620022]    Loss: 0.011668   Batch Acc: 71.88
[Train] Epoch: 1 [176640/620022]    Loss: 0.010079   Batch Acc: 76.56
[Train] Epoch: 1 [176704/620022]    Loss: 0.009775   Batch Acc: 79.69
[Train] Epoch: 1 [176768/620022]    Loss: 0.006658   Batch Acc: 87.50
[Train] Epoch: 1 [176832/620022]    Loss: 0.009784   Batch Acc: 70.31
[Train] Epoch: 1 [176896/620022]    Loss: 0.009551   Batch Acc: 76.56
[Train] Epoch: 1 [176960/620022]    Loss: 0.007512   Batch Acc: 78.12
[Train] Epoch: 1 [177024/620022]    Loss: 0.009525   Batch Acc: 76.56
[Train] Epoch: 1 [177088/620022]    Loss: 0.009121   Batch Acc: 81.25
[Train] Epoch: 1 [177152/620022]    Loss: 0.006602   Batch Acc: 84.38
[Train] Epoch: 1 [177216/620022]    Loss: 0.010434   Batch Acc: 75.00
[Train] Epoch: 1 [177280/620022]    Loss: 0.007815   Batch Acc: 84.38
[Train] Epoch: 1 [177344/620022]    Loss: 0.006122   Batch Acc: 79.69
[Train] Epoch: 1 [177408/620022]    Loss: 0.008025   Batch Acc: 81.25
[Train] Epoch: 1 [177472/620022]    Loss: 0.007301   Batch Acc: 82.81
[Train] Epoch: 1 [177536/620022]    Loss: 0.009365   Batch Acc: 75.00
[Train] Epoch: 1 [177600/620022]    Loss: 0.009356   Batch Acc: 75.00
[Train] Epoch: 1 [177664/620022]    Loss: 0.008131   Batch Acc: 79.69
[Train] Epoch: 1 [177728/620022]    Loss: 0.010539   Batch Acc: 75.00
[Train] Epoch: 1 [177792/620022]    Loss: 0.008887   Batch Acc: 79.69
[Train] Epoch: 1 [177856/620022]    Loss: 0.008461   Batch Acc: 76.56
[Train] Epoch: 1 [177920/620022]    Loss: 0.009541   Batch Acc: 73.44
[Train] Epoch: 1 [177984/620022]    Loss: 0.010143   Batch Acc: 76.56
[Train] Epoch: 1 [178048/620022]    Loss: 0.011714   Batch Acc: 65.62
[Train] Epoch: 1 [178112/620022]    Loss: 0.008273   Batch Acc: 76.56
[Train] Epoch: 1 [178176/620022]    Loss: 0.010426   Batch Acc: 75.00
[Train] Epoch: 1 [178240/620022]    Loss: 0.008632   Batch Acc: 79.69
[Train] Epoch: 1 [178304/620022]    Loss: 0.009586   Batch Acc: 71.88
[Train] Epoch: 1 [178368/620022]    Loss: 0.007340   Batch Acc: 82.81
[Train] Epoch: 1 [178432/620022]    Loss: 0.008180   Batch Acc: 75.00
[Train] Epoch: 1 [178496/620022]    Loss: 0.007738   Batch Acc: 81.25
[Train] Epoch: 1 [178560/620022]    Loss: 0.010616   Batch Acc: 71.88
[Train] Epoch: 1 [178624/620022]    Loss: 0.010300   Batch Acc: 73.44
[Train] Epoch: 1 [178688/620022]    Loss: 0.009001   Batch Acc: 76.56
[Train] Epoch: 1 [178752/620022]    Loss: 0.011678   Batch Acc: 68.75
[Train] Epoch: 1 [178816/620022]    Loss: 0.010249   Batch Acc: 73.44
[Train] Epoch: 1 [178880/620022]    Loss: 0.007103   Batch Acc: 82.81
[Train] Epoch: 1 [178944/620022]    Loss: 0.006728   Batch Acc: 84.38
[Train] Epoch: 1 [179008/620022]    Loss: 0.009076   Batch Acc: 70.31
[Train] Epoch: 1 [179072/620022]    Loss: 0.010595   Batch Acc: 71.88
[Train] Epoch: 1 [179136/620022]    Loss: 0.008794   Batch Acc: 78.12
[Train] Epoch: 1 [179200/620022]    Loss: 0.009878   Batch Acc: 76.56
[Train] Epoch: 1 [179264/620022]    Loss: 0.007220   Batch Acc: 85.94
[Train] Epoch: 1 [179328/620022]    Loss: 0.006226   Batch Acc: 89.06
[Train] Epoch: 1 [179392/620022]    Loss: 0.009166   Batch Acc: 79.69
[Train] Epoch: 1 [179456/620022]    Loss: 0.007339   Batch Acc: 81.25
[Train] Epoch: 1 [179520/620022]    Loss: 0.010628   Batch Acc: 73.44
[Train] Epoch: 1 [179584/620022]    Loss: 0.006446   Batch Acc: 84.38
[Train] Epoch: 1 [179648/620022]    Loss: 0.005170   Batch Acc: 87.50
[Train] Epoch: 1 [179712/620022]    Loss: 0.008249   Batch Acc: 79.69
[Train] Epoch: 1 [179776/620022]    Loss: 0.009281   Batch Acc: 78.12
[Train] Epoch: 1 [179840/620022]    Loss: 0.007683   Batch Acc: 84.38
[Train] Epoch: 1 [179904/620022]    Loss: 0.009276   Batch Acc: 71.88
[Train] Epoch: 1 [179968/620022]    Loss: 0.008809   Batch Acc: 76.56
[Train] Epoch: 1 [180032/620022]    Loss: 0.006234   Batch Acc: 85.94
[Train] Epoch: 1 [180096/620022]    Loss: 0.010239   Batch Acc: 68.75
[Train] Epoch: 1 [180160/620022]    Loss: 0.008512   Batch Acc: 79.69
[Train] Epoch: 1 [180224/620022]    Loss: 0.008488   Batch Acc: 82.81
[Train] Epoch: 1 [180288/620022]    Loss: 0.009116   Batch Acc: 76.56
[Train] Epoch: 1 [180352/620022]    Loss: 0.006691   Batch Acc: 84.38
[Train] Epoch: 1 [180416/620022]    Loss: 0.008225   Batch Acc: 82.81
[Train] Epoch: 1 [180480/620022]    Loss: 0.006288   Batch Acc: 87.50
[Train] Epoch: 1 [180544/620022]    Loss: 0.010125   Batch Acc: 76.56
[Train] Epoch: 1 [180608/620022]    Loss: 0.007672   Batch Acc: 82.81
[Train] Epoch: 1 [180672/620022]    Loss: 0.008825   Batch Acc: 79.69
[Train] Epoch: 1 [180736/620022]    Loss: 0.007648   Batch Acc: 82.81
[Train] Epoch: 1 [180800/620022]    Loss: 0.006748   Batch Acc: 79.69
[Train] Epoch: 1 [180864/620022]    Loss: 0.010036   Batch Acc: 75.00
[Train] Epoch: 1 [180928/620022]    Loss: 0.008888   Batch Acc: 70.31
[Train] Epoch: 1 [180992/620022]    Loss: 0.009137   Batch Acc: 76.56
[Train] Epoch: 1 [181056/620022]    Loss: 0.009556   Batch Acc: 75.00
[Train] Epoch: 1 [181120/620022]    Loss: 0.008886   Batch Acc: 75.00
[Train] Epoch: 1 [181184/620022]    Loss: 0.007723   Batch Acc: 85.94
[Train] Epoch: 1 [181248/620022]    Loss: 0.007883   Batch Acc: 84.38
[Train] Epoch: 1 [181312/620022]    Loss: 0.010190   Batch Acc: 76.56
[Train] Epoch: 1 [181376/620022]    Loss: 0.007721   Batch Acc: 81.25
[Train] Epoch: 1 [181440/620022]    Loss: 0.011714   Batch Acc: 73.44
[Train] Epoch: 1 [181504/620022]    Loss: 0.007895   Batch Acc: 84.38
[Train] Epoch: 1 [181568/620022]    Loss: 0.009069   Batch Acc: 82.81
[Train] Epoch: 1 [181632/620022]    Loss: 0.010490   Batch Acc: 71.88
[Train] Epoch: 1 [181696/620022]    Loss: 0.007303   Batch Acc: 81.25
[Train] Epoch: 1 [181760/620022]    Loss: 0.007408   Batch Acc: 78.12
[Train] Epoch: 1 [181824/620022]    Loss: 0.006342   Batch Acc: 89.06
[Train] Epoch: 1 [181888/620022]    Loss: 0.007670   Batch Acc: 82.81
[Train] Epoch: 1 [181952/620022]    Loss: 0.008226   Batch Acc: 81.25
[Train] Epoch: 1 [182016/620022]    Loss: 0.010822   Batch Acc: 71.88
[Train] Epoch: 1 [182080/620022]    Loss: 0.006557   Batch Acc: 87.50
[Train] Epoch: 1 [182144/620022]    Loss: 0.008356   Batch Acc: 76.56
[Train] Epoch: 1 [182208/620022]    Loss: 0.009168   Batch Acc: 75.00
[Train] Epoch: 1 [182272/620022]    Loss: 0.007200   Batch Acc: 85.94
[Train] Epoch: 1 [182336/620022]    Loss: 0.006558   Batch Acc: 82.81
[Train] Epoch: 1 [182400/620022]    Loss: 0.007309   Batch Acc: 79.69
[Train] Epoch: 1 [182464/620022]    Loss: 0.008228   Batch Acc: 78.12
[Train] Epoch: 1 [182528/620022]    Loss: 0.006799   Batch Acc: 82.81
[Train] Epoch: 1 [182592/620022]    Loss: 0.007695   Batch Acc: 85.94
[Train] Epoch: 1 [182656/620022]    Loss: 0.008147   Batch Acc: 81.25
[Train] Epoch: 1 [182720/620022]    Loss: 0.007941   Batch Acc: 79.69
[Train] Epoch: 1 [182784/620022]    Loss: 0.009101   Batch Acc: 78.12
[Train] Epoch: 1 [182848/620022]    Loss: 0.008925   Batch Acc: 81.25
[Train] Epoch: 1 [182912/620022]    Loss: 0.008640   Batch Acc: 78.12
[Train] Epoch: 1 [182976/620022]    Loss: 0.007657   Batch Acc: 79.69
[Train] Epoch: 1 [183040/620022]    Loss: 0.007912   Batch Acc: 76.56
[Train] Epoch: 1 [183104/620022]    Loss: 0.007348   Batch Acc: 81.25
[Train] Epoch: 1 [183168/620022]    Loss: 0.008838   Batch Acc: 78.12
[Train] Epoch: 1 [183232/620022]    Loss: 0.009215   Batch Acc: 78.12
[Train] Epoch: 1 [183296/620022]    Loss: 0.009008   Batch Acc: 78.12
[Train] Epoch: 1 [183360/620022]    Loss: 0.007049   Batch Acc: 84.38
[Train] Epoch: 1 [183424/620022]    Loss: 0.009703   Batch Acc: 70.31
[Train] Epoch: 1 [183488/620022]    Loss: 0.009699   Batch Acc: 81.25
[Train] Epoch: 1 [183552/620022]    Loss: 0.008046   Batch Acc: 81.25
[Train] Epoch: 1 [183616/620022]    Loss: 0.009759   Batch Acc: 73.44
[Train] Epoch: 1 [183680/620022]    Loss: 0.008931   Batch Acc: 71.88
[Train] Epoch: 1 [183744/620022]    Loss: 0.008422   Batch Acc: 81.25
[Train] Epoch: 1 [183808/620022]    Loss: 0.008270   Batch Acc: 75.00
[Train] Epoch: 1 [183872/620022]    Loss: 0.008595   Batch Acc: 79.69
[Train] Epoch: 1 [183936/620022]    Loss: 0.008584   Batch Acc: 78.12
[Train] Epoch: 1 [184000/620022]    Loss: 0.009800   Batch Acc: 71.88
[Train] Epoch: 1 [184064/620022]    Loss: 0.010278   Batch Acc: 70.31
[Train] Epoch: 1 [184128/620022]    Loss: 0.008260   Batch Acc: 78.12
[Train] Epoch: 1 [184192/620022]    Loss: 0.007934   Batch Acc: 84.38
[Train] Epoch: 1 [184256/620022]    Loss: 0.010450   Batch Acc: 71.88
[Train] Epoch: 1 [184320/620022]    Loss: 0.008399   Batch Acc: 78.12
[Train] Epoch: 1 [184384/620022]    Loss: 0.008993   Batch Acc: 76.56
[Train] Epoch: 1 [184448/620022]    Loss: 0.008123   Batch Acc: 75.00
[Train] Epoch: 1 [184512/620022]    Loss: 0.010107   Batch Acc: 75.00
[Train] Epoch: 1 [184576/620022]    Loss: 0.010485   Batch Acc: 73.44
[Train] Epoch: 1 [184640/620022]    Loss: 0.011142   Batch Acc: 75.00
[Train] Epoch: 1 [184704/620022]    Loss: 0.007931   Batch Acc: 78.12
[Train] Epoch: 1 [184768/620022]    Loss: 0.008123   Batch Acc: 79.69
[Train] Epoch: 1 [184832/620022]    Loss: 0.008605   Batch Acc: 78.12
[Train] Epoch: 1 [184896/620022]    Loss: 0.009968   Batch Acc: 68.75
[Train] Epoch: 1 [184960/620022]    Loss: 0.008468   Batch Acc: 73.44
[Train] Epoch: 1 [185024/620022]    Loss: 0.009261   Batch Acc: 75.00
[Train] Epoch: 1 [185088/620022]    Loss: 0.011069   Batch Acc: 71.88
[Train] Epoch: 1 [185152/620022]    Loss: 0.009853   Batch Acc: 75.00
[Train] Epoch: 1 [185216/620022]    Loss: 0.009096   Batch Acc: 75.00
[Train] Epoch: 1 [185280/620022]    Loss: 0.007594   Batch Acc: 81.25
[Train] Epoch: 1 [185344/620022]    Loss: 0.007960   Batch Acc: 79.69
[Train] Epoch: 1 [185408/620022]    Loss: 0.009869   Batch Acc: 81.25
[Train] Epoch: 1 [185472/620022]    Loss: 0.009739   Batch Acc: 79.69
[Train] Epoch: 1 [185536/620022]    Loss: 0.010731   Batch Acc: 67.19
[Train] Epoch: 1 [185600/620022]    Loss: 0.009077   Batch Acc: 81.25
[Train] Epoch: 1 [185664/620022]    Loss: 0.005890   Batch Acc: 90.62
[Train] Epoch: 1 [185728/620022]    Loss: 0.007931   Batch Acc: 78.12
[Train] Epoch: 1 [185792/620022]    Loss: 0.006104   Batch Acc: 85.94
[Train] Epoch: 1 [185856/620022]    Loss: 0.008620   Batch Acc: 76.56
[Train] Epoch: 1 [185920/620022]    Loss: 0.010724   Batch Acc: 71.88
[Train] Epoch: 1 [185984/620022]    Loss: 0.009985   Batch Acc: 71.88
[Train] Epoch: 1 [186048/620022]    Loss: 0.008850   Batch Acc: 78.12
[Train] Epoch: 1 [186112/620022]    Loss: 0.012777   Batch Acc: 62.50
[Train] Epoch: 1 [186176/620022]    Loss: 0.009626   Batch Acc: 78.12
[Train] Epoch: 1 [186240/620022]    Loss: 0.009853   Batch Acc: 75.00
[Train] Epoch: 1 [186304/620022]    Loss: 0.008337   Batch Acc: 79.69
[Train] Epoch: 1 [186368/620022]    Loss: 0.007207   Batch Acc: 87.50
[Train] Epoch: 1 [186432/620022]    Loss: 0.010107   Batch Acc: 70.31
[Train] Epoch: 1 [186496/620022]    Loss: 0.011024   Batch Acc: 65.62
[Train] Epoch: 1 [186560/620022]    Loss: 0.007208   Batch Acc: 85.94
[Train] Epoch: 1 [186624/620022]    Loss: 0.009079   Batch Acc: 78.12
[Train] Epoch: 1 [186688/620022]    Loss: 0.008064   Batch Acc: 79.69
[Train] Epoch: 1 [186752/620022]    Loss: 0.008889   Batch Acc: 85.94
[Train] Epoch: 1 [186816/620022]    Loss: 0.006226   Batch Acc: 79.69
[Train] Epoch: 1 [186880/620022]    Loss: 0.008878   Batch Acc: 73.44
[Train] Epoch: 1 [186944/620022]    Loss: 0.009280   Batch Acc: 75.00
[Train] Epoch: 1 [187008/620022]    Loss: 0.006714   Batch Acc: 84.38
[Train] Epoch: 1 [187072/620022]    Loss: 0.009262   Batch Acc: 75.00
[Train] Epoch: 1 [187136/620022]    Loss: 0.009752   Batch Acc: 73.44
[Train] Epoch: 1 [187200/620022]    Loss: 0.006702   Batch Acc: 85.94
[Train] Epoch: 1 [187264/620022]    Loss: 0.007884   Batch Acc: 76.56
[Train] Epoch: 1 [187328/620022]    Loss: 0.009788   Batch Acc: 79.69
[Train] Epoch: 1 [187392/620022]    Loss: 0.009165   Batch Acc: 75.00
[Train] Epoch: 1 [187456/620022]    Loss: 0.008689   Batch Acc: 82.81
[Train] Epoch: 1 [187520/620022]    Loss: 0.009677   Batch Acc: 81.25
[Train] Epoch: 1 [187584/620022]    Loss: 0.007072   Batch Acc: 82.81
[Train] Epoch: 1 [187648/620022]    Loss: 0.007604   Batch Acc: 79.69
[Train] Epoch: 1 [187712/620022]    Loss: 0.006506   Batch Acc: 81.25
[Train] Epoch: 1 [187776/620022]    Loss: 0.011753   Batch Acc: 70.31
[Train] Epoch: 1 [187840/620022]    Loss: 0.008753   Batch Acc: 79.69
[Train] Epoch: 1 [187904/620022]    Loss: 0.010629   Batch Acc: 68.75
[Train] Epoch: 1 [187968/620022]    Loss: 0.009516   Batch Acc: 79.69
[Train] Epoch: 1 [188032/620022]    Loss: 0.009884   Batch Acc: 68.75
[Train] Epoch: 1 [188096/620022]    Loss: 0.010007   Batch Acc: 73.44
[Train] Epoch: 1 [188160/620022]    Loss: 0.009251   Batch Acc: 73.44
[Train] Epoch: 1 [188224/620022]    Loss: 0.009694   Batch Acc: 76.56
[Train] Epoch: 1 [188288/620022]    Loss: 0.009917   Batch Acc: 78.12
[Train] Epoch: 1 [188352/620022]    Loss: 0.008593   Batch Acc: 76.56
[Train] Epoch: 1 [188416/620022]    Loss: 0.009719   Batch Acc: 70.31
[Train] Epoch: 1 [188480/620022]    Loss: 0.009031   Batch Acc: 78.12
[Train] Epoch: 1 [188544/620022]    Loss: 0.007253   Batch Acc: 84.38
[Train] Epoch: 1 [188608/620022]    Loss: 0.009002   Batch Acc: 81.25
[Train] Epoch: 1 [188672/620022]    Loss: 0.009698   Batch Acc: 75.00
[Train] Epoch: 1 [188736/620022]    Loss: 0.008202   Batch Acc: 79.69
[Train] Epoch: 1 [188800/620022]    Loss: 0.009580   Batch Acc: 73.44
[Train] Epoch: 1 [188864/620022]    Loss: 0.008247   Batch Acc: 79.69
[Train] Epoch: 1 [188928/620022]    Loss: 0.008835   Batch Acc: 79.69
[Train] Epoch: 1 [188992/620022]    Loss: 0.007934   Batch Acc: 75.00
[Train] Epoch: 1 [189056/620022]    Loss: 0.008775   Batch Acc: 76.56
[Train] Epoch: 1 [189120/620022]    Loss: 0.010514   Batch Acc: 70.31
[Train] Epoch: 1 [189184/620022]    Loss: 0.010746   Batch Acc: 70.31
[Train] Epoch: 1 [189248/620022]    Loss: 0.007664   Batch Acc: 82.81
[Train] Epoch: 1 [189312/620022]    Loss: 0.007557   Batch Acc: 84.38
[Train] Epoch: 1 [189376/620022]    Loss: 0.008158   Batch Acc: 79.69
[Train] Epoch: 1 [189440/620022]    Loss: 0.007954   Batch Acc: 75.00
[Train] Epoch: 1 [189504/620022]    Loss: 0.012897   Batch Acc: 62.50
[Train] Epoch: 1 [189568/620022]    Loss: 0.009162   Batch Acc: 75.00
[Train] Epoch: 1 [189632/620022]    Loss: 0.008257   Batch Acc: 81.25
[Train] Epoch: 1 [189696/620022]    Loss: 0.008610   Batch Acc: 75.00
[Train] Epoch: 1 [189760/620022]    Loss: 0.010263   Batch Acc: 76.56
[Train] Epoch: 1 [189824/620022]    Loss: 0.009887   Batch Acc: 76.56
[Train] Epoch: 1 [189888/620022]    Loss: 0.010687   Batch Acc: 68.75
[Train] Epoch: 1 [189952/620022]    Loss: 0.009469   Batch Acc: 71.88
[Train] Epoch: 1 [190016/620022]    Loss: 0.009169   Batch Acc: 76.56
[Train] Epoch: 1 [190080/620022]    Loss: 0.008589   Batch Acc: 75.00
[Train] Epoch: 1 [190144/620022]    Loss: 0.009341   Batch Acc: 76.56
[Train] Epoch: 1 [190208/620022]    Loss: 0.009463   Batch Acc: 68.75
[Train] Epoch: 1 [190272/620022]    Loss: 0.008197   Batch Acc: 81.25
[Train] Epoch: 1 [190336/620022]    Loss: 0.005525   Batch Acc: 87.50
[Train] Epoch: 1 [190400/620022]    Loss: 0.009692   Batch Acc: 76.56
[Train] Epoch: 1 [190464/620022]    Loss: 0.008175   Batch Acc: 84.38
[Train] Epoch: 1 [190528/620022]    Loss: 0.008571   Batch Acc: 78.12
[Train] Epoch: 1 [190592/620022]    Loss: 0.007702   Batch Acc: 82.81
[Train] Epoch: 1 [190656/620022]    Loss: 0.009836   Batch Acc: 76.56
[Train] Epoch: 1 [190720/620022]    Loss: 0.007822   Batch Acc: 81.25
[Train] Epoch: 1 [190784/620022]    Loss: 0.007505   Batch Acc: 89.06
[Train] Epoch: 1 [190848/620022]    Loss: 0.008547   Batch Acc: 76.56
[Train] Epoch: 1 [190912/620022]    Loss: 0.008472   Batch Acc: 79.69
[Train] Epoch: 1 [190976/620022]    Loss: 0.012344   Batch Acc: 65.62
[Train] Epoch: 1 [191040/620022]    Loss: 0.007833   Batch Acc: 84.38
[Train] Epoch: 1 [191104/620022]    Loss: 0.008310   Batch Acc: 84.38
[Train] Epoch: 1 [191168/620022]    Loss: 0.008710   Batch Acc: 81.25
[Train] Epoch: 1 [191232/620022]    Loss: 0.007633   Batch Acc: 81.25
[Train] Epoch: 1 [191296/620022]    Loss: 0.010165   Batch Acc: 71.88
[Train] Epoch: 1 [191360/620022]    Loss: 0.010034   Batch Acc: 76.56
[Train] Epoch: 1 [191424/620022]    Loss: 0.009956   Batch Acc: 68.75
[Train] Epoch: 1 [191488/620022]    Loss: 0.008712   Batch Acc: 81.25
[Train] Epoch: 1 [191552/620022]    Loss: 0.009761   Batch Acc: 73.44
[Train] Epoch: 1 [191616/620022]    Loss: 0.010622   Batch Acc: 70.31
[Train] Epoch: 1 [191680/620022]    Loss: 0.007922   Batch Acc: 81.25
[Train] Epoch: 1 [191744/620022]    Loss: 0.007977   Batch Acc: 81.25
[Train] Epoch: 1 [191808/620022]    Loss: 0.011076   Batch Acc: 71.88
[Train] Epoch: 1 [191872/620022]    Loss: 0.009447   Batch Acc: 79.69
[Train] Epoch: 1 [191936/620022]    Loss: 0.007250   Batch Acc: 79.69
[Train] Epoch: 1 [192000/620022]    Loss: 0.008277   Batch Acc: 84.38
[Train] Epoch: 1 [192064/620022]    Loss: 0.009664   Batch Acc: 70.31
[Train] Epoch: 1 [192128/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 1 [192192/620022]    Loss: 0.009197   Batch Acc: 75.00
[Train] Epoch: 1 [192256/620022]    Loss: 0.008303   Batch Acc: 76.56
[Train] Epoch: 1 [192320/620022]    Loss: 0.008023   Batch Acc: 76.56
[Train] Epoch: 1 [192384/620022]    Loss: 0.011835   Batch Acc: 67.19
[Train] Epoch: 1 [192448/620022]    Loss: 0.006548   Batch Acc: 84.38
[Train] Epoch: 1 [192512/620022]    Loss: 0.008521   Batch Acc: 79.69
[Train] Epoch: 1 [192576/620022]    Loss: 0.008500   Batch Acc: 79.69
[Train] Epoch: 1 [192640/620022]    Loss: 0.006538   Batch Acc: 89.06
[Train] Epoch: 1 [192704/620022]    Loss: 0.008487   Batch Acc: 81.25
[Train] Epoch: 1 [192768/620022]    Loss: 0.006616   Batch Acc: 82.81
[Train] Epoch: 1 [192832/620022]    Loss: 0.006010   Batch Acc: 87.50
[Train] Epoch: 1 [192896/620022]    Loss: 0.008520   Batch Acc: 79.69
[Train] Epoch: 1 [192960/620022]    Loss: 0.008959   Batch Acc: 78.12
[Train] Epoch: 1 [193024/620022]    Loss: 0.007872   Batch Acc: 82.81
[Train] Epoch: 1 [193088/620022]    Loss: 0.010272   Batch Acc: 75.00
[Train] Epoch: 1 [193152/620022]    Loss: 0.008151   Batch Acc: 73.44
[Train] Epoch: 1 [193216/620022]    Loss: 0.007194   Batch Acc: 79.69
[Train] Epoch: 1 [193280/620022]    Loss: 0.006934   Batch Acc: 85.94
[Train] Epoch: 1 [193344/620022]    Loss: 0.010030   Batch Acc: 78.12
[Train] Epoch: 1 [193408/620022]    Loss: 0.009567   Batch Acc: 73.44
[Train] Epoch: 1 [193472/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 1 [193536/620022]    Loss: 0.007996   Batch Acc: 71.88
[Train] Epoch: 1 [193600/620022]    Loss: 0.007783   Batch Acc: 81.25
[Train] Epoch: 1 [193664/620022]    Loss: 0.010204   Batch Acc: 68.75
[Train] Epoch: 1 [193728/620022]    Loss: 0.009124   Batch Acc: 79.69
[Train] Epoch: 1 [193792/620022]    Loss: 0.009377   Batch Acc: 71.88
[Train] Epoch: 1 [193856/620022]    Loss: 0.007838   Batch Acc: 81.25
[Train] Epoch: 1 [193920/620022]    Loss: 0.007195   Batch Acc: 84.38
[Train] Epoch: 1 [193984/620022]    Loss: 0.007833   Batch Acc: 73.44
[Train] Epoch: 1 [194048/620022]    Loss: 0.009796   Batch Acc: 73.44
[Train] Epoch: 1 [194112/620022]    Loss: 0.008121   Batch Acc: 75.00
[Train] Epoch: 1 [194176/620022]    Loss: 0.009545   Batch Acc: 75.00
[Train] Epoch: 1 [194240/620022]    Loss: 0.009306   Batch Acc: 76.56
[Train] Epoch: 1 [194304/620022]    Loss: 0.006258   Batch Acc: 82.81
[Train] Epoch: 1 [194368/620022]    Loss: 0.007435   Batch Acc: 82.81
[Train] Epoch: 1 [194432/620022]    Loss: 0.006169   Batch Acc: 90.62
[Train] Epoch: 1 [194496/620022]    Loss: 0.007515   Batch Acc: 82.81
[Train] Epoch: 1 [194560/620022]    Loss: 0.010356   Batch Acc: 75.00
[Train] Epoch: 1 [194624/620022]    Loss: 0.008016   Batch Acc: 81.25
[Train] Epoch: 1 [194688/620022]    Loss: 0.007870   Batch Acc: 84.38
[Train] Epoch: 1 [194752/620022]    Loss: 0.010321   Batch Acc: 67.19
[Train] Epoch: 1 [194816/620022]    Loss: 0.009697   Batch Acc: 70.31
[Train] Epoch: 1 [194880/620022]    Loss: 0.008863   Batch Acc: 75.00
[Train] Epoch: 1 [194944/620022]    Loss: 0.008491   Batch Acc: 81.25
[Train] Epoch: 1 [195008/620022]    Loss: 0.008058   Batch Acc: 79.69
[Train] Epoch: 1 [195072/620022]    Loss: 0.008589   Batch Acc: 79.69
[Train] Epoch: 1 [195136/620022]    Loss: 0.007541   Batch Acc: 82.81
[Train] Epoch: 1 [195200/620022]    Loss: 0.008296   Batch Acc: 75.00
[Train] Epoch: 1 [195264/620022]    Loss: 0.007822   Batch Acc: 84.38
[Train] Epoch: 1 [195328/620022]    Loss: 0.009452   Batch Acc: 73.44
[Train] Epoch: 1 [195392/620022]    Loss: 0.008245   Batch Acc: 76.56
[Train] Epoch: 1 [195456/620022]    Loss: 0.009935   Batch Acc: 78.12
[Train] Epoch: 1 [195520/620022]    Loss: 0.010325   Batch Acc: 68.75
[Train] Epoch: 1 [195584/620022]    Loss: 0.009097   Batch Acc: 76.56
[Train] Epoch: 1 [195648/620022]    Loss: 0.007273   Batch Acc: 81.25
[Train] Epoch: 1 [195712/620022]    Loss: 0.009210   Batch Acc: 75.00
[Train] Epoch: 1 [195776/620022]    Loss: 0.009158   Batch Acc: 75.00
[Train] Epoch: 1 [195840/620022]    Loss: 0.011477   Batch Acc: 73.44
[Train] Epoch: 1 [195904/620022]    Loss: 0.007020   Batch Acc: 82.81
[Train] Epoch: 1 [195968/620022]    Loss: 0.006546   Batch Acc: 89.06
[Train] Epoch: 1 [196032/620022]    Loss: 0.008859   Batch Acc: 78.12
[Train] Epoch: 1 [196096/620022]    Loss: 0.009119   Batch Acc: 78.12
[Train] Epoch: 1 [196160/620022]    Loss: 0.006674   Batch Acc: 85.94
[Train] Epoch: 1 [196224/620022]    Loss: 0.008812   Batch Acc: 70.31
[Train] Epoch: 1 [196288/620022]    Loss: 0.009129   Batch Acc: 76.56
[Train] Epoch: 1 [196352/620022]    Loss: 0.007716   Batch Acc: 79.69
[Train] Epoch: 1 [196416/620022]    Loss: 0.008200   Batch Acc: 76.56
[Train] Epoch: 1 [196480/620022]    Loss: 0.009553   Batch Acc: 71.88
[Train] Epoch: 1 [196544/620022]    Loss: 0.008507   Batch Acc: 81.25
[Train] Epoch: 1 [196608/620022]    Loss: 0.008685   Batch Acc: 76.56
[Train] Epoch: 1 [196672/620022]    Loss: 0.007771   Batch Acc: 81.25
[Train] Epoch: 1 [196736/620022]    Loss: 0.010002   Batch Acc: 71.88
[Train] Epoch: 1 [196800/620022]    Loss: 0.006820   Batch Acc: 84.38
[Train] Epoch: 1 [196864/620022]    Loss: 0.009331   Batch Acc: 76.56
[Train] Epoch: 1 [196928/620022]    Loss: 0.008219   Batch Acc: 76.56
[Train] Epoch: 1 [196992/620022]    Loss: 0.009462   Batch Acc: 76.56
[Train] Epoch: 1 [197056/620022]    Loss: 0.007714   Batch Acc: 79.69
[Train] Epoch: 1 [197120/620022]    Loss: 0.007342   Batch Acc: 85.94
[Train] Epoch: 1 [197184/620022]    Loss: 0.008684   Batch Acc: 76.56
[Train] Epoch: 1 [197248/620022]    Loss: 0.008962   Batch Acc: 76.56
[Train] Epoch: 1 [197312/620022]    Loss: 0.013089   Batch Acc: 62.50
[Train] Epoch: 1 [197376/620022]    Loss: 0.007993   Batch Acc: 81.25
[Train] Epoch: 1 [197440/620022]    Loss: 0.008505   Batch Acc: 81.25
[Train] Epoch: 1 [197504/620022]    Loss: 0.010156   Batch Acc: 73.44
[Train] Epoch: 1 [197568/620022]    Loss: 0.007894   Batch Acc: 81.25
[Train] Epoch: 1 [197632/620022]    Loss: 0.011374   Batch Acc: 67.19
[Train] Epoch: 1 [197696/620022]    Loss: 0.010687   Batch Acc: 71.88
[Train] Epoch: 1 [197760/620022]    Loss: 0.009474   Batch Acc: 71.88
[Train] Epoch: 1 [197824/620022]    Loss: 0.010223   Batch Acc: 75.00
[Train] Epoch: 1 [197888/620022]    Loss: 0.007283   Batch Acc: 81.25
[Train] Epoch: 1 [197952/620022]    Loss: 0.008020   Batch Acc: 75.00
[Train] Epoch: 1 [198016/620022]    Loss: 0.010051   Batch Acc: 70.31
[Train] Epoch: 1 [198080/620022]    Loss: 0.007571   Batch Acc: 82.81
[Train] Epoch: 1 [198144/620022]    Loss: 0.007970   Batch Acc: 78.12
[Train] Epoch: 1 [198208/620022]    Loss: 0.007983   Batch Acc: 81.25
[Train] Epoch: 1 [198272/620022]    Loss: 0.008744   Batch Acc: 73.44
[Train] Epoch: 1 [198336/620022]    Loss: 0.009717   Batch Acc: 67.19
[Train] Epoch: 1 [198400/620022]    Loss: 0.010073   Batch Acc: 70.31
[Train] Epoch: 1 [198464/620022]    Loss: 0.007749   Batch Acc: 81.25
[Train] Epoch: 1 [198528/620022]    Loss: 0.010835   Batch Acc: 71.88
[Train] Epoch: 1 [198592/620022]    Loss: 0.009279   Batch Acc: 71.88
[Train] Epoch: 1 [198656/620022]    Loss: 0.009020   Batch Acc: 82.81
[Train] Epoch: 1 [198720/620022]    Loss: 0.007500   Batch Acc: 81.25
[Train] Epoch: 1 [198784/620022]    Loss: 0.005886   Batch Acc: 89.06
[Train] Epoch: 1 [198848/620022]    Loss: 0.010473   Batch Acc: 60.94
[Train] Epoch: 1 [198912/620022]    Loss: 0.008351   Batch Acc: 78.12
[Train] Epoch: 1 [198976/620022]    Loss: 0.009483   Batch Acc: 75.00
[Train] Epoch: 1 [199040/620022]    Loss: 0.008881   Batch Acc: 71.88
[Train] Epoch: 1 [199104/620022]    Loss: 0.007901   Batch Acc: 82.81
[Train] Epoch: 1 [199168/620022]    Loss: 0.008312   Batch Acc: 81.25
[Train] Epoch: 1 [199232/620022]    Loss: 0.007615   Batch Acc: 82.81
[Train] Epoch: 1 [199296/620022]    Loss: 0.008386   Batch Acc: 76.56
[Train] Epoch: 1 [199360/620022]    Loss: 0.007406   Batch Acc: 85.94
[Train] Epoch: 1 [199424/620022]    Loss: 0.008499   Batch Acc: 78.12
[Train] Epoch: 1 [199488/620022]    Loss: 0.008795   Batch Acc: 75.00
[Train] Epoch: 1 [199552/620022]    Loss: 0.009451   Batch Acc: 79.69
[Train] Epoch: 1 [199616/620022]    Loss: 0.009385   Batch Acc: 78.12
[Train] Epoch: 1 [199680/620022]    Loss: 0.007729   Batch Acc: 78.12
[Train] Epoch: 1 [199744/620022]    Loss: 0.009064   Batch Acc: 76.56
[Train] Epoch: 1 [199808/620022]    Loss: 0.010383   Batch Acc: 82.81
[Train] Epoch: 1 [199872/620022]    Loss: 0.008131   Batch Acc: 79.69
[Train] Epoch: 1 [199936/620022]    Loss: 0.006408   Batch Acc: 82.81
[Train] Epoch: 1 [200000/620022]    Loss: 0.005692   Batch Acc: 93.75
[Train] Epoch: 1 [200064/620022]    Loss: 0.008286   Batch Acc: 82.81
[Train] Epoch: 1 [200128/620022]    Loss: 0.009073   Batch Acc: 68.75
[Train] Epoch: 1 [200192/620022]    Loss: 0.007763   Batch Acc: 76.56
[Train] Epoch: 1 [200256/620022]    Loss: 0.007812   Batch Acc: 79.69
[Train] Epoch: 1 [200320/620022]    Loss: 0.006103   Batch Acc: 85.94
[Train] Epoch: 1 [200384/620022]    Loss: 0.006923   Batch Acc: 81.25
[Train] Epoch: 1 [200448/620022]    Loss: 0.009825   Batch Acc: 71.88
[Train] Epoch: 1 [200512/620022]    Loss: 0.008524   Batch Acc: 79.69
[Train] Epoch: 1 [200576/620022]    Loss: 0.009145   Batch Acc: 79.69
[Train] Epoch: 1 [200640/620022]    Loss: 0.010487   Batch Acc: 75.00
[Train] Epoch: 1 [200704/620022]    Loss: 0.007066   Batch Acc: 85.94
[Train] Epoch: 1 [200768/620022]    Loss: 0.009589   Batch Acc: 73.44
[Train] Epoch: 1 [200832/620022]    Loss: 0.009804   Batch Acc: 78.12
[Train] Epoch: 1 [200896/620022]    Loss: 0.006749   Batch Acc: 78.12
[Train] Epoch: 1 [200960/620022]    Loss: 0.008310   Batch Acc: 78.12
[Train] Epoch: 1 [201024/620022]    Loss: 0.007441   Batch Acc: 81.25
[Train] Epoch: 1 [201088/620022]    Loss: 0.006755   Batch Acc: 81.25
[Train] Epoch: 1 [201152/620022]    Loss: 0.008352   Batch Acc: 82.81
[Train] Epoch: 1 [201216/620022]    Loss: 0.007487   Batch Acc: 81.25
[Train] Epoch: 1 [201280/620022]    Loss: 0.010620   Batch Acc: 70.31
[Train] Epoch: 1 [201344/620022]    Loss: 0.008758   Batch Acc: 75.00
[Train] Epoch: 1 [201408/620022]    Loss: 0.010487   Batch Acc: 71.88
[Train] Epoch: 1 [201472/620022]    Loss: 0.008322   Batch Acc: 79.69
[Train] Epoch: 1 [201536/620022]    Loss: 0.007157   Batch Acc: 84.38
[Train] Epoch: 1 [201600/620022]    Loss: 0.007494   Batch Acc: 84.38
[Train] Epoch: 1 [201664/620022]    Loss: 0.005498   Batch Acc: 90.62
[Train] Epoch: 1 [201728/620022]    Loss: 0.008286   Batch Acc: 71.88
[Train] Epoch: 1 [201792/620022]    Loss: 0.010681   Batch Acc: 70.31
[Train] Epoch: 1 [201856/620022]    Loss: 0.010037   Batch Acc: 73.44
[Train] Epoch: 1 [201920/620022]    Loss: 0.008861   Batch Acc: 78.12
[Train] Epoch: 1 [201984/620022]    Loss: 0.007246   Batch Acc: 82.81
[Train] Epoch: 1 [202048/620022]    Loss: 0.009737   Batch Acc: 75.00
[Train] Epoch: 1 [202112/620022]    Loss: 0.009752   Batch Acc: 78.12
[Train] Epoch: 1 [202176/620022]    Loss: 0.009168   Batch Acc: 78.12
[Train] Epoch: 1 [202240/620022]    Loss: 0.010103   Batch Acc: 68.75
[Train] Epoch: 1 [202304/620022]    Loss: 0.007465   Batch Acc: 76.56
[Train] Epoch: 1 [202368/620022]    Loss: 0.006505   Batch Acc: 85.94
[Train] Epoch: 1 [202432/620022]    Loss: 0.009807   Batch Acc: 71.88
[Train] Epoch: 1 [202496/620022]    Loss: 0.006535   Batch Acc: 82.81
[Train] Epoch: 1 [202560/620022]    Loss: 0.009129   Batch Acc: 81.25
[Train] Epoch: 1 [202624/620022]    Loss: 0.011367   Batch Acc: 75.00
[Train] Epoch: 1 [202688/620022]    Loss: 0.009293   Batch Acc: 73.44
[Train] Epoch: 1 [202752/620022]    Loss: 0.007646   Batch Acc: 87.50
[Train] Epoch: 1 [202816/620022]    Loss: 0.013354   Batch Acc: 65.62
[Train] Epoch: 1 [202880/620022]    Loss: 0.007625   Batch Acc: 78.12
[Train] Epoch: 1 [202944/620022]    Loss: 0.010751   Batch Acc: 73.44
[Train] Epoch: 1 [203008/620022]    Loss: 0.008745   Batch Acc: 79.69
[Train] Epoch: 1 [203072/620022]    Loss: 0.009757   Batch Acc: 75.00
[Train] Epoch: 1 [203136/620022]    Loss: 0.009683   Batch Acc: 71.88
[Train] Epoch: 1 [203200/620022]    Loss: 0.007972   Batch Acc: 82.81
[Train] Epoch: 1 [203264/620022]    Loss: 0.007687   Batch Acc: 82.81
[Train] Epoch: 1 [203328/620022]    Loss: 0.010746   Batch Acc: 68.75
[Train] Epoch: 1 [203392/620022]    Loss: 0.011594   Batch Acc: 60.94
[Train] Epoch: 1 [203456/620022]    Loss: 0.007474   Batch Acc: 81.25
[Train] Epoch: 1 [203520/620022]    Loss: 0.008583   Batch Acc: 76.56
[Train] Epoch: 1 [203584/620022]    Loss: 0.010086   Batch Acc: 76.56
[Train] Epoch: 1 [203648/620022]    Loss: 0.011350   Batch Acc: 65.62
[Train] Epoch: 1 [203712/620022]    Loss: 0.009279   Batch Acc: 73.44
[Train] Epoch: 1 [203776/620022]    Loss: 0.009626   Batch Acc: 73.44
[Train] Epoch: 1 [203840/620022]    Loss: 0.011248   Batch Acc: 76.56
[Train] Epoch: 1 [203904/620022]    Loss: 0.010549   Batch Acc: 67.19
[Train] Epoch: 1 [203968/620022]    Loss: 0.008310   Batch Acc: 75.00
[Train] Epoch: 1 [204032/620022]    Loss: 0.009990   Batch Acc: 76.56
[Train] Epoch: 1 [204096/620022]    Loss: 0.006809   Batch Acc: 85.94
[Train] Epoch: 1 [204160/620022]    Loss: 0.007277   Batch Acc: 78.12
[Train] Epoch: 1 [204224/620022]    Loss: 0.008471   Batch Acc: 79.69
[Train] Epoch: 1 [204288/620022]    Loss: 0.010589   Batch Acc: 76.56
[Train] Epoch: 1 [204352/620022]    Loss: 0.009472   Batch Acc: 75.00
[Train] Epoch: 1 [204416/620022]    Loss: 0.008325   Batch Acc: 76.56
[Train] Epoch: 1 [204480/620022]    Loss: 0.010271   Batch Acc: 70.31
[Train] Epoch: 1 [204544/620022]    Loss: 0.008051   Batch Acc: 79.69
[Train] Epoch: 1 [204608/620022]    Loss: 0.009382   Batch Acc: 78.12
[Train] Epoch: 1 [204672/620022]    Loss: 0.008149   Batch Acc: 78.12
[Train] Epoch: 1 [204736/620022]    Loss: 0.008024   Batch Acc: 81.25
[Train] Epoch: 1 [204800/620022]    Loss: 0.008510   Batch Acc: 71.88
[Train] Epoch: 1 [204864/620022]    Loss: 0.006328   Batch Acc: 84.38
[Train] Epoch: 1 [204928/620022]    Loss: 0.007597   Batch Acc: 84.38
[Train] Epoch: 1 [204992/620022]    Loss: 0.010159   Batch Acc: 75.00
[Train] Epoch: 1 [205056/620022]    Loss: 0.011010   Batch Acc: 73.44
[Train] Epoch: 1 [205120/620022]    Loss: 0.012595   Batch Acc: 68.75
[Train] Epoch: 1 [205184/620022]    Loss: 0.011729   Batch Acc: 70.31
[Train] Epoch: 1 [205248/620022]    Loss: 0.007271   Batch Acc: 81.25
[Train] Epoch: 1 [205312/620022]    Loss: 0.008199   Batch Acc: 78.12
[Train] Epoch: 1 [205376/620022]    Loss: 0.008118   Batch Acc: 76.56
[Train] Epoch: 1 [205440/620022]    Loss: 0.009106   Batch Acc: 75.00
[Train] Epoch: 1 [205504/620022]    Loss: 0.008414   Batch Acc: 81.25
[Train] Epoch: 1 [205568/620022]    Loss: 0.010874   Batch Acc: 68.75
[Train] Epoch: 1 [205632/620022]    Loss: 0.006362   Batch Acc: 90.62
[Train] Epoch: 1 [205696/620022]    Loss: 0.006920   Batch Acc: 82.81
[Train] Epoch: 1 [205760/620022]    Loss: 0.008435   Batch Acc: 81.25
[Train] Epoch: 1 [205824/620022]    Loss: 0.008116   Batch Acc: 81.25
[Train] Epoch: 1 [205888/620022]    Loss: 0.008771   Batch Acc: 78.12
[Train] Epoch: 1 [205952/620022]    Loss: 0.008778   Batch Acc: 81.25
[Train] Epoch: 1 [206016/620022]    Loss: 0.008600   Batch Acc: 81.25
[Train] Epoch: 1 [206080/620022]    Loss: 0.011042   Batch Acc: 75.00
[Train] Epoch: 1 [206144/620022]    Loss: 0.008939   Batch Acc: 76.56
[Train] Epoch: 1 [206208/620022]    Loss: 0.011914   Batch Acc: 67.19
[Train] Epoch: 1 [206272/620022]    Loss: 0.008394   Batch Acc: 75.00
[Train] Epoch: 1 [206336/620022]    Loss: 0.009869   Batch Acc: 70.31
[Train] Epoch: 1 [206400/620022]    Loss: 0.006709   Batch Acc: 87.50
[Train] Epoch: 1 [206464/620022]    Loss: 0.007612   Batch Acc: 84.38
[Train] Epoch: 1 [206528/620022]    Loss: 0.009436   Batch Acc: 73.44
[Train] Epoch: 1 [206592/620022]    Loss: 0.009550   Batch Acc: 73.44
[Train] Epoch: 1 [206656/620022]    Loss: 0.007791   Batch Acc: 81.25
[Train] Epoch: 1 [206720/620022]    Loss: 0.009103   Batch Acc: 81.25
[Train] Epoch: 1 [206784/620022]    Loss: 0.008942   Batch Acc: 71.88
[Train] Epoch: 1 [206848/620022]    Loss: 0.007214   Batch Acc: 84.38
[Train] Epoch: 1 [206912/620022]    Loss: 0.009273   Batch Acc: 73.44
[Train] Epoch: 1 [206976/620022]    Loss: 0.008394   Batch Acc: 79.69
[Train] Epoch: 1 [207040/620022]    Loss: 0.008927   Batch Acc: 76.56
[Train] Epoch: 1 [207104/620022]    Loss: 0.007517   Batch Acc: 81.25
[Train] Epoch: 1 [207168/620022]    Loss: 0.007357   Batch Acc: 79.69
[Train] Epoch: 1 [207232/620022]    Loss: 0.007644   Batch Acc: 82.81
[Train] Epoch: 1 [207296/620022]    Loss: 0.008699   Batch Acc: 68.75
[Train] Epoch: 1 [207360/620022]    Loss: 0.010081   Batch Acc: 70.31
[Train] Epoch: 1 [207424/620022]    Loss: 0.008477   Batch Acc: 73.44
[Train] Epoch: 1 [207488/620022]    Loss: 0.007067   Batch Acc: 81.25
[Train] Epoch: 1 [207552/620022]    Loss: 0.008445   Batch Acc: 81.25
[Train] Epoch: 1 [207616/620022]    Loss: 0.007246   Batch Acc: 82.81
[Train] Epoch: 1 [207680/620022]    Loss: 0.008720   Batch Acc: 81.25
[Train] Epoch: 1 [207744/620022]    Loss: 0.007414   Batch Acc: 85.94
[Train] Epoch: 1 [207808/620022]    Loss: 0.009976   Batch Acc: 70.31
[Train] Epoch: 1 [207872/620022]    Loss: 0.007341   Batch Acc: 85.94
[Train] Epoch: 1 [207936/620022]    Loss: 0.008266   Batch Acc: 78.12
[Train] Epoch: 1 [208000/620022]    Loss: 0.008950   Batch Acc: 79.69
[Train] Epoch: 1 [208064/620022]    Loss: 0.009223   Batch Acc: 73.44
[Train] Epoch: 1 [208128/620022]    Loss: 0.010478   Batch Acc: 75.00
[Train] Epoch: 1 [208192/620022]    Loss: 0.008556   Batch Acc: 82.81
[Train] Epoch: 1 [208256/620022]    Loss: 0.008098   Batch Acc: 79.69
[Train] Epoch: 1 [208320/620022]    Loss: 0.007599   Batch Acc: 84.38
[Train] Epoch: 1 [208384/620022]    Loss: 0.007543   Batch Acc: 79.69
[Train] Epoch: 1 [208448/620022]    Loss: 0.007881   Batch Acc: 82.81
[Train] Epoch: 1 [208512/620022]    Loss: 0.009953   Batch Acc: 75.00
[Train] Epoch: 1 [208576/620022]    Loss: 0.006278   Batch Acc: 82.81
[Train] Epoch: 1 [208640/620022]    Loss: 0.009127   Batch Acc: 82.81
[Train] Epoch: 1 [208704/620022]    Loss: 0.008190   Batch Acc: 76.56
[Train] Epoch: 1 [208768/620022]    Loss: 0.007407   Batch Acc: 81.25
[Train] Epoch: 1 [208832/620022]    Loss: 0.008819   Batch Acc: 73.44
[Train] Epoch: 1 [208896/620022]    Loss: 0.006580   Batch Acc: 85.94
[Train] Epoch: 1 [208960/620022]    Loss: 0.010982   Batch Acc: 71.88
[Train] Epoch: 1 [209024/620022]    Loss: 0.008174   Batch Acc: 79.69
[Train] Epoch: 1 [209088/620022]    Loss: 0.008232   Batch Acc: 78.12
[Train] Epoch: 1 [209152/620022]    Loss: 0.007435   Batch Acc: 82.81
[Train] Epoch: 1 [209216/620022]    Loss: 0.009034   Batch Acc: 75.00
[Train] Epoch: 1 [209280/620022]    Loss: 0.009139   Batch Acc: 78.12
[Train] Epoch: 1 [209344/620022]    Loss: 0.007063   Batch Acc: 84.38
[Train] Epoch: 1 [209408/620022]    Loss: 0.010250   Batch Acc: 71.88
[Train] Epoch: 1 [209472/620022]    Loss: 0.008294   Batch Acc: 75.00
[Train] Epoch: 1 [209536/620022]    Loss: 0.009641   Batch Acc: 79.69
[Train] Epoch: 1 [209600/620022]    Loss: 0.007410   Batch Acc: 87.50
[Train] Epoch: 1 [209664/620022]    Loss: 0.008694   Batch Acc: 78.12
[Train] Epoch: 1 [209728/620022]    Loss: 0.007436   Batch Acc: 78.12
[Train] Epoch: 1 [209792/620022]    Loss: 0.009673   Batch Acc: 76.56
[Train] Epoch: 1 [209856/620022]    Loss: 0.008494   Batch Acc: 78.12
[Train] Epoch: 1 [209920/620022]    Loss: 0.007143   Batch Acc: 81.25
[Train] Epoch: 1 [209984/620022]    Loss: 0.009852   Batch Acc: 76.56
[Train] Epoch: 1 [210048/620022]    Loss: 0.009077   Batch Acc: 79.69
[Train] Epoch: 1 [210112/620022]    Loss: 0.009822   Batch Acc: 70.31
[Train] Epoch: 1 [210176/620022]    Loss: 0.008300   Batch Acc: 85.94
[Train] Epoch: 1 [210240/620022]    Loss: 0.009489   Batch Acc: 79.69
[Train] Epoch: 1 [210304/620022]    Loss: 0.006724   Batch Acc: 84.38
[Train] Epoch: 1 [210368/620022]    Loss: 0.006293   Batch Acc: 87.50
[Train] Epoch: 1 [210432/620022]    Loss: 0.007333   Batch Acc: 87.50
[Train] Epoch: 1 [210496/620022]    Loss: 0.009696   Batch Acc: 71.88
[Train] Epoch: 1 [210560/620022]    Loss: 0.008597   Batch Acc: 76.56
[Train] Epoch: 1 [210624/620022]    Loss: 0.007780   Batch Acc: 79.69
[Train] Epoch: 1 [210688/620022]    Loss: 0.007031   Batch Acc: 85.94
[Train] Epoch: 1 [210752/620022]    Loss: 0.008094   Batch Acc: 79.69
[Train] Epoch: 1 [210816/620022]    Loss: 0.008146   Batch Acc: 82.81
[Train] Epoch: 1 [210880/620022]    Loss: 0.006256   Batch Acc: 84.38
[Train] Epoch: 1 [210944/620022]    Loss: 0.008634   Batch Acc: 81.25
[Train] Epoch: 1 [211008/620022]    Loss: 0.007355   Batch Acc: 82.81
[Train] Epoch: 1 [211072/620022]    Loss: 0.008840   Batch Acc: 76.56
[Train] Epoch: 1 [211136/620022]    Loss: 0.008015   Batch Acc: 82.81
[Train] Epoch: 1 [211200/620022]    Loss: 0.007174   Batch Acc: 82.81
[Train] Epoch: 1 [211264/620022]    Loss: 0.008138   Batch Acc: 81.25
[Train] Epoch: 1 [211328/620022]    Loss: 0.007102   Batch Acc: 81.25
[Train] Epoch: 1 [211392/620022]    Loss: 0.009314   Batch Acc: 71.88
[Train] Epoch: 1 [211456/620022]    Loss: 0.009565   Batch Acc: 81.25
[Train] Epoch: 1 [211520/620022]    Loss: 0.007601   Batch Acc: 84.38
[Train] Epoch: 1 [211584/620022]    Loss: 0.008934   Batch Acc: 76.56
[Train] Epoch: 1 [211648/620022]    Loss: 0.009769   Batch Acc: 73.44
[Train] Epoch: 1 [211712/620022]    Loss: 0.008159   Batch Acc: 78.12
[Train] Epoch: 1 [211776/620022]    Loss: 0.006470   Batch Acc: 85.94
[Train] Epoch: 1 [211840/620022]    Loss: 0.009438   Batch Acc: 71.88
[Train] Epoch: 1 [211904/620022]    Loss: 0.009694   Batch Acc: 73.44
[Train] Epoch: 1 [211968/620022]    Loss: 0.007540   Batch Acc: 79.69
[Train] Epoch: 1 [212032/620022]    Loss: 0.008787   Batch Acc: 71.88
[Train] Epoch: 1 [212096/620022]    Loss: 0.009254   Batch Acc: 68.75
[Train] Epoch: 1 [212160/620022]    Loss: 0.008991   Batch Acc: 78.12
[Train] Epoch: 1 [212224/620022]    Loss: 0.010120   Batch Acc: 76.56
[Train] Epoch: 1 [212288/620022]    Loss: 0.009526   Batch Acc: 76.56
[Train] Epoch: 1 [212352/620022]    Loss: 0.007728   Batch Acc: 76.56
[Train] Epoch: 1 [212416/620022]    Loss: 0.006705   Batch Acc: 81.25
[Train] Epoch: 1 [212480/620022]    Loss: 0.007473   Batch Acc: 79.69
[Train] Epoch: 1 [212544/620022]    Loss: 0.007079   Batch Acc: 87.50
[Train] Epoch: 1 [212608/620022]    Loss: 0.008315   Batch Acc: 78.12
[Train] Epoch: 1 [212672/620022]    Loss: 0.009251   Batch Acc: 73.44
[Train] Epoch: 1 [212736/620022]    Loss: 0.009669   Batch Acc: 73.44
[Train] Epoch: 1 [212800/620022]    Loss: 0.008056   Batch Acc: 79.69
[Train] Epoch: 1 [212864/620022]    Loss: 0.009683   Batch Acc: 76.56
[Train] Epoch: 1 [212928/620022]    Loss: 0.009862   Batch Acc: 73.44
[Train] Epoch: 1 [212992/620022]    Loss: 0.008387   Batch Acc: 81.25
[Train] Epoch: 1 [213056/620022]    Loss: 0.007285   Batch Acc: 79.69
[Train] Epoch: 1 [213120/620022]    Loss: 0.009295   Batch Acc: 79.69
[Train] Epoch: 1 [213184/620022]    Loss: 0.008885   Batch Acc: 73.44
[Train] Epoch: 1 [213248/620022]    Loss: 0.010993   Batch Acc: 70.31
[Train] Epoch: 1 [213312/620022]    Loss: 0.008315   Batch Acc: 84.38
[Train] Epoch: 1 [213376/620022]    Loss: 0.007768   Batch Acc: 78.12
[Train] Epoch: 1 [213440/620022]    Loss: 0.010095   Batch Acc: 75.00
[Train] Epoch: 1 [213504/620022]    Loss: 0.007993   Batch Acc: 87.50
[Train] Epoch: 1 [213568/620022]    Loss: 0.010874   Batch Acc: 76.56
[Train] Epoch: 1 [213632/620022]    Loss: 0.008741   Batch Acc: 71.88
[Train] Epoch: 1 [213696/620022]    Loss: 0.009935   Batch Acc: 70.31
[Train] Epoch: 1 [213760/620022]    Loss: 0.010091   Batch Acc: 76.56
[Train] Epoch: 1 [213824/620022]    Loss: 0.010075   Batch Acc: 73.44
[Train] Epoch: 1 [213888/620022]    Loss: 0.006660   Batch Acc: 89.06
[Train] Epoch: 1 [213952/620022]    Loss: 0.008316   Batch Acc: 73.44
[Train] Epoch: 1 [214016/620022]    Loss: 0.010751   Batch Acc: 68.75
[Train] Epoch: 1 [214080/620022]    Loss: 0.008425   Batch Acc: 79.69
[Train] Epoch: 1 [214144/620022]    Loss: 0.006871   Batch Acc: 79.69
[Train] Epoch: 1 [214208/620022]    Loss: 0.007810   Batch Acc: 85.94
[Train] Epoch: 1 [214272/620022]    Loss: 0.008755   Batch Acc: 78.12
[Train] Epoch: 1 [214336/620022]    Loss: 0.009386   Batch Acc: 76.56
[Train] Epoch: 1 [214400/620022]    Loss: 0.010657   Batch Acc: 73.44
[Train] Epoch: 1 [214464/620022]    Loss: 0.007938   Batch Acc: 79.69
[Train] Epoch: 1 [214528/620022]    Loss: 0.008992   Batch Acc: 71.88
[Train] Epoch: 1 [214592/620022]    Loss: 0.006177   Batch Acc: 87.50
[Train] Epoch: 1 [214656/620022]    Loss: 0.007491   Batch Acc: 78.12
[Train] Epoch: 1 [214720/620022]    Loss: 0.008779   Batch Acc: 78.12
[Train] Epoch: 1 [214784/620022]    Loss: 0.010242   Batch Acc: 71.88
[Train] Epoch: 1 [214848/620022]    Loss: 0.009455   Batch Acc: 78.12
[Train] Epoch: 1 [214912/620022]    Loss: 0.009038   Batch Acc: 76.56
[Train] Epoch: 1 [214976/620022]    Loss: 0.009878   Batch Acc: 78.12
[Train] Epoch: 1 [215040/620022]    Loss: 0.009192   Batch Acc: 81.25
[Train] Epoch: 1 [215104/620022]    Loss: 0.008853   Batch Acc: 75.00
[Train] Epoch: 1 [215168/620022]    Loss: 0.006036   Batch Acc: 85.94
[Train] Epoch: 1 [215232/620022]    Loss: 0.009662   Batch Acc: 79.69
[Train] Epoch: 1 [215296/620022]    Loss: 0.010814   Batch Acc: 70.31
[Train] Epoch: 1 [215360/620022]    Loss: 0.009849   Batch Acc: 71.88
[Train] Epoch: 1 [215424/620022]    Loss: 0.010854   Batch Acc: 68.75
[Train] Epoch: 1 [215488/620022]    Loss: 0.008223   Batch Acc: 82.81
[Train] Epoch: 1 [215552/620022]    Loss: 0.008005   Batch Acc: 75.00
[Train] Epoch: 1 [215616/620022]    Loss: 0.007620   Batch Acc: 81.25
[Train] Epoch: 1 [215680/620022]    Loss: 0.006960   Batch Acc: 84.38
[Train] Epoch: 1 [215744/620022]    Loss: 0.007912   Batch Acc: 78.12
[Train] Epoch: 1 [215808/620022]    Loss: 0.008724   Batch Acc: 76.56
[Train] Epoch: 1 [215872/620022]    Loss: 0.010363   Batch Acc: 71.88
[Train] Epoch: 1 [215936/620022]    Loss: 0.006405   Batch Acc: 87.50
[Train] Epoch: 1 [216000/620022]    Loss: 0.008155   Batch Acc: 81.25
[Train] Epoch: 1 [216064/620022]    Loss: 0.008539   Batch Acc: 79.69
[Train] Epoch: 1 [216128/620022]    Loss: 0.008085   Batch Acc: 82.81
[Train] Epoch: 1 [216192/620022]    Loss: 0.007816   Batch Acc: 81.25
[Train] Epoch: 1 [216256/620022]    Loss: 0.009633   Batch Acc: 70.31
[Train] Epoch: 1 [216320/620022]    Loss: 0.009066   Batch Acc: 78.12
[Train] Epoch: 1 [216384/620022]    Loss: 0.007378   Batch Acc: 85.94
[Train] Epoch: 1 [216448/620022]    Loss: 0.008784   Batch Acc: 79.69
[Train] Epoch: 1 [216512/620022]    Loss: 0.007658   Batch Acc: 79.69
[Train] Epoch: 1 [216576/620022]    Loss: 0.006641   Batch Acc: 85.94
[Train] Epoch: 1 [216640/620022]    Loss: 0.009287   Batch Acc: 78.12
[Train] Epoch: 1 [216704/620022]    Loss: 0.008542   Batch Acc: 81.25
[Train] Epoch: 1 [216768/620022]    Loss: 0.008621   Batch Acc: 79.69
[Train] Epoch: 1 [216832/620022]    Loss: 0.007938   Batch Acc: 79.69
[Train] Epoch: 1 [216896/620022]    Loss: 0.006600   Batch Acc: 85.94
[Train] Epoch: 1 [216960/620022]    Loss: 0.011329   Batch Acc: 64.06
[Train] Epoch: 1 [217024/620022]    Loss: 0.007103   Batch Acc: 76.56
[Train] Epoch: 1 [217088/620022]    Loss: 0.010578   Batch Acc: 76.56
[Train] Epoch: 1 [217152/620022]    Loss: 0.009223   Batch Acc: 75.00
[Train] Epoch: 1 [217216/620022]    Loss: 0.008310   Batch Acc: 81.25
[Train] Epoch: 1 [217280/620022]    Loss: 0.007216   Batch Acc: 79.69
[Train] Epoch: 1 [217344/620022]    Loss: 0.007965   Batch Acc: 84.38
[Train] Epoch: 1 [217408/620022]    Loss: 0.008855   Batch Acc: 75.00
[Train] Epoch: 1 [217472/620022]    Loss: 0.008796   Batch Acc: 73.44
[Train] Epoch: 1 [217536/620022]    Loss: 0.010129   Batch Acc: 75.00
[Train] Epoch: 1 [217600/620022]    Loss: 0.007747   Batch Acc: 82.81
[Train] Epoch: 1 [217664/620022]    Loss: 0.009804   Batch Acc: 76.56
[Train] Epoch: 1 [217728/620022]    Loss: 0.009325   Batch Acc: 75.00
[Train] Epoch: 1 [217792/620022]    Loss: 0.008134   Batch Acc: 82.81
[Train] Epoch: 1 [217856/620022]    Loss: 0.009026   Batch Acc: 78.12
[Train] Epoch: 1 [217920/620022]    Loss: 0.008147   Batch Acc: 75.00
[Train] Epoch: 1 [217984/620022]    Loss: 0.008339   Batch Acc: 78.12
[Train] Epoch: 1 [218048/620022]    Loss: 0.007861   Batch Acc: 81.25
[Train] Epoch: 1 [218112/620022]    Loss: 0.007949   Batch Acc: 81.25
[Train] Epoch: 1 [218176/620022]    Loss: 0.008240   Batch Acc: 78.12
[Train] Epoch: 1 [218240/620022]    Loss: 0.007180   Batch Acc: 81.25
[Train] Epoch: 1 [218304/620022]    Loss: 0.007259   Batch Acc: 84.38
[Train] Epoch: 1 [218368/620022]    Loss: 0.009856   Batch Acc: 75.00
[Train] Epoch: 1 [218432/620022]    Loss: 0.008315   Batch Acc: 73.44
[Train] Epoch: 1 [218496/620022]    Loss: 0.009799   Batch Acc: 75.00
[Train] Epoch: 1 [218560/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 1 [218624/620022]    Loss: 0.006755   Batch Acc: 84.38
[Train] Epoch: 1 [218688/620022]    Loss: 0.008297   Batch Acc: 78.12
[Train] Epoch: 1 [218752/620022]    Loss: 0.009049   Batch Acc: 79.69
[Train] Epoch: 1 [218816/620022]    Loss: 0.008840   Batch Acc: 75.00
[Train] Epoch: 1 [218880/620022]    Loss: 0.005678   Batch Acc: 89.06
[Train] Epoch: 1 [218944/620022]    Loss: 0.010202   Batch Acc: 79.69
[Train] Epoch: 1 [219008/620022]    Loss: 0.008905   Batch Acc: 70.31
[Train] Epoch: 1 [219072/620022]    Loss: 0.008998   Batch Acc: 75.00
[Train] Epoch: 1 [219136/620022]    Loss: 0.006761   Batch Acc: 85.94
[Train] Epoch: 1 [219200/620022]    Loss: 0.006443   Batch Acc: 85.94
[Train] Epoch: 1 [219264/620022]    Loss: 0.008142   Batch Acc: 78.12
[Train] Epoch: 1 [219328/620022]    Loss: 0.012063   Batch Acc: 65.62
[Train] Epoch: 1 [219392/620022]    Loss: 0.008917   Batch Acc: 78.12
[Train] Epoch: 1 [219456/620022]    Loss: 0.008814   Batch Acc: 73.44
[Train] Epoch: 1 [219520/620022]    Loss: 0.008098   Batch Acc: 78.12
[Train] Epoch: 1 [219584/620022]    Loss: 0.010239   Batch Acc: 73.44
[Train] Epoch: 1 [219648/620022]    Loss: 0.009294   Batch Acc: 78.12
[Train] Epoch: 1 [219712/620022]    Loss: 0.010826   Batch Acc: 71.88
[Train] Epoch: 1 [219776/620022]    Loss: 0.009180   Batch Acc: 81.25
[Train] Epoch: 1 [219840/620022]    Loss: 0.006551   Batch Acc: 81.25
[Train] Epoch: 1 [219904/620022]    Loss: 0.009816   Batch Acc: 81.25
[Train] Epoch: 1 [219968/620022]    Loss: 0.011012   Batch Acc: 79.69
[Train] Epoch: 1 [220032/620022]    Loss: 0.008353   Batch Acc: 84.38
[Train] Epoch: 1 [220096/620022]    Loss: 0.006543   Batch Acc: 81.25
[Train] Epoch: 1 [220160/620022]    Loss: 0.007561   Batch Acc: 81.25
[Train] Epoch: 1 [220224/620022]    Loss: 0.012093   Batch Acc: 68.75
[Train] Epoch: 1 [220288/620022]    Loss: 0.011447   Batch Acc: 70.31
[Train] Epoch: 1 [220352/620022]    Loss: 0.008429   Batch Acc: 78.12
[Train] Epoch: 1 [220416/620022]    Loss: 0.008789   Batch Acc: 81.25
[Train] Epoch: 1 [220480/620022]    Loss: 0.010282   Batch Acc: 73.44
[Train] Epoch: 1 [220544/620022]    Loss: 0.008056   Batch Acc: 81.25
[Train] Epoch: 1 [220608/620022]    Loss: 0.010091   Batch Acc: 75.00
[Train] Epoch: 1 [220672/620022]    Loss: 0.007980   Batch Acc: 79.69
[Train] Epoch: 1 [220736/620022]    Loss: 0.008262   Batch Acc: 79.69
[Train] Epoch: 1 [220800/620022]    Loss: 0.008254   Batch Acc: 81.25
[Train] Epoch: 1 [220864/620022]    Loss: 0.009749   Batch Acc: 73.44
[Train] Epoch: 1 [220928/620022]    Loss: 0.008851   Batch Acc: 76.56
[Train] Epoch: 1 [220992/620022]    Loss: 0.007173   Batch Acc: 81.25
[Train] Epoch: 1 [221056/620022]    Loss: 0.008921   Batch Acc: 71.88
[Train] Epoch: 1 [221120/620022]    Loss: 0.007418   Batch Acc: 79.69
[Train] Epoch: 1 [221184/620022]    Loss: 0.007959   Batch Acc: 81.25
[Train] Epoch: 1 [221248/620022]    Loss: 0.006073   Batch Acc: 90.62
[Train] Epoch: 1 [221312/620022]    Loss: 0.008810   Batch Acc: 79.69
[Train] Epoch: 1 [221376/620022]    Loss: 0.008705   Batch Acc: 73.44
[Train] Epoch: 1 [221440/620022]    Loss: 0.005912   Batch Acc: 90.62
[Train] Epoch: 1 [221504/620022]    Loss: 0.009258   Batch Acc: 79.69
[Train] Epoch: 1 [221568/620022]    Loss: 0.008052   Batch Acc: 84.38
[Train] Epoch: 1 [221632/620022]    Loss: 0.010007   Batch Acc: 73.44
[Train] Epoch: 1 [221696/620022]    Loss: 0.007006   Batch Acc: 76.56
[Train] Epoch: 1 [221760/620022]    Loss: 0.008577   Batch Acc: 79.69
[Train] Epoch: 1 [221824/620022]    Loss: 0.008540   Batch Acc: 82.81
[Train] Epoch: 1 [221888/620022]    Loss: 0.008417   Batch Acc: 79.69
[Train] Epoch: 1 [221952/620022]    Loss: 0.009223   Batch Acc: 75.00
[Train] Epoch: 1 [222016/620022]    Loss: 0.011102   Batch Acc: 71.88
[Train] Epoch: 1 [222080/620022]    Loss: 0.009016   Batch Acc: 76.56
[Train] Epoch: 1 [222144/620022]    Loss: 0.010388   Batch Acc: 60.94
[Train] Epoch: 1 [222208/620022]    Loss: 0.009749   Batch Acc: 71.88
[Train] Epoch: 1 [222272/620022]    Loss: 0.006854   Batch Acc: 84.38
[Train] Epoch: 1 [222336/620022]    Loss: 0.006387   Batch Acc: 85.94
[Train] Epoch: 1 [222400/620022]    Loss: 0.006111   Batch Acc: 87.50
[Train] Epoch: 1 [222464/620022]    Loss: 0.009553   Batch Acc: 71.88
[Train] Epoch: 1 [222528/620022]    Loss: 0.007661   Batch Acc: 82.81
[Train] Epoch: 1 [222592/620022]    Loss: 0.011148   Batch Acc: 67.19
[Train] Epoch: 1 [222656/620022]    Loss: 0.010048   Batch Acc: 75.00
[Train] Epoch: 1 [222720/620022]    Loss: 0.010004   Batch Acc: 75.00
[Train] Epoch: 1 [222784/620022]    Loss: 0.008251   Batch Acc: 79.69
[Train] Epoch: 1 [222848/620022]    Loss: 0.009083   Batch Acc: 73.44
[Train] Epoch: 1 [222912/620022]    Loss: 0.008504   Batch Acc: 78.12
[Train] Epoch: 1 [222976/620022]    Loss: 0.009246   Batch Acc: 76.56
[Train] Epoch: 1 [223040/620022]    Loss: 0.008145   Batch Acc: 82.81
[Train] Epoch: 1 [223104/620022]    Loss: 0.007348   Batch Acc: 85.94
[Train] Epoch: 1 [223168/620022]    Loss: 0.007146   Batch Acc: 84.38
[Train] Epoch: 1 [223232/620022]    Loss: 0.008855   Batch Acc: 76.56
[Train] Epoch: 1 [223296/620022]    Loss: 0.009911   Batch Acc: 75.00
[Train] Epoch: 1 [223360/620022]    Loss: 0.007435   Batch Acc: 79.69
[Train] Epoch: 1 [223424/620022]    Loss: 0.010109   Batch Acc: 76.56
[Train] Epoch: 1 [223488/620022]    Loss: 0.007374   Batch Acc: 78.12
[Train] Epoch: 1 [223552/620022]    Loss: 0.007703   Batch Acc: 84.38
[Train] Epoch: 1 [223616/620022]    Loss: 0.008358   Batch Acc: 76.56
[Train] Epoch: 1 [223680/620022]    Loss: 0.008218   Batch Acc: 84.38
[Train] Epoch: 1 [223744/620022]    Loss: 0.007749   Batch Acc: 79.69
[Train] Epoch: 1 [223808/620022]    Loss: 0.009232   Batch Acc: 71.88
[Train] Epoch: 1 [223872/620022]    Loss: 0.005935   Batch Acc: 87.50
[Train] Epoch: 1 [223936/620022]    Loss: 0.008038   Batch Acc: 84.38
[Train] Epoch: 1 [224000/620022]    Loss: 0.007160   Batch Acc: 82.81
[Train] Epoch: 1 [224064/620022]    Loss: 0.008514   Batch Acc: 71.88
[Train] Epoch: 1 [224128/620022]    Loss: 0.011960   Batch Acc: 67.19
[Train] Epoch: 1 [224192/620022]    Loss: 0.006274   Batch Acc: 87.50
[Train] Epoch: 1 [224256/620022]    Loss: 0.008549   Batch Acc: 78.12
[Train] Epoch: 1 [224320/620022]    Loss: 0.012352   Batch Acc: 68.75
[Train] Epoch: 1 [224384/620022]    Loss: 0.011098   Batch Acc: 71.88
[Train] Epoch: 1 [224448/620022]    Loss: 0.008840   Batch Acc: 79.69
[Train] Epoch: 1 [224512/620022]    Loss: 0.008753   Batch Acc: 76.56
[Train] Epoch: 1 [224576/620022]    Loss: 0.009379   Batch Acc: 78.12
[Train] Epoch: 1 [224640/620022]    Loss: 0.007847   Batch Acc: 85.94
[Train] Epoch: 1 [224704/620022]    Loss: 0.008290   Batch Acc: 75.00
[Train] Epoch: 1 [224768/620022]    Loss: 0.009270   Batch Acc: 70.31
[Train] Epoch: 1 [224832/620022]    Loss: 0.008671   Batch Acc: 78.12
[Train] Epoch: 1 [224896/620022]    Loss: 0.008925   Batch Acc: 75.00
[Train] Epoch: 1 [224960/620022]    Loss: 0.009207   Batch Acc: 73.44
[Train] Epoch: 1 [225024/620022]    Loss: 0.009163   Batch Acc: 79.69
[Train] Epoch: 1 [225088/620022]    Loss: 0.008706   Batch Acc: 81.25
[Train] Epoch: 1 [225152/620022]    Loss: 0.008326   Batch Acc: 78.12
[Train] Epoch: 1 [225216/620022]    Loss: 0.008103   Batch Acc: 81.25
[Train] Epoch: 1 [225280/620022]    Loss: 0.009486   Batch Acc: 71.88
[Train] Epoch: 1 [225344/620022]    Loss: 0.008154   Batch Acc: 82.81
[Train] Epoch: 1 [225408/620022]    Loss: 0.010803   Batch Acc: 65.62
[Train] Epoch: 1 [225472/620022]    Loss: 0.009289   Batch Acc: 76.56
[Train] Epoch: 1 [225536/620022]    Loss: 0.008178   Batch Acc: 75.00
[Train] Epoch: 1 [225600/620022]    Loss: 0.010324   Batch Acc: 73.44
[Train] Epoch: 1 [225664/620022]    Loss: 0.009001   Batch Acc: 75.00
[Train] Epoch: 1 [225728/620022]    Loss: 0.006990   Batch Acc: 84.38
[Train] Epoch: 1 [225792/620022]    Loss: 0.009367   Batch Acc: 73.44
[Train] Epoch: 1 [225856/620022]    Loss: 0.008031   Batch Acc: 82.81
[Train] Epoch: 1 [225920/620022]    Loss: 0.006805   Batch Acc: 85.94
[Train] Epoch: 1 [225984/620022]    Loss: 0.007237   Batch Acc: 79.69
[Train] Epoch: 1 [226048/620022]    Loss: 0.008537   Batch Acc: 79.69
[Train] Epoch: 1 [226112/620022]    Loss: 0.010209   Batch Acc: 68.75
[Train] Epoch: 1 [226176/620022]    Loss: 0.008139   Batch Acc: 79.69
[Train] Epoch: 1 [226240/620022]    Loss: 0.007131   Batch Acc: 87.50
[Train] Epoch: 1 [226304/620022]    Loss: 0.007524   Batch Acc: 82.81
[Train] Epoch: 1 [226368/620022]    Loss: 0.008661   Batch Acc: 75.00
[Train] Epoch: 1 [226432/620022]    Loss: 0.009888   Batch Acc: 73.44
[Train] Epoch: 1 [226496/620022]    Loss: 0.007389   Batch Acc: 81.25
[Train] Epoch: 1 [226560/620022]    Loss: 0.010513   Batch Acc: 76.56
[Train] Epoch: 1 [226624/620022]    Loss: 0.009117   Batch Acc: 78.12
[Train] Epoch: 1 [226688/620022]    Loss: 0.007865   Batch Acc: 81.25
[Train] Epoch: 1 [226752/620022]    Loss: 0.013292   Batch Acc: 68.75
[Train] Epoch: 1 [226816/620022]    Loss: 0.010047   Batch Acc: 76.56
[Train] Epoch: 1 [226880/620022]    Loss: 0.008213   Batch Acc: 81.25
[Train] Epoch: 1 [226944/620022]    Loss: 0.007059   Batch Acc: 82.81
[Train] Epoch: 1 [227008/620022]    Loss: 0.007482   Batch Acc: 79.69
[Train] Epoch: 1 [227072/620022]    Loss: 0.009676   Batch Acc: 73.44
[Train] Epoch: 1 [227136/620022]    Loss: 0.008302   Batch Acc: 82.81
[Train] Epoch: 1 [227200/620022]    Loss: 0.007273   Batch Acc: 82.81
[Train] Epoch: 1 [227264/620022]    Loss: 0.007208   Batch Acc: 79.69
[Train] Epoch: 1 [227328/620022]    Loss: 0.008686   Batch Acc: 81.25
[Train] Epoch: 1 [227392/620022]    Loss: 0.010185   Batch Acc: 76.56
[Train] Epoch: 1 [227456/620022]    Loss: 0.007840   Batch Acc: 78.12
[Train] Epoch: 1 [227520/620022]    Loss: 0.006543   Batch Acc: 87.50
[Train] Epoch: 1 [227584/620022]    Loss: 0.008666   Batch Acc: 81.25
[Train] Epoch: 1 [227648/620022]    Loss: 0.007203   Batch Acc: 85.94
[Train] Epoch: 1 [227712/620022]    Loss: 0.007457   Batch Acc: 81.25
[Train] Epoch: 1 [227776/620022]    Loss: 0.006897   Batch Acc: 85.94
[Train] Epoch: 1 [227840/620022]    Loss: 0.008676   Batch Acc: 71.88
[Train] Epoch: 1 [227904/620022]    Loss: 0.008933   Batch Acc: 76.56
[Train] Epoch: 1 [227968/620022]    Loss: 0.011939   Batch Acc: 76.56
[Train] Epoch: 1 [228032/620022]    Loss: 0.007756   Batch Acc: 76.56
[Train] Epoch: 1 [228096/620022]    Loss: 0.009362   Batch Acc: 73.44
[Train] Epoch: 1 [228160/620022]    Loss: 0.008629   Batch Acc: 76.56
[Train] Epoch: 1 [228224/620022]    Loss: 0.010404   Batch Acc: 71.88
[Train] Epoch: 1 [228288/620022]    Loss: 0.006103   Batch Acc: 87.50
[Train] Epoch: 1 [228352/620022]    Loss: 0.008078   Batch Acc: 82.81
[Train] Epoch: 1 [228416/620022]    Loss: 0.009405   Batch Acc: 70.31
[Train] Epoch: 1 [228480/620022]    Loss: 0.008738   Batch Acc: 73.44
[Train] Epoch: 1 [228544/620022]    Loss: 0.005854   Batch Acc: 89.06
[Train] Epoch: 1 [228608/620022]    Loss: 0.008637   Batch Acc: 78.12
[Train] Epoch: 1 [228672/620022]    Loss: 0.008244   Batch Acc: 85.94
[Train] Epoch: 1 [228736/620022]    Loss: 0.009436   Batch Acc: 75.00
[Train] Epoch: 1 [228800/620022]    Loss: 0.006885   Batch Acc: 82.81
[Train] Epoch: 1 [228864/620022]    Loss: 0.008463   Batch Acc: 76.56
[Train] Epoch: 1 [228928/620022]    Loss: 0.006496   Batch Acc: 84.38
[Train] Epoch: 1 [228992/620022]    Loss: 0.007425   Batch Acc: 82.81
[Train] Epoch: 1 [229056/620022]    Loss: 0.006927   Batch Acc: 84.38
[Train] Epoch: 1 [229120/620022]    Loss: 0.009907   Batch Acc: 67.19
[Train] Epoch: 1 [229184/620022]    Loss: 0.007635   Batch Acc: 84.38
[Train] Epoch: 1 [229248/620022]    Loss: 0.008385   Batch Acc: 78.12
[Train] Epoch: 1 [229312/620022]    Loss: 0.009197   Batch Acc: 75.00
[Train] Epoch: 1 [229376/620022]    Loss: 0.008643   Batch Acc: 78.12
[Train] Epoch: 1 [229440/620022]    Loss: 0.008970   Batch Acc: 81.25
[Train] Epoch: 1 [229504/620022]    Loss: 0.007887   Batch Acc: 75.00
[Train] Epoch: 1 [229568/620022]    Loss: 0.010149   Batch Acc: 76.56
[Train] Epoch: 1 [229632/620022]    Loss: 0.008463   Batch Acc: 73.44
[Train] Epoch: 1 [229696/620022]    Loss: 0.009454   Batch Acc: 79.69
[Train] Epoch: 1 [229760/620022]    Loss: 0.012161   Batch Acc: 70.31
[Train] Epoch: 1 [229824/620022]    Loss: 0.008957   Batch Acc: 79.69
[Train] Epoch: 1 [229888/620022]    Loss: 0.006197   Batch Acc: 90.62
[Train] Epoch: 1 [229952/620022]    Loss: 0.007533   Batch Acc: 78.12
[Train] Epoch: 1 [230016/620022]    Loss: 0.007632   Batch Acc: 81.25
[Train] Epoch: 1 [230080/620022]    Loss: 0.008877   Batch Acc: 81.25
[Train] Epoch: 1 [230144/620022]    Loss: 0.012358   Batch Acc: 70.31
[Train] Epoch: 1 [230208/620022]    Loss: 0.008289   Batch Acc: 76.56
[Train] Epoch: 1 [230272/620022]    Loss: 0.010553   Batch Acc: 75.00
[Train] Epoch: 1 [230336/620022]    Loss: 0.009382   Batch Acc: 79.69
[Train] Epoch: 1 [230400/620022]    Loss: 0.006892   Batch Acc: 82.81
[Train] Epoch: 1 [230464/620022]    Loss: 0.011696   Batch Acc: 70.31
[Train] Epoch: 1 [230528/620022]    Loss: 0.009877   Batch Acc: 79.69
[Train] Epoch: 1 [230592/620022]    Loss: 0.008713   Batch Acc: 75.00
[Train] Epoch: 1 [230656/620022]    Loss: 0.009087   Batch Acc: 81.25
[Train] Epoch: 1 [230720/620022]    Loss: 0.007666   Batch Acc: 82.81
[Train] Epoch: 1 [230784/620022]    Loss: 0.006528   Batch Acc: 82.81
[Train] Epoch: 1 [230848/620022]    Loss: 0.009419   Batch Acc: 75.00
[Train] Epoch: 1 [230912/620022]    Loss: 0.008864   Batch Acc: 79.69
[Train] Epoch: 1 [230976/620022]    Loss: 0.007691   Batch Acc: 84.38
[Train] Epoch: 1 [231040/620022]    Loss: 0.006856   Batch Acc: 85.94
[Train] Epoch: 1 [231104/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 1 [231168/620022]    Loss: 0.010342   Batch Acc: 76.56
[Train] Epoch: 1 [231232/620022]    Loss: 0.009325   Batch Acc: 81.25
[Train] Epoch: 1 [231296/620022]    Loss: 0.010061   Batch Acc: 75.00
[Train] Epoch: 1 [231360/620022]    Loss: 0.009817   Batch Acc: 70.31
[Train] Epoch: 1 [231424/620022]    Loss: 0.008031   Batch Acc: 82.81
[Train] Epoch: 1 [231488/620022]    Loss: 0.008287   Batch Acc: 75.00
[Train] Epoch: 1 [231552/620022]    Loss: 0.007853   Batch Acc: 81.25
[Train] Epoch: 1 [231616/620022]    Loss: 0.007102   Batch Acc: 81.25
[Train] Epoch: 1 [231680/620022]    Loss: 0.010298   Batch Acc: 75.00
[Train] Epoch: 1 [231744/620022]    Loss: 0.006816   Batch Acc: 85.94
[Train] Epoch: 1 [231808/620022]    Loss: 0.006812   Batch Acc: 84.38
[Train] Epoch: 1 [231872/620022]    Loss: 0.009957   Batch Acc: 76.56
[Train] Epoch: 1 [231936/620022]    Loss: 0.010300   Batch Acc: 68.75
[Train] Epoch: 1 [232000/620022]    Loss: 0.009146   Batch Acc: 82.81
[Train] Epoch: 1 [232064/620022]    Loss: 0.009216   Batch Acc: 73.44
[Train] Epoch: 1 [232128/620022]    Loss: 0.009606   Batch Acc: 71.88
[Train] Epoch: 1 [232192/620022]    Loss: 0.008603   Batch Acc: 78.12
[Train] Epoch: 1 [232256/620022]    Loss: 0.009012   Batch Acc: 79.69
[Train] Epoch: 1 [232320/620022]    Loss: 0.007386   Batch Acc: 84.38
[Train] Epoch: 1 [232384/620022]    Loss: 0.008151   Batch Acc: 78.12
[Train] Epoch: 1 [232448/620022]    Loss: 0.008407   Batch Acc: 76.56
[Train] Epoch: 1 [232512/620022]    Loss: 0.008235   Batch Acc: 82.81
[Train] Epoch: 1 [232576/620022]    Loss: 0.009446   Batch Acc: 71.88
[Train] Epoch: 1 [232640/620022]    Loss: 0.009412   Batch Acc: 75.00
[Train] Epoch: 1 [232704/620022]    Loss: 0.010669   Batch Acc: 78.12
[Train] Epoch: 1 [232768/620022]    Loss: 0.011514   Batch Acc: 65.62
[Train] Epoch: 1 [232832/620022]    Loss: 0.006007   Batch Acc: 90.62
[Train] Epoch: 1 [232896/620022]    Loss: 0.007748   Batch Acc: 81.25
[Train] Epoch: 1 [232960/620022]    Loss: 0.009100   Batch Acc: 71.88
[Train] Epoch: 1 [233024/620022]    Loss: 0.010046   Batch Acc: 70.31
[Train] Epoch: 1 [233088/620022]    Loss: 0.008244   Batch Acc: 79.69
[Train] Epoch: 1 [233152/620022]    Loss: 0.008702   Batch Acc: 78.12
[Train] Epoch: 1 [233216/620022]    Loss: 0.009038   Batch Acc: 73.44
[Train] Epoch: 1 [233280/620022]    Loss: 0.010173   Batch Acc: 70.31
[Train] Epoch: 1 [233344/620022]    Loss: 0.009971   Batch Acc: 73.44
[Train] Epoch: 1 [233408/620022]    Loss: 0.009025   Batch Acc: 73.44
[Train] Epoch: 1 [233472/620022]    Loss: 0.009047   Batch Acc: 73.44
[Train] Epoch: 1 [233536/620022]    Loss: 0.008382   Batch Acc: 79.69
[Train] Epoch: 1 [233600/620022]    Loss: 0.007109   Batch Acc: 82.81
[Train] Epoch: 1 [233664/620022]    Loss: 0.005818   Batch Acc: 85.94
[Train] Epoch: 1 [233728/620022]    Loss: 0.008726   Batch Acc: 75.00
[Train] Epoch: 1 [233792/620022]    Loss: 0.008737   Batch Acc: 76.56
[Train] Epoch: 1 [233856/620022]    Loss: 0.006805   Batch Acc: 82.81
[Train] Epoch: 1 [233920/620022]    Loss: 0.008706   Batch Acc: 75.00
[Train] Epoch: 1 [233984/620022]    Loss: 0.009444   Batch Acc: 71.88
[Train] Epoch: 1 [234048/620022]    Loss: 0.007339   Batch Acc: 84.38
[Train] Epoch: 1 [234112/620022]    Loss: 0.012474   Batch Acc: 68.75
[Train] Epoch: 1 [234176/620022]    Loss: 0.009981   Batch Acc: 78.12
[Train] Epoch: 1 [234240/620022]    Loss: 0.009095   Batch Acc: 78.12
[Train] Epoch: 1 [234304/620022]    Loss: 0.009621   Batch Acc: 71.88
[Train] Epoch: 1 [234368/620022]    Loss: 0.009024   Batch Acc: 84.38
[Train] Epoch: 1 [234432/620022]    Loss: 0.008012   Batch Acc: 78.12
[Train] Epoch: 1 [234496/620022]    Loss: 0.007888   Batch Acc: 82.81
[Train] Epoch: 1 [234560/620022]    Loss: 0.008062   Batch Acc: 78.12
[Train] Epoch: 1 [234624/620022]    Loss: 0.008974   Batch Acc: 73.44
[Train] Epoch: 1 [234688/620022]    Loss: 0.007631   Batch Acc: 78.12
[Train] Epoch: 1 [234752/620022]    Loss: 0.006369   Batch Acc: 87.50
[Train] Epoch: 1 [234816/620022]    Loss: 0.009765   Batch Acc: 76.56
[Train] Epoch: 1 [234880/620022]    Loss: 0.009056   Batch Acc: 76.56
[Train] Epoch: 1 [234944/620022]    Loss: 0.009622   Batch Acc: 75.00
[Train] Epoch: 1 [235008/620022]    Loss: 0.006716   Batch Acc: 82.81
[Train] Epoch: 1 [235072/620022]    Loss: 0.008304   Batch Acc: 81.25
[Train] Epoch: 1 [235136/620022]    Loss: 0.010899   Batch Acc: 65.62
[Train] Epoch: 1 [235200/620022]    Loss: 0.008285   Batch Acc: 79.69
[Train] Epoch: 1 [235264/620022]    Loss: 0.011401   Batch Acc: 68.75
[Train] Epoch: 1 [235328/620022]    Loss: 0.012113   Batch Acc: 71.88
[Train] Epoch: 1 [235392/620022]    Loss: 0.008995   Batch Acc: 78.12
[Train] Epoch: 1 [235456/620022]    Loss: 0.008074   Batch Acc: 75.00
[Train] Epoch: 1 [235520/620022]    Loss: 0.011106   Batch Acc: 71.88
[Train] Epoch: 1 [235584/620022]    Loss: 0.007416   Batch Acc: 82.81
[Train] Epoch: 1 [235648/620022]    Loss: 0.007311   Batch Acc: 81.25
[Train] Epoch: 1 [235712/620022]    Loss: 0.007234   Batch Acc: 84.38
[Train] Epoch: 1 [235776/620022]    Loss: 0.007407   Batch Acc: 81.25
[Train] Epoch: 1 [235840/620022]    Loss: 0.008761   Batch Acc: 76.56
[Train] Epoch: 1 [235904/620022]    Loss: 0.009373   Batch Acc: 70.31
[Train] Epoch: 1 [235968/620022]    Loss: 0.010537   Batch Acc: 68.75
[Train] Epoch: 1 [236032/620022]    Loss: 0.009433   Batch Acc: 81.25
[Train] Epoch: 1 [236096/620022]    Loss: 0.008100   Batch Acc: 78.12
[Train] Epoch: 1 [236160/620022]    Loss: 0.008307   Batch Acc: 81.25
[Train] Epoch: 1 [236224/620022]    Loss: 0.007789   Batch Acc: 76.56
[Train] Epoch: 1 [236288/620022]    Loss: 0.009393   Batch Acc: 79.69
[Train] Epoch: 1 [236352/620022]    Loss: 0.008244   Batch Acc: 75.00
[Train] Epoch: 1 [236416/620022]    Loss: 0.010945   Batch Acc: 68.75
[Train] Epoch: 1 [236480/620022]    Loss: 0.008196   Batch Acc: 79.69
[Train] Epoch: 1 [236544/620022]    Loss: 0.007996   Batch Acc: 79.69
[Train] Epoch: 1 [236608/620022]    Loss: 0.011138   Batch Acc: 75.00
[Train] Epoch: 1 [236672/620022]    Loss: 0.007641   Batch Acc: 85.94
[Train] Epoch: 1 [236736/620022]    Loss: 0.008485   Batch Acc: 75.00
[Train] Epoch: 1 [236800/620022]    Loss: 0.008250   Batch Acc: 82.81
[Train] Epoch: 1 [236864/620022]    Loss: 0.008084   Batch Acc: 79.69
[Train] Epoch: 1 [236928/620022]    Loss: 0.008017   Batch Acc: 75.00
[Train] Epoch: 1 [236992/620022]    Loss: 0.009378   Batch Acc: 75.00
[Train] Epoch: 1 [237056/620022]    Loss: 0.007315   Batch Acc: 89.06
[Train] Epoch: 1 [237120/620022]    Loss: 0.009627   Batch Acc: 81.25
[Train] Epoch: 1 [237184/620022]    Loss: 0.008213   Batch Acc: 81.25
[Train] Epoch: 1 [237248/620022]    Loss: 0.008192   Batch Acc: 79.69
[Train] Epoch: 1 [237312/620022]    Loss: 0.008519   Batch Acc: 78.12
[Train] Epoch: 1 [237376/620022]    Loss: 0.009916   Batch Acc: 71.88
[Train] Epoch: 1 [237440/620022]    Loss: 0.008824   Batch Acc: 75.00
[Train] Epoch: 1 [237504/620022]    Loss: 0.010156   Batch Acc: 73.44
[Train] Epoch: 1 [237568/620022]    Loss: 0.007382   Batch Acc: 85.94
[Train] Epoch: 1 [237632/620022]    Loss: 0.008926   Batch Acc: 76.56
[Train] Epoch: 1 [237696/620022]    Loss: 0.007435   Batch Acc: 79.69
[Train] Epoch: 1 [237760/620022]    Loss: 0.008829   Batch Acc: 79.69
[Train] Epoch: 1 [237824/620022]    Loss: 0.009062   Batch Acc: 75.00
[Train] Epoch: 1 [237888/620022]    Loss: 0.011877   Batch Acc: 70.31
[Train] Epoch: 1 [237952/620022]    Loss: 0.010437   Batch Acc: 76.56
[Train] Epoch: 1 [238016/620022]    Loss: 0.009737   Batch Acc: 75.00
[Train] Epoch: 1 [238080/620022]    Loss: 0.007661   Batch Acc: 84.38
[Train] Epoch: 1 [238144/620022]    Loss: 0.008594   Batch Acc: 81.25
[Train] Epoch: 1 [238208/620022]    Loss: 0.008788   Batch Acc: 79.69
[Train] Epoch: 1 [238272/620022]    Loss: 0.010930   Batch Acc: 71.88
[Train] Epoch: 1 [238336/620022]    Loss: 0.007878   Batch Acc: 81.25
[Train] Epoch: 1 [238400/620022]    Loss: 0.008753   Batch Acc: 71.88
[Train] Epoch: 1 [238464/620022]    Loss: 0.009907   Batch Acc: 75.00
[Train] Epoch: 1 [238528/620022]    Loss: 0.007653   Batch Acc: 82.81
[Train] Epoch: 1 [238592/620022]    Loss: 0.010199   Batch Acc: 76.56
[Train] Epoch: 1 [238656/620022]    Loss: 0.009983   Batch Acc: 75.00
[Train] Epoch: 1 [238720/620022]    Loss: 0.008850   Batch Acc: 76.56
[Train] Epoch: 1 [238784/620022]    Loss: 0.009917   Batch Acc: 73.44
[Train] Epoch: 1 [238848/620022]    Loss: 0.010468   Batch Acc: 73.44
[Train] Epoch: 1 [238912/620022]    Loss: 0.008040   Batch Acc: 82.81
[Train] Epoch: 1 [238976/620022]    Loss: 0.006087   Batch Acc: 89.06
[Train] Epoch: 1 [239040/620022]    Loss: 0.005716   Batch Acc: 89.06
[Train] Epoch: 1 [239104/620022]    Loss: 0.007465   Batch Acc: 78.12
[Train] Epoch: 1 [239168/620022]    Loss: 0.008887   Batch Acc: 73.44
[Train] Epoch: 1 [239232/620022]    Loss: 0.007638   Batch Acc: 82.81
[Train] Epoch: 1 [239296/620022]    Loss: 0.009887   Batch Acc: 79.69
[Train] Epoch: 1 [239360/620022]    Loss: 0.008457   Batch Acc: 79.69
[Train] Epoch: 1 [239424/620022]    Loss: 0.008638   Batch Acc: 75.00
[Train] Epoch: 1 [239488/620022]    Loss: 0.010334   Batch Acc: 70.31
[Train] Epoch: 1 [239552/620022]    Loss: 0.009372   Batch Acc: 76.56
[Train] Epoch: 1 [239616/620022]    Loss: 0.007487   Batch Acc: 79.69
[Train] Epoch: 1 [239680/620022]    Loss: 0.008554   Batch Acc: 76.56
[Train] Epoch: 1 [239744/620022]    Loss: 0.008021   Batch Acc: 81.25
[Train] Epoch: 1 [239808/620022]    Loss: 0.006470   Batch Acc: 87.50
[Train] Epoch: 1 [239872/620022]    Loss: 0.007476   Batch Acc: 84.38
[Train] Epoch: 1 [239936/620022]    Loss: 0.005777   Batch Acc: 87.50
[Train] Epoch: 1 [240000/620022]    Loss: 0.008887   Batch Acc: 78.12
[Train] Epoch: 1 [240064/620022]    Loss: 0.005569   Batch Acc: 90.62
[Train] Epoch: 1 [240128/620022]    Loss: 0.009706   Batch Acc: 75.00
[Train] Epoch: 1 [240192/620022]    Loss: 0.006103   Batch Acc: 87.50
[Train] Epoch: 1 [240256/620022]    Loss: 0.006182   Batch Acc: 85.94
[Train] Epoch: 1 [240320/620022]    Loss: 0.008611   Batch Acc: 78.12
[Train] Epoch: 1 [240384/620022]    Loss: 0.007284   Batch Acc: 84.38
[Train] Epoch: 1 [240448/620022]    Loss: 0.008720   Batch Acc: 75.00
[Train] Epoch: 1 [240512/620022]    Loss: 0.007756   Batch Acc: 87.50
[Train] Epoch: 1 [240576/620022]    Loss: 0.011413   Batch Acc: 64.06
[Train] Epoch: 1 [240640/620022]    Loss: 0.008341   Batch Acc: 81.25
[Train] Epoch: 1 [240704/620022]    Loss: 0.009074   Batch Acc: 78.12
[Train] Epoch: 1 [240768/620022]    Loss: 0.009006   Batch Acc: 78.12
[Train] Epoch: 1 [240832/620022]    Loss: 0.006884   Batch Acc: 76.56
[Train] Epoch: 1 [240896/620022]    Loss: 0.011338   Batch Acc: 71.88
[Train] Epoch: 1 [240960/620022]    Loss: 0.008411   Batch Acc: 79.69
[Train] Epoch: 1 [241024/620022]    Loss: 0.009308   Batch Acc: 70.31
[Train] Epoch: 1 [241088/620022]    Loss: 0.011258   Batch Acc: 75.00
[Train] Epoch: 1 [241152/620022]    Loss: 0.008144   Batch Acc: 79.69
[Train] Epoch: 1 [241216/620022]    Loss: 0.009260   Batch Acc: 73.44
[Train] Epoch: 1 [241280/620022]    Loss: 0.009890   Batch Acc: 75.00
[Train] Epoch: 1 [241344/620022]    Loss: 0.008021   Batch Acc: 78.12
[Train] Epoch: 1 [241408/620022]    Loss: 0.010258   Batch Acc: 73.44
[Train] Epoch: 1 [241472/620022]    Loss: 0.007144   Batch Acc: 85.94
[Train] Epoch: 1 [241536/620022]    Loss: 0.006693   Batch Acc: 84.38
[Train] Epoch: 1 [241600/620022]    Loss: 0.007176   Batch Acc: 84.38
[Train] Epoch: 1 [241664/620022]    Loss: 0.008680   Batch Acc: 79.69
[Train] Epoch: 1 [241728/620022]    Loss: 0.008161   Batch Acc: 81.25
[Train] Epoch: 1 [241792/620022]    Loss: 0.009217   Batch Acc: 78.12
[Train] Epoch: 1 [241856/620022]    Loss: 0.009466   Batch Acc: 73.44
[Train] Epoch: 1 [241920/620022]    Loss: 0.007495   Batch Acc: 82.81
[Train] Epoch: 1 [241984/620022]    Loss: 0.009735   Batch Acc: 78.12
[Train] Epoch: 1 [242048/620022]    Loss: 0.009664   Batch Acc: 76.56
[Train] Epoch: 1 [242112/620022]    Loss: 0.008738   Batch Acc: 73.44
[Train] Epoch: 1 [242176/620022]    Loss: 0.009097   Batch Acc: 70.31
[Train] Epoch: 1 [242240/620022]    Loss: 0.009133   Batch Acc: 75.00
[Train] Epoch: 1 [242304/620022]    Loss: 0.008437   Batch Acc: 81.25
[Train] Epoch: 1 [242368/620022]    Loss: 0.008211   Batch Acc: 79.69
[Train] Epoch: 1 [242432/620022]    Loss: 0.006987   Batch Acc: 84.38
[Train] Epoch: 1 [242496/620022]    Loss: 0.008478   Batch Acc: 81.25
[Train] Epoch: 1 [242560/620022]    Loss: 0.007988   Batch Acc: 81.25
[Train] Epoch: 1 [242624/620022]    Loss: 0.010219   Batch Acc: 68.75
[Train] Epoch: 1 [242688/620022]    Loss: 0.010093   Batch Acc: 71.88
[Train] Epoch: 1 [242752/620022]    Loss: 0.010067   Batch Acc: 75.00
[Train] Epoch: 1 [242816/620022]    Loss: 0.008940   Batch Acc: 71.88
[Train] Epoch: 1 [242880/620022]    Loss: 0.007260   Batch Acc: 85.94
[Train] Epoch: 1 [242944/620022]    Loss: 0.010535   Batch Acc: 78.12
[Train] Epoch: 1 [243008/620022]    Loss: 0.008717   Batch Acc: 79.69
[Train] Epoch: 1 [243072/620022]    Loss: 0.006672   Batch Acc: 85.94
[Train] Epoch: 1 [243136/620022]    Loss: 0.009432   Batch Acc: 75.00
[Train] Epoch: 1 [243200/620022]    Loss: 0.008122   Batch Acc: 75.00
[Train] Epoch: 1 [243264/620022]    Loss: 0.007178   Batch Acc: 78.12
[Train] Epoch: 1 [243328/620022]    Loss: 0.008177   Batch Acc: 76.56
[Train] Epoch: 1 [243392/620022]    Loss: 0.007896   Batch Acc: 78.12
[Train] Epoch: 1 [243456/620022]    Loss: 0.009681   Batch Acc: 75.00
[Train] Epoch: 1 [243520/620022]    Loss: 0.010855   Batch Acc: 78.12
[Train] Epoch: 1 [243584/620022]    Loss: 0.010288   Batch Acc: 68.75
[Train] Epoch: 1 [243648/620022]    Loss: 0.009283   Batch Acc: 71.88
[Train] Epoch: 1 [243712/620022]    Loss: 0.008998   Batch Acc: 71.88
[Train] Epoch: 1 [243776/620022]    Loss: 0.011674   Batch Acc: 73.44
[Train] Epoch: 1 [243840/620022]    Loss: 0.009971   Batch Acc: 73.44
[Train] Epoch: 1 [243904/620022]    Loss: 0.008563   Batch Acc: 79.69
[Train] Epoch: 1 [243968/620022]    Loss: 0.008536   Batch Acc: 75.00
[Train] Epoch: 1 [244032/620022]    Loss: 0.007829   Batch Acc: 79.69
[Train] Epoch: 1 [244096/620022]    Loss: 0.006794   Batch Acc: 89.06
[Train] Epoch: 1 [244160/620022]    Loss: 0.007753   Batch Acc: 84.38
[Train] Epoch: 1 [244224/620022]    Loss: 0.010288   Batch Acc: 76.56
[Train] Epoch: 1 [244288/620022]    Loss: 0.007261   Batch Acc: 81.25
[Train] Epoch: 1 [244352/620022]    Loss: 0.008182   Batch Acc: 76.56
[Train] Epoch: 1 [244416/620022]    Loss: 0.009409   Batch Acc: 71.88
[Train] Epoch: 1 [244480/620022]    Loss: 0.007921   Batch Acc: 76.56
[Train] Epoch: 1 [244544/620022]    Loss: 0.008229   Batch Acc: 79.69
[Train] Epoch: 1 [244608/620022]    Loss: 0.007801   Batch Acc: 85.94
[Train] Epoch: 1 [244672/620022]    Loss: 0.008021   Batch Acc: 82.81
[Train] Epoch: 1 [244736/620022]    Loss: 0.008329   Batch Acc: 75.00
[Train] Epoch: 1 [244800/620022]    Loss: 0.009483   Batch Acc: 70.31
[Train] Epoch: 1 [244864/620022]    Loss: 0.006746   Batch Acc: 85.94
[Train] Epoch: 1 [244928/620022]    Loss: 0.009975   Batch Acc: 79.69
[Train] Epoch: 1 [244992/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 1 [245056/620022]    Loss: 0.010086   Batch Acc: 76.56
[Train] Epoch: 1 [245120/620022]    Loss: 0.008444   Batch Acc: 76.56
[Train] Epoch: 1 [245184/620022]    Loss: 0.010603   Batch Acc: 68.75
[Train] Epoch: 1 [245248/620022]    Loss: 0.008831   Batch Acc: 79.69
[Train] Epoch: 1 [245312/620022]    Loss: 0.006558   Batch Acc: 85.94
[Train] Epoch: 1 [245376/620022]    Loss: 0.005563   Batch Acc: 87.50
[Train] Epoch: 1 [245440/620022]    Loss: 0.007615   Batch Acc: 79.69
[Train] Epoch: 1 [245504/620022]    Loss: 0.012199   Batch Acc: 67.19
[Train] Epoch: 1 [245568/620022]    Loss: 0.007729   Batch Acc: 81.25
[Train] Epoch: 1 [245632/620022]    Loss: 0.010781   Batch Acc: 70.31
[Train] Epoch: 1 [245696/620022]    Loss: 0.007035   Batch Acc: 78.12
[Train] Epoch: 1 [245760/620022]    Loss: 0.008905   Batch Acc: 75.00
[Train] Epoch: 1 [245824/620022]    Loss: 0.008027   Batch Acc: 76.56
[Train] Epoch: 1 [245888/620022]    Loss: 0.007949   Batch Acc: 76.56
[Train] Epoch: 1 [245952/620022]    Loss: 0.007306   Batch Acc: 82.81
[Train] Epoch: 1 [246016/620022]    Loss: 0.005973   Batch Acc: 87.50
[Train] Epoch: 1 [246080/620022]    Loss: 0.009040   Batch Acc: 75.00
[Train] Epoch: 1 [246144/620022]    Loss: 0.008878   Batch Acc: 75.00
[Train] Epoch: 1 [246208/620022]    Loss: 0.008565   Batch Acc: 76.56
[Train] Epoch: 1 [246272/620022]    Loss: 0.010435   Batch Acc: 75.00
[Train] Epoch: 1 [246336/620022]    Loss: 0.008826   Batch Acc: 75.00
[Train] Epoch: 1 [246400/620022]    Loss: 0.008870   Batch Acc: 78.12
[Train] Epoch: 1 [246464/620022]    Loss: 0.007586   Batch Acc: 76.56
[Train] Epoch: 1 [246528/620022]    Loss: 0.008877   Batch Acc: 76.56
[Train] Epoch: 1 [246592/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 1 [246656/620022]    Loss: 0.007962   Batch Acc: 78.12
[Train] Epoch: 1 [246720/620022]    Loss: 0.012120   Batch Acc: 71.88
[Train] Epoch: 1 [246784/620022]    Loss: 0.006036   Batch Acc: 90.62
[Train] Epoch: 1 [246848/620022]    Loss: 0.009479   Batch Acc: 76.56
[Train] Epoch: 1 [246912/620022]    Loss: 0.007614   Batch Acc: 79.69
[Train] Epoch: 1 [246976/620022]    Loss: 0.009417   Batch Acc: 78.12
[Train] Epoch: 1 [247040/620022]    Loss: 0.010137   Batch Acc: 76.56
[Train] Epoch: 1 [247104/620022]    Loss: 0.008253   Batch Acc: 82.81
[Train] Epoch: 1 [247168/620022]    Loss: 0.008511   Batch Acc: 79.69
[Train] Epoch: 1 [247232/620022]    Loss: 0.009000   Batch Acc: 76.56
[Train] Epoch: 1 [247296/620022]    Loss: 0.009683   Batch Acc: 79.69
[Train] Epoch: 1 [247360/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 1 [247424/620022]    Loss: 0.007095   Batch Acc: 85.94
[Train] Epoch: 1 [247488/620022]    Loss: 0.010047   Batch Acc: 71.88
[Train] Epoch: 1 [247552/620022]    Loss: 0.009988   Batch Acc: 73.44
[Train] Epoch: 1 [247616/620022]    Loss: 0.007539   Batch Acc: 82.81
[Train] Epoch: 1 [247680/620022]    Loss: 0.009532   Batch Acc: 73.44
[Train] Epoch: 1 [247744/620022]    Loss: 0.008646   Batch Acc: 79.69
[Train] Epoch: 1 [247808/620022]    Loss: 0.009135   Batch Acc: 78.12
[Train] Epoch: 1 [247872/620022]    Loss: 0.005860   Batch Acc: 92.19
[Train] Epoch: 1 [247936/620022]    Loss: 0.009395   Batch Acc: 73.44
[Train] Epoch: 1 [248000/620022]    Loss: 0.010057   Batch Acc: 76.56
[Train] Epoch: 1 [248064/620022]    Loss: 0.009478   Batch Acc: 71.88
[Train] Epoch: 1 [248128/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 1 [248192/620022]    Loss: 0.009242   Batch Acc: 75.00
[Train] Epoch: 1 [248256/620022]    Loss: 0.005008   Batch Acc: 92.19
[Train] Epoch: 1 [248320/620022]    Loss: 0.006352   Batch Acc: 89.06
[Train] Epoch: 1 [248384/620022]    Loss: 0.007914   Batch Acc: 75.00
[Train] Epoch: 1 [248448/620022]    Loss: 0.008755   Batch Acc: 78.12
[Train] Epoch: 1 [248512/620022]    Loss: 0.009105   Batch Acc: 78.12
[Train] Epoch: 1 [248576/620022]    Loss: 0.011599   Batch Acc: 68.75
[Train] Epoch: 1 [248640/620022]    Loss: 0.010290   Batch Acc: 76.56
[Train] Epoch: 1 [248704/620022]    Loss: 0.008097   Batch Acc: 81.25
[Train] Epoch: 1 [248768/620022]    Loss: 0.009462   Batch Acc: 75.00
[Train] Epoch: 1 [248832/620022]    Loss: 0.009729   Batch Acc: 76.56
[Train] Epoch: 1 [248896/620022]    Loss: 0.008627   Batch Acc: 73.44
[Train] Epoch: 1 [248960/620022]    Loss: 0.010571   Batch Acc: 73.44
[Train] Epoch: 1 [249024/620022]    Loss: 0.009540   Batch Acc: 76.56
[Train] Epoch: 1 [249088/620022]    Loss: 0.007429   Batch Acc: 84.38
[Train] Epoch: 1 [249152/620022]    Loss: 0.010728   Batch Acc: 68.75
[Train] Epoch: 1 [249216/620022]    Loss: 0.008437   Batch Acc: 78.12
[Train] Epoch: 1 [249280/620022]    Loss: 0.008235   Batch Acc: 78.12
[Train] Epoch: 1 [249344/620022]    Loss: 0.010290   Batch Acc: 73.44
[Train] Epoch: 1 [249408/620022]    Loss: 0.007751   Batch Acc: 84.38
[Train] Epoch: 1 [249472/620022]    Loss: 0.009259   Batch Acc: 78.12
[Train] Epoch: 1 [249536/620022]    Loss: 0.008123   Batch Acc: 75.00
[Train] Epoch: 1 [249600/620022]    Loss: 0.009242   Batch Acc: 75.00
[Train] Epoch: 1 [249664/620022]    Loss: 0.008269   Batch Acc: 82.81
[Train] Epoch: 1 [249728/620022]    Loss: 0.010577   Batch Acc: 70.31
[Train] Epoch: 1 [249792/620022]    Loss: 0.007411   Batch Acc: 84.38
[Train] Epoch: 1 [249856/620022]    Loss: 0.008803   Batch Acc: 78.12
[Train] Epoch: 1 [249920/620022]    Loss: 0.008050   Batch Acc: 76.56
[Train] Epoch: 1 [249984/620022]    Loss: 0.008788   Batch Acc: 82.81
[Train] Epoch: 1 [250048/620022]    Loss: 0.007279   Batch Acc: 81.25
[Train] Epoch: 1 [250112/620022]    Loss: 0.007640   Batch Acc: 81.25
[Train] Epoch: 1 [250176/620022]    Loss: 0.011097   Batch Acc: 71.88
[Train] Epoch: 1 [250240/620022]    Loss: 0.009642   Batch Acc: 71.88
[Train] Epoch: 1 [250304/620022]    Loss: 0.008686   Batch Acc: 76.56
[Train] Epoch: 1 [250368/620022]    Loss: 0.010687   Batch Acc: 68.75
[Train] Epoch: 1 [250432/620022]    Loss: 0.009218   Batch Acc: 78.12
[Train] Epoch: 1 [250496/620022]    Loss: 0.008802   Batch Acc: 76.56
[Train] Epoch: 1 [250560/620022]    Loss: 0.007896   Batch Acc: 81.25
[Train] Epoch: 1 [250624/620022]    Loss: 0.007332   Batch Acc: 81.25
[Train] Epoch: 1 [250688/620022]    Loss: 0.006137   Batch Acc: 84.38
[Train] Epoch: 1 [250752/620022]    Loss: 0.010670   Batch Acc: 70.31
[Train] Epoch: 1 [250816/620022]    Loss: 0.007689   Batch Acc: 78.12
[Train] Epoch: 1 [250880/620022]    Loss: 0.008970   Batch Acc: 76.56
[Train] Epoch: 1 [250944/620022]    Loss: 0.009067   Batch Acc: 75.00
[Train] Epoch: 1 [251008/620022]    Loss: 0.007494   Batch Acc: 79.69
[Train] Epoch: 1 [251072/620022]    Loss: 0.007881   Batch Acc: 81.25
[Train] Epoch: 1 [251136/620022]    Loss: 0.008616   Batch Acc: 76.56
[Train] Epoch: 1 [251200/620022]    Loss: 0.008991   Batch Acc: 75.00
[Train] Epoch: 1 [251264/620022]    Loss: 0.009204   Batch Acc: 75.00
[Train] Epoch: 1 [251328/620022]    Loss: 0.007508   Batch Acc: 82.81
[Train] Epoch: 1 [251392/620022]    Loss: 0.007594   Batch Acc: 81.25
[Train] Epoch: 1 [251456/620022]    Loss: 0.006908   Batch Acc: 84.38
[Train] Epoch: 1 [251520/620022]    Loss: 0.009461   Batch Acc: 75.00
[Train] Epoch: 1 [251584/620022]    Loss: 0.008063   Batch Acc: 76.56
[Train] Epoch: 1 [251648/620022]    Loss: 0.009398   Batch Acc: 67.19
[Train] Epoch: 1 [251712/620022]    Loss: 0.008113   Batch Acc: 73.44
[Train] Epoch: 1 [251776/620022]    Loss: 0.009759   Batch Acc: 75.00
[Train] Epoch: 1 [251840/620022]    Loss: 0.008753   Batch Acc: 73.44
[Train] Epoch: 1 [251904/620022]    Loss: 0.007950   Batch Acc: 81.25
[Train] Epoch: 1 [251968/620022]    Loss: 0.010140   Batch Acc: 68.75
[Train] Epoch: 1 [252032/620022]    Loss: 0.008273   Batch Acc: 75.00
[Train] Epoch: 1 [252096/620022]    Loss: 0.010047   Batch Acc: 70.31
[Train] Epoch: 1 [252160/620022]    Loss: 0.009178   Batch Acc: 76.56
[Train] Epoch: 1 [252224/620022]    Loss: 0.009785   Batch Acc: 71.88
[Train] Epoch: 1 [252288/620022]    Loss: 0.011813   Batch Acc: 67.19
[Train] Epoch: 1 [252352/620022]    Loss: 0.008190   Batch Acc: 81.25
[Train] Epoch: 1 [252416/620022]    Loss: 0.007355   Batch Acc: 82.81
[Train] Epoch: 1 [252480/620022]    Loss: 0.007723   Batch Acc: 82.81
[Train] Epoch: 1 [252544/620022]    Loss: 0.009440   Batch Acc: 73.44
[Train] Epoch: 1 [252608/620022]    Loss: 0.008545   Batch Acc: 79.69
[Train] Epoch: 1 [252672/620022]    Loss: 0.008814   Batch Acc: 79.69
[Train] Epoch: 1 [252736/620022]    Loss: 0.009305   Batch Acc: 71.88
[Train] Epoch: 1 [252800/620022]    Loss: 0.009294   Batch Acc: 76.56
[Train] Epoch: 1 [252864/620022]    Loss: 0.007855   Batch Acc: 85.94
[Train] Epoch: 1 [252928/620022]    Loss: 0.009018   Batch Acc: 76.56
[Train] Epoch: 1 [252992/620022]    Loss: 0.009372   Batch Acc: 79.69
[Train] Epoch: 1 [253056/620022]    Loss: 0.008361   Batch Acc: 78.12
[Train] Epoch: 1 [253120/620022]    Loss: 0.010719   Batch Acc: 71.88
[Train] Epoch: 1 [253184/620022]    Loss: 0.008704   Batch Acc: 79.69
[Train] Epoch: 1 [253248/620022]    Loss: 0.009555   Batch Acc: 76.56
[Train] Epoch: 1 [253312/620022]    Loss: 0.009082   Batch Acc: 76.56
[Train] Epoch: 1 [253376/620022]    Loss: 0.009321   Batch Acc: 76.56
[Train] Epoch: 1 [253440/620022]    Loss: 0.008694   Batch Acc: 71.88
[Train] Epoch: 1 [253504/620022]    Loss: 0.007845   Batch Acc: 79.69
[Train] Epoch: 1 [253568/620022]    Loss: 0.009287   Batch Acc: 73.44
[Train] Epoch: 1 [253632/620022]    Loss: 0.007779   Batch Acc: 75.00
[Train] Epoch: 1 [253696/620022]    Loss: 0.009389   Batch Acc: 76.56
[Train] Epoch: 1 [253760/620022]    Loss: 0.009736   Batch Acc: 75.00
[Train] Epoch: 1 [253824/620022]    Loss: 0.010638   Batch Acc: 73.44
[Train] Epoch: 1 [253888/620022]    Loss: 0.011445   Batch Acc: 73.44
[Train] Epoch: 1 [253952/620022]    Loss: 0.010057   Batch Acc: 70.31
[Train] Epoch: 1 [254016/620022]    Loss: 0.006582   Batch Acc: 87.50
[Train] Epoch: 1 [254080/620022]    Loss: 0.008120   Batch Acc: 78.12
[Train] Epoch: 1 [254144/620022]    Loss: 0.009162   Batch Acc: 78.12
[Train] Epoch: 1 [254208/620022]    Loss: 0.009039   Batch Acc: 76.56
[Train] Epoch: 1 [254272/620022]    Loss: 0.008208   Batch Acc: 78.12
[Train] Epoch: 1 [254336/620022]    Loss: 0.007853   Batch Acc: 79.69
[Train] Epoch: 1 [254400/620022]    Loss: 0.011132   Batch Acc: 65.62
[Train] Epoch: 1 [254464/620022]    Loss: 0.011317   Batch Acc: 68.75
[Train] Epoch: 1 [254528/620022]    Loss: 0.007612   Batch Acc: 79.69
[Train] Epoch: 1 [254592/620022]    Loss: 0.008586   Batch Acc: 81.25
[Train] Epoch: 1 [254656/620022]    Loss: 0.009638   Batch Acc: 70.31
[Train] Epoch: 1 [254720/620022]    Loss: 0.010509   Batch Acc: 76.56
[Train] Epoch: 1 [254784/620022]    Loss: 0.008817   Batch Acc: 81.25
[Train] Epoch: 1 [254848/620022]    Loss: 0.008870   Batch Acc: 73.44
[Train] Epoch: 1 [254912/620022]    Loss: 0.007956   Batch Acc: 81.25
[Train] Epoch: 1 [254976/620022]    Loss: 0.009628   Batch Acc: 75.00
[Train] Epoch: 1 [255040/620022]    Loss: 0.008491   Batch Acc: 79.69
[Train] Epoch: 1 [255104/620022]    Loss: 0.009254   Batch Acc: 76.56
[Train] Epoch: 1 [255168/620022]    Loss: 0.011082   Batch Acc: 65.62
[Train] Epoch: 1 [255232/620022]    Loss: 0.007533   Batch Acc: 81.25
[Train] Epoch: 1 [255296/620022]    Loss: 0.009225   Batch Acc: 73.44
[Train] Epoch: 1 [255360/620022]    Loss: 0.009108   Batch Acc: 73.44
[Train] Epoch: 1 [255424/620022]    Loss: 0.009271   Batch Acc: 79.69
[Train] Epoch: 1 [255488/620022]    Loss: 0.008206   Batch Acc: 73.44
[Train] Epoch: 1 [255552/620022]    Loss: 0.006958   Batch Acc: 79.69
[Train] Epoch: 1 [255616/620022]    Loss: 0.009538   Batch Acc: 71.88
[Train] Epoch: 1 [255680/620022]    Loss: 0.011338   Batch Acc: 67.19
[Train] Epoch: 1 [255744/620022]    Loss: 0.010187   Batch Acc: 73.44
[Train] Epoch: 1 [255808/620022]    Loss: 0.008199   Batch Acc: 78.12
[Train] Epoch: 1 [255872/620022]    Loss: 0.011511   Batch Acc: 71.88
[Train] Epoch: 1 [255936/620022]    Loss: 0.010527   Batch Acc: 76.56
[Train] Epoch: 1 [256000/620022]    Loss: 0.008924   Batch Acc: 76.56
[Train] Epoch: 1 [256064/620022]    Loss: 0.008600   Batch Acc: 78.12
[Train] Epoch: 1 [256128/620022]    Loss: 0.007794   Batch Acc: 79.69
[Train] Epoch: 1 [256192/620022]    Loss: 0.008420   Batch Acc: 78.12
[Train] Epoch: 1 [256256/620022]    Loss: 0.005869   Batch Acc: 85.94
[Train] Epoch: 1 [256320/620022]    Loss: 0.006994   Batch Acc: 81.25
[Train] Epoch: 1 [256384/620022]    Loss: 0.008115   Batch Acc: 81.25
[Train] Epoch: 1 [256448/620022]    Loss: 0.007184   Batch Acc: 78.12
[Train] Epoch: 1 [256512/620022]    Loss: 0.009159   Batch Acc: 79.69
[Train] Epoch: 1 [256576/620022]    Loss: 0.008131   Batch Acc: 79.69
[Train] Epoch: 1 [256640/620022]    Loss: 0.009599   Batch Acc: 73.44
[Train] Epoch: 1 [256704/620022]    Loss: 0.006438   Batch Acc: 84.38
[Train] Epoch: 1 [256768/620022]    Loss: 0.008838   Batch Acc: 79.69
[Train] Epoch: 1 [256832/620022]    Loss: 0.008414   Batch Acc: 79.69
[Train] Epoch: 1 [256896/620022]    Loss: 0.008321   Batch Acc: 81.25
[Train] Epoch: 1 [256960/620022]    Loss: 0.009458   Batch Acc: 68.75
[Train] Epoch: 1 [257024/620022]    Loss: 0.012261   Batch Acc: 73.44
[Train] Epoch: 1 [257088/620022]    Loss: 0.007144   Batch Acc: 79.69
[Train] Epoch: 1 [257152/620022]    Loss: 0.008397   Batch Acc: 78.12
[Train] Epoch: 1 [257216/620022]    Loss: 0.010481   Batch Acc: 76.56
[Train] Epoch: 1 [257280/620022]    Loss: 0.008453   Batch Acc: 78.12
[Train] Epoch: 1 [257344/620022]    Loss: 0.008717   Batch Acc: 79.69
[Train] Epoch: 1 [257408/620022]    Loss: 0.010265   Batch Acc: 75.00
[Train] Epoch: 1 [257472/620022]    Loss: 0.010743   Batch Acc: 67.19
[Train] Epoch: 1 [257536/620022]    Loss: 0.008507   Batch Acc: 79.69
[Train] Epoch: 1 [257600/620022]    Loss: 0.009657   Batch Acc: 78.12
[Train] Epoch: 1 [257664/620022]    Loss: 0.008037   Batch Acc: 81.25
[Train] Epoch: 1 [257728/620022]    Loss: 0.009389   Batch Acc: 71.88
[Train] Epoch: 1 [257792/620022]    Loss: 0.009704   Batch Acc: 75.00
[Train] Epoch: 1 [257856/620022]    Loss: 0.007443   Batch Acc: 81.25
[Train] Epoch: 1 [257920/620022]    Loss: 0.007682   Batch Acc: 82.81
[Train] Epoch: 1 [257984/620022]    Loss: 0.007989   Batch Acc: 82.81
[Train] Epoch: 1 [258048/620022]    Loss: 0.008636   Batch Acc: 78.12
[Train] Epoch: 1 [258112/620022]    Loss: 0.010448   Batch Acc: 76.56
[Train] Epoch: 1 [258176/620022]    Loss: 0.009112   Batch Acc: 78.12
[Train] Epoch: 1 [258240/620022]    Loss: 0.007504   Batch Acc: 79.69
[Train] Epoch: 1 [258304/620022]    Loss: 0.009340   Batch Acc: 73.44
[Train] Epoch: 1 [258368/620022]    Loss: 0.005633   Batch Acc: 92.19
[Train] Epoch: 1 [258432/620022]    Loss: 0.009988   Batch Acc: 70.31
[Train] Epoch: 1 [258496/620022]    Loss: 0.008401   Batch Acc: 84.38
[Train] Epoch: 1 [258560/620022]    Loss: 0.009393   Batch Acc: 70.31
[Train] Epoch: 1 [258624/620022]    Loss: 0.009671   Batch Acc: 79.69
[Train] Epoch: 1 [258688/620022]    Loss: 0.008726   Batch Acc: 75.00
[Train] Epoch: 1 [258752/620022]    Loss: 0.008901   Batch Acc: 81.25
[Train] Epoch: 1 [258816/620022]    Loss: 0.009369   Batch Acc: 76.56
[Train] Epoch: 1 [258880/620022]    Loss: 0.007721   Batch Acc: 76.56
[Train] Epoch: 1 [258944/620022]    Loss: 0.010229   Batch Acc: 73.44
[Train] Epoch: 1 [259008/620022]    Loss: 0.007683   Batch Acc: 81.25
[Train] Epoch: 1 [259072/620022]    Loss: 0.011141   Batch Acc: 71.88
[Train] Epoch: 1 [259136/620022]    Loss: 0.009172   Batch Acc: 68.75
[Train] Epoch: 1 [259200/620022]    Loss: 0.009790   Batch Acc: 71.88
[Train] Epoch: 1 [259264/620022]    Loss: 0.009874   Batch Acc: 73.44
[Train] Epoch: 1 [259328/620022]    Loss: 0.012525   Batch Acc: 67.19
[Train] Epoch: 1 [259392/620022]    Loss: 0.007478   Batch Acc: 73.44
[Train] Epoch: 1 [259456/620022]    Loss: 0.011064   Batch Acc: 67.19
[Train] Epoch: 1 [259520/620022]    Loss: 0.011628   Batch Acc: 73.44
[Train] Epoch: 1 [259584/620022]    Loss: 0.008127   Batch Acc: 73.44
[Train] Epoch: 1 [259648/620022]    Loss: 0.008610   Batch Acc: 79.69
[Train] Epoch: 1 [259712/620022]    Loss: 0.010644   Batch Acc: 64.06
[Train] Epoch: 1 [259776/620022]    Loss: 0.009122   Batch Acc: 79.69
[Train] Epoch: 1 [259840/620022]    Loss: 0.008008   Batch Acc: 78.12
[Train] Epoch: 1 [259904/620022]    Loss: 0.008666   Batch Acc: 82.81
[Train] Epoch: 1 [259968/620022]    Loss: 0.010090   Batch Acc: 70.31
[Train] Epoch: 1 [260032/620022]    Loss: 0.010424   Batch Acc: 73.44
[Train] Epoch: 1 [260096/620022]    Loss: 0.008747   Batch Acc: 75.00
[Train] Epoch: 1 [260160/620022]    Loss: 0.006796   Batch Acc: 84.38
[Train] Epoch: 1 [260224/620022]    Loss: 0.009850   Batch Acc: 75.00
[Train] Epoch: 1 [260288/620022]    Loss: 0.009251   Batch Acc: 79.69
[Train] Epoch: 1 [260352/620022]    Loss: 0.007487   Batch Acc: 82.81
[Train] Epoch: 1 [260416/620022]    Loss: 0.010343   Batch Acc: 78.12
[Train] Epoch: 1 [260480/620022]    Loss: 0.009030   Batch Acc: 78.12
[Train] Epoch: 1 [260544/620022]    Loss: 0.008009   Batch Acc: 84.38
[Train] Epoch: 1 [260608/620022]    Loss: 0.008662   Batch Acc: 75.00
[Train] Epoch: 1 [260672/620022]    Loss: 0.007787   Batch Acc: 78.12
[Train] Epoch: 1 [260736/620022]    Loss: 0.008331   Batch Acc: 84.38
[Train] Epoch: 1 [260800/620022]    Loss: 0.007847   Batch Acc: 79.69
[Train] Epoch: 1 [260864/620022]    Loss: 0.008981   Batch Acc: 76.56
[Train] Epoch: 1 [260928/620022]    Loss: 0.007734   Batch Acc: 79.69
[Train] Epoch: 1 [260992/620022]    Loss: 0.008947   Batch Acc: 71.88
[Train] Epoch: 1 [261056/620022]    Loss: 0.008094   Batch Acc: 79.69
[Train] Epoch: 1 [261120/620022]    Loss: 0.006767   Batch Acc: 84.38
[Train] Epoch: 1 [261184/620022]    Loss: 0.010191   Batch Acc: 73.44
[Train] Epoch: 1 [261248/620022]    Loss: 0.008411   Batch Acc: 75.00
[Train] Epoch: 1 [261312/620022]    Loss: 0.008720   Batch Acc: 85.94
[Train] Epoch: 1 [261376/620022]    Loss: 0.010009   Batch Acc: 70.31
[Train] Epoch: 1 [261440/620022]    Loss: 0.008200   Batch Acc: 82.81
[Train] Epoch: 1 [261504/620022]    Loss: 0.007047   Batch Acc: 85.94
[Train] Epoch: 1 [261568/620022]    Loss: 0.007975   Batch Acc: 81.25
[Train] Epoch: 1 [261632/620022]    Loss: 0.007406   Batch Acc: 84.38
[Train] Epoch: 1 [261696/620022]    Loss: 0.007609   Batch Acc: 79.69
[Train] Epoch: 1 [261760/620022]    Loss: 0.009442   Batch Acc: 75.00
[Train] Epoch: 1 [261824/620022]    Loss: 0.008163   Batch Acc: 81.25
[Train] Epoch: 1 [261888/620022]    Loss: 0.008329   Batch Acc: 79.69
[Train] Epoch: 1 [261952/620022]    Loss: 0.010382   Batch Acc: 73.44
[Train] Epoch: 1 [262016/620022]    Loss: 0.009690   Batch Acc: 75.00
[Train] Epoch: 1 [262080/620022]    Loss: 0.008461   Batch Acc: 82.81
[Train] Epoch: 1 [262144/620022]    Loss: 0.008369   Batch Acc: 79.69
[Train] Epoch: 1 [262208/620022]    Loss: 0.007679   Batch Acc: 84.38
[Train] Epoch: 1 [262272/620022]    Loss: 0.008596   Batch Acc: 73.44
[Train] Epoch: 1 [262336/620022]    Loss: 0.007304   Batch Acc: 79.69
[Train] Epoch: 1 [262400/620022]    Loss: 0.010593   Batch Acc: 68.75
[Train] Epoch: 1 [262464/620022]    Loss: 0.012435   Batch Acc: 62.50
[Train] Epoch: 1 [262528/620022]    Loss: 0.008593   Batch Acc: 78.12
[Train] Epoch: 1 [262592/620022]    Loss: 0.008835   Batch Acc: 73.44
[Train] Epoch: 1 [262656/620022]    Loss: 0.006985   Batch Acc: 85.94
[Train] Epoch: 1 [262720/620022]    Loss: 0.010006   Batch Acc: 71.88
[Train] Epoch: 1 [262784/620022]    Loss: 0.010989   Batch Acc: 79.69
[Train] Epoch: 1 [262848/620022]    Loss: 0.007547   Batch Acc: 79.69
[Train] Epoch: 1 [262912/620022]    Loss: 0.008002   Batch Acc: 79.69
[Train] Epoch: 1 [262976/620022]    Loss: 0.009215   Batch Acc: 76.56
[Train] Epoch: 1 [263040/620022]    Loss: 0.012047   Batch Acc: 68.75
[Train] Epoch: 1 [263104/620022]    Loss: 0.007597   Batch Acc: 78.12
[Train] Epoch: 1 [263168/620022]    Loss: 0.009933   Batch Acc: 73.44
[Train] Epoch: 1 [263232/620022]    Loss: 0.007369   Batch Acc: 89.06
[Train] Epoch: 1 [263296/620022]    Loss: 0.009392   Batch Acc: 71.88
[Train] Epoch: 1 [263360/620022]    Loss: 0.007381   Batch Acc: 82.81
[Train] Epoch: 1 [263424/620022]    Loss: 0.009424   Batch Acc: 73.44
[Train] Epoch: 1 [263488/620022]    Loss: 0.007908   Batch Acc: 73.44
[Train] Epoch: 1 [263552/620022]    Loss: 0.009484   Batch Acc: 71.88
[Train] Epoch: 1 [263616/620022]    Loss: 0.010471   Batch Acc: 68.75
[Train] Epoch: 1 [263680/620022]    Loss: 0.006379   Batch Acc: 85.94
[Train] Epoch: 1 [263744/620022]    Loss: 0.008584   Batch Acc: 73.44
[Train] Epoch: 1 [263808/620022]    Loss: 0.008266   Batch Acc: 81.25
[Train] Epoch: 1 [263872/620022]    Loss: 0.008501   Batch Acc: 75.00
[Train] Epoch: 1 [263936/620022]    Loss: 0.008605   Batch Acc: 76.56
[Train] Epoch: 1 [264000/620022]    Loss: 0.007256   Batch Acc: 79.69
[Train] Epoch: 1 [264064/620022]    Loss: 0.007024   Batch Acc: 81.25
[Train] Epoch: 1 [264128/620022]    Loss: 0.008065   Batch Acc: 78.12
[Train] Epoch: 1 [264192/620022]    Loss: 0.009431   Batch Acc: 79.69
[Train] Epoch: 1 [264256/620022]    Loss: 0.012187   Batch Acc: 75.00
[Train] Epoch: 1 [264320/620022]    Loss: 0.010406   Batch Acc: 75.00
[Train] Epoch: 1 [264384/620022]    Loss: 0.009919   Batch Acc: 76.56
[Train] Epoch: 1 [264448/620022]    Loss: 0.006968   Batch Acc: 82.81
[Train] Epoch: 1 [264512/620022]    Loss: 0.007497   Batch Acc: 84.38
[Train] Epoch: 1 [264576/620022]    Loss: 0.009509   Batch Acc: 75.00
[Train] Epoch: 1 [264640/620022]    Loss: 0.008419   Batch Acc: 79.69
[Train] Epoch: 1 [264704/620022]    Loss: 0.010913   Batch Acc: 73.44
[Train] Epoch: 1 [264768/620022]    Loss: 0.009045   Batch Acc: 78.12
[Train] Epoch: 1 [264832/620022]    Loss: 0.007834   Batch Acc: 78.12
[Train] Epoch: 1 [264896/620022]    Loss: 0.007970   Batch Acc: 82.81
[Train] Epoch: 1 [264960/620022]    Loss: 0.008061   Batch Acc: 78.12
[Train] Epoch: 1 [265024/620022]    Loss: 0.006572   Batch Acc: 79.69
[Train] Epoch: 1 [265088/620022]    Loss: 0.007040   Batch Acc: 81.25
[Train] Epoch: 1 [265152/620022]    Loss: 0.009924   Batch Acc: 75.00
[Train] Epoch: 1 [265216/620022]    Loss: 0.010197   Batch Acc: 68.75
[Train] Epoch: 1 [265280/620022]    Loss: 0.009058   Batch Acc: 76.56
[Train] Epoch: 1 [265344/620022]    Loss: 0.008004   Batch Acc: 81.25
[Train] Epoch: 1 [265408/620022]    Loss: 0.008668   Batch Acc: 79.69
[Train] Epoch: 1 [265472/620022]    Loss: 0.006970   Batch Acc: 81.25
[Train] Epoch: 1 [265536/620022]    Loss: 0.008349   Batch Acc: 82.81
[Train] Epoch: 1 [265600/620022]    Loss: 0.008078   Batch Acc: 82.81
[Train] Epoch: 1 [265664/620022]    Loss: 0.009134   Batch Acc: 78.12
[Train] Epoch: 1 [265728/620022]    Loss: 0.007620   Batch Acc: 82.81
[Train] Epoch: 1 [265792/620022]    Loss: 0.008148   Batch Acc: 81.25
[Train] Epoch: 1 [265856/620022]    Loss: 0.008244   Batch Acc: 78.12
[Train] Epoch: 1 [265920/620022]    Loss: 0.008480   Batch Acc: 81.25
[Train] Epoch: 1 [265984/620022]    Loss: 0.009839   Batch Acc: 75.00
[Train] Epoch: 1 [266048/620022]    Loss: 0.009026   Batch Acc: 76.56
[Train] Epoch: 1 [266112/620022]    Loss: 0.008986   Batch Acc: 76.56
[Train] Epoch: 1 [266176/620022]    Loss: 0.007679   Batch Acc: 79.69
[Train] Epoch: 1 [266240/620022]    Loss: 0.006868   Batch Acc: 85.94
[Train] Epoch: 1 [266304/620022]    Loss: 0.007771   Batch Acc: 79.69
[Train] Epoch: 1 [266368/620022]    Loss: 0.010466   Batch Acc: 78.12
[Train] Epoch: 1 [266432/620022]    Loss: 0.008862   Batch Acc: 81.25
[Train] Epoch: 1 [266496/620022]    Loss: 0.009564   Batch Acc: 73.44
[Train] Epoch: 1 [266560/620022]    Loss: 0.009308   Batch Acc: 82.81
[Train] Epoch: 1 [266624/620022]    Loss: 0.008639   Batch Acc: 76.56
[Train] Epoch: 1 [266688/620022]    Loss: 0.008206   Batch Acc: 81.25
[Train] Epoch: 1 [266752/620022]    Loss: 0.010187   Batch Acc: 76.56
[Train] Epoch: 1 [266816/620022]    Loss: 0.007744   Batch Acc: 82.81
[Train] Epoch: 1 [266880/620022]    Loss: 0.008918   Batch Acc: 76.56
[Train] Epoch: 1 [266944/620022]    Loss: 0.008439   Batch Acc: 73.44
[Train] Epoch: 1 [267008/620022]    Loss: 0.007590   Batch Acc: 76.56
[Train] Epoch: 1 [267072/620022]    Loss: 0.008382   Batch Acc: 79.69
[Train] Epoch: 1 [267136/620022]    Loss: 0.007258   Batch Acc: 79.69
[Train] Epoch: 1 [267200/620022]    Loss: 0.008117   Batch Acc: 79.69
[Train] Epoch: 1 [267264/620022]    Loss: 0.007681   Batch Acc: 76.56
[Train] Epoch: 1 [267328/620022]    Loss: 0.009599   Batch Acc: 82.81
[Train] Epoch: 1 [267392/620022]    Loss: 0.008414   Batch Acc: 75.00
[Train] Epoch: 1 [267456/620022]    Loss: 0.009099   Batch Acc: 79.69
[Train] Epoch: 1 [267520/620022]    Loss: 0.008306   Batch Acc: 73.44
[Train] Epoch: 1 [267584/620022]    Loss: 0.011243   Batch Acc: 70.31
[Train] Epoch: 1 [267648/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 1 [267712/620022]    Loss: 0.007632   Batch Acc: 81.25
[Train] Epoch: 1 [267776/620022]    Loss: 0.008706   Batch Acc: 79.69
[Train] Epoch: 1 [267840/620022]    Loss: 0.009257   Batch Acc: 78.12
[Train] Epoch: 1 [267904/620022]    Loss: 0.009463   Batch Acc: 78.12
[Train] Epoch: 1 [267968/620022]    Loss: 0.007881   Batch Acc: 79.69
[Train] Epoch: 1 [268032/620022]    Loss: 0.009542   Batch Acc: 75.00
[Train] Epoch: 1 [268096/620022]    Loss: 0.008585   Batch Acc: 76.56
[Train] Epoch: 1 [268160/620022]    Loss: 0.008725   Batch Acc: 71.88
[Train] Epoch: 1 [268224/620022]    Loss: 0.006998   Batch Acc: 81.25
[Train] Epoch: 1 [268288/620022]    Loss: 0.008800   Batch Acc: 76.56
[Train] Epoch: 1 [268352/620022]    Loss: 0.006810   Batch Acc: 79.69
[Train] Epoch: 1 [268416/620022]    Loss: 0.009649   Batch Acc: 75.00
[Train] Epoch: 1 [268480/620022]    Loss: 0.008793   Batch Acc: 78.12
[Train] Epoch: 1 [268544/620022]    Loss: 0.010035   Batch Acc: 73.44
[Train] Epoch: 1 [268608/620022]    Loss: 0.008782   Batch Acc: 75.00
[Train] Epoch: 1 [268672/620022]    Loss: 0.009459   Batch Acc: 75.00
[Train] Epoch: 1 [268736/620022]    Loss: 0.007507   Batch Acc: 81.25
[Train] Epoch: 1 [268800/620022]    Loss: 0.009200   Batch Acc: 81.25
[Train] Epoch: 1 [268864/620022]    Loss: 0.009551   Batch Acc: 71.88
[Train] Epoch: 1 [268928/620022]    Loss: 0.008191   Batch Acc: 76.56
[Train] Epoch: 1 [268992/620022]    Loss: 0.008146   Batch Acc: 79.69
[Train] Epoch: 1 [269056/620022]    Loss: 0.008233   Batch Acc: 81.25
[Train] Epoch: 1 [269120/620022]    Loss: 0.007741   Batch Acc: 82.81
[Train] Epoch: 1 [269184/620022]    Loss: 0.008716   Batch Acc: 76.56
[Train] Epoch: 1 [269248/620022]    Loss: 0.007972   Batch Acc: 89.06
[Train] Epoch: 1 [269312/620022]    Loss: 0.009395   Batch Acc: 75.00
[Train] Epoch: 1 [269376/620022]    Loss: 0.009445   Batch Acc: 79.69
[Train] Epoch: 1 [269440/620022]    Loss: 0.008170   Batch Acc: 76.56
[Train] Epoch: 1 [269504/620022]    Loss: 0.006937   Batch Acc: 82.81
[Train] Epoch: 1 [269568/620022]    Loss: 0.007741   Batch Acc: 82.81
[Train] Epoch: 1 [269632/620022]    Loss: 0.006850   Batch Acc: 84.38
[Train] Epoch: 1 [269696/620022]    Loss: 0.006387   Batch Acc: 87.50
[Train] Epoch: 1 [269760/620022]    Loss: 0.009398   Batch Acc: 76.56
[Train] Epoch: 1 [269824/620022]    Loss: 0.006392   Batch Acc: 87.50
[Train] Epoch: 1 [269888/620022]    Loss: 0.008390   Batch Acc: 78.12
[Train] Epoch: 1 [269952/620022]    Loss: 0.009099   Batch Acc: 71.88
[Train] Epoch: 1 [270016/620022]    Loss: 0.008093   Batch Acc: 81.25
[Train] Epoch: 1 [270080/620022]    Loss: 0.007272   Batch Acc: 79.69
[Train] Epoch: 1 [270144/620022]    Loss: 0.006523   Batch Acc: 84.38
[Train] Epoch: 1 [270208/620022]    Loss: 0.009368   Batch Acc: 76.56
[Train] Epoch: 1 [270272/620022]    Loss: 0.009876   Batch Acc: 68.75
[Train] Epoch: 1 [270336/620022]    Loss: 0.008582   Batch Acc: 78.12
[Train] Epoch: 1 [270400/620022]    Loss: 0.008667   Batch Acc: 79.69
[Train] Epoch: 1 [270464/620022]    Loss: 0.008920   Batch Acc: 81.25
[Train] Epoch: 1 [270528/620022]    Loss: 0.011377   Batch Acc: 64.06
[Train] Epoch: 1 [270592/620022]    Loss: 0.009914   Batch Acc: 75.00
[Train] Epoch: 1 [270656/620022]    Loss: 0.006104   Batch Acc: 87.50
[Train] Epoch: 1 [270720/620022]    Loss: 0.010231   Batch Acc: 70.31
[Train] Epoch: 1 [270784/620022]    Loss: 0.008047   Batch Acc: 81.25
[Train] Epoch: 1 [270848/620022]    Loss: 0.010012   Batch Acc: 73.44
[Train] Epoch: 1 [270912/620022]    Loss: 0.007716   Batch Acc: 82.81
[Train] Epoch: 1 [270976/620022]    Loss: 0.008120   Batch Acc: 82.81
[Train] Epoch: 1 [271040/620022]    Loss: 0.010135   Batch Acc: 70.31
[Train] Epoch: 1 [271104/620022]    Loss: 0.009086   Batch Acc: 73.44
[Train] Epoch: 1 [271168/620022]    Loss: 0.006334   Batch Acc: 84.38
[Train] Epoch: 1 [271232/620022]    Loss: 0.008914   Batch Acc: 78.12
[Train] Epoch: 1 [271296/620022]    Loss: 0.007417   Batch Acc: 81.25
[Train] Epoch: 1 [271360/620022]    Loss: 0.008202   Batch Acc: 78.12
[Train] Epoch: 1 [271424/620022]    Loss: 0.008290   Batch Acc: 79.69
[Train] Epoch: 1 [271488/620022]    Loss: 0.009673   Batch Acc: 70.31
[Train] Epoch: 1 [271552/620022]    Loss: 0.008791   Batch Acc: 79.69
[Train] Epoch: 1 [271616/620022]    Loss: 0.008896   Batch Acc: 81.25
[Train] Epoch: 1 [271680/620022]    Loss: 0.008472   Batch Acc: 78.12
[Train] Epoch: 1 [271744/620022]    Loss: 0.008152   Batch Acc: 78.12
[Train] Epoch: 1 [271808/620022]    Loss: 0.009827   Batch Acc: 73.44
[Train] Epoch: 1 [271872/620022]    Loss: 0.008655   Batch Acc: 75.00
[Train] Epoch: 1 [271936/620022]    Loss: 0.007703   Batch Acc: 82.81
[Train] Epoch: 1 [272000/620022]    Loss: 0.013222   Batch Acc: 56.25
[Train] Epoch: 1 [272064/620022]    Loss: 0.010655   Batch Acc: 75.00
[Train] Epoch: 1 [272128/620022]    Loss: 0.009655   Batch Acc: 73.44
[Train] Epoch: 1 [272192/620022]    Loss: 0.008136   Batch Acc: 81.25
[Train] Epoch: 1 [272256/620022]    Loss: 0.009926   Batch Acc: 71.88
[Train] Epoch: 1 [272320/620022]    Loss: 0.009117   Batch Acc: 73.44
[Train] Epoch: 1 [272384/620022]    Loss: 0.009997   Batch Acc: 71.88
[Train] Epoch: 1 [272448/620022]    Loss: 0.008250   Batch Acc: 78.12
[Train] Epoch: 1 [272512/620022]    Loss: 0.009183   Batch Acc: 79.69
[Train] Epoch: 1 [272576/620022]    Loss: 0.005580   Batch Acc: 85.94
[Train] Epoch: 1 [272640/620022]    Loss: 0.010710   Batch Acc: 73.44
[Train] Epoch: 1 [272704/620022]    Loss: 0.007362   Batch Acc: 85.94
[Train] Epoch: 1 [272768/620022]    Loss: 0.009343   Batch Acc: 73.44
[Train] Epoch: 1 [272832/620022]    Loss: 0.007193   Batch Acc: 82.81
[Train] Epoch: 1 [272896/620022]    Loss: 0.007103   Batch Acc: 81.25
[Train] Epoch: 1 [272960/620022]    Loss: 0.008690   Batch Acc: 79.69
[Train] Epoch: 1 [273024/620022]    Loss: 0.007220   Batch Acc: 82.81
[Train] Epoch: 1 [273088/620022]    Loss: 0.009661   Batch Acc: 65.62
[Train] Epoch: 1 [273152/620022]    Loss: 0.010165   Batch Acc: 76.56
[Train] Epoch: 1 [273216/620022]    Loss: 0.007535   Batch Acc: 81.25
[Train] Epoch: 1 [273280/620022]    Loss: 0.009482   Batch Acc: 73.44
[Train] Epoch: 1 [273344/620022]    Loss: 0.009731   Batch Acc: 82.81
[Train] Epoch: 1 [273408/620022]    Loss: 0.009464   Batch Acc: 73.44
[Train] Epoch: 1 [273472/620022]    Loss: 0.008632   Batch Acc: 76.56
[Train] Epoch: 1 [273536/620022]    Loss: 0.009195   Batch Acc: 78.12
[Train] Epoch: 1 [273600/620022]    Loss: 0.007677   Batch Acc: 81.25
[Train] Epoch: 1 [273664/620022]    Loss: 0.008154   Batch Acc: 78.12
[Train] Epoch: 1 [273728/620022]    Loss: 0.008152   Batch Acc: 73.44
[Train] Epoch: 1 [273792/620022]    Loss: 0.008363   Batch Acc: 85.94
[Train] Epoch: 1 [273856/620022]    Loss: 0.008896   Batch Acc: 78.12
[Train] Epoch: 1 [273920/620022]    Loss: 0.007441   Batch Acc: 85.94
[Train] Epoch: 1 [273984/620022]    Loss: 0.008391   Batch Acc: 84.38
[Train] Epoch: 1 [274048/620022]    Loss: 0.007104   Batch Acc: 87.50
[Train] Epoch: 1 [274112/620022]    Loss: 0.008040   Batch Acc: 85.94
[Train] Epoch: 1 [274176/620022]    Loss: 0.008633   Batch Acc: 78.12
[Train] Epoch: 1 [274240/620022]    Loss: 0.012082   Batch Acc: 68.75
[Train] Epoch: 1 [274304/620022]    Loss: 0.009775   Batch Acc: 73.44
[Train] Epoch: 1 [274368/620022]    Loss: 0.009333   Batch Acc: 71.88
[Train] Epoch: 1 [274432/620022]    Loss: 0.008066   Batch Acc: 76.56
[Train] Epoch: 1 [274496/620022]    Loss: 0.006995   Batch Acc: 84.38
[Train] Epoch: 1 [274560/620022]    Loss: 0.009707   Batch Acc: 71.88
[Train] Epoch: 1 [274624/620022]    Loss: 0.010146   Batch Acc: 73.44
[Train] Epoch: 1 [274688/620022]    Loss: 0.006514   Batch Acc: 92.19
[Train] Epoch: 1 [274752/620022]    Loss: 0.008100   Batch Acc: 75.00
[Train] Epoch: 1 [274816/620022]    Loss: 0.007710   Batch Acc: 82.81
[Train] Epoch: 1 [274880/620022]    Loss: 0.009112   Batch Acc: 76.56
[Train] Epoch: 1 [274944/620022]    Loss: 0.009369   Batch Acc: 78.12
[Train] Epoch: 1 [275008/620022]    Loss: 0.006975   Batch Acc: 81.25
[Train] Epoch: 1 [275072/620022]    Loss: 0.011191   Batch Acc: 71.88
[Train] Epoch: 1 [275136/620022]    Loss: 0.009433   Batch Acc: 78.12
[Train] Epoch: 1 [275200/620022]    Loss: 0.010802   Batch Acc: 73.44
[Train] Epoch: 1 [275264/620022]    Loss: 0.009552   Batch Acc: 71.88
[Train] Epoch: 1 [275328/620022]    Loss: 0.008170   Batch Acc: 78.12
[Train] Epoch: 1 [275392/620022]    Loss: 0.011204   Batch Acc: 65.62
[Train] Epoch: 1 [275456/620022]    Loss: 0.007386   Batch Acc: 81.25
[Train] Epoch: 1 [275520/620022]    Loss: 0.010197   Batch Acc: 79.69
[Train] Epoch: 1 [275584/620022]    Loss: 0.009252   Batch Acc: 73.44
[Train] Epoch: 1 [275648/620022]    Loss: 0.007529   Batch Acc: 81.25
[Train] Epoch: 1 [275712/620022]    Loss: 0.008175   Batch Acc: 82.81
[Train] Epoch: 1 [275776/620022]    Loss: 0.008932   Batch Acc: 79.69
[Train] Epoch: 1 [275840/620022]    Loss: 0.010621   Batch Acc: 67.19
[Train] Epoch: 1 [275904/620022]    Loss: 0.010152   Batch Acc: 67.19
[Train] Epoch: 1 [275968/620022]    Loss: 0.009599   Batch Acc: 71.88
[Train] Epoch: 1 [276032/620022]    Loss: 0.007866   Batch Acc: 75.00
[Train] Epoch: 1 [276096/620022]    Loss: 0.009233   Batch Acc: 75.00
[Train] Epoch: 1 [276160/620022]    Loss: 0.008408   Batch Acc: 78.12
[Train] Epoch: 1 [276224/620022]    Loss: 0.009617   Batch Acc: 75.00
[Train] Epoch: 1 [276288/620022]    Loss: 0.008075   Batch Acc: 81.25
[Train] Epoch: 1 [276352/620022]    Loss: 0.007135   Batch Acc: 84.38
[Train] Epoch: 1 [276416/620022]    Loss: 0.009574   Batch Acc: 67.19
[Train] Epoch: 1 [276480/620022]    Loss: 0.007928   Batch Acc: 84.38
[Train] Epoch: 1 [276544/620022]    Loss: 0.009202   Batch Acc: 67.19
[Train] Epoch: 1 [276608/620022]    Loss: 0.010321   Batch Acc: 70.31
[Train] Epoch: 1 [276672/620022]    Loss: 0.007765   Batch Acc: 81.25
[Train] Epoch: 1 [276736/620022]    Loss: 0.007845   Batch Acc: 87.50
[Train] Epoch: 1 [276800/620022]    Loss: 0.010628   Batch Acc: 71.88
[Train] Epoch: 1 [276864/620022]    Loss: 0.010265   Batch Acc: 76.56
[Train] Epoch: 1 [276928/620022]    Loss: 0.008139   Batch Acc: 78.12
[Train] Epoch: 1 [276992/620022]    Loss: 0.008067   Batch Acc: 76.56
[Train] Epoch: 1 [277056/620022]    Loss: 0.011926   Batch Acc: 71.88
[Train] Epoch: 1 [277120/620022]    Loss: 0.009308   Batch Acc: 76.56
[Train] Epoch: 1 [277184/620022]    Loss: 0.007268   Batch Acc: 85.94
[Train] Epoch: 1 [277248/620022]    Loss: 0.009502   Batch Acc: 81.25
[Train] Epoch: 1 [277312/620022]    Loss: 0.009488   Batch Acc: 65.62
[Train] Epoch: 1 [277376/620022]    Loss: 0.008924   Batch Acc: 81.25
[Train] Epoch: 1 [277440/620022]    Loss: 0.006641   Batch Acc: 87.50
[Train] Epoch: 1 [277504/620022]    Loss: 0.009491   Batch Acc: 75.00
[Train] Epoch: 1 [277568/620022]    Loss: 0.008566   Batch Acc: 79.69
[Train] Epoch: 1 [277632/620022]    Loss: 0.008417   Batch Acc: 79.69
[Train] Epoch: 1 [277696/620022]    Loss: 0.011897   Batch Acc: 68.75
[Train] Epoch: 1 [277760/620022]    Loss: 0.007833   Batch Acc: 84.38
[Train] Epoch: 1 [277824/620022]    Loss: 0.007362   Batch Acc: 87.50
[Train] Epoch: 1 [277888/620022]    Loss: 0.006891   Batch Acc: 82.81
[Train] Epoch: 1 [277952/620022]    Loss: 0.009937   Batch Acc: 79.69
[Train] Epoch: 1 [278016/620022]    Loss: 0.008919   Batch Acc: 75.00
[Train] Epoch: 1 [278080/620022]    Loss: 0.008994   Batch Acc: 78.12
[Train] Epoch: 1 [278144/620022]    Loss: 0.007833   Batch Acc: 81.25
[Train] Epoch: 1 [278208/620022]    Loss: 0.010104   Batch Acc: 71.88
[Train] Epoch: 1 [278272/620022]    Loss: 0.009259   Batch Acc: 75.00
[Train] Epoch: 1 [278336/620022]    Loss: 0.010970   Batch Acc: 70.31
[Train] Epoch: 1 [278400/620022]    Loss: 0.009971   Batch Acc: 70.31
[Train] Epoch: 1 [278464/620022]    Loss: 0.010931   Batch Acc: 71.88
[Train] Epoch: 1 [278528/620022]    Loss: 0.010456   Batch Acc: 73.44
[Train] Epoch: 1 [278592/620022]    Loss: 0.008228   Batch Acc: 76.56
[Train] Epoch: 1 [278656/620022]    Loss: 0.009739   Batch Acc: 71.88
[Train] Epoch: 1 [278720/620022]    Loss: 0.007641   Batch Acc: 79.69
[Train] Epoch: 1 [278784/620022]    Loss: 0.011428   Batch Acc: 68.75
[Train] Epoch: 1 [278848/620022]    Loss: 0.007794   Batch Acc: 78.12
[Train] Epoch: 1 [278912/620022]    Loss: 0.009041   Batch Acc: 75.00
[Train] Epoch: 1 [278976/620022]    Loss: 0.008303   Batch Acc: 84.38
[Train] Epoch: 1 [279040/620022]    Loss: 0.006762   Batch Acc: 85.94
[Train] Epoch: 1 [279104/620022]    Loss: 0.009639   Batch Acc: 76.56
[Train] Epoch: 1 [279168/620022]    Loss: 0.009719   Batch Acc: 73.44
[Train] Epoch: 1 [279232/620022]    Loss: 0.009093   Batch Acc: 76.56
[Train] Epoch: 1 [279296/620022]    Loss: 0.007243   Batch Acc: 81.25
[Train] Epoch: 1 [279360/620022]    Loss: 0.006099   Batch Acc: 89.06
[Train] Epoch: 1 [279424/620022]    Loss: 0.006897   Batch Acc: 75.00
[Train] Epoch: 1 [279488/620022]    Loss: 0.008289   Batch Acc: 75.00
[Train] Epoch: 1 [279552/620022]    Loss: 0.006531   Batch Acc: 84.38
[Train] Epoch: 1 [279616/620022]    Loss: 0.009374   Batch Acc: 71.88
[Train] Epoch: 1 [279680/620022]    Loss: 0.009637   Batch Acc: 78.12
[Train] Epoch: 1 [279744/620022]    Loss: 0.008255   Batch Acc: 81.25
[Train] Epoch: 1 [279808/620022]    Loss: 0.010688   Batch Acc: 70.31
[Train] Epoch: 1 [279872/620022]    Loss: 0.009097   Batch Acc: 71.88
[Train] Epoch: 1 [279936/620022]    Loss: 0.010049   Batch Acc: 71.88
[Train] Epoch: 1 [280000/620022]    Loss: 0.008554   Batch Acc: 85.94
[Train] Epoch: 1 [280064/620022]    Loss: 0.008072   Batch Acc: 78.12
[Train] Epoch: 1 [280128/620022]    Loss: 0.007657   Batch Acc: 78.12
[Train] Epoch: 1 [280192/620022]    Loss: 0.008680   Batch Acc: 76.56
[Train] Epoch: 1 [280256/620022]    Loss: 0.009379   Batch Acc: 71.88
[Train] Epoch: 1 [280320/620022]    Loss: 0.008524   Batch Acc: 76.56
[Train] Epoch: 1 [280384/620022]    Loss: 0.008005   Batch Acc: 78.12
[Train] Epoch: 1 [280448/620022]    Loss: 0.011010   Batch Acc: 76.56
[Train] Epoch: 1 [280512/620022]    Loss: 0.007626   Batch Acc: 81.25
[Train] Epoch: 1 [280576/620022]    Loss: 0.009013   Batch Acc: 76.56
[Train] Epoch: 1 [280640/620022]    Loss: 0.010530   Batch Acc: 73.44
[Train] Epoch: 1 [280704/620022]    Loss: 0.006733   Batch Acc: 84.38
[Train] Epoch: 1 [280768/620022]    Loss: 0.007998   Batch Acc: 79.69
[Train] Epoch: 1 [280832/620022]    Loss: 0.007090   Batch Acc: 82.81
[Train] Epoch: 1 [280896/620022]    Loss: 0.011021   Batch Acc: 65.62
[Train] Epoch: 1 [280960/620022]    Loss: 0.008021   Batch Acc: 78.12
[Train] Epoch: 1 [281024/620022]    Loss: 0.009061   Batch Acc: 78.12
[Train] Epoch: 1 [281088/620022]    Loss: 0.007487   Batch Acc: 85.94
[Train] Epoch: 1 [281152/620022]    Loss: 0.009962   Batch Acc: 70.31
[Train] Epoch: 1 [281216/620022]    Loss: 0.006382   Batch Acc: 87.50
[Train] Epoch: 1 [281280/620022]    Loss: 0.007233   Batch Acc: 81.25
[Train] Epoch: 1 [281344/620022]    Loss: 0.007228   Batch Acc: 84.38
[Train] Epoch: 1 [281408/620022]    Loss: 0.009049   Batch Acc: 78.12
[Train] Epoch: 1 [281472/620022]    Loss: 0.008430   Batch Acc: 78.12
[Train] Epoch: 1 [281536/620022]    Loss: 0.009737   Batch Acc: 71.88
[Train] Epoch: 1 [281600/620022]    Loss: 0.008227   Batch Acc: 82.81
[Train] Epoch: 1 [281664/620022]    Loss: 0.008542   Batch Acc: 76.56
[Train] Epoch: 1 [281728/620022]    Loss: 0.011415   Batch Acc: 70.31
[Train] Epoch: 1 [281792/620022]    Loss: 0.008153   Batch Acc: 78.12
[Train] Epoch: 1 [281856/620022]    Loss: 0.008188   Batch Acc: 78.12
[Train] Epoch: 1 [281920/620022]    Loss: 0.010584   Batch Acc: 75.00
[Train] Epoch: 1 [281984/620022]    Loss: 0.008948   Batch Acc: 75.00
[Train] Epoch: 1 [282048/620022]    Loss: 0.008492   Batch Acc: 71.88
[Train] Epoch: 1 [282112/620022]    Loss: 0.009034   Batch Acc: 78.12
[Train] Epoch: 1 [282176/620022]    Loss: 0.007369   Batch Acc: 84.38
[Train] Epoch: 1 [282240/620022]    Loss: 0.008987   Batch Acc: 70.31
[Train] Epoch: 1 [282304/620022]    Loss: 0.008044   Batch Acc: 82.81
[Train] Epoch: 1 [282368/620022]    Loss: 0.009818   Batch Acc: 71.88
[Train] Epoch: 1 [282432/620022]    Loss: 0.009318   Batch Acc: 73.44
[Train] Epoch: 1 [282496/620022]    Loss: 0.007083   Batch Acc: 84.38
[Train] Epoch: 1 [282560/620022]    Loss: 0.007055   Batch Acc: 82.81
[Train] Epoch: 1 [282624/620022]    Loss: 0.007759   Batch Acc: 82.81
[Train] Epoch: 1 [282688/620022]    Loss: 0.008289   Batch Acc: 73.44
[Train] Epoch: 1 [282752/620022]    Loss: 0.010361   Batch Acc: 75.00
[Train] Epoch: 1 [282816/620022]    Loss: 0.009462   Batch Acc: 73.44
[Train] Epoch: 1 [282880/620022]    Loss: 0.007805   Batch Acc: 84.38
[Train] Epoch: 1 [282944/620022]    Loss: 0.007007   Batch Acc: 85.94
[Train] Epoch: 1 [283008/620022]    Loss: 0.007950   Batch Acc: 81.25
[Train] Epoch: 1 [283072/620022]    Loss: 0.008505   Batch Acc: 78.12
[Train] Epoch: 1 [283136/620022]    Loss: 0.009679   Batch Acc: 71.88
[Train] Epoch: 1 [283200/620022]    Loss: 0.010166   Batch Acc: 73.44
[Train] Epoch: 1 [283264/620022]    Loss: 0.008794   Batch Acc: 82.81
[Train] Epoch: 1 [283328/620022]    Loss: 0.010489   Batch Acc: 68.75
[Train] Epoch: 1 [283392/620022]    Loss: 0.009015   Batch Acc: 75.00
[Train] Epoch: 1 [283456/620022]    Loss: 0.008653   Batch Acc: 76.56
[Train] Epoch: 1 [283520/620022]    Loss: 0.006621   Batch Acc: 84.38
[Train] Epoch: 1 [283584/620022]    Loss: 0.008443   Batch Acc: 78.12
[Train] Epoch: 1 [283648/620022]    Loss: 0.008667   Batch Acc: 75.00
[Train] Epoch: 1 [283712/620022]    Loss: 0.007401   Batch Acc: 79.69
[Train] Epoch: 1 [283776/620022]    Loss: 0.008761   Batch Acc: 82.81
[Train] Epoch: 1 [283840/620022]    Loss: 0.008378   Batch Acc: 81.25
[Train] Epoch: 1 [283904/620022]    Loss: 0.010856   Batch Acc: 68.75
[Train] Epoch: 1 [283968/620022]    Loss: 0.007755   Batch Acc: 76.56
[Train] Epoch: 1 [284032/620022]    Loss: 0.008431   Batch Acc: 78.12
[Train] Epoch: 1 [284096/620022]    Loss: 0.009522   Batch Acc: 79.69
[Train] Epoch: 1 [284160/620022]    Loss: 0.008912   Batch Acc: 78.12
[Train] Epoch: 1 [284224/620022]    Loss: 0.010253   Batch Acc: 68.75
[Train] Epoch: 1 [284288/620022]    Loss: 0.007554   Batch Acc: 85.94
[Train] Epoch: 1 [284352/620022]    Loss: 0.007315   Batch Acc: 85.94
[Train] Epoch: 1 [284416/620022]    Loss: 0.008590   Batch Acc: 75.00
[Train] Epoch: 1 [284480/620022]    Loss: 0.008851   Batch Acc: 73.44
[Train] Epoch: 1 [284544/620022]    Loss: 0.008741   Batch Acc: 71.88
[Train] Epoch: 1 [284608/620022]    Loss: 0.008718   Batch Acc: 78.12
[Train] Epoch: 1 [284672/620022]    Loss: 0.006448   Batch Acc: 87.50
[Train] Epoch: 1 [284736/620022]    Loss: 0.007633   Batch Acc: 81.25
[Train] Epoch: 1 [284800/620022]    Loss: 0.009198   Batch Acc: 79.69
[Train] Epoch: 1 [284864/620022]    Loss: 0.007778   Batch Acc: 76.56
[Train] Epoch: 1 [284928/620022]    Loss: 0.009984   Batch Acc: 79.69
[Train] Epoch: 1 [284992/620022]    Loss: 0.009317   Batch Acc: 73.44
[Train] Epoch: 1 [285056/620022]    Loss: 0.009459   Batch Acc: 70.31
[Train] Epoch: 1 [285120/620022]    Loss: 0.010382   Batch Acc: 78.12
[Train] Epoch: 1 [285184/620022]    Loss: 0.007219   Batch Acc: 79.69
[Train] Epoch: 1 [285248/620022]    Loss: 0.006766   Batch Acc: 79.69
[Train] Epoch: 1 [285312/620022]    Loss: 0.007078   Batch Acc: 85.94
[Train] Epoch: 1 [285376/620022]    Loss: 0.008497   Batch Acc: 78.12
[Train] Epoch: 1 [285440/620022]    Loss: 0.010403   Batch Acc: 67.19
[Train] Epoch: 1 [285504/620022]    Loss: 0.009758   Batch Acc: 73.44
[Train] Epoch: 1 [285568/620022]    Loss: 0.008725   Batch Acc: 75.00
[Train] Epoch: 1 [285632/620022]    Loss: 0.008913   Batch Acc: 73.44
[Train] Epoch: 1 [285696/620022]    Loss: 0.008704   Batch Acc: 76.56
[Train] Epoch: 1 [285760/620022]    Loss: 0.008844   Batch Acc: 76.56
[Train] Epoch: 1 [285824/620022]    Loss: 0.008787   Batch Acc: 75.00
[Train] Epoch: 1 [285888/620022]    Loss: 0.007585   Batch Acc: 81.25
[Train] Epoch: 1 [285952/620022]    Loss: 0.005932   Batch Acc: 85.94
[Train] Epoch: 1 [286016/620022]    Loss: 0.008406   Batch Acc: 73.44
[Train] Epoch: 1 [286080/620022]    Loss: 0.008298   Batch Acc: 78.12
[Train] Epoch: 1 [286144/620022]    Loss: 0.008542   Batch Acc: 75.00
[Train] Epoch: 1 [286208/620022]    Loss: 0.008964   Batch Acc: 78.12
[Train] Epoch: 1 [286272/620022]    Loss: 0.010056   Batch Acc: 75.00
[Train] Epoch: 1 [286336/620022]    Loss: 0.008813   Batch Acc: 75.00
[Train] Epoch: 1 [286400/620022]    Loss: 0.009403   Batch Acc: 78.12
[Train] Epoch: 1 [286464/620022]    Loss: 0.007064   Batch Acc: 82.81
[Train] Epoch: 1 [286528/620022]    Loss: 0.009802   Batch Acc: 71.88
[Train] Epoch: 1 [286592/620022]    Loss: 0.007049   Batch Acc: 84.38
[Train] Epoch: 1 [286656/620022]    Loss: 0.007438   Batch Acc: 81.25
[Train] Epoch: 1 [286720/620022]    Loss: 0.008212   Batch Acc: 76.56
[Train] Epoch: 1 [286784/620022]    Loss: 0.007444   Batch Acc: 81.25
[Train] Epoch: 1 [286848/620022]    Loss: 0.008908   Batch Acc: 78.12
[Train] Epoch: 1 [286912/620022]    Loss: 0.007590   Batch Acc: 81.25
[Train] Epoch: 1 [286976/620022]    Loss: 0.007561   Batch Acc: 82.81
[Train] Epoch: 1 [287040/620022]    Loss: 0.008003   Batch Acc: 84.38
[Train] Epoch: 1 [287104/620022]    Loss: 0.009887   Batch Acc: 76.56
[Train] Epoch: 1 [287168/620022]    Loss: 0.010906   Batch Acc: 71.88
[Train] Epoch: 1 [287232/620022]    Loss: 0.010823   Batch Acc: 71.88
[Train] Epoch: 1 [287296/620022]    Loss: 0.008311   Batch Acc: 78.12
[Train] Epoch: 1 [287360/620022]    Loss: 0.009008   Batch Acc: 76.56
[Train] Epoch: 1 [287424/620022]    Loss: 0.007428   Batch Acc: 82.81
[Train] Epoch: 1 [287488/620022]    Loss: 0.008270   Batch Acc: 79.69
[Train] Epoch: 1 [287552/620022]    Loss: 0.008979   Batch Acc: 76.56
[Train] Epoch: 1 [287616/620022]    Loss: 0.007342   Batch Acc: 87.50
[Train] Epoch: 1 [287680/620022]    Loss: 0.010023   Batch Acc: 73.44
[Train] Epoch: 1 [287744/620022]    Loss: 0.007959   Batch Acc: 79.69
[Train] Epoch: 1 [287808/620022]    Loss: 0.011791   Batch Acc: 71.88
[Train] Epoch: 1 [287872/620022]    Loss: 0.007959   Batch Acc: 85.94
[Train] Epoch: 1 [287936/620022]    Loss: 0.006295   Batch Acc: 85.94
[Train] Epoch: 1 [288000/620022]    Loss: 0.009083   Batch Acc: 79.69
[Train] Epoch: 1 [288064/620022]    Loss: 0.007889   Batch Acc: 78.12
[Train] Epoch: 1 [288128/620022]    Loss: 0.012236   Batch Acc: 64.06
[Train] Epoch: 1 [288192/620022]    Loss: 0.009026   Batch Acc: 76.56
[Train] Epoch: 1 [288256/620022]    Loss: 0.008267   Batch Acc: 78.12
[Train] Epoch: 1 [288320/620022]    Loss: 0.007982   Batch Acc: 78.12
[Train] Epoch: 1 [288384/620022]    Loss: 0.010609   Batch Acc: 73.44
[Train] Epoch: 1 [288448/620022]    Loss: 0.005928   Batch Acc: 89.06
[Train] Epoch: 1 [288512/620022]    Loss: 0.008914   Batch Acc: 82.81
[Train] Epoch: 1 [288576/620022]    Loss: 0.008072   Batch Acc: 79.69
[Train] Epoch: 1 [288640/620022]    Loss: 0.009151   Batch Acc: 75.00
[Train] Epoch: 1 [288704/620022]    Loss: 0.007095   Batch Acc: 82.81
[Train] Epoch: 1 [288768/620022]    Loss: 0.008765   Batch Acc: 75.00
[Train] Epoch: 1 [288832/620022]    Loss: 0.007885   Batch Acc: 84.38
[Train] Epoch: 1 [288896/620022]    Loss: 0.009124   Batch Acc: 71.88
[Train] Epoch: 1 [288960/620022]    Loss: 0.008594   Batch Acc: 75.00
[Train] Epoch: 1 [289024/620022]    Loss: 0.010035   Batch Acc: 71.88
[Train] Epoch: 1 [289088/620022]    Loss: 0.006432   Batch Acc: 84.38
[Train] Epoch: 1 [289152/620022]    Loss: 0.006545   Batch Acc: 85.94
[Train] Epoch: 1 [289216/620022]    Loss: 0.007332   Batch Acc: 79.69
[Train] Epoch: 1 [289280/620022]    Loss: 0.008781   Batch Acc: 75.00
[Train] Epoch: 1 [289344/620022]    Loss: 0.010102   Batch Acc: 73.44
[Train] Epoch: 1 [289408/620022]    Loss: 0.007598   Batch Acc: 81.25
[Train] Epoch: 1 [289472/620022]    Loss: 0.008475   Batch Acc: 76.56
[Train] Epoch: 1 [289536/620022]    Loss: 0.012309   Batch Acc: 67.19
[Train] Epoch: 1 [289600/620022]    Loss: 0.009249   Batch Acc: 81.25
[Train] Epoch: 1 [289664/620022]    Loss: 0.007142   Batch Acc: 82.81
[Train] Epoch: 1 [289728/620022]    Loss: 0.008702   Batch Acc: 79.69
[Train] Epoch: 1 [289792/620022]    Loss: 0.010710   Batch Acc: 67.19
[Train] Epoch: 1 [289856/620022]    Loss: 0.008793   Batch Acc: 78.12
[Train] Epoch: 1 [289920/620022]    Loss: 0.009654   Batch Acc: 75.00
[Train] Epoch: 1 [289984/620022]    Loss: 0.010120   Batch Acc: 78.12
[Train] Epoch: 1 [290048/620022]    Loss: 0.007653   Batch Acc: 84.38
[Train] Epoch: 1 [290112/620022]    Loss: 0.008459   Batch Acc: 78.12
[Train] Epoch: 1 [290176/620022]    Loss: 0.009461   Batch Acc: 76.56
[Train] Epoch: 1 [290240/620022]    Loss: 0.007987   Batch Acc: 81.25
[Train] Epoch: 1 [290304/620022]    Loss: 0.008851   Batch Acc: 73.44
[Train] Epoch: 1 [290368/620022]    Loss: 0.009606   Batch Acc: 73.44
[Train] Epoch: 1 [290432/620022]    Loss: 0.007882   Batch Acc: 79.69
[Train] Epoch: 1 [290496/620022]    Loss: 0.007031   Batch Acc: 78.12
[Train] Epoch: 1 [290560/620022]    Loss: 0.007030   Batch Acc: 81.25
[Train] Epoch: 1 [290624/620022]    Loss: 0.009685   Batch Acc: 76.56
[Train] Epoch: 1 [290688/620022]    Loss: 0.009200   Batch Acc: 81.25
[Train] Epoch: 1 [290752/620022]    Loss: 0.008159   Batch Acc: 76.56
[Train] Epoch: 1 [290816/620022]    Loss: 0.006472   Batch Acc: 87.50
[Train] Epoch: 1 [290880/620022]    Loss: 0.008936   Batch Acc: 78.12
[Train] Epoch: 1 [290944/620022]    Loss: 0.008278   Batch Acc: 82.81
[Train] Epoch: 1 [291008/620022]    Loss: 0.009207   Batch Acc: 71.88
[Train] Epoch: 1 [291072/620022]    Loss: 0.007033   Batch Acc: 84.38
[Train] Epoch: 1 [291136/620022]    Loss: 0.008547   Batch Acc: 84.38
[Train] Epoch: 1 [291200/620022]    Loss: 0.011439   Batch Acc: 68.75
[Train] Epoch: 1 [291264/620022]    Loss: 0.009165   Batch Acc: 76.56
[Train] Epoch: 1 [291328/620022]    Loss: 0.008141   Batch Acc: 81.25
[Train] Epoch: 1 [291392/620022]    Loss: 0.005496   Batch Acc: 92.19
[Train] Epoch: 1 [291456/620022]    Loss: 0.010867   Batch Acc: 71.88
[Train] Epoch: 1 [291520/620022]    Loss: 0.008554   Batch Acc: 84.38
[Train] Epoch: 1 [291584/620022]    Loss: 0.011034   Batch Acc: 67.19
[Train] Epoch: 1 [291648/620022]    Loss: 0.007334   Batch Acc: 82.81
[Train] Epoch: 1 [291712/620022]    Loss: 0.005809   Batch Acc: 89.06
[Train] Epoch: 1 [291776/620022]    Loss: 0.008454   Batch Acc: 79.69
[Train] Epoch: 1 [291840/620022]    Loss: 0.008754   Batch Acc: 76.56
[Train] Epoch: 1 [291904/620022]    Loss: 0.009597   Batch Acc: 76.56
[Train] Epoch: 1 [291968/620022]    Loss: 0.008448   Batch Acc: 81.25
[Train] Epoch: 1 [292032/620022]    Loss: 0.008621   Batch Acc: 82.81
[Train] Epoch: 1 [292096/620022]    Loss: 0.006910   Batch Acc: 84.38
[Train] Epoch: 1 [292160/620022]    Loss: 0.007358   Batch Acc: 84.38
[Train] Epoch: 1 [292224/620022]    Loss: 0.008665   Batch Acc: 81.25
[Train] Epoch: 1 [292288/620022]    Loss: 0.010982   Batch Acc: 68.75
[Train] Epoch: 1 [292352/620022]    Loss: 0.010751   Batch Acc: 67.19
[Train] Epoch: 1 [292416/620022]    Loss: 0.012825   Batch Acc: 68.75
[Train] Epoch: 1 [292480/620022]    Loss: 0.007949   Batch Acc: 78.12
[Train] Epoch: 1 [292544/620022]    Loss: 0.010746   Batch Acc: 71.88
[Train] Epoch: 1 [292608/620022]    Loss: 0.009713   Batch Acc: 75.00
[Train] Epoch: 1 [292672/620022]    Loss: 0.008919   Batch Acc: 73.44
[Train] Epoch: 1 [292736/620022]    Loss: 0.010884   Batch Acc: 71.88
[Train] Epoch: 1 [292800/620022]    Loss: 0.008973   Batch Acc: 76.56
[Train] Epoch: 1 [292864/620022]    Loss: 0.009603   Batch Acc: 75.00
[Train] Epoch: 1 [292928/620022]    Loss: 0.008128   Batch Acc: 76.56
[Train] Epoch: 1 [292992/620022]    Loss: 0.009248   Batch Acc: 76.56
[Train] Epoch: 1 [293056/620022]    Loss: 0.008740   Batch Acc: 76.56
[Train] Epoch: 1 [293120/620022]    Loss: 0.011822   Batch Acc: 68.75
[Train] Epoch: 1 [293184/620022]    Loss: 0.009113   Batch Acc: 71.88
[Train] Epoch: 1 [293248/620022]    Loss: 0.007594   Batch Acc: 82.81
[Train] Epoch: 1 [293312/620022]    Loss: 0.008368   Batch Acc: 78.12
[Train] Epoch: 1 [293376/620022]    Loss: 0.007445   Batch Acc: 81.25
[Train] Epoch: 1 [293440/620022]    Loss: 0.007656   Batch Acc: 79.69
[Train] Epoch: 1 [293504/620022]    Loss: 0.008385   Batch Acc: 81.25
[Train] Epoch: 1 [293568/620022]    Loss: 0.007771   Batch Acc: 79.69
[Train] Epoch: 1 [293632/620022]    Loss: 0.006124   Batch Acc: 84.38
[Train] Epoch: 1 [293696/620022]    Loss: 0.010559   Batch Acc: 71.88
[Train] Epoch: 1 [293760/620022]    Loss: 0.008398   Batch Acc: 79.69
[Train] Epoch: 1 [293824/620022]    Loss: 0.008886   Batch Acc: 75.00
[Train] Epoch: 1 [293888/620022]    Loss: 0.010464   Batch Acc: 71.88
[Train] Epoch: 1 [293952/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 1 [294016/620022]    Loss: 0.007486   Batch Acc: 81.25
[Train] Epoch: 1 [294080/620022]    Loss: 0.006971   Batch Acc: 84.38
[Train] Epoch: 1 [294144/620022]    Loss: 0.006649   Batch Acc: 89.06
[Train] Epoch: 1 [294208/620022]    Loss: 0.009024   Batch Acc: 82.81
[Train] Epoch: 1 [294272/620022]    Loss: 0.009153   Batch Acc: 68.75
[Train] Epoch: 1 [294336/620022]    Loss: 0.008013   Batch Acc: 82.81
[Train] Epoch: 1 [294400/620022]    Loss: 0.007766   Batch Acc: 84.38
[Train] Epoch: 1 [294464/620022]    Loss: 0.007413   Batch Acc: 82.81
[Train] Epoch: 1 [294528/620022]    Loss: 0.006549   Batch Acc: 89.06
[Train] Epoch: 1 [294592/620022]    Loss: 0.006583   Batch Acc: 87.50
[Train] Epoch: 1 [294656/620022]    Loss: 0.007499   Batch Acc: 78.12
[Train] Epoch: 1 [294720/620022]    Loss: 0.009862   Batch Acc: 76.56
[Train] Epoch: 1 [294784/620022]    Loss: 0.008384   Batch Acc: 78.12
[Train] Epoch: 1 [294848/620022]    Loss: 0.010306   Batch Acc: 75.00
[Train] Epoch: 1 [294912/620022]    Loss: 0.009612   Batch Acc: 78.12
[Train] Epoch: 1 [294976/620022]    Loss: 0.008323   Batch Acc: 73.44
[Train] Epoch: 1 [295040/620022]    Loss: 0.010071   Batch Acc: 71.88
[Train] Epoch: 1 [295104/620022]    Loss: 0.007287   Batch Acc: 75.00
[Train] Epoch: 1 [295168/620022]    Loss: 0.010816   Batch Acc: 64.06
[Train] Epoch: 1 [295232/620022]    Loss: 0.009918   Batch Acc: 71.88
[Train] Epoch: 1 [295296/620022]    Loss: 0.008712   Batch Acc: 75.00
[Train] Epoch: 1 [295360/620022]    Loss: 0.008068   Batch Acc: 75.00
[Train] Epoch: 1 [295424/620022]    Loss: 0.006832   Batch Acc: 84.38
[Train] Epoch: 1 [295488/620022]    Loss: 0.007954   Batch Acc: 78.12
[Train] Epoch: 1 [295552/620022]    Loss: 0.011809   Batch Acc: 68.75
[Train] Epoch: 1 [295616/620022]    Loss: 0.007425   Batch Acc: 81.25
[Train] Epoch: 1 [295680/620022]    Loss: 0.009331   Batch Acc: 75.00
[Train] Epoch: 1 [295744/620022]    Loss: 0.008543   Batch Acc: 71.88
[Train] Epoch: 1 [295808/620022]    Loss: 0.009481   Batch Acc: 78.12
[Train] Epoch: 1 [295872/620022]    Loss: 0.009529   Batch Acc: 75.00
[Train] Epoch: 1 [295936/620022]    Loss: 0.009144   Batch Acc: 76.56
[Train] Epoch: 1 [296000/620022]    Loss: 0.008513   Batch Acc: 76.56
[Train] Epoch: 1 [296064/620022]    Loss: 0.008896   Batch Acc: 79.69
[Train] Epoch: 1 [296128/620022]    Loss: 0.009450   Batch Acc: 70.31
[Train] Epoch: 1 [296192/620022]    Loss: 0.007932   Batch Acc: 78.12
[Train] Epoch: 1 [296256/620022]    Loss: 0.007447   Batch Acc: 84.38
[Train] Epoch: 1 [296320/620022]    Loss: 0.010143   Batch Acc: 73.44
[Train] Epoch: 1 [296384/620022]    Loss: 0.008531   Batch Acc: 76.56
[Train] Epoch: 1 [296448/620022]    Loss: 0.008444   Batch Acc: 81.25
[Train] Epoch: 1 [296512/620022]    Loss: 0.006966   Batch Acc: 82.81
[Train] Epoch: 1 [296576/620022]    Loss: 0.008840   Batch Acc: 78.12
[Train] Epoch: 1 [296640/620022]    Loss: 0.007465   Batch Acc: 82.81
[Train] Epoch: 1 [296704/620022]    Loss: 0.005848   Batch Acc: 92.19
[Train] Epoch: 1 [296768/620022]    Loss: 0.007380   Batch Acc: 85.94
[Train] Epoch: 1 [296832/620022]    Loss: 0.010808   Batch Acc: 71.88
[Train] Epoch: 1 [296896/620022]    Loss: 0.008645   Batch Acc: 79.69
[Train] Epoch: 1 [296960/620022]    Loss: 0.006273   Batch Acc: 89.06
[Train] Epoch: 1 [297024/620022]    Loss: 0.009034   Batch Acc: 75.00
[Train] Epoch: 1 [297088/620022]    Loss: 0.007710   Batch Acc: 84.38
[Train] Epoch: 1 [297152/620022]    Loss: 0.009246   Batch Acc: 84.38
[Train] Epoch: 1 [297216/620022]    Loss: 0.009286   Batch Acc: 70.31
[Train] Epoch: 1 [297280/620022]    Loss: 0.007491   Batch Acc: 78.12
[Train] Epoch: 1 [297344/620022]    Loss: 0.007952   Batch Acc: 82.81
[Train] Epoch: 1 [297408/620022]    Loss: 0.008365   Batch Acc: 81.25
[Train] Epoch: 1 [297472/620022]    Loss: 0.010437   Batch Acc: 75.00
[Train] Epoch: 1 [297536/620022]    Loss: 0.011591   Batch Acc: 62.50
[Train] Epoch: 1 [297600/620022]    Loss: 0.008187   Batch Acc: 76.56
[Train] Epoch: 1 [297664/620022]    Loss: 0.009076   Batch Acc: 81.25
[Train] Epoch: 1 [297728/620022]    Loss: 0.010299   Batch Acc: 75.00
[Train] Epoch: 1 [297792/620022]    Loss: 0.007213   Batch Acc: 79.69
[Train] Epoch: 1 [297856/620022]    Loss: 0.006393   Batch Acc: 87.50
[Train] Epoch: 1 [297920/620022]    Loss: 0.007765   Batch Acc: 82.81
[Train] Epoch: 1 [297984/620022]    Loss: 0.007720   Batch Acc: 81.25
[Train] Epoch: 1 [298048/620022]    Loss: 0.007848   Batch Acc: 81.25
[Train] Epoch: 1 [298112/620022]    Loss: 0.009312   Batch Acc: 76.56
[Train] Epoch: 1 [298176/620022]    Loss: 0.006410   Batch Acc: 84.38
[Train] Epoch: 1 [298240/620022]    Loss: 0.008427   Batch Acc: 81.25
[Train] Epoch: 1 [298304/620022]    Loss: 0.008321   Batch Acc: 78.12
[Train] Epoch: 1 [298368/620022]    Loss: 0.008568   Batch Acc: 76.56
[Train] Epoch: 1 [298432/620022]    Loss: 0.008492   Batch Acc: 79.69
[Train] Epoch: 1 [298496/620022]    Loss: 0.009365   Batch Acc: 68.75
[Train] Epoch: 1 [298560/620022]    Loss: 0.009357   Batch Acc: 71.88
[Train] Epoch: 1 [298624/620022]    Loss: 0.006991   Batch Acc: 84.38
[Train] Epoch: 1 [298688/620022]    Loss: 0.006268   Batch Acc: 84.38
[Train] Epoch: 1 [298752/620022]    Loss: 0.009531   Batch Acc: 75.00
[Train] Epoch: 1 [298816/620022]    Loss: 0.010021   Batch Acc: 76.56
[Train] Epoch: 1 [298880/620022]    Loss: 0.010460   Batch Acc: 71.88
[Train] Epoch: 1 [298944/620022]    Loss: 0.007773   Batch Acc: 76.56
[Train] Epoch: 1 [299008/620022]    Loss: 0.012831   Batch Acc: 62.50
[Train] Epoch: 1 [299072/620022]    Loss: 0.008795   Batch Acc: 79.69
[Train] Epoch: 1 [299136/620022]    Loss: 0.008913   Batch Acc: 79.69
[Train] Epoch: 1 [299200/620022]    Loss: 0.007466   Batch Acc: 79.69
[Train] Epoch: 1 [299264/620022]    Loss: 0.007681   Batch Acc: 84.38
[Train] Epoch: 1 [299328/620022]    Loss: 0.006910   Batch Acc: 87.50
[Train] Epoch: 1 [299392/620022]    Loss: 0.009448   Batch Acc: 78.12
[Train] Epoch: 1 [299456/620022]    Loss: 0.006708   Batch Acc: 85.94
[Train] Epoch: 1 [299520/620022]    Loss: 0.005942   Batch Acc: 85.94
[Train] Epoch: 1 [299584/620022]    Loss: 0.009830   Batch Acc: 70.31
[Train] Epoch: 1 [299648/620022]    Loss: 0.010309   Batch Acc: 73.44
[Train] Epoch: 1 [299712/620022]    Loss: 0.007348   Batch Acc: 81.25
[Train] Epoch: 1 [299776/620022]    Loss: 0.007811   Batch Acc: 82.81
[Train] Epoch: 1 [299840/620022]    Loss: 0.007840   Batch Acc: 78.12
[Train] Epoch: 1 [299904/620022]    Loss: 0.009213   Batch Acc: 76.56
[Train] Epoch: 1 [299968/620022]    Loss: 0.008472   Batch Acc: 82.81
[Train] Epoch: 1 [300032/620022]    Loss: 0.007277   Batch Acc: 85.94
[Train] Epoch: 1 [300096/620022]    Loss: 0.009925   Batch Acc: 70.31
[Train] Epoch: 1 [300160/620022]    Loss: 0.009066   Batch Acc: 79.69
[Train] Epoch: 1 [300224/620022]    Loss: 0.007096   Batch Acc: 84.38
[Train] Epoch: 1 [300288/620022]    Loss: 0.008653   Batch Acc: 75.00
[Train] Epoch: 1 [300352/620022]    Loss: 0.007985   Batch Acc: 78.12
[Train] Epoch: 1 [300416/620022]    Loss: 0.009237   Batch Acc: 79.69
[Train] Epoch: 1 [300480/620022]    Loss: 0.010195   Batch Acc: 70.31
[Train] Epoch: 1 [300544/620022]    Loss: 0.010411   Batch Acc: 67.19
[Train] Epoch: 1 [300608/620022]    Loss: 0.009606   Batch Acc: 71.88
[Train] Epoch: 1 [300672/620022]    Loss: 0.007526   Batch Acc: 81.25
[Train] Epoch: 1 [300736/620022]    Loss: 0.009647   Batch Acc: 73.44
[Train] Epoch: 1 [300800/620022]    Loss: 0.008283   Batch Acc: 78.12
[Train] Epoch: 1 [300864/620022]    Loss: 0.012296   Batch Acc: 68.75
[Train] Epoch: 1 [300928/620022]    Loss: 0.008264   Batch Acc: 73.44
[Train] Epoch: 1 [300992/620022]    Loss: 0.008504   Batch Acc: 78.12
[Train] Epoch: 1 [301056/620022]    Loss: 0.008977   Batch Acc: 76.56
[Train] Epoch: 1 [301120/620022]    Loss: 0.011009   Batch Acc: 68.75
[Train] Epoch: 1 [301184/620022]    Loss: 0.006118   Batch Acc: 85.94
[Train] Epoch: 1 [301248/620022]    Loss: 0.008972   Batch Acc: 71.88
[Train] Epoch: 1 [301312/620022]    Loss: 0.011308   Batch Acc: 68.75
[Train] Epoch: 1 [301376/620022]    Loss: 0.006999   Batch Acc: 87.50
[Train] Epoch: 1 [301440/620022]    Loss: 0.006806   Batch Acc: 82.81
[Train] Epoch: 1 [301504/620022]    Loss: 0.009245   Batch Acc: 70.31
[Train] Epoch: 1 [301568/620022]    Loss: 0.006809   Batch Acc: 75.00
[Train] Epoch: 1 [301632/620022]    Loss: 0.008435   Batch Acc: 78.12
[Train] Epoch: 1 [301696/620022]    Loss: 0.006753   Batch Acc: 79.69
[Train] Epoch: 1 [301760/620022]    Loss: 0.007845   Batch Acc: 82.81
[Train] Epoch: 1 [301824/620022]    Loss: 0.007717   Batch Acc: 78.12
[Train] Epoch: 1 [301888/620022]    Loss: 0.008531   Batch Acc: 78.12
[Train] Epoch: 1 [301952/620022]    Loss: 0.006377   Batch Acc: 82.81
[Train] Epoch: 1 [302016/620022]    Loss: 0.006988   Batch Acc: 84.38
[Train] Epoch: 1 [302080/620022]    Loss: 0.007846   Batch Acc: 85.94
[Train] Epoch: 1 [302144/620022]    Loss: 0.009731   Batch Acc: 78.12
[Train] Epoch: 1 [302208/620022]    Loss: 0.010883   Batch Acc: 68.75
[Train] Epoch: 1 [302272/620022]    Loss: 0.008759   Batch Acc: 76.56
[Train] Epoch: 1 [302336/620022]    Loss: 0.007243   Batch Acc: 87.50
[Train] Epoch: 1 [302400/620022]    Loss: 0.009213   Batch Acc: 79.69
[Train] Epoch: 1 [302464/620022]    Loss: 0.009298   Batch Acc: 76.56
[Train] Epoch: 1 [302528/620022]    Loss: 0.010097   Batch Acc: 68.75
[Train] Epoch: 1 [302592/620022]    Loss: 0.011887   Batch Acc: 68.75
[Train] Epoch: 1 [302656/620022]    Loss: 0.007580   Batch Acc: 84.38
[Train] Epoch: 1 [302720/620022]    Loss: 0.008545   Batch Acc: 81.25
[Train] Epoch: 1 [302784/620022]    Loss: 0.007374   Batch Acc: 84.38
[Train] Epoch: 1 [302848/620022]    Loss: 0.007511   Batch Acc: 82.81
[Train] Epoch: 1 [302912/620022]    Loss: 0.009854   Batch Acc: 78.12
[Train] Epoch: 1 [302976/620022]    Loss: 0.009678   Batch Acc: 71.88
[Train] Epoch: 1 [303040/620022]    Loss: 0.009783   Batch Acc: 81.25
[Train] Epoch: 1 [303104/620022]    Loss: 0.008540   Batch Acc: 78.12
[Train] Epoch: 1 [303168/620022]    Loss: 0.008526   Batch Acc: 82.81
[Train] Epoch: 1 [303232/620022]    Loss: 0.010186   Batch Acc: 73.44
[Train] Epoch: 1 [303296/620022]    Loss: 0.008357   Batch Acc: 82.81
[Train] Epoch: 1 [303360/620022]    Loss: 0.010155   Batch Acc: 79.69
[Train] Epoch: 1 [303424/620022]    Loss: 0.011333   Batch Acc: 73.44
[Train] Epoch: 1 [303488/620022]    Loss: 0.009688   Batch Acc: 70.31
[Train] Epoch: 1 [303552/620022]    Loss: 0.008923   Batch Acc: 71.88
[Train] Epoch: 1 [303616/620022]    Loss: 0.008291   Batch Acc: 82.81
[Train] Epoch: 1 [303680/620022]    Loss: 0.009414   Batch Acc: 76.56
[Train] Epoch: 1 [303744/620022]    Loss: 0.008933   Batch Acc: 82.81
[Train] Epoch: 1 [303808/620022]    Loss: 0.008933   Batch Acc: 76.56
[Train] Epoch: 1 [303872/620022]    Loss: 0.008717   Batch Acc: 82.81
[Train] Epoch: 1 [303936/620022]    Loss: 0.008686   Batch Acc: 76.56
[Train] Epoch: 1 [304000/620022]    Loss: 0.010710   Batch Acc: 70.31
[Train] Epoch: 1 [304064/620022]    Loss: 0.011673   Batch Acc: 60.94
[Train] Epoch: 1 [304128/620022]    Loss: 0.007726   Batch Acc: 81.25
[Train] Epoch: 1 [304192/620022]    Loss: 0.008863   Batch Acc: 76.56
[Train] Epoch: 1 [304256/620022]    Loss: 0.009966   Batch Acc: 81.25
[Train] Epoch: 1 [304320/620022]    Loss: 0.008122   Batch Acc: 79.69
[Train] Epoch: 1 [304384/620022]    Loss: 0.010765   Batch Acc: 70.31
[Train] Epoch: 1 [304448/620022]    Loss: 0.010135   Batch Acc: 73.44
[Train] Epoch: 1 [304512/620022]    Loss: 0.009050   Batch Acc: 76.56
[Train] Epoch: 1 [304576/620022]    Loss: 0.008553   Batch Acc: 76.56
[Train] Epoch: 1 [304640/620022]    Loss: 0.009668   Batch Acc: 78.12
[Train] Epoch: 1 [304704/620022]    Loss: 0.007770   Batch Acc: 81.25
[Train] Epoch: 1 [304768/620022]    Loss: 0.008102   Batch Acc: 78.12
[Train] Epoch: 1 [304832/620022]    Loss: 0.007164   Batch Acc: 84.38
[Train] Epoch: 1 [304896/620022]    Loss: 0.008672   Batch Acc: 76.56
[Train] Epoch: 1 [304960/620022]    Loss: 0.007330   Batch Acc: 81.25
[Train] Epoch: 1 [305024/620022]    Loss: 0.008688   Batch Acc: 73.44
[Train] Epoch: 1 [305088/620022]    Loss: 0.007687   Batch Acc: 81.25
[Train] Epoch: 1 [305152/620022]    Loss: 0.007170   Batch Acc: 82.81
[Train] Epoch: 1 [305216/620022]    Loss: 0.008777   Batch Acc: 79.69
[Train] Epoch: 1 [305280/620022]    Loss: 0.008494   Batch Acc: 73.44
[Train] Epoch: 1 [305344/620022]    Loss: 0.006934   Batch Acc: 82.81
[Train] Epoch: 1 [305408/620022]    Loss: 0.009691   Batch Acc: 78.12
[Train] Epoch: 1 [305472/620022]    Loss: 0.007231   Batch Acc: 81.25
[Train] Epoch: 1 [305536/620022]    Loss: 0.009044   Batch Acc: 76.56
[Train] Epoch: 1 [305600/620022]    Loss: 0.008314   Batch Acc: 75.00
[Train] Epoch: 1 [305664/620022]    Loss: 0.008979   Batch Acc: 82.81
[Train] Epoch: 1 [305728/620022]    Loss: 0.010159   Batch Acc: 68.75
[Train] Epoch: 1 [305792/620022]    Loss: 0.008212   Batch Acc: 76.56
[Train] Epoch: 1 [305856/620022]    Loss: 0.008116   Batch Acc: 78.12
[Train] Epoch: 1 [305920/620022]    Loss: 0.011280   Batch Acc: 75.00
[Train] Epoch: 1 [305984/620022]    Loss: 0.006896   Batch Acc: 82.81
[Train] Epoch: 1 [306048/620022]    Loss: 0.008709   Batch Acc: 82.81
[Train] Epoch: 1 [306112/620022]    Loss: 0.010028   Batch Acc: 75.00
[Train] Epoch: 1 [306176/620022]    Loss: 0.008064   Batch Acc: 79.69
[Train] Epoch: 1 [306240/620022]    Loss: 0.008624   Batch Acc: 76.56
[Train] Epoch: 1 [306304/620022]    Loss: 0.009379   Batch Acc: 78.12
[Train] Epoch: 1 [306368/620022]    Loss: 0.009837   Batch Acc: 73.44
[Train] Epoch: 1 [306432/620022]    Loss: 0.007166   Batch Acc: 81.25
[Train] Epoch: 1 [306496/620022]    Loss: 0.006772   Batch Acc: 85.94
[Train] Epoch: 1 [306560/620022]    Loss: 0.007160   Batch Acc: 81.25
[Train] Epoch: 1 [306624/620022]    Loss: 0.010988   Batch Acc: 68.75
[Train] Epoch: 1 [306688/620022]    Loss: 0.009656   Batch Acc: 78.12
[Train] Epoch: 1 [306752/620022]    Loss: 0.010161   Batch Acc: 73.44
[Train] Epoch: 1 [306816/620022]    Loss: 0.007750   Batch Acc: 84.38
[Train] Epoch: 1 [306880/620022]    Loss: 0.011194   Batch Acc: 68.75
[Train] Epoch: 1 [306944/620022]    Loss: 0.009617   Batch Acc: 75.00
[Train] Epoch: 1 [307008/620022]    Loss: 0.009527   Batch Acc: 75.00
[Train] Epoch: 1 [307072/620022]    Loss: 0.009253   Batch Acc: 76.56
[Train] Epoch: 1 [307136/620022]    Loss: 0.009320   Batch Acc: 76.56
[Train] Epoch: 1 [307200/620022]    Loss: 0.010783   Batch Acc: 70.31
[Train] Epoch: 1 [307264/620022]    Loss: 0.010377   Batch Acc: 67.19
[Train] Epoch: 1 [307328/620022]    Loss: 0.007405   Batch Acc: 81.25
[Train] Epoch: 1 [307392/620022]    Loss: 0.010153   Batch Acc: 73.44
[Train] Epoch: 1 [307456/620022]    Loss: 0.009445   Batch Acc: 73.44
[Train] Epoch: 1 [307520/620022]    Loss: 0.009028   Batch Acc: 76.56
[Train] Epoch: 1 [307584/620022]    Loss: 0.008519   Batch Acc: 81.25
[Train] Epoch: 1 [307648/620022]    Loss: 0.008422   Batch Acc: 73.44
[Train] Epoch: 1 [307712/620022]    Loss: 0.009034   Batch Acc: 73.44
[Train] Epoch: 1 [307776/620022]    Loss: 0.008357   Batch Acc: 82.81
[Train] Epoch: 1 [307840/620022]    Loss: 0.008560   Batch Acc: 82.81
[Train] Epoch: 1 [307904/620022]    Loss: 0.009683   Batch Acc: 75.00
[Train] Epoch: 1 [307968/620022]    Loss: 0.011839   Batch Acc: 71.88
[Train] Epoch: 1 [308032/620022]    Loss: 0.006898   Batch Acc: 89.06
[Train] Epoch: 1 [308096/620022]    Loss: 0.007770   Batch Acc: 82.81
[Train] Epoch: 1 [308160/620022]    Loss: 0.010354   Batch Acc: 73.44
[Train] Epoch: 1 [308224/620022]    Loss: 0.007892   Batch Acc: 78.12
[Train] Epoch: 1 [308288/620022]    Loss: 0.007590   Batch Acc: 81.25
[Train] Epoch: 1 [308352/620022]    Loss: 0.007037   Batch Acc: 85.94
[Train] Epoch: 1 [308416/620022]    Loss: 0.007416   Batch Acc: 81.25
[Train] Epoch: 1 [308480/620022]    Loss: 0.012054   Batch Acc: 68.75
[Train] Epoch: 1 [308544/620022]    Loss: 0.009900   Batch Acc: 73.44
[Train] Epoch: 1 [308608/620022]    Loss: 0.007030   Batch Acc: 79.69
[Train] Epoch: 1 [308672/620022]    Loss: 0.007280   Batch Acc: 81.25
[Train] Epoch: 1 [308736/620022]    Loss: 0.008510   Batch Acc: 75.00
[Train] Epoch: 1 [308800/620022]    Loss: 0.006831   Batch Acc: 79.69
[Train] Epoch: 1 [308864/620022]    Loss: 0.006928   Batch Acc: 85.94
[Train] Epoch: 1 [308928/620022]    Loss: 0.009483   Batch Acc: 75.00
[Train] Epoch: 1 [308992/620022]    Loss: 0.008107   Batch Acc: 79.69
[Train] Epoch: 1 [309056/620022]    Loss: 0.010009   Batch Acc: 70.31
[Train] Epoch: 1 [309120/620022]    Loss: 0.007945   Batch Acc: 79.69
[Train] Epoch: 1 [309184/620022]    Loss: 0.008141   Batch Acc: 84.38
[Train] Epoch: 1 [309248/620022]    Loss: 0.009257   Batch Acc: 76.56
[Train] Epoch: 1 [309312/620022]    Loss: 0.009534   Batch Acc: 73.44
[Train] Epoch: 1 [309376/620022]    Loss: 0.009658   Batch Acc: 75.00
[Train] Epoch: 1 [309440/620022]    Loss: 0.009115   Batch Acc: 76.56
[Train] Epoch: 1 [309504/620022]    Loss: 0.009829   Batch Acc: 75.00
[Train] Epoch: 1 [309568/620022]    Loss: 0.005433   Batch Acc: 85.94
[Train] Epoch: 1 [309632/620022]    Loss: 0.008663   Batch Acc: 78.12
[Train] Epoch: 1 [309696/620022]    Loss: 0.013126   Batch Acc: 65.62
[Train] Epoch: 1 [309760/620022]    Loss: 0.006779   Batch Acc: 84.38
[Train] Epoch: 1 [309824/620022]    Loss: 0.008154   Batch Acc: 81.25
[Train] Epoch: 1 [309888/620022]    Loss: 0.007279   Batch Acc: 81.25
[Train] Epoch: 1 [309952/620022]    Loss: 0.009454   Batch Acc: 68.75
[Train] Epoch: 1 [310016/620022]    Loss: 0.009327   Batch Acc: 82.81
[Train] Epoch: 1 [310080/620022]    Loss: 0.008565   Batch Acc: 78.12
[Train] Epoch: 1 [310144/620022]    Loss: 0.005870   Batch Acc: 85.94
[Train] Epoch: 1 [310208/620022]    Loss: 0.010610   Batch Acc: 76.56
[Train] Epoch: 1 [310272/620022]    Loss: 0.008145   Batch Acc: 79.69
[Train] Epoch: 1 [310336/620022]    Loss: 0.010054   Batch Acc: 70.31
[Train] Epoch: 1 [310400/620022]    Loss: 0.007703   Batch Acc: 81.25
[Train] Epoch: 1 [310464/620022]    Loss: 0.009183   Batch Acc: 76.56
[Train] Epoch: 1 [310528/620022]    Loss: 0.009251   Batch Acc: 73.44
[Train] Epoch: 1 [310592/620022]    Loss: 0.007885   Batch Acc: 81.25
[Train] Epoch: 1 [310656/620022]    Loss: 0.008756   Batch Acc: 76.56
[Train] Epoch: 1 [310720/620022]    Loss: 0.006758   Batch Acc: 81.25
[Train] Epoch: 1 [310784/620022]    Loss: 0.010886   Batch Acc: 65.62
[Train] Epoch: 1 [310848/620022]    Loss: 0.009194   Batch Acc: 75.00
[Train] Epoch: 1 [310912/620022]    Loss: 0.006810   Batch Acc: 82.81
[Train] Epoch: 1 [310976/620022]    Loss: 0.011207   Batch Acc: 67.19
[Train] Epoch: 1 [311040/620022]    Loss: 0.011518   Batch Acc: 62.50
[Train] Epoch: 1 [311104/620022]    Loss: 0.007632   Batch Acc: 81.25
[Train] Epoch: 1 [311168/620022]    Loss: 0.010004   Batch Acc: 67.19
[Train] Epoch: 1 [311232/620022]    Loss: 0.008247   Batch Acc: 78.12
[Train] Epoch: 1 [311296/620022]    Loss: 0.007773   Batch Acc: 85.94
[Train] Epoch: 1 [311360/620022]    Loss: 0.010570   Batch Acc: 68.75
[Train] Epoch: 1 [311424/620022]    Loss: 0.008681   Batch Acc: 73.44
[Train] Epoch: 1 [311488/620022]    Loss: 0.009577   Batch Acc: 73.44
[Train] Epoch: 1 [311552/620022]    Loss: 0.007604   Batch Acc: 84.38
[Train] Epoch: 1 [311616/620022]    Loss: 0.007821   Batch Acc: 78.12
[Train] Epoch: 1 [311680/620022]    Loss: 0.008235   Batch Acc: 81.25
[Train] Epoch: 1 [311744/620022]    Loss: 0.011083   Batch Acc: 65.62
[Train] Epoch: 1 [311808/620022]    Loss: 0.009373   Batch Acc: 76.56
[Train] Epoch: 1 [311872/620022]    Loss: 0.010965   Batch Acc: 73.44
[Train] Epoch: 1 [311936/620022]    Loss: 0.007709   Batch Acc: 84.38
[Train] Epoch: 1 [312000/620022]    Loss: 0.007686   Batch Acc: 79.69
[Train] Epoch: 1 [312064/620022]    Loss: 0.006750   Batch Acc: 79.69
[Train] Epoch: 1 [312128/620022]    Loss: 0.009137   Batch Acc: 81.25
[Train] Epoch: 1 [312192/620022]    Loss: 0.008187   Batch Acc: 78.12
[Train] Epoch: 1 [312256/620022]    Loss: 0.007322   Batch Acc: 81.25
[Train] Epoch: 1 [312320/620022]    Loss: 0.006372   Batch Acc: 82.81
[Train] Epoch: 1 [312384/620022]    Loss: 0.006133   Batch Acc: 87.50
[Train] Epoch: 1 [312448/620022]    Loss: 0.008049   Batch Acc: 76.56
[Train] Epoch: 1 [312512/620022]    Loss: 0.007909   Batch Acc: 82.81
[Train] Epoch: 1 [312576/620022]    Loss: 0.009527   Batch Acc: 82.81
[Train] Epoch: 1 [312640/620022]    Loss: 0.008756   Batch Acc: 78.12
[Train] Epoch: 1 [312704/620022]    Loss: 0.010607   Batch Acc: 70.31
[Train] Epoch: 1 [312768/620022]    Loss: 0.010131   Batch Acc: 75.00
[Train] Epoch: 1 [312832/620022]    Loss: 0.008377   Batch Acc: 79.69
[Train] Epoch: 1 [312896/620022]    Loss: 0.007109   Batch Acc: 85.94
[Train] Epoch: 1 [312960/620022]    Loss: 0.010333   Batch Acc: 70.31
[Train] Epoch: 1 [313024/620022]    Loss: 0.009081   Batch Acc: 73.44
[Train] Epoch: 1 [313088/620022]    Loss: 0.010095   Batch Acc: 71.88
[Train] Epoch: 1 [313152/620022]    Loss: 0.009385   Batch Acc: 76.56
[Train] Epoch: 1 [313216/620022]    Loss: 0.009604   Batch Acc: 76.56
[Train] Epoch: 1 [313280/620022]    Loss: 0.007658   Batch Acc: 79.69
[Train] Epoch: 1 [313344/620022]    Loss: 0.009207   Batch Acc: 71.88
[Train] Epoch: 1 [313408/620022]    Loss: 0.008086   Batch Acc: 78.12
[Train] Epoch: 1 [313472/620022]    Loss: 0.007577   Batch Acc: 84.38
[Train] Epoch: 1 [313536/620022]    Loss: 0.010977   Batch Acc: 71.88
[Train] Epoch: 1 [313600/620022]    Loss: 0.009757   Batch Acc: 75.00
[Train] Epoch: 1 [313664/620022]    Loss: 0.007090   Batch Acc: 87.50
[Train] Epoch: 1 [313728/620022]    Loss: 0.007239   Batch Acc: 84.38
[Train] Epoch: 1 [313792/620022]    Loss: 0.007765   Batch Acc: 79.69
[Train] Epoch: 1 [313856/620022]    Loss: 0.008433   Batch Acc: 78.12
[Train] Epoch: 1 [313920/620022]    Loss: 0.008783   Batch Acc: 76.56
[Train] Epoch: 1 [313984/620022]    Loss: 0.008532   Batch Acc: 75.00
[Train] Epoch: 1 [314048/620022]    Loss: 0.009884   Batch Acc: 65.62
[Train] Epoch: 1 [314112/620022]    Loss: 0.010294   Batch Acc: 73.44
[Train] Epoch: 1 [314176/620022]    Loss: 0.010008   Batch Acc: 81.25
[Train] Epoch: 1 [314240/620022]    Loss: 0.009124   Batch Acc: 73.44
[Train] Epoch: 1 [314304/620022]    Loss: 0.008158   Batch Acc: 79.69
[Train] Epoch: 1 [314368/620022]    Loss: 0.008594   Batch Acc: 76.56
[Train] Epoch: 1 [314432/620022]    Loss: 0.009285   Batch Acc: 76.56
[Train] Epoch: 1 [314496/620022]    Loss: 0.008592   Batch Acc: 76.56
[Train] Epoch: 1 [314560/620022]    Loss: 0.010184   Batch Acc: 78.12
[Train] Epoch: 1 [314624/620022]    Loss: 0.009415   Batch Acc: 71.88
[Train] Epoch: 1 [314688/620022]    Loss: 0.006970   Batch Acc: 78.12
[Train] Epoch: 1 [314752/620022]    Loss: 0.009740   Batch Acc: 68.75
[Train] Epoch: 1 [314816/620022]    Loss: 0.008996   Batch Acc: 76.56
[Train] Epoch: 1 [314880/620022]    Loss: 0.007533   Batch Acc: 79.69
[Train] Epoch: 1 [314944/620022]    Loss: 0.006591   Batch Acc: 82.81
[Train] Epoch: 1 [315008/620022]    Loss: 0.007959   Batch Acc: 81.25
[Train] Epoch: 1 [315072/620022]    Loss: 0.009590   Batch Acc: 78.12
[Train] Epoch: 1 [315136/620022]    Loss: 0.007731   Batch Acc: 84.38
[Train] Epoch: 1 [315200/620022]    Loss: 0.007923   Batch Acc: 78.12
[Train] Epoch: 1 [315264/620022]    Loss: 0.008686   Batch Acc: 78.12
[Train] Epoch: 1 [315328/620022]    Loss: 0.009825   Batch Acc: 73.44
[Train] Epoch: 1 [315392/620022]    Loss: 0.008521   Batch Acc: 75.00
[Train] Epoch: 1 [315456/620022]    Loss: 0.008909   Batch Acc: 75.00
[Train] Epoch: 1 [315520/620022]    Loss: 0.009559   Batch Acc: 75.00
[Train] Epoch: 1 [315584/620022]    Loss: 0.008040   Batch Acc: 81.25
[Train] Epoch: 1 [315648/620022]    Loss: 0.008138   Batch Acc: 82.81
[Train] Epoch: 1 [315712/620022]    Loss: 0.006952   Batch Acc: 87.50
[Train] Epoch: 1 [315776/620022]    Loss: 0.007934   Batch Acc: 81.25
[Train] Epoch: 1 [315840/620022]    Loss: 0.008528   Batch Acc: 79.69
[Train] Epoch: 1 [315904/620022]    Loss: 0.008488   Batch Acc: 78.12
[Train] Epoch: 1 [315968/620022]    Loss: 0.008024   Batch Acc: 76.56
[Train] Epoch: 1 [316032/620022]    Loss: 0.008080   Batch Acc: 78.12
[Train] Epoch: 1 [316096/620022]    Loss: 0.008741   Batch Acc: 71.88
[Train] Epoch: 1 [316160/620022]    Loss: 0.010934   Batch Acc: 68.75
[Train] Epoch: 1 [316224/620022]    Loss: 0.008666   Batch Acc: 82.81
[Train] Epoch: 1 [316288/620022]    Loss: 0.009264   Batch Acc: 73.44
[Train] Epoch: 1 [316352/620022]    Loss: 0.008253   Batch Acc: 78.12
[Train] Epoch: 1 [316416/620022]    Loss: 0.007274   Batch Acc: 82.81
[Train] Epoch: 1 [316480/620022]    Loss: 0.009616   Batch Acc: 68.75
[Train] Epoch: 1 [316544/620022]    Loss: 0.009843   Batch Acc: 75.00
[Train] Epoch: 1 [316608/620022]    Loss: 0.009369   Batch Acc: 73.44
[Train] Epoch: 1 [316672/620022]    Loss: 0.008359   Batch Acc: 78.12
[Train] Epoch: 1 [316736/620022]    Loss: 0.009279   Batch Acc: 68.75
[Train] Epoch: 1 [316800/620022]    Loss: 0.008979   Batch Acc: 75.00
[Train] Epoch: 1 [316864/620022]    Loss: 0.008958   Batch Acc: 82.81
[Train] Epoch: 1 [316928/620022]    Loss: 0.010258   Batch Acc: 70.31
[Train] Epoch: 1 [316992/620022]    Loss: 0.010359   Batch Acc: 70.31
[Train] Epoch: 1 [317056/620022]    Loss: 0.008737   Batch Acc: 75.00
[Train] Epoch: 1 [317120/620022]    Loss: 0.009482   Batch Acc: 73.44
[Train] Epoch: 1 [317184/620022]    Loss: 0.009487   Batch Acc: 78.12
[Train] Epoch: 1 [317248/620022]    Loss: 0.009412   Batch Acc: 78.12
[Train] Epoch: 1 [317312/620022]    Loss: 0.009885   Batch Acc: 70.31
[Train] Epoch: 1 [317376/620022]    Loss: 0.007448   Batch Acc: 79.69
[Train] Epoch: 1 [317440/620022]    Loss: 0.009197   Batch Acc: 73.44
[Train] Epoch: 1 [317504/620022]    Loss: 0.008028   Batch Acc: 81.25
[Train] Epoch: 1 [317568/620022]    Loss: 0.006197   Batch Acc: 89.06
[Train] Epoch: 1 [317632/620022]    Loss: 0.009317   Batch Acc: 71.88
[Train] Epoch: 1 [317696/620022]    Loss: 0.010322   Batch Acc: 75.00
[Train] Epoch: 1 [317760/620022]    Loss: 0.008463   Batch Acc: 79.69
[Train] Epoch: 1 [317824/620022]    Loss: 0.010132   Batch Acc: 73.44
[Train] Epoch: 1 [317888/620022]    Loss: 0.009114   Batch Acc: 73.44
[Train] Epoch: 1 [317952/620022]    Loss: 0.008481   Batch Acc: 79.69
[Train] Epoch: 1 [318016/620022]    Loss: 0.008988   Batch Acc: 76.56
[Train] Epoch: 1 [318080/620022]    Loss: 0.007817   Batch Acc: 85.94
[Train] Epoch: 1 [318144/620022]    Loss: 0.007152   Batch Acc: 84.38
[Train] Epoch: 1 [318208/620022]    Loss: 0.008060   Batch Acc: 84.38
[Train] Epoch: 1 [318272/620022]    Loss: 0.010982   Batch Acc: 62.50
[Train] Epoch: 1 [318336/620022]    Loss: 0.009932   Batch Acc: 73.44
[Train] Epoch: 1 [318400/620022]    Loss: 0.008732   Batch Acc: 75.00
[Train] Epoch: 1 [318464/620022]    Loss: 0.006502   Batch Acc: 87.50
[Train] Epoch: 1 [318528/620022]    Loss: 0.010109   Batch Acc: 70.31
[Train] Epoch: 1 [318592/620022]    Loss: 0.006019   Batch Acc: 84.38
[Train] Epoch: 1 [318656/620022]    Loss: 0.006515   Batch Acc: 89.06
[Train] Epoch: 1 [318720/620022]    Loss: 0.011133   Batch Acc: 70.31
[Train] Epoch: 1 [318784/620022]    Loss: 0.008431   Batch Acc: 73.44
[Train] Epoch: 1 [318848/620022]    Loss: 0.007335   Batch Acc: 82.81
[Train] Epoch: 1 [318912/620022]    Loss: 0.008022   Batch Acc: 76.56
[Train] Epoch: 1 [318976/620022]    Loss: 0.009987   Batch Acc: 70.31
[Train] Epoch: 1 [319040/620022]    Loss: 0.009466   Batch Acc: 71.88
[Train] Epoch: 1 [319104/620022]    Loss: 0.008775   Batch Acc: 78.12
[Train] Epoch: 1 [319168/620022]    Loss: 0.009563   Batch Acc: 75.00
[Train] Epoch: 1 [319232/620022]    Loss: 0.007737   Batch Acc: 85.94
[Train] Epoch: 1 [319296/620022]    Loss: 0.007625   Batch Acc: 78.12
[Train] Epoch: 1 [319360/620022]    Loss: 0.009229   Batch Acc: 75.00
[Train] Epoch: 1 [319424/620022]    Loss: 0.008340   Batch Acc: 78.12
[Train] Epoch: 1 [319488/620022]    Loss: 0.009118   Batch Acc: 76.56
[Train] Epoch: 1 [319552/620022]    Loss: 0.008692   Batch Acc: 81.25
[Train] Epoch: 1 [319616/620022]    Loss: 0.009247   Batch Acc: 75.00
[Train] Epoch: 1 [319680/620022]    Loss: 0.008104   Batch Acc: 81.25
[Train] Epoch: 1 [319744/620022]    Loss: 0.008373   Batch Acc: 75.00
[Train] Epoch: 1 [319808/620022]    Loss: 0.008584   Batch Acc: 79.69
[Train] Epoch: 1 [319872/620022]    Loss: 0.007508   Batch Acc: 81.25
[Train] Epoch: 1 [319936/620022]    Loss: 0.005746   Batch Acc: 90.62
[Train] Epoch: 1 [320000/620022]    Loss: 0.010595   Batch Acc: 76.56
[Train] Epoch: 1 [320064/620022]    Loss: 0.009196   Batch Acc: 75.00
[Train] Epoch: 1 [320128/620022]    Loss: 0.007314   Batch Acc: 82.81
[Train] Epoch: 1 [320192/620022]    Loss: 0.007602   Batch Acc: 85.94
[Train] Epoch: 1 [320256/620022]    Loss: 0.008249   Batch Acc: 79.69
[Train] Epoch: 1 [320320/620022]    Loss: 0.008368   Batch Acc: 81.25
[Train] Epoch: 1 [320384/620022]    Loss: 0.008702   Batch Acc: 76.56
[Train] Epoch: 1 [320448/620022]    Loss: 0.005933   Batch Acc: 85.94
[Train] Epoch: 1 [320512/620022]    Loss: 0.007601   Batch Acc: 84.38
[Train] Epoch: 1 [320576/620022]    Loss: 0.007680   Batch Acc: 78.12
[Train] Epoch: 1 [320640/620022]    Loss: 0.008161   Batch Acc: 85.94
[Train] Epoch: 1 [320704/620022]    Loss: 0.009652   Batch Acc: 76.56
[Train] Epoch: 1 [320768/620022]    Loss: 0.006815   Batch Acc: 82.81
[Train] Epoch: 1 [320832/620022]    Loss: 0.008605   Batch Acc: 76.56
[Train] Epoch: 1 [320896/620022]    Loss: 0.008522   Batch Acc: 82.81
[Train] Epoch: 1 [320960/620022]    Loss: 0.008226   Batch Acc: 78.12
[Train] Epoch: 1 [321024/620022]    Loss: 0.011476   Batch Acc: 68.75
[Train] Epoch: 1 [321088/620022]    Loss: 0.007316   Batch Acc: 79.69
[Train] Epoch: 1 [321152/620022]    Loss: 0.008953   Batch Acc: 76.56
[Train] Epoch: 1 [321216/620022]    Loss: 0.006467   Batch Acc: 82.81
[Train] Epoch: 1 [321280/620022]    Loss: 0.010506   Batch Acc: 75.00
[Train] Epoch: 1 [321344/620022]    Loss: 0.009688   Batch Acc: 73.44
[Train] Epoch: 1 [321408/620022]    Loss: 0.009367   Batch Acc: 79.69
[Train] Epoch: 1 [321472/620022]    Loss: 0.010840   Batch Acc: 67.19
[Train] Epoch: 1 [321536/620022]    Loss: 0.007916   Batch Acc: 82.81
[Train] Epoch: 1 [321600/620022]    Loss: 0.008166   Batch Acc: 76.56
[Train] Epoch: 1 [321664/620022]    Loss: 0.010026   Batch Acc: 71.88
[Train] Epoch: 1 [321728/620022]    Loss: 0.010704   Batch Acc: 76.56
[Train] Epoch: 1 [321792/620022]    Loss: 0.007768   Batch Acc: 81.25
[Train] Epoch: 1 [321856/620022]    Loss: 0.007751   Batch Acc: 79.69
[Train] Epoch: 1 [321920/620022]    Loss: 0.010465   Batch Acc: 68.75
[Train] Epoch: 1 [321984/620022]    Loss: 0.008920   Batch Acc: 78.12
[Train] Epoch: 1 [322048/620022]    Loss: 0.009699   Batch Acc: 73.44
[Train] Epoch: 1 [322112/620022]    Loss: 0.007758   Batch Acc: 82.81
[Train] Epoch: 1 [322176/620022]    Loss: 0.009657   Batch Acc: 76.56
[Train] Epoch: 1 [322240/620022]    Loss: 0.007593   Batch Acc: 79.69
[Train] Epoch: 1 [322304/620022]    Loss: 0.007580   Batch Acc: 78.12
[Train] Epoch: 1 [322368/620022]    Loss: 0.008317   Batch Acc: 82.81
[Train] Epoch: 1 [322432/620022]    Loss: 0.008784   Batch Acc: 73.44
[Train] Epoch: 1 [322496/620022]    Loss: 0.006601   Batch Acc: 85.94
[Train] Epoch: 1 [322560/620022]    Loss: 0.008337   Batch Acc: 76.56
[Train] Epoch: 1 [322624/620022]    Loss: 0.009848   Batch Acc: 73.44
[Train] Epoch: 1 [322688/620022]    Loss: 0.008887   Batch Acc: 79.69
[Train] Epoch: 1 [322752/620022]    Loss: 0.009086   Batch Acc: 76.56
[Train] Epoch: 1 [322816/620022]    Loss: 0.007838   Batch Acc: 81.25
[Train] Epoch: 1 [322880/620022]    Loss: 0.006572   Batch Acc: 89.06
[Train] Epoch: 1 [322944/620022]    Loss: 0.008844   Batch Acc: 76.56
[Train] Epoch: 1 [323008/620022]    Loss: 0.011875   Batch Acc: 65.62
[Train] Epoch: 1 [323072/620022]    Loss: 0.010163   Batch Acc: 70.31
[Train] Epoch: 1 [323136/620022]    Loss: 0.010186   Batch Acc: 65.62
[Train] Epoch: 1 [323200/620022]    Loss: 0.007335   Batch Acc: 85.94
[Train] Epoch: 1 [323264/620022]    Loss: 0.007580   Batch Acc: 79.69
[Train] Epoch: 1 [323328/620022]    Loss: 0.008792   Batch Acc: 78.12
[Train] Epoch: 1 [323392/620022]    Loss: 0.009712   Batch Acc: 75.00
[Train] Epoch: 1 [323456/620022]    Loss: 0.009921   Batch Acc: 78.12
[Train] Epoch: 1 [323520/620022]    Loss: 0.008046   Batch Acc: 78.12
[Train] Epoch: 1 [323584/620022]    Loss: 0.008581   Batch Acc: 78.12
[Train] Epoch: 1 [323648/620022]    Loss: 0.009046   Batch Acc: 79.69
[Train] Epoch: 1 [323712/620022]    Loss: 0.007238   Batch Acc: 81.25
[Train] Epoch: 1 [323776/620022]    Loss: 0.009407   Batch Acc: 81.25
[Train] Epoch: 1 [323840/620022]    Loss: 0.010342   Batch Acc: 79.69
[Train] Epoch: 1 [323904/620022]    Loss: 0.008091   Batch Acc: 78.12
[Train] Epoch: 1 [323968/620022]    Loss: 0.007181   Batch Acc: 87.50
[Train] Epoch: 1 [324032/620022]    Loss: 0.007417   Batch Acc: 79.69
[Train] Epoch: 1 [324096/620022]    Loss: 0.007642   Batch Acc: 76.56
[Train] Epoch: 1 [324160/620022]    Loss: 0.009652   Batch Acc: 64.06
[Train] Epoch: 1 [324224/620022]    Loss: 0.007677   Batch Acc: 79.69
[Train] Epoch: 1 [324288/620022]    Loss: 0.008926   Batch Acc: 78.12
[Train] Epoch: 1 [324352/620022]    Loss: 0.008821   Batch Acc: 75.00
[Train] Epoch: 1 [324416/620022]    Loss: 0.009864   Batch Acc: 75.00
[Train] Epoch: 1 [324480/620022]    Loss: 0.007971   Batch Acc: 79.69
[Train] Epoch: 1 [324544/620022]    Loss: 0.010269   Batch Acc: 73.44
[Train] Epoch: 1 [324608/620022]    Loss: 0.011335   Batch Acc: 65.62
[Train] Epoch: 1 [324672/620022]    Loss: 0.008736   Batch Acc: 75.00
[Train] Epoch: 1 [324736/620022]    Loss: 0.007220   Batch Acc: 82.81
[Train] Epoch: 1 [324800/620022]    Loss: 0.008784   Batch Acc: 73.44
[Train] Epoch: 1 [324864/620022]    Loss: 0.007084   Batch Acc: 82.81
[Train] Epoch: 1 [324928/620022]    Loss: 0.006912   Batch Acc: 82.81
[Train] Epoch: 1 [324992/620022]    Loss: 0.008783   Batch Acc: 76.56
[Train] Epoch: 1 [325056/620022]    Loss: 0.007959   Batch Acc: 78.12
[Train] Epoch: 1 [325120/620022]    Loss: 0.009018   Batch Acc: 73.44
[Train] Epoch: 1 [325184/620022]    Loss: 0.011234   Batch Acc: 70.31
[Train] Epoch: 1 [325248/620022]    Loss: 0.009221   Batch Acc: 81.25
[Train] Epoch: 1 [325312/620022]    Loss: 0.008030   Batch Acc: 82.81
[Train] Epoch: 1 [325376/620022]    Loss: 0.008598   Batch Acc: 79.69
[Train] Epoch: 1 [325440/620022]    Loss: 0.010135   Batch Acc: 70.31
[Train] Epoch: 1 [325504/620022]    Loss: 0.011361   Batch Acc: 67.19
[Train] Epoch: 1 [325568/620022]    Loss: 0.009424   Batch Acc: 76.56
[Train] Epoch: 1 [325632/620022]    Loss: 0.006110   Batch Acc: 89.06
[Train] Epoch: 1 [325696/620022]    Loss: 0.009454   Batch Acc: 78.12
[Train] Epoch: 1 [325760/620022]    Loss: 0.006503   Batch Acc: 84.38
[Train] Epoch: 1 [325824/620022]    Loss: 0.008809   Batch Acc: 75.00
[Train] Epoch: 1 [325888/620022]    Loss: 0.008285   Batch Acc: 78.12
[Train] Epoch: 1 [325952/620022]    Loss: 0.010362   Batch Acc: 75.00
[Train] Epoch: 1 [326016/620022]    Loss: 0.008396   Batch Acc: 76.56
[Train] Epoch: 1 [326080/620022]    Loss: 0.010481   Batch Acc: 70.31
[Train] Epoch: 1 [326144/620022]    Loss: 0.008825   Batch Acc: 79.69
[Train] Epoch: 1 [326208/620022]    Loss: 0.012952   Batch Acc: 68.75
[Train] Epoch: 1 [326272/620022]    Loss: 0.008880   Batch Acc: 76.56
[Train] Epoch: 1 [326336/620022]    Loss: 0.007249   Batch Acc: 79.69
[Train] Epoch: 1 [326400/620022]    Loss: 0.009393   Batch Acc: 78.12
[Train] Epoch: 1 [326464/620022]    Loss: 0.007305   Batch Acc: 81.25
[Train] Epoch: 1 [326528/620022]    Loss: 0.009087   Batch Acc: 76.56
[Train] Epoch: 1 [326592/620022]    Loss: 0.011101   Batch Acc: 78.12
[Train] Epoch: 1 [326656/620022]    Loss: 0.007486   Batch Acc: 84.38
[Train] Epoch: 1 [326720/620022]    Loss: 0.006982   Batch Acc: 87.50
[Train] Epoch: 1 [326784/620022]    Loss: 0.008509   Batch Acc: 75.00
[Train] Epoch: 1 [326848/620022]    Loss: 0.010068   Batch Acc: 73.44
[Train] Epoch: 1 [326912/620022]    Loss: 0.010959   Batch Acc: 71.88
[Train] Epoch: 1 [326976/620022]    Loss: 0.006714   Batch Acc: 82.81
[Train] Epoch: 1 [327040/620022]    Loss: 0.009878   Batch Acc: 76.56
[Train] Epoch: 1 [327104/620022]    Loss: 0.008276   Batch Acc: 79.69
[Train] Epoch: 1 [327168/620022]    Loss: 0.007473   Batch Acc: 82.81
[Train] Epoch: 1 [327232/620022]    Loss: 0.007895   Batch Acc: 76.56
[Train] Epoch: 1 [327296/620022]    Loss: 0.007541   Batch Acc: 81.25
[Train] Epoch: 1 [327360/620022]    Loss: 0.006728   Batch Acc: 81.25
[Train] Epoch: 1 [327424/620022]    Loss: 0.008576   Batch Acc: 79.69
[Train] Epoch: 1 [327488/620022]    Loss: 0.009904   Batch Acc: 78.12
[Train] Epoch: 1 [327552/620022]    Loss: 0.008763   Batch Acc: 78.12
[Train] Epoch: 1 [327616/620022]    Loss: 0.006879   Batch Acc: 87.50
[Train] Epoch: 1 [327680/620022]    Loss: 0.010552   Batch Acc: 70.31
[Train] Epoch: 1 [327744/620022]    Loss: 0.008560   Batch Acc: 73.44
[Train] Epoch: 1 [327808/620022]    Loss: 0.009914   Batch Acc: 68.75
[Train] Epoch: 1 [327872/620022]    Loss: 0.006904   Batch Acc: 81.25
[Train] Epoch: 1 [327936/620022]    Loss: 0.009365   Batch Acc: 73.44
[Train] Epoch: 1 [328000/620022]    Loss: 0.008090   Batch Acc: 76.56
[Train] Epoch: 1 [328064/620022]    Loss: 0.008891   Batch Acc: 73.44
[Train] Epoch: 1 [328128/620022]    Loss: 0.009642   Batch Acc: 76.56
[Train] Epoch: 1 [328192/620022]    Loss: 0.009905   Batch Acc: 76.56
[Train] Epoch: 1 [328256/620022]    Loss: 0.008186   Batch Acc: 76.56
[Train] Epoch: 1 [328320/620022]    Loss: 0.009749   Batch Acc: 78.12
[Train] Epoch: 1 [328384/620022]    Loss: 0.009424   Batch Acc: 73.44
[Train] Epoch: 1 [328448/620022]    Loss: 0.010807   Batch Acc: 65.62
[Train] Epoch: 1 [328512/620022]    Loss: 0.010501   Batch Acc: 71.88
[Train] Epoch: 1 [328576/620022]    Loss: 0.009042   Batch Acc: 73.44
[Train] Epoch: 1 [328640/620022]    Loss: 0.007159   Batch Acc: 78.12
[Train] Epoch: 1 [328704/620022]    Loss: 0.008138   Batch Acc: 81.25
[Train] Epoch: 1 [328768/620022]    Loss: 0.008759   Batch Acc: 76.56
[Train] Epoch: 1 [328832/620022]    Loss: 0.009244   Batch Acc: 79.69
[Train] Epoch: 1 [328896/620022]    Loss: 0.008521   Batch Acc: 79.69
[Train] Epoch: 1 [328960/620022]    Loss: 0.011382   Batch Acc: 71.88
[Train] Epoch: 1 [329024/620022]    Loss: 0.006651   Batch Acc: 84.38
[Train] Epoch: 1 [329088/620022]    Loss: 0.006974   Batch Acc: 81.25
[Train] Epoch: 1 [329152/620022]    Loss: 0.010915   Batch Acc: 71.88
[Train] Epoch: 1 [329216/620022]    Loss: 0.010204   Batch Acc: 73.44
[Train] Epoch: 1 [329280/620022]    Loss: 0.008712   Batch Acc: 78.12
[Train] Epoch: 1 [329344/620022]    Loss: 0.008924   Batch Acc: 76.56
[Train] Epoch: 1 [329408/620022]    Loss: 0.010833   Batch Acc: 70.31
[Train] Epoch: 1 [329472/620022]    Loss: 0.009000   Batch Acc: 73.44
[Train] Epoch: 1 [329536/620022]    Loss: 0.008000   Batch Acc: 78.12
[Train] Epoch: 1 [329600/620022]    Loss: 0.008651   Batch Acc: 76.56
[Train] Epoch: 1 [329664/620022]    Loss: 0.011942   Batch Acc: 70.31
[Train] Epoch: 1 [329728/620022]    Loss: 0.008976   Batch Acc: 75.00
[Train] Epoch: 1 [329792/620022]    Loss: 0.008879   Batch Acc: 75.00
[Train] Epoch: 1 [329856/620022]    Loss: 0.009266   Batch Acc: 71.88
[Train] Epoch: 1 [329920/620022]    Loss: 0.008597   Batch Acc: 76.56
[Train] Epoch: 1 [329984/620022]    Loss: 0.011515   Batch Acc: 70.31
[Train] Epoch: 1 [330048/620022]    Loss: 0.008741   Batch Acc: 81.25
[Train] Epoch: 1 [330112/620022]    Loss: 0.009324   Batch Acc: 75.00
[Train] Epoch: 1 [330176/620022]    Loss: 0.007467   Batch Acc: 78.12
[Train] Epoch: 1 [330240/620022]    Loss: 0.010054   Batch Acc: 75.00
[Train] Epoch: 1 [330304/620022]    Loss: 0.005763   Batch Acc: 93.75
[Train] Epoch: 1 [330368/620022]    Loss: 0.010146   Batch Acc: 75.00
[Train] Epoch: 1 [330432/620022]    Loss: 0.010827   Batch Acc: 75.00
[Train] Epoch: 1 [330496/620022]    Loss: 0.009009   Batch Acc: 78.12
[Train] Epoch: 1 [330560/620022]    Loss: 0.008044   Batch Acc: 76.56
[Train] Epoch: 1 [330624/620022]    Loss: 0.009196   Batch Acc: 73.44
[Train] Epoch: 1 [330688/620022]    Loss: 0.008584   Batch Acc: 70.31
[Train] Epoch: 1 [330752/620022]    Loss: 0.009213   Batch Acc: 81.25
[Train] Epoch: 1 [330816/620022]    Loss: 0.009555   Batch Acc: 79.69
[Train] Epoch: 1 [330880/620022]    Loss: 0.008737   Batch Acc: 75.00
[Train] Epoch: 1 [330944/620022]    Loss: 0.009346   Batch Acc: 79.69
[Train] Epoch: 1 [331008/620022]    Loss: 0.011066   Batch Acc: 73.44
[Train] Epoch: 1 [331072/620022]    Loss: 0.008719   Batch Acc: 75.00
[Train] Epoch: 1 [331136/620022]    Loss: 0.007850   Batch Acc: 78.12
[Train] Epoch: 1 [331200/620022]    Loss: 0.011104   Batch Acc: 71.88
[Train] Epoch: 1 [331264/620022]    Loss: 0.006737   Batch Acc: 84.38
[Train] Epoch: 1 [331328/620022]    Loss: 0.008456   Batch Acc: 84.38
[Train] Epoch: 1 [331392/620022]    Loss: 0.008783   Batch Acc: 78.12
[Train] Epoch: 1 [331456/620022]    Loss: 0.008757   Batch Acc: 78.12
[Train] Epoch: 1 [331520/620022]    Loss: 0.009752   Batch Acc: 71.88
[Train] Epoch: 1 [331584/620022]    Loss: 0.008161   Batch Acc: 75.00
[Train] Epoch: 1 [331648/620022]    Loss: 0.008740   Batch Acc: 79.69
[Train] Epoch: 1 [331712/620022]    Loss: 0.008233   Batch Acc: 81.25
[Train] Epoch: 1 [331776/620022]    Loss: 0.007975   Batch Acc: 78.12
[Train] Epoch: 1 [331840/620022]    Loss: 0.009160   Batch Acc: 75.00
[Train] Epoch: 1 [331904/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 1 [331968/620022]    Loss: 0.008726   Batch Acc: 73.44
[Train] Epoch: 1 [332032/620022]    Loss: 0.009180   Batch Acc: 75.00
[Train] Epoch: 1 [332096/620022]    Loss: 0.008017   Batch Acc: 79.69
[Train] Epoch: 1 [332160/620022]    Loss: 0.008919   Batch Acc: 81.25
[Train] Epoch: 1 [332224/620022]    Loss: 0.007237   Batch Acc: 85.94
[Train] Epoch: 1 [332288/620022]    Loss: 0.008222   Batch Acc: 78.12
[Train] Epoch: 1 [332352/620022]    Loss: 0.007291   Batch Acc: 79.69
[Train] Epoch: 1 [332416/620022]    Loss: 0.008631   Batch Acc: 78.12
[Train] Epoch: 1 [332480/620022]    Loss: 0.006958   Batch Acc: 85.94
[Train] Epoch: 1 [332544/620022]    Loss: 0.008003   Batch Acc: 79.69
[Train] Epoch: 1 [332608/620022]    Loss: 0.007536   Batch Acc: 82.81
[Train] Epoch: 1 [332672/620022]    Loss: 0.009026   Batch Acc: 75.00
[Train] Epoch: 1 [332736/620022]    Loss: 0.009634   Batch Acc: 76.56
[Train] Epoch: 1 [332800/620022]    Loss: 0.007670   Batch Acc: 79.69
[Train] Epoch: 1 [332864/620022]    Loss: 0.009743   Batch Acc: 73.44
[Train] Epoch: 1 [332928/620022]    Loss: 0.008319   Batch Acc: 79.69
[Train] Epoch: 1 [332992/620022]    Loss: 0.009730   Batch Acc: 75.00
[Train] Epoch: 1 [333056/620022]    Loss: 0.007249   Batch Acc: 79.69
[Train] Epoch: 1 [333120/620022]    Loss: 0.008809   Batch Acc: 71.88
[Train] Epoch: 1 [333184/620022]    Loss: 0.008519   Batch Acc: 78.12
[Train] Epoch: 1 [333248/620022]    Loss: 0.007250   Batch Acc: 82.81
[Train] Epoch: 1 [333312/620022]    Loss: 0.007386   Batch Acc: 81.25
[Train] Epoch: 1 [333376/620022]    Loss: 0.008529   Batch Acc: 81.25
[Train] Epoch: 1 [333440/620022]    Loss: 0.010511   Batch Acc: 75.00
[Train] Epoch: 1 [333504/620022]    Loss: 0.008522   Batch Acc: 78.12
[Train] Epoch: 1 [333568/620022]    Loss: 0.007608   Batch Acc: 82.81
[Train] Epoch: 1 [333632/620022]    Loss: 0.006544   Batch Acc: 87.50
[Train] Epoch: 1 [333696/620022]    Loss: 0.011778   Batch Acc: 70.31
[Train] Epoch: 1 [333760/620022]    Loss: 0.009390   Batch Acc: 71.88
[Train] Epoch: 1 [333824/620022]    Loss: 0.009407   Batch Acc: 76.56
[Train] Epoch: 1 [333888/620022]    Loss: 0.009990   Batch Acc: 76.56
[Train] Epoch: 1 [333952/620022]    Loss: 0.008758   Batch Acc: 79.69
[Train] Epoch: 1 [334016/620022]    Loss: 0.010600   Batch Acc: 71.88
[Train] Epoch: 1 [334080/620022]    Loss: 0.009642   Batch Acc: 75.00
[Train] Epoch: 1 [334144/620022]    Loss: 0.008628   Batch Acc: 76.56
[Train] Epoch: 1 [334208/620022]    Loss: 0.008355   Batch Acc: 76.56
[Train] Epoch: 1 [334272/620022]    Loss: 0.010579   Batch Acc: 75.00
[Train] Epoch: 1 [334336/620022]    Loss: 0.008477   Batch Acc: 81.25
[Train] Epoch: 1 [334400/620022]    Loss: 0.011876   Batch Acc: 70.31
[Train] Epoch: 1 [334464/620022]    Loss: 0.009545   Batch Acc: 75.00
[Train] Epoch: 1 [334528/620022]    Loss: 0.007048   Batch Acc: 87.50
[Train] Epoch: 1 [334592/620022]    Loss: 0.007800   Batch Acc: 79.69
[Train] Epoch: 1 [334656/620022]    Loss: 0.009119   Batch Acc: 71.88
[Train] Epoch: 1 [334720/620022]    Loss: 0.009296   Batch Acc: 76.56
[Train] Epoch: 1 [334784/620022]    Loss: 0.007991   Batch Acc: 79.69
[Train] Epoch: 1 [334848/620022]    Loss: 0.010027   Batch Acc: 73.44
[Train] Epoch: 1 [334912/620022]    Loss: 0.008640   Batch Acc: 78.12
[Train] Epoch: 1 [334976/620022]    Loss: 0.008183   Batch Acc: 79.69
[Train] Epoch: 1 [335040/620022]    Loss: 0.008944   Batch Acc: 81.25
[Train] Epoch: 1 [335104/620022]    Loss: 0.007225   Batch Acc: 85.94
[Train] Epoch: 1 [335168/620022]    Loss: 0.009680   Batch Acc: 71.88
[Train] Epoch: 1 [335232/620022]    Loss: 0.007836   Batch Acc: 79.69
[Train] Epoch: 1 [335296/620022]    Loss: 0.012249   Batch Acc: 75.00
[Train] Epoch: 1 [335360/620022]    Loss: 0.008829   Batch Acc: 76.56
[Train] Epoch: 1 [335424/620022]    Loss: 0.008821   Batch Acc: 79.69
[Train] Epoch: 1 [335488/620022]    Loss: 0.009046   Batch Acc: 76.56
[Train] Epoch: 1 [335552/620022]    Loss: 0.007557   Batch Acc: 82.81
[Train] Epoch: 1 [335616/620022]    Loss: 0.009533   Batch Acc: 73.44
[Train] Epoch: 1 [335680/620022]    Loss: 0.007595   Batch Acc: 82.81
[Train] Epoch: 1 [335744/620022]    Loss: 0.008246   Batch Acc: 78.12
[Train] Epoch: 1 [335808/620022]    Loss: 0.007065   Batch Acc: 85.94
[Train] Epoch: 1 [335872/620022]    Loss: 0.008424   Batch Acc: 81.25
[Train] Epoch: 1 [335936/620022]    Loss: 0.008329   Batch Acc: 81.25
[Train] Epoch: 1 [336000/620022]    Loss: 0.006271   Batch Acc: 78.12
[Train] Epoch: 1 [336064/620022]    Loss: 0.008388   Batch Acc: 78.12
[Train] Epoch: 1 [336128/620022]    Loss: 0.009117   Batch Acc: 73.44
[Train] Epoch: 1 [336192/620022]    Loss: 0.009979   Batch Acc: 73.44
[Train] Epoch: 1 [336256/620022]    Loss: 0.006667   Batch Acc: 85.94
[Train] Epoch: 1 [336320/620022]    Loss: 0.010401   Batch Acc: 68.75
[Train] Epoch: 1 [336384/620022]    Loss: 0.009121   Batch Acc: 65.62
[Train] Epoch: 1 [336448/620022]    Loss: 0.010270   Batch Acc: 78.12
[Train] Epoch: 1 [336512/620022]    Loss: 0.009916   Batch Acc: 76.56
[Train] Epoch: 1 [336576/620022]    Loss: 0.009259   Batch Acc: 73.44
[Train] Epoch: 1 [336640/620022]    Loss: 0.008306   Batch Acc: 81.25
[Train] Epoch: 1 [336704/620022]    Loss: 0.009363   Batch Acc: 65.62
[Train] Epoch: 1 [336768/620022]    Loss: 0.010410   Batch Acc: 65.62
[Train] Epoch: 1 [336832/620022]    Loss: 0.011446   Batch Acc: 68.75
[Train] Epoch: 1 [336896/620022]    Loss: 0.008884   Batch Acc: 73.44
[Train] Epoch: 1 [336960/620022]    Loss: 0.009427   Batch Acc: 78.12
[Train] Epoch: 1 [337024/620022]    Loss: 0.008808   Batch Acc: 75.00
[Train] Epoch: 1 [337088/620022]    Loss: 0.009536   Batch Acc: 78.12
[Train] Epoch: 1 [337152/620022]    Loss: 0.006191   Batch Acc: 85.94
[Train] Epoch: 1 [337216/620022]    Loss: 0.010574   Batch Acc: 75.00
[Train] Epoch: 1 [337280/620022]    Loss: 0.008426   Batch Acc: 82.81
[Train] Epoch: 1 [337344/620022]    Loss: 0.008117   Batch Acc: 81.25
[Train] Epoch: 1 [337408/620022]    Loss: 0.009120   Batch Acc: 76.56
[Train] Epoch: 1 [337472/620022]    Loss: 0.010268   Batch Acc: 73.44
[Train] Epoch: 1 [337536/620022]    Loss: 0.008311   Batch Acc: 78.12
[Train] Epoch: 1 [337600/620022]    Loss: 0.010244   Batch Acc: 70.31
[Train] Epoch: 1 [337664/620022]    Loss: 0.007962   Batch Acc: 76.56
[Train] Epoch: 1 [337728/620022]    Loss: 0.010878   Batch Acc: 67.19
[Train] Epoch: 1 [337792/620022]    Loss: 0.006250   Batch Acc: 85.94
[Train] Epoch: 1 [337856/620022]    Loss: 0.008329   Batch Acc: 76.56
[Train] Epoch: 1 [337920/620022]    Loss: 0.008269   Batch Acc: 70.31
[Train] Epoch: 1 [337984/620022]    Loss: 0.008862   Batch Acc: 78.12
[Train] Epoch: 1 [338048/620022]    Loss: 0.007243   Batch Acc: 79.69
[Train] Epoch: 1 [338112/620022]    Loss: 0.006711   Batch Acc: 82.81
[Train] Epoch: 1 [338176/620022]    Loss: 0.007152   Batch Acc: 81.25
[Train] Epoch: 1 [338240/620022]    Loss: 0.007347   Batch Acc: 87.50
[Train] Epoch: 1 [338304/620022]    Loss: 0.009571   Batch Acc: 70.31
[Train] Epoch: 1 [338368/620022]    Loss: 0.007134   Batch Acc: 81.25
[Train] Epoch: 1 [338432/620022]    Loss: 0.007315   Batch Acc: 82.81
[Train] Epoch: 1 [338496/620022]    Loss: 0.008116   Batch Acc: 78.12
[Train] Epoch: 1 [338560/620022]    Loss: 0.008867   Batch Acc: 75.00
[Train] Epoch: 1 [338624/620022]    Loss: 0.008020   Batch Acc: 85.94
[Train] Epoch: 1 [338688/620022]    Loss: 0.009991   Batch Acc: 75.00
[Train] Epoch: 1 [338752/620022]    Loss: 0.009021   Batch Acc: 76.56
[Train] Epoch: 1 [338816/620022]    Loss: 0.008626   Batch Acc: 73.44
[Train] Epoch: 1 [338880/620022]    Loss: 0.008350   Batch Acc: 81.25
[Train] Epoch: 1 [338944/620022]    Loss: 0.007500   Batch Acc: 84.38
[Train] Epoch: 1 [339008/620022]    Loss: 0.006417   Batch Acc: 87.50
[Train] Epoch: 1 [339072/620022]    Loss: 0.007937   Batch Acc: 84.38
[Train] Epoch: 1 [339136/620022]    Loss: 0.007769   Batch Acc: 87.50
[Train] Epoch: 1 [339200/620022]    Loss: 0.006600   Batch Acc: 85.94
[Train] Epoch: 1 [339264/620022]    Loss: 0.011954   Batch Acc: 67.19
[Train] Epoch: 1 [339328/620022]    Loss: 0.007344   Batch Acc: 84.38
[Train] Epoch: 1 [339392/620022]    Loss: 0.009192   Batch Acc: 73.44
[Train] Epoch: 1 [339456/620022]    Loss: 0.008145   Batch Acc: 81.25
[Train] Epoch: 1 [339520/620022]    Loss: 0.009299   Batch Acc: 73.44
[Train] Epoch: 1 [339584/620022]    Loss: 0.007240   Batch Acc: 84.38
[Train] Epoch: 1 [339648/620022]    Loss: 0.007997   Batch Acc: 79.69
[Train] Epoch: 1 [339712/620022]    Loss: 0.010742   Batch Acc: 67.19
[Train] Epoch: 1 [339776/620022]    Loss: 0.009194   Batch Acc: 76.56
[Train] Epoch: 1 [339840/620022]    Loss: 0.009105   Batch Acc: 75.00
[Train] Epoch: 1 [339904/620022]    Loss: 0.009490   Batch Acc: 73.44
[Train] Epoch: 1 [339968/620022]    Loss: 0.009173   Batch Acc: 73.44
[Train] Epoch: 1 [340032/620022]    Loss: 0.009373   Batch Acc: 78.12
[Train] Epoch: 1 [340096/620022]    Loss: 0.009558   Batch Acc: 79.69
[Train] Epoch: 1 [340160/620022]    Loss: 0.007194   Batch Acc: 78.12
[Train] Epoch: 1 [340224/620022]    Loss: 0.010347   Batch Acc: 73.44
[Train] Epoch: 1 [340288/620022]    Loss: 0.006823   Batch Acc: 89.06
[Train] Epoch: 1 [340352/620022]    Loss: 0.008732   Batch Acc: 82.81
[Train] Epoch: 1 [340416/620022]    Loss: 0.005795   Batch Acc: 87.50
[Train] Epoch: 1 [340480/620022]    Loss: 0.010260   Batch Acc: 71.88
[Train] Epoch: 1 [340544/620022]    Loss: 0.009886   Batch Acc: 71.88
[Train] Epoch: 1 [340608/620022]    Loss: 0.009572   Batch Acc: 76.56
[Train] Epoch: 1 [340672/620022]    Loss: 0.007628   Batch Acc: 79.69
[Train] Epoch: 1 [340736/620022]    Loss: 0.007989   Batch Acc: 81.25
[Train] Epoch: 1 [340800/620022]    Loss: 0.010472   Batch Acc: 75.00
[Train] Epoch: 1 [340864/620022]    Loss: 0.008509   Batch Acc: 84.38
[Train] Epoch: 1 [340928/620022]    Loss: 0.008560   Batch Acc: 75.00
[Train] Epoch: 1 [340992/620022]    Loss: 0.007976   Batch Acc: 79.69
[Train] Epoch: 1 [341056/620022]    Loss: 0.008303   Batch Acc: 84.38
[Train] Epoch: 1 [341120/620022]    Loss: 0.008616   Batch Acc: 75.00
[Train] Epoch: 1 [341184/620022]    Loss: 0.008135   Batch Acc: 79.69
[Train] Epoch: 1 [341248/620022]    Loss: 0.008854   Batch Acc: 73.44
[Train] Epoch: 1 [341312/620022]    Loss: 0.008210   Batch Acc: 78.12
[Train] Epoch: 1 [341376/620022]    Loss: 0.007535   Batch Acc: 82.81
[Train] Epoch: 1 [341440/620022]    Loss: 0.008637   Batch Acc: 76.56
[Train] Epoch: 1 [341504/620022]    Loss: 0.007422   Batch Acc: 82.81
[Train] Epoch: 1 [341568/620022]    Loss: 0.010456   Batch Acc: 75.00
[Train] Epoch: 1 [341632/620022]    Loss: 0.007533   Batch Acc: 79.69
[Train] Epoch: 1 [341696/620022]    Loss: 0.007968   Batch Acc: 78.12
[Train] Epoch: 1 [341760/620022]    Loss: 0.008015   Batch Acc: 78.12
[Train] Epoch: 1 [341824/620022]    Loss: 0.008377   Batch Acc: 78.12
[Train] Epoch: 1 [341888/620022]    Loss: 0.007879   Batch Acc: 81.25
[Train] Epoch: 1 [341952/620022]    Loss: 0.010264   Batch Acc: 81.25
[Train] Epoch: 1 [342016/620022]    Loss: 0.008968   Batch Acc: 75.00
[Train] Epoch: 1 [342080/620022]    Loss: 0.009623   Batch Acc: 75.00
[Train] Epoch: 1 [342144/620022]    Loss: 0.007042   Batch Acc: 81.25
[Train] Epoch: 1 [342208/620022]    Loss: 0.011287   Batch Acc: 71.88
[Train] Epoch: 1 [342272/620022]    Loss: 0.007802   Batch Acc: 81.25
[Train] Epoch: 1 [342336/620022]    Loss: 0.006588   Batch Acc: 82.81
[Train] Epoch: 1 [342400/620022]    Loss: 0.008913   Batch Acc: 75.00
[Train] Epoch: 1 [342464/620022]    Loss: 0.009107   Batch Acc: 70.31
[Train] Epoch: 1 [342528/620022]    Loss: 0.008341   Batch Acc: 79.69
[Train] Epoch: 1 [342592/620022]    Loss: 0.009477   Batch Acc: 73.44
[Train] Epoch: 1 [342656/620022]    Loss: 0.010562   Batch Acc: 68.75
[Train] Epoch: 1 [342720/620022]    Loss: 0.006608   Batch Acc: 89.06
[Train] Epoch: 1 [342784/620022]    Loss: 0.009476   Batch Acc: 70.31
[Train] Epoch: 1 [342848/620022]    Loss: 0.010049   Batch Acc: 71.88
[Train] Epoch: 1 [342912/620022]    Loss: 0.010800   Batch Acc: 70.31
[Train] Epoch: 1 [342976/620022]    Loss: 0.007943   Batch Acc: 78.12
[Train] Epoch: 1 [343040/620022]    Loss: 0.007814   Batch Acc: 81.25
[Train] Epoch: 1 [343104/620022]    Loss: 0.008079   Batch Acc: 78.12
[Train] Epoch: 1 [343168/620022]    Loss: 0.008729   Batch Acc: 75.00
[Train] Epoch: 1 [343232/620022]    Loss: 0.008293   Batch Acc: 71.88
[Train] Epoch: 1 [343296/620022]    Loss: 0.010261   Batch Acc: 70.31
[Train] Epoch: 1 [343360/620022]    Loss: 0.007641   Batch Acc: 84.38
[Train] Epoch: 1 [343424/620022]    Loss: 0.010799   Batch Acc: 68.75
[Train] Epoch: 1 [343488/620022]    Loss: 0.008421   Batch Acc: 76.56
[Train] Epoch: 1 [343552/620022]    Loss: 0.010348   Batch Acc: 71.88
[Train] Epoch: 1 [343616/620022]    Loss: 0.010134   Batch Acc: 73.44
[Train] Epoch: 1 [343680/620022]    Loss: 0.008700   Batch Acc: 73.44
[Train] Epoch: 1 [343744/620022]    Loss: 0.007489   Batch Acc: 84.38
[Train] Epoch: 1 [343808/620022]    Loss: 0.009535   Batch Acc: 75.00
[Train] Epoch: 1 [343872/620022]    Loss: 0.006974   Batch Acc: 84.38
[Train] Epoch: 1 [343936/620022]    Loss: 0.006789   Batch Acc: 87.50
[Train] Epoch: 1 [344000/620022]    Loss: 0.008692   Batch Acc: 84.38
[Train] Epoch: 1 [344064/620022]    Loss: 0.008903   Batch Acc: 71.88
[Train] Epoch: 1 [344128/620022]    Loss: 0.008124   Batch Acc: 78.12
[Train] Epoch: 1 [344192/620022]    Loss: 0.009403   Batch Acc: 79.69
[Train] Epoch: 1 [344256/620022]    Loss: 0.008001   Batch Acc: 76.56
[Train] Epoch: 1 [344320/620022]    Loss: 0.010107   Batch Acc: 70.31
[Train] Epoch: 1 [344384/620022]    Loss: 0.009556   Batch Acc: 70.31
[Train] Epoch: 1 [344448/620022]    Loss: 0.007420   Batch Acc: 79.69
[Train] Epoch: 1 [344512/620022]    Loss: 0.011388   Batch Acc: 67.19
[Train] Epoch: 1 [344576/620022]    Loss: 0.008594   Batch Acc: 78.12
[Train] Epoch: 1 [344640/620022]    Loss: 0.007002   Batch Acc: 82.81
[Train] Epoch: 1 [344704/620022]    Loss: 0.007546   Batch Acc: 82.81
[Train] Epoch: 1 [344768/620022]    Loss: 0.011005   Batch Acc: 70.31
[Train] Epoch: 1 [344832/620022]    Loss: 0.007486   Batch Acc: 82.81
[Train] Epoch: 1 [344896/620022]    Loss: 0.010677   Batch Acc: 73.44
[Train] Epoch: 1 [344960/620022]    Loss: 0.008190   Batch Acc: 78.12
[Train] Epoch: 1 [345024/620022]    Loss: 0.009421   Batch Acc: 79.69
[Train] Epoch: 1 [345088/620022]    Loss: 0.009434   Batch Acc: 79.69
[Train] Epoch: 1 [345152/620022]    Loss: 0.007018   Batch Acc: 81.25
[Train] Epoch: 1 [345216/620022]    Loss: 0.008315   Batch Acc: 75.00
[Train] Epoch: 1 [345280/620022]    Loss: 0.008281   Batch Acc: 71.88
[Train] Epoch: 1 [345344/620022]    Loss: 0.009544   Batch Acc: 78.12
[Train] Epoch: 1 [345408/620022]    Loss: 0.009609   Batch Acc: 79.69
[Train] Epoch: 1 [345472/620022]    Loss: 0.010704   Batch Acc: 70.31
[Train] Epoch: 1 [345536/620022]    Loss: 0.010814   Batch Acc: 68.75
[Train] Epoch: 1 [345600/620022]    Loss: 0.010213   Batch Acc: 68.75
[Train] Epoch: 1 [345664/620022]    Loss: 0.006525   Batch Acc: 79.69
[Train] Epoch: 1 [345728/620022]    Loss: 0.010821   Batch Acc: 67.19
[Train] Epoch: 1 [345792/620022]    Loss: 0.011191   Batch Acc: 64.06
[Train] Epoch: 1 [345856/620022]    Loss: 0.009552   Batch Acc: 79.69
[Train] Epoch: 1 [345920/620022]    Loss: 0.007970   Batch Acc: 78.12
[Train] Epoch: 1 [345984/620022]    Loss: 0.009443   Batch Acc: 76.56
[Train] Epoch: 1 [346048/620022]    Loss: 0.009024   Batch Acc: 76.56
[Train] Epoch: 1 [346112/620022]    Loss: 0.007857   Batch Acc: 78.12
[Train] Epoch: 1 [346176/620022]    Loss: 0.007034   Batch Acc: 81.25
[Train] Epoch: 1 [346240/620022]    Loss: 0.007599   Batch Acc: 78.12
[Train] Epoch: 1 [346304/620022]    Loss: 0.009113   Batch Acc: 76.56
[Train] Epoch: 1 [346368/620022]    Loss: 0.008446   Batch Acc: 76.56
[Train] Epoch: 1 [346432/620022]    Loss: 0.007802   Batch Acc: 78.12
[Train] Epoch: 1 [346496/620022]    Loss: 0.007404   Batch Acc: 81.25
[Train] Epoch: 1 [346560/620022]    Loss: 0.009091   Batch Acc: 79.69
[Train] Epoch: 1 [346624/620022]    Loss: 0.007429   Batch Acc: 82.81
[Train] Epoch: 1 [346688/620022]    Loss: 0.007952   Batch Acc: 81.25
[Train] Epoch: 1 [346752/620022]    Loss: 0.009085   Batch Acc: 76.56
[Train] Epoch: 1 [346816/620022]    Loss: 0.005632   Batch Acc: 92.19
[Train] Epoch: 1 [346880/620022]    Loss: 0.008729   Batch Acc: 78.12
[Train] Epoch: 1 [346944/620022]    Loss: 0.010251   Batch Acc: 70.31
[Train] Epoch: 1 [347008/620022]    Loss: 0.008802   Batch Acc: 78.12
[Train] Epoch: 1 [347072/620022]    Loss: 0.008584   Batch Acc: 78.12
[Train] Epoch: 1 [347136/620022]    Loss: 0.009426   Batch Acc: 81.25
[Train] Epoch: 1 [347200/620022]    Loss: 0.008337   Batch Acc: 78.12
[Train] Epoch: 1 [347264/620022]    Loss: 0.010506   Batch Acc: 73.44
[Train] Epoch: 1 [347328/620022]    Loss: 0.009013   Batch Acc: 75.00
[Train] Epoch: 1 [347392/620022]    Loss: 0.011652   Batch Acc: 73.44
[Train] Epoch: 1 [347456/620022]    Loss: 0.010925   Batch Acc: 71.88
[Train] Epoch: 1 [347520/620022]    Loss: 0.009587   Batch Acc: 75.00
[Train] Epoch: 1 [347584/620022]    Loss: 0.008664   Batch Acc: 73.44
[Train] Epoch: 1 [347648/620022]    Loss: 0.007110   Batch Acc: 82.81
[Train] Epoch: 1 [347712/620022]    Loss: 0.008717   Batch Acc: 84.38
[Train] Epoch: 1 [347776/620022]    Loss: 0.011087   Batch Acc: 68.75
[Train] Epoch: 1 [347840/620022]    Loss: 0.011289   Batch Acc: 68.75
[Train] Epoch: 1 [347904/620022]    Loss: 0.008288   Batch Acc: 81.25
[Train] Epoch: 1 [347968/620022]    Loss: 0.010054   Batch Acc: 70.31
[Train] Epoch: 1 [348032/620022]    Loss: 0.009246   Batch Acc: 73.44
[Train] Epoch: 1 [348096/620022]    Loss: 0.008298   Batch Acc: 85.94
[Train] Epoch: 1 [348160/620022]    Loss: 0.011151   Batch Acc: 70.31
[Train] Epoch: 1 [348224/620022]    Loss: 0.008141   Batch Acc: 79.69
[Train] Epoch: 1 [348288/620022]    Loss: 0.010597   Batch Acc: 75.00
[Train] Epoch: 1 [348352/620022]    Loss: 0.007537   Batch Acc: 79.69
[Train] Epoch: 1 [348416/620022]    Loss: 0.010281   Batch Acc: 73.44
[Train] Epoch: 1 [348480/620022]    Loss: 0.006281   Batch Acc: 85.94
[Train] Epoch: 1 [348544/620022]    Loss: 0.006890   Batch Acc: 84.38
[Train] Epoch: 1 [348608/620022]    Loss: 0.007690   Batch Acc: 81.25
[Train] Epoch: 1 [348672/620022]    Loss: 0.008631   Batch Acc: 79.69
[Train] Epoch: 1 [348736/620022]    Loss: 0.008658   Batch Acc: 79.69
[Train] Epoch: 1 [348800/620022]    Loss: 0.007822   Batch Acc: 84.38
[Train] Epoch: 1 [348864/620022]    Loss: 0.008312   Batch Acc: 76.56
[Train] Epoch: 1 [348928/620022]    Loss: 0.008587   Batch Acc: 73.44
[Train] Epoch: 1 [348992/620022]    Loss: 0.009458   Batch Acc: 81.25
[Train] Epoch: 1 [349056/620022]    Loss: 0.008799   Batch Acc: 78.12
[Train] Epoch: 1 [349120/620022]    Loss: 0.009717   Batch Acc: 73.44
[Train] Epoch: 1 [349184/620022]    Loss: 0.006797   Batch Acc: 82.81
[Train] Epoch: 1 [349248/620022]    Loss: 0.010148   Batch Acc: 71.88
[Train] Epoch: 1 [349312/620022]    Loss: 0.008510   Batch Acc: 82.81
[Train] Epoch: 1 [349376/620022]    Loss: 0.010064   Batch Acc: 73.44
[Train] Epoch: 1 [349440/620022]    Loss: 0.008428   Batch Acc: 76.56
[Train] Epoch: 1 [349504/620022]    Loss: 0.008820   Batch Acc: 76.56
[Train] Epoch: 1 [349568/620022]    Loss: 0.008326   Batch Acc: 75.00
[Train] Epoch: 1 [349632/620022]    Loss: 0.007928   Batch Acc: 79.69
[Train] Epoch: 1 [349696/620022]    Loss: 0.008985   Batch Acc: 78.12
[Train] Epoch: 1 [349760/620022]    Loss: 0.007849   Batch Acc: 75.00
[Train] Epoch: 1 [349824/620022]    Loss: 0.008444   Batch Acc: 82.81
[Train] Epoch: 1 [349888/620022]    Loss: 0.009839   Batch Acc: 78.12
[Train] Epoch: 1 [349952/620022]    Loss: 0.010134   Batch Acc: 70.31
[Train] Epoch: 1 [350016/620022]    Loss: 0.006925   Batch Acc: 84.38
[Train] Epoch: 1 [350080/620022]    Loss: 0.008865   Batch Acc: 71.88
[Train] Epoch: 1 [350144/620022]    Loss: 0.008736   Batch Acc: 79.69
[Train] Epoch: 1 [350208/620022]    Loss: 0.010915   Batch Acc: 75.00
[Train] Epoch: 1 [350272/620022]    Loss: 0.007913   Batch Acc: 76.56
[Train] Epoch: 1 [350336/620022]    Loss: 0.007686   Batch Acc: 82.81
[Train] Epoch: 1 [350400/620022]    Loss: 0.009627   Batch Acc: 75.00
[Train] Epoch: 1 [350464/620022]    Loss: 0.007737   Batch Acc: 82.81
[Train] Epoch: 1 [350528/620022]    Loss: 0.009410   Batch Acc: 78.12
[Train] Epoch: 1 [350592/620022]    Loss: 0.009385   Batch Acc: 75.00
[Train] Epoch: 1 [350656/620022]    Loss: 0.009409   Batch Acc: 76.56
[Train] Epoch: 1 [350720/620022]    Loss: 0.007621   Batch Acc: 79.69
[Train] Epoch: 1 [350784/620022]    Loss: 0.007651   Batch Acc: 78.12
[Train] Epoch: 1 [350848/620022]    Loss: 0.008899   Batch Acc: 75.00
[Train] Epoch: 1 [350912/620022]    Loss: 0.008870   Batch Acc: 78.12
[Train] Epoch: 1 [350976/620022]    Loss: 0.007831   Batch Acc: 79.69
[Train] Epoch: 1 [351040/620022]    Loss: 0.006433   Batch Acc: 84.38
[Train] Epoch: 1 [351104/620022]    Loss: 0.009852   Batch Acc: 67.19
[Train] Epoch: 1 [351168/620022]    Loss: 0.009158   Batch Acc: 76.56
[Train] Epoch: 1 [351232/620022]    Loss: 0.007591   Batch Acc: 81.25
[Train] Epoch: 1 [351296/620022]    Loss: 0.013133   Batch Acc: 67.19
[Train] Epoch: 1 [351360/620022]    Loss: 0.009347   Batch Acc: 73.44
[Train] Epoch: 1 [351424/620022]    Loss: 0.007942   Batch Acc: 78.12
[Train] Epoch: 1 [351488/620022]    Loss: 0.007970   Batch Acc: 81.25
[Train] Epoch: 1 [351552/620022]    Loss: 0.006793   Batch Acc: 78.12
[Train] Epoch: 1 [351616/620022]    Loss: 0.006767   Batch Acc: 85.94
[Train] Epoch: 1 [351680/620022]    Loss: 0.008521   Batch Acc: 75.00
[Train] Epoch: 1 [351744/620022]    Loss: 0.007575   Batch Acc: 85.94
[Train] Epoch: 1 [351808/620022]    Loss: 0.009855   Batch Acc: 73.44
[Train] Epoch: 1 [351872/620022]    Loss: 0.009575   Batch Acc: 78.12
[Train] Epoch: 1 [351936/620022]    Loss: 0.009664   Batch Acc: 71.88
[Train] Epoch: 1 [352000/620022]    Loss: 0.009194   Batch Acc: 76.56
[Train] Epoch: 1 [352064/620022]    Loss: 0.009320   Batch Acc: 75.00
[Train] Epoch: 1 [352128/620022]    Loss: 0.008463   Batch Acc: 78.12
[Train] Epoch: 1 [352192/620022]    Loss: 0.008822   Batch Acc: 79.69
[Train] Epoch: 1 [352256/620022]    Loss: 0.008556   Batch Acc: 76.56
[Train] Epoch: 1 [352320/620022]    Loss: 0.010298   Batch Acc: 71.88
[Train] Epoch: 1 [352384/620022]    Loss: 0.008018   Batch Acc: 78.12
[Train] Epoch: 1 [352448/620022]    Loss: 0.009130   Batch Acc: 75.00
[Train] Epoch: 1 [352512/620022]    Loss: 0.008421   Batch Acc: 73.44
[Train] Epoch: 1 [352576/620022]    Loss: 0.008092   Batch Acc: 79.69
[Train] Epoch: 1 [352640/620022]    Loss: 0.008964   Batch Acc: 76.56
[Train] Epoch: 1 [352704/620022]    Loss: 0.010456   Batch Acc: 73.44
[Train] Epoch: 1 [352768/620022]    Loss: 0.007803   Batch Acc: 82.81
[Train] Epoch: 1 [352832/620022]    Loss: 0.006549   Batch Acc: 84.38
[Train] Epoch: 1 [352896/620022]    Loss: 0.008294   Batch Acc: 79.69
[Train] Epoch: 1 [352960/620022]    Loss: 0.008808   Batch Acc: 78.12
[Train] Epoch: 1 [353024/620022]    Loss: 0.009024   Batch Acc: 78.12
[Train] Epoch: 1 [353088/620022]    Loss: 0.007356   Batch Acc: 82.81
[Train] Epoch: 1 [353152/620022]    Loss: 0.009403   Batch Acc: 76.56
[Train] Epoch: 1 [353216/620022]    Loss: 0.009232   Batch Acc: 76.56
[Train] Epoch: 1 [353280/620022]    Loss: 0.007627   Batch Acc: 81.25
[Train] Epoch: 1 [353344/620022]    Loss: 0.008936   Batch Acc: 81.25
[Train] Epoch: 1 [353408/620022]    Loss: 0.008934   Batch Acc: 79.69
[Train] Epoch: 1 [353472/620022]    Loss: 0.009258   Batch Acc: 73.44
[Train] Epoch: 1 [353536/620022]    Loss: 0.008549   Batch Acc: 75.00
[Train] Epoch: 1 [353600/620022]    Loss: 0.006497   Batch Acc: 82.81
[Train] Epoch: 1 [353664/620022]    Loss: 0.008493   Batch Acc: 75.00
[Train] Epoch: 1 [353728/620022]    Loss: 0.008895   Batch Acc: 82.81
[Train] Epoch: 1 [353792/620022]    Loss: 0.008587   Batch Acc: 75.00
[Train] Epoch: 1 [353856/620022]    Loss: 0.009979   Batch Acc: 73.44
[Train] Epoch: 1 [353920/620022]    Loss: 0.008894   Batch Acc: 76.56
[Train] Epoch: 1 [353984/620022]    Loss: 0.007223   Batch Acc: 81.25
[Train] Epoch: 1 [354048/620022]    Loss: 0.010640   Batch Acc: 68.75
[Train] Epoch: 1 [354112/620022]    Loss: 0.007498   Batch Acc: 82.81
[Train] Epoch: 1 [354176/620022]    Loss: 0.007895   Batch Acc: 79.69
[Train] Epoch: 1 [354240/620022]    Loss: 0.010361   Batch Acc: 71.88
[Train] Epoch: 1 [354304/620022]    Loss: 0.012130   Batch Acc: 60.94
[Train] Epoch: 1 [354368/620022]    Loss: 0.008445   Batch Acc: 82.81
[Train] Epoch: 1 [354432/620022]    Loss: 0.007714   Batch Acc: 78.12
[Train] Epoch: 1 [354496/620022]    Loss: 0.008646   Batch Acc: 79.69
[Train] Epoch: 1 [354560/620022]    Loss: 0.008611   Batch Acc: 81.25
[Train] Epoch: 1 [354624/620022]    Loss: 0.008030   Batch Acc: 81.25
[Train] Epoch: 1 [354688/620022]    Loss: 0.009500   Batch Acc: 70.31
[Train] Epoch: 1 [354752/620022]    Loss: 0.008680   Batch Acc: 82.81
[Train] Epoch: 1 [354816/620022]    Loss: 0.011349   Batch Acc: 78.12
[Train] Epoch: 1 [354880/620022]    Loss: 0.007406   Batch Acc: 84.38
[Train] Epoch: 1 [354944/620022]    Loss: 0.007772   Batch Acc: 81.25
[Train] Epoch: 1 [355008/620022]    Loss: 0.008129   Batch Acc: 85.94
[Train] Epoch: 1 [355072/620022]    Loss: 0.009430   Batch Acc: 79.69
[Train] Epoch: 1 [355136/620022]    Loss: 0.009485   Batch Acc: 82.81
[Train] Epoch: 1 [355200/620022]    Loss: 0.009124   Batch Acc: 75.00
[Train] Epoch: 1 [355264/620022]    Loss: 0.006320   Batch Acc: 89.06
[Train] Epoch: 1 [355328/620022]    Loss: 0.007899   Batch Acc: 75.00
[Train] Epoch: 1 [355392/620022]    Loss: 0.009169   Batch Acc: 76.56
[Train] Epoch: 1 [355456/620022]    Loss: 0.008687   Batch Acc: 84.38
[Train] Epoch: 1 [355520/620022]    Loss: 0.007893   Batch Acc: 79.69
[Train] Epoch: 1 [355584/620022]    Loss: 0.008301   Batch Acc: 81.25
[Train] Epoch: 1 [355648/620022]    Loss: 0.005480   Batch Acc: 89.06
[Train] Epoch: 1 [355712/620022]    Loss: 0.008302   Batch Acc: 78.12
[Train] Epoch: 1 [355776/620022]    Loss: 0.009146   Batch Acc: 78.12
[Train] Epoch: 1 [355840/620022]    Loss: 0.009135   Batch Acc: 76.56
[Train] Epoch: 1 [355904/620022]    Loss: 0.007116   Batch Acc: 87.50
[Train] Epoch: 1 [355968/620022]    Loss: 0.008662   Batch Acc: 82.81
[Train] Epoch: 1 [356032/620022]    Loss: 0.010683   Batch Acc: 68.75
[Train] Epoch: 1 [356096/620022]    Loss: 0.009650   Batch Acc: 79.69
[Train] Epoch: 1 [356160/620022]    Loss: 0.010023   Batch Acc: 73.44
[Train] Epoch: 1 [356224/620022]    Loss: 0.008622   Batch Acc: 79.69
[Train] Epoch: 1 [356288/620022]    Loss: 0.007775   Batch Acc: 76.56
[Train] Epoch: 1 [356352/620022]    Loss: 0.007775   Batch Acc: 79.69
[Train] Epoch: 1 [356416/620022]    Loss: 0.008185   Batch Acc: 78.12
[Train] Epoch: 1 [356480/620022]    Loss: 0.008550   Batch Acc: 71.88
[Train] Epoch: 1 [356544/620022]    Loss: 0.007206   Batch Acc: 82.81
[Train] Epoch: 1 [356608/620022]    Loss: 0.011389   Batch Acc: 71.88
[Train] Epoch: 1 [356672/620022]    Loss: 0.006360   Batch Acc: 85.94
[Train] Epoch: 1 [356736/620022]    Loss: 0.008197   Batch Acc: 76.56
[Train] Epoch: 1 [356800/620022]    Loss: 0.007799   Batch Acc: 82.81
[Train] Epoch: 1 [356864/620022]    Loss: 0.009556   Batch Acc: 73.44
[Train] Epoch: 1 [356928/620022]    Loss: 0.007945   Batch Acc: 84.38
[Train] Epoch: 1 [356992/620022]    Loss: 0.007957   Batch Acc: 81.25
[Train] Epoch: 1 [357056/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 1 [357120/620022]    Loss: 0.007445   Batch Acc: 82.81
[Train] Epoch: 1 [357184/620022]    Loss: 0.009675   Batch Acc: 71.88
[Train] Epoch: 1 [357248/620022]    Loss: 0.009212   Batch Acc: 73.44
[Train] Epoch: 1 [357312/620022]    Loss: 0.008644   Batch Acc: 71.88
[Train] Epoch: 1 [357376/620022]    Loss: 0.010094   Batch Acc: 71.88
[Train] Epoch: 1 [357440/620022]    Loss: 0.006740   Batch Acc: 84.38
[Train] Epoch: 1 [357504/620022]    Loss: 0.007848   Batch Acc: 79.69
[Train] Epoch: 1 [357568/620022]    Loss: 0.008018   Batch Acc: 81.25
[Train] Epoch: 1 [357632/620022]    Loss: 0.010563   Batch Acc: 71.88
[Train] Epoch: 1 [357696/620022]    Loss: 0.007293   Batch Acc: 82.81
[Train] Epoch: 1 [357760/620022]    Loss: 0.008142   Batch Acc: 78.12
[Train] Epoch: 1 [357824/620022]    Loss: 0.008176   Batch Acc: 75.00
[Train] Epoch: 1 [357888/620022]    Loss: 0.008298   Batch Acc: 78.12
[Train] Epoch: 1 [357952/620022]    Loss: 0.010379   Batch Acc: 68.75
[Train] Epoch: 1 [358016/620022]    Loss: 0.008148   Batch Acc: 82.81
[Train] Epoch: 1 [358080/620022]    Loss: 0.009410   Batch Acc: 78.12
[Train] Epoch: 1 [358144/620022]    Loss: 0.008307   Batch Acc: 81.25
[Train] Epoch: 1 [358208/620022]    Loss: 0.008745   Batch Acc: 71.88
[Train] Epoch: 1 [358272/620022]    Loss: 0.009753   Batch Acc: 73.44
[Train] Epoch: 1 [358336/620022]    Loss: 0.007270   Batch Acc: 89.06
[Train] Epoch: 1 [358400/620022]    Loss: 0.006435   Batch Acc: 87.50
[Train] Epoch: 1 [358464/620022]    Loss: 0.007852   Batch Acc: 75.00
[Train] Epoch: 1 [358528/620022]    Loss: 0.006060   Batch Acc: 82.81
[Train] Epoch: 1 [358592/620022]    Loss: 0.008964   Batch Acc: 78.12
[Train] Epoch: 1 [358656/620022]    Loss: 0.011351   Batch Acc: 70.31
[Train] Epoch: 1 [358720/620022]    Loss: 0.006286   Batch Acc: 84.38
[Train] Epoch: 1 [358784/620022]    Loss: 0.009232   Batch Acc: 75.00
[Train] Epoch: 1 [358848/620022]    Loss: 0.007399   Batch Acc: 78.12
[Train] Epoch: 1 [358912/620022]    Loss: 0.010204   Batch Acc: 70.31
[Train] Epoch: 1 [358976/620022]    Loss: 0.006738   Batch Acc: 79.69
[Train] Epoch: 1 [359040/620022]    Loss: 0.007709   Batch Acc: 81.25
[Train] Epoch: 1 [359104/620022]    Loss: 0.012288   Batch Acc: 68.75
[Train] Epoch: 1 [359168/620022]    Loss: 0.007861   Batch Acc: 81.25
[Train] Epoch: 1 [359232/620022]    Loss: 0.010308   Batch Acc: 71.88
[Train] Epoch: 1 [359296/620022]    Loss: 0.008232   Batch Acc: 82.81
[Train] Epoch: 1 [359360/620022]    Loss: 0.008226   Batch Acc: 79.69
[Train] Epoch: 1 [359424/620022]    Loss: 0.009732   Batch Acc: 73.44
[Train] Epoch: 1 [359488/620022]    Loss: 0.008690   Batch Acc: 73.44
[Train] Epoch: 1 [359552/620022]    Loss: 0.008382   Batch Acc: 82.81
[Train] Epoch: 1 [359616/620022]    Loss: 0.007918   Batch Acc: 82.81
[Train] Epoch: 1 [359680/620022]    Loss: 0.009137   Batch Acc: 82.81
[Train] Epoch: 1 [359744/620022]    Loss: 0.009360   Batch Acc: 71.88
[Train] Epoch: 1 [359808/620022]    Loss: 0.008249   Batch Acc: 76.56
[Train] Epoch: 1 [359872/620022]    Loss: 0.007012   Batch Acc: 82.81
[Train] Epoch: 1 [359936/620022]    Loss: 0.007275   Batch Acc: 87.50
[Train] Epoch: 1 [360000/620022]    Loss: 0.009185   Batch Acc: 75.00
[Train] Epoch: 1 [360064/620022]    Loss: 0.007170   Batch Acc: 81.25
[Train] Epoch: 1 [360128/620022]    Loss: 0.010630   Batch Acc: 67.19
[Train] Epoch: 1 [360192/620022]    Loss: 0.007571   Batch Acc: 81.25
[Train] Epoch: 1 [360256/620022]    Loss: 0.010311   Batch Acc: 71.88
[Train] Epoch: 1 [360320/620022]    Loss: 0.009878   Batch Acc: 79.69
[Train] Epoch: 1 [360384/620022]    Loss: 0.008674   Batch Acc: 76.56
[Train] Epoch: 1 [360448/620022]    Loss: 0.008107   Batch Acc: 78.12
[Train] Epoch: 1 [360512/620022]    Loss: 0.008719   Batch Acc: 71.88
[Train] Epoch: 1 [360576/620022]    Loss: 0.008930   Batch Acc: 71.88
[Train] Epoch: 1 [360640/620022]    Loss: 0.008910   Batch Acc: 76.56
[Train] Epoch: 1 [360704/620022]    Loss: 0.010030   Batch Acc: 71.88
[Train] Epoch: 1 [360768/620022]    Loss: 0.010089   Batch Acc: 76.56
[Train] Epoch: 1 [360832/620022]    Loss: 0.009028   Batch Acc: 78.12
[Train] Epoch: 1 [360896/620022]    Loss: 0.009586   Batch Acc: 71.88
[Train] Epoch: 1 [360960/620022]    Loss: 0.008428   Batch Acc: 81.25
[Train] Epoch: 1 [361024/620022]    Loss: 0.008514   Batch Acc: 76.56
[Train] Epoch: 1 [361088/620022]    Loss: 0.011448   Batch Acc: 65.62
[Train] Epoch: 1 [361152/620022]    Loss: 0.008812   Batch Acc: 79.69
[Train] Epoch: 1 [361216/620022]    Loss: 0.008848   Batch Acc: 71.88
[Train] Epoch: 1 [361280/620022]    Loss: 0.009274   Batch Acc: 78.12
[Train] Epoch: 1 [361344/620022]    Loss: 0.008799   Batch Acc: 79.69
[Train] Epoch: 1 [361408/620022]    Loss: 0.007661   Batch Acc: 81.25
[Train] Epoch: 1 [361472/620022]    Loss: 0.009913   Batch Acc: 76.56
[Train] Epoch: 1 [361536/620022]    Loss: 0.006209   Batch Acc: 82.81
[Train] Epoch: 1 [361600/620022]    Loss: 0.009146   Batch Acc: 79.69
[Train] Epoch: 1 [361664/620022]    Loss: 0.008065   Batch Acc: 73.44
[Train] Epoch: 1 [361728/620022]    Loss: 0.007262   Batch Acc: 81.25
[Train] Epoch: 1 [361792/620022]    Loss: 0.008478   Batch Acc: 76.56
[Train] Epoch: 1 [361856/620022]    Loss: 0.009211   Batch Acc: 81.25
[Train] Epoch: 1 [361920/620022]    Loss: 0.008007   Batch Acc: 79.69
[Train] Epoch: 1 [361984/620022]    Loss: 0.009630   Batch Acc: 75.00
[Train] Epoch: 1 [362048/620022]    Loss: 0.011413   Batch Acc: 70.31
[Train] Epoch: 1 [362112/620022]    Loss: 0.008752   Batch Acc: 76.56
[Train] Epoch: 1 [362176/620022]    Loss: 0.008114   Batch Acc: 79.69
[Train] Epoch: 1 [362240/620022]    Loss: 0.008628   Batch Acc: 81.25
[Train] Epoch: 1 [362304/620022]    Loss: 0.007407   Batch Acc: 82.81
[Train] Epoch: 1 [362368/620022]    Loss: 0.008886   Batch Acc: 79.69
[Train] Epoch: 1 [362432/620022]    Loss: 0.008682   Batch Acc: 79.69
[Train] Epoch: 1 [362496/620022]    Loss: 0.010487   Batch Acc: 78.12
[Train] Epoch: 1 [362560/620022]    Loss: 0.008773   Batch Acc: 75.00
[Train] Epoch: 1 [362624/620022]    Loss: 0.007324   Batch Acc: 84.38
[Train] Epoch: 1 [362688/620022]    Loss: 0.006963   Batch Acc: 81.25
[Train] Epoch: 1 [362752/620022]    Loss: 0.012781   Batch Acc: 67.19
[Train] Epoch: 1 [362816/620022]    Loss: 0.008912   Batch Acc: 76.56
[Train] Epoch: 1 [362880/620022]    Loss: 0.008734   Batch Acc: 75.00
[Train] Epoch: 1 [362944/620022]    Loss: 0.007988   Batch Acc: 78.12
[Train] Epoch: 1 [363008/620022]    Loss: 0.010421   Batch Acc: 71.88
[Train] Epoch: 1 [363072/620022]    Loss: 0.008782   Batch Acc: 73.44
[Train] Epoch: 1 [363136/620022]    Loss: 0.011951   Batch Acc: 62.50
[Train] Epoch: 1 [363200/620022]    Loss: 0.007259   Batch Acc: 79.69
[Train] Epoch: 1 [363264/620022]    Loss: 0.007119   Batch Acc: 78.12
[Train] Epoch: 1 [363328/620022]    Loss: 0.007951   Batch Acc: 85.94
[Train] Epoch: 1 [363392/620022]    Loss: 0.009521   Batch Acc: 75.00
[Train] Epoch: 1 [363456/620022]    Loss: 0.010112   Batch Acc: 75.00
[Train] Epoch: 1 [363520/620022]    Loss: 0.007131   Batch Acc: 76.56
[Train] Epoch: 1 [363584/620022]    Loss: 0.007067   Batch Acc: 85.94
[Train] Epoch: 1 [363648/620022]    Loss: 0.008788   Batch Acc: 76.56
[Train] Epoch: 1 [363712/620022]    Loss: 0.007208   Batch Acc: 84.38
[Train] Epoch: 1 [363776/620022]    Loss: 0.008703   Batch Acc: 78.12
[Train] Epoch: 1 [363840/620022]    Loss: 0.008579   Batch Acc: 81.25
[Train] Epoch: 1 [363904/620022]    Loss: 0.007003   Batch Acc: 82.81
[Train] Epoch: 1 [363968/620022]    Loss: 0.007733   Batch Acc: 79.69
[Train] Epoch: 1 [364032/620022]    Loss: 0.008858   Batch Acc: 76.56
[Train] Epoch: 1 [364096/620022]    Loss: 0.008224   Batch Acc: 78.12
[Train] Epoch: 1 [364160/620022]    Loss: 0.008609   Batch Acc: 76.56
[Train] Epoch: 1 [364224/620022]    Loss: 0.009138   Batch Acc: 75.00
[Train] Epoch: 1 [364288/620022]    Loss: 0.009540   Batch Acc: 78.12
[Train] Epoch: 1 [364352/620022]    Loss: 0.009239   Batch Acc: 78.12
[Train] Epoch: 1 [364416/620022]    Loss: 0.010483   Batch Acc: 70.31
[Train] Epoch: 1 [364480/620022]    Loss: 0.009917   Batch Acc: 78.12
[Train] Epoch: 1 [364544/620022]    Loss: 0.009150   Batch Acc: 76.56
[Train] Epoch: 1 [364608/620022]    Loss: 0.009451   Batch Acc: 76.56
[Train] Epoch: 1 [364672/620022]    Loss: 0.007318   Batch Acc: 84.38
[Train] Epoch: 1 [364736/620022]    Loss: 0.010361   Batch Acc: 73.44
[Train] Epoch: 1 [364800/620022]    Loss: 0.008206   Batch Acc: 76.56
[Train] Epoch: 1 [364864/620022]    Loss: 0.011831   Batch Acc: 62.50
[Train] Epoch: 1 [364928/620022]    Loss: 0.008390   Batch Acc: 78.12
[Train] Epoch: 1 [364992/620022]    Loss: 0.010013   Batch Acc: 75.00
[Train] Epoch: 1 [365056/620022]    Loss: 0.009449   Batch Acc: 78.12
[Train] Epoch: 1 [365120/620022]    Loss: 0.006813   Batch Acc: 87.50
[Train] Epoch: 1 [365184/620022]    Loss: 0.008294   Batch Acc: 76.56
[Train] Epoch: 1 [365248/620022]    Loss: 0.010871   Batch Acc: 70.31
[Train] Epoch: 1 [365312/620022]    Loss: 0.008252   Batch Acc: 78.12
[Train] Epoch: 1 [365376/620022]    Loss: 0.008357   Batch Acc: 81.25
[Train] Epoch: 1 [365440/620022]    Loss: 0.008156   Batch Acc: 84.38
[Train] Epoch: 1 [365504/620022]    Loss: 0.009669   Batch Acc: 68.75
[Train] Epoch: 1 [365568/620022]    Loss: 0.011990   Batch Acc: 71.88
[Train] Epoch: 1 [365632/620022]    Loss: 0.008327   Batch Acc: 76.56
[Train] Epoch: 1 [365696/620022]    Loss: 0.008950   Batch Acc: 78.12
[Train] Epoch: 1 [365760/620022]    Loss: 0.008179   Batch Acc: 76.56
[Train] Epoch: 1 [365824/620022]    Loss: 0.009589   Batch Acc: 73.44
[Train] Epoch: 1 [365888/620022]    Loss: 0.010905   Batch Acc: 76.56
[Train] Epoch: 1 [365952/620022]    Loss: 0.008475   Batch Acc: 75.00
[Train] Epoch: 1 [366016/620022]    Loss: 0.010892   Batch Acc: 70.31
[Train] Epoch: 1 [366080/620022]    Loss: 0.007006   Batch Acc: 81.25
[Train] Epoch: 1 [366144/620022]    Loss: 0.008475   Batch Acc: 82.81
[Train] Epoch: 1 [366208/620022]    Loss: 0.009414   Batch Acc: 68.75
[Train] Epoch: 1 [366272/620022]    Loss: 0.006950   Batch Acc: 82.81
[Train] Epoch: 1 [366336/620022]    Loss: 0.010183   Batch Acc: 71.88
[Train] Epoch: 1 [366400/620022]    Loss: 0.007009   Batch Acc: 84.38
[Train] Epoch: 1 [366464/620022]    Loss: 0.006679   Batch Acc: 87.50
[Train] Epoch: 1 [366528/620022]    Loss: 0.010651   Batch Acc: 73.44
[Train] Epoch: 1 [366592/620022]    Loss: 0.010036   Batch Acc: 75.00
[Train] Epoch: 1 [366656/620022]    Loss: 0.010322   Batch Acc: 75.00
[Train] Epoch: 1 [366720/620022]    Loss: 0.007109   Batch Acc: 84.38
[Train] Epoch: 1 [366784/620022]    Loss: 0.010553   Batch Acc: 70.31
[Train] Epoch: 1 [366848/620022]    Loss: 0.009871   Batch Acc: 81.25
[Train] Epoch: 1 [366912/620022]    Loss: 0.008135   Batch Acc: 81.25
[Train] Epoch: 1 [366976/620022]    Loss: 0.005976   Batch Acc: 90.62
[Train] Epoch: 1 [367040/620022]    Loss: 0.010291   Batch Acc: 68.75
[Train] Epoch: 1 [367104/620022]    Loss: 0.010002   Batch Acc: 70.31
[Train] Epoch: 1 [367168/620022]    Loss: 0.007081   Batch Acc: 87.50
[Train] Epoch: 1 [367232/620022]    Loss: 0.008884   Batch Acc: 78.12
[Train] Epoch: 1 [367296/620022]    Loss: 0.006010   Batch Acc: 87.50
[Train] Epoch: 1 [367360/620022]    Loss: 0.008770   Batch Acc: 78.12
[Train] Epoch: 1 [367424/620022]    Loss: 0.008287   Batch Acc: 78.12
[Train] Epoch: 1 [367488/620022]    Loss: 0.009144   Batch Acc: 75.00
[Train] Epoch: 1 [367552/620022]    Loss: 0.009131   Batch Acc: 79.69
[Train] Epoch: 1 [367616/620022]    Loss: 0.008776   Batch Acc: 79.69
[Train] Epoch: 1 [367680/620022]    Loss: 0.007894   Batch Acc: 82.81
[Train] Epoch: 1 [367744/620022]    Loss: 0.009928   Batch Acc: 73.44
[Train] Epoch: 1 [367808/620022]    Loss: 0.008685   Batch Acc: 73.44
[Train] Epoch: 1 [367872/620022]    Loss: 0.009249   Batch Acc: 78.12
[Train] Epoch: 1 [367936/620022]    Loss: 0.008492   Batch Acc: 79.69
[Train] Epoch: 1 [368000/620022]    Loss: 0.007883   Batch Acc: 81.25
[Train] Epoch: 1 [368064/620022]    Loss: 0.007442   Batch Acc: 82.81
[Train] Epoch: 1 [368128/620022]    Loss: 0.009139   Batch Acc: 79.69
[Train] Epoch: 1 [368192/620022]    Loss: 0.006496   Batch Acc: 84.38
[Train] Epoch: 1 [368256/620022]    Loss: 0.007514   Batch Acc: 75.00
[Train] Epoch: 1 [368320/620022]    Loss: 0.007414   Batch Acc: 82.81
[Train] Epoch: 1 [368384/620022]    Loss: 0.007185   Batch Acc: 79.69
[Train] Epoch: 1 [368448/620022]    Loss: 0.008503   Batch Acc: 78.12
[Train] Epoch: 1 [368512/620022]    Loss: 0.007255   Batch Acc: 79.69
[Train] Epoch: 1 [368576/620022]    Loss: 0.008365   Batch Acc: 82.81
[Train] Epoch: 1 [368640/620022]    Loss: 0.009445   Batch Acc: 71.88
[Train] Epoch: 1 [368704/620022]    Loss: 0.007599   Batch Acc: 79.69
[Train] Epoch: 1 [368768/620022]    Loss: 0.007969   Batch Acc: 82.81
[Train] Epoch: 1 [368832/620022]    Loss: 0.007260   Batch Acc: 81.25
[Train] Epoch: 1 [368896/620022]    Loss: 0.008856   Batch Acc: 75.00
[Train] Epoch: 1 [368960/620022]    Loss: 0.008941   Batch Acc: 76.56
[Train] Epoch: 1 [369024/620022]    Loss: 0.007581   Batch Acc: 81.25
[Train] Epoch: 1 [369088/620022]    Loss: 0.006965   Batch Acc: 85.94
[Train] Epoch: 1 [369152/620022]    Loss: 0.009280   Batch Acc: 76.56
[Train] Epoch: 1 [369216/620022]    Loss: 0.010675   Batch Acc: 73.44
[Train] Epoch: 1 [369280/620022]    Loss: 0.008521   Batch Acc: 78.12
[Train] Epoch: 1 [369344/620022]    Loss: 0.009166   Batch Acc: 78.12
[Train] Epoch: 1 [369408/620022]    Loss: 0.008632   Batch Acc: 75.00
[Train] Epoch: 1 [369472/620022]    Loss: 0.008897   Batch Acc: 76.56
[Train] Epoch: 1 [369536/620022]    Loss: 0.011268   Batch Acc: 75.00
[Train] Epoch: 1 [369600/620022]    Loss: 0.008521   Batch Acc: 78.12
[Train] Epoch: 1 [369664/620022]    Loss: 0.009635   Batch Acc: 75.00
[Train] Epoch: 1 [369728/620022]    Loss: 0.009006   Batch Acc: 75.00
[Train] Epoch: 1 [369792/620022]    Loss: 0.006768   Batch Acc: 84.38
[Train] Epoch: 1 [369856/620022]    Loss: 0.006983   Batch Acc: 82.81
[Train] Epoch: 1 [369920/620022]    Loss: 0.009644   Batch Acc: 71.88
[Train] Epoch: 1 [369984/620022]    Loss: 0.009175   Batch Acc: 78.12
[Train] Epoch: 1 [370048/620022]    Loss: 0.009421   Batch Acc: 70.31
[Train] Epoch: 1 [370112/620022]    Loss: 0.007130   Batch Acc: 85.94
[Train] Epoch: 1 [370176/620022]    Loss: 0.009151   Batch Acc: 76.56
[Train] Epoch: 1 [370240/620022]    Loss: 0.008530   Batch Acc: 79.69
[Train] Epoch: 1 [370304/620022]    Loss: 0.011114   Batch Acc: 68.75
[Train] Epoch: 1 [370368/620022]    Loss: 0.008820   Batch Acc: 73.44
[Train] Epoch: 1 [370432/620022]    Loss: 0.009634   Batch Acc: 71.88
[Train] Epoch: 1 [370496/620022]    Loss: 0.008634   Batch Acc: 76.56
[Train] Epoch: 1 [370560/620022]    Loss: 0.009417   Batch Acc: 71.88
[Train] Epoch: 1 [370624/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 1 [370688/620022]    Loss: 0.009515   Batch Acc: 73.44
[Train] Epoch: 1 [370752/620022]    Loss: 0.007444   Batch Acc: 82.81
[Train] Epoch: 1 [370816/620022]    Loss: 0.009688   Batch Acc: 78.12
[Train] Epoch: 1 [370880/620022]    Loss: 0.008785   Batch Acc: 79.69
[Train] Epoch: 1 [370944/620022]    Loss: 0.008781   Batch Acc: 79.69
[Train] Epoch: 1 [371008/620022]    Loss: 0.007467   Batch Acc: 82.81
[Train] Epoch: 1 [371072/620022]    Loss: 0.007000   Batch Acc: 85.94
[Train] Epoch: 1 [371136/620022]    Loss: 0.006976   Batch Acc: 85.94
[Train] Epoch: 1 [371200/620022]    Loss: 0.007643   Batch Acc: 85.94
[Train] Epoch: 1 [371264/620022]    Loss: 0.008576   Batch Acc: 78.12
[Train] Epoch: 1 [371328/620022]    Loss: 0.007589   Batch Acc: 79.69
[Train] Epoch: 1 [371392/620022]    Loss: 0.011699   Batch Acc: 73.44
[Train] Epoch: 1 [371456/620022]    Loss: 0.006009   Batch Acc: 85.94
[Train] Epoch: 1 [371520/620022]    Loss: 0.007274   Batch Acc: 84.38
[Train] Epoch: 1 [371584/620022]    Loss: 0.009074   Batch Acc: 78.12
[Train] Epoch: 1 [371648/620022]    Loss: 0.008760   Batch Acc: 78.12
[Train] Epoch: 1 [371712/620022]    Loss: 0.007228   Batch Acc: 78.12
[Train] Epoch: 1 [371776/620022]    Loss: 0.007755   Batch Acc: 78.12
[Train] Epoch: 1 [371840/620022]    Loss: 0.009684   Batch Acc: 75.00
[Train] Epoch: 1 [371904/620022]    Loss: 0.009511   Batch Acc: 75.00
[Train] Epoch: 1 [371968/620022]    Loss: 0.009067   Batch Acc: 81.25
[Train] Epoch: 1 [372032/620022]    Loss: 0.008043   Batch Acc: 76.56
[Train] Epoch: 1 [372096/620022]    Loss: 0.007827   Batch Acc: 78.12
[Train] Epoch: 1 [372160/620022]    Loss: 0.007626   Batch Acc: 82.81
[Train] Epoch: 1 [372224/620022]    Loss: 0.009359   Batch Acc: 76.56
[Train] Epoch: 1 [372288/620022]    Loss: 0.006738   Batch Acc: 82.81
[Train] Epoch: 1 [372352/620022]    Loss: 0.008234   Batch Acc: 81.25
[Train] Epoch: 1 [372416/620022]    Loss: 0.009374   Batch Acc: 70.31
[Train] Epoch: 1 [372480/620022]    Loss: 0.007739   Batch Acc: 73.44
[Train] Epoch: 1 [372544/620022]    Loss: 0.009817   Batch Acc: 76.56
[Train] Epoch: 1 [372608/620022]    Loss: 0.012128   Batch Acc: 65.62
[Train] Epoch: 1 [372672/620022]    Loss: 0.009132   Batch Acc: 78.12
[Train] Epoch: 1 [372736/620022]    Loss: 0.007957   Batch Acc: 82.81
[Train] Epoch: 1 [372800/620022]    Loss: 0.007144   Batch Acc: 81.25
[Train] Epoch: 1 [372864/620022]    Loss: 0.007753   Batch Acc: 79.69
[Train] Epoch: 1 [372928/620022]    Loss: 0.009710   Batch Acc: 73.44
[Train] Epoch: 1 [372992/620022]    Loss: 0.007083   Batch Acc: 84.38
[Train] Epoch: 1 [373056/620022]    Loss: 0.009272   Batch Acc: 81.25
[Train] Epoch: 1 [373120/620022]    Loss: 0.009683   Batch Acc: 76.56
[Train] Epoch: 1 [373184/620022]    Loss: 0.011028   Batch Acc: 73.44
[Train] Epoch: 1 [373248/620022]    Loss: 0.009539   Batch Acc: 75.00
[Train] Epoch: 1 [373312/620022]    Loss: 0.007884   Batch Acc: 75.00
[Train] Epoch: 1 [373376/620022]    Loss: 0.010264   Batch Acc: 73.44
[Train] Epoch: 1 [373440/620022]    Loss: 0.009057   Batch Acc: 78.12
[Train] Epoch: 1 [373504/620022]    Loss: 0.013293   Batch Acc: 65.62
[Train] Epoch: 1 [373568/620022]    Loss: 0.009733   Batch Acc: 76.56
[Train] Epoch: 1 [373632/620022]    Loss: 0.006311   Batch Acc: 85.94
[Train] Epoch: 1 [373696/620022]    Loss: 0.009048   Batch Acc: 73.44
[Train] Epoch: 1 [373760/620022]    Loss: 0.007847   Batch Acc: 75.00
[Train] Epoch: 1 [373824/620022]    Loss: 0.008999   Batch Acc: 73.44
[Train] Epoch: 1 [373888/620022]    Loss: 0.007770   Batch Acc: 84.38
[Train] Epoch: 1 [373952/620022]    Loss: 0.010621   Batch Acc: 68.75
[Train] Epoch: 1 [374016/620022]    Loss: 0.007104   Batch Acc: 85.94
[Train] Epoch: 1 [374080/620022]    Loss: 0.006941   Batch Acc: 85.94
[Train] Epoch: 1 [374144/620022]    Loss: 0.009621   Batch Acc: 79.69
[Train] Epoch: 1 [374208/620022]    Loss: 0.011161   Batch Acc: 70.31
[Train] Epoch: 1 [374272/620022]    Loss: 0.006600   Batch Acc: 85.94
[Train] Epoch: 1 [374336/620022]    Loss: 0.009572   Batch Acc: 76.56
[Train] Epoch: 1 [374400/620022]    Loss: 0.009617   Batch Acc: 75.00
[Train] Epoch: 1 [374464/620022]    Loss: 0.008387   Batch Acc: 78.12
[Train] Epoch: 1 [374528/620022]    Loss: 0.007180   Batch Acc: 81.25
[Train] Epoch: 1 [374592/620022]    Loss: 0.007763   Batch Acc: 82.81
[Train] Epoch: 1 [374656/620022]    Loss: 0.007663   Batch Acc: 84.38
[Train] Epoch: 1 [374720/620022]    Loss: 0.009928   Batch Acc: 71.88
[Train] Epoch: 1 [374784/620022]    Loss: 0.008549   Batch Acc: 76.56
[Train] Epoch: 1 [374848/620022]    Loss: 0.009699   Batch Acc: 71.88
[Train] Epoch: 1 [374912/620022]    Loss: 0.009069   Batch Acc: 75.00
[Train] Epoch: 1 [374976/620022]    Loss: 0.009785   Batch Acc: 70.31
[Train] Epoch: 1 [375040/620022]    Loss: 0.008047   Batch Acc: 78.12
[Train] Epoch: 1 [375104/620022]    Loss: 0.011003   Batch Acc: 76.56
[Train] Epoch: 1 [375168/620022]    Loss: 0.007980   Batch Acc: 76.56
[Train] Epoch: 1 [375232/620022]    Loss: 0.009279   Batch Acc: 79.69
[Train] Epoch: 1 [375296/620022]    Loss: 0.008611   Batch Acc: 78.12
[Train] Epoch: 1 [375360/620022]    Loss: 0.005730   Batch Acc: 90.62
[Train] Epoch: 1 [375424/620022]    Loss: 0.009046   Batch Acc: 73.44
[Train] Epoch: 1 [375488/620022]    Loss: 0.006788   Batch Acc: 81.25
[Train] Epoch: 1 [375552/620022]    Loss: 0.008657   Batch Acc: 81.25
[Train] Epoch: 1 [375616/620022]    Loss: 0.010009   Batch Acc: 78.12
[Train] Epoch: 1 [375680/620022]    Loss: 0.008812   Batch Acc: 75.00
[Train] Epoch: 1 [375744/620022]    Loss: 0.008535   Batch Acc: 81.25
[Train] Epoch: 1 [375808/620022]    Loss: 0.008758   Batch Acc: 79.69
[Train] Epoch: 1 [375872/620022]    Loss: 0.009469   Batch Acc: 75.00
[Train] Epoch: 1 [375936/620022]    Loss: 0.007338   Batch Acc: 82.81
[Train] Epoch: 1 [376000/620022]    Loss: 0.006084   Batch Acc: 85.94
[Train] Epoch: 1 [376064/620022]    Loss: 0.007259   Batch Acc: 82.81
[Train] Epoch: 1 [376128/620022]    Loss: 0.011011   Batch Acc: 73.44
[Train] Epoch: 1 [376192/620022]    Loss: 0.007958   Batch Acc: 82.81
[Train] Epoch: 1 [376256/620022]    Loss: 0.011292   Batch Acc: 70.31
[Train] Epoch: 1 [376320/620022]    Loss: 0.006922   Batch Acc: 81.25
[Train] Epoch: 1 [376384/620022]    Loss: 0.008389   Batch Acc: 75.00
[Train] Epoch: 1 [376448/620022]    Loss: 0.009616   Batch Acc: 70.31
[Train] Epoch: 1 [376512/620022]    Loss: 0.007435   Batch Acc: 82.81
[Train] Epoch: 1 [376576/620022]    Loss: 0.007860   Batch Acc: 82.81
[Train] Epoch: 1 [376640/620022]    Loss: 0.006459   Batch Acc: 90.62
[Train] Epoch: 1 [376704/620022]    Loss: 0.009365   Batch Acc: 75.00
[Train] Epoch: 1 [376768/620022]    Loss: 0.006391   Batch Acc: 89.06
[Train] Epoch: 1 [376832/620022]    Loss: 0.006843   Batch Acc: 89.06
[Train] Epoch: 1 [376896/620022]    Loss: 0.008964   Batch Acc: 78.12
[Train] Epoch: 1 [376960/620022]    Loss: 0.009075   Batch Acc: 79.69
[Train] Epoch: 1 [377024/620022]    Loss: 0.008053   Batch Acc: 82.81
[Train] Epoch: 1 [377088/620022]    Loss: 0.009905   Batch Acc: 78.12
[Train] Epoch: 1 [377152/620022]    Loss: 0.010036   Batch Acc: 78.12
[Train] Epoch: 1 [377216/620022]    Loss: 0.008780   Batch Acc: 82.81
[Train] Epoch: 1 [377280/620022]    Loss: 0.009622   Batch Acc: 76.56
[Train] Epoch: 1 [377344/620022]    Loss: 0.009180   Batch Acc: 81.25
[Train] Epoch: 1 [377408/620022]    Loss: 0.008338   Batch Acc: 78.12
[Train] Epoch: 1 [377472/620022]    Loss: 0.010666   Batch Acc: 76.56
[Train] Epoch: 1 [377536/620022]    Loss: 0.008972   Batch Acc: 78.12
[Train] Epoch: 1 [377600/620022]    Loss: 0.011792   Batch Acc: 65.62
[Train] Epoch: 1 [377664/620022]    Loss: 0.008957   Batch Acc: 76.56
[Train] Epoch: 1 [377728/620022]    Loss: 0.008056   Batch Acc: 79.69
[Train] Epoch: 1 [377792/620022]    Loss: 0.008485   Batch Acc: 79.69
[Train] Epoch: 1 [377856/620022]    Loss: 0.007084   Batch Acc: 82.81
[Train] Epoch: 1 [377920/620022]    Loss: 0.006434   Batch Acc: 84.38
[Train] Epoch: 1 [377984/620022]    Loss: 0.009354   Batch Acc: 73.44
[Train] Epoch: 1 [378048/620022]    Loss: 0.008313   Batch Acc: 76.56
[Train] Epoch: 1 [378112/620022]    Loss: 0.006530   Batch Acc: 82.81
[Train] Epoch: 1 [378176/620022]    Loss: 0.010278   Batch Acc: 73.44
[Train] Epoch: 1 [378240/620022]    Loss: 0.008753   Batch Acc: 82.81
[Train] Epoch: 1 [378304/620022]    Loss: 0.008906   Batch Acc: 71.88
[Train] Epoch: 1 [378368/620022]    Loss: 0.007381   Batch Acc: 82.81
[Train] Epoch: 1 [378432/620022]    Loss: 0.007170   Batch Acc: 82.81
[Train] Epoch: 1 [378496/620022]    Loss: 0.009575   Batch Acc: 71.88
[Train] Epoch: 1 [378560/620022]    Loss: 0.008170   Batch Acc: 81.25
[Train] Epoch: 1 [378624/620022]    Loss: 0.008387   Batch Acc: 76.56
[Train] Epoch: 1 [378688/620022]    Loss: 0.007886   Batch Acc: 81.25
[Train] Epoch: 1 [378752/620022]    Loss: 0.009236   Batch Acc: 76.56
[Train] Epoch: 1 [378816/620022]    Loss: 0.010813   Batch Acc: 70.31
[Train] Epoch: 1 [378880/620022]    Loss: 0.008312   Batch Acc: 75.00
[Train] Epoch: 1 [378944/620022]    Loss: 0.009711   Batch Acc: 75.00
[Train] Epoch: 1 [379008/620022]    Loss: 0.009186   Batch Acc: 73.44
[Train] Epoch: 1 [379072/620022]    Loss: 0.010548   Batch Acc: 70.31
[Train] Epoch: 1 [379136/620022]    Loss: 0.009187   Batch Acc: 79.69
[Train] Epoch: 1 [379200/620022]    Loss: 0.007777   Batch Acc: 78.12
[Train] Epoch: 1 [379264/620022]    Loss: 0.010212   Batch Acc: 68.75
[Train] Epoch: 1 [379328/620022]    Loss: 0.008799   Batch Acc: 79.69
[Train] Epoch: 1 [379392/620022]    Loss: 0.008106   Batch Acc: 76.56
[Train] Epoch: 1 [379456/620022]    Loss: 0.008976   Batch Acc: 79.69
[Train] Epoch: 1 [379520/620022]    Loss: 0.006610   Batch Acc: 85.94
[Train] Epoch: 1 [379584/620022]    Loss: 0.008827   Batch Acc: 75.00
[Train] Epoch: 1 [379648/620022]    Loss: 0.008189   Batch Acc: 79.69
[Train] Epoch: 1 [379712/620022]    Loss: 0.007523   Batch Acc: 84.38
[Train] Epoch: 1 [379776/620022]    Loss: 0.008319   Batch Acc: 78.12
[Train] Epoch: 1 [379840/620022]    Loss: 0.006088   Batch Acc: 89.06
[Train] Epoch: 1 [379904/620022]    Loss: 0.010128   Batch Acc: 70.31
[Train] Epoch: 1 [379968/620022]    Loss: 0.007357   Batch Acc: 79.69
[Train] Epoch: 1 [380032/620022]    Loss: 0.008157   Batch Acc: 79.69
[Train] Epoch: 1 [380096/620022]    Loss: 0.008457   Batch Acc: 81.25
[Train] Epoch: 1 [380160/620022]    Loss: 0.008180   Batch Acc: 81.25
[Train] Epoch: 1 [380224/620022]    Loss: 0.011541   Batch Acc: 70.31
[Train] Epoch: 1 [380288/620022]    Loss: 0.009908   Batch Acc: 79.69
[Train] Epoch: 1 [380352/620022]    Loss: 0.011318   Batch Acc: 67.19
[Train] Epoch: 1 [380416/620022]    Loss: 0.007573   Batch Acc: 75.00
[Train] Epoch: 1 [380480/620022]    Loss: 0.008110   Batch Acc: 82.81
[Train] Epoch: 1 [380544/620022]    Loss: 0.007941   Batch Acc: 76.56
[Train] Epoch: 1 [380608/620022]    Loss: 0.007466   Batch Acc: 78.12
[Train] Epoch: 1 [380672/620022]    Loss: 0.010561   Batch Acc: 71.88
[Train] Epoch: 1 [380736/620022]    Loss: 0.006661   Batch Acc: 87.50
[Train] Epoch: 1 [380800/620022]    Loss: 0.007832   Batch Acc: 81.25
[Train] Epoch: 1 [380864/620022]    Loss: 0.006569   Batch Acc: 81.25
[Train] Epoch: 1 [380928/620022]    Loss: 0.010102   Batch Acc: 70.31
[Train] Epoch: 1 [380992/620022]    Loss: 0.006066   Batch Acc: 81.25
[Train] Epoch: 1 [381056/620022]    Loss: 0.009251   Batch Acc: 71.88
[Train] Epoch: 1 [381120/620022]    Loss: 0.007799   Batch Acc: 76.56
[Train] Epoch: 1 [381184/620022]    Loss: 0.009103   Batch Acc: 75.00
[Train] Epoch: 1 [381248/620022]    Loss: 0.008650   Batch Acc: 75.00
[Train] Epoch: 1 [381312/620022]    Loss: 0.007255   Batch Acc: 82.81
[Train] Epoch: 1 [381376/620022]    Loss: 0.010540   Batch Acc: 73.44
[Train] Epoch: 1 [381440/620022]    Loss: 0.008071   Batch Acc: 85.94
[Train] Epoch: 1 [381504/620022]    Loss: 0.008817   Batch Acc: 76.56
[Train] Epoch: 1 [381568/620022]    Loss: 0.008503   Batch Acc: 79.69
[Train] Epoch: 1 [381632/620022]    Loss: 0.008508   Batch Acc: 71.88
[Train] Epoch: 1 [381696/620022]    Loss: 0.010252   Batch Acc: 71.88
[Train] Epoch: 1 [381760/620022]    Loss: 0.009121   Batch Acc: 75.00
[Train] Epoch: 1 [381824/620022]    Loss: 0.009044   Batch Acc: 79.69
[Train] Epoch: 1 [381888/620022]    Loss: 0.009663   Batch Acc: 71.88
[Train] Epoch: 1 [381952/620022]    Loss: 0.009386   Batch Acc: 71.88
[Train] Epoch: 1 [382016/620022]    Loss: 0.011744   Batch Acc: 70.31
[Train] Epoch: 1 [382080/620022]    Loss: 0.007455   Batch Acc: 79.69
[Train] Epoch: 1 [382144/620022]    Loss: 0.008901   Batch Acc: 75.00
[Train] Epoch: 1 [382208/620022]    Loss: 0.010058   Batch Acc: 71.88
[Train] Epoch: 1 [382272/620022]    Loss: 0.009546   Batch Acc: 71.88
[Train] Epoch: 1 [382336/620022]    Loss: 0.005331   Batch Acc: 87.50
[Train] Epoch: 1 [382400/620022]    Loss: 0.009174   Batch Acc: 75.00
[Train] Epoch: 1 [382464/620022]    Loss: 0.009003   Batch Acc: 75.00
[Train] Epoch: 1 [382528/620022]    Loss: 0.007613   Batch Acc: 84.38
[Train] Epoch: 1 [382592/620022]    Loss: 0.010046   Batch Acc: 76.56
[Train] Epoch: 1 [382656/620022]    Loss: 0.009664   Batch Acc: 73.44
[Train] Epoch: 1 [382720/620022]    Loss: 0.010584   Batch Acc: 68.75
[Train] Epoch: 1 [382784/620022]    Loss: 0.008864   Batch Acc: 79.69
[Train] Epoch: 1 [382848/620022]    Loss: 0.007648   Batch Acc: 81.25
[Train] Epoch: 1 [382912/620022]    Loss: 0.008768   Batch Acc: 78.12
[Train] Epoch: 1 [382976/620022]    Loss: 0.008174   Batch Acc: 84.38
[Train] Epoch: 1 [383040/620022]    Loss: 0.009001   Batch Acc: 79.69
[Train] Epoch: 1 [383104/620022]    Loss: 0.006960   Batch Acc: 82.81
[Train] Epoch: 1 [383168/620022]    Loss: 0.009833   Batch Acc: 73.44
[Train] Epoch: 1 [383232/620022]    Loss: 0.007724   Batch Acc: 81.25
[Train] Epoch: 1 [383296/620022]    Loss: 0.008901   Batch Acc: 76.56
[Train] Epoch: 1 [383360/620022]    Loss: 0.010408   Batch Acc: 75.00
[Train] Epoch: 1 [383424/620022]    Loss: 0.009497   Batch Acc: 79.69
[Train] Epoch: 1 [383488/620022]    Loss: 0.008028   Batch Acc: 82.81
[Train] Epoch: 1 [383552/620022]    Loss: 0.008151   Batch Acc: 79.69
[Train] Epoch: 1 [383616/620022]    Loss: 0.008512   Batch Acc: 81.25
[Train] Epoch: 1 [383680/620022]    Loss: 0.008073   Batch Acc: 78.12
[Train] Epoch: 1 [383744/620022]    Loss: 0.008523   Batch Acc: 73.44
[Train] Epoch: 1 [383808/620022]    Loss: 0.009053   Batch Acc: 71.88
[Train] Epoch: 1 [383872/620022]    Loss: 0.008269   Batch Acc: 79.69
[Train] Epoch: 1 [383936/620022]    Loss: 0.007450   Batch Acc: 82.81
[Train] Epoch: 1 [384000/620022]    Loss: 0.009896   Batch Acc: 73.44
[Train] Epoch: 1 [384064/620022]    Loss: 0.008245   Batch Acc: 76.56
[Train] Epoch: 1 [384128/620022]    Loss: 0.007037   Batch Acc: 84.38
[Train] Epoch: 1 [384192/620022]    Loss: 0.009288   Batch Acc: 71.88
[Train] Epoch: 1 [384256/620022]    Loss: 0.008541   Batch Acc: 81.25
[Train] Epoch: 1 [384320/620022]    Loss: 0.008958   Batch Acc: 78.12
[Train] Epoch: 1 [384384/620022]    Loss: 0.009740   Batch Acc: 70.31
[Train] Epoch: 1 [384448/620022]    Loss: 0.008121   Batch Acc: 79.69
[Train] Epoch: 1 [384512/620022]    Loss: 0.009034   Batch Acc: 73.44
[Train] Epoch: 1 [384576/620022]    Loss: 0.009430   Batch Acc: 70.31
[Train] Epoch: 1 [384640/620022]    Loss: 0.009179   Batch Acc: 79.69
[Train] Epoch: 1 [384704/620022]    Loss: 0.008489   Batch Acc: 82.81
[Train] Epoch: 1 [384768/620022]    Loss: 0.008433   Batch Acc: 79.69
[Train] Epoch: 1 [384832/620022]    Loss: 0.010348   Batch Acc: 76.56
[Train] Epoch: 1 [384896/620022]    Loss: 0.008903   Batch Acc: 78.12
[Train] Epoch: 1 [384960/620022]    Loss: 0.006824   Batch Acc: 82.81
[Train] Epoch: 1 [385024/620022]    Loss: 0.008883   Batch Acc: 79.69
[Train] Epoch: 1 [385088/620022]    Loss: 0.009149   Batch Acc: 78.12
[Train] Epoch: 1 [385152/620022]    Loss: 0.012240   Batch Acc: 65.62
[Train] Epoch: 1 [385216/620022]    Loss: 0.009379   Batch Acc: 73.44
[Train] Epoch: 1 [385280/620022]    Loss: 0.009629   Batch Acc: 76.56
[Train] Epoch: 1 [385344/620022]    Loss: 0.009824   Batch Acc: 78.12
[Train] Epoch: 1 [385408/620022]    Loss: 0.009001   Batch Acc: 78.12
[Train] Epoch: 1 [385472/620022]    Loss: 0.007234   Batch Acc: 79.69
[Train] Epoch: 1 [385536/620022]    Loss: 0.008198   Batch Acc: 78.12
[Train] Epoch: 1 [385600/620022]    Loss: 0.007914   Batch Acc: 84.38
[Train] Epoch: 1 [385664/620022]    Loss: 0.008985   Batch Acc: 79.69
[Train] Epoch: 1 [385728/620022]    Loss: 0.010304   Batch Acc: 73.44
[Train] Epoch: 1 [385792/620022]    Loss: 0.007467   Batch Acc: 87.50
[Train] Epoch: 1 [385856/620022]    Loss: 0.007799   Batch Acc: 81.25
[Train] Epoch: 1 [385920/620022]    Loss: 0.009932   Batch Acc: 73.44
[Train] Epoch: 1 [385984/620022]    Loss: 0.011635   Batch Acc: 64.06
[Train] Epoch: 1 [386048/620022]    Loss: 0.010962   Batch Acc: 75.00
[Train] Epoch: 1 [386112/620022]    Loss: 0.008547   Batch Acc: 79.69
[Train] Epoch: 1 [386176/620022]    Loss: 0.008584   Batch Acc: 78.12
[Train] Epoch: 1 [386240/620022]    Loss: 0.010416   Batch Acc: 70.31
[Train] Epoch: 1 [386304/620022]    Loss: 0.011433   Batch Acc: 65.62
[Train] Epoch: 1 [386368/620022]    Loss: 0.008639   Batch Acc: 78.12
[Train] Epoch: 1 [386432/620022]    Loss: 0.011706   Batch Acc: 70.31
[Train] Epoch: 1 [386496/620022]    Loss: 0.007853   Batch Acc: 81.25
[Train] Epoch: 1 [386560/620022]    Loss: 0.009719   Batch Acc: 73.44
[Train] Epoch: 1 [386624/620022]    Loss: 0.009110   Batch Acc: 79.69
[Train] Epoch: 1 [386688/620022]    Loss: 0.010169   Batch Acc: 71.88
[Train] Epoch: 1 [386752/620022]    Loss: 0.006790   Batch Acc: 84.38
[Train] Epoch: 1 [386816/620022]    Loss: 0.008360   Batch Acc: 75.00
[Train] Epoch: 1 [386880/620022]    Loss: 0.007738   Batch Acc: 82.81
[Train] Epoch: 1 [386944/620022]    Loss: 0.009720   Batch Acc: 71.88
[Train] Epoch: 1 [387008/620022]    Loss: 0.009930   Batch Acc: 76.56
[Train] Epoch: 1 [387072/620022]    Loss: 0.007884   Batch Acc: 78.12
[Train] Epoch: 1 [387136/620022]    Loss: 0.011325   Batch Acc: 65.62
[Train] Epoch: 1 [387200/620022]    Loss: 0.006742   Batch Acc: 84.38
[Train] Epoch: 1 [387264/620022]    Loss: 0.007117   Batch Acc: 85.94
[Train] Epoch: 1 [387328/620022]    Loss: 0.007591   Batch Acc: 81.25
[Train] Epoch: 1 [387392/620022]    Loss: 0.009055   Batch Acc: 84.38
[Train] Epoch: 1 [387456/620022]    Loss: 0.007031   Batch Acc: 84.38
[Train] Epoch: 1 [387520/620022]    Loss: 0.009965   Batch Acc: 73.44
[Train] Epoch: 1 [387584/620022]    Loss: 0.008741   Batch Acc: 78.12
[Train] Epoch: 1 [387648/620022]    Loss: 0.010617   Batch Acc: 71.88
[Train] Epoch: 1 [387712/620022]    Loss: 0.010290   Batch Acc: 73.44
[Train] Epoch: 1 [387776/620022]    Loss: 0.011015   Batch Acc: 71.88
[Train] Epoch: 1 [387840/620022]    Loss: 0.007867   Batch Acc: 78.12
[Train] Epoch: 1 [387904/620022]    Loss: 0.007382   Batch Acc: 82.81
[Train] Epoch: 1 [387968/620022]    Loss: 0.008655   Batch Acc: 81.25
[Train] Epoch: 1 [388032/620022]    Loss: 0.009353   Batch Acc: 73.44
[Train] Epoch: 1 [388096/620022]    Loss: 0.013079   Batch Acc: 71.88
[Train] Epoch: 1 [388160/620022]    Loss: 0.009498   Batch Acc: 73.44
[Train] Epoch: 1 [388224/620022]    Loss: 0.009487   Batch Acc: 71.88
[Train] Epoch: 1 [388288/620022]    Loss: 0.009905   Batch Acc: 79.69
[Train] Epoch: 1 [388352/620022]    Loss: 0.008134   Batch Acc: 82.81
[Train] Epoch: 1 [388416/620022]    Loss: 0.008923   Batch Acc: 73.44
[Train] Epoch: 1 [388480/620022]    Loss: 0.009934   Batch Acc: 78.12
[Train] Epoch: 1 [388544/620022]    Loss: 0.009727   Batch Acc: 75.00
[Train] Epoch: 1 [388608/620022]    Loss: 0.009586   Batch Acc: 71.88
[Train] Epoch: 1 [388672/620022]    Loss: 0.008184   Batch Acc: 79.69
[Train] Epoch: 1 [388736/620022]    Loss: 0.008679   Batch Acc: 79.69
[Train] Epoch: 1 [388800/620022]    Loss: 0.009120   Batch Acc: 70.31
[Train] Epoch: 1 [388864/620022]    Loss: 0.008835   Batch Acc: 78.12
[Train] Epoch: 1 [388928/620022]    Loss: 0.009411   Batch Acc: 70.31
[Train] Epoch: 1 [388992/620022]    Loss: 0.009169   Batch Acc: 75.00
[Train] Epoch: 1 [389056/620022]    Loss: 0.009310   Batch Acc: 76.56
[Train] Epoch: 1 [389120/620022]    Loss: 0.007836   Batch Acc: 79.69
[Train] Epoch: 1 [389184/620022]    Loss: 0.010072   Batch Acc: 78.12
[Train] Epoch: 1 [389248/620022]    Loss: 0.009920   Batch Acc: 76.56
[Train] Epoch: 1 [389312/620022]    Loss: 0.008727   Batch Acc: 70.31
[Train] Epoch: 1 [389376/620022]    Loss: 0.008205   Batch Acc: 82.81
[Train] Epoch: 1 [389440/620022]    Loss: 0.009830   Batch Acc: 73.44
[Train] Epoch: 1 [389504/620022]    Loss: 0.008341   Batch Acc: 78.12
[Train] Epoch: 1 [389568/620022]    Loss: 0.007371   Batch Acc: 84.38
[Train] Epoch: 1 [389632/620022]    Loss: 0.010190   Batch Acc: 71.88
[Train] Epoch: 1 [389696/620022]    Loss: 0.009429   Batch Acc: 68.75
[Train] Epoch: 1 [389760/620022]    Loss: 0.009277   Batch Acc: 78.12
[Train] Epoch: 1 [389824/620022]    Loss: 0.007027   Batch Acc: 89.06
[Train] Epoch: 1 [389888/620022]    Loss: 0.007212   Batch Acc: 84.38
[Train] Epoch: 1 [389952/620022]    Loss: 0.008507   Batch Acc: 78.12
[Train] Epoch: 1 [390016/620022]    Loss: 0.008956   Batch Acc: 76.56
[Train] Epoch: 1 [390080/620022]    Loss: 0.010027   Batch Acc: 78.12
[Train] Epoch: 1 [390144/620022]    Loss: 0.010830   Batch Acc: 67.19
[Train] Epoch: 1 [390208/620022]    Loss: 0.008070   Batch Acc: 82.81
[Train] Epoch: 1 [390272/620022]    Loss: 0.008614   Batch Acc: 79.69
[Train] Epoch: 1 [390336/620022]    Loss: 0.006491   Batch Acc: 89.06
[Train] Epoch: 1 [390400/620022]    Loss: 0.008169   Batch Acc: 84.38
[Train] Epoch: 1 [390464/620022]    Loss: 0.008398   Batch Acc: 75.00
[Train] Epoch: 1 [390528/620022]    Loss: 0.009324   Batch Acc: 73.44
[Train] Epoch: 1 [390592/620022]    Loss: 0.010405   Batch Acc: 82.81
[Train] Epoch: 1 [390656/620022]    Loss: 0.010671   Batch Acc: 71.88
[Train] Epoch: 1 [390720/620022]    Loss: 0.005677   Batch Acc: 89.06
[Train] Epoch: 1 [390784/620022]    Loss: 0.007587   Batch Acc: 84.38
[Train] Epoch: 1 [390848/620022]    Loss: 0.008099   Batch Acc: 78.12
[Train] Epoch: 1 [390912/620022]    Loss: 0.008633   Batch Acc: 76.56
[Train] Epoch: 1 [390976/620022]    Loss: 0.007825   Batch Acc: 76.56
[Train] Epoch: 1 [391040/620022]    Loss: 0.006850   Batch Acc: 85.94
[Train] Epoch: 1 [391104/620022]    Loss: 0.004740   Batch Acc: 90.62
[Train] Epoch: 1 [391168/620022]    Loss: 0.010508   Batch Acc: 70.31
[Train] Epoch: 1 [391232/620022]    Loss: 0.008130   Batch Acc: 78.12
[Train] Epoch: 1 [391296/620022]    Loss: 0.008138   Batch Acc: 76.56
[Train] Epoch: 1 [391360/620022]    Loss: 0.007000   Batch Acc: 79.69
[Train] Epoch: 1 [391424/620022]    Loss: 0.008356   Batch Acc: 75.00
[Train] Epoch: 1 [391488/620022]    Loss: 0.011420   Batch Acc: 70.31
[Train] Epoch: 1 [391552/620022]    Loss: 0.010165   Batch Acc: 71.88
[Train] Epoch: 1 [391616/620022]    Loss: 0.011760   Batch Acc: 65.62
[Train] Epoch: 1 [391680/620022]    Loss: 0.007117   Batch Acc: 82.81
[Train] Epoch: 1 [391744/620022]    Loss: 0.009294   Batch Acc: 79.69
[Train] Epoch: 1 [391808/620022]    Loss: 0.009508   Batch Acc: 76.56
[Train] Epoch: 1 [391872/620022]    Loss: 0.008014   Batch Acc: 78.12
[Train] Epoch: 1 [391936/620022]    Loss: 0.007496   Batch Acc: 85.94
[Train] Epoch: 1 [392000/620022]    Loss: 0.008919   Batch Acc: 71.88
[Train] Epoch: 1 [392064/620022]    Loss: 0.008965   Batch Acc: 75.00
[Train] Epoch: 1 [392128/620022]    Loss: 0.008340   Batch Acc: 79.69
[Train] Epoch: 1 [392192/620022]    Loss: 0.009213   Batch Acc: 76.56
[Train] Epoch: 1 [392256/620022]    Loss: 0.009356   Batch Acc: 76.56
[Train] Epoch: 1 [392320/620022]    Loss: 0.010183   Batch Acc: 79.69
[Train] Epoch: 1 [392384/620022]    Loss: 0.009340   Batch Acc: 75.00
[Train] Epoch: 1 [392448/620022]    Loss: 0.006654   Batch Acc: 81.25
[Train] Epoch: 1 [392512/620022]    Loss: 0.008797   Batch Acc: 82.81
[Train] Epoch: 1 [392576/620022]    Loss: 0.010884   Batch Acc: 71.88
[Train] Epoch: 1 [392640/620022]    Loss: 0.008784   Batch Acc: 75.00
[Train] Epoch: 1 [392704/620022]    Loss: 0.008301   Batch Acc: 78.12
[Train] Epoch: 1 [392768/620022]    Loss: 0.008172   Batch Acc: 85.94
[Train] Epoch: 1 [392832/620022]    Loss: 0.008569   Batch Acc: 79.69
[Train] Epoch: 1 [392896/620022]    Loss: 0.008440   Batch Acc: 78.12
[Train] Epoch: 1 [392960/620022]    Loss: 0.007628   Batch Acc: 82.81
[Train] Epoch: 1 [393024/620022]    Loss: 0.007732   Batch Acc: 82.81
[Train] Epoch: 1 [393088/620022]    Loss: 0.009143   Batch Acc: 81.25
[Train] Epoch: 1 [393152/620022]    Loss: 0.008784   Batch Acc: 76.56
[Train] Epoch: 1 [393216/620022]    Loss: 0.010556   Batch Acc: 71.88
[Train] Epoch: 1 [393280/620022]    Loss: 0.008548   Batch Acc: 75.00
[Train] Epoch: 1 [393344/620022]    Loss: 0.007700   Batch Acc: 78.12
[Train] Epoch: 1 [393408/620022]    Loss: 0.008263   Batch Acc: 76.56
[Train] Epoch: 1 [393472/620022]    Loss: 0.009054   Batch Acc: 79.69
[Train] Epoch: 1 [393536/620022]    Loss: 0.010946   Batch Acc: 73.44
[Train] Epoch: 1 [393600/620022]    Loss: 0.011103   Batch Acc: 65.62
[Train] Epoch: 1 [393664/620022]    Loss: 0.008059   Batch Acc: 75.00
[Train] Epoch: 1 [393728/620022]    Loss: 0.009764   Batch Acc: 73.44
[Train] Epoch: 1 [393792/620022]    Loss: 0.007538   Batch Acc: 79.69
[Train] Epoch: 1 [393856/620022]    Loss: 0.009117   Batch Acc: 76.56
[Train] Epoch: 1 [393920/620022]    Loss: 0.009193   Batch Acc: 75.00
[Train] Epoch: 1 [393984/620022]    Loss: 0.008677   Batch Acc: 73.44
[Train] Epoch: 1 [394048/620022]    Loss: 0.011864   Batch Acc: 68.75
[Train] Epoch: 1 [394112/620022]    Loss: 0.009715   Batch Acc: 68.75
[Train] Epoch: 1 [394176/620022]    Loss: 0.006740   Batch Acc: 87.50
[Train] Epoch: 1 [394240/620022]    Loss: 0.009345   Batch Acc: 75.00
[Train] Epoch: 1 [394304/620022]    Loss: 0.008703   Batch Acc: 78.12
[Train] Epoch: 1 [394368/620022]    Loss: 0.009405   Batch Acc: 76.56
[Train] Epoch: 1 [394432/620022]    Loss: 0.010594   Batch Acc: 71.88
[Train] Epoch: 1 [394496/620022]    Loss: 0.008463   Batch Acc: 78.12
[Train] Epoch: 1 [394560/620022]    Loss: 0.009496   Batch Acc: 75.00
[Train] Epoch: 1 [394624/620022]    Loss: 0.008119   Batch Acc: 78.12
[Train] Epoch: 1 [394688/620022]    Loss: 0.008453   Batch Acc: 78.12
[Train] Epoch: 1 [394752/620022]    Loss: 0.009478   Batch Acc: 75.00
[Train] Epoch: 1 [394816/620022]    Loss: 0.008388   Batch Acc: 81.25
[Train] Epoch: 1 [394880/620022]    Loss: 0.007746   Batch Acc: 81.25
[Train] Epoch: 1 [394944/620022]    Loss: 0.007699   Batch Acc: 78.12
[Train] Epoch: 1 [395008/620022]    Loss: 0.007195   Batch Acc: 84.38
[Train] Epoch: 1 [395072/620022]    Loss: 0.008645   Batch Acc: 75.00
[Train] Epoch: 1 [395136/620022]    Loss: 0.011299   Batch Acc: 64.06
[Train] Epoch: 1 [395200/620022]    Loss: 0.009501   Batch Acc: 75.00
[Train] Epoch: 1 [395264/620022]    Loss: 0.008891   Batch Acc: 76.56
[Train] Epoch: 1 [395328/620022]    Loss: 0.010225   Batch Acc: 70.31
[Train] Epoch: 1 [395392/620022]    Loss: 0.009409   Batch Acc: 73.44
[Train] Epoch: 1 [395456/620022]    Loss: 0.011153   Batch Acc: 67.19
[Train] Epoch: 1 [395520/620022]    Loss: 0.008680   Batch Acc: 84.38
[Train] Epoch: 1 [395584/620022]    Loss: 0.007497   Batch Acc: 84.38
[Train] Epoch: 1 [395648/620022]    Loss: 0.006933   Batch Acc: 82.81
[Train] Epoch: 1 [395712/620022]    Loss: 0.009119   Batch Acc: 75.00
[Train] Epoch: 1 [395776/620022]    Loss: 0.007466   Batch Acc: 82.81
[Train] Epoch: 1 [395840/620022]    Loss: 0.006980   Batch Acc: 82.81
[Train] Epoch: 1 [395904/620022]    Loss: 0.009905   Batch Acc: 70.31
[Train] Epoch: 1 [395968/620022]    Loss: 0.008632   Batch Acc: 76.56
[Train] Epoch: 1 [396032/620022]    Loss: 0.007508   Batch Acc: 79.69
[Train] Epoch: 1 [396096/620022]    Loss: 0.008188   Batch Acc: 78.12
[Train] Epoch: 1 [396160/620022]    Loss: 0.007065   Batch Acc: 85.94
[Train] Epoch: 1 [396224/620022]    Loss: 0.008274   Batch Acc: 79.69
[Train] Epoch: 1 [396288/620022]    Loss: 0.008441   Batch Acc: 82.81
[Train] Epoch: 1 [396352/620022]    Loss: 0.007047   Batch Acc: 79.69
[Train] Epoch: 1 [396416/620022]    Loss: 0.008915   Batch Acc: 75.00
[Train] Epoch: 1 [396480/620022]    Loss: 0.009879   Batch Acc: 75.00
[Train] Epoch: 1 [396544/620022]    Loss: 0.008744   Batch Acc: 79.69
[Train] Epoch: 1 [396608/620022]    Loss: 0.009819   Batch Acc: 78.12
[Train] Epoch: 1 [396672/620022]    Loss: 0.008092   Batch Acc: 81.25
[Train] Epoch: 1 [396736/620022]    Loss: 0.010003   Batch Acc: 78.12
[Train] Epoch: 1 [396800/620022]    Loss: 0.009608   Batch Acc: 71.88
[Train] Epoch: 1 [396864/620022]    Loss: 0.008552   Batch Acc: 75.00
[Train] Epoch: 1 [396928/620022]    Loss: 0.007147   Batch Acc: 81.25
[Train] Epoch: 1 [396992/620022]    Loss: 0.009191   Batch Acc: 79.69
[Train] Epoch: 1 [397056/620022]    Loss: 0.008141   Batch Acc: 76.56
[Train] Epoch: 1 [397120/620022]    Loss: 0.008755   Batch Acc: 71.88
[Train] Epoch: 1 [397184/620022]    Loss: 0.008950   Batch Acc: 78.12
[Train] Epoch: 1 [397248/620022]    Loss: 0.010313   Batch Acc: 76.56
[Train] Epoch: 1 [397312/620022]    Loss: 0.008408   Batch Acc: 76.56
[Train] Epoch: 1 [397376/620022]    Loss: 0.007488   Batch Acc: 85.94
[Train] Epoch: 1 [397440/620022]    Loss: 0.008811   Batch Acc: 79.69
[Train] Epoch: 1 [397504/620022]    Loss: 0.010801   Batch Acc: 64.06
[Train] Epoch: 1 [397568/620022]    Loss: 0.008544   Batch Acc: 79.69
[Train] Epoch: 1 [397632/620022]    Loss: 0.009650   Batch Acc: 76.56
[Train] Epoch: 1 [397696/620022]    Loss: 0.006945   Batch Acc: 82.81
[Train] Epoch: 1 [397760/620022]    Loss: 0.009071   Batch Acc: 76.56
[Train] Epoch: 1 [397824/620022]    Loss: 0.009881   Batch Acc: 75.00
[Train] Epoch: 1 [397888/620022]    Loss: 0.006911   Batch Acc: 84.38
[Train] Epoch: 1 [397952/620022]    Loss: 0.008235   Batch Acc: 78.12
[Train] Epoch: 1 [398016/620022]    Loss: 0.013107   Batch Acc: 62.50
[Train] Epoch: 1 [398080/620022]    Loss: 0.008783   Batch Acc: 73.44
[Train] Epoch: 1 [398144/620022]    Loss: 0.007573   Batch Acc: 79.69
[Train] Epoch: 1 [398208/620022]    Loss: 0.007878   Batch Acc: 82.81
[Train] Epoch: 1 [398272/620022]    Loss: 0.007941   Batch Acc: 82.81
[Train] Epoch: 1 [398336/620022]    Loss: 0.007748   Batch Acc: 79.69
[Train] Epoch: 1 [398400/620022]    Loss: 0.008071   Batch Acc: 76.56
[Train] Epoch: 1 [398464/620022]    Loss: 0.009225   Batch Acc: 82.81
[Train] Epoch: 1 [398528/620022]    Loss: 0.009079   Batch Acc: 73.44
[Train] Epoch: 1 [398592/620022]    Loss: 0.009994   Batch Acc: 73.44
[Train] Epoch: 1 [398656/620022]    Loss: 0.009667   Batch Acc: 73.44
[Train] Epoch: 1 [398720/620022]    Loss: 0.011391   Batch Acc: 68.75
[Train] Epoch: 1 [398784/620022]    Loss: 0.007764   Batch Acc: 85.94
[Train] Epoch: 1 [398848/620022]    Loss: 0.009886   Batch Acc: 76.56
[Train] Epoch: 1 [398912/620022]    Loss: 0.009895   Batch Acc: 75.00
[Train] Epoch: 1 [398976/620022]    Loss: 0.007920   Batch Acc: 81.25
[Train] Epoch: 1 [399040/620022]    Loss: 0.008793   Batch Acc: 71.88
[Train] Epoch: 1 [399104/620022]    Loss: 0.008610   Batch Acc: 75.00
[Train] Epoch: 1 [399168/620022]    Loss: 0.010538   Batch Acc: 70.31
[Train] Epoch: 1 [399232/620022]    Loss: 0.006931   Batch Acc: 82.81
[Train] Epoch: 1 [399296/620022]    Loss: 0.008277   Batch Acc: 75.00
[Train] Epoch: 1 [399360/620022]    Loss: 0.009627   Batch Acc: 76.56
[Train] Epoch: 1 [399424/620022]    Loss: 0.009475   Batch Acc: 68.75
[Train] Epoch: 1 [399488/620022]    Loss: 0.010185   Batch Acc: 68.75
[Train] Epoch: 1 [399552/620022]    Loss: 0.009547   Batch Acc: 76.56
[Train] Epoch: 1 [399616/620022]    Loss: 0.006736   Batch Acc: 84.38
[Train] Epoch: 1 [399680/620022]    Loss: 0.009794   Batch Acc: 71.88
[Train] Epoch: 1 [399744/620022]    Loss: 0.009480   Batch Acc: 75.00
[Train] Epoch: 1 [399808/620022]    Loss: 0.007906   Batch Acc: 79.69
[Train] Epoch: 1 [399872/620022]    Loss: 0.006282   Batch Acc: 84.38
[Train] Epoch: 1 [399936/620022]    Loss: 0.008733   Batch Acc: 84.38
[Train] Epoch: 1 [400000/620022]    Loss: 0.007972   Batch Acc: 82.81
[Train] Epoch: 1 [400064/620022]    Loss: 0.007509   Batch Acc: 79.69
[Train] Epoch: 1 [400128/620022]    Loss: 0.010462   Batch Acc: 75.00
[Train] Epoch: 1 [400192/620022]    Loss: 0.008269   Batch Acc: 81.25
[Train] Epoch: 1 [400256/620022]    Loss: 0.008351   Batch Acc: 79.69
[Train] Epoch: 1 [400320/620022]    Loss: 0.007419   Batch Acc: 85.94
[Train] Epoch: 1 [400384/620022]    Loss: 0.006382   Batch Acc: 84.38
[Train] Epoch: 1 [400448/620022]    Loss: 0.008662   Batch Acc: 76.56
[Train] Epoch: 1 [400512/620022]    Loss: 0.006116   Batch Acc: 87.50
[Train] Epoch: 1 [400576/620022]    Loss: 0.010419   Batch Acc: 71.88
[Train] Epoch: 1 [400640/620022]    Loss: 0.009424   Batch Acc: 68.75
[Train] Epoch: 1 [400704/620022]    Loss: 0.009669   Batch Acc: 73.44
[Train] Epoch: 1 [400768/620022]    Loss: 0.008348   Batch Acc: 81.25
[Train] Epoch: 1 [400832/620022]    Loss: 0.008305   Batch Acc: 78.12
[Train] Epoch: 1 [400896/620022]    Loss: 0.011054   Batch Acc: 71.88
[Train] Epoch: 1 [400960/620022]    Loss: 0.010636   Batch Acc: 81.25
[Train] Epoch: 1 [401024/620022]    Loss: 0.009455   Batch Acc: 73.44
[Train] Epoch: 1 [401088/620022]    Loss: 0.009256   Batch Acc: 71.88
[Train] Epoch: 1 [401152/620022]    Loss: 0.008767   Batch Acc: 79.69
[Train] Epoch: 1 [401216/620022]    Loss: 0.012044   Batch Acc: 70.31
[Train] Epoch: 1 [401280/620022]    Loss: 0.009328   Batch Acc: 73.44
[Train] Epoch: 1 [401344/620022]    Loss: 0.009123   Batch Acc: 78.12
[Train] Epoch: 1 [401408/620022]    Loss: 0.009559   Batch Acc: 70.31
[Train] Epoch: 1 [401472/620022]    Loss: 0.009969   Batch Acc: 73.44
[Train] Epoch: 1 [401536/620022]    Loss: 0.009847   Batch Acc: 73.44
[Train] Epoch: 1 [401600/620022]    Loss: 0.010904   Batch Acc: 65.62
[Train] Epoch: 1 [401664/620022]    Loss: 0.007168   Batch Acc: 85.94
[Train] Epoch: 1 [401728/620022]    Loss: 0.010382   Batch Acc: 73.44
[Train] Epoch: 1 [401792/620022]    Loss: 0.007382   Batch Acc: 87.50
[Train] Epoch: 1 [401856/620022]    Loss: 0.010380   Batch Acc: 76.56
[Train] Epoch: 1 [401920/620022]    Loss: 0.010560   Batch Acc: 73.44
[Train] Epoch: 1 [401984/620022]    Loss: 0.008375   Batch Acc: 79.69
[Train] Epoch: 1 [402048/620022]    Loss: 0.011777   Batch Acc: 68.75
[Train] Epoch: 1 [402112/620022]    Loss: 0.010227   Batch Acc: 70.31
[Train] Epoch: 1 [402176/620022]    Loss: 0.005727   Batch Acc: 82.81
[Train] Epoch: 1 [402240/620022]    Loss: 0.009532   Batch Acc: 71.88
[Train] Epoch: 1 [402304/620022]    Loss: 0.008662   Batch Acc: 75.00
[Train] Epoch: 1 [402368/620022]    Loss: 0.008931   Batch Acc: 79.69
[Train] Epoch: 1 [402432/620022]    Loss: 0.009639   Batch Acc: 76.56
[Train] Epoch: 1 [402496/620022]    Loss: 0.008536   Batch Acc: 79.69
[Train] Epoch: 1 [402560/620022]    Loss: 0.011259   Batch Acc: 68.75
[Train] Epoch: 1 [402624/620022]    Loss: 0.007484   Batch Acc: 78.12
[Train] Epoch: 1 [402688/620022]    Loss: 0.009553   Batch Acc: 79.69
[Train] Epoch: 1 [402752/620022]    Loss: 0.009298   Batch Acc: 79.69
[Train] Epoch: 1 [402816/620022]    Loss: 0.009677   Batch Acc: 73.44
[Train] Epoch: 1 [402880/620022]    Loss: 0.007876   Batch Acc: 78.12
[Train] Epoch: 1 [402944/620022]    Loss: 0.007479   Batch Acc: 82.81
[Train] Epoch: 1 [403008/620022]    Loss: 0.008907   Batch Acc: 81.25
[Train] Epoch: 1 [403072/620022]    Loss: 0.007695   Batch Acc: 81.25
[Train] Epoch: 1 [403136/620022]    Loss: 0.011815   Batch Acc: 68.75
[Train] Epoch: 1 [403200/620022]    Loss: 0.005103   Batch Acc: 93.75
[Train] Epoch: 1 [403264/620022]    Loss: 0.010120   Batch Acc: 71.88
[Train] Epoch: 1 [403328/620022]    Loss: 0.008992   Batch Acc: 71.88
[Train] Epoch: 1 [403392/620022]    Loss: 0.009117   Batch Acc: 75.00
[Train] Epoch: 1 [403456/620022]    Loss: 0.009112   Batch Acc: 75.00
[Train] Epoch: 1 [403520/620022]    Loss: 0.008987   Batch Acc: 73.44
[Train] Epoch: 1 [403584/620022]    Loss: 0.007779   Batch Acc: 82.81
[Train] Epoch: 1 [403648/620022]    Loss: 0.007992   Batch Acc: 76.56
[Train] Epoch: 1 [403712/620022]    Loss: 0.010558   Batch Acc: 71.88
[Train] Epoch: 1 [403776/620022]    Loss: 0.007214   Batch Acc: 84.38
[Train] Epoch: 1 [403840/620022]    Loss: 0.009369   Batch Acc: 75.00
[Train] Epoch: 1 [403904/620022]    Loss: 0.008701   Batch Acc: 81.25
[Train] Epoch: 1 [403968/620022]    Loss: 0.010494   Batch Acc: 68.75
[Train] Epoch: 1 [404032/620022]    Loss: 0.010504   Batch Acc: 75.00
[Train] Epoch: 1 [404096/620022]    Loss: 0.011006   Batch Acc: 68.75
[Train] Epoch: 1 [404160/620022]    Loss: 0.009099   Batch Acc: 71.88
[Train] Epoch: 1 [404224/620022]    Loss: 0.008960   Batch Acc: 79.69
[Train] Epoch: 1 [404288/620022]    Loss: 0.009186   Batch Acc: 78.12
[Train] Epoch: 1 [404352/620022]    Loss: 0.007306   Batch Acc: 82.81
[Train] Epoch: 1 [404416/620022]    Loss: 0.008298   Batch Acc: 76.56
[Train] Epoch: 1 [404480/620022]    Loss: 0.009670   Batch Acc: 71.88
[Train] Epoch: 1 [404544/620022]    Loss: 0.009018   Batch Acc: 76.56
[Train] Epoch: 1 [404608/620022]    Loss: 0.008388   Batch Acc: 79.69
[Train] Epoch: 1 [404672/620022]    Loss: 0.010447   Batch Acc: 75.00
[Train] Epoch: 1 [404736/620022]    Loss: 0.008604   Batch Acc: 84.38
[Train] Epoch: 1 [404800/620022]    Loss: 0.007310   Batch Acc: 82.81
[Train] Epoch: 1 [404864/620022]    Loss: 0.011439   Batch Acc: 73.44
[Train] Epoch: 1 [404928/620022]    Loss: 0.009163   Batch Acc: 70.31
[Train] Epoch: 1 [404992/620022]    Loss: 0.006723   Batch Acc: 84.38
[Train] Epoch: 1 [405056/620022]    Loss: 0.008264   Batch Acc: 78.12
[Train] Epoch: 1 [405120/620022]    Loss: 0.009359   Batch Acc: 76.56
[Train] Epoch: 1 [405184/620022]    Loss: 0.009017   Batch Acc: 78.12
[Train] Epoch: 1 [405248/620022]    Loss: 0.009275   Batch Acc: 73.44
[Train] Epoch: 1 [405312/620022]    Loss: 0.007736   Batch Acc: 81.25
[Train] Epoch: 1 [405376/620022]    Loss: 0.009793   Batch Acc: 76.56
[Train] Epoch: 1 [405440/620022]    Loss: 0.008630   Batch Acc: 76.56
[Train] Epoch: 1 [405504/620022]    Loss: 0.007971   Batch Acc: 82.81
[Train] Epoch: 1 [405568/620022]    Loss: 0.008341   Batch Acc: 81.25
[Train] Epoch: 1 [405632/620022]    Loss: 0.009056   Batch Acc: 73.44
[Train] Epoch: 1 [405696/620022]    Loss: 0.008272   Batch Acc: 85.94
[Train] Epoch: 1 [405760/620022]    Loss: 0.008827   Batch Acc: 79.69
[Train] Epoch: 1 [405824/620022]    Loss: 0.009091   Batch Acc: 82.81
[Train] Epoch: 1 [405888/620022]    Loss: 0.010813   Batch Acc: 71.88
[Train] Epoch: 1 [405952/620022]    Loss: 0.006429   Batch Acc: 85.94
[Train] Epoch: 1 [406016/620022]    Loss: 0.008534   Batch Acc: 78.12
[Train] Epoch: 1 [406080/620022]    Loss: 0.008878   Batch Acc: 71.88
[Train] Epoch: 1 [406144/620022]    Loss: 0.006264   Batch Acc: 89.06
[Train] Epoch: 1 [406208/620022]    Loss: 0.007758   Batch Acc: 81.25
[Train] Epoch: 1 [406272/620022]    Loss: 0.010914   Batch Acc: 71.88
[Train] Epoch: 1 [406336/620022]    Loss: 0.009768   Batch Acc: 71.88
[Train] Epoch: 1 [406400/620022]    Loss: 0.007503   Batch Acc: 76.56
[Train] Epoch: 1 [406464/620022]    Loss: 0.007244   Batch Acc: 85.94
[Train] Epoch: 1 [406528/620022]    Loss: 0.006924   Batch Acc: 84.38
[Train] Epoch: 1 [406592/620022]    Loss: 0.010254   Batch Acc: 76.56
[Train] Epoch: 1 [406656/620022]    Loss: 0.007524   Batch Acc: 81.25
[Train] Epoch: 1 [406720/620022]    Loss: 0.007419   Batch Acc: 84.38
[Train] Epoch: 1 [406784/620022]    Loss: 0.006506   Batch Acc: 92.19
[Train] Epoch: 1 [406848/620022]    Loss: 0.009126   Batch Acc: 75.00
[Train] Epoch: 1 [406912/620022]    Loss: 0.009995   Batch Acc: 73.44
[Train] Epoch: 1 [406976/620022]    Loss: 0.009953   Batch Acc: 71.88
[Train] Epoch: 1 [407040/620022]    Loss: 0.009956   Batch Acc: 71.88
[Train] Epoch: 1 [407104/620022]    Loss: 0.010375   Batch Acc: 65.62
[Train] Epoch: 1 [407168/620022]    Loss: 0.008960   Batch Acc: 78.12
[Train] Epoch: 1 [407232/620022]    Loss: 0.009573   Batch Acc: 73.44
[Train] Epoch: 1 [407296/620022]    Loss: 0.006764   Batch Acc: 79.69
[Train] Epoch: 1 [407360/620022]    Loss: 0.008043   Batch Acc: 85.94
[Train] Epoch: 1 [407424/620022]    Loss: 0.010621   Batch Acc: 71.88
[Train] Epoch: 1 [407488/620022]    Loss: 0.010031   Batch Acc: 73.44
[Train] Epoch: 1 [407552/620022]    Loss: 0.007464   Batch Acc: 79.69
[Train] Epoch: 1 [407616/620022]    Loss: 0.009479   Batch Acc: 76.56
[Train] Epoch: 1 [407680/620022]    Loss: 0.007641   Batch Acc: 81.25
[Train] Epoch: 1 [407744/620022]    Loss: 0.008031   Batch Acc: 82.81
[Train] Epoch: 1 [407808/620022]    Loss: 0.008891   Batch Acc: 76.56
[Train] Epoch: 1 [407872/620022]    Loss: 0.008606   Batch Acc: 73.44
[Train] Epoch: 1 [407936/620022]    Loss: 0.010564   Batch Acc: 76.56
[Train] Epoch: 1 [408000/620022]    Loss: 0.008557   Batch Acc: 76.56
[Train] Epoch: 1 [408064/620022]    Loss: 0.011019   Batch Acc: 71.88
[Train] Epoch: 1 [408128/620022]    Loss: 0.009563   Batch Acc: 78.12
[Train] Epoch: 1 [408192/620022]    Loss: 0.006438   Batch Acc: 78.12
[Train] Epoch: 1 [408256/620022]    Loss: 0.008158   Batch Acc: 78.12
[Train] Epoch: 1 [408320/620022]    Loss: 0.007997   Batch Acc: 78.12
[Train] Epoch: 1 [408384/620022]    Loss: 0.008656   Batch Acc: 76.56
[Train] Epoch: 1 [408448/620022]    Loss: 0.007462   Batch Acc: 81.25
[Train] Epoch: 1 [408512/620022]    Loss: 0.008397   Batch Acc: 81.25
[Train] Epoch: 1 [408576/620022]    Loss: 0.007864   Batch Acc: 84.38
[Train] Epoch: 1 [408640/620022]    Loss: 0.008993   Batch Acc: 78.12
[Train] Epoch: 1 [408704/620022]    Loss: 0.009491   Batch Acc: 76.56
[Train] Epoch: 1 [408768/620022]    Loss: 0.008228   Batch Acc: 75.00
[Train] Epoch: 1 [408832/620022]    Loss: 0.008223   Batch Acc: 81.25
[Train] Epoch: 1 [408896/620022]    Loss: 0.009309   Batch Acc: 75.00
[Train] Epoch: 1 [408960/620022]    Loss: 0.008966   Batch Acc: 78.12
[Train] Epoch: 1 [409024/620022]    Loss: 0.008965   Batch Acc: 75.00
[Train] Epoch: 1 [409088/620022]    Loss: 0.006702   Batch Acc: 84.38
[Train] Epoch: 1 [409152/620022]    Loss: 0.007826   Batch Acc: 82.81
[Train] Epoch: 1 [409216/620022]    Loss: 0.008204   Batch Acc: 78.12
[Train] Epoch: 1 [409280/620022]    Loss: 0.010118   Batch Acc: 73.44
[Train] Epoch: 1 [409344/620022]    Loss: 0.009316   Batch Acc: 73.44
[Train] Epoch: 1 [409408/620022]    Loss: 0.008796   Batch Acc: 76.56
[Train] Epoch: 1 [409472/620022]    Loss: 0.008942   Batch Acc: 78.12
[Train] Epoch: 1 [409536/620022]    Loss: 0.009390   Batch Acc: 81.25
[Train] Epoch: 1 [409600/620022]    Loss: 0.008417   Batch Acc: 75.00
[Train] Epoch: 1 [409664/620022]    Loss: 0.008336   Batch Acc: 79.69
[Train] Epoch: 1 [409728/620022]    Loss: 0.009339   Batch Acc: 73.44
[Train] Epoch: 1 [409792/620022]    Loss: 0.007583   Batch Acc: 82.81
[Train] Epoch: 1 [409856/620022]    Loss: 0.008486   Batch Acc: 73.44
[Train] Epoch: 1 [409920/620022]    Loss: 0.010412   Batch Acc: 68.75
[Train] Epoch: 1 [409984/620022]    Loss: 0.008037   Batch Acc: 71.88
[Train] Epoch: 1 [410048/620022]    Loss: 0.008792   Batch Acc: 73.44
[Train] Epoch: 1 [410112/620022]    Loss: 0.011109   Batch Acc: 68.75
[Train] Epoch: 1 [410176/620022]    Loss: 0.006786   Batch Acc: 85.94
[Train] Epoch: 1 [410240/620022]    Loss: 0.008640   Batch Acc: 78.12
[Train] Epoch: 1 [410304/620022]    Loss: 0.007450   Batch Acc: 76.56
[Train] Epoch: 1 [410368/620022]    Loss: 0.007167   Batch Acc: 84.38
[Train] Epoch: 1 [410432/620022]    Loss: 0.008343   Batch Acc: 78.12
[Train] Epoch: 1 [410496/620022]    Loss: 0.006965   Batch Acc: 82.81
[Train] Epoch: 1 [410560/620022]    Loss: 0.009137   Batch Acc: 76.56
[Train] Epoch: 1 [410624/620022]    Loss: 0.009097   Batch Acc: 70.31
[Train] Epoch: 1 [410688/620022]    Loss: 0.007670   Batch Acc: 79.69
[Train] Epoch: 1 [410752/620022]    Loss: 0.008973   Batch Acc: 81.25
[Train] Epoch: 1 [410816/620022]    Loss: 0.010419   Batch Acc: 70.31
[Train] Epoch: 1 [410880/620022]    Loss: 0.008466   Batch Acc: 76.56
[Train] Epoch: 1 [410944/620022]    Loss: 0.006945   Batch Acc: 82.81
[Train] Epoch: 1 [411008/620022]    Loss: 0.009500   Batch Acc: 71.88
[Train] Epoch: 1 [411072/620022]    Loss: 0.007301   Batch Acc: 81.25
[Train] Epoch: 1 [411136/620022]    Loss: 0.007816   Batch Acc: 84.38
[Train] Epoch: 1 [411200/620022]    Loss: 0.007610   Batch Acc: 84.38
[Train] Epoch: 1 [411264/620022]    Loss: 0.008513   Batch Acc: 81.25
[Train] Epoch: 1 [411328/620022]    Loss: 0.009648   Batch Acc: 75.00
[Train] Epoch: 1 [411392/620022]    Loss: 0.007738   Batch Acc: 82.81
[Train] Epoch: 1 [411456/620022]    Loss: 0.007501   Batch Acc: 84.38
[Train] Epoch: 1 [411520/620022]    Loss: 0.009558   Batch Acc: 79.69
[Train] Epoch: 1 [411584/620022]    Loss: 0.008698   Batch Acc: 78.12
[Train] Epoch: 1 [411648/620022]    Loss: 0.007096   Batch Acc: 81.25
[Train] Epoch: 1 [411712/620022]    Loss: 0.010068   Batch Acc: 71.88
[Train] Epoch: 1 [411776/620022]    Loss: 0.010166   Batch Acc: 76.56
[Train] Epoch: 1 [411840/620022]    Loss: 0.009038   Batch Acc: 76.56
[Train] Epoch: 1 [411904/620022]    Loss: 0.008513   Batch Acc: 75.00
[Train] Epoch: 1 [411968/620022]    Loss: 0.008718   Batch Acc: 75.00
[Train] Epoch: 1 [412032/620022]    Loss: 0.009746   Batch Acc: 75.00
[Train] Epoch: 1 [412096/620022]    Loss: 0.010045   Batch Acc: 73.44
[Train] Epoch: 1 [412160/620022]    Loss: 0.010363   Batch Acc: 75.00
[Train] Epoch: 1 [412224/620022]    Loss: 0.009446   Batch Acc: 81.25
[Train] Epoch: 1 [412288/620022]    Loss: 0.007596   Batch Acc: 75.00
[Train] Epoch: 1 [412352/620022]    Loss: 0.007646   Batch Acc: 85.94
[Train] Epoch: 1 [412416/620022]    Loss: 0.010182   Batch Acc: 70.31
[Train] Epoch: 1 [412480/620022]    Loss: 0.006803   Batch Acc: 89.06
[Train] Epoch: 1 [412544/620022]    Loss: 0.008260   Batch Acc: 75.00
[Train] Epoch: 1 [412608/620022]    Loss: 0.008998   Batch Acc: 71.88
[Train] Epoch: 1 [412672/620022]    Loss: 0.010965   Batch Acc: 68.75
[Train] Epoch: 1 [412736/620022]    Loss: 0.009699   Batch Acc: 70.31
[Train] Epoch: 1 [412800/620022]    Loss: 0.008907   Batch Acc: 78.12
[Train] Epoch: 1 [412864/620022]    Loss: 0.008403   Batch Acc: 79.69
[Train] Epoch: 1 [412928/620022]    Loss: 0.008621   Batch Acc: 78.12
[Train] Epoch: 1 [412992/620022]    Loss: 0.008306   Batch Acc: 73.44
[Train] Epoch: 1 [413056/620022]    Loss: 0.008079   Batch Acc: 84.38
[Train] Epoch: 1 [413120/620022]    Loss: 0.008494   Batch Acc: 76.56
[Train] Epoch: 1 [413184/620022]    Loss: 0.007182   Batch Acc: 84.38
[Train] Epoch: 1 [413248/620022]    Loss: 0.007768   Batch Acc: 78.12
[Train] Epoch: 1 [413312/620022]    Loss: 0.011715   Batch Acc: 68.75
[Train] Epoch: 1 [413376/620022]    Loss: 0.008918   Batch Acc: 78.12
[Train] Epoch: 1 [413440/620022]    Loss: 0.008832   Batch Acc: 76.56
[Train] Epoch: 1 [413504/620022]    Loss: 0.008734   Batch Acc: 81.25
[Train] Epoch: 1 [413568/620022]    Loss: 0.008880   Batch Acc: 81.25
[Train] Epoch: 1 [413632/620022]    Loss: 0.009131   Batch Acc: 71.88
[Train] Epoch: 1 [413696/620022]    Loss: 0.007928   Batch Acc: 79.69
[Train] Epoch: 1 [413760/620022]    Loss: 0.010099   Batch Acc: 75.00
[Train] Epoch: 1 [413824/620022]    Loss: 0.007963   Batch Acc: 84.38
[Train] Epoch: 1 [413888/620022]    Loss: 0.009810   Batch Acc: 68.75
[Train] Epoch: 1 [413952/620022]    Loss: 0.009638   Batch Acc: 78.12
[Train] Epoch: 1 [414016/620022]    Loss: 0.008489   Batch Acc: 81.25
[Train] Epoch: 1 [414080/620022]    Loss: 0.009216   Batch Acc: 76.56
[Train] Epoch: 1 [414144/620022]    Loss: 0.008189   Batch Acc: 81.25
[Train] Epoch: 1 [414208/620022]    Loss: 0.008981   Batch Acc: 78.12
[Train] Epoch: 1 [414272/620022]    Loss: 0.009161   Batch Acc: 76.56
[Train] Epoch: 1 [414336/620022]    Loss: 0.007264   Batch Acc: 82.81
[Train] Epoch: 1 [414400/620022]    Loss: 0.008815   Batch Acc: 76.56
[Train] Epoch: 1 [414464/620022]    Loss: 0.009398   Batch Acc: 76.56
[Train] Epoch: 1 [414528/620022]    Loss: 0.010261   Batch Acc: 71.88
[Train] Epoch: 1 [414592/620022]    Loss: 0.007251   Batch Acc: 85.94
[Train] Epoch: 1 [414656/620022]    Loss: 0.007620   Batch Acc: 78.12
[Train] Epoch: 1 [414720/620022]    Loss: 0.008033   Batch Acc: 75.00
[Train] Epoch: 1 [414784/620022]    Loss: 0.008374   Batch Acc: 81.25
[Train] Epoch: 1 [414848/620022]    Loss: 0.010205   Batch Acc: 68.75
[Train] Epoch: 1 [414912/620022]    Loss: 0.007910   Batch Acc: 79.69
[Train] Epoch: 1 [414976/620022]    Loss: 0.010297   Batch Acc: 68.75
[Train] Epoch: 1 [415040/620022]    Loss: 0.006688   Batch Acc: 82.81
[Train] Epoch: 1 [415104/620022]    Loss: 0.008512   Batch Acc: 79.69
[Train] Epoch: 1 [415168/620022]    Loss: 0.007263   Batch Acc: 82.81
[Train] Epoch: 1 [415232/620022]    Loss: 0.007777   Batch Acc: 76.56
[Train] Epoch: 1 [415296/620022]    Loss: 0.008735   Batch Acc: 85.94
[Train] Epoch: 1 [415360/620022]    Loss: 0.011299   Batch Acc: 71.88
[Train] Epoch: 1 [415424/620022]    Loss: 0.007669   Batch Acc: 79.69
[Train] Epoch: 1 [415488/620022]    Loss: 0.008993   Batch Acc: 82.81
[Train] Epoch: 1 [415552/620022]    Loss: 0.007851   Batch Acc: 78.12
[Train] Epoch: 1 [415616/620022]    Loss: 0.009773   Batch Acc: 73.44
[Train] Epoch: 1 [415680/620022]    Loss: 0.008073   Batch Acc: 81.25
[Train] Epoch: 1 [415744/620022]    Loss: 0.008143   Batch Acc: 76.56
[Train] Epoch: 1 [415808/620022]    Loss: 0.008481   Batch Acc: 73.44
[Train] Epoch: 1 [415872/620022]    Loss: 0.007491   Batch Acc: 78.12
[Train] Epoch: 1 [415936/620022]    Loss: 0.006973   Batch Acc: 78.12
[Train] Epoch: 1 [416000/620022]    Loss: 0.007468   Batch Acc: 79.69
[Train] Epoch: 1 [416064/620022]    Loss: 0.009862   Batch Acc: 76.56
[Train] Epoch: 1 [416128/620022]    Loss: 0.007675   Batch Acc: 81.25
[Train] Epoch: 1 [416192/620022]    Loss: 0.007005   Batch Acc: 82.81
[Train] Epoch: 1 [416256/620022]    Loss: 0.008845   Batch Acc: 81.25
[Train] Epoch: 1 [416320/620022]    Loss: 0.007291   Batch Acc: 78.12
[Train] Epoch: 1 [416384/620022]    Loss: 0.009523   Batch Acc: 75.00
[Train] Epoch: 1 [416448/620022]    Loss: 0.010052   Batch Acc: 76.56
[Train] Epoch: 1 [416512/620022]    Loss: 0.009534   Batch Acc: 76.56
[Train] Epoch: 1 [416576/620022]    Loss: 0.010004   Batch Acc: 76.56
[Train] Epoch: 1 [416640/620022]    Loss: 0.010102   Batch Acc: 75.00
[Train] Epoch: 1 [416704/620022]    Loss: 0.009091   Batch Acc: 73.44
[Train] Epoch: 1 [416768/620022]    Loss: 0.009363   Batch Acc: 78.12
[Train] Epoch: 1 [416832/620022]    Loss: 0.008647   Batch Acc: 79.69
[Train] Epoch: 1 [416896/620022]    Loss: 0.008551   Batch Acc: 78.12
[Train] Epoch: 1 [416960/620022]    Loss: 0.006294   Batch Acc: 82.81
[Train] Epoch: 1 [417024/620022]    Loss: 0.008495   Batch Acc: 78.12
[Train] Epoch: 1 [417088/620022]    Loss: 0.008854   Batch Acc: 73.44
[Train] Epoch: 1 [417152/620022]    Loss: 0.008638   Batch Acc: 71.88
[Train] Epoch: 1 [417216/620022]    Loss: 0.008140   Batch Acc: 78.12
[Train] Epoch: 1 [417280/620022]    Loss: 0.009443   Batch Acc: 79.69
[Train] Epoch: 1 [417344/620022]    Loss: 0.008365   Batch Acc: 78.12
[Train] Epoch: 1 [417408/620022]    Loss: 0.007895   Batch Acc: 79.69
[Train] Epoch: 1 [417472/620022]    Loss: 0.010896   Batch Acc: 71.88
[Train] Epoch: 1 [417536/620022]    Loss: 0.008091   Batch Acc: 75.00
[Train] Epoch: 1 [417600/620022]    Loss: 0.007998   Batch Acc: 78.12
[Train] Epoch: 1 [417664/620022]    Loss: 0.009012   Batch Acc: 75.00
[Train] Epoch: 1 [417728/620022]    Loss: 0.010075   Batch Acc: 71.88
[Train] Epoch: 1 [417792/620022]    Loss: 0.009132   Batch Acc: 71.88
[Train] Epoch: 1 [417856/620022]    Loss: 0.010666   Batch Acc: 70.31
[Train] Epoch: 1 [417920/620022]    Loss: 0.006074   Batch Acc: 87.50
[Train] Epoch: 1 [417984/620022]    Loss: 0.007648   Batch Acc: 81.25
[Train] Epoch: 1 [418048/620022]    Loss: 0.007046   Batch Acc: 81.25
[Train] Epoch: 1 [418112/620022]    Loss: 0.007239   Batch Acc: 79.69
[Train] Epoch: 1 [418176/620022]    Loss: 0.009636   Batch Acc: 79.69
[Train] Epoch: 1 [418240/620022]    Loss: 0.009580   Batch Acc: 68.75
[Train] Epoch: 1 [418304/620022]    Loss: 0.007636   Batch Acc: 81.25
[Train] Epoch: 1 [418368/620022]    Loss: 0.011774   Batch Acc: 68.75
[Train] Epoch: 1 [418432/620022]    Loss: 0.010563   Batch Acc: 70.31
[Train] Epoch: 1 [418496/620022]    Loss: 0.009554   Batch Acc: 73.44
[Train] Epoch: 1 [418560/620022]    Loss: 0.008390   Batch Acc: 79.69
[Train] Epoch: 1 [418624/620022]    Loss: 0.008302   Batch Acc: 76.56
[Train] Epoch: 1 [418688/620022]    Loss: 0.009248   Batch Acc: 76.56
[Train] Epoch: 1 [418752/620022]    Loss: 0.008326   Batch Acc: 79.69
[Train] Epoch: 1 [418816/620022]    Loss: 0.006766   Batch Acc: 84.38
[Train] Epoch: 1 [418880/620022]    Loss: 0.009350   Batch Acc: 71.88
[Train] Epoch: 1 [418944/620022]    Loss: 0.009187   Batch Acc: 78.12
[Train] Epoch: 1 [419008/620022]    Loss: 0.011261   Batch Acc: 71.88
[Train] Epoch: 1 [419072/620022]    Loss: 0.011388   Batch Acc: 75.00
[Train] Epoch: 1 [419136/620022]    Loss: 0.008267   Batch Acc: 79.69
[Train] Epoch: 1 [419200/620022]    Loss: 0.009884   Batch Acc: 73.44
[Train] Epoch: 1 [419264/620022]    Loss: 0.009110   Batch Acc: 78.12
[Train] Epoch: 1 [419328/620022]    Loss: 0.006013   Batch Acc: 92.19
[Train] Epoch: 1 [419392/620022]    Loss: 0.005989   Batch Acc: 82.81
[Train] Epoch: 1 [419456/620022]    Loss: 0.010343   Batch Acc: 75.00
[Train] Epoch: 1 [419520/620022]    Loss: 0.010672   Batch Acc: 73.44
[Train] Epoch: 1 [419584/620022]    Loss: 0.008141   Batch Acc: 84.38
[Train] Epoch: 1 [419648/620022]    Loss: 0.009435   Batch Acc: 71.88
[Train] Epoch: 1 [419712/620022]    Loss: 0.010118   Batch Acc: 76.56
[Train] Epoch: 1 [419776/620022]    Loss: 0.009080   Batch Acc: 78.12
[Train] Epoch: 1 [419840/620022]    Loss: 0.008353   Batch Acc: 78.12
[Train] Epoch: 1 [419904/620022]    Loss: 0.007386   Batch Acc: 81.25
[Train] Epoch: 1 [419968/620022]    Loss: 0.008073   Batch Acc: 81.25
[Train] Epoch: 1 [420032/620022]    Loss: 0.008844   Batch Acc: 75.00
[Train] Epoch: 1 [420096/620022]    Loss: 0.010954   Batch Acc: 65.62
[Train] Epoch: 1 [420160/620022]    Loss: 0.009672   Batch Acc: 71.88
[Train] Epoch: 1 [420224/620022]    Loss: 0.009274   Batch Acc: 71.88
[Train] Epoch: 1 [420288/620022]    Loss: 0.008991   Batch Acc: 71.88
[Train] Epoch: 1 [420352/620022]    Loss: 0.010076   Batch Acc: 75.00
[Train] Epoch: 1 [420416/620022]    Loss: 0.009449   Batch Acc: 70.31
[Train] Epoch: 1 [420480/620022]    Loss: 0.007886   Batch Acc: 78.12
[Train] Epoch: 1 [420544/620022]    Loss: 0.007566   Batch Acc: 79.69
[Train] Epoch: 1 [420608/620022]    Loss: 0.008781   Batch Acc: 78.12
[Train] Epoch: 1 [420672/620022]    Loss: 0.012747   Batch Acc: 68.75
[Train] Epoch: 1 [420736/620022]    Loss: 0.008815   Batch Acc: 81.25
[Train] Epoch: 1 [420800/620022]    Loss: 0.007528   Batch Acc: 82.81
[Train] Epoch: 1 [420864/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 1 [420928/620022]    Loss: 0.007720   Batch Acc: 78.12
[Train] Epoch: 1 [420992/620022]    Loss: 0.007604   Batch Acc: 79.69
[Train] Epoch: 1 [421056/620022]    Loss: 0.006674   Batch Acc: 87.50
[Train] Epoch: 1 [421120/620022]    Loss: 0.008916   Batch Acc: 79.69
[Train] Epoch: 1 [421184/620022]    Loss: 0.010210   Batch Acc: 75.00
[Train] Epoch: 1 [421248/620022]    Loss: 0.008681   Batch Acc: 73.44
[Train] Epoch: 1 [421312/620022]    Loss: 0.010672   Batch Acc: 75.00
[Train] Epoch: 1 [421376/620022]    Loss: 0.009952   Batch Acc: 73.44
[Train] Epoch: 1 [421440/620022]    Loss: 0.010023   Batch Acc: 75.00
[Train] Epoch: 1 [421504/620022]    Loss: 0.008609   Batch Acc: 73.44
[Train] Epoch: 1 [421568/620022]    Loss: 0.007312   Batch Acc: 81.25
[Train] Epoch: 1 [421632/620022]    Loss: 0.007942   Batch Acc: 76.56
[Train] Epoch: 1 [421696/620022]    Loss: 0.007344   Batch Acc: 79.69
[Train] Epoch: 1 [421760/620022]    Loss: 0.008859   Batch Acc: 76.56
[Train] Epoch: 1 [421824/620022]    Loss: 0.008383   Batch Acc: 79.69
[Train] Epoch: 1 [421888/620022]    Loss: 0.008036   Batch Acc: 78.12
[Train] Epoch: 1 [421952/620022]    Loss: 0.007239   Batch Acc: 81.25
[Train] Epoch: 1 [422016/620022]    Loss: 0.009777   Batch Acc: 79.69
[Train] Epoch: 1 [422080/620022]    Loss: 0.008373   Batch Acc: 75.00
[Train] Epoch: 1 [422144/620022]    Loss: 0.008526   Batch Acc: 76.56
[Train] Epoch: 1 [422208/620022]    Loss: 0.007056   Batch Acc: 82.81
[Train] Epoch: 1 [422272/620022]    Loss: 0.009473   Batch Acc: 75.00
[Train] Epoch: 1 [422336/620022]    Loss: 0.010559   Batch Acc: 73.44
[Train] Epoch: 1 [422400/620022]    Loss: 0.008650   Batch Acc: 81.25
[Train] Epoch: 1 [422464/620022]    Loss: 0.007954   Batch Acc: 78.12
[Train] Epoch: 1 [422528/620022]    Loss: 0.008157   Batch Acc: 75.00
[Train] Epoch: 1 [422592/620022]    Loss: 0.009540   Batch Acc: 76.56
[Train] Epoch: 1 [422656/620022]    Loss: 0.008435   Batch Acc: 78.12
[Train] Epoch: 1 [422720/620022]    Loss: 0.008590   Batch Acc: 76.56
[Train] Epoch: 1 [422784/620022]    Loss: 0.009984   Batch Acc: 76.56
[Train] Epoch: 1 [422848/620022]    Loss: 0.008159   Batch Acc: 78.12
[Train] Epoch: 1 [422912/620022]    Loss: 0.012010   Batch Acc: 64.06
[Train] Epoch: 1 [422976/620022]    Loss: 0.008265   Batch Acc: 84.38
[Train] Epoch: 1 [423040/620022]    Loss: 0.009015   Batch Acc: 76.56
[Train] Epoch: 1 [423104/620022]    Loss: 0.009143   Batch Acc: 78.12
[Train] Epoch: 1 [423168/620022]    Loss: 0.009112   Batch Acc: 73.44
[Train] Epoch: 1 [423232/620022]    Loss: 0.009574   Batch Acc: 78.12
[Train] Epoch: 1 [423296/620022]    Loss: 0.009992   Batch Acc: 71.88
[Train] Epoch: 1 [423360/620022]    Loss: 0.007929   Batch Acc: 79.69
[Train] Epoch: 1 [423424/620022]    Loss: 0.007334   Batch Acc: 85.94
[Train] Epoch: 1 [423488/620022]    Loss: 0.008548   Batch Acc: 76.56
[Train] Epoch: 1 [423552/620022]    Loss: 0.009389   Batch Acc: 70.31
[Train] Epoch: 1 [423616/620022]    Loss: 0.011987   Batch Acc: 67.19
[Train] Epoch: 1 [423680/620022]    Loss: 0.012082   Batch Acc: 64.06
[Train] Epoch: 1 [423744/620022]    Loss: 0.009242   Batch Acc: 81.25
[Train] Epoch: 1 [423808/620022]    Loss: 0.010195   Batch Acc: 67.19
[Train] Epoch: 1 [423872/620022]    Loss: 0.006908   Batch Acc: 81.25
[Train] Epoch: 1 [423936/620022]    Loss: 0.007213   Batch Acc: 82.81
[Train] Epoch: 1 [424000/620022]    Loss: 0.009898   Batch Acc: 75.00
[Train] Epoch: 1 [424064/620022]    Loss: 0.010148   Batch Acc: 75.00
[Train] Epoch: 1 [424128/620022]    Loss: 0.011331   Batch Acc: 70.31
[Train] Epoch: 1 [424192/620022]    Loss: 0.007530   Batch Acc: 82.81
[Train] Epoch: 1 [424256/620022]    Loss: 0.008721   Batch Acc: 73.44
[Train] Epoch: 1 [424320/620022]    Loss: 0.008321   Batch Acc: 76.56
[Train] Epoch: 1 [424384/620022]    Loss: 0.007055   Batch Acc: 79.69
[Train] Epoch: 1 [424448/620022]    Loss: 0.009425   Batch Acc: 76.56
[Train] Epoch: 1 [424512/620022]    Loss: 0.009268   Batch Acc: 78.12
[Train] Epoch: 1 [424576/620022]    Loss: 0.013131   Batch Acc: 64.06
[Train] Epoch: 1 [424640/620022]    Loss: 0.008423   Batch Acc: 76.56
[Train] Epoch: 1 [424704/620022]    Loss: 0.010518   Batch Acc: 71.88
[Train] Epoch: 1 [424768/620022]    Loss: 0.010264   Batch Acc: 75.00
[Train] Epoch: 1 [424832/620022]    Loss: 0.010459   Batch Acc: 70.31
[Train] Epoch: 1 [424896/620022]    Loss: 0.010865   Batch Acc: 68.75
[Train] Epoch: 1 [424960/620022]    Loss: 0.009769   Batch Acc: 73.44
[Train] Epoch: 1 [425024/620022]    Loss: 0.011470   Batch Acc: 70.31
[Train] Epoch: 1 [425088/620022]    Loss: 0.009083   Batch Acc: 79.69
[Train] Epoch: 1 [425152/620022]    Loss: 0.009397   Batch Acc: 70.31
[Train] Epoch: 1 [425216/620022]    Loss: 0.009215   Batch Acc: 76.56
[Train] Epoch: 1 [425280/620022]    Loss: 0.008314   Batch Acc: 81.25
[Train] Epoch: 1 [425344/620022]    Loss: 0.008427   Batch Acc: 78.12
[Train] Epoch: 1 [425408/620022]    Loss: 0.010553   Batch Acc: 78.12
[Train] Epoch: 1 [425472/620022]    Loss: 0.009982   Batch Acc: 70.31
[Train] Epoch: 1 [425536/620022]    Loss: 0.007406   Batch Acc: 84.38
[Train] Epoch: 1 [425600/620022]    Loss: 0.009181   Batch Acc: 76.56
[Train] Epoch: 1 [425664/620022]    Loss: 0.008553   Batch Acc: 76.56
[Train] Epoch: 1 [425728/620022]    Loss: 0.007691   Batch Acc: 84.38
[Train] Epoch: 1 [425792/620022]    Loss: 0.007107   Batch Acc: 75.00
[Train] Epoch: 1 [425856/620022]    Loss: 0.008660   Batch Acc: 75.00
[Train] Epoch: 1 [425920/620022]    Loss: 0.011637   Batch Acc: 68.75
[Train] Epoch: 1 [425984/620022]    Loss: 0.009776   Batch Acc: 73.44
[Train] Epoch: 1 [426048/620022]    Loss: 0.008307   Batch Acc: 82.81
[Train] Epoch: 1 [426112/620022]    Loss: 0.008738   Batch Acc: 82.81
[Train] Epoch: 1 [426176/620022]    Loss: 0.008192   Batch Acc: 81.25
[Train] Epoch: 1 [426240/620022]    Loss: 0.006545   Batch Acc: 78.12
[Train] Epoch: 1 [426304/620022]    Loss: 0.009345   Batch Acc: 75.00
[Train] Epoch: 1 [426368/620022]    Loss: 0.008143   Batch Acc: 76.56
[Train] Epoch: 1 [426432/620022]    Loss: 0.009427   Batch Acc: 78.12
[Train] Epoch: 1 [426496/620022]    Loss: 0.009981   Batch Acc: 75.00
[Train] Epoch: 1 [426560/620022]    Loss: 0.008356   Batch Acc: 76.56
[Train] Epoch: 1 [426624/620022]    Loss: 0.008511   Batch Acc: 84.38
[Train] Epoch: 1 [426688/620022]    Loss: 0.008588   Batch Acc: 76.56
[Train] Epoch: 1 [426752/620022]    Loss: 0.007311   Batch Acc: 87.50
[Train] Epoch: 1 [426816/620022]    Loss: 0.010843   Batch Acc: 68.75
[Train] Epoch: 1 [426880/620022]    Loss: 0.009347   Batch Acc: 73.44
[Train] Epoch: 1 [426944/620022]    Loss: 0.009223   Batch Acc: 76.56
[Train] Epoch: 1 [427008/620022]    Loss: 0.007451   Batch Acc: 81.25
[Train] Epoch: 1 [427072/620022]    Loss: 0.007746   Batch Acc: 81.25
[Train] Epoch: 1 [427136/620022]    Loss: 0.008230   Batch Acc: 79.69
[Train] Epoch: 1 [427200/620022]    Loss: 0.012517   Batch Acc: 65.62
[Train] Epoch: 1 [427264/620022]    Loss: 0.007211   Batch Acc: 82.81
[Train] Epoch: 1 [427328/620022]    Loss: 0.008861   Batch Acc: 76.56
[Train] Epoch: 1 [427392/620022]    Loss: 0.007654   Batch Acc: 84.38
[Train] Epoch: 1 [427456/620022]    Loss: 0.007137   Batch Acc: 87.50
[Train] Epoch: 1 [427520/620022]    Loss: 0.009346   Batch Acc: 73.44
[Train] Epoch: 1 [427584/620022]    Loss: 0.007800   Batch Acc: 79.69
[Train] Epoch: 1 [427648/620022]    Loss: 0.008506   Batch Acc: 76.56
[Train] Epoch: 1 [427712/620022]    Loss: 0.009358   Batch Acc: 73.44
[Train] Epoch: 1 [427776/620022]    Loss: 0.008702   Batch Acc: 82.81
[Train] Epoch: 1 [427840/620022]    Loss: 0.006642   Batch Acc: 82.81
[Train] Epoch: 1 [427904/620022]    Loss: 0.008500   Batch Acc: 85.94
[Train] Epoch: 1 [427968/620022]    Loss: 0.009259   Batch Acc: 76.56
[Train] Epoch: 1 [428032/620022]    Loss: 0.008284   Batch Acc: 81.25
[Train] Epoch: 1 [428096/620022]    Loss: 0.007829   Batch Acc: 76.56
[Train] Epoch: 1 [428160/620022]    Loss: 0.007903   Batch Acc: 81.25
[Train] Epoch: 1 [428224/620022]    Loss: 0.008284   Batch Acc: 79.69
[Train] Epoch: 1 [428288/620022]    Loss: 0.007549   Batch Acc: 79.69
[Train] Epoch: 1 [428352/620022]    Loss: 0.007656   Batch Acc: 84.38
[Train] Epoch: 1 [428416/620022]    Loss: 0.008651   Batch Acc: 78.12
[Train] Epoch: 1 [428480/620022]    Loss: 0.009179   Batch Acc: 84.38
[Train] Epoch: 1 [428544/620022]    Loss: 0.010167   Batch Acc: 76.56
[Train] Epoch: 1 [428608/620022]    Loss: 0.008466   Batch Acc: 78.12
[Train] Epoch: 1 [428672/620022]    Loss: 0.008002   Batch Acc: 84.38
[Train] Epoch: 1 [428736/620022]    Loss: 0.007720   Batch Acc: 82.81
[Train] Epoch: 1 [428800/620022]    Loss: 0.009227   Batch Acc: 78.12
[Train] Epoch: 1 [428864/620022]    Loss: 0.006755   Batch Acc: 87.50
[Train] Epoch: 1 [428928/620022]    Loss: 0.008140   Batch Acc: 79.69
[Train] Epoch: 1 [428992/620022]    Loss: 0.006436   Batch Acc: 87.50
[Train] Epoch: 1 [429056/620022]    Loss: 0.009478   Batch Acc: 70.31
[Train] Epoch: 1 [429120/620022]    Loss: 0.008956   Batch Acc: 75.00
[Train] Epoch: 1 [429184/620022]    Loss: 0.006430   Batch Acc: 87.50
[Train] Epoch: 1 [429248/620022]    Loss: 0.007892   Batch Acc: 79.69
[Train] Epoch: 1 [429312/620022]    Loss: 0.007866   Batch Acc: 82.81
[Train] Epoch: 1 [429376/620022]    Loss: 0.007349   Batch Acc: 81.25
[Train] Epoch: 1 [429440/620022]    Loss: 0.009776   Batch Acc: 71.88
[Train] Epoch: 1 [429504/620022]    Loss: 0.009521   Batch Acc: 81.25
[Train] Epoch: 1 [429568/620022]    Loss: 0.007337   Batch Acc: 85.94
[Train] Epoch: 1 [429632/620022]    Loss: 0.009118   Batch Acc: 75.00
[Train] Epoch: 1 [429696/620022]    Loss: 0.008932   Batch Acc: 76.56
[Train] Epoch: 1 [429760/620022]    Loss: 0.006768   Batch Acc: 85.94
[Train] Epoch: 1 [429824/620022]    Loss: 0.009430   Batch Acc: 73.44
[Train] Epoch: 1 [429888/620022]    Loss: 0.008776   Batch Acc: 78.12
[Train] Epoch: 1 [429952/620022]    Loss: 0.008165   Batch Acc: 79.69
[Train] Epoch: 1 [430016/620022]    Loss: 0.008940   Batch Acc: 82.81
[Train] Epoch: 1 [430080/620022]    Loss: 0.010746   Batch Acc: 76.56
[Train] Epoch: 1 [430144/620022]    Loss: 0.007363   Batch Acc: 84.38
[Train] Epoch: 1 [430208/620022]    Loss: 0.011126   Batch Acc: 68.75
[Train] Epoch: 1 [430272/620022]    Loss: 0.011382   Batch Acc: 62.50
[Train] Epoch: 1 [430336/620022]    Loss: 0.008315   Batch Acc: 78.12
[Train] Epoch: 1 [430400/620022]    Loss: 0.007073   Batch Acc: 87.50
[Train] Epoch: 1 [430464/620022]    Loss: 0.010495   Batch Acc: 71.88
[Train] Epoch: 1 [430528/620022]    Loss: 0.010980   Batch Acc: 70.31
[Train] Epoch: 1 [430592/620022]    Loss: 0.010934   Batch Acc: 70.31
[Train] Epoch: 1 [430656/620022]    Loss: 0.007610   Batch Acc: 84.38
[Train] Epoch: 1 [430720/620022]    Loss: 0.008638   Batch Acc: 76.56
[Train] Epoch: 1 [430784/620022]    Loss: 0.009106   Batch Acc: 78.12
[Train] Epoch: 1 [430848/620022]    Loss: 0.009589   Batch Acc: 78.12
[Train] Epoch: 1 [430912/620022]    Loss: 0.010443   Batch Acc: 78.12
[Train] Epoch: 1 [430976/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 1 [431040/620022]    Loss: 0.007144   Batch Acc: 79.69
[Train] Epoch: 1 [431104/620022]    Loss: 0.009755   Batch Acc: 75.00
[Train] Epoch: 1 [431168/620022]    Loss: 0.007637   Batch Acc: 79.69
[Train] Epoch: 1 [431232/620022]    Loss: 0.008122   Batch Acc: 76.56
[Train] Epoch: 1 [431296/620022]    Loss: 0.008119   Batch Acc: 79.69
[Train] Epoch: 1 [431360/620022]    Loss: 0.008693   Batch Acc: 75.00
[Train] Epoch: 1 [431424/620022]    Loss: 0.009246   Batch Acc: 82.81
[Train] Epoch: 1 [431488/620022]    Loss: 0.006583   Batch Acc: 82.81
[Train] Epoch: 1 [431552/620022]    Loss: 0.009711   Batch Acc: 71.88
[Train] Epoch: 1 [431616/620022]    Loss: 0.009247   Batch Acc: 70.31
[Train] Epoch: 1 [431680/620022]    Loss: 0.009357   Batch Acc: 71.88
[Train] Epoch: 1 [431744/620022]    Loss: 0.009253   Batch Acc: 75.00
[Train] Epoch: 1 [431808/620022]    Loss: 0.008859   Batch Acc: 78.12
[Train] Epoch: 1 [431872/620022]    Loss: 0.010762   Batch Acc: 67.19
[Train] Epoch: 1 [431936/620022]    Loss: 0.006374   Batch Acc: 84.38
[Train] Epoch: 1 [432000/620022]    Loss: 0.010895   Batch Acc: 65.62
[Train] Epoch: 1 [432064/620022]    Loss: 0.008606   Batch Acc: 75.00
[Train] Epoch: 1 [432128/620022]    Loss: 0.009823   Batch Acc: 71.88
[Train] Epoch: 1 [432192/620022]    Loss: 0.008006   Batch Acc: 75.00
[Train] Epoch: 1 [432256/620022]    Loss: 0.011139   Batch Acc: 76.56
[Train] Epoch: 1 [432320/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 1 [432384/620022]    Loss: 0.008057   Batch Acc: 81.25
[Train] Epoch: 1 [432448/620022]    Loss: 0.009355   Batch Acc: 78.12
[Train] Epoch: 1 [432512/620022]    Loss: 0.006879   Batch Acc: 82.81
[Train] Epoch: 1 [432576/620022]    Loss: 0.009036   Batch Acc: 81.25
[Train] Epoch: 1 [432640/620022]    Loss: 0.010441   Batch Acc: 67.19
[Train] Epoch: 1 [432704/620022]    Loss: 0.008215   Batch Acc: 81.25
[Train] Epoch: 1 [432768/620022]    Loss: 0.008193   Batch Acc: 84.38
[Train] Epoch: 1 [432832/620022]    Loss: 0.008196   Batch Acc: 76.56
[Train] Epoch: 1 [432896/620022]    Loss: 0.008499   Batch Acc: 76.56
[Train] Epoch: 1 [432960/620022]    Loss: 0.009785   Batch Acc: 76.56
[Train] Epoch: 1 [433024/620022]    Loss: 0.006847   Batch Acc: 82.81
[Train] Epoch: 1 [433088/620022]    Loss: 0.007586   Batch Acc: 78.12
[Train] Epoch: 1 [433152/620022]    Loss: 0.008756   Batch Acc: 79.69
[Train] Epoch: 1 [433216/620022]    Loss: 0.006575   Batch Acc: 84.38
[Train] Epoch: 1 [433280/620022]    Loss: 0.006414   Batch Acc: 81.25
[Train] Epoch: 1 [433344/620022]    Loss: 0.010348   Batch Acc: 71.88
[Train] Epoch: 1 [433408/620022]    Loss: 0.010205   Batch Acc: 73.44
[Train] Epoch: 1 [433472/620022]    Loss: 0.010214   Batch Acc: 78.12
[Train] Epoch: 1 [433536/620022]    Loss: 0.010039   Batch Acc: 73.44
[Train] Epoch: 1 [433600/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 1 [433664/620022]    Loss: 0.007908   Batch Acc: 78.12
[Train] Epoch: 1 [433728/620022]    Loss: 0.007887   Batch Acc: 78.12
[Train] Epoch: 1 [433792/620022]    Loss: 0.011403   Batch Acc: 73.44
[Train] Epoch: 1 [433856/620022]    Loss: 0.009166   Batch Acc: 75.00
[Train] Epoch: 1 [433920/620022]    Loss: 0.008339   Batch Acc: 78.12
[Train] Epoch: 1 [433984/620022]    Loss: 0.011305   Batch Acc: 75.00
[Train] Epoch: 1 [434048/620022]    Loss: 0.006505   Batch Acc: 82.81
[Train] Epoch: 1 [434112/620022]    Loss: 0.010146   Batch Acc: 71.88
[Train] Epoch: 1 [434176/620022]    Loss: 0.010407   Batch Acc: 71.88
[Train] Epoch: 1 [434240/620022]    Loss: 0.007663   Batch Acc: 79.69
[Train] Epoch: 1 [434304/620022]    Loss: 0.009118   Batch Acc: 79.69
[Train] Epoch: 1 [434368/620022]    Loss: 0.011674   Batch Acc: 73.44
[Train] Epoch: 1 [434432/620022]    Loss: 0.009879   Batch Acc: 78.12
[Train] Epoch: 1 [434496/620022]    Loss: 0.008738   Batch Acc: 78.12
[Train] Epoch: 1 [434560/620022]    Loss: 0.008736   Batch Acc: 84.38
[Train] Epoch: 1 [434624/620022]    Loss: 0.008366   Batch Acc: 76.56
[Train] Epoch: 1 [434688/620022]    Loss: 0.008378   Batch Acc: 81.25
[Train] Epoch: 1 [434752/620022]    Loss: 0.010099   Batch Acc: 73.44
[Train] Epoch: 1 [434816/620022]    Loss: 0.013084   Batch Acc: 70.31
[Train] Epoch: 1 [434880/620022]    Loss: 0.009554   Batch Acc: 78.12
[Train] Epoch: 1 [434944/620022]    Loss: 0.009732   Batch Acc: 76.56
[Train] Epoch: 1 [435008/620022]    Loss: 0.011202   Batch Acc: 71.88
[Train] Epoch: 1 [435072/620022]    Loss: 0.008583   Batch Acc: 73.44
[Train] Epoch: 1 [435136/620022]    Loss: 0.007598   Batch Acc: 79.69
[Train] Epoch: 1 [435200/620022]    Loss: 0.008321   Batch Acc: 75.00
[Train] Epoch: 1 [435264/620022]    Loss: 0.007444   Batch Acc: 87.50
[Train] Epoch: 1 [435328/620022]    Loss: 0.008394   Batch Acc: 76.56
[Train] Epoch: 1 [435392/620022]    Loss: 0.007349   Batch Acc: 85.94
[Train] Epoch: 1 [435456/620022]    Loss: 0.009187   Batch Acc: 76.56
[Train] Epoch: 1 [435520/620022]    Loss: 0.010751   Batch Acc: 73.44
[Train] Epoch: 1 [435584/620022]    Loss: 0.007662   Batch Acc: 78.12
[Train] Epoch: 1 [435648/620022]    Loss: 0.007753   Batch Acc: 82.81
[Train] Epoch: 1 [435712/620022]    Loss: 0.007549   Batch Acc: 79.69
[Train] Epoch: 1 [435776/620022]    Loss: 0.006254   Batch Acc: 87.50
[Train] Epoch: 1 [435840/620022]    Loss: 0.006911   Batch Acc: 89.06
[Train] Epoch: 1 [435904/620022]    Loss: 0.007388   Batch Acc: 81.25
[Train] Epoch: 1 [435968/620022]    Loss: 0.008750   Batch Acc: 76.56
[Train] Epoch: 1 [436032/620022]    Loss: 0.007442   Batch Acc: 82.81
[Train] Epoch: 1 [436096/620022]    Loss: 0.008153   Batch Acc: 82.81
[Train] Epoch: 1 [436160/620022]    Loss: 0.006690   Batch Acc: 85.94
[Train] Epoch: 1 [436224/620022]    Loss: 0.008086   Batch Acc: 85.94
[Train] Epoch: 1 [436288/620022]    Loss: 0.010559   Batch Acc: 70.31
[Train] Epoch: 1 [436352/620022]    Loss: 0.008987   Batch Acc: 75.00
[Train] Epoch: 1 [436416/620022]    Loss: 0.007340   Batch Acc: 82.81
[Train] Epoch: 1 [436480/620022]    Loss: 0.006796   Batch Acc: 85.94
[Train] Epoch: 1 [436544/620022]    Loss: 0.008514   Batch Acc: 78.12
[Train] Epoch: 1 [436608/620022]    Loss: 0.007263   Batch Acc: 75.00
[Train] Epoch: 1 [436672/620022]    Loss: 0.007893   Batch Acc: 75.00
[Train] Epoch: 1 [436736/620022]    Loss: 0.009750   Batch Acc: 75.00
[Train] Epoch: 1 [436800/620022]    Loss: 0.007632   Batch Acc: 79.69
[Train] Epoch: 1 [436864/620022]    Loss: 0.007721   Batch Acc: 78.12
[Train] Epoch: 1 [436928/620022]    Loss: 0.009255   Batch Acc: 79.69
[Train] Epoch: 1 [436992/620022]    Loss: 0.009797   Batch Acc: 71.88
[Train] Epoch: 1 [437056/620022]    Loss: 0.007303   Batch Acc: 81.25
[Train] Epoch: 1 [437120/620022]    Loss: 0.008785   Batch Acc: 78.12
[Train] Epoch: 1 [437184/620022]    Loss: 0.007841   Batch Acc: 81.25
[Train] Epoch: 1 [437248/620022]    Loss: 0.007944   Batch Acc: 73.44
[Train] Epoch: 1 [437312/620022]    Loss: 0.006972   Batch Acc: 84.38
[Train] Epoch: 1 [437376/620022]    Loss: 0.006850   Batch Acc: 84.38
[Train] Epoch: 1 [437440/620022]    Loss: 0.007825   Batch Acc: 82.81
[Train] Epoch: 1 [437504/620022]    Loss: 0.008103   Batch Acc: 73.44
[Train] Epoch: 1 [437568/620022]    Loss: 0.010278   Batch Acc: 73.44
[Train] Epoch: 1 [437632/620022]    Loss: 0.010305   Batch Acc: 73.44
[Train] Epoch: 1 [437696/620022]    Loss: 0.007746   Batch Acc: 76.56
[Train] Epoch: 1 [437760/620022]    Loss: 0.007686   Batch Acc: 79.69
[Train] Epoch: 1 [437824/620022]    Loss: 0.007341   Batch Acc: 79.69
[Train] Epoch: 1 [437888/620022]    Loss: 0.008462   Batch Acc: 78.12
[Train] Epoch: 1 [437952/620022]    Loss: 0.008237   Batch Acc: 78.12
[Train] Epoch: 1 [438016/620022]    Loss: 0.008267   Batch Acc: 79.69
[Train] Epoch: 1 [438080/620022]    Loss: 0.008372   Batch Acc: 76.56
[Train] Epoch: 1 [438144/620022]    Loss: 0.008245   Batch Acc: 81.25
[Train] Epoch: 1 [438208/620022]    Loss: 0.007372   Batch Acc: 79.69
[Train] Epoch: 1 [438272/620022]    Loss: 0.008158   Batch Acc: 76.56
[Train] Epoch: 1 [438336/620022]    Loss: 0.007211   Batch Acc: 87.50
[Train] Epoch: 1 [438400/620022]    Loss: 0.011269   Batch Acc: 67.19
[Train] Epoch: 1 [438464/620022]    Loss: 0.005769   Batch Acc: 85.94
[Train] Epoch: 1 [438528/620022]    Loss: 0.009820   Batch Acc: 78.12
[Train] Epoch: 1 [438592/620022]    Loss: 0.005515   Batch Acc: 85.94
[Train] Epoch: 1 [438656/620022]    Loss: 0.008148   Batch Acc: 78.12
[Train] Epoch: 1 [438720/620022]    Loss: 0.007047   Batch Acc: 79.69
[Train] Epoch: 1 [438784/620022]    Loss: 0.008677   Batch Acc: 82.81
[Train] Epoch: 1 [438848/620022]    Loss: 0.008949   Batch Acc: 81.25
[Train] Epoch: 1 [438912/620022]    Loss: 0.007760   Batch Acc: 81.25
[Train] Epoch: 1 [438976/620022]    Loss: 0.007503   Batch Acc: 82.81
[Train] Epoch: 1 [439040/620022]    Loss: 0.007691   Batch Acc: 82.81
[Train] Epoch: 1 [439104/620022]    Loss: 0.011940   Batch Acc: 71.88
[Train] Epoch: 1 [439168/620022]    Loss: 0.008318   Batch Acc: 82.81
[Train] Epoch: 1 [439232/620022]    Loss: 0.008656   Batch Acc: 73.44
[Train] Epoch: 1 [439296/620022]    Loss: 0.010005   Batch Acc: 71.88
[Train] Epoch: 1 [439360/620022]    Loss: 0.007356   Batch Acc: 82.81
[Train] Epoch: 1 [439424/620022]    Loss: 0.008832   Batch Acc: 70.31
[Train] Epoch: 1 [439488/620022]    Loss: 0.009394   Batch Acc: 76.56
[Train] Epoch: 1 [439552/620022]    Loss: 0.008052   Batch Acc: 79.69
[Train] Epoch: 1 [439616/620022]    Loss: 0.008212   Batch Acc: 75.00
[Train] Epoch: 1 [439680/620022]    Loss: 0.008260   Batch Acc: 81.25
[Train] Epoch: 1 [439744/620022]    Loss: 0.006918   Batch Acc: 81.25
[Train] Epoch: 1 [439808/620022]    Loss: 0.007549   Batch Acc: 81.25
[Train] Epoch: 1 [439872/620022]    Loss: 0.009019   Batch Acc: 76.56
[Train] Epoch: 1 [439936/620022]    Loss: 0.009888   Batch Acc: 75.00
[Train] Epoch: 1 [440000/620022]    Loss: 0.009222   Batch Acc: 68.75
[Train] Epoch: 1 [440064/620022]    Loss: 0.008347   Batch Acc: 76.56
[Train] Epoch: 1 [440128/620022]    Loss: 0.006434   Batch Acc: 85.94
[Train] Epoch: 1 [440192/620022]    Loss: 0.008155   Batch Acc: 75.00
[Train] Epoch: 1 [440256/620022]    Loss: 0.009420   Batch Acc: 76.56
[Train] Epoch: 1 [440320/620022]    Loss: 0.007750   Batch Acc: 81.25
[Train] Epoch: 1 [440384/620022]    Loss: 0.009137   Batch Acc: 75.00
[Train] Epoch: 1 [440448/620022]    Loss: 0.009508   Batch Acc: 71.88
[Train] Epoch: 1 [440512/620022]    Loss: 0.007726   Batch Acc: 76.56
[Train] Epoch: 1 [440576/620022]    Loss: 0.006635   Batch Acc: 84.38
[Train] Epoch: 1 [440640/620022]    Loss: 0.009801   Batch Acc: 75.00
[Train] Epoch: 1 [440704/620022]    Loss: 0.009448   Batch Acc: 71.88
[Train] Epoch: 1 [440768/620022]    Loss: 0.007393   Batch Acc: 79.69
[Train] Epoch: 1 [440832/620022]    Loss: 0.007272   Batch Acc: 76.56
[Train] Epoch: 1 [440896/620022]    Loss: 0.008563   Batch Acc: 76.56
[Train] Epoch: 1 [440960/620022]    Loss: 0.007588   Batch Acc: 84.38
[Train] Epoch: 1 [441024/620022]    Loss: 0.007445   Batch Acc: 78.12
[Train] Epoch: 1 [441088/620022]    Loss: 0.007486   Batch Acc: 82.81
[Train] Epoch: 1 [441152/620022]    Loss: 0.008493   Batch Acc: 81.25
[Train] Epoch: 1 [441216/620022]    Loss: 0.008060   Batch Acc: 81.25
[Train] Epoch: 1 [441280/620022]    Loss: 0.007525   Batch Acc: 78.12
[Train] Epoch: 1 [441344/620022]    Loss: 0.007515   Batch Acc: 82.81
[Train] Epoch: 1 [441408/620022]    Loss: 0.007593   Batch Acc: 79.69
[Train] Epoch: 1 [441472/620022]    Loss: 0.007759   Batch Acc: 79.69
[Train] Epoch: 1 [441536/620022]    Loss: 0.011009   Batch Acc: 73.44
[Train] Epoch: 1 [441600/620022]    Loss: 0.007435   Batch Acc: 82.81
[Train] Epoch: 1 [441664/620022]    Loss: 0.007928   Batch Acc: 78.12
[Train] Epoch: 1 [441728/620022]    Loss: 0.008935   Batch Acc: 73.44
[Train] Epoch: 1 [441792/620022]    Loss: 0.008021   Batch Acc: 81.25
[Train] Epoch: 1 [441856/620022]    Loss: 0.009613   Batch Acc: 82.81
[Train] Epoch: 1 [441920/620022]    Loss: 0.009537   Batch Acc: 73.44
[Train] Epoch: 1 [441984/620022]    Loss: 0.007600   Batch Acc: 81.25
[Train] Epoch: 1 [442048/620022]    Loss: 0.008155   Batch Acc: 78.12
[Train] Epoch: 1 [442112/620022]    Loss: 0.010166   Batch Acc: 75.00
[Train] Epoch: 1 [442176/620022]    Loss: 0.008817   Batch Acc: 81.25
[Train] Epoch: 1 [442240/620022]    Loss: 0.009464   Batch Acc: 79.69
[Train] Epoch: 1 [442304/620022]    Loss: 0.007250   Batch Acc: 84.38
[Train] Epoch: 1 [442368/620022]    Loss: 0.007534   Batch Acc: 81.25
[Train] Epoch: 1 [442432/620022]    Loss: 0.009213   Batch Acc: 71.88
[Train] Epoch: 1 [442496/620022]    Loss: 0.008640   Batch Acc: 76.56
[Train] Epoch: 1 [442560/620022]    Loss: 0.007461   Batch Acc: 84.38
[Train] Epoch: 1 [442624/620022]    Loss: 0.007873   Batch Acc: 78.12
[Train] Epoch: 1 [442688/620022]    Loss: 0.009697   Batch Acc: 78.12
[Train] Epoch: 1 [442752/620022]    Loss: 0.007683   Batch Acc: 84.38
[Train] Epoch: 1 [442816/620022]    Loss: 0.008226   Batch Acc: 81.25
[Train] Epoch: 1 [442880/620022]    Loss: 0.008602   Batch Acc: 76.56
[Train] Epoch: 1 [442944/620022]    Loss: 0.008103   Batch Acc: 82.81
[Train] Epoch: 1 [443008/620022]    Loss: 0.010071   Batch Acc: 70.31
[Train] Epoch: 1 [443072/620022]    Loss: 0.008527   Batch Acc: 78.12
[Train] Epoch: 1 [443136/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 1 [443200/620022]    Loss: 0.010656   Batch Acc: 68.75
[Train] Epoch: 1 [443264/620022]    Loss: 0.008957   Batch Acc: 81.25
[Train] Epoch: 1 [443328/620022]    Loss: 0.010526   Batch Acc: 65.62
[Train] Epoch: 1 [443392/620022]    Loss: 0.006866   Batch Acc: 82.81
[Train] Epoch: 1 [443456/620022]    Loss: 0.011067   Batch Acc: 68.75
[Train] Epoch: 1 [443520/620022]    Loss: 0.008265   Batch Acc: 85.94
[Train] Epoch: 1 [443584/620022]    Loss: 0.009276   Batch Acc: 71.88
[Train] Epoch: 1 [443648/620022]    Loss: 0.008873   Batch Acc: 71.88
[Train] Epoch: 1 [443712/620022]    Loss: 0.009710   Batch Acc: 76.56
[Train] Epoch: 1 [443776/620022]    Loss: 0.008263   Batch Acc: 79.69
[Train] Epoch: 1 [443840/620022]    Loss: 0.009798   Batch Acc: 71.88
[Train] Epoch: 1 [443904/620022]    Loss: 0.010914   Batch Acc: 67.19
[Train] Epoch: 1 [443968/620022]    Loss: 0.007311   Batch Acc: 81.25
[Train] Epoch: 1 [444032/620022]    Loss: 0.006832   Batch Acc: 82.81
[Train] Epoch: 1 [444096/620022]    Loss: 0.008159   Batch Acc: 76.56
[Train] Epoch: 1 [444160/620022]    Loss: 0.006129   Batch Acc: 84.38
[Train] Epoch: 1 [444224/620022]    Loss: 0.009407   Batch Acc: 70.31
[Train] Epoch: 1 [444288/620022]    Loss: 0.007488   Batch Acc: 76.56
[Train] Epoch: 1 [444352/620022]    Loss: 0.010160   Batch Acc: 70.31
[Train] Epoch: 1 [444416/620022]    Loss: 0.007896   Batch Acc: 81.25
[Train] Epoch: 1 [444480/620022]    Loss: 0.009904   Batch Acc: 67.19
[Train] Epoch: 1 [444544/620022]    Loss: 0.008463   Batch Acc: 85.94
[Train] Epoch: 1 [444608/620022]    Loss: 0.007379   Batch Acc: 81.25
[Train] Epoch: 1 [444672/620022]    Loss: 0.008121   Batch Acc: 81.25
[Train] Epoch: 1 [444736/620022]    Loss: 0.010227   Batch Acc: 67.19
[Train] Epoch: 1 [444800/620022]    Loss: 0.010148   Batch Acc: 76.56
[Train] Epoch: 1 [444864/620022]    Loss: 0.010529   Batch Acc: 73.44
[Train] Epoch: 1 [444928/620022]    Loss: 0.007365   Batch Acc: 85.94
[Train] Epoch: 1 [444992/620022]    Loss: 0.008144   Batch Acc: 82.81
[Train] Epoch: 1 [445056/620022]    Loss: 0.010349   Batch Acc: 65.62
[Train] Epoch: 1 [445120/620022]    Loss: 0.006735   Batch Acc: 84.38
[Train] Epoch: 1 [445184/620022]    Loss: 0.006777   Batch Acc: 85.94
[Train] Epoch: 1 [445248/620022]    Loss: 0.008630   Batch Acc: 78.12
[Train] Epoch: 1 [445312/620022]    Loss: 0.007426   Batch Acc: 76.56
[Train] Epoch: 1 [445376/620022]    Loss: 0.007942   Batch Acc: 78.12
[Train] Epoch: 1 [445440/620022]    Loss: 0.008861   Batch Acc: 70.31
[Train] Epoch: 1 [445504/620022]    Loss: 0.010241   Batch Acc: 76.56
[Train] Epoch: 1 [445568/620022]    Loss: 0.011543   Batch Acc: 67.19
[Train] Epoch: 1 [445632/620022]    Loss: 0.008807   Batch Acc: 79.69
[Train] Epoch: 1 [445696/620022]    Loss: 0.007612   Batch Acc: 78.12
[Train] Epoch: 1 [445760/620022]    Loss: 0.007715   Batch Acc: 82.81
[Train] Epoch: 1 [445824/620022]    Loss: 0.007773   Batch Acc: 79.69
[Train] Epoch: 1 [445888/620022]    Loss: 0.011577   Batch Acc: 60.94
[Train] Epoch: 1 [445952/620022]    Loss: 0.008117   Batch Acc: 78.12
[Train] Epoch: 1 [446016/620022]    Loss: 0.008151   Batch Acc: 78.12
[Train] Epoch: 1 [446080/620022]    Loss: 0.009175   Batch Acc: 75.00
[Train] Epoch: 1 [446144/620022]    Loss: 0.006602   Batch Acc: 84.38
[Train] Epoch: 1 [446208/620022]    Loss: 0.009112   Batch Acc: 76.56
[Train] Epoch: 1 [446272/620022]    Loss: 0.010634   Batch Acc: 73.44
[Train] Epoch: 1 [446336/620022]    Loss: 0.010286   Batch Acc: 71.88
[Train] Epoch: 1 [446400/620022]    Loss: 0.011332   Batch Acc: 70.31
[Train] Epoch: 1 [446464/620022]    Loss: 0.006437   Batch Acc: 82.81
[Train] Epoch: 1 [446528/620022]    Loss: 0.009723   Batch Acc: 76.56
[Train] Epoch: 1 [446592/620022]    Loss: 0.009146   Batch Acc: 75.00
[Train] Epoch: 1 [446656/620022]    Loss: 0.010364   Batch Acc: 68.75
[Train] Epoch: 1 [446720/620022]    Loss: 0.007144   Batch Acc: 82.81
[Train] Epoch: 1 [446784/620022]    Loss: 0.009926   Batch Acc: 71.88
[Train] Epoch: 1 [446848/620022]    Loss: 0.008414   Batch Acc: 75.00
[Train] Epoch: 1 [446912/620022]    Loss: 0.008270   Batch Acc: 79.69
[Train] Epoch: 1 [446976/620022]    Loss: 0.005985   Batch Acc: 82.81
[Train] Epoch: 1 [447040/620022]    Loss: 0.009999   Batch Acc: 76.56
[Train] Epoch: 1 [447104/620022]    Loss: 0.010235   Batch Acc: 75.00
[Train] Epoch: 1 [447168/620022]    Loss: 0.009139   Batch Acc: 73.44
[Train] Epoch: 1 [447232/620022]    Loss: 0.008908   Batch Acc: 81.25
[Train] Epoch: 1 [447296/620022]    Loss: 0.009547   Batch Acc: 70.31
[Train] Epoch: 1 [447360/620022]    Loss: 0.009277   Batch Acc: 76.56
[Train] Epoch: 1 [447424/620022]    Loss: 0.010127   Batch Acc: 70.31
[Train] Epoch: 1 [447488/620022]    Loss: 0.008890   Batch Acc: 82.81
[Train] Epoch: 1 [447552/620022]    Loss: 0.006883   Batch Acc: 85.94
[Train] Epoch: 1 [447616/620022]    Loss: 0.010553   Batch Acc: 71.88
[Train] Epoch: 1 [447680/620022]    Loss: 0.008530   Batch Acc: 78.12
[Train] Epoch: 1 [447744/620022]    Loss: 0.006548   Batch Acc: 78.12
[Train] Epoch: 1 [447808/620022]    Loss: 0.008048   Batch Acc: 73.44
[Train] Epoch: 1 [447872/620022]    Loss: 0.007962   Batch Acc: 76.56
[Train] Epoch: 1 [447936/620022]    Loss: 0.008008   Batch Acc: 78.12
[Train] Epoch: 1 [448000/620022]    Loss: 0.010703   Batch Acc: 75.00
[Train] Epoch: 1 [448064/620022]    Loss: 0.008253   Batch Acc: 75.00
[Train] Epoch: 1 [448128/620022]    Loss: 0.011645   Batch Acc: 70.31
[Train] Epoch: 1 [448192/620022]    Loss: 0.010855   Batch Acc: 71.88
[Train] Epoch: 1 [448256/620022]    Loss: 0.008783   Batch Acc: 78.12
[Train] Epoch: 1 [448320/620022]    Loss: 0.008181   Batch Acc: 76.56
[Train] Epoch: 1 [448384/620022]    Loss: 0.010159   Batch Acc: 76.56
[Train] Epoch: 1 [448448/620022]    Loss: 0.006601   Batch Acc: 84.38
[Train] Epoch: 1 [448512/620022]    Loss: 0.007058   Batch Acc: 85.94
[Train] Epoch: 1 [448576/620022]    Loss: 0.009734   Batch Acc: 81.25
[Train] Epoch: 1 [448640/620022]    Loss: 0.007108   Batch Acc: 81.25
[Train] Epoch: 1 [448704/620022]    Loss: 0.010115   Batch Acc: 78.12
[Train] Epoch: 1 [448768/620022]    Loss: 0.007868   Batch Acc: 75.00
[Train] Epoch: 1 [448832/620022]    Loss: 0.008981   Batch Acc: 75.00
[Train] Epoch: 1 [448896/620022]    Loss: 0.009660   Batch Acc: 73.44
[Train] Epoch: 1 [448960/620022]    Loss: 0.009208   Batch Acc: 81.25
[Train] Epoch: 1 [449024/620022]    Loss: 0.007967   Batch Acc: 84.38
[Train] Epoch: 1 [449088/620022]    Loss: 0.009017   Batch Acc: 79.69
[Train] Epoch: 1 [449152/620022]    Loss: 0.007964   Batch Acc: 78.12
[Train] Epoch: 1 [449216/620022]    Loss: 0.006462   Batch Acc: 87.50
[Train] Epoch: 1 [449280/620022]    Loss: 0.009687   Batch Acc: 75.00
[Train] Epoch: 1 [449344/620022]    Loss: 0.006817   Batch Acc: 82.81
[Train] Epoch: 1 [449408/620022]    Loss: 0.008482   Batch Acc: 81.25
[Train] Epoch: 1 [449472/620022]    Loss: 0.008273   Batch Acc: 82.81
[Train] Epoch: 1 [449536/620022]    Loss: 0.006145   Batch Acc: 87.50
[Train] Epoch: 1 [449600/620022]    Loss: 0.008560   Batch Acc: 79.69
[Train] Epoch: 1 [449664/620022]    Loss: 0.012535   Batch Acc: 68.75
[Train] Epoch: 1 [449728/620022]    Loss: 0.009923   Batch Acc: 75.00
[Train] Epoch: 1 [449792/620022]    Loss: 0.011561   Batch Acc: 68.75
[Train] Epoch: 1 [449856/620022]    Loss: 0.008276   Batch Acc: 78.12
[Train] Epoch: 1 [449920/620022]    Loss: 0.008430   Batch Acc: 75.00
[Train] Epoch: 1 [449984/620022]    Loss: 0.008013   Batch Acc: 76.56
[Train] Epoch: 1 [450048/620022]    Loss: 0.009983   Batch Acc: 71.88
[Train] Epoch: 1 [450112/620022]    Loss: 0.007920   Batch Acc: 84.38
[Train] Epoch: 1 [450176/620022]    Loss: 0.008309   Batch Acc: 85.94
[Train] Epoch: 1 [450240/620022]    Loss: 0.007602   Batch Acc: 82.81
[Train] Epoch: 1 [450304/620022]    Loss: 0.009364   Batch Acc: 76.56
[Train] Epoch: 1 [450368/620022]    Loss: 0.007815   Batch Acc: 81.25
[Train] Epoch: 1 [450432/620022]    Loss: 0.009276   Batch Acc: 67.19
[Train] Epoch: 1 [450496/620022]    Loss: 0.009590   Batch Acc: 75.00
[Train] Epoch: 1 [450560/620022]    Loss: 0.008594   Batch Acc: 76.56
[Train] Epoch: 1 [450624/620022]    Loss: 0.008126   Batch Acc: 84.38
[Train] Epoch: 1 [450688/620022]    Loss: 0.007534   Batch Acc: 82.81
[Train] Epoch: 1 [450752/620022]    Loss: 0.008595   Batch Acc: 81.25
[Train] Epoch: 1 [450816/620022]    Loss: 0.005312   Batch Acc: 87.50
[Train] Epoch: 1 [450880/620022]    Loss: 0.007847   Batch Acc: 85.94
[Train] Epoch: 1 [450944/620022]    Loss: 0.010933   Batch Acc: 64.06
[Train] Epoch: 1 [451008/620022]    Loss: 0.008646   Batch Acc: 81.25
[Train] Epoch: 1 [451072/620022]    Loss: 0.010018   Batch Acc: 75.00
[Train] Epoch: 1 [451136/620022]    Loss: 0.007804   Batch Acc: 79.69
[Train] Epoch: 1 [451200/620022]    Loss: 0.007771   Batch Acc: 79.69
[Train] Epoch: 1 [451264/620022]    Loss: 0.007410   Batch Acc: 79.69
[Train] Epoch: 1 [451328/620022]    Loss: 0.010737   Batch Acc: 70.31
[Train] Epoch: 1 [451392/620022]    Loss: 0.008204   Batch Acc: 76.56
[Train] Epoch: 1 [451456/620022]    Loss: 0.007808   Batch Acc: 82.81
[Train] Epoch: 1 [451520/620022]    Loss: 0.009084   Batch Acc: 76.56
[Train] Epoch: 1 [451584/620022]    Loss: 0.008154   Batch Acc: 84.38
[Train] Epoch: 1 [451648/620022]    Loss: 0.009098   Batch Acc: 73.44
[Train] Epoch: 1 [451712/620022]    Loss: 0.008742   Batch Acc: 73.44
[Train] Epoch: 1 [451776/620022]    Loss: 0.008969   Batch Acc: 75.00
[Train] Epoch: 1 [451840/620022]    Loss: 0.007525   Batch Acc: 85.94
[Train] Epoch: 1 [451904/620022]    Loss: 0.007712   Batch Acc: 82.81
[Train] Epoch: 1 [451968/620022]    Loss: 0.007787   Batch Acc: 82.81
[Train] Epoch: 1 [452032/620022]    Loss: 0.009930   Batch Acc: 70.31
[Train] Epoch: 1 [452096/620022]    Loss: 0.008351   Batch Acc: 81.25
[Train] Epoch: 1 [452160/620022]    Loss: 0.009478   Batch Acc: 79.69
[Train] Epoch: 1 [452224/620022]    Loss: 0.009591   Batch Acc: 78.12
[Train] Epoch: 1 [452288/620022]    Loss: 0.009941   Batch Acc: 68.75
[Train] Epoch: 1 [452352/620022]    Loss: 0.007985   Batch Acc: 76.56
[Train] Epoch: 1 [452416/620022]    Loss: 0.008765   Batch Acc: 78.12
[Train] Epoch: 1 [452480/620022]    Loss: 0.007630   Batch Acc: 78.12
[Train] Epoch: 1 [452544/620022]    Loss: 0.006997   Batch Acc: 81.25
[Train] Epoch: 1 [452608/620022]    Loss: 0.007762   Batch Acc: 78.12
[Train] Epoch: 1 [452672/620022]    Loss: 0.008319   Batch Acc: 78.12
[Train] Epoch: 1 [452736/620022]    Loss: 0.007776   Batch Acc: 78.12
[Train] Epoch: 1 [452800/620022]    Loss: 0.008144   Batch Acc: 76.56
[Train] Epoch: 1 [452864/620022]    Loss: 0.008829   Batch Acc: 79.69
[Train] Epoch: 1 [452928/620022]    Loss: 0.008667   Batch Acc: 79.69
[Train] Epoch: 1 [452992/620022]    Loss: 0.011111   Batch Acc: 75.00
[Train] Epoch: 1 [453056/620022]    Loss: 0.007733   Batch Acc: 79.69
[Train] Epoch: 1 [453120/620022]    Loss: 0.008733   Batch Acc: 84.38
[Train] Epoch: 1 [453184/620022]    Loss: 0.009449   Batch Acc: 76.56
[Train] Epoch: 1 [453248/620022]    Loss: 0.009978   Batch Acc: 64.06
[Train] Epoch: 1 [453312/620022]    Loss: 0.008643   Batch Acc: 79.69
[Train] Epoch: 1 [453376/620022]    Loss: 0.010169   Batch Acc: 76.56
[Train] Epoch: 1 [453440/620022]    Loss: 0.008850   Batch Acc: 75.00
[Train] Epoch: 1 [453504/620022]    Loss: 0.008718   Batch Acc: 73.44
[Train] Epoch: 1 [453568/620022]    Loss: 0.009270   Batch Acc: 76.56
[Train] Epoch: 1 [453632/620022]    Loss: 0.007864   Batch Acc: 81.25
[Train] Epoch: 1 [453696/620022]    Loss: 0.007495   Batch Acc: 85.94
[Train] Epoch: 1 [453760/620022]    Loss: 0.007794   Batch Acc: 75.00
[Train] Epoch: 1 [453824/620022]    Loss: 0.009597   Batch Acc: 78.12
[Train] Epoch: 1 [453888/620022]    Loss: 0.005515   Batch Acc: 89.06
[Train] Epoch: 1 [453952/620022]    Loss: 0.009180   Batch Acc: 81.25
[Train] Epoch: 1 [454016/620022]    Loss: 0.007846   Batch Acc: 85.94
[Train] Epoch: 1 [454080/620022]    Loss: 0.008514   Batch Acc: 79.69
[Train] Epoch: 1 [454144/620022]    Loss: 0.009426   Batch Acc: 76.56
[Train] Epoch: 1 [454208/620022]    Loss: 0.010489   Batch Acc: 73.44
[Train] Epoch: 1 [454272/620022]    Loss: 0.006452   Batch Acc: 85.94
[Train] Epoch: 1 [454336/620022]    Loss: 0.008920   Batch Acc: 73.44
[Train] Epoch: 1 [454400/620022]    Loss: 0.007111   Batch Acc: 84.38
[Train] Epoch: 1 [454464/620022]    Loss: 0.008576   Batch Acc: 79.69
[Train] Epoch: 1 [454528/620022]    Loss: 0.010268   Batch Acc: 71.88
[Train] Epoch: 1 [454592/620022]    Loss: 0.008744   Batch Acc: 79.69
[Train] Epoch: 1 [454656/620022]    Loss: 0.007377   Batch Acc: 82.81
[Train] Epoch: 1 [454720/620022]    Loss: 0.008626   Batch Acc: 75.00
[Train] Epoch: 1 [454784/620022]    Loss: 0.007694   Batch Acc: 81.25
[Train] Epoch: 1 [454848/620022]    Loss: 0.010170   Batch Acc: 70.31
[Train] Epoch: 1 [454912/620022]    Loss: 0.008407   Batch Acc: 78.12
[Train] Epoch: 1 [454976/620022]    Loss: 0.007916   Batch Acc: 81.25
[Train] Epoch: 1 [455040/620022]    Loss: 0.008541   Batch Acc: 76.56
[Train] Epoch: 1 [455104/620022]    Loss: 0.009412   Batch Acc: 78.12
[Train] Epoch: 1 [455168/620022]    Loss: 0.008848   Batch Acc: 78.12
[Train] Epoch: 1 [455232/620022]    Loss: 0.005906   Batch Acc: 84.38
[Train] Epoch: 1 [455296/620022]    Loss: 0.010247   Batch Acc: 76.56
[Train] Epoch: 1 [455360/620022]    Loss: 0.007821   Batch Acc: 79.69
[Train] Epoch: 1 [455424/620022]    Loss: 0.009825   Batch Acc: 68.75
[Train] Epoch: 1 [455488/620022]    Loss: 0.009591   Batch Acc: 78.12
[Train] Epoch: 1 [455552/620022]    Loss: 0.011348   Batch Acc: 65.62
[Train] Epoch: 1 [455616/620022]    Loss: 0.008822   Batch Acc: 76.56
[Train] Epoch: 1 [455680/620022]    Loss: 0.010532   Batch Acc: 78.12
[Train] Epoch: 1 [455744/620022]    Loss: 0.009187   Batch Acc: 73.44
[Train] Epoch: 1 [455808/620022]    Loss: 0.007647   Batch Acc: 82.81
[Train] Epoch: 1 [455872/620022]    Loss: 0.008291   Batch Acc: 85.94
[Train] Epoch: 1 [455936/620022]    Loss: 0.007781   Batch Acc: 76.56
[Train] Epoch: 1 [456000/620022]    Loss: 0.010452   Batch Acc: 67.19
[Train] Epoch: 1 [456064/620022]    Loss: 0.008998   Batch Acc: 79.69
[Train] Epoch: 1 [456128/620022]    Loss: 0.008961   Batch Acc: 75.00
[Train] Epoch: 1 [456192/620022]    Loss: 0.006826   Batch Acc: 85.94
[Train] Epoch: 1 [456256/620022]    Loss: 0.009716   Batch Acc: 78.12
[Train] Epoch: 1 [456320/620022]    Loss: 0.010839   Batch Acc: 73.44
[Train] Epoch: 1 [456384/620022]    Loss: 0.007456   Batch Acc: 84.38
[Train] Epoch: 1 [456448/620022]    Loss: 0.005958   Batch Acc: 89.06
[Train] Epoch: 1 [456512/620022]    Loss: 0.008527   Batch Acc: 78.12
[Train] Epoch: 1 [456576/620022]    Loss: 0.007890   Batch Acc: 81.25
[Train] Epoch: 1 [456640/620022]    Loss: 0.008738   Batch Acc: 78.12
[Train] Epoch: 1 [456704/620022]    Loss: 0.007094   Batch Acc: 82.81
[Train] Epoch: 1 [456768/620022]    Loss: 0.008296   Batch Acc: 78.12
[Train] Epoch: 1 [456832/620022]    Loss: 0.009011   Batch Acc: 75.00
[Train] Epoch: 1 [456896/620022]    Loss: 0.010693   Batch Acc: 71.88
[Train] Epoch: 1 [456960/620022]    Loss: 0.008775   Batch Acc: 76.56
[Train] Epoch: 1 [457024/620022]    Loss: 0.008804   Batch Acc: 75.00
[Train] Epoch: 1 [457088/620022]    Loss: 0.007534   Batch Acc: 82.81
[Train] Epoch: 1 [457152/620022]    Loss: 0.010611   Batch Acc: 76.56
[Train] Epoch: 1 [457216/620022]    Loss: 0.009356   Batch Acc: 78.12
[Train] Epoch: 1 [457280/620022]    Loss: 0.007648   Batch Acc: 85.94
[Train] Epoch: 1 [457344/620022]    Loss: 0.008457   Batch Acc: 75.00
[Train] Epoch: 1 [457408/620022]    Loss: 0.010286   Batch Acc: 75.00
[Train] Epoch: 1 [457472/620022]    Loss: 0.007855   Batch Acc: 78.12
[Train] Epoch: 1 [457536/620022]    Loss: 0.007749   Batch Acc: 81.25
[Train] Epoch: 1 [457600/620022]    Loss: 0.006985   Batch Acc: 78.12
[Train] Epoch: 1 [457664/620022]    Loss: 0.011751   Batch Acc: 73.44
[Train] Epoch: 1 [457728/620022]    Loss: 0.005999   Batch Acc: 82.81
[Train] Epoch: 1 [457792/620022]    Loss: 0.010119   Batch Acc: 82.81
[Train] Epoch: 1 [457856/620022]    Loss: 0.010255   Batch Acc: 78.12
[Train] Epoch: 1 [457920/620022]    Loss: 0.009189   Batch Acc: 76.56
[Train] Epoch: 1 [457984/620022]    Loss: 0.007684   Batch Acc: 78.12
[Train] Epoch: 1 [458048/620022]    Loss: 0.009263   Batch Acc: 79.69
[Train] Epoch: 1 [458112/620022]    Loss: 0.008586   Batch Acc: 81.25
[Train] Epoch: 1 [458176/620022]    Loss: 0.007997   Batch Acc: 81.25
[Train] Epoch: 1 [458240/620022]    Loss: 0.007920   Batch Acc: 82.81
[Train] Epoch: 1 [458304/620022]    Loss: 0.009196   Batch Acc: 81.25
[Train] Epoch: 1 [458368/620022]    Loss: 0.007894   Batch Acc: 82.81
[Train] Epoch: 1 [458432/620022]    Loss: 0.010563   Batch Acc: 64.06
[Train] Epoch: 1 [458496/620022]    Loss: 0.007573   Batch Acc: 85.94
[Train] Epoch: 1 [458560/620022]    Loss: 0.006883   Batch Acc: 84.38
[Train] Epoch: 1 [458624/620022]    Loss: 0.009993   Batch Acc: 73.44
[Train] Epoch: 1 [458688/620022]    Loss: 0.009488   Batch Acc: 79.69
[Train] Epoch: 1 [458752/620022]    Loss: 0.007069   Batch Acc: 84.38
[Train] Epoch: 1 [458816/620022]    Loss: 0.007127   Batch Acc: 81.25
[Train] Epoch: 1 [458880/620022]    Loss: 0.007613   Batch Acc: 79.69
[Train] Epoch: 1 [458944/620022]    Loss: 0.007595   Batch Acc: 79.69
[Train] Epoch: 1 [459008/620022]    Loss: 0.008541   Batch Acc: 81.25
[Train] Epoch: 1 [459072/620022]    Loss: 0.007676   Batch Acc: 78.12
[Train] Epoch: 1 [459136/620022]    Loss: 0.008457   Batch Acc: 73.44
[Train] Epoch: 1 [459200/620022]    Loss: 0.009261   Batch Acc: 76.56
[Train] Epoch: 1 [459264/620022]    Loss: 0.009001   Batch Acc: 79.69
[Train] Epoch: 1 [459328/620022]    Loss: 0.012047   Batch Acc: 71.88
[Train] Epoch: 1 [459392/620022]    Loss: 0.008906   Batch Acc: 73.44
[Train] Epoch: 1 [459456/620022]    Loss: 0.008462   Batch Acc: 79.69
[Train] Epoch: 1 [459520/620022]    Loss: 0.009552   Batch Acc: 73.44
[Train] Epoch: 1 [459584/620022]    Loss: 0.011268   Batch Acc: 71.88
[Train] Epoch: 1 [459648/620022]    Loss: 0.009669   Batch Acc: 73.44
[Train] Epoch: 1 [459712/620022]    Loss: 0.009014   Batch Acc: 75.00
[Train] Epoch: 1 [459776/620022]    Loss: 0.007947   Batch Acc: 75.00
[Train] Epoch: 1 [459840/620022]    Loss: 0.006550   Batch Acc: 82.81
[Train] Epoch: 1 [459904/620022]    Loss: 0.009221   Batch Acc: 78.12
[Train] Epoch: 1 [459968/620022]    Loss: 0.008072   Batch Acc: 82.81
[Train] Epoch: 1 [460032/620022]    Loss: 0.008891   Batch Acc: 75.00
[Train] Epoch: 1 [460096/620022]    Loss: 0.008597   Batch Acc: 70.31
[Train] Epoch: 1 [460160/620022]    Loss: 0.006637   Batch Acc: 85.94
[Train] Epoch: 1 [460224/620022]    Loss: 0.008007   Batch Acc: 78.12
[Train] Epoch: 1 [460288/620022]    Loss: 0.010188   Batch Acc: 75.00
[Train] Epoch: 1 [460352/620022]    Loss: 0.010097   Batch Acc: 75.00
[Train] Epoch: 1 [460416/620022]    Loss: 0.008913   Batch Acc: 76.56
[Train] Epoch: 1 [460480/620022]    Loss: 0.007651   Batch Acc: 79.69
[Train] Epoch: 1 [460544/620022]    Loss: 0.007173   Batch Acc: 85.94
[Train] Epoch: 1 [460608/620022]    Loss: 0.008547   Batch Acc: 78.12
[Train] Epoch: 1 [460672/620022]    Loss: 0.007796   Batch Acc: 79.69
[Train] Epoch: 1 [460736/620022]    Loss: 0.007866   Batch Acc: 82.81
[Train] Epoch: 1 [460800/620022]    Loss: 0.008056   Batch Acc: 78.12
[Train] Epoch: 1 [460864/620022]    Loss: 0.010973   Batch Acc: 68.75
[Train] Epoch: 1 [460928/620022]    Loss: 0.010892   Batch Acc: 76.56
[Train] Epoch: 1 [460992/620022]    Loss: 0.007763   Batch Acc: 79.69
[Train] Epoch: 1 [461056/620022]    Loss: 0.009238   Batch Acc: 81.25
[Train] Epoch: 1 [461120/620022]    Loss: 0.008742   Batch Acc: 79.69
[Train] Epoch: 1 [461184/620022]    Loss: 0.006756   Batch Acc: 82.81
[Train] Epoch: 1 [461248/620022]    Loss: 0.009780   Batch Acc: 71.88
[Train] Epoch: 1 [461312/620022]    Loss: 0.007556   Batch Acc: 87.50
[Train] Epoch: 1 [461376/620022]    Loss: 0.008275   Batch Acc: 81.25
[Train] Epoch: 1 [461440/620022]    Loss: 0.008118   Batch Acc: 79.69
[Train] Epoch: 1 [461504/620022]    Loss: 0.010489   Batch Acc: 75.00
[Train] Epoch: 1 [461568/620022]    Loss: 0.008141   Batch Acc: 75.00
[Train] Epoch: 1 [461632/620022]    Loss: 0.009724   Batch Acc: 76.56
[Train] Epoch: 1 [461696/620022]    Loss: 0.007587   Batch Acc: 84.38
[Train] Epoch: 1 [461760/620022]    Loss: 0.008561   Batch Acc: 76.56
[Train] Epoch: 1 [461824/620022]    Loss: 0.008884   Batch Acc: 78.12
[Train] Epoch: 1 [461888/620022]    Loss: 0.008172   Batch Acc: 79.69
[Train] Epoch: 1 [461952/620022]    Loss: 0.006710   Batch Acc: 79.69
[Train] Epoch: 1 [462016/620022]    Loss: 0.010958   Batch Acc: 68.75
[Train] Epoch: 1 [462080/620022]    Loss: 0.008406   Batch Acc: 81.25
[Train] Epoch: 1 [462144/620022]    Loss: 0.010454   Batch Acc: 75.00
[Train] Epoch: 1 [462208/620022]    Loss: 0.008499   Batch Acc: 78.12
[Train] Epoch: 1 [462272/620022]    Loss: 0.007537   Batch Acc: 78.12
[Train] Epoch: 1 [462336/620022]    Loss: 0.008545   Batch Acc: 78.12
[Train] Epoch: 1 [462400/620022]    Loss: 0.007100   Batch Acc: 84.38
[Train] Epoch: 1 [462464/620022]    Loss: 0.008049   Batch Acc: 79.69
[Train] Epoch: 1 [462528/620022]    Loss: 0.009365   Batch Acc: 78.12
[Train] Epoch: 1 [462592/620022]    Loss: 0.009638   Batch Acc: 76.56
[Train] Epoch: 1 [462656/620022]    Loss: 0.008772   Batch Acc: 71.88
[Train] Epoch: 1 [462720/620022]    Loss: 0.007842   Batch Acc: 81.25
[Train] Epoch: 1 [462784/620022]    Loss: 0.009712   Batch Acc: 70.31
[Train] Epoch: 1 [462848/620022]    Loss: 0.006087   Batch Acc: 92.19
[Train] Epoch: 1 [462912/620022]    Loss: 0.010950   Batch Acc: 70.31
[Train] Epoch: 1 [462976/620022]    Loss: 0.010316   Batch Acc: 75.00
[Train] Epoch: 1 [463040/620022]    Loss: 0.007725   Batch Acc: 82.81
[Train] Epoch: 1 [463104/620022]    Loss: 0.008956   Batch Acc: 70.31
[Train] Epoch: 1 [463168/620022]    Loss: 0.009159   Batch Acc: 71.88
[Train] Epoch: 1 [463232/620022]    Loss: 0.011636   Batch Acc: 64.06
[Train] Epoch: 1 [463296/620022]    Loss: 0.006796   Batch Acc: 90.62
[Train] Epoch: 1 [463360/620022]    Loss: 0.008927   Batch Acc: 73.44
[Train] Epoch: 1 [463424/620022]    Loss: 0.009854   Batch Acc: 70.31
[Train] Epoch: 1 [463488/620022]    Loss: 0.008213   Batch Acc: 82.81
[Train] Epoch: 1 [463552/620022]    Loss: 0.004948   Batch Acc: 93.75
[Train] Epoch: 1 [463616/620022]    Loss: 0.010259   Batch Acc: 70.31
[Train] Epoch: 1 [463680/620022]    Loss: 0.009051   Batch Acc: 75.00
[Train] Epoch: 1 [463744/620022]    Loss: 0.007509   Batch Acc: 84.38
[Train] Epoch: 1 [463808/620022]    Loss: 0.008025   Batch Acc: 82.81
[Train] Epoch: 1 [463872/620022]    Loss: 0.008827   Batch Acc: 73.44
[Train] Epoch: 1 [463936/620022]    Loss: 0.008333   Batch Acc: 82.81
[Train] Epoch: 1 [464000/620022]    Loss: 0.009617   Batch Acc: 73.44
[Train] Epoch: 1 [464064/620022]    Loss: 0.007432   Batch Acc: 82.81
[Train] Epoch: 1 [464128/620022]    Loss: 0.007053   Batch Acc: 81.25
[Train] Epoch: 1 [464192/620022]    Loss: 0.010039   Batch Acc: 73.44
[Train] Epoch: 1 [464256/620022]    Loss: 0.007340   Batch Acc: 79.69
[Train] Epoch: 1 [464320/620022]    Loss: 0.007693   Batch Acc: 79.69
[Train] Epoch: 1 [464384/620022]    Loss: 0.007802   Batch Acc: 79.69
[Train] Epoch: 1 [464448/620022]    Loss: 0.008458   Batch Acc: 75.00
[Train] Epoch: 1 [464512/620022]    Loss: 0.009104   Batch Acc: 78.12
[Train] Epoch: 1 [464576/620022]    Loss: 0.007825   Batch Acc: 76.56
[Train] Epoch: 1 [464640/620022]    Loss: 0.008812   Batch Acc: 78.12
[Train] Epoch: 1 [464704/620022]    Loss: 0.007974   Batch Acc: 76.56
[Train] Epoch: 1 [464768/620022]    Loss: 0.008467   Batch Acc: 78.12
[Train] Epoch: 1 [464832/620022]    Loss: 0.009631   Batch Acc: 76.56
[Train] Epoch: 1 [464896/620022]    Loss: 0.008088   Batch Acc: 82.81
[Train] Epoch: 1 [464960/620022]    Loss: 0.008720   Batch Acc: 73.44
[Train] Epoch: 1 [465024/620022]    Loss: 0.007970   Batch Acc: 78.12
[Train] Epoch: 1 [465088/620022]    Loss: 0.007975   Batch Acc: 78.12
[Train] Epoch: 1 [465152/620022]    Loss: 0.008606   Batch Acc: 73.44
[Train] Epoch: 1 [465216/620022]    Loss: 0.010019   Batch Acc: 70.31
[Train] Epoch: 1 [465280/620022]    Loss: 0.008096   Batch Acc: 79.69
[Train] Epoch: 1 [465344/620022]    Loss: 0.010769   Batch Acc: 70.31
[Train] Epoch: 1 [465408/620022]    Loss: 0.008676   Batch Acc: 79.69
[Train] Epoch: 1 [465472/620022]    Loss: 0.008791   Batch Acc: 79.69
[Train] Epoch: 1 [465536/620022]    Loss: 0.006771   Batch Acc: 81.25
[Train] Epoch: 1 [465600/620022]    Loss: 0.010356   Batch Acc: 67.19
[Train] Epoch: 1 [465664/620022]    Loss: 0.008273   Batch Acc: 79.69
[Train] Epoch: 1 [465728/620022]    Loss: 0.007726   Batch Acc: 76.56
[Train] Epoch: 1 [465792/620022]    Loss: 0.010909   Batch Acc: 67.19
[Train] Epoch: 1 [465856/620022]    Loss: 0.008552   Batch Acc: 84.38
[Train] Epoch: 1 [465920/620022]    Loss: 0.006100   Batch Acc: 89.06
[Train] Epoch: 1 [465984/620022]    Loss: 0.010483   Batch Acc: 71.88
[Train] Epoch: 1 [466048/620022]    Loss: 0.010342   Batch Acc: 71.88
[Train] Epoch: 1 [466112/620022]    Loss: 0.006924   Batch Acc: 81.25
[Train] Epoch: 1 [466176/620022]    Loss: 0.009823   Batch Acc: 71.88
[Train] Epoch: 1 [466240/620022]    Loss: 0.008703   Batch Acc: 76.56
[Train] Epoch: 1 [466304/620022]    Loss: 0.009479   Batch Acc: 75.00
[Train] Epoch: 1 [466368/620022]    Loss: 0.007974   Batch Acc: 79.69
[Train] Epoch: 1 [466432/620022]    Loss: 0.007616   Batch Acc: 76.56
[Train] Epoch: 1 [466496/620022]    Loss: 0.009153   Batch Acc: 73.44
[Train] Epoch: 1 [466560/620022]    Loss: 0.009301   Batch Acc: 75.00
[Train] Epoch: 1 [466624/620022]    Loss: 0.007038   Batch Acc: 82.81
[Train] Epoch: 1 [466688/620022]    Loss: 0.010615   Batch Acc: 65.62
[Train] Epoch: 1 [466752/620022]    Loss: 0.009827   Batch Acc: 65.62
[Train] Epoch: 1 [466816/620022]    Loss: 0.009007   Batch Acc: 78.12
[Train] Epoch: 1 [466880/620022]    Loss: 0.008506   Batch Acc: 79.69
[Train] Epoch: 1 [466944/620022]    Loss: 0.009595   Batch Acc: 75.00
[Train] Epoch: 1 [467008/620022]    Loss: 0.007546   Batch Acc: 85.94
[Train] Epoch: 1 [467072/620022]    Loss: 0.008813   Batch Acc: 79.69
[Train] Epoch: 1 [467136/620022]    Loss: 0.007435   Batch Acc: 81.25
[Train] Epoch: 1 [467200/620022]    Loss: 0.007210   Batch Acc: 84.38
[Train] Epoch: 1 [467264/620022]    Loss: 0.008140   Batch Acc: 78.12
[Train] Epoch: 1 [467328/620022]    Loss: 0.010148   Batch Acc: 70.31
[Train] Epoch: 1 [467392/620022]    Loss: 0.007575   Batch Acc: 84.38
[Train] Epoch: 1 [467456/620022]    Loss: 0.009210   Batch Acc: 76.56
[Train] Epoch: 1 [467520/620022]    Loss: 0.007874   Batch Acc: 81.25
[Train] Epoch: 1 [467584/620022]    Loss: 0.008858   Batch Acc: 76.56
[Train] Epoch: 1 [467648/620022]    Loss: 0.007813   Batch Acc: 82.81
[Train] Epoch: 1 [467712/620022]    Loss: 0.006508   Batch Acc: 84.38
[Train] Epoch: 1 [467776/620022]    Loss: 0.007117   Batch Acc: 84.38
[Train] Epoch: 1 [467840/620022]    Loss: 0.006669   Batch Acc: 85.94
[Train] Epoch: 1 [467904/620022]    Loss: 0.009285   Batch Acc: 75.00
[Train] Epoch: 1 [467968/620022]    Loss: 0.006663   Batch Acc: 78.12
[Train] Epoch: 1 [468032/620022]    Loss: 0.010519   Batch Acc: 70.31
[Train] Epoch: 1 [468096/620022]    Loss: 0.008375   Batch Acc: 75.00
[Train] Epoch: 1 [468160/620022]    Loss: 0.005913   Batch Acc: 87.50
[Train] Epoch: 1 [468224/620022]    Loss: 0.010067   Batch Acc: 73.44
[Train] Epoch: 1 [468288/620022]    Loss: 0.008536   Batch Acc: 76.56
[Train] Epoch: 1 [468352/620022]    Loss: 0.006977   Batch Acc: 81.25
[Train] Epoch: 1 [468416/620022]    Loss: 0.007431   Batch Acc: 76.56
[Train] Epoch: 1 [468480/620022]    Loss: 0.008267   Batch Acc: 78.12
[Train] Epoch: 1 [468544/620022]    Loss: 0.010248   Batch Acc: 67.19
[Train] Epoch: 1 [468608/620022]    Loss: 0.008154   Batch Acc: 79.69
[Train] Epoch: 1 [468672/620022]    Loss: 0.007623   Batch Acc: 84.38
[Train] Epoch: 1 [468736/620022]    Loss: 0.012962   Batch Acc: 70.31
[Train] Epoch: 1 [468800/620022]    Loss: 0.008956   Batch Acc: 78.12
[Train] Epoch: 1 [468864/620022]    Loss: 0.007298   Batch Acc: 79.69
[Train] Epoch: 1 [468928/620022]    Loss: 0.010088   Batch Acc: 71.88
[Train] Epoch: 1 [468992/620022]    Loss: 0.006963   Batch Acc: 81.25
[Train] Epoch: 1 [469056/620022]    Loss: 0.009673   Batch Acc: 73.44
[Train] Epoch: 1 [469120/620022]    Loss: 0.007978   Batch Acc: 82.81
[Train] Epoch: 1 [469184/620022]    Loss: 0.008825   Batch Acc: 75.00
[Train] Epoch: 1 [469248/620022]    Loss: 0.010990   Batch Acc: 68.75
[Train] Epoch: 1 [469312/620022]    Loss: 0.009593   Batch Acc: 75.00
[Train] Epoch: 1 [469376/620022]    Loss: 0.008193   Batch Acc: 79.69
[Train] Epoch: 1 [469440/620022]    Loss: 0.007895   Batch Acc: 76.56
[Train] Epoch: 1 [469504/620022]    Loss: 0.009211   Batch Acc: 73.44
[Train] Epoch: 1 [469568/620022]    Loss: 0.009206   Batch Acc: 75.00
[Train] Epoch: 1 [469632/620022]    Loss: 0.009770   Batch Acc: 67.19
[Train] Epoch: 1 [469696/620022]    Loss: 0.006214   Batch Acc: 84.38
[Train] Epoch: 1 [469760/620022]    Loss: 0.008588   Batch Acc: 78.12
[Train] Epoch: 1 [469824/620022]    Loss: 0.008665   Batch Acc: 82.81
[Train] Epoch: 1 [469888/620022]    Loss: 0.009442   Batch Acc: 73.44
[Train] Epoch: 1 [469952/620022]    Loss: 0.010032   Batch Acc: 67.19
[Train] Epoch: 1 [470016/620022]    Loss: 0.007070   Batch Acc: 85.94
[Train] Epoch: 1 [470080/620022]    Loss: 0.008787   Batch Acc: 75.00
[Train] Epoch: 1 [470144/620022]    Loss: 0.007507   Batch Acc: 82.81
[Train] Epoch: 1 [470208/620022]    Loss: 0.007720   Batch Acc: 79.69
[Train] Epoch: 1 [470272/620022]    Loss: 0.010197   Batch Acc: 68.75
[Train] Epoch: 1 [470336/620022]    Loss: 0.007557   Batch Acc: 78.12
[Train] Epoch: 1 [470400/620022]    Loss: 0.006802   Batch Acc: 89.06
[Train] Epoch: 1 [470464/620022]    Loss: 0.009731   Batch Acc: 73.44
[Train] Epoch: 1 [470528/620022]    Loss: 0.009189   Batch Acc: 73.44
[Train] Epoch: 1 [470592/620022]    Loss: 0.011437   Batch Acc: 68.75
[Train] Epoch: 1 [470656/620022]    Loss: 0.006160   Batch Acc: 87.50
[Train] Epoch: 1 [470720/620022]    Loss: 0.009250   Batch Acc: 78.12
[Train] Epoch: 1 [470784/620022]    Loss: 0.007379   Batch Acc: 78.12
[Train] Epoch: 1 [470848/620022]    Loss: 0.007674   Batch Acc: 79.69
[Train] Epoch: 1 [470912/620022]    Loss: 0.007250   Batch Acc: 82.81
[Train] Epoch: 1 [470976/620022]    Loss: 0.008118   Batch Acc: 79.69
[Train] Epoch: 1 [471040/620022]    Loss: 0.008493   Batch Acc: 76.56
[Train] Epoch: 1 [471104/620022]    Loss: 0.008456   Batch Acc: 76.56
[Train] Epoch: 1 [471168/620022]    Loss: 0.008254   Batch Acc: 75.00
[Train] Epoch: 1 [471232/620022]    Loss: 0.010626   Batch Acc: 70.31
[Train] Epoch: 1 [471296/620022]    Loss: 0.008778   Batch Acc: 76.56
[Train] Epoch: 1 [471360/620022]    Loss: 0.007589   Batch Acc: 87.50
[Train] Epoch: 1 [471424/620022]    Loss: 0.009471   Batch Acc: 68.75
[Train] Epoch: 1 [471488/620022]    Loss: 0.007252   Batch Acc: 82.81
[Train] Epoch: 1 [471552/620022]    Loss: 0.009447   Batch Acc: 70.31
[Train] Epoch: 1 [471616/620022]    Loss: 0.008352   Batch Acc: 81.25
[Train] Epoch: 1 [471680/620022]    Loss: 0.006497   Batch Acc: 85.94
[Train] Epoch: 1 [471744/620022]    Loss: 0.012215   Batch Acc: 65.62
[Train] Epoch: 1 [471808/620022]    Loss: 0.007810   Batch Acc: 78.12
[Train] Epoch: 1 [471872/620022]    Loss: 0.008879   Batch Acc: 71.88
[Train] Epoch: 1 [471936/620022]    Loss: 0.009054   Batch Acc: 76.56
[Train] Epoch: 1 [472000/620022]    Loss: 0.009596   Batch Acc: 71.88
[Train] Epoch: 1 [472064/620022]    Loss: 0.009107   Batch Acc: 79.69
[Train] Epoch: 1 [472128/620022]    Loss: 0.007314   Batch Acc: 84.38
[Train] Epoch: 1 [472192/620022]    Loss: 0.010144   Batch Acc: 79.69
[Train] Epoch: 1 [472256/620022]    Loss: 0.009339   Batch Acc: 75.00
[Train] Epoch: 1 [472320/620022]    Loss: 0.011226   Batch Acc: 70.31
[Train] Epoch: 1 [472384/620022]    Loss: 0.007318   Batch Acc: 81.25
[Train] Epoch: 1 [472448/620022]    Loss: 0.006728   Batch Acc: 79.69
[Train] Epoch: 1 [472512/620022]    Loss: 0.007540   Batch Acc: 78.12
[Train] Epoch: 1 [472576/620022]    Loss: 0.011747   Batch Acc: 71.88
[Train] Epoch: 1 [472640/620022]    Loss: 0.009492   Batch Acc: 78.12
[Train] Epoch: 1 [472704/620022]    Loss: 0.007522   Batch Acc: 82.81
[Train] Epoch: 1 [472768/620022]    Loss: 0.010668   Batch Acc: 73.44
[Train] Epoch: 1 [472832/620022]    Loss: 0.007859   Batch Acc: 78.12
[Train] Epoch: 1 [472896/620022]    Loss: 0.008126   Batch Acc: 78.12
[Train] Epoch: 1 [472960/620022]    Loss: 0.008300   Batch Acc: 78.12
[Train] Epoch: 1 [473024/620022]    Loss: 0.008317   Batch Acc: 81.25
[Train] Epoch: 1 [473088/620022]    Loss: 0.008532   Batch Acc: 79.69
[Train] Epoch: 1 [473152/620022]    Loss: 0.009893   Batch Acc: 68.75
[Train] Epoch: 1 [473216/620022]    Loss: 0.008995   Batch Acc: 75.00
[Train] Epoch: 1 [473280/620022]    Loss: 0.007634   Batch Acc: 82.81
[Train] Epoch: 1 [473344/620022]    Loss: 0.007891   Batch Acc: 84.38
[Train] Epoch: 1 [473408/620022]    Loss: 0.005819   Batch Acc: 89.06
[Train] Epoch: 1 [473472/620022]    Loss: 0.008474   Batch Acc: 76.56
[Train] Epoch: 1 [473536/620022]    Loss: 0.005882   Batch Acc: 90.62
[Train] Epoch: 1 [473600/620022]    Loss: 0.008803   Batch Acc: 71.88
[Train] Epoch: 1 [473664/620022]    Loss: 0.007959   Batch Acc: 79.69
[Train] Epoch: 1 [473728/620022]    Loss: 0.005613   Batch Acc: 82.81
[Train] Epoch: 1 [473792/620022]    Loss: 0.008673   Batch Acc: 81.25
[Train] Epoch: 1 [473856/620022]    Loss: 0.007570   Batch Acc: 82.81
[Train] Epoch: 1 [473920/620022]    Loss: 0.006246   Batch Acc: 79.69
[Train] Epoch: 1 [473984/620022]    Loss: 0.006727   Batch Acc: 85.94
[Train] Epoch: 1 [474048/620022]    Loss: 0.008800   Batch Acc: 70.31
[Train] Epoch: 1 [474112/620022]    Loss: 0.007681   Batch Acc: 79.69
[Train] Epoch: 1 [474176/620022]    Loss: 0.007975   Batch Acc: 81.25
[Train] Epoch: 1 [474240/620022]    Loss: 0.006792   Batch Acc: 82.81
[Train] Epoch: 1 [474304/620022]    Loss: 0.008530   Batch Acc: 76.56
[Train] Epoch: 1 [474368/620022]    Loss: 0.009035   Batch Acc: 79.69
[Train] Epoch: 1 [474432/620022]    Loss: 0.009794   Batch Acc: 76.56
[Train] Epoch: 1 [474496/620022]    Loss: 0.009117   Batch Acc: 79.69
[Train] Epoch: 1 [474560/620022]    Loss: 0.008957   Batch Acc: 76.56
[Train] Epoch: 1 [474624/620022]    Loss: 0.009761   Batch Acc: 71.88
[Train] Epoch: 1 [474688/620022]    Loss: 0.010902   Batch Acc: 70.31
[Train] Epoch: 1 [474752/620022]    Loss: 0.010932   Batch Acc: 65.62
[Train] Epoch: 1 [474816/620022]    Loss: 0.010758   Batch Acc: 70.31
[Train] Epoch: 1 [474880/620022]    Loss: 0.009588   Batch Acc: 70.31
[Train] Epoch: 1 [474944/620022]    Loss: 0.008675   Batch Acc: 78.12
[Train] Epoch: 1 [475008/620022]    Loss: 0.008132   Batch Acc: 82.81
[Train] Epoch: 1 [475072/620022]    Loss: 0.009111   Batch Acc: 76.56
[Train] Epoch: 1 [475136/620022]    Loss: 0.010590   Batch Acc: 73.44
[Train] Epoch: 1 [475200/620022]    Loss: 0.010529   Batch Acc: 76.56
[Train] Epoch: 1 [475264/620022]    Loss: 0.009013   Batch Acc: 76.56
[Train] Epoch: 1 [475328/620022]    Loss: 0.008753   Batch Acc: 84.38
[Train] Epoch: 1 [475392/620022]    Loss: 0.010564   Batch Acc: 73.44
[Train] Epoch: 1 [475456/620022]    Loss: 0.008987   Batch Acc: 75.00
[Train] Epoch: 1 [475520/620022]    Loss: 0.007828   Batch Acc: 79.69
[Train] Epoch: 1 [475584/620022]    Loss: 0.008730   Batch Acc: 73.44
[Train] Epoch: 1 [475648/620022]    Loss: 0.007948   Batch Acc: 76.56
[Train] Epoch: 1 [475712/620022]    Loss: 0.009270   Batch Acc: 73.44
[Train] Epoch: 1 [475776/620022]    Loss: 0.009752   Batch Acc: 73.44
[Train] Epoch: 1 [475840/620022]    Loss: 0.009447   Batch Acc: 75.00
[Train] Epoch: 1 [475904/620022]    Loss: 0.009969   Batch Acc: 73.44
[Train] Epoch: 1 [475968/620022]    Loss: 0.006913   Batch Acc: 82.81
[Train] Epoch: 1 [476032/620022]    Loss: 0.007772   Batch Acc: 82.81
[Train] Epoch: 1 [476096/620022]    Loss: 0.009719   Batch Acc: 78.12
[Train] Epoch: 1 [476160/620022]    Loss: 0.008976   Batch Acc: 76.56
[Train] Epoch: 1 [476224/620022]    Loss: 0.008202   Batch Acc: 78.12
[Train] Epoch: 1 [476288/620022]    Loss: 0.008305   Batch Acc: 78.12
[Train] Epoch: 1 [476352/620022]    Loss: 0.009040   Batch Acc: 76.56
[Train] Epoch: 1 [476416/620022]    Loss: 0.007553   Batch Acc: 82.81
[Train] Epoch: 1 [476480/620022]    Loss: 0.008547   Batch Acc: 85.94
[Train] Epoch: 1 [476544/620022]    Loss: 0.009144   Batch Acc: 78.12
[Train] Epoch: 1 [476608/620022]    Loss: 0.007220   Batch Acc: 84.38
[Train] Epoch: 1 [476672/620022]    Loss: 0.010629   Batch Acc: 68.75
[Train] Epoch: 1 [476736/620022]    Loss: 0.009407   Batch Acc: 82.81
[Train] Epoch: 1 [476800/620022]    Loss: 0.007591   Batch Acc: 85.94
[Train] Epoch: 1 [476864/620022]    Loss: 0.009878   Batch Acc: 75.00
[Train] Epoch: 1 [476928/620022]    Loss: 0.007200   Batch Acc: 85.94
[Train] Epoch: 1 [476992/620022]    Loss: 0.008687   Batch Acc: 75.00
[Train] Epoch: 1 [477056/620022]    Loss: 0.008786   Batch Acc: 79.69
[Train] Epoch: 1 [477120/620022]    Loss: 0.009395   Batch Acc: 81.25
[Train] Epoch: 1 [477184/620022]    Loss: 0.008929   Batch Acc: 76.56
[Train] Epoch: 1 [477248/620022]    Loss: 0.008623   Batch Acc: 81.25
[Train] Epoch: 1 [477312/620022]    Loss: 0.008499   Batch Acc: 82.81
[Train] Epoch: 1 [477376/620022]    Loss: 0.009417   Batch Acc: 79.69
[Train] Epoch: 1 [477440/620022]    Loss: 0.008776   Batch Acc: 76.56
[Train] Epoch: 1 [477504/620022]    Loss: 0.009416   Batch Acc: 70.31
[Train] Epoch: 1 [477568/620022]    Loss: 0.010373   Batch Acc: 75.00
[Train] Epoch: 1 [477632/620022]    Loss: 0.006672   Batch Acc: 84.38
[Train] Epoch: 1 [477696/620022]    Loss: 0.010147   Batch Acc: 71.88
[Train] Epoch: 1 [477760/620022]    Loss: 0.007122   Batch Acc: 81.25
[Train] Epoch: 1 [477824/620022]    Loss: 0.009115   Batch Acc: 76.56
[Train] Epoch: 1 [477888/620022]    Loss: 0.009915   Batch Acc: 76.56
[Train] Epoch: 1 [477952/620022]    Loss: 0.008254   Batch Acc: 82.81
[Train] Epoch: 1 [478016/620022]    Loss: 0.009135   Batch Acc: 82.81
[Train] Epoch: 1 [478080/620022]    Loss: 0.006536   Batch Acc: 85.94
[Train] Epoch: 1 [478144/620022]    Loss: 0.007590   Batch Acc: 81.25
[Train] Epoch: 1 [478208/620022]    Loss: 0.008358   Batch Acc: 71.88
[Train] Epoch: 1 [478272/620022]    Loss: 0.009442   Batch Acc: 81.25
[Train] Epoch: 1 [478336/620022]    Loss: 0.008730   Batch Acc: 75.00
[Train] Epoch: 1 [478400/620022]    Loss: 0.007921   Batch Acc: 75.00
[Train] Epoch: 1 [478464/620022]    Loss: 0.010410   Batch Acc: 70.31
[Train] Epoch: 1 [478528/620022]    Loss: 0.007728   Batch Acc: 82.81
[Train] Epoch: 1 [478592/620022]    Loss: 0.006855   Batch Acc: 84.38
[Train] Epoch: 1 [478656/620022]    Loss: 0.008296   Batch Acc: 78.12
[Train] Epoch: 1 [478720/620022]    Loss: 0.010230   Batch Acc: 76.56
[Train] Epoch: 1 [478784/620022]    Loss: 0.010978   Batch Acc: 75.00
[Train] Epoch: 1 [478848/620022]    Loss: 0.007825   Batch Acc: 79.69
[Train] Epoch: 1 [478912/620022]    Loss: 0.007225   Batch Acc: 85.94
[Train] Epoch: 1 [478976/620022]    Loss: 0.007639   Batch Acc: 79.69
[Train] Epoch: 1 [479040/620022]    Loss: 0.011005   Batch Acc: 71.88
[Train] Epoch: 1 [479104/620022]    Loss: 0.007473   Batch Acc: 82.81
[Train] Epoch: 1 [479168/620022]    Loss: 0.009636   Batch Acc: 78.12
[Train] Epoch: 1 [479232/620022]    Loss: 0.008338   Batch Acc: 81.25
[Train] Epoch: 1 [479296/620022]    Loss: 0.007833   Batch Acc: 78.12
[Train] Epoch: 1 [479360/620022]    Loss: 0.008820   Batch Acc: 85.94
[Train] Epoch: 1 [479424/620022]    Loss: 0.008206   Batch Acc: 76.56
[Train] Epoch: 1 [479488/620022]    Loss: 0.006518   Batch Acc: 87.50
[Train] Epoch: 1 [479552/620022]    Loss: 0.008416   Batch Acc: 81.25
[Train] Epoch: 1 [479616/620022]    Loss: 0.009490   Batch Acc: 73.44
[Train] Epoch: 1 [479680/620022]    Loss: 0.007944   Batch Acc: 78.12
[Train] Epoch: 1 [479744/620022]    Loss: 0.008055   Batch Acc: 78.12
[Train] Epoch: 1 [479808/620022]    Loss: 0.009215   Batch Acc: 76.56
[Train] Epoch: 1 [479872/620022]    Loss: 0.007780   Batch Acc: 78.12
[Train] Epoch: 1 [479936/620022]    Loss: 0.008567   Batch Acc: 82.81
[Train] Epoch: 1 [480000/620022]    Loss: 0.010641   Batch Acc: 71.88
[Train] Epoch: 1 [480064/620022]    Loss: 0.008520   Batch Acc: 76.56
[Train] Epoch: 1 [480128/620022]    Loss: 0.010796   Batch Acc: 68.75
[Train] Epoch: 1 [480192/620022]    Loss: 0.010458   Batch Acc: 71.88
[Train] Epoch: 1 [480256/620022]    Loss: 0.010159   Batch Acc: 71.88
[Train] Epoch: 1 [480320/620022]    Loss: 0.006884   Batch Acc: 85.94
[Train] Epoch: 1 [480384/620022]    Loss: 0.007615   Batch Acc: 81.25
[Train] Epoch: 1 [480448/620022]    Loss: 0.007681   Batch Acc: 81.25
[Train] Epoch: 1 [480512/620022]    Loss: 0.010077   Batch Acc: 73.44
[Train] Epoch: 1 [480576/620022]    Loss: 0.009891   Batch Acc: 75.00
[Train] Epoch: 1 [480640/620022]    Loss: 0.008533   Batch Acc: 73.44
[Train] Epoch: 1 [480704/620022]    Loss: 0.007184   Batch Acc: 81.25
[Train] Epoch: 1 [480768/620022]    Loss: 0.009297   Batch Acc: 78.12
[Train] Epoch: 1 [480832/620022]    Loss: 0.009066   Batch Acc: 76.56
[Train] Epoch: 1 [480896/620022]    Loss: 0.007474   Batch Acc: 82.81
[Train] Epoch: 1 [480960/620022]    Loss: 0.009494   Batch Acc: 79.69
[Train] Epoch: 1 [481024/620022]    Loss: 0.008476   Batch Acc: 79.69
[Train] Epoch: 1 [481088/620022]    Loss: 0.008133   Batch Acc: 78.12
[Train] Epoch: 1 [481152/620022]    Loss: 0.009024   Batch Acc: 76.56
[Train] Epoch: 1 [481216/620022]    Loss: 0.007783   Batch Acc: 73.44
[Train] Epoch: 1 [481280/620022]    Loss: 0.009922   Batch Acc: 75.00
[Train] Epoch: 1 [481344/620022]    Loss: 0.009293   Batch Acc: 75.00
[Train] Epoch: 1 [481408/620022]    Loss: 0.008071   Batch Acc: 79.69
[Train] Epoch: 1 [481472/620022]    Loss: 0.010709   Batch Acc: 73.44
[Train] Epoch: 1 [481536/620022]    Loss: 0.008485   Batch Acc: 79.69
[Train] Epoch: 1 [481600/620022]    Loss: 0.007157   Batch Acc: 82.81
[Train] Epoch: 1 [481664/620022]    Loss: 0.010975   Batch Acc: 65.62
[Train] Epoch: 1 [481728/620022]    Loss: 0.008452   Batch Acc: 79.69
[Train] Epoch: 1 [481792/620022]    Loss: 0.010366   Batch Acc: 76.56
[Train] Epoch: 1 [481856/620022]    Loss: 0.009905   Batch Acc: 76.56
[Train] Epoch: 1 [481920/620022]    Loss: 0.009032   Batch Acc: 75.00
[Train] Epoch: 1 [481984/620022]    Loss: 0.010203   Batch Acc: 70.31
[Train] Epoch: 1 [482048/620022]    Loss: 0.008301   Batch Acc: 81.25
[Train] Epoch: 1 [482112/620022]    Loss: 0.009495   Batch Acc: 78.12
[Train] Epoch: 1 [482176/620022]    Loss: 0.008149   Batch Acc: 82.81
[Train] Epoch: 1 [482240/620022]    Loss: 0.009725   Batch Acc: 73.44
[Train] Epoch: 1 [482304/620022]    Loss: 0.008139   Batch Acc: 81.25
[Train] Epoch: 1 [482368/620022]    Loss: 0.005639   Batch Acc: 89.06
[Train] Epoch: 1 [482432/620022]    Loss: 0.009123   Batch Acc: 70.31
[Train] Epoch: 1 [482496/620022]    Loss: 0.007366   Batch Acc: 79.69
[Train] Epoch: 1 [482560/620022]    Loss: 0.007400   Batch Acc: 82.81
[Train] Epoch: 1 [482624/620022]    Loss: 0.007240   Batch Acc: 84.38
[Train] Epoch: 1 [482688/620022]    Loss: 0.009483   Batch Acc: 73.44
[Train] Epoch: 1 [482752/620022]    Loss: 0.010403   Batch Acc: 75.00
[Train] Epoch: 1 [482816/620022]    Loss: 0.008824   Batch Acc: 79.69
[Train] Epoch: 1 [482880/620022]    Loss: 0.008726   Batch Acc: 76.56
[Train] Epoch: 1 [482944/620022]    Loss: 0.008528   Batch Acc: 71.88
[Train] Epoch: 1 [483008/620022]    Loss: 0.008847   Batch Acc: 82.81
[Train] Epoch: 1 [483072/620022]    Loss: 0.011143   Batch Acc: 70.31
[Train] Epoch: 1 [483136/620022]    Loss: 0.009411   Batch Acc: 75.00
[Train] Epoch: 1 [483200/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 1 [483264/620022]    Loss: 0.008526   Batch Acc: 79.69
[Train] Epoch: 1 [483328/620022]    Loss: 0.007234   Batch Acc: 82.81
[Train] Epoch: 1 [483392/620022]    Loss: 0.009095   Batch Acc: 78.12
[Train] Epoch: 1 [483456/620022]    Loss: 0.010723   Batch Acc: 73.44
[Train] Epoch: 1 [483520/620022]    Loss: 0.009093   Batch Acc: 75.00
[Train] Epoch: 1 [483584/620022]    Loss: 0.009785   Batch Acc: 70.31
[Train] Epoch: 1 [483648/620022]    Loss: 0.011339   Batch Acc: 75.00
[Train] Epoch: 1 [483712/620022]    Loss: 0.009339   Batch Acc: 78.12
[Train] Epoch: 1 [483776/620022]    Loss: 0.007094   Batch Acc: 79.69
[Train] Epoch: 1 [483840/620022]    Loss: 0.009320   Batch Acc: 79.69
[Train] Epoch: 1 [483904/620022]    Loss: 0.006686   Batch Acc: 82.81
[Train] Epoch: 1 [483968/620022]    Loss: 0.011069   Batch Acc: 68.75
[Train] Epoch: 1 [484032/620022]    Loss: 0.009168   Batch Acc: 76.56
[Train] Epoch: 1 [484096/620022]    Loss: 0.010736   Batch Acc: 71.88
[Train] Epoch: 1 [484160/620022]    Loss: 0.011571   Batch Acc: 71.88
[Train] Epoch: 1 [484224/620022]    Loss: 0.010959   Batch Acc: 75.00
[Train] Epoch: 1 [484288/620022]    Loss: 0.008066   Batch Acc: 73.44
[Train] Epoch: 1 [484352/620022]    Loss: 0.009059   Batch Acc: 78.12
[Train] Epoch: 1 [484416/620022]    Loss: 0.007830   Batch Acc: 82.81
[Train] Epoch: 1 [484480/620022]    Loss: 0.009479   Batch Acc: 79.69
[Train] Epoch: 1 [484544/620022]    Loss: 0.009457   Batch Acc: 70.31
[Train] Epoch: 1 [484608/620022]    Loss: 0.007493   Batch Acc: 84.38
[Train] Epoch: 1 [484672/620022]    Loss: 0.008208   Batch Acc: 76.56
[Train] Epoch: 1 [484736/620022]    Loss: 0.010328   Batch Acc: 73.44
[Train] Epoch: 1 [484800/620022]    Loss: 0.006831   Batch Acc: 87.50
[Train] Epoch: 1 [484864/620022]    Loss: 0.007405   Batch Acc: 82.81
[Train] Epoch: 1 [484928/620022]    Loss: 0.010478   Batch Acc: 67.19
[Train] Epoch: 1 [484992/620022]    Loss: 0.007419   Batch Acc: 79.69
[Train] Epoch: 1 [485056/620022]    Loss: 0.011544   Batch Acc: 73.44
[Train] Epoch: 1 [485120/620022]    Loss: 0.010743   Batch Acc: 68.75
[Train] Epoch: 1 [485184/620022]    Loss: 0.008858   Batch Acc: 76.56
[Train] Epoch: 1 [485248/620022]    Loss: 0.009191   Batch Acc: 79.69
[Train] Epoch: 1 [485312/620022]    Loss: 0.007802   Batch Acc: 76.56
[Train] Epoch: 1 [485376/620022]    Loss: 0.006728   Batch Acc: 84.38
[Train] Epoch: 1 [485440/620022]    Loss: 0.008742   Batch Acc: 75.00
[Train] Epoch: 1 [485504/620022]    Loss: 0.010070   Batch Acc: 70.31
[Train] Epoch: 1 [485568/620022]    Loss: 0.010143   Batch Acc: 75.00
[Train] Epoch: 1 [485632/620022]    Loss: 0.008532   Batch Acc: 81.25
[Train] Epoch: 1 [485696/620022]    Loss: 0.008779   Batch Acc: 76.56
[Train] Epoch: 1 [485760/620022]    Loss: 0.006560   Batch Acc: 84.38
[Train] Epoch: 1 [485824/620022]    Loss: 0.009601   Batch Acc: 78.12
[Train] Epoch: 1 [485888/620022]    Loss: 0.010071   Batch Acc: 75.00
[Train] Epoch: 1 [485952/620022]    Loss: 0.009176   Batch Acc: 82.81
[Train] Epoch: 1 [486016/620022]    Loss: 0.010218   Batch Acc: 70.31
[Train] Epoch: 1 [486080/620022]    Loss: 0.008255   Batch Acc: 82.81
[Train] Epoch: 1 [486144/620022]    Loss: 0.011290   Batch Acc: 67.19
[Train] Epoch: 1 [486208/620022]    Loss: 0.009001   Batch Acc: 78.12
[Train] Epoch: 1 [486272/620022]    Loss: 0.007372   Batch Acc: 84.38
[Train] Epoch: 1 [486336/620022]    Loss: 0.008843   Batch Acc: 76.56
[Train] Epoch: 1 [486400/620022]    Loss: 0.006466   Batch Acc: 84.38
[Train] Epoch: 1 [486464/620022]    Loss: 0.010074   Batch Acc: 68.75
[Train] Epoch: 1 [486528/620022]    Loss: 0.007964   Batch Acc: 79.69
[Train] Epoch: 1 [486592/620022]    Loss: 0.006060   Batch Acc: 85.94
[Train] Epoch: 1 [486656/620022]    Loss: 0.007081   Batch Acc: 84.38
[Train] Epoch: 1 [486720/620022]    Loss: 0.008479   Batch Acc: 82.81
[Train] Epoch: 1 [486784/620022]    Loss: 0.007390   Batch Acc: 82.81
[Train] Epoch: 1 [486848/620022]    Loss: 0.006001   Batch Acc: 85.94
[Train] Epoch: 1 [486912/620022]    Loss: 0.008625   Batch Acc: 75.00
[Train] Epoch: 1 [486976/620022]    Loss: 0.006845   Batch Acc: 84.38
[Train] Epoch: 1 [487040/620022]    Loss: 0.008772   Batch Acc: 76.56
[Train] Epoch: 1 [487104/620022]    Loss: 0.008833   Batch Acc: 78.12
[Train] Epoch: 1 [487168/620022]    Loss: 0.011092   Batch Acc: 67.19
[Train] Epoch: 1 [487232/620022]    Loss: 0.008262   Batch Acc: 76.56
[Train] Epoch: 1 [487296/620022]    Loss: 0.009920   Batch Acc: 73.44
[Train] Epoch: 1 [487360/620022]    Loss: 0.009270   Batch Acc: 75.00
[Train] Epoch: 1 [487424/620022]    Loss: 0.006134   Batch Acc: 85.94
[Train] Epoch: 1 [487488/620022]    Loss: 0.008628   Batch Acc: 79.69
[Train] Epoch: 1 [487552/620022]    Loss: 0.007062   Batch Acc: 84.38
[Train] Epoch: 1 [487616/620022]    Loss: 0.009769   Batch Acc: 76.56
[Train] Epoch: 1 [487680/620022]    Loss: 0.008147   Batch Acc: 78.12
[Train] Epoch: 1 [487744/620022]    Loss: 0.010071   Batch Acc: 75.00
[Train] Epoch: 1 [487808/620022]    Loss: 0.007275   Batch Acc: 81.25
[Train] Epoch: 1 [487872/620022]    Loss: 0.006936   Batch Acc: 81.25
[Train] Epoch: 1 [487936/620022]    Loss: 0.010034   Batch Acc: 65.62
[Train] Epoch: 1 [488000/620022]    Loss: 0.008022   Batch Acc: 82.81
[Train] Epoch: 1 [488064/620022]    Loss: 0.006639   Batch Acc: 81.25
[Train] Epoch: 1 [488128/620022]    Loss: 0.008627   Batch Acc: 78.12
[Train] Epoch: 1 [488192/620022]    Loss: 0.008245   Batch Acc: 79.69
[Train] Epoch: 1 [488256/620022]    Loss: 0.009459   Batch Acc: 79.69
[Train] Epoch: 1 [488320/620022]    Loss: 0.009891   Batch Acc: 71.88
[Train] Epoch: 1 [488384/620022]    Loss: 0.008821   Batch Acc: 73.44
[Train] Epoch: 1 [488448/620022]    Loss: 0.007466   Batch Acc: 81.25
[Train] Epoch: 1 [488512/620022]    Loss: 0.007327   Batch Acc: 76.56
[Train] Epoch: 1 [488576/620022]    Loss: 0.007737   Batch Acc: 82.81
[Train] Epoch: 1 [488640/620022]    Loss: 0.009513   Batch Acc: 76.56
[Train] Epoch: 1 [488704/620022]    Loss: 0.008338   Batch Acc: 81.25
[Train] Epoch: 1 [488768/620022]    Loss: 0.010144   Batch Acc: 70.31
[Train] Epoch: 1 [488832/620022]    Loss: 0.008358   Batch Acc: 82.81
[Train] Epoch: 1 [488896/620022]    Loss: 0.008326   Batch Acc: 79.69
[Train] Epoch: 1 [488960/620022]    Loss: 0.008756   Batch Acc: 78.12
[Train] Epoch: 1 [489024/620022]    Loss: 0.009524   Batch Acc: 73.44
[Train] Epoch: 1 [489088/620022]    Loss: 0.011062   Batch Acc: 70.31
[Train] Epoch: 1 [489152/620022]    Loss: 0.009635   Batch Acc: 71.88
[Train] Epoch: 1 [489216/620022]    Loss: 0.006549   Batch Acc: 82.81
[Train] Epoch: 1 [489280/620022]    Loss: 0.007448   Batch Acc: 82.81
[Train] Epoch: 1 [489344/620022]    Loss: 0.008346   Batch Acc: 79.69
[Train] Epoch: 1 [489408/620022]    Loss: 0.008078   Batch Acc: 81.25
[Train] Epoch: 1 [489472/620022]    Loss: 0.008229   Batch Acc: 79.69
[Train] Epoch: 1 [489536/620022]    Loss: 0.008705   Batch Acc: 82.81
[Train] Epoch: 1 [489600/620022]    Loss: 0.008617   Batch Acc: 76.56
[Train] Epoch: 1 [489664/620022]    Loss: 0.007368   Batch Acc: 84.38
[Train] Epoch: 1 [489728/620022]    Loss: 0.009834   Batch Acc: 76.56
[Train] Epoch: 1 [489792/620022]    Loss: 0.008724   Batch Acc: 75.00
[Train] Epoch: 1 [489856/620022]    Loss: 0.007843   Batch Acc: 76.56
[Train] Epoch: 1 [489920/620022]    Loss: 0.007959   Batch Acc: 71.88
[Train] Epoch: 1 [489984/620022]    Loss: 0.011543   Batch Acc: 68.75
[Train] Epoch: 1 [490048/620022]    Loss: 0.008733   Batch Acc: 76.56
[Train] Epoch: 1 [490112/620022]    Loss: 0.007630   Batch Acc: 85.94
[Train] Epoch: 1 [490176/620022]    Loss: 0.009287   Batch Acc: 76.56
[Train] Epoch: 1 [490240/620022]    Loss: 0.009012   Batch Acc: 76.56
[Train] Epoch: 1 [490304/620022]    Loss: 0.007872   Batch Acc: 81.25
[Train] Epoch: 1 [490368/620022]    Loss: 0.009216   Batch Acc: 70.31
[Train] Epoch: 1 [490432/620022]    Loss: 0.007395   Batch Acc: 79.69
[Train] Epoch: 1 [490496/620022]    Loss: 0.005619   Batch Acc: 87.50
[Train] Epoch: 1 [490560/620022]    Loss: 0.008503   Batch Acc: 81.25
[Train] Epoch: 1 [490624/620022]    Loss: 0.007885   Batch Acc: 76.56
[Train] Epoch: 1 [490688/620022]    Loss: 0.007368   Batch Acc: 79.69
[Train] Epoch: 1 [490752/620022]    Loss: 0.008412   Batch Acc: 82.81
[Train] Epoch: 1 [490816/620022]    Loss: 0.008096   Batch Acc: 78.12
[Train] Epoch: 1 [490880/620022]    Loss: 0.007251   Batch Acc: 87.50
[Train] Epoch: 1 [490944/620022]    Loss: 0.007000   Batch Acc: 81.25
[Train] Epoch: 1 [491008/620022]    Loss: 0.008416   Batch Acc: 84.38
[Train] Epoch: 1 [491072/620022]    Loss: 0.007561   Batch Acc: 82.81
[Train] Epoch: 1 [491136/620022]    Loss: 0.008610   Batch Acc: 79.69
[Train] Epoch: 1 [491200/620022]    Loss: 0.008383   Batch Acc: 71.88
[Train] Epoch: 1 [491264/620022]    Loss: 0.011396   Batch Acc: 76.56
[Train] Epoch: 1 [491328/620022]    Loss: 0.010231   Batch Acc: 75.00
[Train] Epoch: 1 [491392/620022]    Loss: 0.008427   Batch Acc: 78.12
[Train] Epoch: 1 [491456/620022]    Loss: 0.008858   Batch Acc: 78.12
[Train] Epoch: 1 [491520/620022]    Loss: 0.008972   Batch Acc: 71.88
[Train] Epoch: 1 [491584/620022]    Loss: 0.007889   Batch Acc: 82.81
[Train] Epoch: 1 [491648/620022]    Loss: 0.007223   Batch Acc: 81.25
[Train] Epoch: 1 [491712/620022]    Loss: 0.008438   Batch Acc: 75.00
[Train] Epoch: 1 [491776/620022]    Loss: 0.009927   Batch Acc: 70.31
[Train] Epoch: 1 [491840/620022]    Loss: 0.010224   Batch Acc: 71.88
[Train] Epoch: 1 [491904/620022]    Loss: 0.008121   Batch Acc: 79.69
[Train] Epoch: 1 [491968/620022]    Loss: 0.009089   Batch Acc: 79.69
[Train] Epoch: 1 [492032/620022]    Loss: 0.008424   Batch Acc: 81.25
[Train] Epoch: 1 [492096/620022]    Loss: 0.008730   Batch Acc: 76.56
[Train] Epoch: 1 [492160/620022]    Loss: 0.007550   Batch Acc: 84.38
[Train] Epoch: 1 [492224/620022]    Loss: 0.009376   Batch Acc: 70.31
[Train] Epoch: 1 [492288/620022]    Loss: 0.008301   Batch Acc: 76.56
[Train] Epoch: 1 [492352/620022]    Loss: 0.008282   Batch Acc: 79.69
[Train] Epoch: 1 [492416/620022]    Loss: 0.005187   Batch Acc: 90.62
[Train] Epoch: 1 [492480/620022]    Loss: 0.009757   Batch Acc: 70.31
[Train] Epoch: 1 [492544/620022]    Loss: 0.006584   Batch Acc: 84.38
[Train] Epoch: 1 [492608/620022]    Loss: 0.009946   Batch Acc: 71.88
[Train] Epoch: 1 [492672/620022]    Loss: 0.009302   Batch Acc: 78.12
[Train] Epoch: 1 [492736/620022]    Loss: 0.007388   Batch Acc: 78.12
[Train] Epoch: 1 [492800/620022]    Loss: 0.009915   Batch Acc: 75.00
[Train] Epoch: 1 [492864/620022]    Loss: 0.012198   Batch Acc: 62.50
[Train] Epoch: 1 [492928/620022]    Loss: 0.008438   Batch Acc: 75.00
[Train] Epoch: 1 [492992/620022]    Loss: 0.007114   Batch Acc: 84.38
[Train] Epoch: 1 [493056/620022]    Loss: 0.010159   Batch Acc: 75.00
[Train] Epoch: 1 [493120/620022]    Loss: 0.008750   Batch Acc: 75.00
[Train] Epoch: 1 [493184/620022]    Loss: 0.010098   Batch Acc: 73.44
[Train] Epoch: 1 [493248/620022]    Loss: 0.009381   Batch Acc: 75.00
[Train] Epoch: 1 [493312/620022]    Loss: 0.006374   Batch Acc: 89.06
[Train] Epoch: 1 [493376/620022]    Loss: 0.010027   Batch Acc: 71.88
[Train] Epoch: 1 [493440/620022]    Loss: 0.008751   Batch Acc: 79.69
[Train] Epoch: 1 [493504/620022]    Loss: 0.007746   Batch Acc: 81.25
[Train] Epoch: 1 [493568/620022]    Loss: 0.007916   Batch Acc: 78.12
[Train] Epoch: 1 [493632/620022]    Loss: 0.008952   Batch Acc: 75.00
[Train] Epoch: 1 [493696/620022]    Loss: 0.007514   Batch Acc: 85.94
[Train] Epoch: 1 [493760/620022]    Loss: 0.009258   Batch Acc: 76.56
[Train] Epoch: 1 [493824/620022]    Loss: 0.008416   Batch Acc: 78.12
[Train] Epoch: 1 [493888/620022]    Loss: 0.006521   Batch Acc: 82.81
[Train] Epoch: 1 [493952/620022]    Loss: 0.010035   Batch Acc: 78.12
[Train] Epoch: 1 [494016/620022]    Loss: 0.008537   Batch Acc: 76.56
[Train] Epoch: 1 [494080/620022]    Loss: 0.008863   Batch Acc: 71.88
[Train] Epoch: 1 [494144/620022]    Loss: 0.008174   Batch Acc: 81.25
[Train] Epoch: 1 [494208/620022]    Loss: 0.007950   Batch Acc: 84.38
[Train] Epoch: 1 [494272/620022]    Loss: 0.006545   Batch Acc: 87.50
[Train] Epoch: 1 [494336/620022]    Loss: 0.007894   Batch Acc: 79.69
[Train] Epoch: 1 [494400/620022]    Loss: 0.008002   Batch Acc: 78.12
[Train] Epoch: 1 [494464/620022]    Loss: 0.009161   Batch Acc: 73.44
[Train] Epoch: 1 [494528/620022]    Loss: 0.006629   Batch Acc: 87.50
[Train] Epoch: 1 [494592/620022]    Loss: 0.009174   Batch Acc: 78.12
[Train] Epoch: 1 [494656/620022]    Loss: 0.009410   Batch Acc: 76.56
[Train] Epoch: 1 [494720/620022]    Loss: 0.008294   Batch Acc: 79.69
[Train] Epoch: 1 [494784/620022]    Loss: 0.010516   Batch Acc: 71.88
[Train] Epoch: 1 [494848/620022]    Loss: 0.008665   Batch Acc: 78.12
[Train] Epoch: 1 [494912/620022]    Loss: 0.010763   Batch Acc: 70.31
[Train] Epoch: 1 [494976/620022]    Loss: 0.008092   Batch Acc: 79.69
[Train] Epoch: 1 [495040/620022]    Loss: 0.008300   Batch Acc: 78.12
[Train] Epoch: 1 [495104/620022]    Loss: 0.009395   Batch Acc: 71.88
[Train] Epoch: 1 [495168/620022]    Loss: 0.011042   Batch Acc: 71.88
[Train] Epoch: 1 [495232/620022]    Loss: 0.011246   Batch Acc: 73.44
[Train] Epoch: 1 [495296/620022]    Loss: 0.008545   Batch Acc: 73.44
[Train] Epoch: 1 [495360/620022]    Loss: 0.010904   Batch Acc: 71.88
[Train] Epoch: 1 [495424/620022]    Loss: 0.007562   Batch Acc: 75.00
[Train] Epoch: 1 [495488/620022]    Loss: 0.009440   Batch Acc: 71.88
[Train] Epoch: 1 [495552/620022]    Loss: 0.010479   Batch Acc: 73.44
[Train] Epoch: 1 [495616/620022]    Loss: 0.008029   Batch Acc: 79.69
[Train] Epoch: 1 [495680/620022]    Loss: 0.009083   Batch Acc: 73.44
[Train] Epoch: 1 [495744/620022]    Loss: 0.006260   Batch Acc: 85.94
[Train] Epoch: 1 [495808/620022]    Loss: 0.011172   Batch Acc: 65.62
[Train] Epoch: 1 [495872/620022]    Loss: 0.010313   Batch Acc: 70.31
[Train] Epoch: 1 [495936/620022]    Loss: 0.008463   Batch Acc: 75.00
[Train] Epoch: 1 [496000/620022]    Loss: 0.008987   Batch Acc: 81.25
[Train] Epoch: 1 [496064/620022]    Loss: 0.008839   Batch Acc: 79.69
[Train] Epoch: 1 [496128/620022]    Loss: 0.007920   Batch Acc: 81.25
[Train] Epoch: 1 [496192/620022]    Loss: 0.009493   Batch Acc: 78.12
[Train] Epoch: 1 [496256/620022]    Loss: 0.007661   Batch Acc: 82.81
[Train] Epoch: 1 [496320/620022]    Loss: 0.007990   Batch Acc: 81.25
[Train] Epoch: 1 [496384/620022]    Loss: 0.008730   Batch Acc: 76.56
[Train] Epoch: 1 [496448/620022]    Loss: 0.008324   Batch Acc: 76.56
[Train] Epoch: 1 [496512/620022]    Loss: 0.008145   Batch Acc: 78.12
[Train] Epoch: 1 [496576/620022]    Loss: 0.010122   Batch Acc: 78.12
[Train] Epoch: 1 [496640/620022]    Loss: 0.009905   Batch Acc: 71.88
[Train] Epoch: 1 [496704/620022]    Loss: 0.010269   Batch Acc: 78.12
[Train] Epoch: 1 [496768/620022]    Loss: 0.007345   Batch Acc: 79.69
[Train] Epoch: 1 [496832/620022]    Loss: 0.008799   Batch Acc: 79.69
[Train] Epoch: 1 [496896/620022]    Loss: 0.009000   Batch Acc: 81.25
[Train] Epoch: 1 [496960/620022]    Loss: 0.010640   Batch Acc: 76.56
[Train] Epoch: 1 [497024/620022]    Loss: 0.008678   Batch Acc: 82.81
[Train] Epoch: 1 [497088/620022]    Loss: 0.007825   Batch Acc: 87.50
[Train] Epoch: 1 [497152/620022]    Loss: 0.005899   Batch Acc: 85.94
[Train] Epoch: 1 [497216/620022]    Loss: 0.008455   Batch Acc: 81.25
[Train] Epoch: 1 [497280/620022]    Loss: 0.007500   Batch Acc: 79.69
[Train] Epoch: 1 [497344/620022]    Loss: 0.008194   Batch Acc: 79.69
[Train] Epoch: 1 [497408/620022]    Loss: 0.009576   Batch Acc: 75.00
[Train] Epoch: 1 [497472/620022]    Loss: 0.010340   Batch Acc: 71.88
[Train] Epoch: 1 [497536/620022]    Loss: 0.009703   Batch Acc: 73.44
[Train] Epoch: 1 [497600/620022]    Loss: 0.008292   Batch Acc: 82.81
[Train] Epoch: 1 [497664/620022]    Loss: 0.007281   Batch Acc: 84.38
[Train] Epoch: 1 [497728/620022]    Loss: 0.005795   Batch Acc: 89.06
[Train] Epoch: 1 [497792/620022]    Loss: 0.007286   Batch Acc: 79.69
[Train] Epoch: 1 [497856/620022]    Loss: 0.011698   Batch Acc: 65.62
[Train] Epoch: 1 [497920/620022]    Loss: 0.008071   Batch Acc: 78.12
[Train] Epoch: 1 [497984/620022]    Loss: 0.008044   Batch Acc: 82.81
[Train] Epoch: 1 [498048/620022]    Loss: 0.007527   Batch Acc: 85.94
[Train] Epoch: 1 [498112/620022]    Loss: 0.008792   Batch Acc: 75.00
[Train] Epoch: 1 [498176/620022]    Loss: 0.007461   Batch Acc: 81.25
[Train] Epoch: 1 [498240/620022]    Loss: 0.010466   Batch Acc: 71.88
[Train] Epoch: 1 [498304/620022]    Loss: 0.007184   Batch Acc: 82.81
[Train] Epoch: 1 [498368/620022]    Loss: 0.009800   Batch Acc: 76.56
[Train] Epoch: 1 [498432/620022]    Loss: 0.007931   Batch Acc: 76.56
[Train] Epoch: 1 [498496/620022]    Loss: 0.008147   Batch Acc: 79.69
[Train] Epoch: 1 [498560/620022]    Loss: 0.009378   Batch Acc: 76.56
[Train] Epoch: 1 [498624/620022]    Loss: 0.008151   Batch Acc: 81.25
[Train] Epoch: 1 [498688/620022]    Loss: 0.007771   Batch Acc: 85.94
[Train] Epoch: 1 [498752/620022]    Loss: 0.007219   Batch Acc: 81.25
[Train] Epoch: 1 [498816/620022]    Loss: 0.010544   Batch Acc: 76.56
[Train] Epoch: 1 [498880/620022]    Loss: 0.008402   Batch Acc: 76.56
[Train] Epoch: 1 [498944/620022]    Loss: 0.009549   Batch Acc: 70.31
[Train] Epoch: 1 [499008/620022]    Loss: 0.010625   Batch Acc: 75.00
[Train] Epoch: 1 [499072/620022]    Loss: 0.009115   Batch Acc: 75.00
[Train] Epoch: 1 [499136/620022]    Loss: 0.009729   Batch Acc: 78.12
[Train] Epoch: 1 [499200/620022]    Loss: 0.011023   Batch Acc: 68.75
[Train] Epoch: 1 [499264/620022]    Loss: 0.009247   Batch Acc: 75.00
[Train] Epoch: 1 [499328/620022]    Loss: 0.007361   Batch Acc: 81.25
[Train] Epoch: 1 [499392/620022]    Loss: 0.008746   Batch Acc: 76.56
[Train] Epoch: 1 [499456/620022]    Loss: 0.007434   Batch Acc: 87.50
[Train] Epoch: 1 [499520/620022]    Loss: 0.010245   Batch Acc: 71.88
[Train] Epoch: 1 [499584/620022]    Loss: 0.008561   Batch Acc: 81.25
[Train] Epoch: 1 [499648/620022]    Loss: 0.009409   Batch Acc: 73.44
[Train] Epoch: 1 [499712/620022]    Loss: 0.009040   Batch Acc: 79.69
[Train] Epoch: 1 [499776/620022]    Loss: 0.009607   Batch Acc: 81.25
[Train] Epoch: 1 [499840/620022]    Loss: 0.009969   Batch Acc: 73.44
[Train] Epoch: 1 [499904/620022]    Loss: 0.008440   Batch Acc: 75.00
[Train] Epoch: 1 [499968/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 1 [500032/620022]    Loss: 0.009165   Batch Acc: 81.25
[Train] Epoch: 1 [500096/620022]    Loss: 0.008368   Batch Acc: 79.69
[Train] Epoch: 1 [500160/620022]    Loss: 0.008226   Batch Acc: 78.12
[Train] Epoch: 1 [500224/620022]    Loss: 0.009035   Batch Acc: 75.00
[Train] Epoch: 1 [500288/620022]    Loss: 0.008583   Batch Acc: 81.25
[Train] Epoch: 1 [500352/620022]    Loss: 0.006874   Batch Acc: 82.81
[Train] Epoch: 1 [500416/620022]    Loss: 0.008322   Batch Acc: 70.31
[Train] Epoch: 1 [500480/620022]    Loss: 0.010111   Batch Acc: 76.56
[Train] Epoch: 1 [500544/620022]    Loss: 0.008320   Batch Acc: 84.38
[Train] Epoch: 1 [500608/620022]    Loss: 0.010758   Batch Acc: 78.12
[Train] Epoch: 1 [500672/620022]    Loss: 0.008310   Batch Acc: 76.56
[Train] Epoch: 1 [500736/620022]    Loss: 0.007233   Batch Acc: 76.56
[Train] Epoch: 1 [500800/620022]    Loss: 0.007698   Batch Acc: 84.38
[Train] Epoch: 1 [500864/620022]    Loss: 0.007686   Batch Acc: 84.38
[Train] Epoch: 1 [500928/620022]    Loss: 0.006596   Batch Acc: 79.69
[Train] Epoch: 1 [500992/620022]    Loss: 0.009731   Batch Acc: 78.12
[Train] Epoch: 1 [501056/620022]    Loss: 0.008083   Batch Acc: 79.69
[Train] Epoch: 1 [501120/620022]    Loss: 0.009976   Batch Acc: 73.44
[Train] Epoch: 1 [501184/620022]    Loss: 0.007214   Batch Acc: 84.38
[Train] Epoch: 1 [501248/620022]    Loss: 0.006192   Batch Acc: 84.38
[Train] Epoch: 1 [501312/620022]    Loss: 0.005726   Batch Acc: 92.19
[Train] Epoch: 1 [501376/620022]    Loss: 0.008203   Batch Acc: 75.00
[Train] Epoch: 1 [501440/620022]    Loss: 0.009831   Batch Acc: 78.12
[Train] Epoch: 1 [501504/620022]    Loss: 0.010967   Batch Acc: 68.75
[Train] Epoch: 1 [501568/620022]    Loss: 0.008675   Batch Acc: 76.56
[Train] Epoch: 1 [501632/620022]    Loss: 0.009750   Batch Acc: 73.44
[Train] Epoch: 1 [501696/620022]    Loss: 0.008958   Batch Acc: 78.12
[Train] Epoch: 1 [501760/620022]    Loss: 0.008762   Batch Acc: 78.12
[Train] Epoch: 1 [501824/620022]    Loss: 0.007500   Batch Acc: 85.94
[Train] Epoch: 1 [501888/620022]    Loss: 0.009344   Batch Acc: 70.31
[Train] Epoch: 1 [501952/620022]    Loss: 0.008358   Batch Acc: 81.25
[Train] Epoch: 1 [502016/620022]    Loss: 0.009254   Batch Acc: 76.56
[Train] Epoch: 1 [502080/620022]    Loss: 0.008458   Batch Acc: 78.12
[Train] Epoch: 1 [502144/620022]    Loss: 0.008406   Batch Acc: 76.56
[Train] Epoch: 1 [502208/620022]    Loss: 0.009711   Batch Acc: 76.56
[Train] Epoch: 1 [502272/620022]    Loss: 0.008434   Batch Acc: 79.69
[Train] Epoch: 1 [502336/620022]    Loss: 0.009211   Batch Acc: 76.56
[Train] Epoch: 1 [502400/620022]    Loss: 0.010064   Batch Acc: 70.31
[Train] Epoch: 1 [502464/620022]    Loss: 0.007503   Batch Acc: 79.69
[Train] Epoch: 1 [502528/620022]    Loss: 0.009275   Batch Acc: 73.44
[Train] Epoch: 1 [502592/620022]    Loss: 0.008987   Batch Acc: 78.12
[Train] Epoch: 1 [502656/620022]    Loss: 0.010208   Batch Acc: 68.75
[Train] Epoch: 1 [502720/620022]    Loss: 0.010907   Batch Acc: 73.44
[Train] Epoch: 1 [502784/620022]    Loss: 0.009104   Batch Acc: 78.12
[Train] Epoch: 1 [502848/620022]    Loss: 0.010514   Batch Acc: 70.31
[Train] Epoch: 1 [502912/620022]    Loss: 0.007536   Batch Acc: 84.38
[Train] Epoch: 1 [502976/620022]    Loss: 0.008074   Batch Acc: 79.69
[Train] Epoch: 1 [503040/620022]    Loss: 0.010335   Batch Acc: 73.44
[Train] Epoch: 1 [503104/620022]    Loss: 0.008394   Batch Acc: 76.56
[Train] Epoch: 1 [503168/620022]    Loss: 0.010508   Batch Acc: 75.00
[Train] Epoch: 1 [503232/620022]    Loss: 0.010206   Batch Acc: 78.12
[Train] Epoch: 1 [503296/620022]    Loss: 0.009650   Batch Acc: 71.88
[Train] Epoch: 1 [503360/620022]    Loss: 0.008908   Batch Acc: 73.44
[Train] Epoch: 1 [503424/620022]    Loss: 0.008584   Batch Acc: 79.69
[Train] Epoch: 1 [503488/620022]    Loss: 0.008643   Batch Acc: 75.00
[Train] Epoch: 1 [503552/620022]    Loss: 0.009895   Batch Acc: 76.56
[Train] Epoch: 1 [503616/620022]    Loss: 0.006924   Batch Acc: 79.69
[Train] Epoch: 1 [503680/620022]    Loss: 0.005993   Batch Acc: 90.62
[Train] Epoch: 1 [503744/620022]    Loss: 0.008453   Batch Acc: 79.69
[Train] Epoch: 1 [503808/620022]    Loss: 0.008556   Batch Acc: 78.12
[Train] Epoch: 1 [503872/620022]    Loss: 0.008437   Batch Acc: 82.81
[Train] Epoch: 1 [503936/620022]    Loss: 0.008443   Batch Acc: 78.12
[Train] Epoch: 1 [504000/620022]    Loss: 0.007041   Batch Acc: 85.94
[Train] Epoch: 1 [504064/620022]    Loss: 0.009575   Batch Acc: 81.25
[Train] Epoch: 1 [504128/620022]    Loss: 0.009090   Batch Acc: 79.69
[Train] Epoch: 1 [504192/620022]    Loss: 0.012313   Batch Acc: 68.75
[Train] Epoch: 1 [504256/620022]    Loss: 0.008104   Batch Acc: 75.00
[Train] Epoch: 1 [504320/620022]    Loss: 0.011483   Batch Acc: 71.88
[Train] Epoch: 1 [504384/620022]    Loss: 0.011598   Batch Acc: 62.50
[Train] Epoch: 1 [504448/620022]    Loss: 0.005062   Batch Acc: 87.50
[Train] Epoch: 1 [504512/620022]    Loss: 0.009079   Batch Acc: 76.56
[Train] Epoch: 1 [504576/620022]    Loss: 0.009786   Batch Acc: 71.88
[Train] Epoch: 1 [504640/620022]    Loss: 0.009401   Batch Acc: 68.75
[Train] Epoch: 1 [504704/620022]    Loss: 0.009962   Batch Acc: 78.12
[Train] Epoch: 1 [504768/620022]    Loss: 0.006709   Batch Acc: 82.81
[Train] Epoch: 1 [504832/620022]    Loss: 0.008039   Batch Acc: 82.81
[Train] Epoch: 1 [504896/620022]    Loss: 0.007912   Batch Acc: 73.44
[Train] Epoch: 1 [504960/620022]    Loss: 0.009016   Batch Acc: 76.56
[Train] Epoch: 1 [505024/620022]    Loss: 0.009281   Batch Acc: 75.00
[Train] Epoch: 1 [505088/620022]    Loss: 0.008769   Batch Acc: 78.12
[Train] Epoch: 1 [505152/620022]    Loss: 0.006832   Batch Acc: 82.81
[Train] Epoch: 1 [505216/620022]    Loss: 0.010165   Batch Acc: 76.56
[Train] Epoch: 1 [505280/620022]    Loss: 0.009065   Batch Acc: 81.25
[Train] Epoch: 1 [505344/620022]    Loss: 0.008133   Batch Acc: 78.12
[Train] Epoch: 1 [505408/620022]    Loss: 0.008834   Batch Acc: 75.00
[Train] Epoch: 1 [505472/620022]    Loss: 0.009317   Batch Acc: 73.44
[Train] Epoch: 1 [505536/620022]    Loss: 0.009407   Batch Acc: 75.00
[Train] Epoch: 1 [505600/620022]    Loss: 0.010570   Batch Acc: 76.56
[Train] Epoch: 1 [505664/620022]    Loss: 0.009259   Batch Acc: 78.12
[Train] Epoch: 1 [505728/620022]    Loss: 0.010167   Batch Acc: 71.88
[Train] Epoch: 1 [505792/620022]    Loss: 0.009879   Batch Acc: 76.56
[Train] Epoch: 1 [505856/620022]    Loss: 0.007836   Batch Acc: 78.12
[Train] Epoch: 1 [505920/620022]    Loss: 0.009682   Batch Acc: 75.00
[Train] Epoch: 1 [505984/620022]    Loss: 0.008912   Batch Acc: 75.00
[Train] Epoch: 1 [506048/620022]    Loss: 0.007748   Batch Acc: 84.38
[Train] Epoch: 1 [506112/620022]    Loss: 0.008878   Batch Acc: 78.12
[Train] Epoch: 1 [506176/620022]    Loss: 0.007437   Batch Acc: 84.38
[Train] Epoch: 1 [506240/620022]    Loss: 0.008080   Batch Acc: 76.56
[Train] Epoch: 1 [506304/620022]    Loss: 0.007043   Batch Acc: 82.81
[Train] Epoch: 1 [506368/620022]    Loss: 0.009865   Batch Acc: 70.31
[Train] Epoch: 1 [506432/620022]    Loss: 0.010694   Batch Acc: 71.88
[Train] Epoch: 1 [506496/620022]    Loss: 0.008067   Batch Acc: 81.25
[Train] Epoch: 1 [506560/620022]    Loss: 0.009127   Batch Acc: 73.44
[Train] Epoch: 1 [506624/620022]    Loss: 0.006045   Batch Acc: 87.50
[Train] Epoch: 1 [506688/620022]    Loss: 0.009401   Batch Acc: 70.31
[Train] Epoch: 1 [506752/620022]    Loss: 0.009078   Batch Acc: 79.69
[Train] Epoch: 1 [506816/620022]    Loss: 0.008187   Batch Acc: 78.12
[Train] Epoch: 1 [506880/620022]    Loss: 0.008060   Batch Acc: 82.81
[Train] Epoch: 1 [506944/620022]    Loss: 0.008485   Batch Acc: 76.56
[Train] Epoch: 1 [507008/620022]    Loss: 0.010689   Batch Acc: 68.75
[Train] Epoch: 1 [507072/620022]    Loss: 0.008083   Batch Acc: 82.81
[Train] Epoch: 1 [507136/620022]    Loss: 0.010311   Batch Acc: 76.56
[Train] Epoch: 1 [507200/620022]    Loss: 0.009771   Batch Acc: 70.31
[Train] Epoch: 1 [507264/620022]    Loss: 0.008865   Batch Acc: 76.56
[Train] Epoch: 1 [507328/620022]    Loss: 0.010165   Batch Acc: 71.88
[Train] Epoch: 1 [507392/620022]    Loss: 0.007614   Batch Acc: 79.69
[Train] Epoch: 1 [507456/620022]    Loss: 0.009975   Batch Acc: 75.00
[Train] Epoch: 1 [507520/620022]    Loss: 0.007967   Batch Acc: 78.12
[Train] Epoch: 1 [507584/620022]    Loss: 0.007461   Batch Acc: 84.38
[Train] Epoch: 1 [507648/620022]    Loss: 0.010396   Batch Acc: 76.56
[Train] Epoch: 1 [507712/620022]    Loss: 0.009290   Batch Acc: 73.44
[Train] Epoch: 1 [507776/620022]    Loss: 0.008450   Batch Acc: 79.69
[Train] Epoch: 1 [507840/620022]    Loss: 0.006594   Batch Acc: 79.69
[Train] Epoch: 1 [507904/620022]    Loss: 0.010413   Batch Acc: 70.31
[Train] Epoch: 1 [507968/620022]    Loss: 0.007493   Batch Acc: 84.38
[Train] Epoch: 1 [508032/620022]    Loss: 0.009779   Batch Acc: 76.56
[Train] Epoch: 1 [508096/620022]    Loss: 0.007422   Batch Acc: 79.69
[Train] Epoch: 1 [508160/620022]    Loss: 0.008038   Batch Acc: 85.94
[Train] Epoch: 1 [508224/620022]    Loss: 0.012289   Batch Acc: 65.62
[Train] Epoch: 1 [508288/620022]    Loss: 0.006017   Batch Acc: 89.06
[Train] Epoch: 1 [508352/620022]    Loss: 0.007784   Batch Acc: 79.69
[Train] Epoch: 1 [508416/620022]    Loss: 0.007192   Batch Acc: 81.25
[Train] Epoch: 1 [508480/620022]    Loss: 0.008335   Batch Acc: 73.44
[Train] Epoch: 1 [508544/620022]    Loss: 0.008608   Batch Acc: 76.56
[Train] Epoch: 1 [508608/620022]    Loss: 0.008740   Batch Acc: 75.00
[Train] Epoch: 1 [508672/620022]    Loss: 0.007993   Batch Acc: 81.25
[Train] Epoch: 1 [508736/620022]    Loss: 0.008982   Batch Acc: 78.12
[Train] Epoch: 1 [508800/620022]    Loss: 0.007466   Batch Acc: 79.69
[Train] Epoch: 1 [508864/620022]    Loss: 0.008515   Batch Acc: 79.69
[Train] Epoch: 1 [508928/620022]    Loss: 0.010235   Batch Acc: 70.31
[Train] Epoch: 1 [508992/620022]    Loss: 0.007982   Batch Acc: 84.38
[Train] Epoch: 1 [509056/620022]    Loss: 0.007814   Batch Acc: 75.00
[Train] Epoch: 1 [509120/620022]    Loss: 0.008077   Batch Acc: 75.00
[Train] Epoch: 1 [509184/620022]    Loss: 0.007828   Batch Acc: 79.69
[Train] Epoch: 1 [509248/620022]    Loss: 0.009092   Batch Acc: 79.69
[Train] Epoch: 1 [509312/620022]    Loss: 0.010751   Batch Acc: 70.31
[Train] Epoch: 1 [509376/620022]    Loss: 0.009142   Batch Acc: 78.12
[Train] Epoch: 1 [509440/620022]    Loss: 0.009034   Batch Acc: 82.81
[Train] Epoch: 1 [509504/620022]    Loss: 0.009955   Batch Acc: 78.12
[Train] Epoch: 1 [509568/620022]    Loss: 0.006516   Batch Acc: 82.81
[Train] Epoch: 1 [509632/620022]    Loss: 0.007812   Batch Acc: 76.56
[Train] Epoch: 1 [509696/620022]    Loss: 0.009571   Batch Acc: 75.00
[Train] Epoch: 1 [509760/620022]    Loss: 0.007047   Batch Acc: 82.81
[Train] Epoch: 1 [509824/620022]    Loss: 0.008818   Batch Acc: 78.12
[Train] Epoch: 1 [509888/620022]    Loss: 0.009746   Batch Acc: 75.00
[Train] Epoch: 1 [509952/620022]    Loss: 0.009117   Batch Acc: 73.44
[Train] Epoch: 1 [510016/620022]    Loss: 0.009908   Batch Acc: 70.31
[Train] Epoch: 1 [510080/620022]    Loss: 0.007641   Batch Acc: 84.38
[Train] Epoch: 1 [510144/620022]    Loss: 0.010126   Batch Acc: 71.88
[Train] Epoch: 1 [510208/620022]    Loss: 0.008794   Batch Acc: 76.56
[Train] Epoch: 1 [510272/620022]    Loss: 0.007739   Batch Acc: 78.12
[Train] Epoch: 1 [510336/620022]    Loss: 0.009646   Batch Acc: 75.00
[Train] Epoch: 1 [510400/620022]    Loss: 0.007438   Batch Acc: 84.38
[Train] Epoch: 1 [510464/620022]    Loss: 0.009690   Batch Acc: 70.31
[Train] Epoch: 1 [510528/620022]    Loss: 0.008136   Batch Acc: 78.12
[Train] Epoch: 1 [510592/620022]    Loss: 0.007142   Batch Acc: 81.25
[Train] Epoch: 1 [510656/620022]    Loss: 0.008640   Batch Acc: 73.44
[Train] Epoch: 1 [510720/620022]    Loss: 0.008469   Batch Acc: 81.25
[Train] Epoch: 1 [510784/620022]    Loss: 0.008957   Batch Acc: 73.44
[Train] Epoch: 1 [510848/620022]    Loss: 0.009178   Batch Acc: 75.00
[Train] Epoch: 1 [510912/620022]    Loss: 0.005709   Batch Acc: 87.50
[Train] Epoch: 1 [510976/620022]    Loss: 0.008807   Batch Acc: 76.56
[Train] Epoch: 1 [511040/620022]    Loss: 0.009222   Batch Acc: 76.56
[Train] Epoch: 1 [511104/620022]    Loss: 0.007753   Batch Acc: 78.12
[Train] Epoch: 1 [511168/620022]    Loss: 0.010210   Batch Acc: 78.12
[Train] Epoch: 1 [511232/620022]    Loss: 0.008373   Batch Acc: 79.69
[Train] Epoch: 1 [511296/620022]    Loss: 0.007252   Batch Acc: 81.25
[Train] Epoch: 1 [511360/620022]    Loss: 0.008092   Batch Acc: 75.00
[Train] Epoch: 1 [511424/620022]    Loss: 0.007839   Batch Acc: 81.25
[Train] Epoch: 1 [511488/620022]    Loss: 0.010356   Batch Acc: 73.44
[Train] Epoch: 1 [511552/620022]    Loss: 0.008438   Batch Acc: 78.12
[Train] Epoch: 1 [511616/620022]    Loss: 0.009667   Batch Acc: 73.44
[Train] Epoch: 1 [511680/620022]    Loss: 0.008896   Batch Acc: 82.81
[Train] Epoch: 1 [511744/620022]    Loss: 0.008017   Batch Acc: 82.81
[Train] Epoch: 1 [511808/620022]    Loss: 0.008465   Batch Acc: 78.12
[Train] Epoch: 1 [511872/620022]    Loss: 0.010642   Batch Acc: 71.88
[Train] Epoch: 1 [511936/620022]    Loss: 0.009715   Batch Acc: 73.44
[Train] Epoch: 1 [512000/620022]    Loss: 0.005771   Batch Acc: 85.94
[Train] Epoch: 1 [512064/620022]    Loss: 0.009882   Batch Acc: 76.56
[Train] Epoch: 1 [512128/620022]    Loss: 0.010346   Batch Acc: 73.44
[Train] Epoch: 1 [512192/620022]    Loss: 0.012589   Batch Acc: 65.62
[Train] Epoch: 1 [512256/620022]    Loss: 0.007538   Batch Acc: 84.38
[Train] Epoch: 1 [512320/620022]    Loss: 0.008320   Batch Acc: 75.00
[Train] Epoch: 1 [512384/620022]    Loss: 0.009628   Batch Acc: 75.00
[Train] Epoch: 1 [512448/620022]    Loss: 0.008500   Batch Acc: 78.12
[Train] Epoch: 1 [512512/620022]    Loss: 0.007071   Batch Acc: 85.94
[Train] Epoch: 1 [512576/620022]    Loss: 0.008133   Batch Acc: 76.56
[Train] Epoch: 1 [512640/620022]    Loss: 0.008094   Batch Acc: 82.81
[Train] Epoch: 1 [512704/620022]    Loss: 0.009093   Batch Acc: 75.00
[Train] Epoch: 1 [512768/620022]    Loss: 0.009519   Batch Acc: 76.56
[Train] Epoch: 1 [512832/620022]    Loss: 0.009476   Batch Acc: 75.00
[Train] Epoch: 1 [512896/620022]    Loss: 0.007847   Batch Acc: 84.38
[Train] Epoch: 1 [512960/620022]    Loss: 0.010913   Batch Acc: 64.06
[Train] Epoch: 1 [513024/620022]    Loss: 0.008646   Batch Acc: 70.31
[Train] Epoch: 1 [513088/620022]    Loss: 0.010263   Batch Acc: 76.56
[Train] Epoch: 1 [513152/620022]    Loss: 0.008046   Batch Acc: 73.44
[Train] Epoch: 1 [513216/620022]    Loss: 0.009419   Batch Acc: 75.00
[Train] Epoch: 1 [513280/620022]    Loss: 0.009711   Batch Acc: 75.00
[Train] Epoch: 1 [513344/620022]    Loss: 0.009979   Batch Acc: 71.88
[Train] Epoch: 1 [513408/620022]    Loss: 0.008810   Batch Acc: 75.00
[Train] Epoch: 1 [513472/620022]    Loss: 0.009286   Batch Acc: 76.56
[Train] Epoch: 1 [513536/620022]    Loss: 0.007799   Batch Acc: 76.56
[Train] Epoch: 1 [513600/620022]    Loss: 0.007424   Batch Acc: 81.25
[Train] Epoch: 1 [513664/620022]    Loss: 0.008309   Batch Acc: 81.25
[Train] Epoch: 1 [513728/620022]    Loss: 0.007707   Batch Acc: 78.12
[Train] Epoch: 1 [513792/620022]    Loss: 0.007244   Batch Acc: 82.81
[Train] Epoch: 1 [513856/620022]    Loss: 0.010688   Batch Acc: 71.88
[Train] Epoch: 1 [513920/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 1 [513984/620022]    Loss: 0.008322   Batch Acc: 73.44
[Train] Epoch: 1 [514048/620022]    Loss: 0.007709   Batch Acc: 79.69
[Train] Epoch: 1 [514112/620022]    Loss: 0.009034   Batch Acc: 75.00
[Train] Epoch: 1 [514176/620022]    Loss: 0.011939   Batch Acc: 68.75
[Train] Epoch: 1 [514240/620022]    Loss: 0.009052   Batch Acc: 76.56
[Train] Epoch: 1 [514304/620022]    Loss: 0.009908   Batch Acc: 78.12
[Train] Epoch: 1 [514368/620022]    Loss: 0.010472   Batch Acc: 71.88
[Train] Epoch: 1 [514432/620022]    Loss: 0.008173   Batch Acc: 81.25
[Train] Epoch: 1 [514496/620022]    Loss: 0.007105   Batch Acc: 85.94
[Train] Epoch: 1 [514560/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 1 [514624/620022]    Loss: 0.008150   Batch Acc: 81.25
[Train] Epoch: 1 [514688/620022]    Loss: 0.009935   Batch Acc: 75.00
[Train] Epoch: 1 [514752/620022]    Loss: 0.010289   Batch Acc: 73.44
[Train] Epoch: 1 [514816/620022]    Loss: 0.007730   Batch Acc: 85.94
[Train] Epoch: 1 [514880/620022]    Loss: 0.007403   Batch Acc: 79.69
[Train] Epoch: 1 [514944/620022]    Loss: 0.008407   Batch Acc: 76.56
[Train] Epoch: 1 [515008/620022]    Loss: 0.010104   Batch Acc: 75.00
[Train] Epoch: 1 [515072/620022]    Loss: 0.009153   Batch Acc: 79.69
[Train] Epoch: 1 [515136/620022]    Loss: 0.011778   Batch Acc: 67.19
[Train] Epoch: 1 [515200/620022]    Loss: 0.007745   Batch Acc: 76.56
[Train] Epoch: 1 [515264/620022]    Loss: 0.009160   Batch Acc: 73.44
[Train] Epoch: 1 [515328/620022]    Loss: 0.006657   Batch Acc: 85.94
[Train] Epoch: 1 [515392/620022]    Loss: 0.007079   Batch Acc: 82.81
[Train] Epoch: 1 [515456/620022]    Loss: 0.008520   Batch Acc: 79.69
[Train] Epoch: 1 [515520/620022]    Loss: 0.008196   Batch Acc: 76.56
[Train] Epoch: 1 [515584/620022]    Loss: 0.006554   Batch Acc: 87.50
[Train] Epoch: 1 [515648/620022]    Loss: 0.007391   Batch Acc: 82.81
[Train] Epoch: 1 [515712/620022]    Loss: 0.007611   Batch Acc: 79.69
[Train] Epoch: 1 [515776/620022]    Loss: 0.006295   Batch Acc: 85.94
[Train] Epoch: 1 [515840/620022]    Loss: 0.008166   Batch Acc: 81.25
[Train] Epoch: 1 [515904/620022]    Loss: 0.011386   Batch Acc: 70.31
[Train] Epoch: 1 [515968/620022]    Loss: 0.007841   Batch Acc: 81.25
[Train] Epoch: 1 [516032/620022]    Loss: 0.008263   Batch Acc: 79.69
[Train] Epoch: 1 [516096/620022]    Loss: 0.010324   Batch Acc: 78.12
[Train] Epoch: 1 [516160/620022]    Loss: 0.009170   Batch Acc: 78.12
[Train] Epoch: 1 [516224/620022]    Loss: 0.009416   Batch Acc: 70.31
[Train] Epoch: 1 [516288/620022]    Loss: 0.007408   Batch Acc: 82.81
[Train] Epoch: 1 [516352/620022]    Loss: 0.009596   Batch Acc: 71.88
[Train] Epoch: 1 [516416/620022]    Loss: 0.010216   Batch Acc: 73.44
[Train] Epoch: 1 [516480/620022]    Loss: 0.008715   Batch Acc: 78.12
[Train] Epoch: 1 [516544/620022]    Loss: 0.008203   Batch Acc: 84.38
[Train] Epoch: 1 [516608/620022]    Loss: 0.008167   Batch Acc: 82.81
[Train] Epoch: 1 [516672/620022]    Loss: 0.010480   Batch Acc: 70.31
[Train] Epoch: 1 [516736/620022]    Loss: 0.008312   Batch Acc: 81.25
[Train] Epoch: 1 [516800/620022]    Loss: 0.007104   Batch Acc: 78.12
[Train] Epoch: 1 [516864/620022]    Loss: 0.009066   Batch Acc: 76.56
[Train] Epoch: 1 [516928/620022]    Loss: 0.010599   Batch Acc: 73.44
[Train] Epoch: 1 [516992/620022]    Loss: 0.010305   Batch Acc: 73.44
[Train] Epoch: 1 [517056/620022]    Loss: 0.009569   Batch Acc: 75.00
[Train] Epoch: 1 [517120/620022]    Loss: 0.008246   Batch Acc: 78.12
[Train] Epoch: 1 [517184/620022]    Loss: 0.011671   Batch Acc: 78.12
[Train] Epoch: 1 [517248/620022]    Loss: 0.006637   Batch Acc: 84.38
[Train] Epoch: 1 [517312/620022]    Loss: 0.011597   Batch Acc: 71.88
[Train] Epoch: 1 [517376/620022]    Loss: 0.009365   Batch Acc: 75.00
[Train] Epoch: 1 [517440/620022]    Loss: 0.011060   Batch Acc: 70.31
[Train] Epoch: 1 [517504/620022]    Loss: 0.009435   Batch Acc: 71.88
[Train] Epoch: 1 [517568/620022]    Loss: 0.008215   Batch Acc: 79.69
[Train] Epoch: 1 [517632/620022]    Loss: 0.007568   Batch Acc: 81.25
[Train] Epoch: 1 [517696/620022]    Loss: 0.008927   Batch Acc: 76.56
[Train] Epoch: 1 [517760/620022]    Loss: 0.008584   Batch Acc: 70.31
[Train] Epoch: 1 [517824/620022]    Loss: 0.006505   Batch Acc: 84.38
[Train] Epoch: 1 [517888/620022]    Loss: 0.008940   Batch Acc: 78.12
[Train] Epoch: 1 [517952/620022]    Loss: 0.010417   Batch Acc: 71.88
[Train] Epoch: 1 [518016/620022]    Loss: 0.008341   Batch Acc: 78.12
[Train] Epoch: 1 [518080/620022]    Loss: 0.006115   Batch Acc: 89.06
[Train] Epoch: 1 [518144/620022]    Loss: 0.010416   Batch Acc: 73.44
[Train] Epoch: 1 [518208/620022]    Loss: 0.008785   Batch Acc: 78.12
[Train] Epoch: 1 [518272/620022]    Loss: 0.009133   Batch Acc: 75.00
[Train] Epoch: 1 [518336/620022]    Loss: 0.008311   Batch Acc: 81.25
[Train] Epoch: 1 [518400/620022]    Loss: 0.009288   Batch Acc: 76.56
[Train] Epoch: 1 [518464/620022]    Loss: 0.008376   Batch Acc: 76.56
[Train] Epoch: 1 [518528/620022]    Loss: 0.007610   Batch Acc: 81.25
[Train] Epoch: 1 [518592/620022]    Loss: 0.010426   Batch Acc: 73.44
[Train] Epoch: 1 [518656/620022]    Loss: 0.008063   Batch Acc: 82.81
[Train] Epoch: 1 [518720/620022]    Loss: 0.008865   Batch Acc: 71.88
[Train] Epoch: 1 [518784/620022]    Loss: 0.007744   Batch Acc: 81.25
[Train] Epoch: 1 [518848/620022]    Loss: 0.009138   Batch Acc: 73.44
[Train] Epoch: 1 [518912/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 1 [518976/620022]    Loss: 0.007107   Batch Acc: 85.94
[Train] Epoch: 1 [519040/620022]    Loss: 0.007479   Batch Acc: 79.69
[Train] Epoch: 1 [519104/620022]    Loss: 0.009961   Batch Acc: 73.44
[Train] Epoch: 1 [519168/620022]    Loss: 0.009424   Batch Acc: 68.75
[Train] Epoch: 1 [519232/620022]    Loss: 0.008131   Batch Acc: 75.00
[Train] Epoch: 1 [519296/620022]    Loss: 0.008072   Batch Acc: 81.25
[Train] Epoch: 1 [519360/620022]    Loss: 0.011036   Batch Acc: 70.31
[Train] Epoch: 1 [519424/620022]    Loss: 0.010817   Batch Acc: 68.75
[Train] Epoch: 1 [519488/620022]    Loss: 0.007864   Batch Acc: 82.81
[Train] Epoch: 1 [519552/620022]    Loss: 0.009614   Batch Acc: 76.56
[Train] Epoch: 1 [519616/620022]    Loss: 0.009278   Batch Acc: 76.56
[Train] Epoch: 1 [519680/620022]    Loss: 0.008689   Batch Acc: 73.44
[Train] Epoch: 1 [519744/620022]    Loss: 0.007976   Batch Acc: 82.81
[Train] Epoch: 1 [519808/620022]    Loss: 0.007136   Batch Acc: 87.50
[Train] Epoch: 1 [519872/620022]    Loss: 0.008400   Batch Acc: 79.69
[Train] Epoch: 1 [519936/620022]    Loss: 0.007659   Batch Acc: 84.38
[Train] Epoch: 1 [520000/620022]    Loss: 0.006644   Batch Acc: 82.81
[Train] Epoch: 1 [520064/620022]    Loss: 0.007686   Batch Acc: 79.69
[Train] Epoch: 1 [520128/620022]    Loss: 0.009472   Batch Acc: 76.56
[Train] Epoch: 1 [520192/620022]    Loss: 0.009050   Batch Acc: 78.12
[Train] Epoch: 1 [520256/620022]    Loss: 0.011294   Batch Acc: 71.88
[Train] Epoch: 1 [520320/620022]    Loss: 0.008742   Batch Acc: 79.69
[Train] Epoch: 1 [520384/620022]    Loss: 0.006430   Batch Acc: 87.50
[Train] Epoch: 1 [520448/620022]    Loss: 0.008385   Batch Acc: 78.12
[Train] Epoch: 1 [520512/620022]    Loss: 0.009375   Batch Acc: 78.12
[Train] Epoch: 1 [520576/620022]    Loss: 0.010645   Batch Acc: 73.44
[Train] Epoch: 1 [520640/620022]    Loss: 0.007787   Batch Acc: 81.25
[Train] Epoch: 1 [520704/620022]    Loss: 0.008667   Batch Acc: 76.56
[Train] Epoch: 1 [520768/620022]    Loss: 0.008675   Batch Acc: 78.12
[Train] Epoch: 1 [520832/620022]    Loss: 0.008478   Batch Acc: 79.69
[Train] Epoch: 1 [520896/620022]    Loss: 0.008492   Batch Acc: 79.69
[Train] Epoch: 1 [520960/620022]    Loss: 0.007406   Batch Acc: 81.25
[Train] Epoch: 1 [521024/620022]    Loss: 0.010470   Batch Acc: 75.00
[Train] Epoch: 1 [521088/620022]    Loss: 0.009665   Batch Acc: 76.56
[Train] Epoch: 1 [521152/620022]    Loss: 0.010056   Batch Acc: 71.88
[Train] Epoch: 1 [521216/620022]    Loss: 0.010592   Batch Acc: 75.00
[Train] Epoch: 1 [521280/620022]    Loss: 0.009109   Batch Acc: 76.56
[Train] Epoch: 1 [521344/620022]    Loss: 0.011297   Batch Acc: 67.19
[Train] Epoch: 1 [521408/620022]    Loss: 0.008449   Batch Acc: 71.88
[Train] Epoch: 1 [521472/620022]    Loss: 0.010495   Batch Acc: 73.44
[Train] Epoch: 1 [521536/620022]    Loss: 0.006687   Batch Acc: 85.94
[Train] Epoch: 1 [521600/620022]    Loss: 0.010507   Batch Acc: 78.12
[Train] Epoch: 1 [521664/620022]    Loss: 0.008643   Batch Acc: 79.69
[Train] Epoch: 1 [521728/620022]    Loss: 0.010728   Batch Acc: 67.19
[Train] Epoch: 1 [521792/620022]    Loss: 0.006253   Batch Acc: 85.94
[Train] Epoch: 1 [521856/620022]    Loss: 0.009875   Batch Acc: 73.44
[Train] Epoch: 1 [521920/620022]    Loss: 0.009009   Batch Acc: 73.44
[Train] Epoch: 1 [521984/620022]    Loss: 0.008360   Batch Acc: 82.81
[Train] Epoch: 1 [522048/620022]    Loss: 0.008641   Batch Acc: 71.88
[Train] Epoch: 1 [522112/620022]    Loss: 0.006904   Batch Acc: 85.94
[Train] Epoch: 1 [522176/620022]    Loss: 0.007594   Batch Acc: 81.25
[Train] Epoch: 1 [522240/620022]    Loss: 0.009475   Batch Acc: 79.69
[Train] Epoch: 1 [522304/620022]    Loss: 0.006731   Batch Acc: 85.94
[Train] Epoch: 1 [522368/620022]    Loss: 0.010357   Batch Acc: 70.31
[Train] Epoch: 1 [522432/620022]    Loss: 0.006988   Batch Acc: 82.81
[Train] Epoch: 1 [522496/620022]    Loss: 0.008620   Batch Acc: 75.00
[Train] Epoch: 1 [522560/620022]    Loss: 0.007076   Batch Acc: 85.94
[Train] Epoch: 1 [522624/620022]    Loss: 0.008005   Batch Acc: 82.81
[Train] Epoch: 1 [522688/620022]    Loss: 0.008399   Batch Acc: 76.56
[Train] Epoch: 1 [522752/620022]    Loss: 0.008384   Batch Acc: 78.12
[Train] Epoch: 1 [522816/620022]    Loss: 0.007351   Batch Acc: 84.38
[Train] Epoch: 1 [522880/620022]    Loss: 0.009528   Batch Acc: 73.44
[Train] Epoch: 1 [522944/620022]    Loss: 0.007309   Batch Acc: 84.38
[Train] Epoch: 1 [523008/620022]    Loss: 0.008629   Batch Acc: 81.25
[Train] Epoch: 1 [523072/620022]    Loss: 0.007633   Batch Acc: 81.25
[Train] Epoch: 1 [523136/620022]    Loss: 0.009075   Batch Acc: 73.44
[Train] Epoch: 1 [523200/620022]    Loss: 0.007630   Batch Acc: 84.38
[Train] Epoch: 1 [523264/620022]    Loss: 0.009129   Batch Acc: 78.12
[Train] Epoch: 1 [523328/620022]    Loss: 0.006583   Batch Acc: 84.38
[Train] Epoch: 1 [523392/620022]    Loss: 0.009930   Batch Acc: 75.00
[Train] Epoch: 1 [523456/620022]    Loss: 0.008098   Batch Acc: 84.38
[Train] Epoch: 1 [523520/620022]    Loss: 0.009329   Batch Acc: 73.44
[Train] Epoch: 1 [523584/620022]    Loss: 0.006860   Batch Acc: 82.81
[Train] Epoch: 1 [523648/620022]    Loss: 0.011263   Batch Acc: 70.31
[Train] Epoch: 1 [523712/620022]    Loss: 0.007709   Batch Acc: 78.12
[Train] Epoch: 1 [523776/620022]    Loss: 0.009361   Batch Acc: 76.56
[Train] Epoch: 1 [523840/620022]    Loss: 0.008407   Batch Acc: 84.38
[Train] Epoch: 1 [523904/620022]    Loss: 0.010102   Batch Acc: 70.31
[Train] Epoch: 1 [523968/620022]    Loss: 0.009330   Batch Acc: 75.00
[Train] Epoch: 1 [524032/620022]    Loss: 0.008185   Batch Acc: 81.25
[Train] Epoch: 1 [524096/620022]    Loss: 0.012582   Batch Acc: 67.19
[Train] Epoch: 1 [524160/620022]    Loss: 0.009031   Batch Acc: 82.81
[Train] Epoch: 1 [524224/620022]    Loss: 0.009258   Batch Acc: 82.81
[Train] Epoch: 1 [524288/620022]    Loss: 0.008472   Batch Acc: 75.00
[Train] Epoch: 1 [524352/620022]    Loss: 0.007776   Batch Acc: 76.56
[Train] Epoch: 1 [524416/620022]    Loss: 0.008118   Batch Acc: 79.69
[Train] Epoch: 1 [524480/620022]    Loss: 0.009896   Batch Acc: 75.00
[Train] Epoch: 1 [524544/620022]    Loss: 0.006934   Batch Acc: 78.12
[Train] Epoch: 1 [524608/620022]    Loss: 0.007417   Batch Acc: 84.38
[Train] Epoch: 1 [524672/620022]    Loss: 0.007508   Batch Acc: 79.69
[Train] Epoch: 1 [524736/620022]    Loss: 0.007600   Batch Acc: 85.94
[Train] Epoch: 1 [524800/620022]    Loss: 0.007007   Batch Acc: 90.62
[Train] Epoch: 1 [524864/620022]    Loss: 0.008453   Batch Acc: 78.12
[Train] Epoch: 1 [524928/620022]    Loss: 0.007943   Batch Acc: 79.69
[Train] Epoch: 1 [524992/620022]    Loss: 0.009244   Batch Acc: 71.88
[Train] Epoch: 1 [525056/620022]    Loss: 0.009188   Batch Acc: 79.69
[Train] Epoch: 1 [525120/620022]    Loss: 0.009225   Batch Acc: 76.56
[Train] Epoch: 1 [525184/620022]    Loss: 0.008946   Batch Acc: 75.00
[Train] Epoch: 1 [525248/620022]    Loss: 0.010657   Batch Acc: 73.44
[Train] Epoch: 1 [525312/620022]    Loss: 0.010020   Batch Acc: 76.56
[Train] Epoch: 1 [525376/620022]    Loss: 0.009845   Batch Acc: 75.00
[Train] Epoch: 1 [525440/620022]    Loss: 0.009968   Batch Acc: 73.44
[Train] Epoch: 1 [525504/620022]    Loss: 0.008192   Batch Acc: 81.25
[Train] Epoch: 1 [525568/620022]    Loss: 0.010637   Batch Acc: 73.44
[Train] Epoch: 1 [525632/620022]    Loss: 0.008830   Batch Acc: 79.69
[Train] Epoch: 1 [525696/620022]    Loss: 0.009292   Batch Acc: 75.00
[Train] Epoch: 1 [525760/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 1 [525824/620022]    Loss: 0.006855   Batch Acc: 85.94
[Train] Epoch: 1 [525888/620022]    Loss: 0.008580   Batch Acc: 78.12
[Train] Epoch: 1 [525952/620022]    Loss: 0.009779   Batch Acc: 68.75
[Train] Epoch: 1 [526016/620022]    Loss: 0.010188   Batch Acc: 70.31
[Train] Epoch: 1 [526080/620022]    Loss: 0.007905   Batch Acc: 81.25
[Train] Epoch: 1 [526144/620022]    Loss: 0.008342   Batch Acc: 79.69
[Train] Epoch: 1 [526208/620022]    Loss: 0.008246   Batch Acc: 79.69
[Train] Epoch: 1 [526272/620022]    Loss: 0.008459   Batch Acc: 84.38
[Train] Epoch: 1 [526336/620022]    Loss: 0.009303   Batch Acc: 78.12
[Train] Epoch: 1 [526400/620022]    Loss: 0.007999   Batch Acc: 78.12
[Train] Epoch: 1 [526464/620022]    Loss: 0.009663   Batch Acc: 73.44
[Train] Epoch: 1 [526528/620022]    Loss: 0.007801   Batch Acc: 76.56
[Train] Epoch: 1 [526592/620022]    Loss: 0.007932   Batch Acc: 84.38
[Train] Epoch: 1 [526656/620022]    Loss: 0.008048   Batch Acc: 75.00
[Train] Epoch: 1 [526720/620022]    Loss: 0.007347   Batch Acc: 75.00
[Train] Epoch: 1 [526784/620022]    Loss: 0.012053   Batch Acc: 64.06
[Train] Epoch: 1 [526848/620022]    Loss: 0.007939   Batch Acc: 84.38
[Train] Epoch: 1 [526912/620022]    Loss: 0.010262   Batch Acc: 75.00
[Train] Epoch: 1 [526976/620022]    Loss: 0.008619   Batch Acc: 79.69
[Train] Epoch: 1 [527040/620022]    Loss: 0.007961   Batch Acc: 76.56
[Train] Epoch: 1 [527104/620022]    Loss: 0.007217   Batch Acc: 89.06
[Train] Epoch: 1 [527168/620022]    Loss: 0.009325   Batch Acc: 73.44
[Train] Epoch: 1 [527232/620022]    Loss: 0.009133   Batch Acc: 73.44
[Train] Epoch: 1 [527296/620022]    Loss: 0.005548   Batch Acc: 92.19
[Train] Epoch: 1 [527360/620022]    Loss: 0.008085   Batch Acc: 75.00
[Train] Epoch: 1 [527424/620022]    Loss: 0.007864   Batch Acc: 81.25
[Train] Epoch: 1 [527488/620022]    Loss: 0.007643   Batch Acc: 81.25
[Train] Epoch: 1 [527552/620022]    Loss: 0.005385   Batch Acc: 92.19
[Train] Epoch: 1 [527616/620022]    Loss: 0.008199   Batch Acc: 81.25
[Train] Epoch: 1 [527680/620022]    Loss: 0.007539   Batch Acc: 82.81
[Train] Epoch: 1 [527744/620022]    Loss: 0.008942   Batch Acc: 73.44
[Train] Epoch: 1 [527808/620022]    Loss: 0.008224   Batch Acc: 82.81
[Train] Epoch: 1 [527872/620022]    Loss: 0.010971   Batch Acc: 71.88
[Train] Epoch: 1 [527936/620022]    Loss: 0.008954   Batch Acc: 76.56
[Train] Epoch: 1 [528000/620022]    Loss: 0.008289   Batch Acc: 81.25
[Train] Epoch: 1 [528064/620022]    Loss: 0.007177   Batch Acc: 82.81
[Train] Epoch: 1 [528128/620022]    Loss: 0.008428   Batch Acc: 78.12
[Train] Epoch: 1 [528192/620022]    Loss: 0.009611   Batch Acc: 71.88
[Train] Epoch: 1 [528256/620022]    Loss: 0.009387   Batch Acc: 73.44
[Train] Epoch: 1 [528320/620022]    Loss: 0.008222   Batch Acc: 75.00
[Train] Epoch: 1 [528384/620022]    Loss: 0.009634   Batch Acc: 73.44
[Train] Epoch: 1 [528448/620022]    Loss: 0.006922   Batch Acc: 89.06
[Train] Epoch: 1 [528512/620022]    Loss: 0.009121   Batch Acc: 78.12
[Train] Epoch: 1 [528576/620022]    Loss: 0.008837   Batch Acc: 73.44
[Train] Epoch: 1 [528640/620022]    Loss: 0.007888   Batch Acc: 84.38
[Train] Epoch: 1 [528704/620022]    Loss: 0.009058   Batch Acc: 73.44
[Train] Epoch: 1 [528768/620022]    Loss: 0.006834   Batch Acc: 87.50
[Train] Epoch: 1 [528832/620022]    Loss: 0.009610   Batch Acc: 73.44
[Train] Epoch: 1 [528896/620022]    Loss: 0.008814   Batch Acc: 78.12
[Train] Epoch: 1 [528960/620022]    Loss: 0.007941   Batch Acc: 76.56
[Train] Epoch: 1 [529024/620022]    Loss: 0.008821   Batch Acc: 81.25
[Train] Epoch: 1 [529088/620022]    Loss: 0.009311   Batch Acc: 75.00
[Train] Epoch: 1 [529152/620022]    Loss: 0.007234   Batch Acc: 82.81
[Train] Epoch: 1 [529216/620022]    Loss: 0.008556   Batch Acc: 73.44
[Train] Epoch: 1 [529280/620022]    Loss: 0.007477   Batch Acc: 79.69
[Train] Epoch: 1 [529344/620022]    Loss: 0.006335   Batch Acc: 89.06
[Train] Epoch: 1 [529408/620022]    Loss: 0.009219   Batch Acc: 73.44
[Train] Epoch: 1 [529472/620022]    Loss: 0.011018   Batch Acc: 67.19
[Train] Epoch: 1 [529536/620022]    Loss: 0.008018   Batch Acc: 84.38
[Train] Epoch: 1 [529600/620022]    Loss: 0.006481   Batch Acc: 84.38
[Train] Epoch: 1 [529664/620022]    Loss: 0.009747   Batch Acc: 78.12
[Train] Epoch: 1 [529728/620022]    Loss: 0.008237   Batch Acc: 79.69
[Train] Epoch: 1 [529792/620022]    Loss: 0.005549   Batch Acc: 90.62
[Train] Epoch: 1 [529856/620022]    Loss: 0.009371   Batch Acc: 73.44
[Train] Epoch: 1 [529920/620022]    Loss: 0.007718   Batch Acc: 78.12
[Train] Epoch: 1 [529984/620022]    Loss: 0.008403   Batch Acc: 79.69
[Train] Epoch: 1 [530048/620022]    Loss: 0.010212   Batch Acc: 75.00
[Train] Epoch: 1 [530112/620022]    Loss: 0.008056   Batch Acc: 84.38
[Train] Epoch: 1 [530176/620022]    Loss: 0.007239   Batch Acc: 84.38
[Train] Epoch: 1 [530240/620022]    Loss: 0.006956   Batch Acc: 82.81
[Train] Epoch: 1 [530304/620022]    Loss: 0.007143   Batch Acc: 78.12
[Train] Epoch: 1 [530368/620022]    Loss: 0.007352   Batch Acc: 78.12
[Train] Epoch: 1 [530432/620022]    Loss: 0.007695   Batch Acc: 81.25
[Train] Epoch: 1 [530496/620022]    Loss: 0.008636   Batch Acc: 79.69
[Train] Epoch: 1 [530560/620022]    Loss: 0.007525   Batch Acc: 78.12
[Train] Epoch: 1 [530624/620022]    Loss: 0.011242   Batch Acc: 76.56
[Train] Epoch: 1 [530688/620022]    Loss: 0.010684   Batch Acc: 75.00
[Train] Epoch: 1 [530752/620022]    Loss: 0.010446   Batch Acc: 71.88
[Train] Epoch: 1 [530816/620022]    Loss: 0.007841   Batch Acc: 78.12
[Train] Epoch: 1 [530880/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 1 [530944/620022]    Loss: 0.008529   Batch Acc: 78.12
[Train] Epoch: 1 [531008/620022]    Loss: 0.009386   Batch Acc: 68.75
[Train] Epoch: 1 [531072/620022]    Loss: 0.008216   Batch Acc: 76.56
[Train] Epoch: 1 [531136/620022]    Loss: 0.008596   Batch Acc: 78.12
[Train] Epoch: 1 [531200/620022]    Loss: 0.008092   Batch Acc: 81.25
[Train] Epoch: 1 [531264/620022]    Loss: 0.009218   Batch Acc: 76.56
[Train] Epoch: 1 [531328/620022]    Loss: 0.010335   Batch Acc: 71.88
[Train] Epoch: 1 [531392/620022]    Loss: 0.010567   Batch Acc: 76.56
[Train] Epoch: 1 [531456/620022]    Loss: 0.009894   Batch Acc: 70.31
[Train] Epoch: 1 [531520/620022]    Loss: 0.010596   Batch Acc: 67.19
[Train] Epoch: 1 [531584/620022]    Loss: 0.010646   Batch Acc: 75.00
[Train] Epoch: 1 [531648/620022]    Loss: 0.010183   Batch Acc: 75.00
[Train] Epoch: 1 [531712/620022]    Loss: 0.009491   Batch Acc: 68.75
[Train] Epoch: 1 [531776/620022]    Loss: 0.009266   Batch Acc: 68.75
[Train] Epoch: 1 [531840/620022]    Loss: 0.010173   Batch Acc: 71.88
[Train] Epoch: 1 [531904/620022]    Loss: 0.010388   Batch Acc: 73.44
[Train] Epoch: 1 [531968/620022]    Loss: 0.008044   Batch Acc: 73.44
[Train] Epoch: 1 [532032/620022]    Loss: 0.006916   Batch Acc: 82.81
[Train] Epoch: 1 [532096/620022]    Loss: 0.009088   Batch Acc: 75.00
[Train] Epoch: 1 [532160/620022]    Loss: 0.007288   Batch Acc: 78.12
[Train] Epoch: 1 [532224/620022]    Loss: 0.006550   Batch Acc: 78.12
[Train] Epoch: 1 [532288/620022]    Loss: 0.007790   Batch Acc: 81.25
[Train] Epoch: 1 [532352/620022]    Loss: 0.009998   Batch Acc: 71.88
[Train] Epoch: 1 [532416/620022]    Loss: 0.007932   Batch Acc: 84.38
[Train] Epoch: 1 [532480/620022]    Loss: 0.010256   Batch Acc: 70.31
[Train] Epoch: 1 [532544/620022]    Loss: 0.007879   Batch Acc: 78.12
[Train] Epoch: 1 [532608/620022]    Loss: 0.007676   Batch Acc: 76.56
[Train] Epoch: 1 [532672/620022]    Loss: 0.008882   Batch Acc: 81.25
[Train] Epoch: 1 [532736/620022]    Loss: 0.008578   Batch Acc: 75.00
[Train] Epoch: 1 [532800/620022]    Loss: 0.011515   Batch Acc: 65.62
[Train] Epoch: 1 [532864/620022]    Loss: 0.006033   Batch Acc: 85.94
[Train] Epoch: 1 [532928/620022]    Loss: 0.009702   Batch Acc: 73.44
[Train] Epoch: 1 [532992/620022]    Loss: 0.010670   Batch Acc: 71.88
[Train] Epoch: 1 [533056/620022]    Loss: 0.008675   Batch Acc: 75.00
[Train] Epoch: 1 [533120/620022]    Loss: 0.007805   Batch Acc: 81.25
[Train] Epoch: 1 [533184/620022]    Loss: 0.009551   Batch Acc: 71.88
[Train] Epoch: 1 [533248/620022]    Loss: 0.008685   Batch Acc: 76.56
[Train] Epoch: 1 [533312/620022]    Loss: 0.007308   Batch Acc: 81.25
[Train] Epoch: 1 [533376/620022]    Loss: 0.008519   Batch Acc: 75.00
[Train] Epoch: 1 [533440/620022]    Loss: 0.008452   Batch Acc: 75.00
[Train] Epoch: 1 [533504/620022]    Loss: 0.007043   Batch Acc: 85.94
[Train] Epoch: 1 [533568/620022]    Loss: 0.008145   Batch Acc: 76.56
[Train] Epoch: 1 [533632/620022]    Loss: 0.008563   Batch Acc: 79.69
[Train] Epoch: 1 [533696/620022]    Loss: 0.010352   Batch Acc: 78.12
[Train] Epoch: 1 [533760/620022]    Loss: 0.009225   Batch Acc: 79.69
[Train] Epoch: 1 [533824/620022]    Loss: 0.009951   Batch Acc: 75.00
[Train] Epoch: 1 [533888/620022]    Loss: 0.009907   Batch Acc: 71.88
[Train] Epoch: 1 [533952/620022]    Loss: 0.007656   Batch Acc: 82.81
[Train] Epoch: 1 [534016/620022]    Loss: 0.008654   Batch Acc: 76.56
[Train] Epoch: 1 [534080/620022]    Loss: 0.010019   Batch Acc: 71.88
[Train] Epoch: 1 [534144/620022]    Loss: 0.009717   Batch Acc: 71.88
[Train] Epoch: 1 [534208/620022]    Loss: 0.009968   Batch Acc: 79.69
[Train] Epoch: 1 [534272/620022]    Loss: 0.007986   Batch Acc: 81.25
[Train] Epoch: 1 [534336/620022]    Loss: 0.005780   Batch Acc: 92.19
[Train] Epoch: 1 [534400/620022]    Loss: 0.008503   Batch Acc: 79.69
[Train] Epoch: 1 [534464/620022]    Loss: 0.007457   Batch Acc: 79.69
[Train] Epoch: 1 [534528/620022]    Loss: 0.009207   Batch Acc: 81.25
[Train] Epoch: 1 [534592/620022]    Loss: 0.006349   Batch Acc: 87.50
[Train] Epoch: 1 [534656/620022]    Loss: 0.009426   Batch Acc: 75.00
[Train] Epoch: 1 [534720/620022]    Loss: 0.008689   Batch Acc: 79.69
[Train] Epoch: 1 [534784/620022]    Loss: 0.009230   Batch Acc: 75.00
[Train] Epoch: 1 [534848/620022]    Loss: 0.008307   Batch Acc: 76.56
[Train] Epoch: 1 [534912/620022]    Loss: 0.010729   Batch Acc: 68.75
[Train] Epoch: 1 [534976/620022]    Loss: 0.009564   Batch Acc: 82.81
[Train] Epoch: 1 [535040/620022]    Loss: 0.010503   Batch Acc: 73.44
[Train] Epoch: 1 [535104/620022]    Loss: 0.007304   Batch Acc: 78.12
[Train] Epoch: 1 [535168/620022]    Loss: 0.009521   Batch Acc: 76.56
[Train] Epoch: 1 [535232/620022]    Loss: 0.008597   Batch Acc: 78.12
[Train] Epoch: 1 [535296/620022]    Loss: 0.010226   Batch Acc: 71.88
[Train] Epoch: 1 [535360/620022]    Loss: 0.006062   Batch Acc: 90.62
[Train] Epoch: 1 [535424/620022]    Loss: 0.008247   Batch Acc: 79.69
[Train] Epoch: 1 [535488/620022]    Loss: 0.008084   Batch Acc: 81.25
[Train] Epoch: 1 [535552/620022]    Loss: 0.007521   Batch Acc: 81.25
[Train] Epoch: 1 [535616/620022]    Loss: 0.007314   Batch Acc: 84.38
[Train] Epoch: 1 [535680/620022]    Loss: 0.008883   Batch Acc: 73.44
[Train] Epoch: 1 [535744/620022]    Loss: 0.005851   Batch Acc: 87.50
[Train] Epoch: 1 [535808/620022]    Loss: 0.006440   Batch Acc: 89.06
[Train] Epoch: 1 [535872/620022]    Loss: 0.010116   Batch Acc: 71.88
[Train] Epoch: 1 [535936/620022]    Loss: 0.007060   Batch Acc: 84.38
[Train] Epoch: 1 [536000/620022]    Loss: 0.009535   Batch Acc: 76.56
[Train] Epoch: 1 [536064/620022]    Loss: 0.008930   Batch Acc: 75.00
[Train] Epoch: 1 [536128/620022]    Loss: 0.010206   Batch Acc: 75.00
[Train] Epoch: 1 [536192/620022]    Loss: 0.007973   Batch Acc: 84.38
[Train] Epoch: 1 [536256/620022]    Loss: 0.008313   Batch Acc: 76.56
[Train] Epoch: 1 [536320/620022]    Loss: 0.006198   Batch Acc: 85.94
[Train] Epoch: 1 [536384/620022]    Loss: 0.008223   Batch Acc: 78.12
[Train] Epoch: 1 [536448/620022]    Loss: 0.011592   Batch Acc: 73.44
[Train] Epoch: 1 [536512/620022]    Loss: 0.009462   Batch Acc: 71.88
[Train] Epoch: 1 [536576/620022]    Loss: 0.009540   Batch Acc: 71.88
[Train] Epoch: 1 [536640/620022]    Loss: 0.008204   Batch Acc: 78.12
[Train] Epoch: 1 [536704/620022]    Loss: 0.008175   Batch Acc: 81.25
[Train] Epoch: 1 [536768/620022]    Loss: 0.010025   Batch Acc: 73.44
[Train] Epoch: 1 [536832/620022]    Loss: 0.008487   Batch Acc: 81.25
[Train] Epoch: 1 [536896/620022]    Loss: 0.008195   Batch Acc: 75.00
[Train] Epoch: 1 [536960/620022]    Loss: 0.008875   Batch Acc: 76.56
[Train] Epoch: 1 [537024/620022]    Loss: 0.008453   Batch Acc: 81.25
[Train] Epoch: 1 [537088/620022]    Loss: 0.007549   Batch Acc: 84.38
[Train] Epoch: 1 [537152/620022]    Loss: 0.010165   Batch Acc: 70.31
[Train] Epoch: 1 [537216/620022]    Loss: 0.008452   Batch Acc: 79.69
[Train] Epoch: 1 [537280/620022]    Loss: 0.009012   Batch Acc: 75.00
[Train] Epoch: 1 [537344/620022]    Loss: 0.007455   Batch Acc: 81.25
[Train] Epoch: 1 [537408/620022]    Loss: 0.010096   Batch Acc: 70.31
[Train] Epoch: 1 [537472/620022]    Loss: 0.008653   Batch Acc: 79.69
[Train] Epoch: 1 [537536/620022]    Loss: 0.008894   Batch Acc: 76.56
[Train] Epoch: 1 [537600/620022]    Loss: 0.009267   Batch Acc: 75.00
[Train] Epoch: 1 [537664/620022]    Loss: 0.006150   Batch Acc: 87.50
[Train] Epoch: 1 [537728/620022]    Loss: 0.008245   Batch Acc: 85.94
[Train] Epoch: 1 [537792/620022]    Loss: 0.006497   Batch Acc: 89.06
[Train] Epoch: 1 [537856/620022]    Loss: 0.010564   Batch Acc: 70.31
[Train] Epoch: 1 [537920/620022]    Loss: 0.008458   Batch Acc: 76.56
[Train] Epoch: 1 [537984/620022]    Loss: 0.009175   Batch Acc: 75.00
[Train] Epoch: 1 [538048/620022]    Loss: 0.009043   Batch Acc: 79.69
[Train] Epoch: 1 [538112/620022]    Loss: 0.010165   Batch Acc: 71.88
[Train] Epoch: 1 [538176/620022]    Loss: 0.010040   Batch Acc: 73.44
[Train] Epoch: 1 [538240/620022]    Loss: 0.008989   Batch Acc: 78.12
[Train] Epoch: 1 [538304/620022]    Loss: 0.009069   Batch Acc: 75.00
[Train] Epoch: 1 [538368/620022]    Loss: 0.009077   Batch Acc: 73.44
[Train] Epoch: 1 [538432/620022]    Loss: 0.012173   Batch Acc: 70.31
[Train] Epoch: 1 [538496/620022]    Loss: 0.010290   Batch Acc: 71.88
[Train] Epoch: 1 [538560/620022]    Loss: 0.008359   Batch Acc: 78.12
[Train] Epoch: 1 [538624/620022]    Loss: 0.010740   Batch Acc: 75.00
[Train] Epoch: 1 [538688/620022]    Loss: 0.010618   Batch Acc: 71.88
[Train] Epoch: 1 [538752/620022]    Loss: 0.010580   Batch Acc: 70.31
[Train] Epoch: 1 [538816/620022]    Loss: 0.007945   Batch Acc: 76.56
[Train] Epoch: 1 [538880/620022]    Loss: 0.007520   Batch Acc: 81.25
[Train] Epoch: 1 [538944/620022]    Loss: 0.008318   Batch Acc: 82.81
[Train] Epoch: 1 [539008/620022]    Loss: 0.007258   Batch Acc: 87.50
[Train] Epoch: 1 [539072/620022]    Loss: 0.009716   Batch Acc: 73.44
[Train] Epoch: 1 [539136/620022]    Loss: 0.008465   Batch Acc: 81.25
[Train] Epoch: 1 [539200/620022]    Loss: 0.007297   Batch Acc: 79.69
[Train] Epoch: 1 [539264/620022]    Loss: 0.010174   Batch Acc: 73.44
[Train] Epoch: 1 [539328/620022]    Loss: 0.008311   Batch Acc: 78.12
[Train] Epoch: 1 [539392/620022]    Loss: 0.010307   Batch Acc: 68.75
[Train] Epoch: 1 [539456/620022]    Loss: 0.007837   Batch Acc: 81.25
[Train] Epoch: 1 [539520/620022]    Loss: 0.008200   Batch Acc: 78.12
[Train] Epoch: 1 [539584/620022]    Loss: 0.008375   Batch Acc: 78.12
[Train] Epoch: 1 [539648/620022]    Loss: 0.010086   Batch Acc: 73.44
[Train] Epoch: 1 [539712/620022]    Loss: 0.006831   Batch Acc: 87.50
[Train] Epoch: 1 [539776/620022]    Loss: 0.006938   Batch Acc: 78.12
[Train] Epoch: 1 [539840/620022]    Loss: 0.010054   Batch Acc: 75.00
[Train] Epoch: 1 [539904/620022]    Loss: 0.009129   Batch Acc: 76.56
[Train] Epoch: 1 [539968/620022]    Loss: 0.009569   Batch Acc: 71.88
[Train] Epoch: 1 [540032/620022]    Loss: 0.008312   Batch Acc: 81.25
[Train] Epoch: 1 [540096/620022]    Loss: 0.006664   Batch Acc: 89.06
[Train] Epoch: 1 [540160/620022]    Loss: 0.008736   Batch Acc: 73.44
[Train] Epoch: 1 [540224/620022]    Loss: 0.009280   Batch Acc: 78.12
[Train] Epoch: 1 [540288/620022]    Loss: 0.009421   Batch Acc: 71.88
[Train] Epoch: 1 [540352/620022]    Loss: 0.010000   Batch Acc: 75.00
[Train] Epoch: 1 [540416/620022]    Loss: 0.009418   Batch Acc: 76.56
[Train] Epoch: 1 [540480/620022]    Loss: 0.006014   Batch Acc: 85.94
[Train] Epoch: 1 [540544/620022]    Loss: 0.007756   Batch Acc: 81.25
[Train] Epoch: 1 [540608/620022]    Loss: 0.010909   Batch Acc: 73.44
[Train] Epoch: 1 [540672/620022]    Loss: 0.007762   Batch Acc: 82.81
[Train] Epoch: 1 [540736/620022]    Loss: 0.009027   Batch Acc: 75.00
[Train] Epoch: 1 [540800/620022]    Loss: 0.009021   Batch Acc: 73.44
[Train] Epoch: 1 [540864/620022]    Loss: 0.009174   Batch Acc: 75.00
[Train] Epoch: 1 [540928/620022]    Loss: 0.009560   Batch Acc: 75.00
[Train] Epoch: 1 [540992/620022]    Loss: 0.007234   Batch Acc: 82.81
[Train] Epoch: 1 [541056/620022]    Loss: 0.009116   Batch Acc: 82.81
[Train] Epoch: 1 [541120/620022]    Loss: 0.009560   Batch Acc: 73.44
[Train] Epoch: 1 [541184/620022]    Loss: 0.011598   Batch Acc: 64.06
[Train] Epoch: 1 [541248/620022]    Loss: 0.009505   Batch Acc: 73.44
[Train] Epoch: 1 [541312/620022]    Loss: 0.007344   Batch Acc: 81.25
[Train] Epoch: 1 [541376/620022]    Loss: 0.008480   Batch Acc: 76.56
[Train] Epoch: 1 [541440/620022]    Loss: 0.010025   Batch Acc: 75.00
[Train] Epoch: 1 [541504/620022]    Loss: 0.010365   Batch Acc: 75.00
[Train] Epoch: 1 [541568/620022]    Loss: 0.008422   Batch Acc: 73.44
[Train] Epoch: 1 [541632/620022]    Loss: 0.008799   Batch Acc: 73.44
[Train] Epoch: 1 [541696/620022]    Loss: 0.007720   Batch Acc: 81.25
[Train] Epoch: 1 [541760/620022]    Loss: 0.009544   Batch Acc: 82.81
[Train] Epoch: 1 [541824/620022]    Loss: 0.009137   Batch Acc: 76.56
[Train] Epoch: 1 [541888/620022]    Loss: 0.006506   Batch Acc: 85.94
[Train] Epoch: 1 [541952/620022]    Loss: 0.007583   Batch Acc: 82.81
[Train] Epoch: 1 [542016/620022]    Loss: 0.009254   Batch Acc: 67.19
[Train] Epoch: 1 [542080/620022]    Loss: 0.009735   Batch Acc: 71.88
[Train] Epoch: 1 [542144/620022]    Loss: 0.010227   Batch Acc: 68.75
[Train] Epoch: 1 [542208/620022]    Loss: 0.009265   Batch Acc: 76.56
[Train] Epoch: 1 [542272/620022]    Loss: 0.007987   Batch Acc: 85.94
[Train] Epoch: 1 [542336/620022]    Loss: 0.010006   Batch Acc: 70.31
[Train] Epoch: 1 [542400/620022]    Loss: 0.008183   Batch Acc: 81.25
[Train] Epoch: 1 [542464/620022]    Loss: 0.006799   Batch Acc: 84.38
[Train] Epoch: 1 [542528/620022]    Loss: 0.009794   Batch Acc: 70.31
[Train] Epoch: 1 [542592/620022]    Loss: 0.008662   Batch Acc: 75.00
[Train] Epoch: 1 [542656/620022]    Loss: 0.008849   Batch Acc: 73.44
[Train] Epoch: 1 [542720/620022]    Loss: 0.006481   Batch Acc: 87.50
[Train] Epoch: 1 [542784/620022]    Loss: 0.007935   Batch Acc: 85.94
[Train] Epoch: 1 [542848/620022]    Loss: 0.010577   Batch Acc: 65.62
[Train] Epoch: 1 [542912/620022]    Loss: 0.009085   Batch Acc: 71.88
[Train] Epoch: 1 [542976/620022]    Loss: 0.009169   Batch Acc: 76.56
[Train] Epoch: 1 [543040/620022]    Loss: 0.008170   Batch Acc: 82.81
[Train] Epoch: 1 [543104/620022]    Loss: 0.009903   Batch Acc: 71.88
[Train] Epoch: 1 [543168/620022]    Loss: 0.007802   Batch Acc: 79.69
[Train] Epoch: 1 [543232/620022]    Loss: 0.007196   Batch Acc: 79.69
[Train] Epoch: 1 [543296/620022]    Loss: 0.008057   Batch Acc: 79.69
[Train] Epoch: 1 [543360/620022]    Loss: 0.007277   Batch Acc: 79.69
[Train] Epoch: 1 [543424/620022]    Loss: 0.008549   Batch Acc: 79.69
[Train] Epoch: 1 [543488/620022]    Loss: 0.007880   Batch Acc: 78.12
[Train] Epoch: 1 [543552/620022]    Loss: 0.011518   Batch Acc: 70.31
[Train] Epoch: 1 [543616/620022]    Loss: 0.008658   Batch Acc: 81.25
[Train] Epoch: 1 [543680/620022]    Loss: 0.008568   Batch Acc: 79.69
[Train] Epoch: 1 [543744/620022]    Loss: 0.008103   Batch Acc: 78.12
[Train] Epoch: 1 [543808/620022]    Loss: 0.007913   Batch Acc: 76.56
[Train] Epoch: 1 [543872/620022]    Loss: 0.007661   Batch Acc: 84.38
[Train] Epoch: 1 [543936/620022]    Loss: 0.006881   Batch Acc: 81.25
[Train] Epoch: 1 [544000/620022]    Loss: 0.008132   Batch Acc: 81.25
[Train] Epoch: 1 [544064/620022]    Loss: 0.008092   Batch Acc: 81.25
[Train] Epoch: 1 [544128/620022]    Loss: 0.007223   Batch Acc: 85.94
[Train] Epoch: 1 [544192/620022]    Loss: 0.008662   Batch Acc: 75.00
[Train] Epoch: 1 [544256/620022]    Loss: 0.006748   Batch Acc: 84.38
[Train] Epoch: 1 [544320/620022]    Loss: 0.008699   Batch Acc: 76.56
[Train] Epoch: 1 [544384/620022]    Loss: 0.009584   Batch Acc: 75.00
[Train] Epoch: 1 [544448/620022]    Loss: 0.007308   Batch Acc: 78.12
[Train] Epoch: 1 [544512/620022]    Loss: 0.009332   Batch Acc: 73.44
[Train] Epoch: 1 [544576/620022]    Loss: 0.006555   Batch Acc: 92.19
[Train] Epoch: 1 [544640/620022]    Loss: 0.010711   Batch Acc: 67.19
[Train] Epoch: 1 [544704/620022]    Loss: 0.006576   Batch Acc: 82.81
[Train] Epoch: 1 [544768/620022]    Loss: 0.008802   Batch Acc: 78.12
[Train] Epoch: 1 [544832/620022]    Loss: 0.006319   Batch Acc: 89.06
[Train] Epoch: 1 [544896/620022]    Loss: 0.009413   Batch Acc: 76.56
[Train] Epoch: 1 [544960/620022]    Loss: 0.006397   Batch Acc: 81.25
[Train] Epoch: 1 [545024/620022]    Loss: 0.009316   Batch Acc: 78.12
[Train] Epoch: 1 [545088/620022]    Loss: 0.008378   Batch Acc: 79.69
[Train] Epoch: 1 [545152/620022]    Loss: 0.009176   Batch Acc: 76.56
[Train] Epoch: 1 [545216/620022]    Loss: 0.011191   Batch Acc: 75.00
[Train] Epoch: 1 [545280/620022]    Loss: 0.006395   Batch Acc: 87.50
[Train] Epoch: 1 [545344/620022]    Loss: 0.009634   Batch Acc: 73.44
[Train] Epoch: 1 [545408/620022]    Loss: 0.010486   Batch Acc: 70.31
[Train] Epoch: 1 [545472/620022]    Loss: 0.008825   Batch Acc: 81.25
[Train] Epoch: 1 [545536/620022]    Loss: 0.008615   Batch Acc: 81.25
[Train] Epoch: 1 [545600/620022]    Loss: 0.007170   Batch Acc: 82.81
[Train] Epoch: 1 [545664/620022]    Loss: 0.008372   Batch Acc: 75.00
[Train] Epoch: 1 [545728/620022]    Loss: 0.008866   Batch Acc: 70.31
[Train] Epoch: 1 [545792/620022]    Loss: 0.006289   Batch Acc: 84.38
[Train] Epoch: 1 [545856/620022]    Loss: 0.009192   Batch Acc: 73.44
[Train] Epoch: 1 [545920/620022]    Loss: 0.008855   Batch Acc: 78.12
[Train] Epoch: 1 [545984/620022]    Loss: 0.008956   Batch Acc: 76.56
[Train] Epoch: 1 [546048/620022]    Loss: 0.009134   Batch Acc: 70.31
[Train] Epoch: 1 [546112/620022]    Loss: 0.008412   Batch Acc: 76.56
[Train] Epoch: 1 [546176/620022]    Loss: 0.007962   Batch Acc: 78.12
[Train] Epoch: 1 [546240/620022]    Loss: 0.006839   Batch Acc: 82.81
[Train] Epoch: 1 [546304/620022]    Loss: 0.009792   Batch Acc: 75.00
[Train] Epoch: 1 [546368/620022]    Loss: 0.009726   Batch Acc: 76.56
[Train] Epoch: 1 [546432/620022]    Loss: 0.007470   Batch Acc: 78.12
[Train] Epoch: 1 [546496/620022]    Loss: 0.010646   Batch Acc: 76.56
[Train] Epoch: 1 [546560/620022]    Loss: 0.009998   Batch Acc: 76.56
[Train] Epoch: 1 [546624/620022]    Loss: 0.008233   Batch Acc: 75.00
[Train] Epoch: 1 [546688/620022]    Loss: 0.007847   Batch Acc: 81.25
[Train] Epoch: 1 [546752/620022]    Loss: 0.008356   Batch Acc: 81.25
[Train] Epoch: 1 [546816/620022]    Loss: 0.011048   Batch Acc: 70.31
[Train] Epoch: 1 [546880/620022]    Loss: 0.007592   Batch Acc: 79.69
[Train] Epoch: 1 [546944/620022]    Loss: 0.006790   Batch Acc: 84.38
[Train] Epoch: 1 [547008/620022]    Loss: 0.008823   Batch Acc: 70.31
[Train] Epoch: 1 [547072/620022]    Loss: 0.009085   Batch Acc: 78.12
[Train] Epoch: 1 [547136/620022]    Loss: 0.009045   Batch Acc: 78.12
[Train] Epoch: 1 [547200/620022]    Loss: 0.007530   Batch Acc: 78.12
[Train] Epoch: 1 [547264/620022]    Loss: 0.006662   Batch Acc: 85.94
[Train] Epoch: 1 [547328/620022]    Loss: 0.008172   Batch Acc: 81.25
[Train] Epoch: 1 [547392/620022]    Loss: 0.007500   Batch Acc: 85.94
[Train] Epoch: 1 [547456/620022]    Loss: 0.009566   Batch Acc: 75.00
[Train] Epoch: 1 [547520/620022]    Loss: 0.007407   Batch Acc: 78.12
[Train] Epoch: 1 [547584/620022]    Loss: 0.008248   Batch Acc: 82.81
[Train] Epoch: 1 [547648/620022]    Loss: 0.007832   Batch Acc: 79.69
[Train] Epoch: 1 [547712/620022]    Loss: 0.009289   Batch Acc: 75.00
[Train] Epoch: 1 [547776/620022]    Loss: 0.007836   Batch Acc: 81.25
[Train] Epoch: 1 [547840/620022]    Loss: 0.006391   Batch Acc: 87.50
[Train] Epoch: 1 [547904/620022]    Loss: 0.007808   Batch Acc: 79.69
[Train] Epoch: 1 [547968/620022]    Loss: 0.009505   Batch Acc: 68.75
[Train] Epoch: 1 [548032/620022]    Loss: 0.011934   Batch Acc: 70.31
[Train] Epoch: 1 [548096/620022]    Loss: 0.010699   Batch Acc: 75.00
[Train] Epoch: 1 [548160/620022]    Loss: 0.008121   Batch Acc: 82.81
[Train] Epoch: 1 [548224/620022]    Loss: 0.007164   Batch Acc: 81.25
[Train] Epoch: 1 [548288/620022]    Loss: 0.007434   Batch Acc: 82.81
[Train] Epoch: 1 [548352/620022]    Loss: 0.006977   Batch Acc: 84.38
[Train] Epoch: 1 [548416/620022]    Loss: 0.010794   Batch Acc: 71.88
[Train] Epoch: 1 [548480/620022]    Loss: 0.008204   Batch Acc: 76.56
[Train] Epoch: 1 [548544/620022]    Loss: 0.009398   Batch Acc: 73.44
[Train] Epoch: 1 [548608/620022]    Loss: 0.008482   Batch Acc: 79.69
[Train] Epoch: 1 [548672/620022]    Loss: 0.006971   Batch Acc: 87.50
[Train] Epoch: 1 [548736/620022]    Loss: 0.009878   Batch Acc: 75.00
[Train] Epoch: 1 [548800/620022]    Loss: 0.011537   Batch Acc: 67.19
[Train] Epoch: 1 [548864/620022]    Loss: 0.007049   Batch Acc: 81.25
[Train] Epoch: 1 [548928/620022]    Loss: 0.006873   Batch Acc: 87.50
[Train] Epoch: 1 [548992/620022]    Loss: 0.007961   Batch Acc: 79.69
[Train] Epoch: 1 [549056/620022]    Loss: 0.008393   Batch Acc: 79.69
[Train] Epoch: 1 [549120/620022]    Loss: 0.008697   Batch Acc: 78.12
[Train] Epoch: 1 [549184/620022]    Loss: 0.007941   Batch Acc: 84.38
[Train] Epoch: 1 [549248/620022]    Loss: 0.009424   Batch Acc: 73.44
[Train] Epoch: 1 [549312/620022]    Loss: 0.010325   Batch Acc: 70.31
[Train] Epoch: 1 [549376/620022]    Loss: 0.008828   Batch Acc: 78.12
[Train] Epoch: 1 [549440/620022]    Loss: 0.009444   Batch Acc: 71.88
[Train] Epoch: 1 [549504/620022]    Loss: 0.008219   Batch Acc: 82.81
[Train] Epoch: 1 [549568/620022]    Loss: 0.009861   Batch Acc: 75.00
[Train] Epoch: 1 [549632/620022]    Loss: 0.007437   Batch Acc: 84.38
[Train] Epoch: 1 [549696/620022]    Loss: 0.009580   Batch Acc: 75.00
[Train] Epoch: 1 [549760/620022]    Loss: 0.008330   Batch Acc: 79.69
[Train] Epoch: 1 [549824/620022]    Loss: 0.008314   Batch Acc: 79.69
[Train] Epoch: 1 [549888/620022]    Loss: 0.006231   Batch Acc: 89.06
[Train] Epoch: 1 [549952/620022]    Loss: 0.007047   Batch Acc: 81.25
[Train] Epoch: 1 [550016/620022]    Loss: 0.008500   Batch Acc: 76.56
[Train] Epoch: 1 [550080/620022]    Loss: 0.007204   Batch Acc: 79.69
[Train] Epoch: 1 [550144/620022]    Loss: 0.007420   Batch Acc: 82.81
[Train] Epoch: 1 [550208/620022]    Loss: 0.010490   Batch Acc: 73.44
[Train] Epoch: 1 [550272/620022]    Loss: 0.007954   Batch Acc: 75.00
[Train] Epoch: 1 [550336/620022]    Loss: 0.012362   Batch Acc: 67.19
[Train] Epoch: 1 [550400/620022]    Loss: 0.006973   Batch Acc: 82.81
[Train] Epoch: 1 [550464/620022]    Loss: 0.009083   Batch Acc: 81.25
[Train] Epoch: 1 [550528/620022]    Loss: 0.007422   Batch Acc: 82.81
[Train] Epoch: 1 [550592/620022]    Loss: 0.008804   Batch Acc: 75.00
[Train] Epoch: 1 [550656/620022]    Loss: 0.008383   Batch Acc: 79.69
[Train] Epoch: 1 [550720/620022]    Loss: 0.009556   Batch Acc: 79.69
[Train] Epoch: 1 [550784/620022]    Loss: 0.008182   Batch Acc: 85.94
[Train] Epoch: 1 [550848/620022]    Loss: 0.007836   Batch Acc: 82.81
[Train] Epoch: 1 [550912/620022]    Loss: 0.008146   Batch Acc: 76.56
[Train] Epoch: 1 [550976/620022]    Loss: 0.009198   Batch Acc: 75.00
[Train] Epoch: 1 [551040/620022]    Loss: 0.009821   Batch Acc: 76.56
[Train] Epoch: 1 [551104/620022]    Loss: 0.007645   Batch Acc: 84.38
[Train] Epoch: 1 [551168/620022]    Loss: 0.009916   Batch Acc: 79.69
[Train] Epoch: 1 [551232/620022]    Loss: 0.009219   Batch Acc: 71.88
[Train] Epoch: 1 [551296/620022]    Loss: 0.007422   Batch Acc: 79.69
[Train] Epoch: 1 [551360/620022]    Loss: 0.009142   Batch Acc: 70.31
[Train] Epoch: 1 [551424/620022]    Loss: 0.008884   Batch Acc: 75.00
[Train] Epoch: 1 [551488/620022]    Loss: 0.007827   Batch Acc: 84.38
[Train] Epoch: 1 [551552/620022]    Loss: 0.010195   Batch Acc: 75.00
[Train] Epoch: 1 [551616/620022]    Loss: 0.011515   Batch Acc: 68.75
[Train] Epoch: 1 [551680/620022]    Loss: 0.008912   Batch Acc: 76.56
[Train] Epoch: 1 [551744/620022]    Loss: 0.007889   Batch Acc: 76.56
[Train] Epoch: 1 [551808/620022]    Loss: 0.007068   Batch Acc: 81.25
[Train] Epoch: 1 [551872/620022]    Loss: 0.009701   Batch Acc: 73.44
[Train] Epoch: 1 [551936/620022]    Loss: 0.009291   Batch Acc: 75.00
[Train] Epoch: 1 [552000/620022]    Loss: 0.007614   Batch Acc: 78.12
[Train] Epoch: 1 [552064/620022]    Loss: 0.009218   Batch Acc: 76.56
[Train] Epoch: 1 [552128/620022]    Loss: 0.007181   Batch Acc: 85.94
[Train] Epoch: 1 [552192/620022]    Loss: 0.010076   Batch Acc: 70.31
[Train] Epoch: 1 [552256/620022]    Loss: 0.010462   Batch Acc: 73.44
[Train] Epoch: 1 [552320/620022]    Loss: 0.011734   Batch Acc: 67.19
[Train] Epoch: 1 [552384/620022]    Loss: 0.008611   Batch Acc: 79.69
[Train] Epoch: 1 [552448/620022]    Loss: 0.009969   Batch Acc: 76.56
[Train] Epoch: 1 [552512/620022]    Loss: 0.009731   Batch Acc: 76.56
[Train] Epoch: 1 [552576/620022]    Loss: 0.008626   Batch Acc: 76.56
[Train] Epoch: 1 [552640/620022]    Loss: 0.008305   Batch Acc: 78.12
[Train] Epoch: 1 [552704/620022]    Loss: 0.009424   Batch Acc: 76.56
[Train] Epoch: 1 [552768/620022]    Loss: 0.007498   Batch Acc: 82.81
[Train] Epoch: 1 [552832/620022]    Loss: 0.008435   Batch Acc: 81.25
[Train] Epoch: 1 [552896/620022]    Loss: 0.008713   Batch Acc: 76.56
[Train] Epoch: 1 [552960/620022]    Loss: 0.006182   Batch Acc: 87.50
[Train] Epoch: 1 [553024/620022]    Loss: 0.008253   Batch Acc: 76.56
[Train] Epoch: 1 [553088/620022]    Loss: 0.009399   Batch Acc: 75.00
[Train] Epoch: 1 [553152/620022]    Loss: 0.006721   Batch Acc: 82.81
[Train] Epoch: 1 [553216/620022]    Loss: 0.009040   Batch Acc: 71.88
[Train] Epoch: 1 [553280/620022]    Loss: 0.009257   Batch Acc: 68.75
[Train] Epoch: 1 [553344/620022]    Loss: 0.009143   Batch Acc: 78.12
[Train] Epoch: 1 [553408/620022]    Loss: 0.009402   Batch Acc: 76.56
[Train] Epoch: 1 [553472/620022]    Loss: 0.007348   Batch Acc: 81.25
[Train] Epoch: 1 [553536/620022]    Loss: 0.011881   Batch Acc: 64.06
[Train] Epoch: 1 [553600/620022]    Loss: 0.007520   Batch Acc: 81.25
[Train] Epoch: 1 [553664/620022]    Loss: 0.009551   Batch Acc: 71.88
[Train] Epoch: 1 [553728/620022]    Loss: 0.007569   Batch Acc: 81.25
[Train] Epoch: 1 [553792/620022]    Loss: 0.007441   Batch Acc: 78.12
[Train] Epoch: 1 [553856/620022]    Loss: 0.008042   Batch Acc: 81.25
[Train] Epoch: 1 [553920/620022]    Loss: 0.007349   Batch Acc: 82.81
[Train] Epoch: 1 [553984/620022]    Loss: 0.009090   Batch Acc: 75.00
[Train] Epoch: 1 [554048/620022]    Loss: 0.008316   Batch Acc: 75.00
[Train] Epoch: 1 [554112/620022]    Loss: 0.006212   Batch Acc: 87.50
[Train] Epoch: 1 [554176/620022]    Loss: 0.010126   Batch Acc: 75.00
[Train] Epoch: 1 [554240/620022]    Loss: 0.007339   Batch Acc: 84.38
[Train] Epoch: 1 [554304/620022]    Loss: 0.007721   Batch Acc: 87.50
[Train] Epoch: 1 [554368/620022]    Loss: 0.006987   Batch Acc: 89.06
[Train] Epoch: 1 [554432/620022]    Loss: 0.008099   Batch Acc: 73.44
[Train] Epoch: 1 [554496/620022]    Loss: 0.007376   Batch Acc: 82.81
[Train] Epoch: 1 [554560/620022]    Loss: 0.006558   Batch Acc: 89.06
[Train] Epoch: 1 [554624/620022]    Loss: 0.010482   Batch Acc: 78.12
[Train] Epoch: 1 [554688/620022]    Loss: 0.010252   Batch Acc: 71.88
[Train] Epoch: 1 [554752/620022]    Loss: 0.009146   Batch Acc: 75.00
[Train] Epoch: 1 [554816/620022]    Loss: 0.007845   Batch Acc: 79.69
[Train] Epoch: 1 [554880/620022]    Loss: 0.007995   Batch Acc: 78.12
[Train] Epoch: 1 [554944/620022]    Loss: 0.010814   Batch Acc: 71.88
[Train] Epoch: 1 [555008/620022]    Loss: 0.009303   Batch Acc: 79.69
[Train] Epoch: 1 [555072/620022]    Loss: 0.007297   Batch Acc: 85.94
[Train] Epoch: 1 [555136/620022]    Loss: 0.006622   Batch Acc: 81.25
[Train] Epoch: 1 [555200/620022]    Loss: 0.009436   Batch Acc: 75.00
[Train] Epoch: 1 [555264/620022]    Loss: 0.007010   Batch Acc: 82.81
[Train] Epoch: 1 [555328/620022]    Loss: 0.006778   Batch Acc: 82.81
[Train] Epoch: 1 [555392/620022]    Loss: 0.009491   Batch Acc: 76.56
[Train] Epoch: 1 [555456/620022]    Loss: 0.007819   Batch Acc: 76.56
[Train] Epoch: 1 [555520/620022]    Loss: 0.008515   Batch Acc: 84.38
[Train] Epoch: 1 [555584/620022]    Loss: 0.008265   Batch Acc: 84.38
[Train] Epoch: 1 [555648/620022]    Loss: 0.009102   Batch Acc: 75.00
[Train] Epoch: 1 [555712/620022]    Loss: 0.009432   Batch Acc: 70.31
[Train] Epoch: 1 [555776/620022]    Loss: 0.008643   Batch Acc: 82.81
[Train] Epoch: 1 [555840/620022]    Loss: 0.006523   Batch Acc: 85.94
[Train] Epoch: 1 [555904/620022]    Loss: 0.007916   Batch Acc: 78.12
[Train] Epoch: 1 [555968/620022]    Loss: 0.008642   Batch Acc: 76.56
[Train] Epoch: 1 [556032/620022]    Loss: 0.007340   Batch Acc: 82.81
[Train] Epoch: 1 [556096/620022]    Loss: 0.009256   Batch Acc: 75.00
[Train] Epoch: 1 [556160/620022]    Loss: 0.006967   Batch Acc: 84.38
[Train] Epoch: 1 [556224/620022]    Loss: 0.008458   Batch Acc: 78.12
[Train] Epoch: 1 [556288/620022]    Loss: 0.008589   Batch Acc: 73.44
[Train] Epoch: 1 [556352/620022]    Loss: 0.009324   Batch Acc: 71.88
[Train] Epoch: 1 [556416/620022]    Loss: 0.007716   Batch Acc: 76.56
[Train] Epoch: 1 [556480/620022]    Loss: 0.010066   Batch Acc: 71.88
[Train] Epoch: 1 [556544/620022]    Loss: 0.008670   Batch Acc: 76.56
[Train] Epoch: 1 [556608/620022]    Loss: 0.009058   Batch Acc: 75.00
[Train] Epoch: 1 [556672/620022]    Loss: 0.010393   Batch Acc: 75.00
[Train] Epoch: 1 [556736/620022]    Loss: 0.007937   Batch Acc: 76.56
[Train] Epoch: 1 [556800/620022]    Loss: 0.009510   Batch Acc: 71.88
[Train] Epoch: 1 [556864/620022]    Loss: 0.005703   Batch Acc: 92.19
[Train] Epoch: 1 [556928/620022]    Loss: 0.009735   Batch Acc: 71.88
[Train] Epoch: 1 [556992/620022]    Loss: 0.008122   Batch Acc: 79.69
[Train] Epoch: 1 [557056/620022]    Loss: 0.009954   Batch Acc: 73.44
[Train] Epoch: 1 [557120/620022]    Loss: 0.008391   Batch Acc: 82.81
[Train] Epoch: 1 [557184/620022]    Loss: 0.007596   Batch Acc: 85.94
[Train] Epoch: 1 [557248/620022]    Loss: 0.006997   Batch Acc: 89.06
[Train] Epoch: 1 [557312/620022]    Loss: 0.008964   Batch Acc: 75.00
[Train] Epoch: 1 [557376/620022]    Loss: 0.009110   Batch Acc: 76.56
[Train] Epoch: 1 [557440/620022]    Loss: 0.012020   Batch Acc: 65.62
[Train] Epoch: 1 [557504/620022]    Loss: 0.007095   Batch Acc: 84.38
[Train] Epoch: 1 [557568/620022]    Loss: 0.007881   Batch Acc: 81.25
[Train] Epoch: 1 [557632/620022]    Loss: 0.010853   Batch Acc: 68.75
[Train] Epoch: 1 [557696/620022]    Loss: 0.007759   Batch Acc: 81.25
[Train] Epoch: 1 [557760/620022]    Loss: 0.008577   Batch Acc: 82.81
[Train] Epoch: 1 [557824/620022]    Loss: 0.010362   Batch Acc: 71.88
[Train] Epoch: 1 [557888/620022]    Loss: 0.008554   Batch Acc: 81.25
[Train] Epoch: 1 [557952/620022]    Loss: 0.009111   Batch Acc: 68.75
[Train] Epoch: 1 [558016/620022]    Loss: 0.007758   Batch Acc: 85.94
[Train] Epoch: 1 [558080/620022]    Loss: 0.008652   Batch Acc: 81.25
[Train] Epoch: 1 [558144/620022]    Loss: 0.008251   Batch Acc: 81.25
[Train] Epoch: 1 [558208/620022]    Loss: 0.007012   Batch Acc: 82.81
[Train] Epoch: 1 [558272/620022]    Loss: 0.013009   Batch Acc: 64.06
[Train] Epoch: 1 [558336/620022]    Loss: 0.011447   Batch Acc: 68.75
[Train] Epoch: 1 [558400/620022]    Loss: 0.007497   Batch Acc: 84.38
[Train] Epoch: 1 [558464/620022]    Loss: 0.010506   Batch Acc: 76.56
[Train] Epoch: 1 [558528/620022]    Loss: 0.008076   Batch Acc: 78.12
[Train] Epoch: 1 [558592/620022]    Loss: 0.010573   Batch Acc: 67.19
[Train] Epoch: 1 [558656/620022]    Loss: 0.008525   Batch Acc: 79.69
[Train] Epoch: 1 [558720/620022]    Loss: 0.007802   Batch Acc: 79.69
[Train] Epoch: 1 [558784/620022]    Loss: 0.010378   Batch Acc: 79.69
[Train] Epoch: 1 [558848/620022]    Loss: 0.009655   Batch Acc: 65.62
[Train] Epoch: 1 [558912/620022]    Loss: 0.008556   Batch Acc: 76.56
[Train] Epoch: 1 [558976/620022]    Loss: 0.007562   Batch Acc: 81.25
[Train] Epoch: 1 [559040/620022]    Loss: 0.009166   Batch Acc: 75.00
[Train] Epoch: 1 [559104/620022]    Loss: 0.011015   Batch Acc: 70.31
[Train] Epoch: 1 [559168/620022]    Loss: 0.009052   Batch Acc: 70.31
[Train] Epoch: 1 [559232/620022]    Loss: 0.009289   Batch Acc: 73.44
[Train] Epoch: 1 [559296/620022]    Loss: 0.009284   Batch Acc: 75.00
[Train] Epoch: 1 [559360/620022]    Loss: 0.008374   Batch Acc: 82.81
[Train] Epoch: 1 [559424/620022]    Loss: 0.007213   Batch Acc: 82.81
[Train] Epoch: 1 [559488/620022]    Loss: 0.010083   Batch Acc: 67.19
[Train] Epoch: 1 [559552/620022]    Loss: 0.010947   Batch Acc: 71.88
[Train] Epoch: 1 [559616/620022]    Loss: 0.008255   Batch Acc: 81.25
[Train] Epoch: 1 [559680/620022]    Loss: 0.008059   Batch Acc: 84.38
[Train] Epoch: 1 [559744/620022]    Loss: 0.008118   Batch Acc: 82.81
[Train] Epoch: 1 [559808/620022]    Loss: 0.008882   Batch Acc: 82.81
[Train] Epoch: 1 [559872/620022]    Loss: 0.010981   Batch Acc: 68.75
[Train] Epoch: 1 [559936/620022]    Loss: 0.010195   Batch Acc: 71.88
[Train] Epoch: 1 [560000/620022]    Loss: 0.007711   Batch Acc: 81.25
[Train] Epoch: 1 [560064/620022]    Loss: 0.007795   Batch Acc: 79.69
[Train] Epoch: 1 [560128/620022]    Loss: 0.008885   Batch Acc: 78.12
[Train] Epoch: 1 [560192/620022]    Loss: 0.008166   Batch Acc: 78.12
[Train] Epoch: 1 [560256/620022]    Loss: 0.006866   Batch Acc: 84.38
[Train] Epoch: 1 [560320/620022]    Loss: 0.009690   Batch Acc: 78.12
[Train] Epoch: 1 [560384/620022]    Loss: 0.006724   Batch Acc: 82.81
[Train] Epoch: 1 [560448/620022]    Loss: 0.007805   Batch Acc: 79.69
[Train] Epoch: 1 [560512/620022]    Loss: 0.010501   Batch Acc: 73.44
[Train] Epoch: 1 [560576/620022]    Loss: 0.009437   Batch Acc: 76.56
[Train] Epoch: 1 [560640/620022]    Loss: 0.009682   Batch Acc: 75.00
[Train] Epoch: 1 [560704/620022]    Loss: 0.008452   Batch Acc: 82.81
[Train] Epoch: 1 [560768/620022]    Loss: 0.008983   Batch Acc: 81.25
[Train] Epoch: 1 [560832/620022]    Loss: 0.008354   Batch Acc: 79.69
[Train] Epoch: 1 [560896/620022]    Loss: 0.009624   Batch Acc: 73.44
[Train] Epoch: 1 [560960/620022]    Loss: 0.008363   Batch Acc: 81.25
[Train] Epoch: 1 [561024/620022]    Loss: 0.007768   Batch Acc: 79.69
[Train] Epoch: 1 [561088/620022]    Loss: 0.007336   Batch Acc: 81.25
[Train] Epoch: 1 [561152/620022]    Loss: 0.010234   Batch Acc: 71.88
[Train] Epoch: 1 [561216/620022]    Loss: 0.009357   Batch Acc: 78.12
[Train] Epoch: 1 [561280/620022]    Loss: 0.008941   Batch Acc: 79.69
[Train] Epoch: 1 [561344/620022]    Loss: 0.005788   Batch Acc: 90.62
[Train] Epoch: 1 [561408/620022]    Loss: 0.007390   Batch Acc: 81.25
[Train] Epoch: 1 [561472/620022]    Loss: 0.008217   Batch Acc: 81.25
[Train] Epoch: 1 [561536/620022]    Loss: 0.008440   Batch Acc: 76.56
[Train] Epoch: 1 [561600/620022]    Loss: 0.007891   Batch Acc: 90.62
[Train] Epoch: 1 [561664/620022]    Loss: 0.006294   Batch Acc: 87.50
[Train] Epoch: 1 [561728/620022]    Loss: 0.007678   Batch Acc: 82.81
[Train] Epoch: 1 [561792/620022]    Loss: 0.007154   Batch Acc: 85.94
[Train] Epoch: 1 [561856/620022]    Loss: 0.008065   Batch Acc: 82.81
[Train] Epoch: 1 [561920/620022]    Loss: 0.011309   Batch Acc: 67.19
[Train] Epoch: 1 [561984/620022]    Loss: 0.012237   Batch Acc: 68.75
[Train] Epoch: 1 [562048/620022]    Loss: 0.006312   Batch Acc: 84.38
[Train] Epoch: 1 [562112/620022]    Loss: 0.008230   Batch Acc: 81.25
[Train] Epoch: 1 [562176/620022]    Loss: 0.008131   Batch Acc: 79.69
[Train] Epoch: 1 [562240/620022]    Loss: 0.010758   Batch Acc: 73.44
[Train] Epoch: 1 [562304/620022]    Loss: 0.008407   Batch Acc: 79.69
[Train] Epoch: 1 [562368/620022]    Loss: 0.009593   Batch Acc: 78.12
[Train] Epoch: 1 [562432/620022]    Loss: 0.005824   Batch Acc: 85.94
[Train] Epoch: 1 [562496/620022]    Loss: 0.010184   Batch Acc: 79.69
[Train] Epoch: 1 [562560/620022]    Loss: 0.009844   Batch Acc: 76.56
[Train] Epoch: 1 [562624/620022]    Loss: 0.007758   Batch Acc: 79.69
[Train] Epoch: 1 [562688/620022]    Loss: 0.008683   Batch Acc: 75.00
[Train] Epoch: 1 [562752/620022]    Loss: 0.008796   Batch Acc: 78.12
[Train] Epoch: 1 [562816/620022]    Loss: 0.008052   Batch Acc: 81.25
[Train] Epoch: 1 [562880/620022]    Loss: 0.007810   Batch Acc: 79.69
[Train] Epoch: 1 [562944/620022]    Loss: 0.008107   Batch Acc: 81.25
[Train] Epoch: 1 [563008/620022]    Loss: 0.006252   Batch Acc: 87.50
[Train] Epoch: 1 [563072/620022]    Loss: 0.008639   Batch Acc: 75.00
[Train] Epoch: 1 [563136/620022]    Loss: 0.007930   Batch Acc: 81.25
[Train] Epoch: 1 [563200/620022]    Loss: 0.010298   Batch Acc: 73.44
[Train] Epoch: 1 [563264/620022]    Loss: 0.006994   Batch Acc: 79.69
[Train] Epoch: 1 [563328/620022]    Loss: 0.006860   Batch Acc: 84.38
[Train] Epoch: 1 [563392/620022]    Loss: 0.008872   Batch Acc: 76.56
[Train] Epoch: 1 [563456/620022]    Loss: 0.007920   Batch Acc: 78.12
[Train] Epoch: 1 [563520/620022]    Loss: 0.008424   Batch Acc: 75.00
[Train] Epoch: 1 [563584/620022]    Loss: 0.006713   Batch Acc: 85.94
[Train] Epoch: 1 [563648/620022]    Loss: 0.007975   Batch Acc: 79.69
[Train] Epoch: 1 [563712/620022]    Loss: 0.007867   Batch Acc: 76.56
[Train] Epoch: 1 [563776/620022]    Loss: 0.008670   Batch Acc: 78.12
[Train] Epoch: 1 [563840/620022]    Loss: 0.008053   Batch Acc: 79.69
[Train] Epoch: 1 [563904/620022]    Loss: 0.009202   Batch Acc: 78.12
[Train] Epoch: 1 [563968/620022]    Loss: 0.009506   Batch Acc: 68.75
[Train] Epoch: 1 [564032/620022]    Loss: 0.008258   Batch Acc: 79.69
[Train] Epoch: 1 [564096/620022]    Loss: 0.009179   Batch Acc: 79.69
[Train] Epoch: 1 [564160/620022]    Loss: 0.007675   Batch Acc: 78.12
[Train] Epoch: 1 [564224/620022]    Loss: 0.008409   Batch Acc: 81.25
[Train] Epoch: 1 [564288/620022]    Loss: 0.010395   Batch Acc: 73.44
[Train] Epoch: 1 [564352/620022]    Loss: 0.007184   Batch Acc: 79.69
[Train] Epoch: 1 [564416/620022]    Loss: 0.007908   Batch Acc: 84.38
[Train] Epoch: 1 [564480/620022]    Loss: 0.007570   Batch Acc: 78.12
[Train] Epoch: 1 [564544/620022]    Loss: 0.008962   Batch Acc: 71.88
[Train] Epoch: 1 [564608/620022]    Loss: 0.007369   Batch Acc: 82.81
[Train] Epoch: 1 [564672/620022]    Loss: 0.008757   Batch Acc: 78.12
[Train] Epoch: 1 [564736/620022]    Loss: 0.007348   Batch Acc: 79.69
[Train] Epoch: 1 [564800/620022]    Loss: 0.009711   Batch Acc: 76.56
[Train] Epoch: 1 [564864/620022]    Loss: 0.010598   Batch Acc: 75.00
[Train] Epoch: 1 [564928/620022]    Loss: 0.008464   Batch Acc: 75.00
[Train] Epoch: 1 [564992/620022]    Loss: 0.009211   Batch Acc: 78.12
[Train] Epoch: 1 [565056/620022]    Loss: 0.007354   Batch Acc: 85.94
[Train] Epoch: 1 [565120/620022]    Loss: 0.009332   Batch Acc: 78.12
[Train] Epoch: 1 [565184/620022]    Loss: 0.008827   Batch Acc: 75.00
[Train] Epoch: 1 [565248/620022]    Loss: 0.008940   Batch Acc: 79.69
[Train] Epoch: 1 [565312/620022]    Loss: 0.009737   Batch Acc: 78.12
[Train] Epoch: 1 [565376/620022]    Loss: 0.007549   Batch Acc: 84.38
[Train] Epoch: 1 [565440/620022]    Loss: 0.007438   Batch Acc: 76.56
[Train] Epoch: 1 [565504/620022]    Loss: 0.007646   Batch Acc: 78.12
[Train] Epoch: 1 [565568/620022]    Loss: 0.008776   Batch Acc: 81.25
[Train] Epoch: 1 [565632/620022]    Loss: 0.008124   Batch Acc: 75.00
[Train] Epoch: 1 [565696/620022]    Loss: 0.007708   Batch Acc: 81.25
[Train] Epoch: 1 [565760/620022]    Loss: 0.007691   Batch Acc: 81.25
[Train] Epoch: 1 [565824/620022]    Loss: 0.008606   Batch Acc: 73.44
[Train] Epoch: 1 [565888/620022]    Loss: 0.011069   Batch Acc: 64.06
[Train] Epoch: 1 [565952/620022]    Loss: 0.008726   Batch Acc: 81.25
[Train] Epoch: 1 [566016/620022]    Loss: 0.009405   Batch Acc: 76.56
[Train] Epoch: 1 [566080/620022]    Loss: 0.007647   Batch Acc: 79.69
[Train] Epoch: 1 [566144/620022]    Loss: 0.008315   Batch Acc: 82.81
[Train] Epoch: 1 [566208/620022]    Loss: 0.009438   Batch Acc: 73.44
[Train] Epoch: 1 [566272/620022]    Loss: 0.009440   Batch Acc: 75.00
[Train] Epoch: 1 [566336/620022]    Loss: 0.009172   Batch Acc: 76.56
[Train] Epoch: 1 [566400/620022]    Loss: 0.007077   Batch Acc: 84.38
[Train] Epoch: 1 [566464/620022]    Loss: 0.006566   Batch Acc: 87.50
[Train] Epoch: 1 [566528/620022]    Loss: 0.008216   Batch Acc: 81.25
[Train] Epoch: 1 [566592/620022]    Loss: 0.007824   Batch Acc: 79.69
[Train] Epoch: 1 [566656/620022]    Loss: 0.007823   Batch Acc: 78.12
[Train] Epoch: 1 [566720/620022]    Loss: 0.007735   Batch Acc: 78.12
[Train] Epoch: 1 [566784/620022]    Loss: 0.008267   Batch Acc: 82.81
[Train] Epoch: 1 [566848/620022]    Loss: 0.007490   Batch Acc: 82.81
[Train] Epoch: 1 [566912/620022]    Loss: 0.008100   Batch Acc: 82.81
[Train] Epoch: 1 [566976/620022]    Loss: 0.010864   Batch Acc: 73.44
[Train] Epoch: 1 [567040/620022]    Loss: 0.007293   Batch Acc: 82.81
[Train] Epoch: 1 [567104/620022]    Loss: 0.010823   Batch Acc: 67.19
[Train] Epoch: 1 [567168/620022]    Loss: 0.008123   Batch Acc: 81.25
[Train] Epoch: 1 [567232/620022]    Loss: 0.008790   Batch Acc: 79.69
[Train] Epoch: 1 [567296/620022]    Loss: 0.008214   Batch Acc: 76.56
[Train] Epoch: 1 [567360/620022]    Loss: 0.006348   Batch Acc: 84.38
[Train] Epoch: 1 [567424/620022]    Loss: 0.009875   Batch Acc: 73.44
[Train] Epoch: 1 [567488/620022]    Loss: 0.008893   Batch Acc: 76.56
[Train] Epoch: 1 [567552/620022]    Loss: 0.007152   Batch Acc: 82.81
[Train] Epoch: 1 [567616/620022]    Loss: 0.008289   Batch Acc: 81.25
[Train] Epoch: 1 [567680/620022]    Loss: 0.009973   Batch Acc: 71.88
[Train] Epoch: 1 [567744/620022]    Loss: 0.009104   Batch Acc: 79.69
[Train] Epoch: 1 [567808/620022]    Loss: 0.010174   Batch Acc: 68.75
[Train] Epoch: 1 [567872/620022]    Loss: 0.010220   Batch Acc: 73.44
[Train] Epoch: 1 [567936/620022]    Loss: 0.009358   Batch Acc: 75.00
[Train] Epoch: 1 [568000/620022]    Loss: 0.009092   Batch Acc: 76.56
[Train] Epoch: 1 [568064/620022]    Loss: 0.006645   Batch Acc: 85.94
[Train] Epoch: 1 [568128/620022]    Loss: 0.007901   Batch Acc: 79.69
[Train] Epoch: 1 [568192/620022]    Loss: 0.009688   Batch Acc: 81.25
[Train] Epoch: 1 [568256/620022]    Loss: 0.010082   Batch Acc: 75.00
[Train] Epoch: 1 [568320/620022]    Loss: 0.009775   Batch Acc: 71.88
[Train] Epoch: 1 [568384/620022]    Loss: 0.009239   Batch Acc: 75.00
[Train] Epoch: 1 [568448/620022]    Loss: 0.007703   Batch Acc: 79.69
[Train] Epoch: 1 [568512/620022]    Loss: 0.008070   Batch Acc: 79.69
[Train] Epoch: 1 [568576/620022]    Loss: 0.008123   Batch Acc: 82.81
[Train] Epoch: 1 [568640/620022]    Loss: 0.008389   Batch Acc: 81.25
[Train] Epoch: 1 [568704/620022]    Loss: 0.009146   Batch Acc: 78.12
[Train] Epoch: 1 [568768/620022]    Loss: 0.009099   Batch Acc: 78.12
[Train] Epoch: 1 [568832/620022]    Loss: 0.010990   Batch Acc: 73.44
[Train] Epoch: 1 [568896/620022]    Loss: 0.009518   Batch Acc: 71.88
[Train] Epoch: 1 [568960/620022]    Loss: 0.009052   Batch Acc: 79.69
[Train] Epoch: 1 [569024/620022]    Loss: 0.010195   Batch Acc: 71.88
[Train] Epoch: 1 [569088/620022]    Loss: 0.008987   Batch Acc: 79.69
[Train] Epoch: 1 [569152/620022]    Loss: 0.011013   Batch Acc: 70.31
[Train] Epoch: 1 [569216/620022]    Loss: 0.008231   Batch Acc: 79.69
[Train] Epoch: 1 [569280/620022]    Loss: 0.008173   Batch Acc: 79.69
[Train] Epoch: 1 [569344/620022]    Loss: 0.008885   Batch Acc: 79.69
[Train] Epoch: 1 [569408/620022]    Loss: 0.010004   Batch Acc: 70.31
[Train] Epoch: 1 [569472/620022]    Loss: 0.008264   Batch Acc: 79.69
[Train] Epoch: 1 [569536/620022]    Loss: 0.011474   Batch Acc: 70.31
[Train] Epoch: 1 [569600/620022]    Loss: 0.010423   Batch Acc: 71.88
[Train] Epoch: 1 [569664/620022]    Loss: 0.007918   Batch Acc: 78.12
[Train] Epoch: 1 [569728/620022]    Loss: 0.008682   Batch Acc: 76.56
[Train] Epoch: 1 [569792/620022]    Loss: 0.008616   Batch Acc: 78.12
[Train] Epoch: 1 [569856/620022]    Loss: 0.010137   Batch Acc: 78.12
[Train] Epoch: 1 [569920/620022]    Loss: 0.006253   Batch Acc: 84.38
[Train] Epoch: 1 [569984/620022]    Loss: 0.009474   Batch Acc: 70.31
[Train] Epoch: 1 [570048/620022]    Loss: 0.007254   Batch Acc: 87.50
[Train] Epoch: 1 [570112/620022]    Loss: 0.007978   Batch Acc: 84.38
[Train] Epoch: 1 [570176/620022]    Loss: 0.009143   Batch Acc: 76.56
[Train] Epoch: 1 [570240/620022]    Loss: 0.008783   Batch Acc: 78.12
[Train] Epoch: 1 [570304/620022]    Loss: 0.009661   Batch Acc: 75.00
[Train] Epoch: 1 [570368/620022]    Loss: 0.008944   Batch Acc: 81.25
[Train] Epoch: 1 [570432/620022]    Loss: 0.008561   Batch Acc: 76.56
[Train] Epoch: 1 [570496/620022]    Loss: 0.007607   Batch Acc: 82.81
[Train] Epoch: 1 [570560/620022]    Loss: 0.007850   Batch Acc: 84.38
[Train] Epoch: 1 [570624/620022]    Loss: 0.006491   Batch Acc: 82.81
[Train] Epoch: 1 [570688/620022]    Loss: 0.008760   Batch Acc: 79.69
[Train] Epoch: 1 [570752/620022]    Loss: 0.007944   Batch Acc: 76.56
[Train] Epoch: 1 [570816/620022]    Loss: 0.009605   Batch Acc: 78.12
[Train] Epoch: 1 [570880/620022]    Loss: 0.008993   Batch Acc: 75.00
[Train] Epoch: 1 [570944/620022]    Loss: 0.006488   Batch Acc: 85.94
[Train] Epoch: 1 [571008/620022]    Loss: 0.009813   Batch Acc: 75.00
[Train] Epoch: 1 [571072/620022]    Loss: 0.008124   Batch Acc: 75.00
[Train] Epoch: 1 [571136/620022]    Loss: 0.009685   Batch Acc: 73.44
[Train] Epoch: 1 [571200/620022]    Loss: 0.009143   Batch Acc: 75.00
[Train] Epoch: 1 [571264/620022]    Loss: 0.009855   Batch Acc: 78.12
[Train] Epoch: 1 [571328/620022]    Loss: 0.008866   Batch Acc: 79.69
[Train] Epoch: 1 [571392/620022]    Loss: 0.009330   Batch Acc: 73.44
[Train] Epoch: 1 [571456/620022]    Loss: 0.009203   Batch Acc: 79.69
[Train] Epoch: 1 [571520/620022]    Loss: 0.007070   Batch Acc: 89.06
[Train] Epoch: 1 [571584/620022]    Loss: 0.007243   Batch Acc: 84.38
[Train] Epoch: 1 [571648/620022]    Loss: 0.008517   Batch Acc: 76.56
[Train] Epoch: 1 [571712/620022]    Loss: 0.009052   Batch Acc: 68.75
[Train] Epoch: 1 [571776/620022]    Loss: 0.007662   Batch Acc: 84.38
[Train] Epoch: 1 [571840/620022]    Loss: 0.008263   Batch Acc: 78.12
[Train] Epoch: 1 [571904/620022]    Loss: 0.009089   Batch Acc: 75.00
[Train] Epoch: 1 [571968/620022]    Loss: 0.007940   Batch Acc: 82.81
[Train] Epoch: 1 [572032/620022]    Loss: 0.008256   Batch Acc: 76.56
[Train] Epoch: 1 [572096/620022]    Loss: 0.010536   Batch Acc: 73.44
[Train] Epoch: 1 [572160/620022]    Loss: 0.008062   Batch Acc: 78.12
[Train] Epoch: 1 [572224/620022]    Loss: 0.008833   Batch Acc: 79.69
[Train] Epoch: 1 [572288/620022]    Loss: 0.007160   Batch Acc: 84.38
[Train] Epoch: 1 [572352/620022]    Loss: 0.008748   Batch Acc: 82.81
[Train] Epoch: 1 [572416/620022]    Loss: 0.007850   Batch Acc: 79.69
[Train] Epoch: 1 [572480/620022]    Loss: 0.007626   Batch Acc: 78.12
[Train] Epoch: 1 [572544/620022]    Loss: 0.008899   Batch Acc: 76.56
[Train] Epoch: 1 [572608/620022]    Loss: 0.008765   Batch Acc: 78.12
[Train] Epoch: 1 [572672/620022]    Loss: 0.009644   Batch Acc: 75.00
[Train] Epoch: 1 [572736/620022]    Loss: 0.010239   Batch Acc: 76.56
[Train] Epoch: 1 [572800/620022]    Loss: 0.008837   Batch Acc: 79.69
[Train] Epoch: 1 [572864/620022]    Loss: 0.008242   Batch Acc: 78.12
[Train] Epoch: 1 [572928/620022]    Loss: 0.007527   Batch Acc: 79.69
[Train] Epoch: 1 [572992/620022]    Loss: 0.009243   Batch Acc: 71.88
[Train] Epoch: 1 [573056/620022]    Loss: 0.007288   Batch Acc: 84.38
[Train] Epoch: 1 [573120/620022]    Loss: 0.008173   Batch Acc: 81.25
[Train] Epoch: 1 [573184/620022]    Loss: 0.009859   Batch Acc: 70.31
[Train] Epoch: 1 [573248/620022]    Loss: 0.010919   Batch Acc: 71.88
[Train] Epoch: 1 [573312/620022]    Loss: 0.009007   Batch Acc: 73.44
[Train] Epoch: 1 [573376/620022]    Loss: 0.009071   Batch Acc: 75.00
[Train] Epoch: 1 [573440/620022]    Loss: 0.008436   Batch Acc: 79.69
[Train] Epoch: 1 [573504/620022]    Loss: 0.009828   Batch Acc: 76.56
[Train] Epoch: 1 [573568/620022]    Loss: 0.011031   Batch Acc: 67.19
[Train] Epoch: 1 [573632/620022]    Loss: 0.007668   Batch Acc: 81.25
[Train] Epoch: 1 [573696/620022]    Loss: 0.008687   Batch Acc: 75.00
[Train] Epoch: 1 [573760/620022]    Loss: 0.007782   Batch Acc: 81.25
[Train] Epoch: 1 [573824/620022]    Loss: 0.009169   Batch Acc: 78.12
[Train] Epoch: 1 [573888/620022]    Loss: 0.006855   Batch Acc: 84.38
[Train] Epoch: 1 [573952/620022]    Loss: 0.009350   Batch Acc: 81.25
[Train] Epoch: 1 [574016/620022]    Loss: 0.007717   Batch Acc: 84.38
[Train] Epoch: 1 [574080/620022]    Loss: 0.008354   Batch Acc: 76.56
[Train] Epoch: 1 [574144/620022]    Loss: 0.008762   Batch Acc: 75.00
[Train] Epoch: 1 [574208/620022]    Loss: 0.007098   Batch Acc: 82.81
[Train] Epoch: 1 [574272/620022]    Loss: 0.005825   Batch Acc: 89.06
[Train] Epoch: 1 [574336/620022]    Loss: 0.009395   Batch Acc: 70.31
[Train] Epoch: 1 [574400/620022]    Loss: 0.008046   Batch Acc: 81.25
[Train] Epoch: 1 [574464/620022]    Loss: 0.008893   Batch Acc: 78.12
[Train] Epoch: 1 [574528/620022]    Loss: 0.008162   Batch Acc: 79.69
[Train] Epoch: 1 [574592/620022]    Loss: 0.007652   Batch Acc: 82.81
[Train] Epoch: 1 [574656/620022]    Loss: 0.008315   Batch Acc: 79.69
[Train] Epoch: 1 [574720/620022]    Loss: 0.007692   Batch Acc: 76.56
[Train] Epoch: 1 [574784/620022]    Loss: 0.007824   Batch Acc: 85.94
[Train] Epoch: 1 [574848/620022]    Loss: 0.011791   Batch Acc: 64.06
[Train] Epoch: 1 [574912/620022]    Loss: 0.009205   Batch Acc: 71.88
[Train] Epoch: 1 [574976/620022]    Loss: 0.009490   Batch Acc: 71.88
[Train] Epoch: 1 [575040/620022]    Loss: 0.008503   Batch Acc: 84.38
[Train] Epoch: 1 [575104/620022]    Loss: 0.006060   Batch Acc: 90.62
[Train] Epoch: 1 [575168/620022]    Loss: 0.009049   Batch Acc: 76.56
[Train] Epoch: 1 [575232/620022]    Loss: 0.008195   Batch Acc: 82.81
[Train] Epoch: 1 [575296/620022]    Loss: 0.010905   Batch Acc: 76.56
[Train] Epoch: 1 [575360/620022]    Loss: 0.009345   Batch Acc: 79.69
[Train] Epoch: 1 [575424/620022]    Loss: 0.005339   Batch Acc: 90.62
[Train] Epoch: 1 [575488/620022]    Loss: 0.009113   Batch Acc: 79.69
[Train] Epoch: 1 [575552/620022]    Loss: 0.007502   Batch Acc: 79.69
[Train] Epoch: 1 [575616/620022]    Loss: 0.008652   Batch Acc: 79.69
[Train] Epoch: 1 [575680/620022]    Loss: 0.009437   Batch Acc: 79.69
[Train] Epoch: 1 [575744/620022]    Loss: 0.010496   Batch Acc: 73.44
[Train] Epoch: 1 [575808/620022]    Loss: 0.008888   Batch Acc: 73.44
[Train] Epoch: 1 [575872/620022]    Loss: 0.008626   Batch Acc: 75.00
[Train] Epoch: 1 [575936/620022]    Loss: 0.006507   Batch Acc: 89.06
[Train] Epoch: 1 [576000/620022]    Loss: 0.008029   Batch Acc: 82.81
[Train] Epoch: 1 [576064/620022]    Loss: 0.010086   Batch Acc: 71.88
[Train] Epoch: 1 [576128/620022]    Loss: 0.009840   Batch Acc: 76.56
[Train] Epoch: 1 [576192/620022]    Loss: 0.008488   Batch Acc: 76.56
[Train] Epoch: 1 [576256/620022]    Loss: 0.007550   Batch Acc: 78.12
[Train] Epoch: 1 [576320/620022]    Loss: 0.008472   Batch Acc: 79.69
[Train] Epoch: 1 [576384/620022]    Loss: 0.008330   Batch Acc: 79.69
[Train] Epoch: 1 [576448/620022]    Loss: 0.008539   Batch Acc: 79.69
[Train] Epoch: 1 [576512/620022]    Loss: 0.009518   Batch Acc: 68.75
[Train] Epoch: 1 [576576/620022]    Loss: 0.009369   Batch Acc: 76.56
[Train] Epoch: 1 [576640/620022]    Loss: 0.009240   Batch Acc: 76.56
[Train] Epoch: 1 [576704/620022]    Loss: 0.009930   Batch Acc: 78.12
[Train] Epoch: 1 [576768/620022]    Loss: 0.007636   Batch Acc: 78.12
[Train] Epoch: 1 [576832/620022]    Loss: 0.007111   Batch Acc: 90.62
[Train] Epoch: 1 [576896/620022]    Loss: 0.008122   Batch Acc: 76.56
[Train] Epoch: 1 [576960/620022]    Loss: 0.006532   Batch Acc: 89.06
[Train] Epoch: 1 [577024/620022]    Loss: 0.007282   Batch Acc: 84.38
[Train] Epoch: 1 [577088/620022]    Loss: 0.006475   Batch Acc: 84.38
[Train] Epoch: 1 [577152/620022]    Loss: 0.008376   Batch Acc: 81.25
[Train] Epoch: 1 [577216/620022]    Loss: 0.007290   Batch Acc: 82.81
[Train] Epoch: 1 [577280/620022]    Loss: 0.006543   Batch Acc: 84.38
[Train] Epoch: 1 [577344/620022]    Loss: 0.009146   Batch Acc: 75.00
[Train] Epoch: 1 [577408/620022]    Loss: 0.008406   Batch Acc: 78.12
[Train] Epoch: 1 [577472/620022]    Loss: 0.007510   Batch Acc: 76.56
[Train] Epoch: 1 [577536/620022]    Loss: 0.008850   Batch Acc: 79.69
[Train] Epoch: 1 [577600/620022]    Loss: 0.009056   Batch Acc: 73.44
[Train] Epoch: 1 [577664/620022]    Loss: 0.006614   Batch Acc: 84.38
[Train] Epoch: 1 [577728/620022]    Loss: 0.009208   Batch Acc: 75.00
[Train] Epoch: 1 [577792/620022]    Loss: 0.010168   Batch Acc: 75.00
[Train] Epoch: 1 [577856/620022]    Loss: 0.009653   Batch Acc: 76.56
[Train] Epoch: 1 [577920/620022]    Loss: 0.011892   Batch Acc: 65.62
[Train] Epoch: 1 [577984/620022]    Loss: 0.009082   Batch Acc: 76.56
[Train] Epoch: 1 [578048/620022]    Loss: 0.010398   Batch Acc: 71.88
[Train] Epoch: 1 [578112/620022]    Loss: 0.010254   Batch Acc: 73.44
[Train] Epoch: 1 [578176/620022]    Loss: 0.008725   Batch Acc: 78.12
[Train] Epoch: 1 [578240/620022]    Loss: 0.007464   Batch Acc: 82.81
[Train] Epoch: 1 [578304/620022]    Loss: 0.009516   Batch Acc: 71.88
[Train] Epoch: 1 [578368/620022]    Loss: 0.007933   Batch Acc: 79.69
[Train] Epoch: 1 [578432/620022]    Loss: 0.008547   Batch Acc: 78.12
[Train] Epoch: 1 [578496/620022]    Loss: 0.011044   Batch Acc: 71.88
[Train] Epoch: 1 [578560/620022]    Loss: 0.011130   Batch Acc: 71.88
[Train] Epoch: 1 [578624/620022]    Loss: 0.008465   Batch Acc: 79.69
[Train] Epoch: 1 [578688/620022]    Loss: 0.005823   Batch Acc: 90.62
[Train] Epoch: 1 [578752/620022]    Loss: 0.008052   Batch Acc: 76.56
[Train] Epoch: 1 [578816/620022]    Loss: 0.008878   Batch Acc: 78.12
[Train] Epoch: 1 [578880/620022]    Loss: 0.006731   Batch Acc: 89.06
[Train] Epoch: 1 [578944/620022]    Loss: 0.010242   Batch Acc: 67.19
[Train] Epoch: 1 [579008/620022]    Loss: 0.009485   Batch Acc: 76.56
[Train] Epoch: 1 [579072/620022]    Loss: 0.009338   Batch Acc: 75.00
[Train] Epoch: 1 [579136/620022]    Loss: 0.010188   Batch Acc: 79.69
[Train] Epoch: 1 [579200/620022]    Loss: 0.006811   Batch Acc: 79.69
[Train] Epoch: 1 [579264/620022]    Loss: 0.008838   Batch Acc: 75.00
[Train] Epoch: 1 [579328/620022]    Loss: 0.009234   Batch Acc: 76.56
[Train] Epoch: 1 [579392/620022]    Loss: 0.011135   Batch Acc: 68.75
[Train] Epoch: 1 [579456/620022]    Loss: 0.007519   Batch Acc: 82.81
[Train] Epoch: 1 [579520/620022]    Loss: 0.010167   Batch Acc: 76.56
[Train] Epoch: 1 [579584/620022]    Loss: 0.008897   Batch Acc: 76.56
[Train] Epoch: 1 [579648/620022]    Loss: 0.009811   Batch Acc: 70.31
[Train] Epoch: 1 [579712/620022]    Loss: 0.008121   Batch Acc: 75.00
[Train] Epoch: 1 [579776/620022]    Loss: 0.007359   Batch Acc: 85.94
[Train] Epoch: 1 [579840/620022]    Loss: 0.009045   Batch Acc: 76.56
[Train] Epoch: 1 [579904/620022]    Loss: 0.007818   Batch Acc: 81.25
[Train] Epoch: 1 [579968/620022]    Loss: 0.008398   Batch Acc: 79.69
[Train] Epoch: 1 [580032/620022]    Loss: 0.009237   Batch Acc: 75.00
[Train] Epoch: 1 [580096/620022]    Loss: 0.009018   Batch Acc: 73.44
[Train] Epoch: 1 [580160/620022]    Loss: 0.007859   Batch Acc: 82.81
[Train] Epoch: 1 [580224/620022]    Loss: 0.007829   Batch Acc: 79.69
[Train] Epoch: 1 [580288/620022]    Loss: 0.011190   Batch Acc: 67.19
[Train] Epoch: 1 [580352/620022]    Loss: 0.009056   Batch Acc: 76.56
[Train] Epoch: 1 [580416/620022]    Loss: 0.007892   Batch Acc: 81.25
[Train] Epoch: 1 [580480/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 1 [580544/620022]    Loss: 0.008106   Batch Acc: 76.56
[Train] Epoch: 1 [580608/620022]    Loss: 0.012363   Batch Acc: 65.62
[Train] Epoch: 1 [580672/620022]    Loss: 0.008172   Batch Acc: 76.56
[Train] Epoch: 1 [580736/620022]    Loss: 0.007718   Batch Acc: 79.69
[Train] Epoch: 1 [580800/620022]    Loss: 0.009051   Batch Acc: 76.56
[Train] Epoch: 1 [580864/620022]    Loss: 0.008125   Batch Acc: 82.81
[Train] Epoch: 1 [580928/620022]    Loss: 0.008766   Batch Acc: 82.81
[Train] Epoch: 1 [580992/620022]    Loss: 0.011387   Batch Acc: 73.44
[Train] Epoch: 1 [581056/620022]    Loss: 0.007614   Batch Acc: 82.81
[Train] Epoch: 1 [581120/620022]    Loss: 0.008319   Batch Acc: 76.56
[Train] Epoch: 1 [581184/620022]    Loss: 0.010794   Batch Acc: 71.88
[Train] Epoch: 1 [581248/620022]    Loss: 0.008969   Batch Acc: 71.88
[Train] Epoch: 1 [581312/620022]    Loss: 0.008093   Batch Acc: 75.00
[Train] Epoch: 1 [581376/620022]    Loss: 0.006092   Batch Acc: 81.25
[Train] Epoch: 1 [581440/620022]    Loss: 0.009593   Batch Acc: 70.31
[Train] Epoch: 1 [581504/620022]    Loss: 0.006825   Batch Acc: 82.81
[Train] Epoch: 1 [581568/620022]    Loss: 0.006451   Batch Acc: 81.25
[Train] Epoch: 1 [581632/620022]    Loss: 0.009925   Batch Acc: 75.00
[Train] Epoch: 1 [581696/620022]    Loss: 0.009328   Batch Acc: 73.44
[Train] Epoch: 1 [581760/620022]    Loss: 0.007436   Batch Acc: 78.12
[Train] Epoch: 1 [581824/620022]    Loss: 0.009326   Batch Acc: 76.56
[Train] Epoch: 1 [581888/620022]    Loss: 0.009634   Batch Acc: 73.44
[Train] Epoch: 1 [581952/620022]    Loss: 0.008998   Batch Acc: 75.00
[Train] Epoch: 1 [582016/620022]    Loss: 0.008780   Batch Acc: 76.56
[Train] Epoch: 1 [582080/620022]    Loss: 0.009086   Batch Acc: 78.12
[Train] Epoch: 1 [582144/620022]    Loss: 0.010724   Batch Acc: 71.88
[Train] Epoch: 1 [582208/620022]    Loss: 0.007205   Batch Acc: 82.81
[Train] Epoch: 1 [582272/620022]    Loss: 0.007729   Batch Acc: 79.69
[Train] Epoch: 1 [582336/620022]    Loss: 0.008689   Batch Acc: 79.69
[Train] Epoch: 1 [582400/620022]    Loss: 0.009093   Batch Acc: 78.12
[Train] Epoch: 1 [582464/620022]    Loss: 0.008494   Batch Acc: 71.88
[Train] Epoch: 1 [582528/620022]    Loss: 0.007299   Batch Acc: 85.94
[Train] Epoch: 1 [582592/620022]    Loss: 0.009754   Batch Acc: 76.56
[Train] Epoch: 1 [582656/620022]    Loss: 0.008945   Batch Acc: 76.56
[Train] Epoch: 1 [582720/620022]    Loss: 0.006863   Batch Acc: 84.38
[Train] Epoch: 1 [582784/620022]    Loss: 0.008173   Batch Acc: 78.12
[Train] Epoch: 1 [582848/620022]    Loss: 0.007755   Batch Acc: 79.69
[Train] Epoch: 1 [582912/620022]    Loss: 0.007044   Batch Acc: 82.81
[Train] Epoch: 1 [582976/620022]    Loss: 0.006773   Batch Acc: 85.94
[Train] Epoch: 1 [583040/620022]    Loss: 0.008040   Batch Acc: 81.25
[Train] Epoch: 1 [583104/620022]    Loss: 0.007879   Batch Acc: 79.69
[Train] Epoch: 1 [583168/620022]    Loss: 0.008548   Batch Acc: 79.69
[Train] Epoch: 1 [583232/620022]    Loss: 0.009309   Batch Acc: 78.12
[Train] Epoch: 1 [583296/620022]    Loss: 0.006384   Batch Acc: 92.19
[Train] Epoch: 1 [583360/620022]    Loss: 0.009258   Batch Acc: 81.25
[Train] Epoch: 1 [583424/620022]    Loss: 0.010527   Batch Acc: 70.31
[Train] Epoch: 1 [583488/620022]    Loss: 0.008903   Batch Acc: 76.56
[Train] Epoch: 1 [583552/620022]    Loss: 0.007929   Batch Acc: 81.25
[Train] Epoch: 1 [583616/620022]    Loss: 0.010266   Batch Acc: 78.12
[Train] Epoch: 1 [583680/620022]    Loss: 0.011844   Batch Acc: 67.19
[Train] Epoch: 1 [583744/620022]    Loss: 0.008989   Batch Acc: 75.00
[Train] Epoch: 1 [583808/620022]    Loss: 0.008084   Batch Acc: 81.25
[Train] Epoch: 1 [583872/620022]    Loss: 0.009481   Batch Acc: 76.56
[Train] Epoch: 1 [583936/620022]    Loss: 0.009242   Batch Acc: 79.69
[Train] Epoch: 1 [584000/620022]    Loss: 0.007052   Batch Acc: 82.81
[Train] Epoch: 1 [584064/620022]    Loss: 0.008779   Batch Acc: 73.44
[Train] Epoch: 1 [584128/620022]    Loss: 0.006468   Batch Acc: 82.81
[Train] Epoch: 1 [584192/620022]    Loss: 0.007647   Batch Acc: 81.25
[Train] Epoch: 1 [584256/620022]    Loss: 0.008993   Batch Acc: 75.00
[Train] Epoch: 1 [584320/620022]    Loss: 0.009535   Batch Acc: 76.56
[Train] Epoch: 1 [584384/620022]    Loss: 0.007219   Batch Acc: 76.56
[Train] Epoch: 1 [584448/620022]    Loss: 0.010149   Batch Acc: 73.44
[Train] Epoch: 1 [584512/620022]    Loss: 0.007704   Batch Acc: 85.94
[Train] Epoch: 1 [584576/620022]    Loss: 0.008575   Batch Acc: 81.25
[Train] Epoch: 1 [584640/620022]    Loss: 0.006827   Batch Acc: 82.81
[Train] Epoch: 1 [584704/620022]    Loss: 0.007951   Batch Acc: 78.12
[Train] Epoch: 1 [584768/620022]    Loss: 0.008135   Batch Acc: 81.25
[Train] Epoch: 1 [584832/620022]    Loss: 0.008771   Batch Acc: 75.00
[Train] Epoch: 1 [584896/620022]    Loss: 0.010275   Batch Acc: 78.12
[Train] Epoch: 1 [584960/620022]    Loss: 0.009500   Batch Acc: 71.88
[Train] Epoch: 1 [585024/620022]    Loss: 0.008058   Batch Acc: 81.25
[Train] Epoch: 1 [585088/620022]    Loss: 0.008961   Batch Acc: 78.12
[Train] Epoch: 1 [585152/620022]    Loss: 0.010873   Batch Acc: 68.75
[Train] Epoch: 1 [585216/620022]    Loss: 0.010325   Batch Acc: 71.88
[Train] Epoch: 1 [585280/620022]    Loss: 0.009264   Batch Acc: 79.69
[Train] Epoch: 1 [585344/620022]    Loss: 0.009771   Batch Acc: 73.44
[Train] Epoch: 1 [585408/620022]    Loss: 0.007111   Batch Acc: 76.56
[Train] Epoch: 1 [585472/620022]    Loss: 0.008443   Batch Acc: 76.56
[Train] Epoch: 1 [585536/620022]    Loss: 0.007366   Batch Acc: 81.25
[Train] Epoch: 1 [585600/620022]    Loss: 0.007568   Batch Acc: 82.81
[Train] Epoch: 1 [585664/620022]    Loss: 0.007395   Batch Acc: 84.38
[Train] Epoch: 1 [585728/620022]    Loss: 0.010070   Batch Acc: 76.56
[Train] Epoch: 1 [585792/620022]    Loss: 0.006881   Batch Acc: 87.50
[Train] Epoch: 1 [585856/620022]    Loss: 0.008481   Batch Acc: 73.44
[Train] Epoch: 1 [585920/620022]    Loss: 0.007503   Batch Acc: 81.25
[Train] Epoch: 1 [585984/620022]    Loss: 0.008801   Batch Acc: 75.00
[Train] Epoch: 1 [586048/620022]    Loss: 0.008461   Batch Acc: 81.25
[Train] Epoch: 1 [586112/620022]    Loss: 0.006272   Batch Acc: 84.38
[Train] Epoch: 1 [586176/620022]    Loss: 0.007963   Batch Acc: 79.69
[Train] Epoch: 1 [586240/620022]    Loss: 0.008887   Batch Acc: 78.12
[Train] Epoch: 1 [586304/620022]    Loss: 0.007287   Batch Acc: 84.38
[Train] Epoch: 1 [586368/620022]    Loss: 0.009433   Batch Acc: 79.69
[Train] Epoch: 1 [586432/620022]    Loss: 0.008082   Batch Acc: 79.69
[Train] Epoch: 1 [586496/620022]    Loss: 0.007701   Batch Acc: 85.94
[Train] Epoch: 1 [586560/620022]    Loss: 0.010624   Batch Acc: 67.19
[Train] Epoch: 1 [586624/620022]    Loss: 0.009546   Batch Acc: 78.12
[Train] Epoch: 1 [586688/620022]    Loss: 0.008299   Batch Acc: 82.81
[Train] Epoch: 1 [586752/620022]    Loss: 0.009131   Batch Acc: 78.12
[Train] Epoch: 1 [586816/620022]    Loss: 0.007613   Batch Acc: 79.69
[Train] Epoch: 1 [586880/620022]    Loss: 0.008948   Batch Acc: 75.00
[Train] Epoch: 1 [586944/620022]    Loss: 0.005749   Batch Acc: 85.94
[Train] Epoch: 1 [587008/620022]    Loss: 0.007912   Batch Acc: 81.25
[Train] Epoch: 1 [587072/620022]    Loss: 0.010045   Batch Acc: 75.00
[Train] Epoch: 1 [587136/620022]    Loss: 0.009201   Batch Acc: 75.00
[Train] Epoch: 1 [587200/620022]    Loss: 0.008898   Batch Acc: 70.31
[Train] Epoch: 1 [587264/620022]    Loss: 0.008245   Batch Acc: 78.12
[Train] Epoch: 1 [587328/620022]    Loss: 0.008441   Batch Acc: 76.56
[Train] Epoch: 1 [587392/620022]    Loss: 0.007799   Batch Acc: 79.69
[Train] Epoch: 1 [587456/620022]    Loss: 0.008967   Batch Acc: 76.56
[Train] Epoch: 1 [587520/620022]    Loss: 0.008430   Batch Acc: 81.25
[Train] Epoch: 1 [587584/620022]    Loss: 0.009744   Batch Acc: 76.56
[Train] Epoch: 1 [587648/620022]    Loss: 0.008186   Batch Acc: 85.94
[Train] Epoch: 1 [587712/620022]    Loss: 0.008784   Batch Acc: 78.12
[Train] Epoch: 1 [587776/620022]    Loss: 0.008417   Batch Acc: 82.81
[Train] Epoch: 1 [587840/620022]    Loss: 0.009372   Batch Acc: 75.00
[Train] Epoch: 1 [587904/620022]    Loss: 0.008254   Batch Acc: 81.25
[Train] Epoch: 1 [587968/620022]    Loss: 0.009150   Batch Acc: 71.88
[Train] Epoch: 1 [588032/620022]    Loss: 0.005571   Batch Acc: 87.50
[Train] Epoch: 1 [588096/620022]    Loss: 0.009181   Batch Acc: 82.81
[Train] Epoch: 1 [588160/620022]    Loss: 0.006761   Batch Acc: 84.38
[Train] Epoch: 1 [588224/620022]    Loss: 0.008380   Batch Acc: 76.56
[Train] Epoch: 1 [588288/620022]    Loss: 0.008454   Batch Acc: 78.12
[Train] Epoch: 1 [588352/620022]    Loss: 0.007011   Batch Acc: 82.81
[Train] Epoch: 1 [588416/620022]    Loss: 0.008988   Batch Acc: 73.44
[Train] Epoch: 1 [588480/620022]    Loss: 0.009788   Batch Acc: 70.31
[Train] Epoch: 1 [588544/620022]    Loss: 0.007855   Batch Acc: 84.38
[Train] Epoch: 1 [588608/620022]    Loss: 0.008499   Batch Acc: 81.25
[Train] Epoch: 1 [588672/620022]    Loss: 0.009354   Batch Acc: 75.00
[Train] Epoch: 1 [588736/620022]    Loss: 0.007581   Batch Acc: 81.25
[Train] Epoch: 1 [588800/620022]    Loss: 0.008029   Batch Acc: 81.25
[Train] Epoch: 1 [588864/620022]    Loss: 0.009152   Batch Acc: 73.44
[Train] Epoch: 1 [588928/620022]    Loss: 0.008893   Batch Acc: 73.44
[Train] Epoch: 1 [588992/620022]    Loss: 0.010983   Batch Acc: 68.75
[Train] Epoch: 1 [589056/620022]    Loss: 0.009903   Batch Acc: 75.00
[Train] Epoch: 1 [589120/620022]    Loss: 0.010538   Batch Acc: 70.31
[Train] Epoch: 1 [589184/620022]    Loss: 0.009871   Batch Acc: 75.00
[Train] Epoch: 1 [589248/620022]    Loss: 0.007167   Batch Acc: 81.25
[Train] Epoch: 1 [589312/620022]    Loss: 0.006944   Batch Acc: 84.38
[Train] Epoch: 1 [589376/620022]    Loss: 0.008106   Batch Acc: 79.69
[Train] Epoch: 1 [589440/620022]    Loss: 0.007547   Batch Acc: 87.50
[Train] Epoch: 1 [589504/620022]    Loss: 0.008595   Batch Acc: 78.12
[Train] Epoch: 1 [589568/620022]    Loss: 0.009802   Batch Acc: 76.56
[Train] Epoch: 1 [589632/620022]    Loss: 0.009028   Batch Acc: 76.56
[Train] Epoch: 1 [589696/620022]    Loss: 0.008862   Batch Acc: 78.12
[Train] Epoch: 1 [589760/620022]    Loss: 0.008275   Batch Acc: 79.69
[Train] Epoch: 1 [589824/620022]    Loss: 0.008537   Batch Acc: 78.12
[Train] Epoch: 1 [589888/620022]    Loss: 0.009861   Batch Acc: 71.88
[Train] Epoch: 1 [589952/620022]    Loss: 0.006921   Batch Acc: 81.25
[Train] Epoch: 1 [590016/620022]    Loss: 0.008757   Batch Acc: 79.69
[Train] Epoch: 1 [590080/620022]    Loss: 0.009309   Batch Acc: 79.69
[Train] Epoch: 1 [590144/620022]    Loss: 0.008686   Batch Acc: 75.00
[Train] Epoch: 1 [590208/620022]    Loss: 0.009093   Batch Acc: 73.44
[Train] Epoch: 1 [590272/620022]    Loss: 0.009714   Batch Acc: 78.12
[Train] Epoch: 1 [590336/620022]    Loss: 0.007496   Batch Acc: 89.06
[Train] Epoch: 1 [590400/620022]    Loss: 0.010966   Batch Acc: 65.62
[Train] Epoch: 1 [590464/620022]    Loss: 0.007941   Batch Acc: 78.12
[Train] Epoch: 1 [590528/620022]    Loss: 0.009820   Batch Acc: 76.56
[Train] Epoch: 1 [590592/620022]    Loss: 0.009299   Batch Acc: 75.00
[Train] Epoch: 1 [590656/620022]    Loss: 0.007292   Batch Acc: 79.69
[Train] Epoch: 1 [590720/620022]    Loss: 0.009427   Batch Acc: 70.31
[Train] Epoch: 1 [590784/620022]    Loss: 0.008661   Batch Acc: 79.69
[Train] Epoch: 1 [590848/620022]    Loss: 0.007544   Batch Acc: 79.69
[Train] Epoch: 1 [590912/620022]    Loss: 0.009215   Batch Acc: 79.69
[Train] Epoch: 1 [590976/620022]    Loss: 0.009243   Batch Acc: 76.56
[Train] Epoch: 1 [591040/620022]    Loss: 0.008533   Batch Acc: 79.69
[Train] Epoch: 1 [591104/620022]    Loss: 0.008377   Batch Acc: 79.69
[Train] Epoch: 1 [591168/620022]    Loss: 0.008680   Batch Acc: 75.00
[Train] Epoch: 1 [591232/620022]    Loss: 0.006911   Batch Acc: 82.81
[Train] Epoch: 1 [591296/620022]    Loss: 0.007408   Batch Acc: 85.94
[Train] Epoch: 1 [591360/620022]    Loss: 0.007316   Batch Acc: 79.69
[Train] Epoch: 1 [591424/620022]    Loss: 0.008256   Batch Acc: 76.56
[Train] Epoch: 1 [591488/620022]    Loss: 0.009998   Batch Acc: 73.44
[Train] Epoch: 1 [591552/620022]    Loss: 0.007388   Batch Acc: 82.81
[Train] Epoch: 1 [591616/620022]    Loss: 0.008195   Batch Acc: 82.81
[Train] Epoch: 1 [591680/620022]    Loss: 0.006589   Batch Acc: 82.81
[Train] Epoch: 1 [591744/620022]    Loss: 0.008904   Batch Acc: 76.56
[Train] Epoch: 1 [591808/620022]    Loss: 0.010283   Batch Acc: 75.00
[Train] Epoch: 1 [591872/620022]    Loss: 0.012003   Batch Acc: 75.00
[Train] Epoch: 1 [591936/620022]    Loss: 0.009074   Batch Acc: 79.69
[Train] Epoch: 1 [592000/620022]    Loss: 0.007550   Batch Acc: 79.69
[Train] Epoch: 1 [592064/620022]    Loss: 0.009244   Batch Acc: 76.56
[Train] Epoch: 1 [592128/620022]    Loss: 0.009516   Batch Acc: 79.69
[Train] Epoch: 1 [592192/620022]    Loss: 0.010976   Batch Acc: 64.06
[Train] Epoch: 1 [592256/620022]    Loss: 0.007394   Batch Acc: 84.38
[Train] Epoch: 1 [592320/620022]    Loss: 0.008752   Batch Acc: 79.69
[Train] Epoch: 1 [592384/620022]    Loss: 0.006987   Batch Acc: 89.06
[Train] Epoch: 1 [592448/620022]    Loss: 0.009400   Batch Acc: 76.56
[Train] Epoch: 1 [592512/620022]    Loss: 0.009552   Batch Acc: 75.00
[Train] Epoch: 1 [592576/620022]    Loss: 0.010065   Batch Acc: 81.25
[Train] Epoch: 1 [592640/620022]    Loss: 0.008892   Batch Acc: 71.88
[Train] Epoch: 1 [592704/620022]    Loss: 0.007725   Batch Acc: 81.25
[Train] Epoch: 1 [592768/620022]    Loss: 0.009128   Batch Acc: 76.56
[Train] Epoch: 1 [592832/620022]    Loss: 0.007081   Batch Acc: 84.38
[Train] Epoch: 1 [592896/620022]    Loss: 0.008725   Batch Acc: 75.00
[Train] Epoch: 1 [592960/620022]    Loss: 0.010864   Batch Acc: 73.44
[Train] Epoch: 1 [593024/620022]    Loss: 0.007007   Batch Acc: 82.81
[Train] Epoch: 1 [593088/620022]    Loss: 0.008932   Batch Acc: 75.00
[Train] Epoch: 1 [593152/620022]    Loss: 0.007994   Batch Acc: 82.81
[Train] Epoch: 1 [593216/620022]    Loss: 0.007886   Batch Acc: 78.12
[Train] Epoch: 1 [593280/620022]    Loss: 0.007864   Batch Acc: 82.81
[Train] Epoch: 1 [593344/620022]    Loss: 0.006997   Batch Acc: 82.81
[Train] Epoch: 1 [593408/620022]    Loss: 0.009889   Batch Acc: 76.56
[Train] Epoch: 1 [593472/620022]    Loss: 0.012360   Batch Acc: 64.06
[Train] Epoch: 1 [593536/620022]    Loss: 0.008513   Batch Acc: 73.44
[Train] Epoch: 1 [593600/620022]    Loss: 0.007995   Batch Acc: 78.12
[Train] Epoch: 1 [593664/620022]    Loss: 0.009298   Batch Acc: 76.56
[Train] Epoch: 1 [593728/620022]    Loss: 0.007857   Batch Acc: 79.69
[Train] Epoch: 1 [593792/620022]    Loss: 0.007824   Batch Acc: 79.69
[Train] Epoch: 1 [593856/620022]    Loss: 0.007640   Batch Acc: 82.81
[Train] Epoch: 1 [593920/620022]    Loss: 0.009668   Batch Acc: 71.88
[Train] Epoch: 1 [593984/620022]    Loss: 0.009191   Batch Acc: 73.44
[Train] Epoch: 1 [594048/620022]    Loss: 0.009050   Batch Acc: 81.25
[Train] Epoch: 1 [594112/620022]    Loss: 0.008716   Batch Acc: 78.12
[Train] Epoch: 1 [594176/620022]    Loss: 0.007513   Batch Acc: 78.12
[Train] Epoch: 1 [594240/620022]    Loss: 0.007969   Batch Acc: 79.69
[Train] Epoch: 1 [594304/620022]    Loss: 0.007800   Batch Acc: 79.69
[Train] Epoch: 1 [594368/620022]    Loss: 0.010716   Batch Acc: 68.75
[Train] Epoch: 1 [594432/620022]    Loss: 0.007705   Batch Acc: 84.38
[Train] Epoch: 1 [594496/620022]    Loss: 0.009445   Batch Acc: 75.00
[Train] Epoch: 1 [594560/620022]    Loss: 0.007073   Batch Acc: 84.38
[Train] Epoch: 1 [594624/620022]    Loss: 0.008307   Batch Acc: 81.25
[Train] Epoch: 1 [594688/620022]    Loss: 0.008144   Batch Acc: 82.81
[Train] Epoch: 1 [594752/620022]    Loss: 0.010270   Batch Acc: 68.75
[Train] Epoch: 1 [594816/620022]    Loss: 0.009035   Batch Acc: 79.69
[Train] Epoch: 1 [594880/620022]    Loss: 0.008192   Batch Acc: 85.94
[Train] Epoch: 1 [594944/620022]    Loss: 0.009473   Batch Acc: 71.88
[Train] Epoch: 1 [595008/620022]    Loss: 0.007747   Batch Acc: 81.25
[Train] Epoch: 1 [595072/620022]    Loss: 0.009446   Batch Acc: 76.56
[Train] Epoch: 1 [595136/620022]    Loss: 0.008500   Batch Acc: 79.69
[Train] Epoch: 1 [595200/620022]    Loss: 0.009149   Batch Acc: 78.12
[Train] Epoch: 1 [595264/620022]    Loss: 0.009369   Batch Acc: 81.25
[Train] Epoch: 1 [595328/620022]    Loss: 0.010860   Batch Acc: 75.00
[Train] Epoch: 1 [595392/620022]    Loss: 0.008500   Batch Acc: 76.56
[Train] Epoch: 1 [595456/620022]    Loss: 0.007060   Batch Acc: 84.38
[Train] Epoch: 1 [595520/620022]    Loss: 0.007493   Batch Acc: 84.38
[Train] Epoch: 1 [595584/620022]    Loss: 0.009002   Batch Acc: 79.69
[Train] Epoch: 1 [595648/620022]    Loss: 0.007874   Batch Acc: 81.25
[Train] Epoch: 1 [595712/620022]    Loss: 0.007791   Batch Acc: 76.56
[Train] Epoch: 1 [595776/620022]    Loss: 0.009594   Batch Acc: 70.31
[Train] Epoch: 1 [595840/620022]    Loss: 0.007640   Batch Acc: 84.38
[Train] Epoch: 1 [595904/620022]    Loss: 0.009214   Batch Acc: 73.44
[Train] Epoch: 1 [595968/620022]    Loss: 0.012859   Batch Acc: 65.62
[Train] Epoch: 1 [596032/620022]    Loss: 0.008143   Batch Acc: 78.12
[Train] Epoch: 1 [596096/620022]    Loss: 0.006936   Batch Acc: 87.50
[Train] Epoch: 1 [596160/620022]    Loss: 0.010593   Batch Acc: 70.31
[Train] Epoch: 1 [596224/620022]    Loss: 0.010808   Batch Acc: 75.00
[Train] Epoch: 1 [596288/620022]    Loss: 0.007907   Batch Acc: 81.25
[Train] Epoch: 1 [596352/620022]    Loss: 0.007307   Batch Acc: 85.94
[Train] Epoch: 1 [596416/620022]    Loss: 0.008736   Batch Acc: 73.44
[Train] Epoch: 1 [596480/620022]    Loss: 0.007503   Batch Acc: 84.38
[Train] Epoch: 1 [596544/620022]    Loss: 0.007207   Batch Acc: 79.69
[Train] Epoch: 1 [596608/620022]    Loss: 0.008089   Batch Acc: 79.69
[Train] Epoch: 1 [596672/620022]    Loss: 0.006299   Batch Acc: 82.81
[Train] Epoch: 1 [596736/620022]    Loss: 0.008088   Batch Acc: 79.69
[Train] Epoch: 1 [596800/620022]    Loss: 0.007509   Batch Acc: 84.38
[Train] Epoch: 1 [596864/620022]    Loss: 0.006746   Batch Acc: 81.25
[Train] Epoch: 1 [596928/620022]    Loss: 0.007418   Batch Acc: 82.81
[Train] Epoch: 1 [596992/620022]    Loss: 0.008010   Batch Acc: 81.25
[Train] Epoch: 1 [597056/620022]    Loss: 0.009573   Batch Acc: 70.31
[Train] Epoch: 1 [597120/620022]    Loss: 0.009625   Batch Acc: 76.56
[Train] Epoch: 1 [597184/620022]    Loss: 0.009393   Batch Acc: 76.56
[Train] Epoch: 1 [597248/620022]    Loss: 0.009494   Batch Acc: 76.56
[Train] Epoch: 1 [597312/620022]    Loss: 0.007477   Batch Acc: 85.94
[Train] Epoch: 1 [597376/620022]    Loss: 0.009638   Batch Acc: 79.69
[Train] Epoch: 1 [597440/620022]    Loss: 0.010220   Batch Acc: 75.00
[Train] Epoch: 1 [597504/620022]    Loss: 0.008018   Batch Acc: 79.69
[Train] Epoch: 1 [597568/620022]    Loss: 0.009706   Batch Acc: 71.88
[Train] Epoch: 1 [597632/620022]    Loss: 0.009014   Batch Acc: 75.00
[Train] Epoch: 1 [597696/620022]    Loss: 0.007560   Batch Acc: 84.38
[Train] Epoch: 1 [597760/620022]    Loss: 0.010050   Batch Acc: 71.88
[Train] Epoch: 1 [597824/620022]    Loss: 0.008144   Batch Acc: 76.56
[Train] Epoch: 1 [597888/620022]    Loss: 0.008318   Batch Acc: 79.69
[Train] Epoch: 1 [597952/620022]    Loss: 0.010203   Batch Acc: 75.00
[Train] Epoch: 1 [598016/620022]    Loss: 0.008737   Batch Acc: 81.25
[Train] Epoch: 1 [598080/620022]    Loss: 0.010412   Batch Acc: 71.88
[Train] Epoch: 1 [598144/620022]    Loss: 0.007435   Batch Acc: 78.12
[Train] Epoch: 1 [598208/620022]    Loss: 0.008985   Batch Acc: 73.44
[Train] Epoch: 1 [598272/620022]    Loss: 0.008852   Batch Acc: 70.31
[Train] Epoch: 1 [598336/620022]    Loss: 0.007812   Batch Acc: 81.25
[Train] Epoch: 1 [598400/620022]    Loss: 0.008418   Batch Acc: 79.69
[Train] Epoch: 1 [598464/620022]    Loss: 0.009392   Batch Acc: 79.69
[Train] Epoch: 1 [598528/620022]    Loss: 0.007716   Batch Acc: 85.94
[Train] Epoch: 1 [598592/620022]    Loss: 0.009860   Batch Acc: 73.44
[Train] Epoch: 1 [598656/620022]    Loss: 0.008478   Batch Acc: 79.69
[Train] Epoch: 1 [598720/620022]    Loss: 0.006976   Batch Acc: 85.94
[Train] Epoch: 1 [598784/620022]    Loss: 0.008119   Batch Acc: 75.00
[Train] Epoch: 1 [598848/620022]    Loss: 0.008490   Batch Acc: 79.69
[Train] Epoch: 1 [598912/620022]    Loss: 0.009709   Batch Acc: 76.56
[Train] Epoch: 1 [598976/620022]    Loss: 0.009356   Batch Acc: 82.81
[Train] Epoch: 1 [599040/620022]    Loss: 0.008192   Batch Acc: 82.81
[Train] Epoch: 1 [599104/620022]    Loss: 0.008712   Batch Acc: 75.00
[Train] Epoch: 1 [599168/620022]    Loss: 0.010353   Batch Acc: 71.88
[Train] Epoch: 1 [599232/620022]    Loss: 0.010205   Batch Acc: 68.75
[Train] Epoch: 1 [599296/620022]    Loss: 0.008051   Batch Acc: 85.94
[Train] Epoch: 1 [599360/620022]    Loss: 0.008471   Batch Acc: 79.69
[Train] Epoch: 1 [599424/620022]    Loss: 0.006455   Batch Acc: 85.94
[Train] Epoch: 1 [599488/620022]    Loss: 0.009106   Batch Acc: 75.00
[Train] Epoch: 1 [599552/620022]    Loss: 0.009396   Batch Acc: 73.44
[Train] Epoch: 1 [599616/620022]    Loss: 0.009445   Batch Acc: 75.00
[Train] Epoch: 1 [599680/620022]    Loss: 0.008370   Batch Acc: 82.81
[Train] Epoch: 1 [599744/620022]    Loss: 0.009762   Batch Acc: 70.31
[Train] Epoch: 1 [599808/620022]    Loss: 0.008205   Batch Acc: 79.69
[Train] Epoch: 1 [599872/620022]    Loss: 0.009260   Batch Acc: 75.00
[Train] Epoch: 1 [599936/620022]    Loss: 0.009090   Batch Acc: 82.81
[Train] Epoch: 1 [600000/620022]    Loss: 0.009364   Batch Acc: 70.31
[Train] Epoch: 1 [600064/620022]    Loss: 0.009814   Batch Acc: 75.00
[Train] Epoch: 1 [600128/620022]    Loss: 0.009890   Batch Acc: 76.56
[Train] Epoch: 1 [600192/620022]    Loss: 0.007434   Batch Acc: 81.25
[Train] Epoch: 1 [600256/620022]    Loss: 0.007984   Batch Acc: 76.56
[Train] Epoch: 1 [600320/620022]    Loss: 0.010104   Batch Acc: 73.44
[Train] Epoch: 1 [600384/620022]    Loss: 0.006877   Batch Acc: 84.38
[Train] Epoch: 1 [600448/620022]    Loss: 0.009808   Batch Acc: 71.88
[Train] Epoch: 1 [600512/620022]    Loss: 0.010114   Batch Acc: 75.00
[Train] Epoch: 1 [600576/620022]    Loss: 0.008057   Batch Acc: 78.12
[Train] Epoch: 1 [600640/620022]    Loss: 0.009571   Batch Acc: 73.44
[Train] Epoch: 1 [600704/620022]    Loss: 0.011925   Batch Acc: 65.62
[Train] Epoch: 1 [600768/620022]    Loss: 0.010326   Batch Acc: 75.00
[Train] Epoch: 1 [600832/620022]    Loss: 0.008454   Batch Acc: 79.69
[Train] Epoch: 1 [600896/620022]    Loss: 0.008601   Batch Acc: 78.12
[Train] Epoch: 1 [600960/620022]    Loss: 0.010144   Batch Acc: 73.44
[Train] Epoch: 1 [601024/620022]    Loss: 0.008061   Batch Acc: 76.56
[Train] Epoch: 1 [601088/620022]    Loss: 0.007920   Batch Acc: 82.81
[Train] Epoch: 1 [601152/620022]    Loss: 0.009006   Batch Acc: 76.56
[Train] Epoch: 1 [601216/620022]    Loss: 0.008362   Batch Acc: 78.12
[Train] Epoch: 1 [601280/620022]    Loss: 0.007254   Batch Acc: 82.81
[Train] Epoch: 1 [601344/620022]    Loss: 0.008288   Batch Acc: 76.56
[Train] Epoch: 1 [601408/620022]    Loss: 0.008544   Batch Acc: 71.88
[Train] Epoch: 1 [601472/620022]    Loss: 0.009335   Batch Acc: 78.12
[Train] Epoch: 1 [601536/620022]    Loss: 0.008449   Batch Acc: 79.69
[Train] Epoch: 1 [601600/620022]    Loss: 0.011280   Batch Acc: 70.31
[Train] Epoch: 1 [601664/620022]    Loss: 0.008335   Batch Acc: 81.25
[Train] Epoch: 1 [601728/620022]    Loss: 0.007276   Batch Acc: 81.25
[Train] Epoch: 1 [601792/620022]    Loss: 0.007416   Batch Acc: 85.94
[Train] Epoch: 1 [601856/620022]    Loss: 0.007444   Batch Acc: 82.81
[Train] Epoch: 1 [601920/620022]    Loss: 0.008012   Batch Acc: 75.00
[Train] Epoch: 1 [601984/620022]    Loss: 0.008764   Batch Acc: 79.69
[Train] Epoch: 1 [602048/620022]    Loss: 0.008779   Batch Acc: 73.44
[Train] Epoch: 1 [602112/620022]    Loss: 0.009066   Batch Acc: 75.00
[Train] Epoch: 1 [602176/620022]    Loss: 0.007619   Batch Acc: 82.81
[Train] Epoch: 1 [602240/620022]    Loss: 0.007320   Batch Acc: 79.69
[Train] Epoch: 1 [602304/620022]    Loss: 0.008176   Batch Acc: 85.94
[Train] Epoch: 1 [602368/620022]    Loss: 0.009584   Batch Acc: 75.00
[Train] Epoch: 1 [602432/620022]    Loss: 0.011335   Batch Acc: 67.19
[Train] Epoch: 1 [602496/620022]    Loss: 0.010464   Batch Acc: 79.69
[Train] Epoch: 1 [602560/620022]    Loss: 0.010093   Batch Acc: 76.56
[Train] Epoch: 1 [602624/620022]    Loss: 0.008145   Batch Acc: 81.25
[Train] Epoch: 1 [602688/620022]    Loss: 0.007598   Batch Acc: 81.25
[Train] Epoch: 1 [602752/620022]    Loss: 0.009501   Batch Acc: 78.12
[Train] Epoch: 1 [602816/620022]    Loss: 0.008334   Batch Acc: 82.81
[Train] Epoch: 1 [602880/620022]    Loss: 0.008082   Batch Acc: 73.44
[Train] Epoch: 1 [602944/620022]    Loss: 0.007420   Batch Acc: 82.81
[Train] Epoch: 1 [603008/620022]    Loss: 0.009907   Batch Acc: 70.31
[Train] Epoch: 1 [603072/620022]    Loss: 0.007541   Batch Acc: 78.12
[Train] Epoch: 1 [603136/620022]    Loss: 0.010418   Batch Acc: 67.19
[Train] Epoch: 1 [603200/620022]    Loss: 0.010579   Batch Acc: 71.88
[Train] Epoch: 1 [603264/620022]    Loss: 0.008204   Batch Acc: 85.94
[Train] Epoch: 1 [603328/620022]    Loss: 0.008436   Batch Acc: 76.56
[Train] Epoch: 1 [603392/620022]    Loss: 0.010136   Batch Acc: 73.44
[Train] Epoch: 1 [603456/620022]    Loss: 0.007816   Batch Acc: 84.38
[Train] Epoch: 1 [603520/620022]    Loss: 0.010659   Batch Acc: 76.56
[Train] Epoch: 1 [603584/620022]    Loss: 0.007005   Batch Acc: 89.06
[Train] Epoch: 1 [603648/620022]    Loss: 0.008366   Batch Acc: 82.81
[Train] Epoch: 1 [603712/620022]    Loss: 0.007512   Batch Acc: 78.12
[Train] Epoch: 1 [603776/620022]    Loss: 0.009718   Batch Acc: 78.12
[Train] Epoch: 1 [603840/620022]    Loss: 0.011199   Batch Acc: 70.31
[Train] Epoch: 1 [603904/620022]    Loss: 0.007196   Batch Acc: 87.50
[Train] Epoch: 1 [603968/620022]    Loss: 0.009188   Batch Acc: 75.00
[Train] Epoch: 1 [604032/620022]    Loss: 0.006822   Batch Acc: 85.94
[Train] Epoch: 1 [604096/620022]    Loss: 0.009540   Batch Acc: 68.75
[Train] Epoch: 1 [604160/620022]    Loss: 0.010388   Batch Acc: 71.88
[Train] Epoch: 1 [604224/620022]    Loss: 0.009241   Batch Acc: 75.00
[Train] Epoch: 1 [604288/620022]    Loss: 0.009087   Batch Acc: 75.00
[Train] Epoch: 1 [604352/620022]    Loss: 0.008614   Batch Acc: 73.44
[Train] Epoch: 1 [604416/620022]    Loss: 0.008184   Batch Acc: 79.69
[Train] Epoch: 1 [604480/620022]    Loss: 0.009683   Batch Acc: 78.12
[Train] Epoch: 1 [604544/620022]    Loss: 0.008730   Batch Acc: 75.00
[Train] Epoch: 1 [604608/620022]    Loss: 0.008423   Batch Acc: 78.12
[Train] Epoch: 1 [604672/620022]    Loss: 0.008484   Batch Acc: 82.81
[Train] Epoch: 1 [604736/620022]    Loss: 0.008854   Batch Acc: 76.56
[Train] Epoch: 1 [604800/620022]    Loss: 0.011868   Batch Acc: 64.06
[Train] Epoch: 1 [604864/620022]    Loss: 0.006740   Batch Acc: 85.94
[Train] Epoch: 1 [604928/620022]    Loss: 0.010165   Batch Acc: 75.00
[Train] Epoch: 1 [604992/620022]    Loss: 0.009046   Batch Acc: 76.56
[Train] Epoch: 1 [605056/620022]    Loss: 0.007920   Batch Acc: 75.00
[Train] Epoch: 1 [605120/620022]    Loss: 0.010501   Batch Acc: 68.75
[Train] Epoch: 1 [605184/620022]    Loss: 0.006819   Batch Acc: 82.81
[Train] Epoch: 1 [605248/620022]    Loss: 0.007568   Batch Acc: 81.25
[Train] Epoch: 1 [605312/620022]    Loss: 0.008900   Batch Acc: 76.56
[Train] Epoch: 1 [605376/620022]    Loss: 0.007127   Batch Acc: 79.69
[Train] Epoch: 1 [605440/620022]    Loss: 0.010277   Batch Acc: 73.44
[Train] Epoch: 1 [605504/620022]    Loss: 0.006406   Batch Acc: 84.38
[Train] Epoch: 1 [605568/620022]    Loss: 0.008201   Batch Acc: 79.69
[Train] Epoch: 1 [605632/620022]    Loss: 0.009117   Batch Acc: 76.56
[Train] Epoch: 1 [605696/620022]    Loss: 0.008935   Batch Acc: 75.00
[Train] Epoch: 1 [605760/620022]    Loss: 0.009463   Batch Acc: 76.56
[Train] Epoch: 1 [605824/620022]    Loss: 0.010049   Batch Acc: 71.88
[Train] Epoch: 1 [605888/620022]    Loss: 0.009983   Batch Acc: 68.75
[Train] Epoch: 1 [605952/620022]    Loss: 0.011415   Batch Acc: 75.00
[Train] Epoch: 1 [606016/620022]    Loss: 0.007855   Batch Acc: 85.94
[Train] Epoch: 1 [606080/620022]    Loss: 0.009275   Batch Acc: 70.31
[Train] Epoch: 1 [606144/620022]    Loss: 0.008021   Batch Acc: 82.81
[Train] Epoch: 1 [606208/620022]    Loss: 0.009353   Batch Acc: 76.56
[Train] Epoch: 1 [606272/620022]    Loss: 0.009574   Batch Acc: 76.56
[Train] Epoch: 1 [606336/620022]    Loss: 0.010492   Batch Acc: 75.00
[Train] Epoch: 1 [606400/620022]    Loss: 0.009513   Batch Acc: 76.56
[Train] Epoch: 1 [606464/620022]    Loss: 0.009175   Batch Acc: 79.69
[Train] Epoch: 1 [606528/620022]    Loss: 0.006882   Batch Acc: 84.38
[Train] Epoch: 1 [606592/620022]    Loss: 0.008732   Batch Acc: 76.56
[Train] Epoch: 1 [606656/620022]    Loss: 0.006806   Batch Acc: 85.94
[Train] Epoch: 1 [606720/620022]    Loss: 0.007522   Batch Acc: 78.12
[Train] Epoch: 1 [606784/620022]    Loss: 0.006728   Batch Acc: 82.81
[Train] Epoch: 1 [606848/620022]    Loss: 0.010038   Batch Acc: 75.00
[Train] Epoch: 1 [606912/620022]    Loss: 0.007589   Batch Acc: 78.12
[Train] Epoch: 1 [606976/620022]    Loss: 0.009928   Batch Acc: 76.56
[Train] Epoch: 1 [607040/620022]    Loss: 0.008855   Batch Acc: 76.56
[Train] Epoch: 1 [607104/620022]    Loss: 0.007274   Batch Acc: 82.81
[Train] Epoch: 1 [607168/620022]    Loss: 0.007035   Batch Acc: 82.81
[Train] Epoch: 1 [607232/620022]    Loss: 0.010132   Batch Acc: 78.12
[Train] Epoch: 1 [607296/620022]    Loss: 0.011631   Batch Acc: 70.31
[Train] Epoch: 1 [607360/620022]    Loss: 0.008281   Batch Acc: 82.81
[Train] Epoch: 1 [607424/620022]    Loss: 0.006508   Batch Acc: 78.12
[Train] Epoch: 1 [607488/620022]    Loss: 0.007438   Batch Acc: 78.12
[Train] Epoch: 1 [607552/620022]    Loss: 0.008040   Batch Acc: 78.12
[Train] Epoch: 1 [607616/620022]    Loss: 0.007841   Batch Acc: 85.94
[Train] Epoch: 1 [607680/620022]    Loss: 0.006632   Batch Acc: 87.50
[Train] Epoch: 1 [607744/620022]    Loss: 0.008868   Batch Acc: 79.69
[Train] Epoch: 1 [607808/620022]    Loss: 0.007838   Batch Acc: 75.00
[Train] Epoch: 1 [607872/620022]    Loss: 0.007381   Batch Acc: 87.50
[Train] Epoch: 1 [607936/620022]    Loss: 0.009821   Batch Acc: 78.12
[Train] Epoch: 1 [608000/620022]    Loss: 0.007508   Batch Acc: 85.94
[Train] Epoch: 1 [608064/620022]    Loss: 0.007804   Batch Acc: 85.94
[Train] Epoch: 1 [608128/620022]    Loss: 0.010091   Batch Acc: 73.44
[Train] Epoch: 1 [608192/620022]    Loss: 0.011622   Batch Acc: 73.44
[Train] Epoch: 1 [608256/620022]    Loss: 0.008360   Batch Acc: 73.44
[Train] Epoch: 1 [608320/620022]    Loss: 0.009260   Batch Acc: 71.88
[Train] Epoch: 1 [608384/620022]    Loss: 0.006985   Batch Acc: 85.94
[Train] Epoch: 1 [608448/620022]    Loss: 0.008621   Batch Acc: 78.12
[Train] Epoch: 1 [608512/620022]    Loss: 0.007484   Batch Acc: 79.69
[Train] Epoch: 1 [608576/620022]    Loss: 0.010274   Batch Acc: 75.00
[Train] Epoch: 1 [608640/620022]    Loss: 0.009747   Batch Acc: 75.00
[Train] Epoch: 1 [608704/620022]    Loss: 0.010167   Batch Acc: 75.00
[Train] Epoch: 1 [608768/620022]    Loss: 0.009575   Batch Acc: 73.44
[Train] Epoch: 1 [608832/620022]    Loss: 0.007485   Batch Acc: 82.81
[Train] Epoch: 1 [608896/620022]    Loss: 0.011100   Batch Acc: 70.31
[Train] Epoch: 1 [608960/620022]    Loss: 0.008363   Batch Acc: 79.69
[Train] Epoch: 1 [609024/620022]    Loss: 0.011236   Batch Acc: 71.88
[Train] Epoch: 1 [609088/620022]    Loss: 0.007592   Batch Acc: 78.12
[Train] Epoch: 1 [609152/620022]    Loss: 0.008542   Batch Acc: 76.56
[Train] Epoch: 1 [609216/620022]    Loss: 0.010434   Batch Acc: 73.44
[Train] Epoch: 1 [609280/620022]    Loss: 0.007001   Batch Acc: 84.38
[Train] Epoch: 1 [609344/620022]    Loss: 0.005799   Batch Acc: 85.94
[Train] Epoch: 1 [609408/620022]    Loss: 0.007570   Batch Acc: 84.38
[Train] Epoch: 1 [609472/620022]    Loss: 0.011169   Batch Acc: 60.94
[Train] Epoch: 1 [609536/620022]    Loss: 0.008631   Batch Acc: 79.69
[Train] Epoch: 1 [609600/620022]    Loss: 0.008460   Batch Acc: 81.25
[Train] Epoch: 1 [609664/620022]    Loss: 0.007375   Batch Acc: 79.69
[Train] Epoch: 1 [609728/620022]    Loss: 0.006537   Batch Acc: 87.50
[Train] Epoch: 1 [609792/620022]    Loss: 0.008101   Batch Acc: 78.12
[Train] Epoch: 1 [609856/620022]    Loss: 0.010313   Batch Acc: 71.88
[Train] Epoch: 1 [609920/620022]    Loss: 0.008002   Batch Acc: 79.69
[Train] Epoch: 1 [609984/620022]    Loss: 0.008811   Batch Acc: 68.75
[Train] Epoch: 1 [610048/620022]    Loss: 0.009123   Batch Acc: 75.00
[Train] Epoch: 1 [610112/620022]    Loss: 0.008168   Batch Acc: 82.81
[Train] Epoch: 1 [610176/620022]    Loss: 0.010793   Batch Acc: 75.00
[Train] Epoch: 1 [610240/620022]    Loss: 0.009777   Batch Acc: 73.44
[Train] Epoch: 1 [610304/620022]    Loss: 0.007677   Batch Acc: 76.56
[Train] Epoch: 1 [610368/620022]    Loss: 0.007847   Batch Acc: 79.69
[Train] Epoch: 1 [610432/620022]    Loss: 0.011369   Batch Acc: 67.19
[Train] Epoch: 1 [610496/620022]    Loss: 0.008114   Batch Acc: 78.12
[Train] Epoch: 1 [610560/620022]    Loss: 0.010552   Batch Acc: 73.44
[Train] Epoch: 1 [610624/620022]    Loss: 0.008275   Batch Acc: 79.69
[Train] Epoch: 1 [610688/620022]    Loss: 0.009048   Batch Acc: 79.69
[Train] Epoch: 1 [610752/620022]    Loss: 0.006714   Batch Acc: 85.94
[Train] Epoch: 1 [610816/620022]    Loss: 0.010710   Batch Acc: 68.75
[Train] Epoch: 1 [610880/620022]    Loss: 0.009214   Batch Acc: 79.69
[Train] Epoch: 1 [610944/620022]    Loss: 0.007000   Batch Acc: 84.38
[Train] Epoch: 1 [611008/620022]    Loss: 0.007453   Batch Acc: 82.81
[Train] Epoch: 1 [611072/620022]    Loss: 0.009519   Batch Acc: 75.00
[Train] Epoch: 1 [611136/620022]    Loss: 0.007990   Batch Acc: 79.69
[Train] Epoch: 1 [611200/620022]    Loss: 0.009948   Batch Acc: 78.12
[Train] Epoch: 1 [611264/620022]    Loss: 0.007977   Batch Acc: 82.81
[Train] Epoch: 1 [611328/620022]    Loss: 0.009753   Batch Acc: 70.31
[Train] Epoch: 1 [611392/620022]    Loss: 0.011227   Batch Acc: 67.19
[Train] Epoch: 1 [611456/620022]    Loss: 0.009270   Batch Acc: 73.44
[Train] Epoch: 1 [611520/620022]    Loss: 0.010162   Batch Acc: 79.69
[Train] Epoch: 1 [611584/620022]    Loss: 0.010371   Batch Acc: 73.44
[Train] Epoch: 1 [611648/620022]    Loss: 0.009109   Batch Acc: 82.81
[Train] Epoch: 1 [611712/620022]    Loss: 0.007566   Batch Acc: 81.25
[Train] Epoch: 1 [611776/620022]    Loss: 0.009678   Batch Acc: 76.56
[Train] Epoch: 1 [611840/620022]    Loss: 0.005424   Batch Acc: 87.50
[Train] Epoch: 1 [611904/620022]    Loss: 0.009134   Batch Acc: 76.56
[Train] Epoch: 1 [611968/620022]    Loss: 0.008655   Batch Acc: 79.69
[Train] Epoch: 1 [612032/620022]    Loss: 0.009002   Batch Acc: 71.88
[Train] Epoch: 1 [612096/620022]    Loss: 0.008530   Batch Acc: 81.25
[Train] Epoch: 1 [612160/620022]    Loss: 0.010222   Batch Acc: 78.12
[Train] Epoch: 1 [612224/620022]    Loss: 0.008543   Batch Acc: 76.56
[Train] Epoch: 1 [612288/620022]    Loss: 0.008644   Batch Acc: 82.81
[Train] Epoch: 1 [612352/620022]    Loss: 0.006571   Batch Acc: 84.38
[Train] Epoch: 1 [612416/620022]    Loss: 0.009446   Batch Acc: 78.12
[Train] Epoch: 1 [612480/620022]    Loss: 0.009136   Batch Acc: 73.44
[Train] Epoch: 1 [612544/620022]    Loss: 0.009095   Batch Acc: 76.56
[Train] Epoch: 1 [612608/620022]    Loss: 0.007861   Batch Acc: 81.25
[Train] Epoch: 1 [612672/620022]    Loss: 0.007987   Batch Acc: 76.56
[Train] Epoch: 1 [612736/620022]    Loss: 0.007739   Batch Acc: 84.38
[Train] Epoch: 1 [612800/620022]    Loss: 0.008949   Batch Acc: 81.25
[Train] Epoch: 1 [612864/620022]    Loss: 0.008615   Batch Acc: 76.56
[Train] Epoch: 1 [612928/620022]    Loss: 0.011100   Batch Acc: 70.31
[Train] Epoch: 1 [612992/620022]    Loss: 0.008266   Batch Acc: 81.25
[Train] Epoch: 1 [613056/620022]    Loss: 0.009050   Batch Acc: 70.31
[Train] Epoch: 1 [613120/620022]    Loss: 0.008682   Batch Acc: 75.00
[Train] Epoch: 1 [613184/620022]    Loss: 0.009337   Batch Acc: 75.00
[Train] Epoch: 1 [613248/620022]    Loss: 0.008945   Batch Acc: 73.44
[Train] Epoch: 1 [613312/620022]    Loss: 0.009593   Batch Acc: 78.12
[Train] Epoch: 1 [613376/620022]    Loss: 0.009742   Batch Acc: 75.00
[Train] Epoch: 1 [613440/620022]    Loss: 0.008767   Batch Acc: 81.25
[Train] Epoch: 1 [613504/620022]    Loss: 0.007531   Batch Acc: 81.25
[Train] Epoch: 1 [613568/620022]    Loss: 0.006833   Batch Acc: 84.38
[Train] Epoch: 1 [613632/620022]    Loss: 0.012146   Batch Acc: 65.62
[Train] Epoch: 1 [613696/620022]    Loss: 0.010177   Batch Acc: 70.31
[Train] Epoch: 1 [613760/620022]    Loss: 0.011424   Batch Acc: 68.75
[Train] Epoch: 1 [613824/620022]    Loss: 0.008197   Batch Acc: 81.25
[Train] Epoch: 1 [613888/620022]    Loss: 0.008152   Batch Acc: 81.25
[Train] Epoch: 1 [613952/620022]    Loss: 0.009695   Batch Acc: 67.19
[Train] Epoch: 1 [614016/620022]    Loss: 0.008515   Batch Acc: 79.69
[Train] Epoch: 1 [614080/620022]    Loss: 0.008194   Batch Acc: 79.69
[Train] Epoch: 1 [614144/620022]    Loss: 0.008444   Batch Acc: 81.25
[Train] Epoch: 1 [614208/620022]    Loss: 0.007596   Batch Acc: 76.56
[Train] Epoch: 1 [614272/620022]    Loss: 0.008425   Batch Acc: 73.44
[Train] Epoch: 1 [614336/620022]    Loss: 0.008798   Batch Acc: 82.81
[Train] Epoch: 1 [614400/620022]    Loss: 0.008773   Batch Acc: 78.12
[Train] Epoch: 1 [614464/620022]    Loss: 0.007241   Batch Acc: 82.81
[Train] Epoch: 1 [614528/620022]    Loss: 0.007734   Batch Acc: 82.81
[Train] Epoch: 1 [614592/620022]    Loss: 0.010061   Batch Acc: 68.75
[Train] Epoch: 1 [614656/620022]    Loss: 0.008432   Batch Acc: 76.56
[Train] Epoch: 1 [614720/620022]    Loss: 0.008583   Batch Acc: 78.12
[Train] Epoch: 1 [614784/620022]    Loss: 0.006135   Batch Acc: 87.50
[Train] Epoch: 1 [614848/620022]    Loss: 0.009659   Batch Acc: 81.25
[Train] Epoch: 1 [614912/620022]    Loss: 0.011197   Batch Acc: 70.31
[Train] Epoch: 1 [614976/620022]    Loss: 0.009004   Batch Acc: 70.31
[Train] Epoch: 1 [615040/620022]    Loss: 0.008195   Batch Acc: 79.69
[Train] Epoch: 1 [615104/620022]    Loss: 0.009113   Batch Acc: 68.75
[Train] Epoch: 1 [615168/620022]    Loss: 0.007202   Batch Acc: 89.06
[Train] Epoch: 1 [615232/620022]    Loss: 0.008272   Batch Acc: 76.56
[Train] Epoch: 1 [615296/620022]    Loss: 0.009932   Batch Acc: 73.44
[Train] Epoch: 1 [615360/620022]    Loss: 0.009624   Batch Acc: 71.88
[Train] Epoch: 1 [615424/620022]    Loss: 0.008196   Batch Acc: 84.38
[Train] Epoch: 1 [615488/620022]    Loss: 0.008085   Batch Acc: 82.81
[Train] Epoch: 1 [615552/620022]    Loss: 0.006605   Batch Acc: 84.38
[Train] Epoch: 1 [615616/620022]    Loss: 0.007503   Batch Acc: 81.25
[Train] Epoch: 1 [615680/620022]    Loss: 0.008245   Batch Acc: 75.00
[Train] Epoch: 1 [615744/620022]    Loss: 0.008792   Batch Acc: 76.56
[Train] Epoch: 1 [615808/620022]    Loss: 0.007951   Batch Acc: 81.25
[Train] Epoch: 1 [615872/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 1 [615936/620022]    Loss: 0.007322   Batch Acc: 85.94
[Train] Epoch: 1 [616000/620022]    Loss: 0.008572   Batch Acc: 73.44
[Train] Epoch: 1 [616064/620022]    Loss: 0.008018   Batch Acc: 79.69
[Train] Epoch: 1 [616128/620022]    Loss: 0.007738   Batch Acc: 78.12
[Train] Epoch: 1 [616192/620022]    Loss: 0.008885   Batch Acc: 82.81
[Train] Epoch: 1 [616256/620022]    Loss: 0.007760   Batch Acc: 79.69
[Train] Epoch: 1 [616320/620022]    Loss: 0.009721   Batch Acc: 75.00
[Train] Epoch: 1 [616384/620022]    Loss: 0.008368   Batch Acc: 75.00
[Train] Epoch: 1 [616448/620022]    Loss: 0.009297   Batch Acc: 73.44
[Train] Epoch: 1 [616512/620022]    Loss: 0.008623   Batch Acc: 75.00
[Train] Epoch: 1 [616576/620022]    Loss: 0.008346   Batch Acc: 85.94
[Train] Epoch: 1 [616640/620022]    Loss: 0.009356   Batch Acc: 78.12
[Train] Epoch: 1 [616704/620022]    Loss: 0.006877   Batch Acc: 81.25
[Train] Epoch: 1 [616768/620022]    Loss: 0.008242   Batch Acc: 78.12
[Train] Epoch: 1 [616832/620022]    Loss: 0.007346   Batch Acc: 84.38
[Train] Epoch: 1 [616896/620022]    Loss: 0.009406   Batch Acc: 78.12
[Train] Epoch: 1 [616960/620022]    Loss: 0.008269   Batch Acc: 81.25
[Train] Epoch: 1 [617024/620022]    Loss: 0.008504   Batch Acc: 79.69
[Train] Epoch: 1 [617088/620022]    Loss: 0.006600   Batch Acc: 84.38
[Train] Epoch: 1 [617152/620022]    Loss: 0.007075   Batch Acc: 81.25
[Train] Epoch: 1 [617216/620022]    Loss: 0.008712   Batch Acc: 79.69
[Train] Epoch: 1 [617280/620022]    Loss: 0.006947   Batch Acc: 81.25
[Train] Epoch: 1 [617344/620022]    Loss: 0.008832   Batch Acc: 78.12
[Train] Epoch: 1 [617408/620022]    Loss: 0.008861   Batch Acc: 76.56
[Train] Epoch: 1 [617472/620022]    Loss: 0.007945   Batch Acc: 76.56
[Train] Epoch: 1 [617536/620022]    Loss: 0.006718   Batch Acc: 84.38
[Train] Epoch: 1 [617600/620022]    Loss: 0.007675   Batch Acc: 79.69
[Train] Epoch: 1 [617664/620022]    Loss: 0.008099   Batch Acc: 78.12
[Train] Epoch: 1 [617728/620022]    Loss: 0.010462   Batch Acc: 71.88
[Train] Epoch: 1 [617792/620022]    Loss: 0.009197   Batch Acc: 81.25
[Train] Epoch: 1 [617856/620022]    Loss: 0.008630   Batch Acc: 76.56
[Train] Epoch: 1 [617920/620022]    Loss: 0.009323   Batch Acc: 78.12
[Train] Epoch: 1 [617984/620022]    Loss: 0.008470   Batch Acc: 78.12
[Train] Epoch: 1 [618048/620022]    Loss: 0.009353   Batch Acc: 79.69
[Train] Epoch: 1 [618112/620022]    Loss: 0.007430   Batch Acc: 76.56
[Train] Epoch: 1 [618176/620022]    Loss: 0.009045   Batch Acc: 76.56
[Train] Epoch: 1 [618240/620022]    Loss: 0.008755   Batch Acc: 75.00
[Train] Epoch: 1 [618304/620022]    Loss: 0.007901   Batch Acc: 78.12
[Train] Epoch: 1 [618368/620022]    Loss: 0.009715   Batch Acc: 71.88
[Train] Epoch: 1 [618432/620022]    Loss: 0.008893   Batch Acc: 79.69
[Train] Epoch: 1 [618496/620022]    Loss: 0.009372   Batch Acc: 75.00
[Train] Epoch: 1 [618560/620022]    Loss: 0.007940   Batch Acc: 84.38
[Train] Epoch: 1 [618624/620022]    Loss: 0.010571   Batch Acc: 73.44
[Train] Epoch: 1 [618688/620022]    Loss: 0.008046   Batch Acc: 81.25
[Train] Epoch: 1 [618752/620022]    Loss: 0.008604   Batch Acc: 78.12
[Train] Epoch: 1 [618816/620022]    Loss: 0.011494   Batch Acc: 70.31
[Train] Epoch: 1 [618880/620022]    Loss: 0.007509   Batch Acc: 89.06
[Train] Epoch: 1 [618944/620022]    Loss: 0.007448   Batch Acc: 78.12
[Train] Epoch: 1 [619008/620022]    Loss: 0.008846   Batch Acc: 75.00
[Train] Epoch: 1 [619072/620022]    Loss: 0.008054   Batch Acc: 81.25
[Train] Epoch: 1 [619136/620022]    Loss: 0.007100   Batch Acc: 79.69
[Train] Epoch: 1 [619200/620022]    Loss: 0.009591   Batch Acc: 79.69
[Train] Epoch: 1 [619264/620022]    Loss: 0.009081   Batch Acc: 78.12
[Train] Epoch: 1 [619328/620022]    Loss: 0.007773   Batch Acc: 84.38
[Train] Epoch: 1 [619392/620022]    Loss: 0.007202   Batch Acc: 84.38
[Train] Epoch: 1 [619456/620022]    Loss: 0.008934   Batch Acc: 78.12
[Train] Epoch: 1 [619520/620022]    Loss: 0.006702   Batch Acc: 82.81
[Train] Epoch: 1 [619584/620022]    Loss: 0.008024   Batch Acc: 75.00
[Train] Epoch: 1 [619648/620022]    Loss: 0.009678   Batch Acc: 71.88
[Train] Epoch: 1 [619712/620022]    Loss: 0.008226   Batch Acc: 82.81
[Train] Epoch: 1 [619776/620022]    Loss: 0.009155   Batch Acc: 81.25
[Train] Epoch: 1 [619840/620022]    Loss: 0.009635   Batch Acc: 70.31
[Train] Epoch: 1 [619904/620022]    Loss: 0.008176   Batch Acc: 79.69
[Train] Epoch: 1 [619968/620022]    Loss: 0.008037   Batch Acc: 87.50
[Train] Epoch: 1 [523152/620022]    Loss: 0.009544   Batch Acc: 77.78
Validation Done: [64/154214]
Validation Done: [128/154214]
Validation Done: [192/154214]
Validation Done: [256/154214]
Validation Done: [320/154214]
Validation Done: [384/154214]
Validation Done: [448/154214]
Validation Done: [512/154214]
Validation Done: [576/154214]
Validation Done: [640/154214]
Validation Done: [704/154214]
Validation Done: [768/154214]
Validation Done: [832/154214]
Validation Done: [896/154214]
Validation Done: [960/154214]
Validation Done: [1024/154214]
Validation Done: [1088/154214]
Validation Done: [1152/154214]
Validation Done: [1216/154214]
Validation Done: [1280/154214]
Validation Done: [1344/154214]
Validation Done: [1408/154214]
Validation Done: [1472/154214]
Validation Done: [1536/154214]
Validation Done: [1600/154214]
Validation Done: [1664/154214]
Validation Done: [1728/154214]
Validation Done: [1792/154214]
Validation Done: [1856/154214]
Validation Done: [1920/154214]
Validation Done: [1984/154214]
Validation Done: [2048/154214]
Validation Done: [2112/154214]
Validation Done: [2176/154214]
Validation Done: [2240/154214]
Validation Done: [2304/154214]
Validation Done: [2368/154214]
Validation Done: [2432/154214]
Validation Done: [2496/154214]
Validation Done: [2560/154214]
Validation Done: [2624/154214]
Validation Done: [2688/154214]
Validation Done: [2752/154214]
Validation Done: [2816/154214]
Validation Done: [2880/154214]
Validation Done: [2944/154214]
Validation Done: [3008/154214]
Validation Done: [3072/154214]
Validation Done: [3136/154214]
Validation Done: [3200/154214]
Validation Done: [3264/154214]
Validation Done: [3328/154214]
Validation Done: [3392/154214]
Validation Done: [3456/154214]
Validation Done: [3520/154214]
Validation Done: [3584/154214]
Validation Done: [3648/154214]
Validation Done: [3712/154214]
Validation Done: [3776/154214]
Validation Done: [3840/154214]
Validation Done: [3904/154214]
Validation Done: [3968/154214]
Validation Done: [4032/154214]
Validation Done: [4096/154214]
Validation Done: [4160/154214]
Validation Done: [4224/154214]
Validation Done: [4288/154214]
Validation Done: [4352/154214]
Validation Done: [4416/154214]
Validation Done: [4480/154214]
Validation Done: [4544/154214]
Validation Done: [4608/154214]
Validation Done: [4672/154214]
Validation Done: [4736/154214]
Validation Done: [4800/154214]
Validation Done: [4864/154214]
Validation Done: [4928/154214]
Validation Done: [4992/154214]
Validation Done: [5056/154214]
Validation Done: [5120/154214]
Validation Done: [5184/154214]
Validation Done: [5248/154214]
Validation Done: [5312/154214]
Validation Done: [5376/154214]
Validation Done: [5440/154214]
Validation Done: [5504/154214]
Validation Done: [5568/154214]
Validation Done: [5632/154214]
Validation Done: [5696/154214]
Validation Done: [5760/154214]
Validation Done: [5824/154214]
Validation Done: [5888/154214]
Validation Done: [5952/154214]
Validation Done: [6016/154214]
Validation Done: [6080/154214]
Validation Done: [6144/154214]
Validation Done: [6208/154214]
Validation Done: [6272/154214]
Validation Done: [6336/154214]
Validation Done: [6400/154214]
Validation Done: [6464/154214]
Validation Done: [6528/154214]
Validation Done: [6592/154214]
Validation Done: [6656/154214]
Validation Done: [6720/154214]
Validation Done: [6784/154214]
Validation Done: [6848/154214]
Validation Done: [6912/154214]
Validation Done: [6976/154214]
Validation Done: [7040/154214]
Validation Done: [7104/154214]
Validation Done: [7168/154214]
Validation Done: [7232/154214]
Validation Done: [7296/154214]
Validation Done: [7360/154214]
Validation Done: [7424/154214]
Validation Done: [7488/154214]
Validation Done: [7552/154214]
Validation Done: [7616/154214]
Validation Done: [7680/154214]
Validation Done: [7744/154214]
Validation Done: [7808/154214]
Validation Done: [7872/154214]
Validation Done: [7936/154214]
Validation Done: [8000/154214]
Validation Done: [8064/154214]
Validation Done: [8128/154214]
Validation Done: [8192/154214]
Validation Done: [8256/154214]
Validation Done: [8320/154214]
Validation Done: [8384/154214]
Validation Done: [8448/154214]
Validation Done: [8512/154214]
Validation Done: [8576/154214]
Validation Done: [8640/154214]
Validation Done: [8704/154214]
Validation Done: [8768/154214]
Validation Done: [8832/154214]
Validation Done: [8896/154214]
Validation Done: [8960/154214]
Validation Done: [9024/154214]
Validation Done: [9088/154214]
Validation Done: [9152/154214]
Validation Done: [9216/154214]
Validation Done: [9280/154214]
Validation Done: [9344/154214]
Validation Done: [9408/154214]
Validation Done: [9472/154214]
Validation Done: [9536/154214]
Validation Done: [9600/154214]
Validation Done: [9664/154214]
Validation Done: [9728/154214]
Validation Done: [9792/154214]
Validation Done: [9856/154214]
Validation Done: [9920/154214]
Validation Done: [9984/154214]
Validation Done: [10048/154214]
Validation Done: [10112/154214]
Validation Done: [10176/154214]
Validation Done: [10240/154214]
Validation Done: [10304/154214]
Validation Done: [10368/154214]
Validation Done: [10432/154214]
Validation Done: [10496/154214]
Validation Done: [10560/154214]
Validation Done: [10624/154214]
Validation Done: [10688/154214]
Validation Done: [10752/154214]
Validation Done: [10816/154214]
Validation Done: [10880/154214]
Validation Done: [10944/154214]
Validation Done: [11008/154214]
Validation Done: [11072/154214]
Validation Done: [11136/154214]
Validation Done: [11200/154214]
Validation Done: [11264/154214]
Validation Done: [11328/154214]
Validation Done: [11392/154214]
Validation Done: [11456/154214]
Validation Done: [11520/154214]
Validation Done: [11584/154214]
Validation Done: [11648/154214]
Validation Done: [11712/154214]
Validation Done: [11776/154214]
Validation Done: [11840/154214]
Validation Done: [11904/154214]
Validation Done: [11968/154214]
Validation Done: [12032/154214]
Validation Done: [12096/154214]
Validation Done: [12160/154214]
Validation Done: [12224/154214]
Validation Done: [12288/154214]
Validation Done: [12352/154214]
Validation Done: [12416/154214]
Validation Done: [12480/154214]
Validation Done: [12544/154214]
Validation Done: [12608/154214]
Validation Done: [12672/154214]
Validation Done: [12736/154214]
Validation Done: [12800/154214]
Validation Done: [12864/154214]
Validation Done: [12928/154214]
Validation Done: [12992/154214]
Validation Done: [13056/154214]
Validation Done: [13120/154214]
Validation Done: [13184/154214]
Validation Done: [13248/154214]
Validation Done: [13312/154214]
Validation Done: [13376/154214]
Validation Done: [13440/154214]
Validation Done: [13504/154214]
Validation Done: [13568/154214]
Validation Done: [13632/154214]
Validation Done: [13696/154214]
Validation Done: [13760/154214]
Validation Done: [13824/154214]
Validation Done: [13888/154214]
Validation Done: [13952/154214]
Validation Done: [14016/154214]
Validation Done: [14080/154214]
Validation Done: [14144/154214]
Validation Done: [14208/154214]
Validation Done: [14272/154214]
Validation Done: [14336/154214]
Validation Done: [14400/154214]
Validation Done: [14464/154214]
Validation Done: [14528/154214]
Validation Done: [14592/154214]
Validation Done: [14656/154214]
Validation Done: [14720/154214]
Validation Done: [14784/154214]
Validation Done: [14848/154214]
Validation Done: [14912/154214]
Validation Done: [14976/154214]
Validation Done: [15040/154214]
Validation Done: [15104/154214]
Validation Done: [15168/154214]
Validation Done: [15232/154214]
Validation Done: [15296/154214]
Validation Done: [15360/154214]
Validation Done: [15424/154214]
Validation Done: [15488/154214]
Validation Done: [15552/154214]
Validation Done: [15616/154214]
Validation Done: [15680/154214]
Validation Done: [15744/154214]
Validation Done: [15808/154214]
Validation Done: [15872/154214]
Validation Done: [15936/154214]
Validation Done: [16000/154214]
Validation Done: [16064/154214]
Validation Done: [16128/154214]
Validation Done: [16192/154214]
Validation Done: [16256/154214]
Validation Done: [16320/154214]
Validation Done: [16384/154214]
Validation Done: [16448/154214]
Validation Done: [16512/154214]
Validation Done: [16576/154214]
Validation Done: [16640/154214]
Validation Done: [16704/154214]
Validation Done: [16768/154214]
Validation Done: [16832/154214]
Validation Done: [16896/154214]
Validation Done: [16960/154214]
Validation Done: [17024/154214]
Validation Done: [17088/154214]
Validation Done: [17152/154214]
Validation Done: [17216/154214]
Validation Done: [17280/154214]
Validation Done: [17344/154214]
Validation Done: [17408/154214]
Validation Done: [17472/154214]
Validation Done: [17536/154214]
Validation Done: [17600/154214]
Validation Done: [17664/154214]
Validation Done: [17728/154214]
Validation Done: [17792/154214]
Validation Done: [17856/154214]
Validation Done: [17920/154214]
Validation Done: [17984/154214]
Validation Done: [18048/154214]
Validation Done: [18112/154214]
Validation Done: [18176/154214]
Validation Done: [18240/154214]
Validation Done: [18304/154214]
Validation Done: [18368/154214]
Validation Done: [18432/154214]
Validation Done: [18496/154214]
Validation Done: [18560/154214]
Validation Done: [18624/154214]
Validation Done: [18688/154214]
Validation Done: [18752/154214]
Validation Done: [18816/154214]
Validation Done: [18880/154214]
Validation Done: [18944/154214]
Validation Done: [19008/154214]
Validation Done: [19072/154214]
Validation Done: [19136/154214]
Validation Done: [19200/154214]
Validation Done: [19264/154214]
Validation Done: [19328/154214]
Validation Done: [19392/154214]
Validation Done: [19456/154214]
Validation Done: [19520/154214]
Validation Done: [19584/154214]
Validation Done: [19648/154214]
Validation Done: [19712/154214]
Validation Done: [19776/154214]
Validation Done: [19840/154214]
Validation Done: [19904/154214]
Validation Done: [19968/154214]
Validation Done: [20032/154214]
Validation Done: [20096/154214]
Validation Done: [20160/154214]
Validation Done: [20224/154214]
Validation Done: [20288/154214]
Validation Done: [20352/154214]
Validation Done: [20416/154214]
Validation Done: [20480/154214]
Validation Done: [20544/154214]
Validation Done: [20608/154214]
Validation Done: [20672/154214]
Validation Done: [20736/154214]
Validation Done: [20800/154214]
Validation Done: [20864/154214]
Validation Done: [20928/154214]
Validation Done: [20992/154214]
Validation Done: [21056/154214]
Validation Done: [21120/154214]
Validation Done: [21184/154214]
Validation Done: [21248/154214]
Validation Done: [21312/154214]
Validation Done: [21376/154214]
Validation Done: [21440/154214]
Validation Done: [21504/154214]
Validation Done: [21568/154214]
Validation Done: [21632/154214]
Validation Done: [21696/154214]
Validation Done: [21760/154214]
Validation Done: [21824/154214]
Validation Done: [21888/154214]
Validation Done: [21952/154214]
Validation Done: [22016/154214]
Validation Done: [22080/154214]
Validation Done: [22144/154214]
Validation Done: [22208/154214]
Validation Done: [22272/154214]
Validation Done: [22336/154214]
Validation Done: [22400/154214]
Validation Done: [22464/154214]
Validation Done: [22528/154214]
Validation Done: [22592/154214]
Validation Done: [22656/154214]
Validation Done: [22720/154214]
Validation Done: [22784/154214]
Validation Done: [22848/154214]
Validation Done: [22912/154214]
Validation Done: [22976/154214]
Validation Done: [23040/154214]
Validation Done: [23104/154214]
Validation Done: [23168/154214]
Validation Done: [23232/154214]
Validation Done: [23296/154214]
Validation Done: [23360/154214]
Validation Done: [23424/154214]
Validation Done: [23488/154214]
Validation Done: [23552/154214]
Validation Done: [23616/154214]
Validation Done: [23680/154214]
Validation Done: [23744/154214]
Validation Done: [23808/154214]
Validation Done: [23872/154214]
Validation Done: [23936/154214]
Validation Done: [24000/154214]
Validation Done: [24064/154214]
Validation Done: [24128/154214]
Validation Done: [24192/154214]
Validation Done: [24256/154214]
Validation Done: [24320/154214]
Validation Done: [24384/154214]
Validation Done: [24448/154214]
Validation Done: [24512/154214]
Validation Done: [24576/154214]
Validation Done: [24640/154214]
Validation Done: [24704/154214]
Validation Done: [24768/154214]
Validation Done: [24832/154214]
Validation Done: [24896/154214]
Validation Done: [24960/154214]
Validation Done: [25024/154214]
Validation Done: [25088/154214]
Validation Done: [25152/154214]
Validation Done: [25216/154214]
Validation Done: [25280/154214]
Validation Done: [25344/154214]
Validation Done: [25408/154214]
Validation Done: [25472/154214]
Validation Done: [25536/154214]
Validation Done: [25600/154214]
Validation Done: [25664/154214]
Validation Done: [25728/154214]
Validation Done: [25792/154214]
Validation Done: [25856/154214]
Validation Done: [25920/154214]
Validation Done: [25984/154214]
Validation Done: [26048/154214]
Validation Done: [26112/154214]
Validation Done: [26176/154214]
Validation Done: [26240/154214]
Validation Done: [26304/154214]
Validation Done: [26368/154214]
Validation Done: [26432/154214]
Validation Done: [26496/154214]
Validation Done: [26560/154214]
Validation Done: [26624/154214]
Validation Done: [26688/154214]
Validation Done: [26752/154214]
Validation Done: [26816/154214]
Validation Done: [26880/154214]
Validation Done: [26944/154214]
Validation Done: [27008/154214]
Validation Done: [27072/154214]
Validation Done: [27136/154214]
Validation Done: [27200/154214]
Validation Done: [27264/154214]
Validation Done: [27328/154214]
Validation Done: [27392/154214]
Validation Done: [27456/154214]
Validation Done: [27520/154214]
Validation Done: [27584/154214]
Validation Done: [27648/154214]
Validation Done: [27712/154214]
Validation Done: [27776/154214]
Validation Done: [27840/154214]
Validation Done: [27904/154214]
Validation Done: [27968/154214]
Validation Done: [28032/154214]
Validation Done: [28096/154214]
Validation Done: [28160/154214]
Validation Done: [28224/154214]
Validation Done: [28288/154214]
Validation Done: [28352/154214]
Validation Done: [28416/154214]
Validation Done: [28480/154214]
Validation Done: [28544/154214]
Validation Done: [28608/154214]
Validation Done: [28672/154214]
Validation Done: [28736/154214]
Validation Done: [28800/154214]
Validation Done: [28864/154214]
Validation Done: [28928/154214]
Validation Done: [28992/154214]
Validation Done: [29056/154214]
Validation Done: [29120/154214]
Validation Done: [29184/154214]
Validation Done: [29248/154214]
Validation Done: [29312/154214]
Validation Done: [29376/154214]
Validation Done: [29440/154214]
Validation Done: [29504/154214]
Validation Done: [29568/154214]
Validation Done: [29632/154214]
Validation Done: [29696/154214]
Validation Done: [29760/154214]
Validation Done: [29824/154214]
Validation Done: [29888/154214]
Validation Done: [29952/154214]
Validation Done: [30016/154214]
Validation Done: [30080/154214]
Validation Done: [30144/154214]
Validation Done: [30208/154214]
Validation Done: [30272/154214]
Validation Done: [30336/154214]
Validation Done: [30400/154214]
Validation Done: [30464/154214]
Validation Done: [30528/154214]
Validation Done: [30592/154214]
Validation Done: [30656/154214]
Validation Done: [30720/154214]
Validation Done: [30784/154214]
Validation Done: [30848/154214]
Validation Done: [30912/154214]
Validation Done: [30976/154214]
Validation Done: [31040/154214]
Validation Done: [31104/154214]
Validation Done: [31168/154214]
Validation Done: [31232/154214]
Validation Done: [31296/154214]
Validation Done: [31360/154214]
Validation Done: [31424/154214]
Validation Done: [31488/154214]
Validation Done: [31552/154214]
Validation Done: [31616/154214]
Validation Done: [31680/154214]
Validation Done: [31744/154214]
Validation Done: [31808/154214]
Validation Done: [31872/154214]
Validation Done: [31936/154214]
Validation Done: [32000/154214]
Validation Done: [32064/154214]
Validation Done: [32128/154214]
Validation Done: [32192/154214]
Validation Done: [32256/154214]
Validation Done: [32320/154214]
Validation Done: [32384/154214]
Validation Done: [32448/154214]
Validation Done: [32512/154214]
Validation Done: [32576/154214]
Validation Done: [32640/154214]
Validation Done: [32704/154214]
Validation Done: [32768/154214]
Validation Done: [32832/154214]
Validation Done: [32896/154214]
Validation Done: [32960/154214]
Validation Done: [33024/154214]
Validation Done: [33088/154214]
Validation Done: [33152/154214]
Validation Done: [33216/154214]
Validation Done: [33280/154214]
Validation Done: [33344/154214]
Validation Done: [33408/154214]
Validation Done: [33472/154214]
Validation Done: [33536/154214]
Validation Done: [33600/154214]
Validation Done: [33664/154214]
Validation Done: [33728/154214]
Validation Done: [33792/154214]
Validation Done: [33856/154214]
Validation Done: [33920/154214]
Validation Done: [33984/154214]
Validation Done: [34048/154214]
Validation Done: [34112/154214]
Validation Done: [34176/154214]
Validation Done: [34240/154214]
Validation Done: [34304/154214]
Validation Done: [34368/154214]
Validation Done: [34432/154214]
Validation Done: [34496/154214]
Validation Done: [34560/154214]
Validation Done: [34624/154214]
Validation Done: [34688/154214]
Validation Done: [34752/154214]
Validation Done: [34816/154214]
Validation Done: [34880/154214]
Validation Done: [34944/154214]
Validation Done: [35008/154214]
Validation Done: [35072/154214]
Validation Done: [35136/154214]
Validation Done: [35200/154214]
Validation Done: [35264/154214]
Validation Done: [35328/154214]
Validation Done: [35392/154214]
Validation Done: [35456/154214]
Validation Done: [35520/154214]
Validation Done: [35584/154214]
Validation Done: [35648/154214]
Validation Done: [35712/154214]
Validation Done: [35776/154214]
Validation Done: [35840/154214]
Validation Done: [35904/154214]
Validation Done: [35968/154214]
Validation Done: [36032/154214]
Validation Done: [36096/154214]
Validation Done: [36160/154214]
Validation Done: [36224/154214]
Validation Done: [36288/154214]
Validation Done: [36352/154214]
Validation Done: [36416/154214]
Validation Done: [36480/154214]
Validation Done: [36544/154214]
Validation Done: [36608/154214]
Validation Done: [36672/154214]
Validation Done: [36736/154214]
Validation Done: [36800/154214]
Validation Done: [36864/154214]
Validation Done: [36928/154214]
Validation Done: [36992/154214]
Validation Done: [37056/154214]
Validation Done: [37120/154214]
Validation Done: [37184/154214]
Validation Done: [37248/154214]
Validation Done: [37312/154214]
Validation Done: [37376/154214]
Validation Done: [37440/154214]
Validation Done: [37504/154214]
Validation Done: [37568/154214]
Validation Done: [37632/154214]
Validation Done: [37696/154214]
Validation Done: [37760/154214]
Validation Done: [37824/154214]
Validation Done: [37888/154214]
Validation Done: [37952/154214]
Validation Done: [38016/154214]
Validation Done: [38080/154214]
Validation Done: [38144/154214]
Validation Done: [38208/154214]
Validation Done: [38272/154214]
Validation Done: [38336/154214]
Validation Done: [38400/154214]
Validation Done: [38464/154214]
Validation Done: [38528/154214]
Validation Done: [38592/154214]
Validation Done: [38656/154214]
Validation Done: [38720/154214]
Validation Done: [38784/154214]
Validation Done: [38848/154214]
Validation Done: [38912/154214]
Validation Done: [38976/154214]
Validation Done: [39040/154214]
Validation Done: [39104/154214]
Validation Done: [39168/154214]
Validation Done: [39232/154214]
Validation Done: [39296/154214]
Validation Done: [39360/154214]
Validation Done: [39424/154214]
Validation Done: [39488/154214]
Validation Done: [39552/154214]
Validation Done: [39616/154214]
Validation Done: [39680/154214]
Validation Done: [39744/154214]
Validation Done: [39808/154214]
Validation Done: [39872/154214]
Validation Done: [39936/154214]
Validation Done: [40000/154214]
Validation Done: [40064/154214]
Validation Done: [40128/154214]
Validation Done: [40192/154214]
Validation Done: [40256/154214]
Validation Done: [40320/154214]
Validation Done: [40384/154214]
Validation Done: [40448/154214]
Validation Done: [40512/154214]
Validation Done: [40576/154214]
Validation Done: [40640/154214]
Validation Done: [40704/154214]
Validation Done: [40768/154214]
Validation Done: [40832/154214]
Validation Done: [40896/154214]
Validation Done: [40960/154214]
Validation Done: [41024/154214]
Validation Done: [41088/154214]
Validation Done: [41152/154214]
Validation Done: [41216/154214]
Validation Done: [41280/154214]
Validation Done: [41344/154214]
Validation Done: [41408/154214]
Validation Done: [41472/154214]
Validation Done: [41536/154214]
Validation Done: [41600/154214]
Validation Done: [41664/154214]
Validation Done: [41728/154214]
Validation Done: [41792/154214]
Validation Done: [41856/154214]
Validation Done: [41920/154214]
Validation Done: [41984/154214]
Validation Done: [42048/154214]
Validation Done: [42112/154214]
Validation Done: [42176/154214]
Validation Done: [42240/154214]
Validation Done: [42304/154214]
Validation Done: [42368/154214]
Validation Done: [42432/154214]
Validation Done: [42496/154214]
Validation Done: [42560/154214]
Validation Done: [42624/154214]
Validation Done: [42688/154214]
Validation Done: [42752/154214]
Validation Done: [42816/154214]
Validation Done: [42880/154214]
Validation Done: [42944/154214]
Validation Done: [43008/154214]
Validation Done: [43072/154214]
Validation Done: [43136/154214]
Validation Done: [43200/154214]
Validation Done: [43264/154214]
Validation Done: [43328/154214]
Validation Done: [43392/154214]
Validation Done: [43456/154214]
Validation Done: [43520/154214]
Validation Done: [43584/154214]
Validation Done: [43648/154214]
Validation Done: [43712/154214]
Validation Done: [43776/154214]
Validation Done: [43840/154214]
Validation Done: [43904/154214]
Validation Done: [43968/154214]
Validation Done: [44032/154214]
Validation Done: [44096/154214]
Validation Done: [44160/154214]
Validation Done: [44224/154214]
Validation Done: [44288/154214]
Validation Done: [44352/154214]
Validation Done: [44416/154214]
Validation Done: [44480/154214]
Validation Done: [44544/154214]
Validation Done: [44608/154214]
Validation Done: [44672/154214]
Validation Done: [44736/154214]
Validation Done: [44800/154214]
Validation Done: [44864/154214]
Validation Done: [44928/154214]
Validation Done: [44992/154214]
Validation Done: [45056/154214]
Validation Done: [45120/154214]
Validation Done: [45184/154214]
Validation Done: [45248/154214]
Validation Done: [45312/154214]
Validation Done: [45376/154214]
Validation Done: [45440/154214]
Validation Done: [45504/154214]
Validation Done: [45568/154214]
Validation Done: [45632/154214]
Validation Done: [45696/154214]
Validation Done: [45760/154214]
Validation Done: [45824/154214]
Validation Done: [45888/154214]
Validation Done: [45952/154214]
Validation Done: [46016/154214]
Validation Done: [46080/154214]
Validation Done: [46144/154214]
Validation Done: [46208/154214]
Validation Done: [46272/154214]
Validation Done: [46336/154214]
Validation Done: [46400/154214]
Validation Done: [46464/154214]
Validation Done: [46528/154214]
Validation Done: [46592/154214]
Validation Done: [46656/154214]
Validation Done: [46720/154214]
Validation Done: [46784/154214]
Validation Done: [46848/154214]
Validation Done: [46912/154214]
Validation Done: [46976/154214]
Validation Done: [47040/154214]
Validation Done: [47104/154214]
Validation Done: [47168/154214]
Validation Done: [47232/154214]
Validation Done: [47296/154214]
Validation Done: [47360/154214]
Validation Done: [47424/154214]
Validation Done: [47488/154214]
Validation Done: [47552/154214]
Validation Done: [47616/154214]
Validation Done: [47680/154214]
Validation Done: [47744/154214]
Validation Done: [47808/154214]
Validation Done: [47872/154214]
Validation Done: [47936/154214]
Validation Done: [48000/154214]
Validation Done: [48064/154214]
Validation Done: [48128/154214]
Validation Done: [48192/154214]
Validation Done: [48256/154214]
Validation Done: [48320/154214]
Validation Done: [48384/154214]
Validation Done: [48448/154214]
Validation Done: [48512/154214]
Validation Done: [48576/154214]
Validation Done: [48640/154214]
Validation Done: [48704/154214]
Validation Done: [48768/154214]
Validation Done: [48832/154214]
Validation Done: [48896/154214]
Validation Done: [48960/154214]
Validation Done: [49024/154214]
Validation Done: [49088/154214]
Validation Done: [49152/154214]
Validation Done: [49216/154214]
Validation Done: [49280/154214]
Validation Done: [49344/154214]
Validation Done: [49408/154214]
Validation Done: [49472/154214]
Validation Done: [49536/154214]
Validation Done: [49600/154214]
Validation Done: [49664/154214]
Validation Done: [49728/154214]
Validation Done: [49792/154214]
Validation Done: [49856/154214]
Validation Done: [49920/154214]
Validation Done: [49984/154214]
Validation Done: [50048/154214]
Validation Done: [50112/154214]
Validation Done: [50176/154214]
Validation Done: [50240/154214]
Validation Done: [50304/154214]
Validation Done: [50368/154214]
Validation Done: [50432/154214]
Validation Done: [50496/154214]
Validation Done: [50560/154214]
Validation Done: [50624/154214]
Validation Done: [50688/154214]
Validation Done: [50752/154214]
Validation Done: [50816/154214]
Validation Done: [50880/154214]
Validation Done: [50944/154214]
Validation Done: [51008/154214]
Validation Done: [51072/154214]
Validation Done: [51136/154214]
Validation Done: [51200/154214]
Validation Done: [51264/154214]
Validation Done: [51328/154214]
Validation Done: [51392/154214]
Validation Done: [51456/154214]
Validation Done: [51520/154214]
Validation Done: [51584/154214]
Validation Done: [51648/154214]
Validation Done: [51712/154214]
Validation Done: [51776/154214]
Validation Done: [51840/154214]
Validation Done: [51904/154214]
Validation Done: [51968/154214]
Validation Done: [52032/154214]
Validation Done: [52096/154214]
Validation Done: [52160/154214]
Validation Done: [52224/154214]
Validation Done: [52288/154214]
Validation Done: [52352/154214]
Validation Done: [52416/154214]
Validation Done: [52480/154214]
Validation Done: [52544/154214]
Validation Done: [52608/154214]
Validation Done: [52672/154214]
Validation Done: [52736/154214]
Validation Done: [52800/154214]
Validation Done: [52864/154214]
Validation Done: [52928/154214]
Validation Done: [52992/154214]
Validation Done: [53056/154214]
Validation Done: [53120/154214]
Validation Done: [53184/154214]
Validation Done: [53248/154214]
Validation Done: [53312/154214]
Validation Done: [53376/154214]
Validation Done: [53440/154214]
Validation Done: [53504/154214]
Validation Done: [53568/154214]
Validation Done: [53632/154214]
Validation Done: [53696/154214]
Validation Done: [53760/154214]
Validation Done: [53824/154214]
Validation Done: [53888/154214]
Validation Done: [53952/154214]
Validation Done: [54016/154214]
Validation Done: [54080/154214]
Validation Done: [54144/154214]
Validation Done: [54208/154214]
Validation Done: [54272/154214]
Validation Done: [54336/154214]
Validation Done: [54400/154214]
Validation Done: [54464/154214]
Validation Done: [54528/154214]
Validation Done: [54592/154214]
Validation Done: [54656/154214]
Validation Done: [54720/154214]
Validation Done: [54784/154214]
Validation Done: [54848/154214]
Validation Done: [54912/154214]
Validation Done: [54976/154214]
Validation Done: [55040/154214]
Validation Done: [55104/154214]
Validation Done: [55168/154214]
Validation Done: [55232/154214]
Validation Done: [55296/154214]
Validation Done: [55360/154214]
Validation Done: [55424/154214]
Validation Done: [55488/154214]
Validation Done: [55552/154214]
Validation Done: [55616/154214]
Validation Done: [55680/154214]
Validation Done: [55744/154214]
Validation Done: [55808/154214]
Validation Done: [55872/154214]
Validation Done: [55936/154214]
Validation Done: [56000/154214]
Validation Done: [56064/154214]
Validation Done: [56128/154214]
Validation Done: [56192/154214]
Validation Done: [56256/154214]
Validation Done: [56320/154214]
Validation Done: [56384/154214]
Validation Done: [56448/154214]
Validation Done: [56512/154214]
Validation Done: [56576/154214]
Validation Done: [56640/154214]
Validation Done: [56704/154214]
Validation Done: [56768/154214]
Validation Done: [56832/154214]
Validation Done: [56896/154214]
Validation Done: [56960/154214]
Validation Done: [57024/154214]
Validation Done: [57088/154214]
Validation Done: [57152/154214]
Validation Done: [57216/154214]
Validation Done: [57280/154214]
Validation Done: [57344/154214]
Validation Done: [57408/154214]
Validation Done: [57472/154214]
Validation Done: [57536/154214]
Validation Done: [57600/154214]
Validation Done: [57664/154214]
Validation Done: [57728/154214]
Validation Done: [57792/154214]
Validation Done: [57856/154214]
Validation Done: [57920/154214]
Validation Done: [57984/154214]
Validation Done: [58048/154214]
Validation Done: [58112/154214]
Validation Done: [58176/154214]
Validation Done: [58240/154214]
Validation Done: [58304/154214]
Validation Done: [58368/154214]
Validation Done: [58432/154214]
Validation Done: [58496/154214]
Validation Done: [58560/154214]
Validation Done: [58624/154214]
Validation Done: [58688/154214]
Validation Done: [58752/154214]
Validation Done: [58816/154214]
Validation Done: [58880/154214]
Validation Done: [58944/154214]
Validation Done: [59008/154214]
Validation Done: [59072/154214]
Validation Done: [59136/154214]
Validation Done: [59200/154214]
Validation Done: [59264/154214]
Validation Done: [59328/154214]
Validation Done: [59392/154214]
Validation Done: [59456/154214]
Validation Done: [59520/154214]
Validation Done: [59584/154214]
Validation Done: [59648/154214]
Validation Done: [59712/154214]
Validation Done: [59776/154214]
Validation Done: [59840/154214]
Validation Done: [59904/154214]
Validation Done: [59968/154214]
Validation Done: [60032/154214]
Validation Done: [60096/154214]
Validation Done: [60160/154214]
Validation Done: [60224/154214]
Validation Done: [60288/154214]
Validation Done: [60352/154214]
Validation Done: [60416/154214]
Validation Done: [60480/154214]
Validation Done: [60544/154214]
Validation Done: [60608/154214]
Validation Done: [60672/154214]
Validation Done: [60736/154214]
Validation Done: [60800/154214]
Validation Done: [60864/154214]
Validation Done: [60928/154214]
Validation Done: [60992/154214]
Validation Done: [61056/154214]
Validation Done: [61120/154214]
Validation Done: [61184/154214]
Validation Done: [61248/154214]
Validation Done: [61312/154214]
Validation Done: [61376/154214]
Validation Done: [61440/154214]
Validation Done: [61504/154214]
Validation Done: [61568/154214]
Validation Done: [61632/154214]
Validation Done: [61696/154214]
Validation Done: [61760/154214]
Validation Done: [61824/154214]
Validation Done: [61888/154214]
Validation Done: [61952/154214]
Validation Done: [62016/154214]
Validation Done: [62080/154214]
Validation Done: [62144/154214]
Validation Done: [62208/154214]
Validation Done: [62272/154214]
Validation Done: [62336/154214]
Validation Done: [62400/154214]
Validation Done: [62464/154214]
Validation Done: [62528/154214]
Validation Done: [62592/154214]
Validation Done: [62656/154214]
Validation Done: [62720/154214]
Validation Done: [62784/154214]
Validation Done: [62848/154214]
Validation Done: [62912/154214]
Validation Done: [62976/154214]
Validation Done: [63040/154214]
Validation Done: [63104/154214]
Validation Done: [63168/154214]
Validation Done: [63232/154214]
Validation Done: [63296/154214]
Validation Done: [63360/154214]
Validation Done: [63424/154214]
Validation Done: [63488/154214]
Validation Done: [63552/154214]
Validation Done: [63616/154214]
Validation Done: [63680/154214]
Validation Done: [63744/154214]
Validation Done: [63808/154214]
Validation Done: [63872/154214]
Validation Done: [63936/154214]
Validation Done: [64000/154214]
Validation Done: [64064/154214]
Validation Done: [64128/154214]
Validation Done: [64192/154214]
Validation Done: [64256/154214]
Validation Done: [64320/154214]
Validation Done: [64384/154214]
Validation Done: [64448/154214]
Validation Done: [64512/154214]
Validation Done: [64576/154214]
Validation Done: [64640/154214]
Validation Done: [64704/154214]
Validation Done: [64768/154214]
Validation Done: [64832/154214]
Validation Done: [64896/154214]
Validation Done: [64960/154214]
Validation Done: [65024/154214]
Validation Done: [65088/154214]
Validation Done: [65152/154214]
Validation Done: [65216/154214]
Validation Done: [65280/154214]
Validation Done: [65344/154214]
Validation Done: [65408/154214]
Validation Done: [65472/154214]
Validation Done: [65536/154214]
Validation Done: [65600/154214]
Validation Done: [65664/154214]
Validation Done: [65728/154214]
Validation Done: [65792/154214]
Validation Done: [65856/154214]
Validation Done: [65920/154214]
Validation Done: [65984/154214]
Validation Done: [66048/154214]
Validation Done: [66112/154214]
Validation Done: [66176/154214]
Validation Done: [66240/154214]
Validation Done: [66304/154214]
Validation Done: [66368/154214]
Validation Done: [66432/154214]
Validation Done: [66496/154214]
Validation Done: [66560/154214]
Validation Done: [66624/154214]
Validation Done: [66688/154214]
Validation Done: [66752/154214]
Validation Done: [66816/154214]
Validation Done: [66880/154214]
Validation Done: [66944/154214]
Validation Done: [67008/154214]
Validation Done: [67072/154214]
Validation Done: [67136/154214]
Validation Done: [67200/154214]
Validation Done: [67264/154214]
Validation Done: [67328/154214]
Validation Done: [67392/154214]
Validation Done: [67456/154214]
Validation Done: [67520/154214]
Validation Done: [67584/154214]
Validation Done: [67648/154214]
Validation Done: [67712/154214]
Validation Done: [67776/154214]
Validation Done: [67840/154214]
Validation Done: [67904/154214]
Validation Done: [67968/154214]
Validation Done: [68032/154214]
Validation Done: [68096/154214]
Validation Done: [68160/154214]
Validation Done: [68224/154214]
Validation Done: [68288/154214]
Validation Done: [68352/154214]
Validation Done: [68416/154214]
Validation Done: [68480/154214]
Validation Done: [68544/154214]
Validation Done: [68608/154214]
Validation Done: [68672/154214]
Validation Done: [68736/154214]
Validation Done: [68800/154214]
Validation Done: [68864/154214]
Validation Done: [68928/154214]
Validation Done: [68992/154214]
Validation Done: [69056/154214]
Validation Done: [69120/154214]
Validation Done: [69184/154214]
Validation Done: [69248/154214]
Validation Done: [69312/154214]
Validation Done: [69376/154214]
Validation Done: [69440/154214]
Validation Done: [69504/154214]
Validation Done: [69568/154214]
Validation Done: [69632/154214]
Validation Done: [69696/154214]
Validation Done: [69760/154214]
Validation Done: [69824/154214]
Validation Done: [69888/154214]
Validation Done: [69952/154214]
Validation Done: [70016/154214]
Validation Done: [70080/154214]
Validation Done: [70144/154214]
Validation Done: [70208/154214]
Validation Done: [70272/154214]
Validation Done: [70336/154214]
Validation Done: [70400/154214]
Validation Done: [70464/154214]
Validation Done: [70528/154214]
Validation Done: [70592/154214]
Validation Done: [70656/154214]
Validation Done: [70720/154214]
Validation Done: [70784/154214]
Validation Done: [70848/154214]
Validation Done: [70912/154214]
Validation Done: [70976/154214]
Validation Done: [71040/154214]
Validation Done: [71104/154214]
Validation Done: [71168/154214]
Validation Done: [71232/154214]
Validation Done: [71296/154214]
Validation Done: [71360/154214]
Validation Done: [71424/154214]
Validation Done: [71488/154214]
Validation Done: [71552/154214]
Validation Done: [71616/154214]
Validation Done: [71680/154214]
Validation Done: [71744/154214]
Validation Done: [71808/154214]
Validation Done: [71872/154214]
Validation Done: [71936/154214]
Validation Done: [72000/154214]
Validation Done: [72064/154214]
Validation Done: [72128/154214]
Validation Done: [72192/154214]
Validation Done: [72256/154214]
Validation Done: [72320/154214]
Validation Done: [72384/154214]
Validation Done: [72448/154214]
Validation Done: [72512/154214]
Validation Done: [72576/154214]
Validation Done: [72640/154214]
Validation Done: [72704/154214]
Validation Done: [72768/154214]
Validation Done: [72832/154214]
Validation Done: [72896/154214]
Validation Done: [72960/154214]
Validation Done: [73024/154214]
Validation Done: [73088/154214]
Validation Done: [73152/154214]
Validation Done: [73216/154214]
Validation Done: [73280/154214]
Validation Done: [73344/154214]
Validation Done: [73408/154214]
Validation Done: [73472/154214]
Validation Done: [73536/154214]
Validation Done: [73600/154214]
Validation Done: [73664/154214]
Validation Done: [73728/154214]
Validation Done: [73792/154214]
Validation Done: [73856/154214]
Validation Done: [73920/154214]
Validation Done: [73984/154214]
Validation Done: [74048/154214]
Validation Done: [74112/154214]
Validation Done: [74176/154214]
Validation Done: [74240/154214]
Validation Done: [74304/154214]
Validation Done: [74368/154214]
Validation Done: [74432/154214]
Validation Done: [74496/154214]
Validation Done: [74560/154214]
Validation Done: [74624/154214]
Validation Done: [74688/154214]
Validation Done: [74752/154214]
Validation Done: [74816/154214]
Validation Done: [74880/154214]
Validation Done: [74944/154214]
Validation Done: [75008/154214]
Validation Done: [75072/154214]
Validation Done: [75136/154214]
Validation Done: [75200/154214]
Validation Done: [75264/154214]
Validation Done: [75328/154214]
Validation Done: [75392/154214]
Validation Done: [75456/154214]
Validation Done: [75520/154214]
Validation Done: [75584/154214]
Validation Done: [75648/154214]
Validation Done: [75712/154214]
Validation Done: [75776/154214]
Validation Done: [75840/154214]
Validation Done: [75904/154214]
Validation Done: [75968/154214]
Validation Done: [76032/154214]
Validation Done: [76096/154214]
Validation Done: [76160/154214]
Validation Done: [76224/154214]
Validation Done: [76288/154214]
Validation Done: [76352/154214]
Validation Done: [76416/154214]
Validation Done: [76480/154214]
Validation Done: [76544/154214]
Validation Done: [76608/154214]
Validation Done: [76672/154214]
Validation Done: [76736/154214]
Validation Done: [76800/154214]
Validation Done: [76864/154214]
Validation Done: [76928/154214]
Validation Done: [76992/154214]
Validation Done: [77056/154214]
Validation Done: [77120/154214]
Validation Done: [77184/154214]
Validation Done: [77248/154214]
Validation Done: [77312/154214]
Validation Done: [77376/154214]
Validation Done: [77440/154214]
Validation Done: [77504/154214]
Validation Done: [77568/154214]
Validation Done: [77632/154214]
Validation Done: [77696/154214]
Validation Done: [77760/154214]
Validation Done: [77824/154214]
Validation Done: [77888/154214]
Validation Done: [77952/154214]
Validation Done: [78016/154214]
Validation Done: [78080/154214]
Validation Done: [78144/154214]
Validation Done: [78208/154214]
Validation Done: [78272/154214]
Validation Done: [78336/154214]
Validation Done: [78400/154214]
Validation Done: [78464/154214]
Validation Done: [78528/154214]
Validation Done: [78592/154214]
Validation Done: [78656/154214]
Validation Done: [78720/154214]
Validation Done: [78784/154214]
Validation Done: [78848/154214]
Validation Done: [78912/154214]
Validation Done: [78976/154214]
Validation Done: [79040/154214]
Validation Done: [79104/154214]
Validation Done: [79168/154214]
Validation Done: [79232/154214]
Validation Done: [79296/154214]
Validation Done: [79360/154214]
Validation Done: [79424/154214]
Validation Done: [79488/154214]
Validation Done: [79552/154214]
Validation Done: [79616/154214]
Validation Done: [79680/154214]
Validation Done: [79744/154214]
Validation Done: [79808/154214]
Validation Done: [79872/154214]
Validation Done: [79936/154214]
Validation Done: [80000/154214]
Validation Done: [80064/154214]
Validation Done: [80128/154214]
Validation Done: [80192/154214]
Validation Done: [80256/154214]
Validation Done: [80320/154214]
Validation Done: [80384/154214]
Validation Done: [80448/154214]
Validation Done: [80512/154214]
Validation Done: [80576/154214]
Validation Done: [80640/154214]
Validation Done: [80704/154214]
Validation Done: [80768/154214]
Validation Done: [80832/154214]
Validation Done: [80896/154214]
Validation Done: [80960/154214]
Validation Done: [81024/154214]
Validation Done: [81088/154214]
Validation Done: [81152/154214]
Validation Done: [81216/154214]
Validation Done: [81280/154214]
Validation Done: [81344/154214]
Validation Done: [81408/154214]
Validation Done: [81472/154214]
Validation Done: [81536/154214]
Validation Done: [81600/154214]
Validation Done: [81664/154214]
Validation Done: [81728/154214]
Validation Done: [81792/154214]
Validation Done: [81856/154214]
Validation Done: [81920/154214]
Validation Done: [81984/154214]
Validation Done: [82048/154214]
Validation Done: [82112/154214]
Validation Done: [82176/154214]
Validation Done: [82240/154214]
Validation Done: [82304/154214]
Validation Done: [82368/154214]
Validation Done: [82432/154214]
Validation Done: [82496/154214]
Validation Done: [82560/154214]
Validation Done: [82624/154214]
Validation Done: [82688/154214]
Validation Done: [82752/154214]
Validation Done: [82816/154214]
Validation Done: [82880/154214]
Validation Done: [82944/154214]
Validation Done: [83008/154214]
Validation Done: [83072/154214]
Validation Done: [83136/154214]
Validation Done: [83200/154214]
Validation Done: [83264/154214]
Validation Done: [83328/154214]
Validation Done: [83392/154214]
Validation Done: [83456/154214]
Validation Done: [83520/154214]
Validation Done: [83584/154214]
Validation Done: [83648/154214]
Validation Done: [83712/154214]
Validation Done: [83776/154214]
Validation Done: [83840/154214]
Validation Done: [83904/154214]
Validation Done: [83968/154214]
Validation Done: [84032/154214]
Validation Done: [84096/154214]
Validation Done: [84160/154214]
Validation Done: [84224/154214]
Validation Done: [84288/154214]
Validation Done: [84352/154214]
Validation Done: [84416/154214]
Validation Done: [84480/154214]
Validation Done: [84544/154214]
Validation Done: [84608/154214]
Validation Done: [84672/154214]
Validation Done: [84736/154214]
Validation Done: [84800/154214]
Validation Done: [84864/154214]
Validation Done: [84928/154214]
Validation Done: [84992/154214]
Validation Done: [85056/154214]
Validation Done: [85120/154214]
Validation Done: [85184/154214]
Validation Done: [85248/154214]
Validation Done: [85312/154214]
Validation Done: [85376/154214]
Validation Done: [85440/154214]
Validation Done: [85504/154214]
Validation Done: [85568/154214]
Validation Done: [85632/154214]
Validation Done: [85696/154214]
Validation Done: [85760/154214]
Validation Done: [85824/154214]
Validation Done: [85888/154214]
Validation Done: [85952/154214]
Validation Done: [86016/154214]
Validation Done: [86080/154214]
Validation Done: [86144/154214]
Validation Done: [86208/154214]
Validation Done: [86272/154214]
Validation Done: [86336/154214]
Validation Done: [86400/154214]
Validation Done: [86464/154214]
Validation Done: [86528/154214]
Validation Done: [86592/154214]
Validation Done: [86656/154214]
Validation Done: [86720/154214]
Validation Done: [86784/154214]
Validation Done: [86848/154214]
Validation Done: [86912/154214]
Validation Done: [86976/154214]
Validation Done: [87040/154214]
Validation Done: [87104/154214]
Validation Done: [87168/154214]
Validation Done: [87232/154214]
Validation Done: [87296/154214]
Validation Done: [87360/154214]
Validation Done: [87424/154214]
Validation Done: [87488/154214]
Validation Done: [87552/154214]
Validation Done: [87616/154214]
Validation Done: [87680/154214]
Validation Done: [87744/154214]
Validation Done: [87808/154214]
Validation Done: [87872/154214]
Validation Done: [87936/154214]
Validation Done: [88000/154214]
Validation Done: [88064/154214]
Validation Done: [88128/154214]
Validation Done: [88192/154214]
Validation Done: [88256/154214]
Validation Done: [88320/154214]
Validation Done: [88384/154214]
Validation Done: [88448/154214]
Validation Done: [88512/154214]
Validation Done: [88576/154214]
Validation Done: [88640/154214]
Validation Done: [88704/154214]
Validation Done: [88768/154214]
Validation Done: [88832/154214]
Validation Done: [88896/154214]
Validation Done: [88960/154214]
Validation Done: [89024/154214]
Validation Done: [89088/154214]
Validation Done: [89152/154214]
Validation Done: [89216/154214]
Validation Done: [89280/154214]
Validation Done: [89344/154214]
Validation Done: [89408/154214]
Validation Done: [89472/154214]
Validation Done: [89536/154214]
Validation Done: [89600/154214]
Validation Done: [89664/154214]
Validation Done: [89728/154214]
Validation Done: [89792/154214]
Validation Done: [89856/154214]
Validation Done: [89920/154214]
Validation Done: [89984/154214]
Validation Done: [90048/154214]
Validation Done: [90112/154214]
Validation Done: [90176/154214]
Validation Done: [90240/154214]
Validation Done: [90304/154214]
Validation Done: [90368/154214]
Validation Done: [90432/154214]
Validation Done: [90496/154214]
Validation Done: [90560/154214]
Validation Done: [90624/154214]
Validation Done: [90688/154214]
Validation Done: [90752/154214]
Validation Done: [90816/154214]
Validation Done: [90880/154214]
Validation Done: [90944/154214]
Validation Done: [91008/154214]
Validation Done: [91072/154214]
Validation Done: [91136/154214]
Validation Done: [91200/154214]
Validation Done: [91264/154214]
Validation Done: [91328/154214]
Validation Done: [91392/154214]
Validation Done: [91456/154214]
Validation Done: [91520/154214]
Validation Done: [91584/154214]
Validation Done: [91648/154214]
Validation Done: [91712/154214]
Validation Done: [91776/154214]
Validation Done: [91840/154214]
Validation Done: [91904/154214]
Validation Done: [91968/154214]
Validation Done: [92032/154214]
Validation Done: [92096/154214]
Validation Done: [92160/154214]
Validation Done: [92224/154214]
Validation Done: [92288/154214]
Validation Done: [92352/154214]
Validation Done: [92416/154214]
Validation Done: [92480/154214]
Validation Done: [92544/154214]
Validation Done: [92608/154214]
Validation Done: [92672/154214]
Validation Done: [92736/154214]
Validation Done: [92800/154214]
Validation Done: [92864/154214]
Validation Done: [92928/154214]
Validation Done: [92992/154214]
Validation Done: [93056/154214]
Validation Done: [93120/154214]
Validation Done: [93184/154214]
Validation Done: [93248/154214]
Validation Done: [93312/154214]
Validation Done: [93376/154214]
Validation Done: [93440/154214]
Validation Done: [93504/154214]
Validation Done: [93568/154214]
Validation Done: [93632/154214]
Validation Done: [93696/154214]
Validation Done: [93760/154214]
Validation Done: [93824/154214]
Validation Done: [93888/154214]
Validation Done: [93952/154214]
Validation Done: [94016/154214]
Validation Done: [94080/154214]
Validation Done: [94144/154214]
Validation Done: [94208/154214]
Validation Done: [94272/154214]
Validation Done: [94336/154214]
Validation Done: [94400/154214]
Validation Done: [94464/154214]
Validation Done: [94528/154214]
Validation Done: [94592/154214]
Validation Done: [94656/154214]
Validation Done: [94720/154214]
Validation Done: [94784/154214]
Validation Done: [94848/154214]
Validation Done: [94912/154214]
Validation Done: [94976/154214]
Validation Done: [95040/154214]
Validation Done: [95104/154214]
Validation Done: [95168/154214]
Validation Done: [95232/154214]
Validation Done: [95296/154214]
Validation Done: [95360/154214]
Validation Done: [95424/154214]
Validation Done: [95488/154214]
Validation Done: [95552/154214]
Validation Done: [95616/154214]
Validation Done: [95680/154214]
Validation Done: [95744/154214]
Validation Done: [95808/154214]
Validation Done: [95872/154214]
Validation Done: [95936/154214]
Validation Done: [96000/154214]
Validation Done: [96064/154214]
Validation Done: [96128/154214]
Validation Done: [96192/154214]
Validation Done: [96256/154214]
Validation Done: [96320/154214]
Validation Done: [96384/154214]
Validation Done: [96448/154214]
Validation Done: [96512/154214]
Validation Done: [96576/154214]
Validation Done: [96640/154214]
Validation Done: [96704/154214]
Validation Done: [96768/154214]
Validation Done: [96832/154214]
Validation Done: [96896/154214]
Validation Done: [96960/154214]
Validation Done: [97024/154214]
Validation Done: [97088/154214]
Validation Done: [97152/154214]
Validation Done: [97216/154214]
Validation Done: [97280/154214]
Validation Done: [97344/154214]
Validation Done: [97408/154214]
Validation Done: [97472/154214]
Validation Done: [97536/154214]
Validation Done: [97600/154214]
Validation Done: [97664/154214]
Validation Done: [97728/154214]
Validation Done: [97792/154214]
Validation Done: [97856/154214]
Validation Done: [97920/154214]
Validation Done: [97984/154214]
Validation Done: [98048/154214]
Validation Done: [98112/154214]
Validation Done: [98176/154214]
Validation Done: [98240/154214]
Validation Done: [98304/154214]
Validation Done: [98368/154214]
Validation Done: [98432/154214]
Validation Done: [98496/154214]
Validation Done: [98560/154214]
Validation Done: [98624/154214]
Validation Done: [98688/154214]
Validation Done: [98752/154214]
Validation Done: [98816/154214]
Validation Done: [98880/154214]
Validation Done: [98944/154214]
Validation Done: [99008/154214]
Validation Done: [99072/154214]
Validation Done: [99136/154214]
Validation Done: [99200/154214]
Validation Done: [99264/154214]
Validation Done: [99328/154214]
Validation Done: [99392/154214]
Validation Done: [99456/154214]
Validation Done: [99520/154214]
Validation Done: [99584/154214]
Validation Done: [99648/154214]
Validation Done: [99712/154214]
Validation Done: [99776/154214]
Validation Done: [99840/154214]
Validation Done: [99904/154214]
Validation Done: [99968/154214]
Validation Done: [100032/154214]
Validation Done: [100096/154214]
Validation Done: [100160/154214]
Validation Done: [100224/154214]
Validation Done: [100288/154214]
Validation Done: [100352/154214]
Validation Done: [100416/154214]
Validation Done: [100480/154214]
Validation Done: [100544/154214]
Validation Done: [100608/154214]
Validation Done: [100672/154214]
Validation Done: [100736/154214]
Validation Done: [100800/154214]
Validation Done: [100864/154214]
Validation Done: [100928/154214]
Validation Done: [100992/154214]
Validation Done: [101056/154214]
Validation Done: [101120/154214]
Validation Done: [101184/154214]
Validation Done: [101248/154214]
Validation Done: [101312/154214]
Validation Done: [101376/154214]
Validation Done: [101440/154214]
Validation Done: [101504/154214]
Validation Done: [101568/154214]
Validation Done: [101632/154214]
Validation Done: [101696/154214]
Validation Done: [101760/154214]
Validation Done: [101824/154214]
Validation Done: [101888/154214]
Validation Done: [101952/154214]
Validation Done: [102016/154214]
Validation Done: [102080/154214]
Validation Done: [102144/154214]
Validation Done: [102208/154214]
Validation Done: [102272/154214]
Validation Done: [102336/154214]
Validation Done: [102400/154214]
Validation Done: [102464/154214]
Validation Done: [102528/154214]
Validation Done: [102592/154214]
Validation Done: [102656/154214]
Validation Done: [102720/154214]
Validation Done: [102784/154214]
Validation Done: [102848/154214]
Validation Done: [102912/154214]
Validation Done: [102976/154214]
Validation Done: [103040/154214]
Validation Done: [103104/154214]
Validation Done: [103168/154214]
Validation Done: [103232/154214]
Validation Done: [103296/154214]
Validation Done: [103360/154214]
Validation Done: [103424/154214]
Validation Done: [103488/154214]
Validation Done: [103552/154214]
Validation Done: [103616/154214]
Validation Done: [103680/154214]
Validation Done: [103744/154214]
Validation Done: [103808/154214]
Validation Done: [103872/154214]
Validation Done: [103936/154214]
Validation Done: [104000/154214]
Validation Done: [104064/154214]
Validation Done: [104128/154214]
Validation Done: [104192/154214]
Validation Done: [104256/154214]
Validation Done: [104320/154214]
Validation Done: [104384/154214]
Validation Done: [104448/154214]
Validation Done: [104512/154214]
Validation Done: [104576/154214]
Validation Done: [104640/154214]
Validation Done: [104704/154214]
Validation Done: [104768/154214]
Validation Done: [104832/154214]
Validation Done: [104896/154214]
Validation Done: [104960/154214]
Validation Done: [105024/154214]
Validation Done: [105088/154214]
Validation Done: [105152/154214]
Validation Done: [105216/154214]
Validation Done: [105280/154214]
Validation Done: [105344/154214]
Validation Done: [105408/154214]
Validation Done: [105472/154214]
Validation Done: [105536/154214]
Validation Done: [105600/154214]
Validation Done: [105664/154214]
Validation Done: [105728/154214]
Validation Done: [105792/154214]
Validation Done: [105856/154214]
Validation Done: [105920/154214]
Validation Done: [105984/154214]
Validation Done: [106048/154214]
Validation Done: [106112/154214]
Validation Done: [106176/154214]
Validation Done: [106240/154214]
Validation Done: [106304/154214]
Validation Done: [106368/154214]
Validation Done: [106432/154214]
Validation Done: [106496/154214]
Validation Done: [106560/154214]
Validation Done: [106624/154214]
Validation Done: [106688/154214]
Validation Done: [106752/154214]
Validation Done: [106816/154214]
Validation Done: [106880/154214]
Validation Done: [106944/154214]
Validation Done: [107008/154214]
Validation Done: [107072/154214]
Validation Done: [107136/154214]
Validation Done: [107200/154214]
Validation Done: [107264/154214]
Validation Done: [107328/154214]
Validation Done: [107392/154214]
Validation Done: [107456/154214]
Validation Done: [107520/154214]
Validation Done: [107584/154214]
Validation Done: [107648/154214]
Validation Done: [107712/154214]
Validation Done: [107776/154214]
Validation Done: [107840/154214]
Validation Done: [107904/154214]
Validation Done: [107968/154214]
Validation Done: [108032/154214]
Validation Done: [108096/154214]
Validation Done: [108160/154214]
Validation Done: [108224/154214]
Validation Done: [108288/154214]
Validation Done: [108352/154214]
Validation Done: [108416/154214]
Validation Done: [108480/154214]
Validation Done: [108544/154214]
Validation Done: [108608/154214]
Validation Done: [108672/154214]
Validation Done: [108736/154214]
Validation Done: [108800/154214]
Validation Done: [108864/154214]
Validation Done: [108928/154214]
Validation Done: [108992/154214]
Validation Done: [109056/154214]
Validation Done: [109120/154214]
Validation Done: [109184/154214]
Validation Done: [109248/154214]
Validation Done: [109312/154214]
Validation Done: [109376/154214]
Validation Done: [109440/154214]
Validation Done: [109504/154214]
Validation Done: [109568/154214]
Validation Done: [109632/154214]
Validation Done: [109696/154214]
Validation Done: [109760/154214]
Validation Done: [109824/154214]
Validation Done: [109888/154214]
Validation Done: [109952/154214]
Validation Done: [110016/154214]
Validation Done: [110080/154214]
Validation Done: [110144/154214]
Validation Done: [110208/154214]
Validation Done: [110272/154214]
Validation Done: [110336/154214]
Validation Done: [110400/154214]
Validation Done: [110464/154214]
Validation Done: [110528/154214]
Validation Done: [110592/154214]
Validation Done: [110656/154214]
Validation Done: [110720/154214]
Validation Done: [110784/154214]
Validation Done: [110848/154214]
Validation Done: [110912/154214]
Validation Done: [110976/154214]
Validation Done: [111040/154214]
Validation Done: [111104/154214]
Validation Done: [111168/154214]
Validation Done: [111232/154214]
Validation Done: [111296/154214]
Validation Done: [111360/154214]
Validation Done: [111424/154214]
Validation Done: [111488/154214]
Validation Done: [111552/154214]
Validation Done: [111616/154214]
Validation Done: [111680/154214]
Validation Done: [111744/154214]
Validation Done: [111808/154214]
Validation Done: [111872/154214]
Validation Done: [111936/154214]
Validation Done: [112000/154214]
Validation Done: [112064/154214]
Validation Done: [112128/154214]
Validation Done: [112192/154214]
Validation Done: [112256/154214]
Validation Done: [112320/154214]
Validation Done: [112384/154214]
Validation Done: [112448/154214]
Validation Done: [112512/154214]
Validation Done: [112576/154214]
Validation Done: [112640/154214]
Validation Done: [112704/154214]
Validation Done: [112768/154214]
Validation Done: [112832/154214]
Validation Done: [112896/154214]
Validation Done: [112960/154214]
Validation Done: [113024/154214]
Validation Done: [113088/154214]
Validation Done: [113152/154214]
Validation Done: [113216/154214]
Validation Done: [113280/154214]
Validation Done: [113344/154214]
Validation Done: [113408/154214]
Validation Done: [113472/154214]
Validation Done: [113536/154214]
Validation Done: [113600/154214]
Validation Done: [113664/154214]
Validation Done: [113728/154214]
Validation Done: [113792/154214]
Validation Done: [113856/154214]
Validation Done: [113920/154214]
Validation Done: [113984/154214]
Validation Done: [114048/154214]
Validation Done: [114112/154214]
Validation Done: [114176/154214]
Validation Done: [114240/154214]
Validation Done: [114304/154214]
Validation Done: [114368/154214]
Validation Done: [114432/154214]
Validation Done: [114496/154214]
Validation Done: [114560/154214]
Validation Done: [114624/154214]
Validation Done: [114688/154214]
Validation Done: [114752/154214]
Validation Done: [114816/154214]
Validation Done: [114880/154214]
Validation Done: [114944/154214]
Validation Done: [115008/154214]
Validation Done: [115072/154214]
Validation Done: [115136/154214]
Validation Done: [115200/154214]
Validation Done: [115264/154214]
Validation Done: [115328/154214]
Validation Done: [115392/154214]
Validation Done: [115456/154214]
Validation Done: [115520/154214]
Validation Done: [115584/154214]
Validation Done: [115648/154214]
Validation Done: [115712/154214]
Validation Done: [115776/154214]
Validation Done: [115840/154214]
Validation Done: [115904/154214]
Validation Done: [115968/154214]
Validation Done: [116032/154214]
Validation Done: [116096/154214]
Validation Done: [116160/154214]
Validation Done: [116224/154214]
Validation Done: [116288/154214]
Validation Done: [116352/154214]
Validation Done: [116416/154214]
Validation Done: [116480/154214]
Validation Done: [116544/154214]
Validation Done: [116608/154214]
Validation Done: [116672/154214]
Validation Done: [116736/154214]
Validation Done: [116800/154214]
Validation Done: [116864/154214]
Validation Done: [116928/154214]
Validation Done: [116992/154214]
Validation Done: [117056/154214]
Validation Done: [117120/154214]
Validation Done: [117184/154214]
Validation Done: [117248/154214]
Validation Done: [117312/154214]
Validation Done: [117376/154214]
Validation Done: [117440/154214]
Validation Done: [117504/154214]
Validation Done: [117568/154214]
Validation Done: [117632/154214]
Validation Done: [117696/154214]
Validation Done: [117760/154214]
Validation Done: [117824/154214]
Validation Done: [117888/154214]
Validation Done: [117952/154214]
Validation Done: [118016/154214]
Validation Done: [118080/154214]
Validation Done: [118144/154214]
Validation Done: [118208/154214]
Validation Done: [118272/154214]
Validation Done: [118336/154214]
Validation Done: [118400/154214]
Validation Done: [118464/154214]
Validation Done: [118528/154214]
Validation Done: [118592/154214]
Validation Done: [118656/154214]
Validation Done: [118720/154214]
Validation Done: [118784/154214]
Validation Done: [118848/154214]
Validation Done: [118912/154214]
Validation Done: [118976/154214]
Validation Done: [119040/154214]
Validation Done: [119104/154214]
Validation Done: [119168/154214]
Validation Done: [119232/154214]
Validation Done: [119296/154214]
Validation Done: [119360/154214]
Validation Done: [119424/154214]
Validation Done: [119488/154214]
Validation Done: [119552/154214]
Validation Done: [119616/154214]
Validation Done: [119680/154214]
Validation Done: [119744/154214]
Validation Done: [119808/154214]
Validation Done: [119872/154214]
Validation Done: [119936/154214]
Validation Done: [120000/154214]
Validation Done: [120064/154214]
Validation Done: [120128/154214]
Validation Done: [120192/154214]
Validation Done: [120256/154214]
Validation Done: [120320/154214]
Validation Done: [120384/154214]
Validation Done: [120448/154214]
Validation Done: [120512/154214]
Validation Done: [120576/154214]
Validation Done: [120640/154214]
Validation Done: [120704/154214]
Validation Done: [120768/154214]
Validation Done: [120832/154214]
Validation Done: [120896/154214]
Validation Done: [120960/154214]
Validation Done: [121024/154214]
Validation Done: [121088/154214]
Validation Done: [121152/154214]
Validation Done: [121216/154214]
Validation Done: [121280/154214]
Validation Done: [121344/154214]
Validation Done: [121408/154214]
Validation Done: [121472/154214]
Validation Done: [121536/154214]
Validation Done: [121600/154214]
Validation Done: [121664/154214]
Validation Done: [121728/154214]
Validation Done: [121792/154214]
Validation Done: [121856/154214]
Validation Done: [121920/154214]
Validation Done: [121984/154214]
Validation Done: [122048/154214]
Validation Done: [122112/154214]
Validation Done: [122176/154214]
Validation Done: [122240/154214]
Validation Done: [122304/154214]
Validation Done: [122368/154214]
Validation Done: [122432/154214]
Validation Done: [122496/154214]
Validation Done: [122560/154214]
Validation Done: [122624/154214]
Validation Done: [122688/154214]
Validation Done: [122752/154214]
Validation Done: [122816/154214]
Validation Done: [122880/154214]
Validation Done: [122944/154214]
Validation Done: [123008/154214]
Validation Done: [123072/154214]
Validation Done: [123136/154214]
Validation Done: [123200/154214]
Validation Done: [123264/154214]
Validation Done: [123328/154214]
Validation Done: [123392/154214]
Validation Done: [123456/154214]
Validation Done: [123520/154214]
Validation Done: [123584/154214]
Validation Done: [123648/154214]
Validation Done: [123712/154214]
Validation Done: [123776/154214]
Validation Done: [123840/154214]
Validation Done: [123904/154214]
Validation Done: [123968/154214]
Validation Done: [124032/154214]
Validation Done: [124096/154214]
Validation Done: [124160/154214]
Validation Done: [124224/154214]
Validation Done: [124288/154214]
Validation Done: [124352/154214]
Validation Done: [124416/154214]
Validation Done: [124480/154214]
Validation Done: [124544/154214]
Validation Done: [124608/154214]
Validation Done: [124672/154214]
Validation Done: [124736/154214]
Validation Done: [124800/154214]
Validation Done: [124864/154214]
Validation Done: [124928/154214]
Validation Done: [124992/154214]
Validation Done: [125056/154214]
Validation Done: [125120/154214]
Validation Done: [125184/154214]
Validation Done: [125248/154214]
Validation Done: [125312/154214]
Validation Done: [125376/154214]
Validation Done: [125440/154214]
Validation Done: [125504/154214]
Validation Done: [125568/154214]
Validation Done: [125632/154214]
Validation Done: [125696/154214]
Validation Done: [125760/154214]
Validation Done: [125824/154214]
Validation Done: [125888/154214]
Validation Done: [125952/154214]
Validation Done: [126016/154214]
Validation Done: [126080/154214]
Validation Done: [126144/154214]
Validation Done: [126208/154214]
Validation Done: [126272/154214]
Validation Done: [126336/154214]
Validation Done: [126400/154214]
Validation Done: [126464/154214]
Validation Done: [126528/154214]
Validation Done: [126592/154214]
Validation Done: [126656/154214]
Validation Done: [126720/154214]
Validation Done: [126784/154214]
Validation Done: [126848/154214]
Validation Done: [126912/154214]
Validation Done: [126976/154214]
Validation Done: [127040/154214]
Validation Done: [127104/154214]
Validation Done: [127168/154214]
Validation Done: [127232/154214]
Validation Done: [127296/154214]
Validation Done: [127360/154214]
Validation Done: [127424/154214]
Validation Done: [127488/154214]
Validation Done: [127552/154214]
Validation Done: [127616/154214]
Validation Done: [127680/154214]
Validation Done: [127744/154214]
Validation Done: [127808/154214]
Validation Done: [127872/154214]
Validation Done: [127936/154214]
Validation Done: [128000/154214]
Validation Done: [128064/154214]
Validation Done: [128128/154214]
Validation Done: [128192/154214]
Validation Done: [128256/154214]
Validation Done: [128320/154214]
Validation Done: [128384/154214]
Validation Done: [128448/154214]
Validation Done: [128512/154214]
Validation Done: [128576/154214]
Validation Done: [128640/154214]
Validation Done: [128704/154214]
Validation Done: [128768/154214]
Validation Done: [128832/154214]
Validation Done: [128896/154214]
Validation Done: [128960/154214]
Validation Done: [129024/154214]
Validation Done: [129088/154214]
Validation Done: [129152/154214]
Validation Done: [129216/154214]
Validation Done: [129280/154214]
Validation Done: [129344/154214]
Validation Done: [129408/154214]
Validation Done: [129472/154214]
Validation Done: [129536/154214]
Validation Done: [129600/154214]
Validation Done: [129664/154214]
Validation Done: [129728/154214]
Validation Done: [129792/154214]
Validation Done: [129856/154214]
Validation Done: [129920/154214]
Validation Done: [129984/154214]
Validation Done: [130048/154214]
Validation Done: [130112/154214]
Validation Done: [130176/154214]
Validation Done: [130240/154214]
Validation Done: [130304/154214]
Validation Done: [130368/154214]
Validation Done: [130432/154214]
Validation Done: [130496/154214]
Validation Done: [130560/154214]
Validation Done: [130624/154214]
Validation Done: [130688/154214]
Validation Done: [130752/154214]
Validation Done: [130816/154214]
Validation Done: [130880/154214]
Validation Done: [130944/154214]
Validation Done: [131008/154214]
Validation Done: [131072/154214]
Validation Done: [131136/154214]
Validation Done: [131200/154214]
Validation Done: [131264/154214]
Validation Done: [131328/154214]
Validation Done: [131392/154214]
Validation Done: [131456/154214]
Validation Done: [131520/154214]
Validation Done: [131584/154214]
Validation Done: [131648/154214]
Validation Done: [131712/154214]
Validation Done: [131776/154214]
Validation Done: [131840/154214]
Validation Done: [131904/154214]
Validation Done: [131968/154214]
Validation Done: [132032/154214]
Validation Done: [132096/154214]
Validation Done: [132160/154214]
Validation Done: [132224/154214]
Validation Done: [132288/154214]
Validation Done: [132352/154214]
Validation Done: [132416/154214]
Validation Done: [132480/154214]
Validation Done: [132544/154214]
Validation Done: [132608/154214]
Validation Done: [132672/154214]
Validation Done: [132736/154214]
Validation Done: [132800/154214]
Validation Done: [132864/154214]
Validation Done: [132928/154214]
Validation Done: [132992/154214]
Validation Done: [133056/154214]
Validation Done: [133120/154214]
Validation Done: [133184/154214]
Validation Done: [133248/154214]
Validation Done: [133312/154214]
Validation Done: [133376/154214]
Validation Done: [133440/154214]
Validation Done: [133504/154214]
Validation Done: [133568/154214]
Validation Done: [133632/154214]
Validation Done: [133696/154214]
Validation Done: [133760/154214]
Validation Done: [133824/154214]
Validation Done: [133888/154214]
Validation Done: [133952/154214]
Validation Done: [134016/154214]
Validation Done: [134080/154214]
Validation Done: [134144/154214]
Validation Done: [134208/154214]
Validation Done: [134272/154214]
Validation Done: [134336/154214]
Validation Done: [134400/154214]
Validation Done: [134464/154214]
Validation Done: [134528/154214]
Validation Done: [134592/154214]
Validation Done: [134656/154214]
Validation Done: [134720/154214]
Validation Done: [134784/154214]
Validation Done: [134848/154214]
Validation Done: [134912/154214]
Validation Done: [134976/154214]
Validation Done: [135040/154214]
Validation Done: [135104/154214]
Validation Done: [135168/154214]
Validation Done: [135232/154214]
Validation Done: [135296/154214]
Validation Done: [135360/154214]
Validation Done: [135424/154214]
Validation Done: [135488/154214]
Validation Done: [135552/154214]
Validation Done: [135616/154214]
Validation Done: [135680/154214]
Validation Done: [135744/154214]
Validation Done: [135808/154214]
Validation Done: [135872/154214]
Validation Done: [135936/154214]
Validation Done: [136000/154214]
Validation Done: [136064/154214]
Validation Done: [136128/154214]
Validation Done: [136192/154214]
Validation Done: [136256/154214]
Validation Done: [136320/154214]
Validation Done: [136384/154214]
Validation Done: [136448/154214]
Validation Done: [136512/154214]
Validation Done: [136576/154214]
Validation Done: [136640/154214]
Validation Done: [136704/154214]
Validation Done: [136768/154214]
Validation Done: [136832/154214]
Validation Done: [136896/154214]
Validation Done: [136960/154214]
Validation Done: [137024/154214]
Validation Done: [137088/154214]
Validation Done: [137152/154214]
Validation Done: [137216/154214]
Validation Done: [137280/154214]
Validation Done: [137344/154214]
Validation Done: [137408/154214]
Validation Done: [137472/154214]
Validation Done: [137536/154214]
Validation Done: [137600/154214]
Validation Done: [137664/154214]
Validation Done: [137728/154214]
Validation Done: [137792/154214]
Validation Done: [137856/154214]
Validation Done: [137920/154214]
Validation Done: [137984/154214]
Validation Done: [138048/154214]
Validation Done: [138112/154214]
Validation Done: [138176/154214]
Validation Done: [138240/154214]
Validation Done: [138304/154214]
Validation Done: [138368/154214]
Validation Done: [138432/154214]
Validation Done: [138496/154214]
Validation Done: [138560/154214]
Validation Done: [138624/154214]
Validation Done: [138688/154214]
Validation Done: [138752/154214]
Validation Done: [138816/154214]
Validation Done: [138880/154214]
Validation Done: [138944/154214]
Validation Done: [139008/154214]
Validation Done: [139072/154214]
Validation Done: [139136/154214]
Validation Done: [139200/154214]
Validation Done: [139264/154214]
Validation Done: [139328/154214]
Validation Done: [139392/154214]
Validation Done: [139456/154214]
Validation Done: [139520/154214]
Validation Done: [139584/154214]
Validation Done: [139648/154214]
Validation Done: [139712/154214]
Validation Done: [139776/154214]
Validation Done: [139840/154214]
Validation Done: [139904/154214]
Validation Done: [139968/154214]
Validation Done: [140032/154214]
Validation Done: [140096/154214]
Validation Done: [140160/154214]
Validation Done: [140224/154214]
Validation Done: [140288/154214]
Validation Done: [140352/154214]
Validation Done: [140416/154214]
Validation Done: [140480/154214]
Validation Done: [140544/154214]
Validation Done: [140608/154214]
Validation Done: [140672/154214]
Validation Done: [140736/154214]
Validation Done: [140800/154214]
Validation Done: [140864/154214]
Validation Done: [140928/154214]
Validation Done: [140992/154214]
Validation Done: [141056/154214]
Validation Done: [141120/154214]
Validation Done: [141184/154214]
Validation Done: [141248/154214]
Validation Done: [141312/154214]
Validation Done: [141376/154214]
Validation Done: [141440/154214]
Validation Done: [141504/154214]
Validation Done: [141568/154214]
Validation Done: [141632/154214]
Validation Done: [141696/154214]
Validation Done: [141760/154214]
Validation Done: [141824/154214]
Validation Done: [141888/154214]
Validation Done: [141952/154214]
Validation Done: [142016/154214]
Validation Done: [142080/154214]
Validation Done: [142144/154214]
Validation Done: [142208/154214]
Validation Done: [142272/154214]
Validation Done: [142336/154214]
Validation Done: [142400/154214]
Validation Done: [142464/154214]
Validation Done: [142528/154214]
Validation Done: [142592/154214]
Validation Done: [142656/154214]
Validation Done: [142720/154214]
Validation Done: [142784/154214]
Validation Done: [142848/154214]
Validation Done: [142912/154214]
Validation Done: [142976/154214]
Validation Done: [143040/154214]
Validation Done: [143104/154214]
Validation Done: [143168/154214]
Validation Done: [143232/154214]
Validation Done: [143296/154214]
Validation Done: [143360/154214]
Validation Done: [143424/154214]
Validation Done: [143488/154214]
Validation Done: [143552/154214]
Validation Done: [143616/154214]
Validation Done: [143680/154214]
Validation Done: [143744/154214]
Validation Done: [143808/154214]
Validation Done: [143872/154214]
Validation Done: [143936/154214]
Validation Done: [144000/154214]
Validation Done: [144064/154214]
Validation Done: [144128/154214]
Validation Done: [144192/154214]
Validation Done: [144256/154214]
Validation Done: [144320/154214]
Validation Done: [144384/154214]
Validation Done: [144448/154214]
Validation Done: [144512/154214]
Validation Done: [144576/154214]
Validation Done: [144640/154214]
Validation Done: [144704/154214]
Validation Done: [144768/154214]
Validation Done: [144832/154214]
Validation Done: [144896/154214]
Validation Done: [144960/154214]
Validation Done: [145024/154214]
Validation Done: [145088/154214]
Validation Done: [145152/154214]
Validation Done: [145216/154214]
Validation Done: [145280/154214]
Validation Done: [145344/154214]
Validation Done: [145408/154214]
Validation Done: [145472/154214]
Validation Done: [145536/154214]
Validation Done: [145600/154214]
Validation Done: [145664/154214]
Validation Done: [145728/154214]
Validation Done: [145792/154214]
Validation Done: [145856/154214]
Validation Done: [145920/154214]
Validation Done: [145984/154214]
Validation Done: [146048/154214]
Validation Done: [146112/154214]
Validation Done: [146176/154214]
Validation Done: [146240/154214]
Validation Done: [146304/154214]
Validation Done: [146368/154214]
Validation Done: [146432/154214]
Validation Done: [146496/154214]
Validation Done: [146560/154214]
Validation Done: [146624/154214]
Validation Done: [146688/154214]
Validation Done: [146752/154214]
Validation Done: [146816/154214]
Validation Done: [146880/154214]
Validation Done: [146944/154214]
Validation Done: [147008/154214]
Validation Done: [147072/154214]
Validation Done: [147136/154214]
Validation Done: [147200/154214]
Validation Done: [147264/154214]
Validation Done: [147328/154214]
Validation Done: [147392/154214]
Validation Done: [147456/154214]
Validation Done: [147520/154214]
Validation Done: [147584/154214]
Validation Done: [147648/154214]
Validation Done: [147712/154214]
Validation Done: [147776/154214]
Validation Done: [147840/154214]
Validation Done: [147904/154214]
Validation Done: [147968/154214]
Validation Done: [148032/154214]
Validation Done: [148096/154214]
Validation Done: [148160/154214]
Validation Done: [148224/154214]
Validation Done: [148288/154214]
Validation Done: [148352/154214]
Validation Done: [148416/154214]
Validation Done: [148480/154214]
Validation Done: [148544/154214]
Validation Done: [148608/154214]
Validation Done: [148672/154214]
Validation Done: [148736/154214]
Validation Done: [148800/154214]
Validation Done: [148864/154214]
Validation Done: [148928/154214]
Validation Done: [148992/154214]
Validation Done: [149056/154214]
Validation Done: [149120/154214]
Validation Done: [149184/154214]
Validation Done: [149248/154214]
Validation Done: [149312/154214]
Validation Done: [149376/154214]
Validation Done: [149440/154214]
Validation Done: [149504/154214]
Validation Done: [149568/154214]
Validation Done: [149632/154214]
Validation Done: [149696/154214]
Validation Done: [149760/154214]
Validation Done: [149824/154214]
Validation Done: [149888/154214]
Validation Done: [149952/154214]
Validation Done: [150016/154214]
Validation Done: [150080/154214]
Validation Done: [150144/154214]
Validation Done: [150208/154214]
Validation Done: [150272/154214]
Validation Done: [150336/154214]
Validation Done: [150400/154214]
Validation Done: [150464/154214]
Validation Done: [150528/154214]
Validation Done: [150592/154214]
Validation Done: [150656/154214]
Validation Done: [150720/154214]
Validation Done: [150784/154214]
Validation Done: [150848/154214]
Validation Done: [150912/154214]
Validation Done: [150976/154214]
Validation Done: [151040/154214]
Validation Done: [151104/154214]
Validation Done: [151168/154214]
Validation Done: [151232/154214]
Validation Done: [151296/154214]
Validation Done: [151360/154214]
Validation Done: [151424/154214]
Validation Done: [151488/154214]
Validation Done: [151552/154214]
Validation Done: [151616/154214]
Validation Done: [151680/154214]
Validation Done: [151744/154214]
Validation Done: [151808/154214]
Validation Done: [151872/154214]
Validation Done: [151936/154214]
Validation Done: [152000/154214]
Validation Done: [152064/154214]
Validation Done: [152128/154214]
Validation Done: [152192/154214]
Validation Done: [152256/154214]
Validation Done: [152320/154214]
Validation Done: [152384/154214]
Validation Done: [152448/154214]
Validation Done: [152512/154214]
Validation Done: [152576/154214]
Validation Done: [152640/154214]
Validation Done: [152704/154214]
Validation Done: [152768/154214]
Validation Done: [152832/154214]
Validation Done: [152896/154214]
Validation Done: [152960/154214]
Validation Done: [153024/154214]
Validation Done: [153088/154214]
Validation Done: [153152/154214]
Validation Done: [153216/154214]
Validation Done: [153280/154214]
Validation Done: [153344/154214]
Validation Done: [153408/154214]
Validation Done: [153472/154214]
Validation Done: [153536/154214]
Validation Done: [153600/154214]
Validation Done: [153664/154214]
Validation Done: [153728/154214]
Validation Done: [153792/154214]
Validation Done: [153856/154214]
Validation Done: [153920/154214]
Validation Done: [153984/154214]
Validation Done: [154048/154214]
Validation Done: [154112/154214]
Validation Done: [154176/154214]
Validation Done: [91580/154214]
[Test] Epoch: 1 Test set: Average loss: 0.0087, Accuracy: 119494/154214 (77.49%)
{'KIRC': {'recall': 0.8876753954777014, 'support': 55945, 'precision': 0.722835975139368, 'f1-score': 0.7968198446826263}, 'weighted avg': {'recall': 0.7748583137717717, 'support': 154214, 'precision': 0.791040766692056, 'f1-score': 0.773851352415763}, 'KICH': {'recall': 0.6740988671472709, 'support': 58260, 'precision': 0.8966028948449842, 'f1-score': 0.7695910329015695}, 'accuracy': 0.7748583137717717, 'macro avg': {'recall': 0.7752008004312572, 'support': 154214, 'precision': 0.7840448170912541, 'f1-score': 0.7714496361243354}, 'KIRP': {'recall': 0.7638281386687995, 'support': 40009, 'precision': 0.7326955812894099, 'f1-score': 0.7479380307888103}}
[Train] Epoch: 2 [64/620022]    Loss: 0.010751   Batch Acc: 68.75
[Train] Epoch: 2 [128/620022]    Loss: 0.009532   Batch Acc: 70.31
[Train] Epoch: 2 [192/620022]    Loss: 0.008287   Batch Acc: 73.44
[Train] Epoch: 2 [256/620022]    Loss: 0.010309   Batch Acc: 65.62
[Train] Epoch: 2 [320/620022]    Loss: 0.006151   Batch Acc: 89.06
[Train] Epoch: 2 [384/620022]    Loss: 0.008968   Batch Acc: 71.88
[Train] Epoch: 2 [448/620022]    Loss: 0.009438   Batch Acc: 73.44
[Train] Epoch: 2 [512/620022]    Loss: 0.005639   Batch Acc: 85.94
[Train] Epoch: 2 [576/620022]    Loss: 0.008729   Batch Acc: 78.12
[Train] Epoch: 2 [640/620022]    Loss: 0.009641   Batch Acc: 71.88
[Train] Epoch: 2 [704/620022]    Loss: 0.008669   Batch Acc: 79.69
[Train] Epoch: 2 [768/620022]    Loss: 0.007520   Batch Acc: 81.25
[Train] Epoch: 2 [832/620022]    Loss: 0.010189   Batch Acc: 75.00
[Train] Epoch: 2 [896/620022]    Loss: 0.008318   Batch Acc: 81.25
[Train] Epoch: 2 [960/620022]    Loss: 0.007331   Batch Acc: 78.12
[Train] Epoch: 2 [1024/620022]    Loss: 0.007297   Batch Acc: 81.25
[Train] Epoch: 2 [1088/620022]    Loss: 0.006435   Batch Acc: 79.69
[Train] Epoch: 2 [1152/620022]    Loss: 0.006620   Batch Acc: 84.38
[Train] Epoch: 2 [1216/620022]    Loss: 0.010593   Batch Acc: 67.19
[Train] Epoch: 2 [1280/620022]    Loss: 0.007623   Batch Acc: 79.69
[Train] Epoch: 2 [1344/620022]    Loss: 0.007652   Batch Acc: 82.81
[Train] Epoch: 2 [1408/620022]    Loss: 0.007995   Batch Acc: 81.25
[Train] Epoch: 2 [1472/620022]    Loss: 0.010233   Batch Acc: 76.56
[Train] Epoch: 2 [1536/620022]    Loss: 0.007447   Batch Acc: 81.25
[Train] Epoch: 2 [1600/620022]    Loss: 0.008580   Batch Acc: 79.69
[Train] Epoch: 2 [1664/620022]    Loss: 0.008282   Batch Acc: 78.12
[Train] Epoch: 2 [1728/620022]    Loss: 0.007766   Batch Acc: 82.81
[Train] Epoch: 2 [1792/620022]    Loss: 0.008050   Batch Acc: 84.38
[Train] Epoch: 2 [1856/620022]    Loss: 0.007706   Batch Acc: 84.38
[Train] Epoch: 2 [1920/620022]    Loss: 0.007842   Batch Acc: 78.12
[Train] Epoch: 2 [1984/620022]    Loss: 0.007369   Batch Acc: 82.81
[Train] Epoch: 2 [2048/620022]    Loss: 0.009500   Batch Acc: 82.81
[Train] Epoch: 2 [2112/620022]    Loss: 0.008276   Batch Acc: 79.69
[Train] Epoch: 2 [2176/620022]    Loss: 0.009061   Batch Acc: 78.12
[Train] Epoch: 2 [2240/620022]    Loss: 0.010697   Batch Acc: 67.19
[Train] Epoch: 2 [2304/620022]    Loss: 0.009310   Batch Acc: 68.75
[Train] Epoch: 2 [2368/620022]    Loss: 0.009177   Batch Acc: 76.56
[Train] Epoch: 2 [2432/620022]    Loss: 0.009999   Batch Acc: 75.00
[Train] Epoch: 2 [2496/620022]    Loss: 0.010375   Batch Acc: 70.31
[Train] Epoch: 2 [2560/620022]    Loss: 0.007664   Batch Acc: 78.12
[Train] Epoch: 2 [2624/620022]    Loss: 0.012722   Batch Acc: 67.19
[Train] Epoch: 2 [2688/620022]    Loss: 0.008336   Batch Acc: 78.12
[Train] Epoch: 2 [2752/620022]    Loss: 0.010384   Batch Acc: 70.31
[Train] Epoch: 2 [2816/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 2 [2880/620022]    Loss: 0.007546   Batch Acc: 81.25
[Train] Epoch: 2 [2944/620022]    Loss: 0.008229   Batch Acc: 82.81
[Train] Epoch: 2 [3008/620022]    Loss: 0.008618   Batch Acc: 76.56
[Train] Epoch: 2 [3072/620022]    Loss: 0.006698   Batch Acc: 82.81
[Train] Epoch: 2 [3136/620022]    Loss: 0.008781   Batch Acc: 78.12
[Train] Epoch: 2 [3200/620022]    Loss: 0.010257   Batch Acc: 71.88
[Train] Epoch: 2 [3264/620022]    Loss: 0.007129   Batch Acc: 82.81
[Train] Epoch: 2 [3328/620022]    Loss: 0.007650   Batch Acc: 82.81
[Train] Epoch: 2 [3392/620022]    Loss: 0.011499   Batch Acc: 71.88
[Train] Epoch: 2 [3456/620022]    Loss: 0.006730   Batch Acc: 84.38
[Train] Epoch: 2 [3520/620022]    Loss: 0.008198   Batch Acc: 78.12
[Train] Epoch: 2 [3584/620022]    Loss: 0.007229   Batch Acc: 84.38
[Train] Epoch: 2 [3648/620022]    Loss: 0.007905   Batch Acc: 82.81
[Train] Epoch: 2 [3712/620022]    Loss: 0.010728   Batch Acc: 68.75
[Train] Epoch: 2 [3776/620022]    Loss: 0.007932   Batch Acc: 79.69
[Train] Epoch: 2 [3840/620022]    Loss: 0.009203   Batch Acc: 76.56
[Train] Epoch: 2 [3904/620022]    Loss: 0.008255   Batch Acc: 75.00
[Train] Epoch: 2 [3968/620022]    Loss: 0.008822   Batch Acc: 79.69
[Train] Epoch: 2 [4032/620022]    Loss: 0.012363   Batch Acc: 60.94
[Train] Epoch: 2 [4096/620022]    Loss: 0.008134   Batch Acc: 79.69
[Train] Epoch: 2 [4160/620022]    Loss: 0.007633   Batch Acc: 85.94
[Train] Epoch: 2 [4224/620022]    Loss: 0.010467   Batch Acc: 70.31
[Train] Epoch: 2 [4288/620022]    Loss: 0.007671   Batch Acc: 84.38
[Train] Epoch: 2 [4352/620022]    Loss: 0.008716   Batch Acc: 79.69
[Train] Epoch: 2 [4416/620022]    Loss: 0.008951   Batch Acc: 75.00
[Train] Epoch: 2 [4480/620022]    Loss: 0.008482   Batch Acc: 78.12
[Train] Epoch: 2 [4544/620022]    Loss: 0.008576   Batch Acc: 73.44
[Train] Epoch: 2 [4608/620022]    Loss: 0.009042   Batch Acc: 79.69
[Train] Epoch: 2 [4672/620022]    Loss: 0.008512   Batch Acc: 70.31
[Train] Epoch: 2 [4736/620022]    Loss: 0.008154   Batch Acc: 84.38
[Train] Epoch: 2 [4800/620022]    Loss: 0.008933   Batch Acc: 71.88
[Train] Epoch: 2 [4864/620022]    Loss: 0.009999   Batch Acc: 76.56
[Train] Epoch: 2 [4928/620022]    Loss: 0.008871   Batch Acc: 78.12
[Train] Epoch: 2 [4992/620022]    Loss: 0.008313   Batch Acc: 78.12
[Train] Epoch: 2 [5056/620022]    Loss: 0.010166   Batch Acc: 75.00
[Train] Epoch: 2 [5120/620022]    Loss: 0.008448   Batch Acc: 78.12
[Train] Epoch: 2 [5184/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 2 [5248/620022]    Loss: 0.008044   Batch Acc: 81.25
[Train] Epoch: 2 [5312/620022]    Loss: 0.005498   Batch Acc: 92.19
[Train] Epoch: 2 [5376/620022]    Loss: 0.006752   Batch Acc: 87.50
[Train] Epoch: 2 [5440/620022]    Loss: 0.008127   Batch Acc: 79.69
[Train] Epoch: 2 [5504/620022]    Loss: 0.009404   Batch Acc: 70.31
[Train] Epoch: 2 [5568/620022]    Loss: 0.009894   Batch Acc: 71.88
[Train] Epoch: 2 [5632/620022]    Loss: 0.008933   Batch Acc: 75.00
[Train] Epoch: 2 [5696/620022]    Loss: 0.007118   Batch Acc: 85.94
[Train] Epoch: 2 [5760/620022]    Loss: 0.007550   Batch Acc: 79.69
[Train] Epoch: 2 [5824/620022]    Loss: 0.008640   Batch Acc: 71.88
[Train] Epoch: 2 [5888/620022]    Loss: 0.009049   Batch Acc: 75.00
[Train] Epoch: 2 [5952/620022]    Loss: 0.009002   Batch Acc: 78.12
[Train] Epoch: 2 [6016/620022]    Loss: 0.006342   Batch Acc: 89.06
[Train] Epoch: 2 [6080/620022]    Loss: 0.008154   Batch Acc: 81.25
[Train] Epoch: 2 [6144/620022]    Loss: 0.009444   Batch Acc: 81.25
[Train] Epoch: 2 [6208/620022]    Loss: 0.007279   Batch Acc: 76.56
[Train] Epoch: 2 [6272/620022]    Loss: 0.009722   Batch Acc: 71.88
[Train] Epoch: 2 [6336/620022]    Loss: 0.009105   Batch Acc: 79.69
[Train] Epoch: 2 [6400/620022]    Loss: 0.006846   Batch Acc: 79.69
[Train] Epoch: 2 [6464/620022]    Loss: 0.010080   Batch Acc: 78.12
[Train] Epoch: 2 [6528/620022]    Loss: 0.007653   Batch Acc: 82.81
[Train] Epoch: 2 [6592/620022]    Loss: 0.008911   Batch Acc: 78.12
[Train] Epoch: 2 [6656/620022]    Loss: 0.009807   Batch Acc: 71.88
[Train] Epoch: 2 [6720/620022]    Loss: 0.009240   Batch Acc: 73.44
[Train] Epoch: 2 [6784/620022]    Loss: 0.008457   Batch Acc: 78.12
[Train] Epoch: 2 [6848/620022]    Loss: 0.007940   Batch Acc: 79.69
[Train] Epoch: 2 [6912/620022]    Loss: 0.007946   Batch Acc: 78.12
[Train] Epoch: 2 [6976/620022]    Loss: 0.008253   Batch Acc: 78.12
[Train] Epoch: 2 [7040/620022]    Loss: 0.008206   Batch Acc: 84.38
[Train] Epoch: 2 [7104/620022]    Loss: 0.007024   Batch Acc: 85.94
[Train] Epoch: 2 [7168/620022]    Loss: 0.008880   Batch Acc: 81.25
[Train] Epoch: 2 [7232/620022]    Loss: 0.007776   Batch Acc: 78.12
[Train] Epoch: 2 [7296/620022]    Loss: 0.008309   Batch Acc: 76.56
[Train] Epoch: 2 [7360/620022]    Loss: 0.010099   Batch Acc: 75.00
[Train] Epoch: 2 [7424/620022]    Loss: 0.005641   Batch Acc: 84.38
[Train] Epoch: 2 [7488/620022]    Loss: 0.010853   Batch Acc: 70.31
[Train] Epoch: 2 [7552/620022]    Loss: 0.008409   Batch Acc: 84.38
[Train] Epoch: 2 [7616/620022]    Loss: 0.008385   Batch Acc: 81.25
[Train] Epoch: 2 [7680/620022]    Loss: 0.010814   Batch Acc: 68.75
[Train] Epoch: 2 [7744/620022]    Loss: 0.008185   Batch Acc: 81.25
[Train] Epoch: 2 [7808/620022]    Loss: 0.009171   Batch Acc: 76.56
[Train] Epoch: 2 [7872/620022]    Loss: 0.006814   Batch Acc: 85.94
[Train] Epoch: 2 [7936/620022]    Loss: 0.010233   Batch Acc: 70.31
[Train] Epoch: 2 [8000/620022]    Loss: 0.007555   Batch Acc: 79.69
[Train] Epoch: 2 [8064/620022]    Loss: 0.007899   Batch Acc: 78.12
[Train] Epoch: 2 [8128/620022]    Loss: 0.009599   Batch Acc: 70.31
[Train] Epoch: 2 [8192/620022]    Loss: 0.011106   Batch Acc: 62.50
[Train] Epoch: 2 [8256/620022]    Loss: 0.009247   Batch Acc: 76.56
[Train] Epoch: 2 [8320/620022]    Loss: 0.008417   Batch Acc: 78.12
[Train] Epoch: 2 [8384/620022]    Loss: 0.007592   Batch Acc: 87.50
[Train] Epoch: 2 [8448/620022]    Loss: 0.008703   Batch Acc: 76.56
[Train] Epoch: 2 [8512/620022]    Loss: 0.007122   Batch Acc: 82.81
[Train] Epoch: 2 [8576/620022]    Loss: 0.006089   Batch Acc: 84.38
[Train] Epoch: 2 [8640/620022]    Loss: 0.008175   Batch Acc: 75.00
[Train] Epoch: 2 [8704/620022]    Loss: 0.008376   Batch Acc: 75.00
[Train] Epoch: 2 [8768/620022]    Loss: 0.007685   Batch Acc: 85.94
[Train] Epoch: 2 [8832/620022]    Loss: 0.009171   Batch Acc: 78.12
[Train] Epoch: 2 [8896/620022]    Loss: 0.006954   Batch Acc: 76.56
[Train] Epoch: 2 [8960/620022]    Loss: 0.007674   Batch Acc: 87.50
[Train] Epoch: 2 [9024/620022]    Loss: 0.009832   Batch Acc: 78.12
[Train] Epoch: 2 [9088/620022]    Loss: 0.007560   Batch Acc: 81.25
[Train] Epoch: 2 [9152/620022]    Loss: 0.008959   Batch Acc: 79.69
[Train] Epoch: 2 [9216/620022]    Loss: 0.007689   Batch Acc: 81.25
[Train] Epoch: 2 [9280/620022]    Loss: 0.008923   Batch Acc: 70.31
[Train] Epoch: 2 [9344/620022]    Loss: 0.007793   Batch Acc: 79.69
[Train] Epoch: 2 [9408/620022]    Loss: 0.009968   Batch Acc: 68.75
[Train] Epoch: 2 [9472/620022]    Loss: 0.009468   Batch Acc: 68.75
[Train] Epoch: 2 [9536/620022]    Loss: 0.008097   Batch Acc: 81.25
[Train] Epoch: 2 [9600/620022]    Loss: 0.010719   Batch Acc: 75.00
[Train] Epoch: 2 [9664/620022]    Loss: 0.006915   Batch Acc: 81.25
[Train] Epoch: 2 [9728/620022]    Loss: 0.009923   Batch Acc: 71.88
[Train] Epoch: 2 [9792/620022]    Loss: 0.009261   Batch Acc: 76.56
[Train] Epoch: 2 [9856/620022]    Loss: 0.005745   Batch Acc: 87.50
[Train] Epoch: 2 [9920/620022]    Loss: 0.007618   Batch Acc: 76.56
[Train] Epoch: 2 [9984/620022]    Loss: 0.008073   Batch Acc: 78.12
[Train] Epoch: 2 [10048/620022]    Loss: 0.008909   Batch Acc: 71.88
[Train] Epoch: 2 [10112/620022]    Loss: 0.007930   Batch Acc: 81.25
[Train] Epoch: 2 [10176/620022]    Loss: 0.009035   Batch Acc: 73.44
[Train] Epoch: 2 [10240/620022]    Loss: 0.012143   Batch Acc: 71.88
[Train] Epoch: 2 [10304/620022]    Loss: 0.007535   Batch Acc: 82.81
[Train] Epoch: 2 [10368/620022]    Loss: 0.007130   Batch Acc: 76.56
[Train] Epoch: 2 [10432/620022]    Loss: 0.005786   Batch Acc: 84.38
[Train] Epoch: 2 [10496/620022]    Loss: 0.010118   Batch Acc: 65.62
[Train] Epoch: 2 [10560/620022]    Loss: 0.007836   Batch Acc: 82.81
[Train] Epoch: 2 [10624/620022]    Loss: 0.006672   Batch Acc: 85.94
[Train] Epoch: 2 [10688/620022]    Loss: 0.008173   Batch Acc: 78.12
[Train] Epoch: 2 [10752/620022]    Loss: 0.008793   Batch Acc: 73.44
[Train] Epoch: 2 [10816/620022]    Loss: 0.007903   Batch Acc: 84.38
[Train] Epoch: 2 [10880/620022]    Loss: 0.010399   Batch Acc: 70.31
[Train] Epoch: 2 [10944/620022]    Loss: 0.007280   Batch Acc: 82.81
[Train] Epoch: 2 [11008/620022]    Loss: 0.008350   Batch Acc: 79.69
[Train] Epoch: 2 [11072/620022]    Loss: 0.009087   Batch Acc: 76.56
[Train] Epoch: 2 [11136/620022]    Loss: 0.006253   Batch Acc: 81.25
[Train] Epoch: 2 [11200/620022]    Loss: 0.008608   Batch Acc: 76.56
[Train] Epoch: 2 [11264/620022]    Loss: 0.007508   Batch Acc: 81.25
[Train] Epoch: 2 [11328/620022]    Loss: 0.009486   Batch Acc: 68.75
[Train] Epoch: 2 [11392/620022]    Loss: 0.007266   Batch Acc: 82.81
[Train] Epoch: 2 [11456/620022]    Loss: 0.008356   Batch Acc: 78.12
[Train] Epoch: 2 [11520/620022]    Loss: 0.008975   Batch Acc: 82.81
[Train] Epoch: 2 [11584/620022]    Loss: 0.007219   Batch Acc: 78.12
[Train] Epoch: 2 [11648/620022]    Loss: 0.010335   Batch Acc: 73.44
[Train] Epoch: 2 [11712/620022]    Loss: 0.006977   Batch Acc: 87.50
[Train] Epoch: 2 [11776/620022]    Loss: 0.008957   Batch Acc: 73.44
[Train] Epoch: 2 [11840/620022]    Loss: 0.010363   Batch Acc: 70.31
[Train] Epoch: 2 [11904/620022]    Loss: 0.007881   Batch Acc: 79.69
[Train] Epoch: 2 [11968/620022]    Loss: 0.008101   Batch Acc: 81.25
[Train] Epoch: 2 [12032/620022]    Loss: 0.005456   Batch Acc: 85.94
[Train] Epoch: 2 [12096/620022]    Loss: 0.007507   Batch Acc: 76.56
[Train] Epoch: 2 [12160/620022]    Loss: 0.007273   Batch Acc: 82.81
[Train] Epoch: 2 [12224/620022]    Loss: 0.008604   Batch Acc: 79.69
[Train] Epoch: 2 [12288/620022]    Loss: 0.008485   Batch Acc: 76.56
[Train] Epoch: 2 [12352/620022]    Loss: 0.006895   Batch Acc: 81.25
[Train] Epoch: 2 [12416/620022]    Loss: 0.007966   Batch Acc: 78.12
[Train] Epoch: 2 [12480/620022]    Loss: 0.006641   Batch Acc: 82.81
[Train] Epoch: 2 [12544/620022]    Loss: 0.007617   Batch Acc: 81.25
[Train] Epoch: 2 [12608/620022]    Loss: 0.010376   Batch Acc: 73.44
[Train] Epoch: 2 [12672/620022]    Loss: 0.009016   Batch Acc: 73.44
[Train] Epoch: 2 [12736/620022]    Loss: 0.009251   Batch Acc: 71.88
[Train] Epoch: 2 [12800/620022]    Loss: 0.010002   Batch Acc: 81.25
[Train] Epoch: 2 [12864/620022]    Loss: 0.007125   Batch Acc: 85.94
[Train] Epoch: 2 [12928/620022]    Loss: 0.008436   Batch Acc: 73.44
[Train] Epoch: 2 [12992/620022]    Loss: 0.007311   Batch Acc: 78.12
[Train] Epoch: 2 [13056/620022]    Loss: 0.008637   Batch Acc: 75.00
[Train] Epoch: 2 [13120/620022]    Loss: 0.008908   Batch Acc: 76.56
[Train] Epoch: 2 [13184/620022]    Loss: 0.010535   Batch Acc: 75.00
[Train] Epoch: 2 [13248/620022]    Loss: 0.010509   Batch Acc: 70.31
[Train] Epoch: 2 [13312/620022]    Loss: 0.009807   Batch Acc: 76.56
[Train] Epoch: 2 [13376/620022]    Loss: 0.008429   Batch Acc: 81.25
[Train] Epoch: 2 [13440/620022]    Loss: 0.008568   Batch Acc: 71.88
[Train] Epoch: 2 [13504/620022]    Loss: 0.008507   Batch Acc: 82.81
[Train] Epoch: 2 [13568/620022]    Loss: 0.008038   Batch Acc: 79.69
[Train] Epoch: 2 [13632/620022]    Loss: 0.008335   Batch Acc: 78.12
[Train] Epoch: 2 [13696/620022]    Loss: 0.008520   Batch Acc: 79.69
[Train] Epoch: 2 [13760/620022]    Loss: 0.008907   Batch Acc: 73.44
[Train] Epoch: 2 [13824/620022]    Loss: 0.007446   Batch Acc: 82.81
[Train] Epoch: 2 [13888/620022]    Loss: 0.010503   Batch Acc: 73.44
[Train] Epoch: 2 [13952/620022]    Loss: 0.006179   Batch Acc: 84.38
[Train] Epoch: 2 [14016/620022]    Loss: 0.008056   Batch Acc: 78.12
[Train] Epoch: 2 [14080/620022]    Loss: 0.009898   Batch Acc: 67.19
[Train] Epoch: 2 [14144/620022]    Loss: 0.009549   Batch Acc: 79.69
[Train] Epoch: 2 [14208/620022]    Loss: 0.009828   Batch Acc: 79.69
[Train] Epoch: 2 [14272/620022]    Loss: 0.007598   Batch Acc: 85.94
[Train] Epoch: 2 [14336/620022]    Loss: 0.008685   Batch Acc: 76.56
[Train] Epoch: 2 [14400/620022]    Loss: 0.009071   Batch Acc: 79.69
[Train] Epoch: 2 [14464/620022]    Loss: 0.009320   Batch Acc: 78.12
[Train] Epoch: 2 [14528/620022]    Loss: 0.005914   Batch Acc: 82.81
[Train] Epoch: 2 [14592/620022]    Loss: 0.010265   Batch Acc: 73.44
[Train] Epoch: 2 [14656/620022]    Loss: 0.009299   Batch Acc: 81.25
[Train] Epoch: 2 [14720/620022]    Loss: 0.009138   Batch Acc: 73.44
[Train] Epoch: 2 [14784/620022]    Loss: 0.009277   Batch Acc: 78.12
[Train] Epoch: 2 [14848/620022]    Loss: 0.009286   Batch Acc: 76.56
[Train] Epoch: 2 [14912/620022]    Loss: 0.008639   Batch Acc: 78.12
[Train] Epoch: 2 [14976/620022]    Loss: 0.008309   Batch Acc: 78.12
[Train] Epoch: 2 [15040/620022]    Loss: 0.006927   Batch Acc: 85.94
[Train] Epoch: 2 [15104/620022]    Loss: 0.009250   Batch Acc: 78.12
[Train] Epoch: 2 [15168/620022]    Loss: 0.007202   Batch Acc: 82.81
[Train] Epoch: 2 [15232/620022]    Loss: 0.007643   Batch Acc: 82.81
[Train] Epoch: 2 [15296/620022]    Loss: 0.009236   Batch Acc: 73.44
[Train] Epoch: 2 [15360/620022]    Loss: 0.009446   Batch Acc: 78.12
[Train] Epoch: 2 [15424/620022]    Loss: 0.009602   Batch Acc: 73.44
[Train] Epoch: 2 [15488/620022]    Loss: 0.011225   Batch Acc: 67.19
[Train] Epoch: 2 [15552/620022]    Loss: 0.006916   Batch Acc: 79.69
[Train] Epoch: 2 [15616/620022]    Loss: 0.006921   Batch Acc: 85.94
[Train] Epoch: 2 [15680/620022]    Loss: 0.012701   Batch Acc: 64.06
[Train] Epoch: 2 [15744/620022]    Loss: 0.008509   Batch Acc: 78.12
[Train] Epoch: 2 [15808/620022]    Loss: 0.008879   Batch Acc: 84.38
[Train] Epoch: 2 [15872/620022]    Loss: 0.008866   Batch Acc: 79.69
[Train] Epoch: 2 [15936/620022]    Loss: 0.009997   Batch Acc: 73.44
[Train] Epoch: 2 [16000/620022]    Loss: 0.006999   Batch Acc: 85.94
[Train] Epoch: 2 [16064/620022]    Loss: 0.008177   Batch Acc: 79.69
[Train] Epoch: 2 [16128/620022]    Loss: 0.009224   Batch Acc: 79.69
[Train] Epoch: 2 [16192/620022]    Loss: 0.007634   Batch Acc: 82.81
[Train] Epoch: 2 [16256/620022]    Loss: 0.009864   Batch Acc: 75.00
[Train] Epoch: 2 [16320/620022]    Loss: 0.005609   Batch Acc: 87.50
[Train] Epoch: 2 [16384/620022]    Loss: 0.006946   Batch Acc: 84.38
[Train] Epoch: 2 [16448/620022]    Loss: 0.008219   Batch Acc: 81.25
[Train] Epoch: 2 [16512/620022]    Loss: 0.007150   Batch Acc: 84.38
[Train] Epoch: 2 [16576/620022]    Loss: 0.006714   Batch Acc: 89.06
[Train] Epoch: 2 [16640/620022]    Loss: 0.009735   Batch Acc: 73.44
[Train] Epoch: 2 [16704/620022]    Loss: 0.007427   Batch Acc: 81.25
[Train] Epoch: 2 [16768/620022]    Loss: 0.007761   Batch Acc: 82.81
[Train] Epoch: 2 [16832/620022]    Loss: 0.007807   Batch Acc: 82.81
[Train] Epoch: 2 [16896/620022]    Loss: 0.007449   Batch Acc: 85.94
[Train] Epoch: 2 [16960/620022]    Loss: 0.008985   Batch Acc: 76.56
[Train] Epoch: 2 [17024/620022]    Loss: 0.008612   Batch Acc: 76.56
[Train] Epoch: 2 [17088/620022]    Loss: 0.010044   Batch Acc: 75.00
[Train] Epoch: 2 [17152/620022]    Loss: 0.009239   Batch Acc: 75.00
[Train] Epoch: 2 [17216/620022]    Loss: 0.011659   Batch Acc: 68.75
[Train] Epoch: 2 [17280/620022]    Loss: 0.009385   Batch Acc: 79.69
[Train] Epoch: 2 [17344/620022]    Loss: 0.008685   Batch Acc: 78.12
[Train] Epoch: 2 [17408/620022]    Loss: 0.008691   Batch Acc: 78.12
[Train] Epoch: 2 [17472/620022]    Loss: 0.010970   Batch Acc: 70.31
[Train] Epoch: 2 [17536/620022]    Loss: 0.006343   Batch Acc: 84.38
[Train] Epoch: 2 [17600/620022]    Loss: 0.009507   Batch Acc: 75.00
[Train] Epoch: 2 [17664/620022]    Loss: 0.008359   Batch Acc: 81.25
[Train] Epoch: 2 [17728/620022]    Loss: 0.010775   Batch Acc: 67.19
[Train] Epoch: 2 [17792/620022]    Loss: 0.009471   Batch Acc: 75.00
[Train] Epoch: 2 [17856/620022]    Loss: 0.011356   Batch Acc: 71.88
[Train] Epoch: 2 [17920/620022]    Loss: 0.009742   Batch Acc: 73.44
[Train] Epoch: 2 [17984/620022]    Loss: 0.009407   Batch Acc: 73.44
[Train] Epoch: 2 [18048/620022]    Loss: 0.010784   Batch Acc: 76.56
[Train] Epoch: 2 [18112/620022]    Loss: 0.008277   Batch Acc: 79.69
[Train] Epoch: 2 [18176/620022]    Loss: 0.009452   Batch Acc: 73.44
[Train] Epoch: 2 [18240/620022]    Loss: 0.010231   Batch Acc: 70.31
[Train] Epoch: 2 [18304/620022]    Loss: 0.006718   Batch Acc: 82.81
[Train] Epoch: 2 [18368/620022]    Loss: 0.009303   Batch Acc: 73.44
[Train] Epoch: 2 [18432/620022]    Loss: 0.010215   Batch Acc: 76.56
[Train] Epoch: 2 [18496/620022]    Loss: 0.006374   Batch Acc: 85.94
[Train] Epoch: 2 [18560/620022]    Loss: 0.007557   Batch Acc: 82.81
[Train] Epoch: 2 [18624/620022]    Loss: 0.008946   Batch Acc: 81.25
[Train] Epoch: 2 [18688/620022]    Loss: 0.011073   Batch Acc: 71.88
[Train] Epoch: 2 [18752/620022]    Loss: 0.008820   Batch Acc: 78.12
[Train] Epoch: 2 [18816/620022]    Loss: 0.010118   Batch Acc: 68.75
[Train] Epoch: 2 [18880/620022]    Loss: 0.009294   Batch Acc: 78.12
[Train] Epoch: 2 [18944/620022]    Loss: 0.009310   Batch Acc: 75.00
[Train] Epoch: 2 [19008/620022]    Loss: 0.009548   Batch Acc: 75.00
[Train] Epoch: 2 [19072/620022]    Loss: 0.008420   Batch Acc: 82.81
[Train] Epoch: 2 [19136/620022]    Loss: 0.005528   Batch Acc: 87.50
[Train] Epoch: 2 [19200/620022]    Loss: 0.008892   Batch Acc: 75.00
[Train] Epoch: 2 [19264/620022]    Loss: 0.011430   Batch Acc: 60.94
[Train] Epoch: 2 [19328/620022]    Loss: 0.008048   Batch Acc: 87.50
[Train] Epoch: 2 [19392/620022]    Loss: 0.006253   Batch Acc: 84.38
[Train] Epoch: 2 [19456/620022]    Loss: 0.006885   Batch Acc: 79.69
[Train] Epoch: 2 [19520/620022]    Loss: 0.007427   Batch Acc: 79.69
[Train] Epoch: 2 [19584/620022]    Loss: 0.010431   Batch Acc: 76.56
[Train] Epoch: 2 [19648/620022]    Loss: 0.007935   Batch Acc: 76.56
[Train] Epoch: 2 [19712/620022]    Loss: 0.010844   Batch Acc: 73.44
[Train] Epoch: 2 [19776/620022]    Loss: 0.009217   Batch Acc: 71.88
[Train] Epoch: 2 [19840/620022]    Loss: 0.011970   Batch Acc: 73.44
[Train] Epoch: 2 [19904/620022]    Loss: 0.008022   Batch Acc: 79.69
[Train] Epoch: 2 [19968/620022]    Loss: 0.007642   Batch Acc: 82.81
[Train] Epoch: 2 [20032/620022]    Loss: 0.007937   Batch Acc: 78.12
[Train] Epoch: 2 [20096/620022]    Loss: 0.009268   Batch Acc: 78.12
[Train] Epoch: 2 [20160/620022]    Loss: 0.007171   Batch Acc: 84.38
[Train] Epoch: 2 [20224/620022]    Loss: 0.007216   Batch Acc: 81.25
[Train] Epoch: 2 [20288/620022]    Loss: 0.008046   Batch Acc: 76.56
[Train] Epoch: 2 [20352/620022]    Loss: 0.009062   Batch Acc: 76.56
[Train] Epoch: 2 [20416/620022]    Loss: 0.007009   Batch Acc: 75.00
[Train] Epoch: 2 [20480/620022]    Loss: 0.008752   Batch Acc: 82.81
[Train] Epoch: 2 [20544/620022]    Loss: 0.006735   Batch Acc: 82.81
[Train] Epoch: 2 [20608/620022]    Loss: 0.007544   Batch Acc: 84.38
[Train] Epoch: 2 [20672/620022]    Loss: 0.010594   Batch Acc: 70.31
[Train] Epoch: 2 [20736/620022]    Loss: 0.008347   Batch Acc: 76.56
[Train] Epoch: 2 [20800/620022]    Loss: 0.007855   Batch Acc: 84.38
[Train] Epoch: 2 [20864/620022]    Loss: 0.011988   Batch Acc: 68.75
[Train] Epoch: 2 [20928/620022]    Loss: 0.009080   Batch Acc: 75.00
[Train] Epoch: 2 [20992/620022]    Loss: 0.011790   Batch Acc: 62.50
[Train] Epoch: 2 [21056/620022]    Loss: 0.009976   Batch Acc: 73.44
[Train] Epoch: 2 [21120/620022]    Loss: 0.007012   Batch Acc: 85.94
[Train] Epoch: 2 [21184/620022]    Loss: 0.007738   Batch Acc: 78.12
[Train] Epoch: 2 [21248/620022]    Loss: 0.009889   Batch Acc: 78.12
[Train] Epoch: 2 [21312/620022]    Loss: 0.007609   Batch Acc: 82.81
[Train] Epoch: 2 [21376/620022]    Loss: 0.008957   Batch Acc: 68.75
[Train] Epoch: 2 [21440/620022]    Loss: 0.007810   Batch Acc: 75.00
[Train] Epoch: 2 [21504/620022]    Loss: 0.007488   Batch Acc: 79.69
[Train] Epoch: 2 [21568/620022]    Loss: 0.009406   Batch Acc: 75.00
[Train] Epoch: 2 [21632/620022]    Loss: 0.009654   Batch Acc: 78.12
[Train] Epoch: 2 [21696/620022]    Loss: 0.008342   Batch Acc: 84.38
[Train] Epoch: 2 [21760/620022]    Loss: 0.010696   Batch Acc: 70.31
[Train] Epoch: 2 [21824/620022]    Loss: 0.008702   Batch Acc: 78.12
[Train] Epoch: 2 [21888/620022]    Loss: 0.009134   Batch Acc: 78.12
[Train] Epoch: 2 [21952/620022]    Loss: 0.008211   Batch Acc: 82.81
[Train] Epoch: 2 [22016/620022]    Loss: 0.008852   Batch Acc: 73.44
[Train] Epoch: 2 [22080/620022]    Loss: 0.008455   Batch Acc: 76.56
[Train] Epoch: 2 [22144/620022]    Loss: 0.007484   Batch Acc: 84.38
[Train] Epoch: 2 [22208/620022]    Loss: 0.010340   Batch Acc: 70.31
[Train] Epoch: 2 [22272/620022]    Loss: 0.006782   Batch Acc: 89.06
[Train] Epoch: 2 [22336/620022]    Loss: 0.007971   Batch Acc: 79.69
[Train] Epoch: 2 [22400/620022]    Loss: 0.009703   Batch Acc: 71.88
[Train] Epoch: 2 [22464/620022]    Loss: 0.007727   Batch Acc: 82.81
[Train] Epoch: 2 [22528/620022]    Loss: 0.006339   Batch Acc: 82.81
[Train] Epoch: 2 [22592/620022]    Loss: 0.009440   Batch Acc: 73.44
[Train] Epoch: 2 [22656/620022]    Loss: 0.008715   Batch Acc: 79.69
[Train] Epoch: 2 [22720/620022]    Loss: 0.007104   Batch Acc: 79.69
[Train] Epoch: 2 [22784/620022]    Loss: 0.009074   Batch Acc: 75.00
[Train] Epoch: 2 [22848/620022]    Loss: 0.007541   Batch Acc: 79.69
[Train] Epoch: 2 [22912/620022]    Loss: 0.009375   Batch Acc: 75.00
[Train] Epoch: 2 [22976/620022]    Loss: 0.009699   Batch Acc: 73.44
[Train] Epoch: 2 [23040/620022]    Loss: 0.008711   Batch Acc: 78.12
[Train] Epoch: 2 [23104/620022]    Loss: 0.009384   Batch Acc: 78.12
[Train] Epoch: 2 [23168/620022]    Loss: 0.007426   Batch Acc: 79.69
[Train] Epoch: 2 [23232/620022]    Loss: 0.008924   Batch Acc: 75.00
[Train] Epoch: 2 [23296/620022]    Loss: 0.010608   Batch Acc: 75.00
[Train] Epoch: 2 [23360/620022]    Loss: 0.007499   Batch Acc: 84.38
[Train] Epoch: 2 [23424/620022]    Loss: 0.007322   Batch Acc: 75.00
[Train] Epoch: 2 [23488/620022]    Loss: 0.008410   Batch Acc: 79.69
[Train] Epoch: 2 [23552/620022]    Loss: 0.007987   Batch Acc: 76.56
[Train] Epoch: 2 [23616/620022]    Loss: 0.006194   Batch Acc: 87.50
[Train] Epoch: 2 [23680/620022]    Loss: 0.008985   Batch Acc: 73.44
[Train] Epoch: 2 [23744/620022]    Loss: 0.006900   Batch Acc: 76.56
[Train] Epoch: 2 [23808/620022]    Loss: 0.009280   Batch Acc: 71.88
[Train] Epoch: 2 [23872/620022]    Loss: 0.009740   Batch Acc: 81.25
[Train] Epoch: 2 [23936/620022]    Loss: 0.007103   Batch Acc: 87.50
[Train] Epoch: 2 [24000/620022]    Loss: 0.007080   Batch Acc: 85.94
[Train] Epoch: 2 [24064/620022]    Loss: 0.007546   Batch Acc: 81.25
[Train] Epoch: 2 [24128/620022]    Loss: 0.007754   Batch Acc: 84.38
[Train] Epoch: 2 [24192/620022]    Loss: 0.010365   Batch Acc: 70.31
[Train] Epoch: 2 [24256/620022]    Loss: 0.008134   Batch Acc: 81.25
[Train] Epoch: 2 [24320/620022]    Loss: 0.008441   Batch Acc: 78.12
[Train] Epoch: 2 [24384/620022]    Loss: 0.007712   Batch Acc: 81.25
[Train] Epoch: 2 [24448/620022]    Loss: 0.007740   Batch Acc: 82.81
[Train] Epoch: 2 [24512/620022]    Loss: 0.007502   Batch Acc: 87.50
[Train] Epoch: 2 [24576/620022]    Loss: 0.010462   Batch Acc: 67.19
[Train] Epoch: 2 [24640/620022]    Loss: 0.011073   Batch Acc: 73.44
[Train] Epoch: 2 [24704/620022]    Loss: 0.011057   Batch Acc: 73.44
[Train] Epoch: 2 [24768/620022]    Loss: 0.008308   Batch Acc: 84.38
[Train] Epoch: 2 [24832/620022]    Loss: 0.008738   Batch Acc: 76.56
[Train] Epoch: 2 [24896/620022]    Loss: 0.007348   Batch Acc: 81.25
[Train] Epoch: 2 [24960/620022]    Loss: 0.008426   Batch Acc: 79.69
[Train] Epoch: 2 [25024/620022]    Loss: 0.008800   Batch Acc: 76.56
[Train] Epoch: 2 [25088/620022]    Loss: 0.009080   Batch Acc: 78.12
[Train] Epoch: 2 [25152/620022]    Loss: 0.007676   Batch Acc: 81.25
[Train] Epoch: 2 [25216/620022]    Loss: 0.009144   Batch Acc: 81.25
[Train] Epoch: 2 [25280/620022]    Loss: 0.008826   Batch Acc: 82.81
[Train] Epoch: 2 [25344/620022]    Loss: 0.013103   Batch Acc: 67.19
[Train] Epoch: 2 [25408/620022]    Loss: 0.008403   Batch Acc: 81.25
[Train] Epoch: 2 [25472/620022]    Loss: 0.005768   Batch Acc: 87.50
[Train] Epoch: 2 [25536/620022]    Loss: 0.009115   Batch Acc: 75.00
[Train] Epoch: 2 [25600/620022]    Loss: 0.008856   Batch Acc: 78.12
[Train] Epoch: 2 [25664/620022]    Loss: 0.006794   Batch Acc: 81.25
[Train] Epoch: 2 [25728/620022]    Loss: 0.006202   Batch Acc: 85.94
[Train] Epoch: 2 [25792/620022]    Loss: 0.012522   Batch Acc: 67.19
[Train] Epoch: 2 [25856/620022]    Loss: 0.010169   Batch Acc: 73.44
[Train] Epoch: 2 [25920/620022]    Loss: 0.008986   Batch Acc: 75.00
[Train] Epoch: 2 [25984/620022]    Loss: 0.009388   Batch Acc: 79.69
[Train] Epoch: 2 [26048/620022]    Loss: 0.008239   Batch Acc: 78.12
[Train] Epoch: 2 [26112/620022]    Loss: 0.008252   Batch Acc: 76.56
[Train] Epoch: 2 [26176/620022]    Loss: 0.008196   Batch Acc: 78.12
[Train] Epoch: 2 [26240/620022]    Loss: 0.006964   Batch Acc: 81.25
[Train] Epoch: 2 [26304/620022]    Loss: 0.008769   Batch Acc: 82.81
[Train] Epoch: 2 [26368/620022]    Loss: 0.007130   Batch Acc: 82.81
[Train] Epoch: 2 [26432/620022]    Loss: 0.007878   Batch Acc: 82.81
[Train] Epoch: 2 [26496/620022]    Loss: 0.007530   Batch Acc: 84.38
[Train] Epoch: 2 [26560/620022]    Loss: 0.010785   Batch Acc: 70.31
[Train] Epoch: 2 [26624/620022]    Loss: 0.006858   Batch Acc: 84.38
[Train] Epoch: 2 [26688/620022]    Loss: 0.009729   Batch Acc: 70.31
[Train] Epoch: 2 [26752/620022]    Loss: 0.008205   Batch Acc: 81.25
[Train] Epoch: 2 [26816/620022]    Loss: 0.008671   Batch Acc: 78.12
[Train] Epoch: 2 [26880/620022]    Loss: 0.008260   Batch Acc: 79.69
[Train] Epoch: 2 [26944/620022]    Loss: 0.008373   Batch Acc: 82.81
[Train] Epoch: 2 [27008/620022]    Loss: 0.007789   Batch Acc: 82.81
[Train] Epoch: 2 [27072/620022]    Loss: 0.007608   Batch Acc: 81.25
[Train] Epoch: 2 [27136/620022]    Loss: 0.007839   Batch Acc: 75.00
[Train] Epoch: 2 [27200/620022]    Loss: 0.008839   Batch Acc: 81.25
[Train] Epoch: 2 [27264/620022]    Loss: 0.008225   Batch Acc: 78.12
[Train] Epoch: 2 [27328/620022]    Loss: 0.006609   Batch Acc: 76.56
[Train] Epoch: 2 [27392/620022]    Loss: 0.008200   Batch Acc: 81.25
[Train] Epoch: 2 [27456/620022]    Loss: 0.006596   Batch Acc: 84.38
[Train] Epoch: 2 [27520/620022]    Loss: 0.008353   Batch Acc: 73.44
[Train] Epoch: 2 [27584/620022]    Loss: 0.008174   Batch Acc: 79.69
[Train] Epoch: 2 [27648/620022]    Loss: 0.008077   Batch Acc: 78.12
[Train] Epoch: 2 [27712/620022]    Loss: 0.010093   Batch Acc: 70.31
[Train] Epoch: 2 [27776/620022]    Loss: 0.006443   Batch Acc: 92.19
[Train] Epoch: 2 [27840/620022]    Loss: 0.009609   Batch Acc: 78.12
[Train] Epoch: 2 [27904/620022]    Loss: 0.008415   Batch Acc: 79.69
[Train] Epoch: 2 [27968/620022]    Loss: 0.010181   Batch Acc: 78.12
[Train] Epoch: 2 [28032/620022]    Loss: 0.009562   Batch Acc: 75.00
[Train] Epoch: 2 [28096/620022]    Loss: 0.009816   Batch Acc: 73.44
[Train] Epoch: 2 [28160/620022]    Loss: 0.010852   Batch Acc: 78.12
[Train] Epoch: 2 [28224/620022]    Loss: 0.006916   Batch Acc: 87.50
[Train] Epoch: 2 [28288/620022]    Loss: 0.008016   Batch Acc: 79.69
[Train] Epoch: 2 [28352/620022]    Loss: 0.006715   Batch Acc: 79.69
[Train] Epoch: 2 [28416/620022]    Loss: 0.005489   Batch Acc: 89.06
[Train] Epoch: 2 [28480/620022]    Loss: 0.008512   Batch Acc: 78.12
[Train] Epoch: 2 [28544/620022]    Loss: 0.009384   Batch Acc: 75.00
[Train] Epoch: 2 [28608/620022]    Loss: 0.009224   Batch Acc: 68.75
[Train] Epoch: 2 [28672/620022]    Loss: 0.009040   Batch Acc: 79.69
[Train] Epoch: 2 [28736/620022]    Loss: 0.010314   Batch Acc: 73.44
[Train] Epoch: 2 [28800/620022]    Loss: 0.007445   Batch Acc: 78.12
[Train] Epoch: 2 [28864/620022]    Loss: 0.008701   Batch Acc: 81.25
[Train] Epoch: 2 [28928/620022]    Loss: 0.009290   Batch Acc: 76.56
[Train] Epoch: 2 [28992/620022]    Loss: 0.008036   Batch Acc: 81.25
[Train] Epoch: 2 [29056/620022]    Loss: 0.010111   Batch Acc: 76.56
[Train] Epoch: 2 [29120/620022]    Loss: 0.009807   Batch Acc: 76.56
[Train] Epoch: 2 [29184/620022]    Loss: 0.011935   Batch Acc: 71.88
[Train] Epoch: 2 [29248/620022]    Loss: 0.008460   Batch Acc: 81.25
[Train] Epoch: 2 [29312/620022]    Loss: 0.010221   Batch Acc: 76.56
[Train] Epoch: 2 [29376/620022]    Loss: 0.008727   Batch Acc: 78.12
[Train] Epoch: 2 [29440/620022]    Loss: 0.009050   Batch Acc: 81.25
[Train] Epoch: 2 [29504/620022]    Loss: 0.007928   Batch Acc: 84.38
[Train] Epoch: 2 [29568/620022]    Loss: 0.009782   Batch Acc: 71.88
[Train] Epoch: 2 [29632/620022]    Loss: 0.008865   Batch Acc: 75.00
[Train] Epoch: 2 [29696/620022]    Loss: 0.008242   Batch Acc: 78.12
[Train] Epoch: 2 [29760/620022]    Loss: 0.008917   Batch Acc: 78.12
[Train] Epoch: 2 [29824/620022]    Loss: 0.008778   Batch Acc: 73.44
[Train] Epoch: 2 [29888/620022]    Loss: 0.007470   Batch Acc: 81.25
[Train] Epoch: 2 [29952/620022]    Loss: 0.006698   Batch Acc: 82.81
[Train] Epoch: 2 [30016/620022]    Loss: 0.007635   Batch Acc: 79.69
[Train] Epoch: 2 [30080/620022]    Loss: 0.007673   Batch Acc: 82.81
[Train] Epoch: 2 [30144/620022]    Loss: 0.009979   Batch Acc: 70.31
[Train] Epoch: 2 [30208/620022]    Loss: 0.008717   Batch Acc: 79.69
[Train] Epoch: 2 [30272/620022]    Loss: 0.009240   Batch Acc: 73.44
[Train] Epoch: 2 [30336/620022]    Loss: 0.007930   Batch Acc: 82.81
[Train] Epoch: 2 [30400/620022]    Loss: 0.007421   Batch Acc: 78.12
[Train] Epoch: 2 [30464/620022]    Loss: 0.007979   Batch Acc: 76.56
[Train] Epoch: 2 [30528/620022]    Loss: 0.008220   Batch Acc: 73.44
[Train] Epoch: 2 [30592/620022]    Loss: 0.009052   Batch Acc: 70.31
[Train] Epoch: 2 [30656/620022]    Loss: 0.010923   Batch Acc: 75.00
[Train] Epoch: 2 [30720/620022]    Loss: 0.008498   Batch Acc: 76.56
[Train] Epoch: 2 [30784/620022]    Loss: 0.009740   Batch Acc: 73.44
[Train] Epoch: 2 [30848/620022]    Loss: 0.007180   Batch Acc: 79.69
[Train] Epoch: 2 [30912/620022]    Loss: 0.006089   Batch Acc: 84.38
[Train] Epoch: 2 [30976/620022]    Loss: 0.009455   Batch Acc: 76.56
[Train] Epoch: 2 [31040/620022]    Loss: 0.009785   Batch Acc: 73.44
[Train] Epoch: 2 [31104/620022]    Loss: 0.011420   Batch Acc: 75.00
[Train] Epoch: 2 [31168/620022]    Loss: 0.007417   Batch Acc: 82.81
[Train] Epoch: 2 [31232/620022]    Loss: 0.008243   Batch Acc: 79.69
[Train] Epoch: 2 [31296/620022]    Loss: 0.009261   Batch Acc: 73.44
[Train] Epoch: 2 [31360/620022]    Loss: 0.010368   Batch Acc: 65.62
[Train] Epoch: 2 [31424/620022]    Loss: 0.006708   Batch Acc: 85.94
[Train] Epoch: 2 [31488/620022]    Loss: 0.009436   Batch Acc: 79.69
[Train] Epoch: 2 [31552/620022]    Loss: 0.005379   Batch Acc: 93.75
[Train] Epoch: 2 [31616/620022]    Loss: 0.010473   Batch Acc: 70.31
[Train] Epoch: 2 [31680/620022]    Loss: 0.008470   Batch Acc: 78.12
[Train] Epoch: 2 [31744/620022]    Loss: 0.011506   Batch Acc: 60.94
[Train] Epoch: 2 [31808/620022]    Loss: 0.011472   Batch Acc: 68.75
[Train] Epoch: 2 [31872/620022]    Loss: 0.010044   Batch Acc: 67.19
[Train] Epoch: 2 [31936/620022]    Loss: 0.008965   Batch Acc: 79.69
[Train] Epoch: 2 [32000/620022]    Loss: 0.007623   Batch Acc: 81.25
[Train] Epoch: 2 [32064/620022]    Loss: 0.008401   Batch Acc: 76.56
[Train] Epoch: 2 [32128/620022]    Loss: 0.011703   Batch Acc: 64.06
[Train] Epoch: 2 [32192/620022]    Loss: 0.008168   Batch Acc: 79.69
[Train] Epoch: 2 [32256/620022]    Loss: 0.008470   Batch Acc: 79.69
[Train] Epoch: 2 [32320/620022]    Loss: 0.008981   Batch Acc: 78.12
[Train] Epoch: 2 [32384/620022]    Loss: 0.006848   Batch Acc: 81.25
[Train] Epoch: 2 [32448/620022]    Loss: 0.007408   Batch Acc: 78.12
[Train] Epoch: 2 [32512/620022]    Loss: 0.009401   Batch Acc: 75.00
[Train] Epoch: 2 [32576/620022]    Loss: 0.008377   Batch Acc: 76.56
[Train] Epoch: 2 [32640/620022]    Loss: 0.010202   Batch Acc: 71.88
[Train] Epoch: 2 [32704/620022]    Loss: 0.011033   Batch Acc: 71.88
[Train] Epoch: 2 [32768/620022]    Loss: 0.009188   Batch Acc: 79.69
[Train] Epoch: 2 [32832/620022]    Loss: 0.008328   Batch Acc: 79.69
[Train] Epoch: 2 [32896/620022]    Loss: 0.007263   Batch Acc: 82.81
[Train] Epoch: 2 [32960/620022]    Loss: 0.009224   Batch Acc: 76.56
[Train] Epoch: 2 [33024/620022]    Loss: 0.007008   Batch Acc: 79.69
[Train] Epoch: 2 [33088/620022]    Loss: 0.009734   Batch Acc: 71.88
[Train] Epoch: 2 [33152/620022]    Loss: 0.009968   Batch Acc: 67.19
[Train] Epoch: 2 [33216/620022]    Loss: 0.010107   Batch Acc: 79.69
[Train] Epoch: 2 [33280/620022]    Loss: 0.008721   Batch Acc: 76.56
[Train] Epoch: 2 [33344/620022]    Loss: 0.008715   Batch Acc: 78.12
[Train] Epoch: 2 [33408/620022]    Loss: 0.008750   Batch Acc: 79.69
[Train] Epoch: 2 [33472/620022]    Loss: 0.008503   Batch Acc: 79.69
[Train] Epoch: 2 [33536/620022]    Loss: 0.010275   Batch Acc: 70.31
[Train] Epoch: 2 [33600/620022]    Loss: 0.010098   Batch Acc: 71.88
[Train] Epoch: 2 [33664/620022]    Loss: 0.011020   Batch Acc: 73.44
[Train] Epoch: 2 [33728/620022]    Loss: 0.007293   Batch Acc: 82.81
[Train] Epoch: 2 [33792/620022]    Loss: 0.006611   Batch Acc: 87.50
[Train] Epoch: 2 [33856/620022]    Loss: 0.010387   Batch Acc: 75.00
[Train] Epoch: 2 [33920/620022]    Loss: 0.008365   Batch Acc: 82.81
[Train] Epoch: 2 [33984/620022]    Loss: 0.011517   Batch Acc: 68.75
[Train] Epoch: 2 [34048/620022]    Loss: 0.009270   Batch Acc: 76.56
[Train] Epoch: 2 [34112/620022]    Loss: 0.008721   Batch Acc: 75.00
[Train] Epoch: 2 [34176/620022]    Loss: 0.009978   Batch Acc: 76.56
[Train] Epoch: 2 [34240/620022]    Loss: 0.007497   Batch Acc: 82.81
[Train] Epoch: 2 [34304/620022]    Loss: 0.007986   Batch Acc: 84.38
[Train] Epoch: 2 [34368/620022]    Loss: 0.007694   Batch Acc: 79.69
[Train] Epoch: 2 [34432/620022]    Loss: 0.007642   Batch Acc: 78.12
[Train] Epoch: 2 [34496/620022]    Loss: 0.008087   Batch Acc: 76.56
[Train] Epoch: 2 [34560/620022]    Loss: 0.010016   Batch Acc: 73.44
[Train] Epoch: 2 [34624/620022]    Loss: 0.008788   Batch Acc: 84.38
[Train] Epoch: 2 [34688/620022]    Loss: 0.011409   Batch Acc: 62.50
[Train] Epoch: 2 [34752/620022]    Loss: 0.008670   Batch Acc: 78.12
[Train] Epoch: 2 [34816/620022]    Loss: 0.007395   Batch Acc: 76.56
[Train] Epoch: 2 [34880/620022]    Loss: 0.007453   Batch Acc: 85.94
[Train] Epoch: 2 [34944/620022]    Loss: 0.006619   Batch Acc: 87.50
[Train] Epoch: 2 [35008/620022]    Loss: 0.011063   Batch Acc: 70.31
[Train] Epoch: 2 [35072/620022]    Loss: 0.008284   Batch Acc: 79.69
[Train] Epoch: 2 [35136/620022]    Loss: 0.009330   Batch Acc: 71.88
[Train] Epoch: 2 [35200/620022]    Loss: 0.007449   Batch Acc: 81.25
[Train] Epoch: 2 [35264/620022]    Loss: 0.008347   Batch Acc: 78.12
[Train] Epoch: 2 [35328/620022]    Loss: 0.009065   Batch Acc: 76.56
[Train] Epoch: 2 [35392/620022]    Loss: 0.008858   Batch Acc: 81.25
[Train] Epoch: 2 [35456/620022]    Loss: 0.007391   Batch Acc: 75.00
[Train] Epoch: 2 [35520/620022]    Loss: 0.009106   Batch Acc: 78.12
[Train] Epoch: 2 [35584/620022]    Loss: 0.008978   Batch Acc: 78.12
[Train] Epoch: 2 [35648/620022]    Loss: 0.008917   Batch Acc: 71.88
[Train] Epoch: 2 [35712/620022]    Loss: 0.007617   Batch Acc: 78.12
[Train] Epoch: 2 [35776/620022]    Loss: 0.008627   Batch Acc: 78.12
[Train] Epoch: 2 [35840/620022]    Loss: 0.008829   Batch Acc: 76.56
[Train] Epoch: 2 [35904/620022]    Loss: 0.007278   Batch Acc: 81.25
[Train] Epoch: 2 [35968/620022]    Loss: 0.010679   Batch Acc: 70.31
[Train] Epoch: 2 [36032/620022]    Loss: 0.008676   Batch Acc: 75.00
[Train] Epoch: 2 [36096/620022]    Loss: 0.008287   Batch Acc: 79.69
[Train] Epoch: 2 [36160/620022]    Loss: 0.009109   Batch Acc: 71.88
[Train] Epoch: 2 [36224/620022]    Loss: 0.008760   Batch Acc: 75.00
[Train] Epoch: 2 [36288/620022]    Loss: 0.011245   Batch Acc: 65.62
[Train] Epoch: 2 [36352/620022]    Loss: 0.010371   Batch Acc: 68.75
[Train] Epoch: 2 [36416/620022]    Loss: 0.010115   Batch Acc: 70.31
[Train] Epoch: 2 [36480/620022]    Loss: 0.007541   Batch Acc: 85.94
[Train] Epoch: 2 [36544/620022]    Loss: 0.012496   Batch Acc: 68.75
[Train] Epoch: 2 [36608/620022]    Loss: 0.008791   Batch Acc: 79.69
[Train] Epoch: 2 [36672/620022]    Loss: 0.007834   Batch Acc: 78.12
[Train] Epoch: 2 [36736/620022]    Loss: 0.008234   Batch Acc: 79.69
[Train] Epoch: 2 [36800/620022]    Loss: 0.008449   Batch Acc: 78.12
[Train] Epoch: 2 [36864/620022]    Loss: 0.009109   Batch Acc: 78.12
[Train] Epoch: 2 [36928/620022]    Loss: 0.009439   Batch Acc: 78.12
[Train] Epoch: 2 [36992/620022]    Loss: 0.009659   Batch Acc: 76.56
[Train] Epoch: 2 [37056/620022]    Loss: 0.009590   Batch Acc: 76.56
[Train] Epoch: 2 [37120/620022]    Loss: 0.007644   Batch Acc: 79.69
[Train] Epoch: 2 [37184/620022]    Loss: 0.009468   Batch Acc: 70.31
[Train] Epoch: 2 [37248/620022]    Loss: 0.008156   Batch Acc: 79.69
[Train] Epoch: 2 [37312/620022]    Loss: 0.007612   Batch Acc: 82.81
[Train] Epoch: 2 [37376/620022]    Loss: 0.009881   Batch Acc: 73.44
[Train] Epoch: 2 [37440/620022]    Loss: 0.007262   Batch Acc: 82.81
[Train] Epoch: 2 [37504/620022]    Loss: 0.008215   Batch Acc: 78.12
[Train] Epoch: 2 [37568/620022]    Loss: 0.007656   Batch Acc: 84.38
[Train] Epoch: 2 [37632/620022]    Loss: 0.009985   Batch Acc: 67.19
[Train] Epoch: 2 [37696/620022]    Loss: 0.007849   Batch Acc: 78.12
[Train] Epoch: 2 [37760/620022]    Loss: 0.009267   Batch Acc: 73.44
[Train] Epoch: 2 [37824/620022]    Loss: 0.008274   Batch Acc: 79.69
[Train] Epoch: 2 [37888/620022]    Loss: 0.008591   Batch Acc: 81.25
[Train] Epoch: 2 [37952/620022]    Loss: 0.010253   Batch Acc: 78.12
[Train] Epoch: 2 [38016/620022]    Loss: 0.006502   Batch Acc: 89.06
[Train] Epoch: 2 [38080/620022]    Loss: 0.010149   Batch Acc: 75.00
[Train] Epoch: 2 [38144/620022]    Loss: 0.010622   Batch Acc: 78.12
[Train] Epoch: 2 [38208/620022]    Loss: 0.007303   Batch Acc: 81.25
[Train] Epoch: 2 [38272/620022]    Loss: 0.007326   Batch Acc: 82.81
[Train] Epoch: 2 [38336/620022]    Loss: 0.009460   Batch Acc: 75.00
[Train] Epoch: 2 [38400/620022]    Loss: 0.008047   Batch Acc: 75.00
[Train] Epoch: 2 [38464/620022]    Loss: 0.008646   Batch Acc: 76.56
[Train] Epoch: 2 [38528/620022]    Loss: 0.009175   Batch Acc: 75.00
[Train] Epoch: 2 [38592/620022]    Loss: 0.007758   Batch Acc: 82.81
[Train] Epoch: 2 [38656/620022]    Loss: 0.014363   Batch Acc: 62.50
[Train] Epoch: 2 [38720/620022]    Loss: 0.009811   Batch Acc: 76.56
[Train] Epoch: 2 [38784/620022]    Loss: 0.008654   Batch Acc: 81.25
[Train] Epoch: 2 [38848/620022]    Loss: 0.009431   Batch Acc: 71.88
[Train] Epoch: 2 [38912/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 2 [38976/620022]    Loss: 0.007740   Batch Acc: 78.12
[Train] Epoch: 2 [39040/620022]    Loss: 0.009713   Batch Acc: 73.44
[Train] Epoch: 2 [39104/620022]    Loss: 0.010539   Batch Acc: 67.19
[Train] Epoch: 2 [39168/620022]    Loss: 0.006762   Batch Acc: 87.50
[Train] Epoch: 2 [39232/620022]    Loss: 0.006833   Batch Acc: 82.81
[Train] Epoch: 2 [39296/620022]    Loss: 0.009783   Batch Acc: 76.56
[Train] Epoch: 2 [39360/620022]    Loss: 0.008841   Batch Acc: 73.44
[Train] Epoch: 2 [39424/620022]    Loss: 0.008599   Batch Acc: 79.69
[Train] Epoch: 2 [39488/620022]    Loss: 0.008925   Batch Acc: 76.56
[Train] Epoch: 2 [39552/620022]    Loss: 0.009144   Batch Acc: 78.12
[Train] Epoch: 2 [39616/620022]    Loss: 0.006800   Batch Acc: 85.94
[Train] Epoch: 2 [39680/620022]    Loss: 0.007121   Batch Acc: 85.94
[Train] Epoch: 2 [39744/620022]    Loss: 0.009201   Batch Acc: 82.81
[Train] Epoch: 2 [39808/620022]    Loss: 0.009803   Batch Acc: 79.69
[Train] Epoch: 2 [39872/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 2 [39936/620022]    Loss: 0.009420   Batch Acc: 78.12
[Train] Epoch: 2 [40000/620022]    Loss: 0.008818   Batch Acc: 76.56
[Train] Epoch: 2 [40064/620022]    Loss: 0.007716   Batch Acc: 82.81
[Train] Epoch: 2 [40128/620022]    Loss: 0.007371   Batch Acc: 81.25
[Train] Epoch: 2 [40192/620022]    Loss: 0.008355   Batch Acc: 84.38
[Train] Epoch: 2 [40256/620022]    Loss: 0.008714   Batch Acc: 78.12
[Train] Epoch: 2 [40320/620022]    Loss: 0.006444   Batch Acc: 85.94
[Train] Epoch: 2 [40384/620022]    Loss: 0.007301   Batch Acc: 84.38
[Train] Epoch: 2 [40448/620022]    Loss: 0.009835   Batch Acc: 76.56
[Train] Epoch: 2 [40512/620022]    Loss: 0.009631   Batch Acc: 73.44
[Train] Epoch: 2 [40576/620022]    Loss: 0.008767   Batch Acc: 76.56
[Train] Epoch: 2 [40640/620022]    Loss: 0.007290   Batch Acc: 79.69
[Train] Epoch: 2 [40704/620022]    Loss: 0.009524   Batch Acc: 71.88
[Train] Epoch: 2 [40768/620022]    Loss: 0.007574   Batch Acc: 84.38
[Train] Epoch: 2 [40832/620022]    Loss: 0.010993   Batch Acc: 67.19
[Train] Epoch: 2 [40896/620022]    Loss: 0.010181   Batch Acc: 70.31
[Train] Epoch: 2 [40960/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 2 [41024/620022]    Loss: 0.011503   Batch Acc: 68.75
[Train] Epoch: 2 [41088/620022]    Loss: 0.008446   Batch Acc: 81.25
[Train] Epoch: 2 [41152/620022]    Loss: 0.007725   Batch Acc: 79.69
[Train] Epoch: 2 [41216/620022]    Loss: 0.007722   Batch Acc: 84.38
[Train] Epoch: 2 [41280/620022]    Loss: 0.007854   Batch Acc: 79.69
[Train] Epoch: 2 [41344/620022]    Loss: 0.006557   Batch Acc: 85.94
[Train] Epoch: 2 [41408/620022]    Loss: 0.007629   Batch Acc: 84.38
[Train] Epoch: 2 [41472/620022]    Loss: 0.007825   Batch Acc: 85.94
[Train] Epoch: 2 [41536/620022]    Loss: 0.011122   Batch Acc: 75.00
[Train] Epoch: 2 [41600/620022]    Loss: 0.007861   Batch Acc: 75.00
[Train] Epoch: 2 [41664/620022]    Loss: 0.009810   Batch Acc: 71.88
[Train] Epoch: 2 [41728/620022]    Loss: 0.007623   Batch Acc: 79.69
[Train] Epoch: 2 [41792/620022]    Loss: 0.009910   Batch Acc: 73.44
[Train] Epoch: 2 [41856/620022]    Loss: 0.007974   Batch Acc: 76.56
[Train] Epoch: 2 [41920/620022]    Loss: 0.008563   Batch Acc: 81.25
[Train] Epoch: 2 [41984/620022]    Loss: 0.009282   Batch Acc: 73.44
[Train] Epoch: 2 [42048/620022]    Loss: 0.006214   Batch Acc: 90.62
[Train] Epoch: 2 [42112/620022]    Loss: 0.009568   Batch Acc: 78.12
[Train] Epoch: 2 [42176/620022]    Loss: 0.008653   Batch Acc: 79.69
[Train] Epoch: 2 [42240/620022]    Loss: 0.009031   Batch Acc: 76.56
[Train] Epoch: 2 [42304/620022]    Loss: 0.008313   Batch Acc: 78.12
[Train] Epoch: 2 [42368/620022]    Loss: 0.008659   Batch Acc: 79.69
[Train] Epoch: 2 [42432/620022]    Loss: 0.008345   Batch Acc: 78.12
[Train] Epoch: 2 [42496/620022]    Loss: 0.008365   Batch Acc: 85.94
[Train] Epoch: 2 [42560/620022]    Loss: 0.010939   Batch Acc: 73.44
[Train] Epoch: 2 [42624/620022]    Loss: 0.010293   Batch Acc: 70.31
[Train] Epoch: 2 [42688/620022]    Loss: 0.007677   Batch Acc: 81.25
[Train] Epoch: 2 [42752/620022]    Loss: 0.009559   Batch Acc: 78.12
[Train] Epoch: 2 [42816/620022]    Loss: 0.010002   Batch Acc: 68.75
[Train] Epoch: 2 [42880/620022]    Loss: 0.009033   Batch Acc: 76.56
[Train] Epoch: 2 [42944/620022]    Loss: 0.009917   Batch Acc: 73.44
[Train] Epoch: 2 [43008/620022]    Loss: 0.009581   Batch Acc: 79.69
[Train] Epoch: 2 [43072/620022]    Loss: 0.006790   Batch Acc: 84.38
[Train] Epoch: 2 [43136/620022]    Loss: 0.009213   Batch Acc: 73.44
[Train] Epoch: 2 [43200/620022]    Loss: 0.009190   Batch Acc: 73.44
[Train] Epoch: 2 [43264/620022]    Loss: 0.006857   Batch Acc: 87.50
[Train] Epoch: 2 [43328/620022]    Loss: 0.010427   Batch Acc: 71.88
[Train] Epoch: 2 [43392/620022]    Loss: 0.009877   Batch Acc: 76.56
[Train] Epoch: 2 [43456/620022]    Loss: 0.008667   Batch Acc: 79.69
[Train] Epoch: 2 [43520/620022]    Loss: 0.009388   Batch Acc: 75.00
[Train] Epoch: 2 [43584/620022]    Loss: 0.009934   Batch Acc: 75.00
[Train] Epoch: 2 [43648/620022]    Loss: 0.007953   Batch Acc: 79.69
[Train] Epoch: 2 [43712/620022]    Loss: 0.010454   Batch Acc: 70.31
[Train] Epoch: 2 [43776/620022]    Loss: 0.008029   Batch Acc: 79.69
[Train] Epoch: 2 [43840/620022]    Loss: 0.009364   Batch Acc: 73.44
[Train] Epoch: 2 [43904/620022]    Loss: 0.009546   Batch Acc: 76.56
[Train] Epoch: 2 [43968/620022]    Loss: 0.009698   Batch Acc: 70.31
[Train] Epoch: 2 [44032/620022]    Loss: 0.008767   Batch Acc: 78.12
[Train] Epoch: 2 [44096/620022]    Loss: 0.009773   Batch Acc: 73.44
[Train] Epoch: 2 [44160/620022]    Loss: 0.007102   Batch Acc: 82.81
[Train] Epoch: 2 [44224/620022]    Loss: 0.009525   Batch Acc: 73.44
[Train] Epoch: 2 [44288/620022]    Loss: 0.008564   Batch Acc: 79.69
[Train] Epoch: 2 [44352/620022]    Loss: 0.008589   Batch Acc: 78.12
[Train] Epoch: 2 [44416/620022]    Loss: 0.008751   Batch Acc: 76.56
[Train] Epoch: 2 [44480/620022]    Loss: 0.008713   Batch Acc: 71.88
[Train] Epoch: 2 [44544/620022]    Loss: 0.012834   Batch Acc: 70.31
[Train] Epoch: 2 [44608/620022]    Loss: 0.007563   Batch Acc: 84.38
[Train] Epoch: 2 [44672/620022]    Loss: 0.008302   Batch Acc: 76.56
[Train] Epoch: 2 [44736/620022]    Loss: 0.006798   Batch Acc: 85.94
[Train] Epoch: 2 [44800/620022]    Loss: 0.008133   Batch Acc: 81.25
[Train] Epoch: 2 [44864/620022]    Loss: 0.009470   Batch Acc: 76.56
[Train] Epoch: 2 [44928/620022]    Loss: 0.007597   Batch Acc: 85.94
[Train] Epoch: 2 [44992/620022]    Loss: 0.007402   Batch Acc: 82.81
[Train] Epoch: 2 [45056/620022]    Loss: 0.009524   Batch Acc: 71.88
[Train] Epoch: 2 [45120/620022]    Loss: 0.007601   Batch Acc: 89.06
[Train] Epoch: 2 [45184/620022]    Loss: 0.006031   Batch Acc: 87.50
[Train] Epoch: 2 [45248/620022]    Loss: 0.006998   Batch Acc: 82.81
[Train] Epoch: 2 [45312/620022]    Loss: 0.006993   Batch Acc: 82.81
[Train] Epoch: 2 [45376/620022]    Loss: 0.008382   Batch Acc: 79.69
[Train] Epoch: 2 [45440/620022]    Loss: 0.008926   Batch Acc: 76.56
[Train] Epoch: 2 [45504/620022]    Loss: 0.009187   Batch Acc: 73.44
[Train] Epoch: 2 [45568/620022]    Loss: 0.007587   Batch Acc: 84.38
[Train] Epoch: 2 [45632/620022]    Loss: 0.009147   Batch Acc: 78.12
[Train] Epoch: 2 [45696/620022]    Loss: 0.008273   Batch Acc: 79.69
[Train] Epoch: 2 [45760/620022]    Loss: 0.006770   Batch Acc: 82.81
[Train] Epoch: 2 [45824/620022]    Loss: 0.008839   Batch Acc: 79.69
[Train] Epoch: 2 [45888/620022]    Loss: 0.008985   Batch Acc: 71.88
[Train] Epoch: 2 [45952/620022]    Loss: 0.009859   Batch Acc: 75.00
[Train] Epoch: 2 [46016/620022]    Loss: 0.010541   Batch Acc: 70.31
[Train] Epoch: 2 [46080/620022]    Loss: 0.006582   Batch Acc: 84.38
[Train] Epoch: 2 [46144/620022]    Loss: 0.008770   Batch Acc: 76.56
[Train] Epoch: 2 [46208/620022]    Loss: 0.009008   Batch Acc: 75.00
[Train] Epoch: 2 [46272/620022]    Loss: 0.009475   Batch Acc: 81.25
[Train] Epoch: 2 [46336/620022]    Loss: 0.007872   Batch Acc: 79.69
[Train] Epoch: 2 [46400/620022]    Loss: 0.008683   Batch Acc: 73.44
[Train] Epoch: 2 [46464/620022]    Loss: 0.006947   Batch Acc: 84.38
[Train] Epoch: 2 [46528/620022]    Loss: 0.007955   Batch Acc: 76.56
[Train] Epoch: 2 [46592/620022]    Loss: 0.007302   Batch Acc: 84.38
[Train] Epoch: 2 [46656/620022]    Loss: 0.007659   Batch Acc: 76.56
[Train] Epoch: 2 [46720/620022]    Loss: 0.009999   Batch Acc: 78.12
[Train] Epoch: 2 [46784/620022]    Loss: 0.006415   Batch Acc: 84.38
[Train] Epoch: 2 [46848/620022]    Loss: 0.007735   Batch Acc: 87.50
[Train] Epoch: 2 [46912/620022]    Loss: 0.008954   Batch Acc: 76.56
[Train] Epoch: 2 [46976/620022]    Loss: 0.008115   Batch Acc: 75.00
[Train] Epoch: 2 [47040/620022]    Loss: 0.010965   Batch Acc: 65.62
[Train] Epoch: 2 [47104/620022]    Loss: 0.010670   Batch Acc: 76.56
[Train] Epoch: 2 [47168/620022]    Loss: 0.008302   Batch Acc: 79.69
[Train] Epoch: 2 [47232/620022]    Loss: 0.011467   Batch Acc: 68.75
[Train] Epoch: 2 [47296/620022]    Loss: 0.011204   Batch Acc: 65.62
[Train] Epoch: 2 [47360/620022]    Loss: 0.007723   Batch Acc: 81.25
[Train] Epoch: 2 [47424/620022]    Loss: 0.007268   Batch Acc: 84.38
[Train] Epoch: 2 [47488/620022]    Loss: 0.008152   Batch Acc: 79.69
[Train] Epoch: 2 [47552/620022]    Loss: 0.007733   Batch Acc: 78.12
[Train] Epoch: 2 [47616/620022]    Loss: 0.008540   Batch Acc: 75.00
[Train] Epoch: 2 [47680/620022]    Loss: 0.010568   Batch Acc: 67.19
[Train] Epoch: 2 [47744/620022]    Loss: 0.009336   Batch Acc: 75.00
[Train] Epoch: 2 [47808/620022]    Loss: 0.007176   Batch Acc: 82.81
[Train] Epoch: 2 [47872/620022]    Loss: 0.008599   Batch Acc: 78.12
[Train] Epoch: 2 [47936/620022]    Loss: 0.009354   Batch Acc: 70.31
[Train] Epoch: 2 [48000/620022]    Loss: 0.008366   Batch Acc: 79.69
[Train] Epoch: 2 [48064/620022]    Loss: 0.009898   Batch Acc: 70.31
[Train] Epoch: 2 [48128/620022]    Loss: 0.007465   Batch Acc: 81.25
[Train] Epoch: 2 [48192/620022]    Loss: 0.007984   Batch Acc: 79.69
[Train] Epoch: 2 [48256/620022]    Loss: 0.009395   Batch Acc: 71.88
[Train] Epoch: 2 [48320/620022]    Loss: 0.009622   Batch Acc: 75.00
[Train] Epoch: 2 [48384/620022]    Loss: 0.007178   Batch Acc: 84.38
[Train] Epoch: 2 [48448/620022]    Loss: 0.010152   Batch Acc: 76.56
[Train] Epoch: 2 [48512/620022]    Loss: 0.007807   Batch Acc: 78.12
[Train] Epoch: 2 [48576/620022]    Loss: 0.008590   Batch Acc: 79.69
[Train] Epoch: 2 [48640/620022]    Loss: 0.006000   Batch Acc: 92.19
[Train] Epoch: 2 [48704/620022]    Loss: 0.006635   Batch Acc: 82.81
[Train] Epoch: 2 [48768/620022]    Loss: 0.008595   Batch Acc: 73.44
[Train] Epoch: 2 [48832/620022]    Loss: 0.007479   Batch Acc: 82.81
[Train] Epoch: 2 [48896/620022]    Loss: 0.007707   Batch Acc: 81.25
[Train] Epoch: 2 [48960/620022]    Loss: 0.007315   Batch Acc: 82.81
[Train] Epoch: 2 [49024/620022]    Loss: 0.010284   Batch Acc: 71.88
[Train] Epoch: 2 [49088/620022]    Loss: 0.005793   Batch Acc: 87.50
[Train] Epoch: 2 [49152/620022]    Loss: 0.010829   Batch Acc: 68.75
[Train] Epoch: 2 [49216/620022]    Loss: 0.008568   Batch Acc: 76.56
[Train] Epoch: 2 [49280/620022]    Loss: 0.006513   Batch Acc: 87.50
[Train] Epoch: 2 [49344/620022]    Loss: 0.011525   Batch Acc: 70.31
[Train] Epoch: 2 [49408/620022]    Loss: 0.009804   Batch Acc: 76.56
[Train] Epoch: 2 [49472/620022]    Loss: 0.011248   Batch Acc: 62.50
[Train] Epoch: 2 [49536/620022]    Loss: 0.008001   Batch Acc: 81.25
[Train] Epoch: 2 [49600/620022]    Loss: 0.010070   Batch Acc: 71.88
[Train] Epoch: 2 [49664/620022]    Loss: 0.007544   Batch Acc: 82.81
[Train] Epoch: 2 [49728/620022]    Loss: 0.009065   Batch Acc: 68.75
[Train] Epoch: 2 [49792/620022]    Loss: 0.007506   Batch Acc: 85.94
[Train] Epoch: 2 [49856/620022]    Loss: 0.008436   Batch Acc: 76.56
[Train] Epoch: 2 [49920/620022]    Loss: 0.005714   Batch Acc: 89.06
[Train] Epoch: 2 [49984/620022]    Loss: 0.010617   Batch Acc: 67.19
[Train] Epoch: 2 [50048/620022]    Loss: 0.009056   Batch Acc: 71.88
[Train] Epoch: 2 [50112/620022]    Loss: 0.008847   Batch Acc: 73.44
[Train] Epoch: 2 [50176/620022]    Loss: 0.007404   Batch Acc: 82.81
[Train] Epoch: 2 [50240/620022]    Loss: 0.010148   Batch Acc: 68.75
[Train] Epoch: 2 [50304/620022]    Loss: 0.009558   Batch Acc: 73.44
[Train] Epoch: 2 [50368/620022]    Loss: 0.007543   Batch Acc: 78.12
[Train] Epoch: 2 [50432/620022]    Loss: 0.008570   Batch Acc: 75.00
[Train] Epoch: 2 [50496/620022]    Loss: 0.010409   Batch Acc: 70.31
[Train] Epoch: 2 [50560/620022]    Loss: 0.009229   Batch Acc: 78.12
[Train] Epoch: 2 [50624/620022]    Loss: 0.008140   Batch Acc: 76.56
[Train] Epoch: 2 [50688/620022]    Loss: 0.008748   Batch Acc: 78.12
[Train] Epoch: 2 [50752/620022]    Loss: 0.010064   Batch Acc: 67.19
[Train] Epoch: 2 [50816/620022]    Loss: 0.008867   Batch Acc: 78.12
[Train] Epoch: 2 [50880/620022]    Loss: 0.009023   Batch Acc: 75.00
[Train] Epoch: 2 [50944/620022]    Loss: 0.008079   Batch Acc: 79.69
[Train] Epoch: 2 [51008/620022]    Loss: 0.009146   Batch Acc: 71.88
[Train] Epoch: 2 [51072/620022]    Loss: 0.010612   Batch Acc: 70.31
[Train] Epoch: 2 [51136/620022]    Loss: 0.010120   Batch Acc: 76.56
[Train] Epoch: 2 [51200/620022]    Loss: 0.008062   Batch Acc: 81.25
[Train] Epoch: 2 [51264/620022]    Loss: 0.007827   Batch Acc: 81.25
[Train] Epoch: 2 [51328/620022]    Loss: 0.010003   Batch Acc: 75.00
[Train] Epoch: 2 [51392/620022]    Loss: 0.008671   Batch Acc: 81.25
[Train] Epoch: 2 [51456/620022]    Loss: 0.007641   Batch Acc: 84.38
[Train] Epoch: 2 [51520/620022]    Loss: 0.008575   Batch Acc: 79.69
[Train] Epoch: 2 [51584/620022]    Loss: 0.008923   Batch Acc: 73.44
[Train] Epoch: 2 [51648/620022]    Loss: 0.009454   Batch Acc: 76.56
[Train] Epoch: 2 [51712/620022]    Loss: 0.010978   Batch Acc: 75.00
[Train] Epoch: 2 [51776/620022]    Loss: 0.009264   Batch Acc: 76.56
[Train] Epoch: 2 [51840/620022]    Loss: 0.007664   Batch Acc: 84.38
[Train] Epoch: 2 [51904/620022]    Loss: 0.007900   Batch Acc: 81.25
[Train] Epoch: 2 [51968/620022]    Loss: 0.008401   Batch Acc: 71.88
[Train] Epoch: 2 [52032/620022]    Loss: 0.009893   Batch Acc: 76.56
[Train] Epoch: 2 [52096/620022]    Loss: 0.007940   Batch Acc: 81.25
[Train] Epoch: 2 [52160/620022]    Loss: 0.006501   Batch Acc: 85.94
[Train] Epoch: 2 [52224/620022]    Loss: 0.009526   Batch Acc: 68.75
[Train] Epoch: 2 [52288/620022]    Loss: 0.006264   Batch Acc: 85.94
[Train] Epoch: 2 [52352/620022]    Loss: 0.007063   Batch Acc: 85.94
[Train] Epoch: 2 [52416/620022]    Loss: 0.010847   Batch Acc: 70.31
[Train] Epoch: 2 [52480/620022]    Loss: 0.008470   Batch Acc: 76.56
[Train] Epoch: 2 [52544/620022]    Loss: 0.006779   Batch Acc: 82.81
[Train] Epoch: 2 [52608/620022]    Loss: 0.010300   Batch Acc: 68.75
[Train] Epoch: 2 [52672/620022]    Loss: 0.007879   Batch Acc: 78.12
[Train] Epoch: 2 [52736/620022]    Loss: 0.009698   Batch Acc: 78.12
[Train] Epoch: 2 [52800/620022]    Loss: 0.006504   Batch Acc: 85.94
[Train] Epoch: 2 [52864/620022]    Loss: 0.011298   Batch Acc: 67.19
[Train] Epoch: 2 [52928/620022]    Loss: 0.009847   Batch Acc: 75.00
[Train] Epoch: 2 [52992/620022]    Loss: 0.009309   Batch Acc: 79.69
[Train] Epoch: 2 [53056/620022]    Loss: 0.005668   Batch Acc: 82.81
[Train] Epoch: 2 [53120/620022]    Loss: 0.009129   Batch Acc: 68.75
[Train] Epoch: 2 [53184/620022]    Loss: 0.008248   Batch Acc: 78.12
[Train] Epoch: 2 [53248/620022]    Loss: 0.010373   Batch Acc: 67.19
[Train] Epoch: 2 [53312/620022]    Loss: 0.011200   Batch Acc: 70.31
[Train] Epoch: 2 [53376/620022]    Loss: 0.008919   Batch Acc: 75.00
[Train] Epoch: 2 [53440/620022]    Loss: 0.008654   Batch Acc: 82.81
[Train] Epoch: 2 [53504/620022]    Loss: 0.009019   Batch Acc: 81.25
[Train] Epoch: 2 [53568/620022]    Loss: 0.007595   Batch Acc: 78.12
[Train] Epoch: 2 [53632/620022]    Loss: 0.007044   Batch Acc: 84.38
[Train] Epoch: 2 [53696/620022]    Loss: 0.008766   Batch Acc: 76.56
[Train] Epoch: 2 [53760/620022]    Loss: 0.008310   Batch Acc: 78.12
[Train] Epoch: 2 [53824/620022]    Loss: 0.010152   Batch Acc: 71.88
[Train] Epoch: 2 [53888/620022]    Loss: 0.009738   Batch Acc: 78.12
[Train] Epoch: 2 [53952/620022]    Loss: 0.008443   Batch Acc: 78.12
[Train] Epoch: 2 [54016/620022]    Loss: 0.010092   Batch Acc: 73.44
[Train] Epoch: 2 [54080/620022]    Loss: 0.009135   Batch Acc: 76.56
[Train] Epoch: 2 [54144/620022]    Loss: 0.009717   Batch Acc: 76.56
[Train] Epoch: 2 [54208/620022]    Loss: 0.008006   Batch Acc: 79.69
[Train] Epoch: 2 [54272/620022]    Loss: 0.007805   Batch Acc: 79.69
[Train] Epoch: 2 [54336/620022]    Loss: 0.007265   Batch Acc: 82.81
[Train] Epoch: 2 [54400/620022]    Loss: 0.008518   Batch Acc: 75.00
[Train] Epoch: 2 [54464/620022]    Loss: 0.007349   Batch Acc: 79.69
[Train] Epoch: 2 [54528/620022]    Loss: 0.009727   Batch Acc: 71.88
[Train] Epoch: 2 [54592/620022]    Loss: 0.010806   Batch Acc: 65.62
[Train] Epoch: 2 [54656/620022]    Loss: 0.010968   Batch Acc: 73.44
[Train] Epoch: 2 [54720/620022]    Loss: 0.008120   Batch Acc: 76.56
[Train] Epoch: 2 [54784/620022]    Loss: 0.008730   Batch Acc: 82.81
[Train] Epoch: 2 [54848/620022]    Loss: 0.007273   Batch Acc: 78.12
[Train] Epoch: 2 [54912/620022]    Loss: 0.009456   Batch Acc: 76.56
[Train] Epoch: 2 [54976/620022]    Loss: 0.007017   Batch Acc: 82.81
[Train] Epoch: 2 [55040/620022]    Loss: 0.008579   Batch Acc: 78.12
[Train] Epoch: 2 [55104/620022]    Loss: 0.011369   Batch Acc: 65.62
[Train] Epoch: 2 [55168/620022]    Loss: 0.008604   Batch Acc: 79.69
[Train] Epoch: 2 [55232/620022]    Loss: 0.008172   Batch Acc: 75.00
[Train] Epoch: 2 [55296/620022]    Loss: 0.007709   Batch Acc: 78.12
[Train] Epoch: 2 [55360/620022]    Loss: 0.009700   Batch Acc: 73.44
[Train] Epoch: 2 [55424/620022]    Loss: 0.009326   Batch Acc: 81.25
[Train] Epoch: 2 [55488/620022]    Loss: 0.009034   Batch Acc: 73.44
[Train] Epoch: 2 [55552/620022]    Loss: 0.009403   Batch Acc: 71.88
[Train] Epoch: 2 [55616/620022]    Loss: 0.009420   Batch Acc: 78.12
[Train] Epoch: 2 [55680/620022]    Loss: 0.009599   Batch Acc: 76.56
[Train] Epoch: 2 [55744/620022]    Loss: 0.009044   Batch Acc: 75.00
[Train] Epoch: 2 [55808/620022]    Loss: 0.008331   Batch Acc: 78.12
[Train] Epoch: 2 [55872/620022]    Loss: 0.008476   Batch Acc: 75.00
[Train] Epoch: 2 [55936/620022]    Loss: 0.010480   Batch Acc: 71.88
[Train] Epoch: 2 [56000/620022]    Loss: 0.010065   Batch Acc: 68.75
[Train] Epoch: 2 [56064/620022]    Loss: 0.007324   Batch Acc: 78.12
[Train] Epoch: 2 [56128/620022]    Loss: 0.007682   Batch Acc: 79.69
[Train] Epoch: 2 [56192/620022]    Loss: 0.006696   Batch Acc: 87.50
[Train] Epoch: 2 [56256/620022]    Loss: 0.009555   Batch Acc: 70.31
[Train] Epoch: 2 [56320/620022]    Loss: 0.009571   Batch Acc: 71.88
[Train] Epoch: 2 [56384/620022]    Loss: 0.009188   Batch Acc: 73.44
[Train] Epoch: 2 [56448/620022]    Loss: 0.008806   Batch Acc: 78.12
[Train] Epoch: 2 [56512/620022]    Loss: 0.008763   Batch Acc: 79.69
[Train] Epoch: 2 [56576/620022]    Loss: 0.008997   Batch Acc: 73.44
[Train] Epoch: 2 [56640/620022]    Loss: 0.008354   Batch Acc: 78.12
[Train] Epoch: 2 [56704/620022]    Loss: 0.006327   Batch Acc: 89.06
[Train] Epoch: 2 [56768/620022]    Loss: 0.008885   Batch Acc: 76.56
[Train] Epoch: 2 [56832/620022]    Loss: 0.009642   Batch Acc: 71.88
[Train] Epoch: 2 [56896/620022]    Loss: 0.009039   Batch Acc: 75.00
[Train] Epoch: 2 [56960/620022]    Loss: 0.009757   Batch Acc: 76.56
[Train] Epoch: 2 [57024/620022]    Loss: 0.009586   Batch Acc: 73.44
[Train] Epoch: 2 [57088/620022]    Loss: 0.006532   Batch Acc: 87.50
[Train] Epoch: 2 [57152/620022]    Loss: 0.007635   Batch Acc: 81.25
[Train] Epoch: 2 [57216/620022]    Loss: 0.007727   Batch Acc: 79.69
[Train] Epoch: 2 [57280/620022]    Loss: 0.009925   Batch Acc: 78.12
[Train] Epoch: 2 [57344/620022]    Loss: 0.009100   Batch Acc: 75.00
[Train] Epoch: 2 [57408/620022]    Loss: 0.007119   Batch Acc: 82.81
[Train] Epoch: 2 [57472/620022]    Loss: 0.007237   Batch Acc: 85.94
[Train] Epoch: 2 [57536/620022]    Loss: 0.007160   Batch Acc: 82.81
[Train] Epoch: 2 [57600/620022]    Loss: 0.008537   Batch Acc: 75.00
[Train] Epoch: 2 [57664/620022]    Loss: 0.010454   Batch Acc: 78.12
[Train] Epoch: 2 [57728/620022]    Loss: 0.008501   Batch Acc: 78.12
[Train] Epoch: 2 [57792/620022]    Loss: 0.008612   Batch Acc: 78.12
[Train] Epoch: 2 [57856/620022]    Loss: 0.005754   Batch Acc: 90.62
[Train] Epoch: 2 [57920/620022]    Loss: 0.008978   Batch Acc: 71.88
[Train] Epoch: 2 [57984/620022]    Loss: 0.006842   Batch Acc: 82.81
[Train] Epoch: 2 [58048/620022]    Loss: 0.008965   Batch Acc: 73.44
[Train] Epoch: 2 [58112/620022]    Loss: 0.008271   Batch Acc: 76.56
[Train] Epoch: 2 [58176/620022]    Loss: 0.010265   Batch Acc: 78.12
[Train] Epoch: 2 [58240/620022]    Loss: 0.011004   Batch Acc: 75.00
[Train] Epoch: 2 [58304/620022]    Loss: 0.008729   Batch Acc: 78.12
[Train] Epoch: 2 [58368/620022]    Loss: 0.009780   Batch Acc: 78.12
[Train] Epoch: 2 [58432/620022]    Loss: 0.009122   Batch Acc: 76.56
[Train] Epoch: 2 [58496/620022]    Loss: 0.007915   Batch Acc: 82.81
[Train] Epoch: 2 [58560/620022]    Loss: 0.007252   Batch Acc: 82.81
[Train] Epoch: 2 [58624/620022]    Loss: 0.007588   Batch Acc: 87.50
[Train] Epoch: 2 [58688/620022]    Loss: 0.009050   Batch Acc: 71.88
[Train] Epoch: 2 [58752/620022]    Loss: 0.006926   Batch Acc: 84.38
[Train] Epoch: 2 [58816/620022]    Loss: 0.007592   Batch Acc: 79.69
[Train] Epoch: 2 [58880/620022]    Loss: 0.007919   Batch Acc: 76.56
[Train] Epoch: 2 [58944/620022]    Loss: 0.007027   Batch Acc: 84.38
[Train] Epoch: 2 [59008/620022]    Loss: 0.008770   Batch Acc: 70.31
[Train] Epoch: 2 [59072/620022]    Loss: 0.009651   Batch Acc: 76.56
[Train] Epoch: 2 [59136/620022]    Loss: 0.008113   Batch Acc: 78.12
[Train] Epoch: 2 [59200/620022]    Loss: 0.008900   Batch Acc: 82.81
[Train] Epoch: 2 [59264/620022]    Loss: 0.009908   Batch Acc: 71.88
[Train] Epoch: 2 [59328/620022]    Loss: 0.007463   Batch Acc: 81.25
[Train] Epoch: 2 [59392/620022]    Loss: 0.009143   Batch Acc: 75.00
[Train] Epoch: 2 [59456/620022]    Loss: 0.008000   Batch Acc: 79.69
[Train] Epoch: 2 [59520/620022]    Loss: 0.007955   Batch Acc: 81.25
[Train] Epoch: 2 [59584/620022]    Loss: 0.008976   Batch Acc: 75.00
[Train] Epoch: 2 [59648/620022]    Loss: 0.008927   Batch Acc: 84.38
[Train] Epoch: 2 [59712/620022]    Loss: 0.007966   Batch Acc: 85.94
[Train] Epoch: 2 [59776/620022]    Loss: 0.009587   Batch Acc: 75.00
[Train] Epoch: 2 [59840/620022]    Loss: 0.009945   Batch Acc: 76.56
[Train] Epoch: 2 [59904/620022]    Loss: 0.006735   Batch Acc: 85.94
[Train] Epoch: 2 [59968/620022]    Loss: 0.010903   Batch Acc: 67.19
[Train] Epoch: 2 [60032/620022]    Loss: 0.010008   Batch Acc: 75.00
[Train] Epoch: 2 [60096/620022]    Loss: 0.011321   Batch Acc: 68.75
[Train] Epoch: 2 [60160/620022]    Loss: 0.007375   Batch Acc: 81.25
[Train] Epoch: 2 [60224/620022]    Loss: 0.008778   Batch Acc: 75.00
[Train] Epoch: 2 [60288/620022]    Loss: 0.009050   Batch Acc: 78.12
[Train] Epoch: 2 [60352/620022]    Loss: 0.008955   Batch Acc: 76.56
[Train] Epoch: 2 [60416/620022]    Loss: 0.007550   Batch Acc: 81.25
[Train] Epoch: 2 [60480/620022]    Loss: 0.007754   Batch Acc: 82.81
[Train] Epoch: 2 [60544/620022]    Loss: 0.007413   Batch Acc: 82.81
[Train] Epoch: 2 [60608/620022]    Loss: 0.008585   Batch Acc: 73.44
[Train] Epoch: 2 [60672/620022]    Loss: 0.009693   Batch Acc: 70.31
[Train] Epoch: 2 [60736/620022]    Loss: 0.009243   Batch Acc: 75.00
[Train] Epoch: 2 [60800/620022]    Loss: 0.011000   Batch Acc: 75.00
[Train] Epoch: 2 [60864/620022]    Loss: 0.007344   Batch Acc: 85.94
[Train] Epoch: 2 [60928/620022]    Loss: 0.007448   Batch Acc: 81.25
[Train] Epoch: 2 [60992/620022]    Loss: 0.006932   Batch Acc: 79.69
[Train] Epoch: 2 [61056/620022]    Loss: 0.008594   Batch Acc: 76.56
[Train] Epoch: 2 [61120/620022]    Loss: 0.008075   Batch Acc: 78.12
[Train] Epoch: 2 [61184/620022]    Loss: 0.007883   Batch Acc: 82.81
[Train] Epoch: 2 [61248/620022]    Loss: 0.008579   Batch Acc: 75.00
[Train] Epoch: 2 [61312/620022]    Loss: 0.007394   Batch Acc: 79.69
[Train] Epoch: 2 [61376/620022]    Loss: 0.008438   Batch Acc: 76.56
[Train] Epoch: 2 [61440/620022]    Loss: 0.008484   Batch Acc: 81.25
[Train] Epoch: 2 [61504/620022]    Loss: 0.009438   Batch Acc: 76.56
[Train] Epoch: 2 [61568/620022]    Loss: 0.009202   Batch Acc: 73.44
[Train] Epoch: 2 [61632/620022]    Loss: 0.008243   Batch Acc: 82.81
[Train] Epoch: 2 [61696/620022]    Loss: 0.006183   Batch Acc: 89.06
[Train] Epoch: 2 [61760/620022]    Loss: 0.009300   Batch Acc: 70.31
[Train] Epoch: 2 [61824/620022]    Loss: 0.008959   Batch Acc: 82.81
[Train] Epoch: 2 [61888/620022]    Loss: 0.010185   Batch Acc: 73.44
[Train] Epoch: 2 [61952/620022]    Loss: 0.007282   Batch Acc: 81.25
[Train] Epoch: 2 [62016/620022]    Loss: 0.008183   Batch Acc: 76.56
[Train] Epoch: 2 [62080/620022]    Loss: 0.010376   Batch Acc: 73.44
[Train] Epoch: 2 [62144/620022]    Loss: 0.012863   Batch Acc: 64.06
[Train] Epoch: 2 [62208/620022]    Loss: 0.008697   Batch Acc: 79.69
[Train] Epoch: 2 [62272/620022]    Loss: 0.008208   Batch Acc: 79.69
[Train] Epoch: 2 [62336/620022]    Loss: 0.009861   Batch Acc: 79.69
[Train] Epoch: 2 [62400/620022]    Loss: 0.010928   Batch Acc: 68.75
[Train] Epoch: 2 [62464/620022]    Loss: 0.011209   Batch Acc: 64.06
[Train] Epoch: 2 [62528/620022]    Loss: 0.007060   Batch Acc: 85.94
[Train] Epoch: 2 [62592/620022]    Loss: 0.009980   Batch Acc: 70.31
[Train] Epoch: 2 [62656/620022]    Loss: 0.008063   Batch Acc: 75.00
[Train] Epoch: 2 [62720/620022]    Loss: 0.007223   Batch Acc: 82.81
[Train] Epoch: 2 [62784/620022]    Loss: 0.007477   Batch Acc: 75.00
[Train] Epoch: 2 [62848/620022]    Loss: 0.008128   Batch Acc: 79.69
[Train] Epoch: 2 [62912/620022]    Loss: 0.012591   Batch Acc: 67.19
[Train] Epoch: 2 [62976/620022]    Loss: 0.007828   Batch Acc: 78.12
[Train] Epoch: 2 [63040/620022]    Loss: 0.007333   Batch Acc: 84.38
[Train] Epoch: 2 [63104/620022]    Loss: 0.007792   Batch Acc: 81.25
[Train] Epoch: 2 [63168/620022]    Loss: 0.007304   Batch Acc: 84.38
[Train] Epoch: 2 [63232/620022]    Loss: 0.009274   Batch Acc: 73.44
[Train] Epoch: 2 [63296/620022]    Loss: 0.009257   Batch Acc: 78.12
[Train] Epoch: 2 [63360/620022]    Loss: 0.008568   Batch Acc: 84.38
[Train] Epoch: 2 [63424/620022]    Loss: 0.010141   Batch Acc: 70.31
[Train] Epoch: 2 [63488/620022]    Loss: 0.009194   Batch Acc: 79.69
[Train] Epoch: 2 [63552/620022]    Loss: 0.007855   Batch Acc: 82.81
[Train] Epoch: 2 [63616/620022]    Loss: 0.008546   Batch Acc: 78.12
[Train] Epoch: 2 [63680/620022]    Loss: 0.010174   Batch Acc: 71.88
[Train] Epoch: 2 [63744/620022]    Loss: 0.007748   Batch Acc: 81.25
[Train] Epoch: 2 [63808/620022]    Loss: 0.008598   Batch Acc: 78.12
[Train] Epoch: 2 [63872/620022]    Loss: 0.008593   Batch Acc: 79.69
[Train] Epoch: 2 [63936/620022]    Loss: 0.011176   Batch Acc: 62.50
[Train] Epoch: 2 [64000/620022]    Loss: 0.009063   Batch Acc: 71.88
[Train] Epoch: 2 [64064/620022]    Loss: 0.008374   Batch Acc: 76.56
[Train] Epoch: 2 [64128/620022]    Loss: 0.007722   Batch Acc: 79.69
[Train] Epoch: 2 [64192/620022]    Loss: 0.009493   Batch Acc: 71.88
[Train] Epoch: 2 [64256/620022]    Loss: 0.009677   Batch Acc: 79.69
[Train] Epoch: 2 [64320/620022]    Loss: 0.008811   Batch Acc: 76.56
[Train] Epoch: 2 [64384/620022]    Loss: 0.007674   Batch Acc: 82.81
[Train] Epoch: 2 [64448/620022]    Loss: 0.008173   Batch Acc: 82.81
[Train] Epoch: 2 [64512/620022]    Loss: 0.008159   Batch Acc: 76.56
[Train] Epoch: 2 [64576/620022]    Loss: 0.009664   Batch Acc: 73.44
[Train] Epoch: 2 [64640/620022]    Loss: 0.011401   Batch Acc: 65.62
[Train] Epoch: 2 [64704/620022]    Loss: 0.009451   Batch Acc: 79.69
[Train] Epoch: 2 [64768/620022]    Loss: 0.010403   Batch Acc: 71.88
[Train] Epoch: 2 [64832/620022]    Loss: 0.007809   Batch Acc: 82.81
[Train] Epoch: 2 [64896/620022]    Loss: 0.009914   Batch Acc: 76.56
[Train] Epoch: 2 [64960/620022]    Loss: 0.010954   Batch Acc: 73.44
[Train] Epoch: 2 [65024/620022]    Loss: 0.008960   Batch Acc: 76.56
[Train] Epoch: 2 [65088/620022]    Loss: 0.006489   Batch Acc: 87.50
[Train] Epoch: 2 [65152/620022]    Loss: 0.008835   Batch Acc: 75.00
[Train] Epoch: 2 [65216/620022]    Loss: 0.008379   Batch Acc: 75.00
[Train] Epoch: 2 [65280/620022]    Loss: 0.006260   Batch Acc: 82.81
[Train] Epoch: 2 [65344/620022]    Loss: 0.009447   Batch Acc: 71.88
[Train] Epoch: 2 [65408/620022]    Loss: 0.007025   Batch Acc: 89.06
[Train] Epoch: 2 [65472/620022]    Loss: 0.009743   Batch Acc: 71.88
[Train] Epoch: 2 [65536/620022]    Loss: 0.009657   Batch Acc: 75.00
[Train] Epoch: 2 [65600/620022]    Loss: 0.007513   Batch Acc: 79.69
[Train] Epoch: 2 [65664/620022]    Loss: 0.008654   Batch Acc: 78.12
[Train] Epoch: 2 [65728/620022]    Loss: 0.007371   Batch Acc: 81.25
[Train] Epoch: 2 [65792/620022]    Loss: 0.008079   Batch Acc: 82.81
[Train] Epoch: 2 [65856/620022]    Loss: 0.008075   Batch Acc: 81.25
[Train] Epoch: 2 [65920/620022]    Loss: 0.007691   Batch Acc: 81.25
[Train] Epoch: 2 [65984/620022]    Loss: 0.009967   Batch Acc: 71.88
[Train] Epoch: 2 [66048/620022]    Loss: 0.009728   Batch Acc: 73.44
[Train] Epoch: 2 [66112/620022]    Loss: 0.011548   Batch Acc: 70.31
[Train] Epoch: 2 [66176/620022]    Loss: 0.008772   Batch Acc: 78.12
[Train] Epoch: 2 [66240/620022]    Loss: 0.009315   Batch Acc: 78.12
[Train] Epoch: 2 [66304/620022]    Loss: 0.008412   Batch Acc: 79.69
[Train] Epoch: 2 [66368/620022]    Loss: 0.011468   Batch Acc: 67.19
[Train] Epoch: 2 [66432/620022]    Loss: 0.010527   Batch Acc: 78.12
[Train] Epoch: 2 [66496/620022]    Loss: 0.010159   Batch Acc: 71.88
[Train] Epoch: 2 [66560/620022]    Loss: 0.008224   Batch Acc: 76.56
[Train] Epoch: 2 [66624/620022]    Loss: 0.009548   Batch Acc: 76.56
[Train] Epoch: 2 [66688/620022]    Loss: 0.007284   Batch Acc: 84.38
[Train] Epoch: 2 [66752/620022]    Loss: 0.007092   Batch Acc: 81.25
[Train] Epoch: 2 [66816/620022]    Loss: 0.008853   Batch Acc: 78.12
[Train] Epoch: 2 [66880/620022]    Loss: 0.007927   Batch Acc: 81.25
[Train] Epoch: 2 [66944/620022]    Loss: 0.008477   Batch Acc: 78.12
[Train] Epoch: 2 [67008/620022]    Loss: 0.009830   Batch Acc: 73.44
[Train] Epoch: 2 [67072/620022]    Loss: 0.009502   Batch Acc: 75.00
[Train] Epoch: 2 [67136/620022]    Loss: 0.011048   Batch Acc: 67.19
[Train] Epoch: 2 [67200/620022]    Loss: 0.006951   Batch Acc: 82.81
[Train] Epoch: 2 [67264/620022]    Loss: 0.008698   Batch Acc: 78.12
[Train] Epoch: 2 [67328/620022]    Loss: 0.006284   Batch Acc: 84.38
[Train] Epoch: 2 [67392/620022]    Loss: 0.009650   Batch Acc: 70.31
[Train] Epoch: 2 [67456/620022]    Loss: 0.009223   Batch Acc: 81.25
[Train] Epoch: 2 [67520/620022]    Loss: 0.009211   Batch Acc: 71.88
[Train] Epoch: 2 [67584/620022]    Loss: 0.007477   Batch Acc: 79.69
[Train] Epoch: 2 [67648/620022]    Loss: 0.007088   Batch Acc: 87.50
[Train] Epoch: 2 [67712/620022]    Loss: 0.007897   Batch Acc: 75.00
[Train] Epoch: 2 [67776/620022]    Loss: 0.008927   Batch Acc: 79.69
[Train] Epoch: 2 [67840/620022]    Loss: 0.007593   Batch Acc: 84.38
[Train] Epoch: 2 [67904/620022]    Loss: 0.008922   Batch Acc: 81.25
[Train] Epoch: 2 [67968/620022]    Loss: 0.007789   Batch Acc: 79.69
[Train] Epoch: 2 [68032/620022]    Loss: 0.006284   Batch Acc: 81.25
[Train] Epoch: 2 [68096/620022]    Loss: 0.008215   Batch Acc: 78.12
[Train] Epoch: 2 [68160/620022]    Loss: 0.009170   Batch Acc: 71.88
[Train] Epoch: 2 [68224/620022]    Loss: 0.007959   Batch Acc: 81.25
[Train] Epoch: 2 [68288/620022]    Loss: 0.006179   Batch Acc: 90.62
[Train] Epoch: 2 [68352/620022]    Loss: 0.007393   Batch Acc: 81.25
[Train] Epoch: 2 [68416/620022]    Loss: 0.006732   Batch Acc: 84.38
[Train] Epoch: 2 [68480/620022]    Loss: 0.009512   Batch Acc: 76.56
[Train] Epoch: 2 [68544/620022]    Loss: 0.010527   Batch Acc: 73.44
[Train] Epoch: 2 [68608/620022]    Loss: 0.009411   Batch Acc: 76.56
[Train] Epoch: 2 [68672/620022]    Loss: 0.007485   Batch Acc: 84.38
[Train] Epoch: 2 [68736/620022]    Loss: 0.009008   Batch Acc: 78.12
[Train] Epoch: 2 [68800/620022]    Loss: 0.007987   Batch Acc: 79.69
[Train] Epoch: 2 [68864/620022]    Loss: 0.008574   Batch Acc: 75.00
[Train] Epoch: 2 [68928/620022]    Loss: 0.007732   Batch Acc: 81.25
[Train] Epoch: 2 [68992/620022]    Loss: 0.007899   Batch Acc: 79.69
[Train] Epoch: 2 [69056/620022]    Loss: 0.009671   Batch Acc: 65.62
[Train] Epoch: 2 [69120/620022]    Loss: 0.009710   Batch Acc: 70.31
[Train] Epoch: 2 [69184/620022]    Loss: 0.008840   Batch Acc: 75.00
[Train] Epoch: 2 [69248/620022]    Loss: 0.010596   Batch Acc: 73.44
[Train] Epoch: 2 [69312/620022]    Loss: 0.008140   Batch Acc: 84.38
[Train] Epoch: 2 [69376/620022]    Loss: 0.008171   Batch Acc: 81.25
[Train] Epoch: 2 [69440/620022]    Loss: 0.007201   Batch Acc: 81.25
[Train] Epoch: 2 [69504/620022]    Loss: 0.008559   Batch Acc: 84.38
[Train] Epoch: 2 [69568/620022]    Loss: 0.008609   Batch Acc: 75.00
[Train] Epoch: 2 [69632/620022]    Loss: 0.008589   Batch Acc: 78.12
[Train] Epoch: 2 [69696/620022]    Loss: 0.007789   Batch Acc: 79.69
[Train] Epoch: 2 [69760/620022]    Loss: 0.011034   Batch Acc: 70.31
[Train] Epoch: 2 [69824/620022]    Loss: 0.008947   Batch Acc: 76.56
[Train] Epoch: 2 [69888/620022]    Loss: 0.007558   Batch Acc: 78.12
[Train] Epoch: 2 [69952/620022]    Loss: 0.007715   Batch Acc: 82.81
[Train] Epoch: 2 [70016/620022]    Loss: 0.008881   Batch Acc: 82.81
[Train] Epoch: 2 [70080/620022]    Loss: 0.007305   Batch Acc: 89.06
[Train] Epoch: 2 [70144/620022]    Loss: 0.006602   Batch Acc: 82.81
[Train] Epoch: 2 [70208/620022]    Loss: 0.006739   Batch Acc: 81.25
[Train] Epoch: 2 [70272/620022]    Loss: 0.008703   Batch Acc: 76.56
[Train] Epoch: 2 [70336/620022]    Loss: 0.009878   Batch Acc: 70.31
[Train] Epoch: 2 [70400/620022]    Loss: 0.010579   Batch Acc: 68.75
[Train] Epoch: 2 [70464/620022]    Loss: 0.009047   Batch Acc: 75.00
[Train] Epoch: 2 [70528/620022]    Loss: 0.011297   Batch Acc: 68.75
[Train] Epoch: 2 [70592/620022]    Loss: 0.009418   Batch Acc: 82.81
[Train] Epoch: 2 [70656/620022]    Loss: 0.006752   Batch Acc: 82.81
[Train] Epoch: 2 [70720/620022]    Loss: 0.006477   Batch Acc: 89.06
[Train] Epoch: 2 [70784/620022]    Loss: 0.010198   Batch Acc: 75.00
[Train] Epoch: 2 [70848/620022]    Loss: 0.007893   Batch Acc: 76.56
[Train] Epoch: 2 [70912/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 2 [70976/620022]    Loss: 0.008865   Batch Acc: 78.12
[Train] Epoch: 2 [71040/620022]    Loss: 0.011617   Batch Acc: 70.31
[Train] Epoch: 2 [71104/620022]    Loss: 0.009442   Batch Acc: 73.44
[Train] Epoch: 2 [71168/620022]    Loss: 0.013984   Batch Acc: 59.38
[Train] Epoch: 2 [71232/620022]    Loss: 0.007963   Batch Acc: 79.69
[Train] Epoch: 2 [71296/620022]    Loss: 0.009707   Batch Acc: 75.00
[Train] Epoch: 2 [71360/620022]    Loss: 0.008697   Batch Acc: 82.81
[Train] Epoch: 2 [71424/620022]    Loss: 0.006827   Batch Acc: 84.38
[Train] Epoch: 2 [71488/620022]    Loss: 0.007875   Batch Acc: 81.25
[Train] Epoch: 2 [71552/620022]    Loss: 0.010081   Batch Acc: 75.00
[Train] Epoch: 2 [71616/620022]    Loss: 0.007461   Batch Acc: 82.81
[Train] Epoch: 2 [71680/620022]    Loss: 0.011805   Batch Acc: 67.19
[Train] Epoch: 2 [71744/620022]    Loss: 0.010156   Batch Acc: 65.62
[Train] Epoch: 2 [71808/620022]    Loss: 0.008920   Batch Acc: 81.25
[Train] Epoch: 2 [71872/620022]    Loss: 0.007862   Batch Acc: 78.12
[Train] Epoch: 2 [71936/620022]    Loss: 0.007433   Batch Acc: 82.81
[Train] Epoch: 2 [72000/620022]    Loss: 0.010527   Batch Acc: 70.31
[Train] Epoch: 2 [72064/620022]    Loss: 0.008499   Batch Acc: 73.44
[Train] Epoch: 2 [72128/620022]    Loss: 0.008826   Batch Acc: 71.88
[Train] Epoch: 2 [72192/620022]    Loss: 0.009051   Batch Acc: 73.44
[Train] Epoch: 2 [72256/620022]    Loss: 0.007256   Batch Acc: 82.81
[Train] Epoch: 2 [72320/620022]    Loss: 0.008868   Batch Acc: 75.00
[Train] Epoch: 2 [72384/620022]    Loss: 0.008435   Batch Acc: 78.12
[Train] Epoch: 2 [72448/620022]    Loss: 0.009227   Batch Acc: 76.56
[Train] Epoch: 2 [72512/620022]    Loss: 0.010109   Batch Acc: 78.12
[Train] Epoch: 2 [72576/620022]    Loss: 0.007997   Batch Acc: 81.25
[Train] Epoch: 2 [72640/620022]    Loss: 0.006715   Batch Acc: 81.25
[Train] Epoch: 2 [72704/620022]    Loss: 0.009398   Batch Acc: 75.00
[Train] Epoch: 2 [72768/620022]    Loss: 0.010271   Batch Acc: 78.12
[Train] Epoch: 2 [72832/620022]    Loss: 0.009033   Batch Acc: 78.12
[Train] Epoch: 2 [72896/620022]    Loss: 0.007971   Batch Acc: 79.69
[Train] Epoch: 2 [72960/620022]    Loss: 0.008859   Batch Acc: 76.56
[Train] Epoch: 2 [73024/620022]    Loss: 0.009089   Batch Acc: 78.12
[Train] Epoch: 2 [73088/620022]    Loss: 0.009757   Batch Acc: 73.44
[Train] Epoch: 2 [73152/620022]    Loss: 0.009620   Batch Acc: 75.00
[Train] Epoch: 2 [73216/620022]    Loss: 0.008864   Batch Acc: 73.44
[Train] Epoch: 2 [73280/620022]    Loss: 0.009418   Batch Acc: 76.56
[Train] Epoch: 2 [73344/620022]    Loss: 0.009674   Batch Acc: 71.88
[Train] Epoch: 2 [73408/620022]    Loss: 0.009241   Batch Acc: 75.00
[Train] Epoch: 2 [73472/620022]    Loss: 0.009175   Batch Acc: 71.88
[Train] Epoch: 2 [73536/620022]    Loss: 0.008391   Batch Acc: 82.81
[Train] Epoch: 2 [73600/620022]    Loss: 0.008170   Batch Acc: 81.25
[Train] Epoch: 2 [73664/620022]    Loss: 0.007083   Batch Acc: 85.94
[Train] Epoch: 2 [73728/620022]    Loss: 0.009724   Batch Acc: 75.00
[Train] Epoch: 2 [73792/620022]    Loss: 0.008331   Batch Acc: 78.12
[Train] Epoch: 2 [73856/620022]    Loss: 0.007697   Batch Acc: 76.56
[Train] Epoch: 2 [73920/620022]    Loss: 0.010054   Batch Acc: 73.44
[Train] Epoch: 2 [73984/620022]    Loss: 0.008833   Batch Acc: 79.69
[Train] Epoch: 2 [74048/620022]    Loss: 0.009640   Batch Acc: 78.12
[Train] Epoch: 2 [74112/620022]    Loss: 0.008456   Batch Acc: 79.69
[Train] Epoch: 2 [74176/620022]    Loss: 0.007907   Batch Acc: 81.25
[Train] Epoch: 2 [74240/620022]    Loss: 0.010115   Batch Acc: 78.12
[Train] Epoch: 2 [74304/620022]    Loss: 0.008234   Batch Acc: 79.69
[Train] Epoch: 2 [74368/620022]    Loss: 0.007940   Batch Acc: 82.81
[Train] Epoch: 2 [74432/620022]    Loss: 0.009723   Batch Acc: 71.88
[Train] Epoch: 2 [74496/620022]    Loss: 0.007168   Batch Acc: 85.94
[Train] Epoch: 2 [74560/620022]    Loss: 0.009618   Batch Acc: 78.12
[Train] Epoch: 2 [74624/620022]    Loss: 0.008752   Batch Acc: 81.25
[Train] Epoch: 2 [74688/620022]    Loss: 0.009809   Batch Acc: 78.12
[Train] Epoch: 2 [74752/620022]    Loss: 0.007159   Batch Acc: 84.38
[Train] Epoch: 2 [74816/620022]    Loss: 0.008251   Batch Acc: 79.69
[Train] Epoch: 2 [74880/620022]    Loss: 0.007108   Batch Acc: 84.38
[Train] Epoch: 2 [74944/620022]    Loss: 0.008675   Batch Acc: 82.81
[Train] Epoch: 2 [75008/620022]    Loss: 0.009162   Batch Acc: 79.69
[Train] Epoch: 2 [75072/620022]    Loss: 0.009217   Batch Acc: 79.69
[Train] Epoch: 2 [75136/620022]    Loss: 0.010597   Batch Acc: 73.44
[Train] Epoch: 2 [75200/620022]    Loss: 0.009463   Batch Acc: 75.00
[Train] Epoch: 2 [75264/620022]    Loss: 0.008893   Batch Acc: 78.12
[Train] Epoch: 2 [75328/620022]    Loss: 0.008713   Batch Acc: 81.25
[Train] Epoch: 2 [75392/620022]    Loss: 0.006813   Batch Acc: 82.81
[Train] Epoch: 2 [75456/620022]    Loss: 0.008109   Batch Acc: 78.12
[Train] Epoch: 2 [75520/620022]    Loss: 0.006250   Batch Acc: 87.50
[Train] Epoch: 2 [75584/620022]    Loss: 0.010147   Batch Acc: 73.44
[Train] Epoch: 2 [75648/620022]    Loss: 0.008701   Batch Acc: 78.12
[Train] Epoch: 2 [75712/620022]    Loss: 0.007384   Batch Acc: 79.69
[Train] Epoch: 2 [75776/620022]    Loss: 0.009634   Batch Acc: 76.56
[Train] Epoch: 2 [75840/620022]    Loss: 0.008365   Batch Acc: 79.69
[Train] Epoch: 2 [75904/620022]    Loss: 0.009902   Batch Acc: 73.44
[Train] Epoch: 2 [75968/620022]    Loss: 0.009462   Batch Acc: 71.88
[Train] Epoch: 2 [76032/620022]    Loss: 0.008570   Batch Acc: 82.81
[Train] Epoch: 2 [76096/620022]    Loss: 0.007676   Batch Acc: 78.12
[Train] Epoch: 2 [76160/620022]    Loss: 0.006690   Batch Acc: 87.50
[Train] Epoch: 2 [76224/620022]    Loss: 0.008912   Batch Acc: 75.00
[Train] Epoch: 2 [76288/620022]    Loss: 0.009543   Batch Acc: 76.56
[Train] Epoch: 2 [76352/620022]    Loss: 0.007896   Batch Acc: 76.56
[Train] Epoch: 2 [76416/620022]    Loss: 0.010026   Batch Acc: 71.88
[Train] Epoch: 2 [76480/620022]    Loss: 0.008280   Batch Acc: 81.25
[Train] Epoch: 2 [76544/620022]    Loss: 0.008120   Batch Acc: 79.69
[Train] Epoch: 2 [76608/620022]    Loss: 0.010782   Batch Acc: 73.44
[Train] Epoch: 2 [76672/620022]    Loss: 0.006682   Batch Acc: 87.50
[Train] Epoch: 2 [76736/620022]    Loss: 0.009275   Batch Acc: 78.12
[Train] Epoch: 2 [76800/620022]    Loss: 0.008804   Batch Acc: 82.81
[Train] Epoch: 2 [76864/620022]    Loss: 0.008100   Batch Acc: 81.25
[Train] Epoch: 2 [76928/620022]    Loss: 0.010275   Batch Acc: 76.56
[Train] Epoch: 2 [76992/620022]    Loss: 0.008569   Batch Acc: 79.69
[Train] Epoch: 2 [77056/620022]    Loss: 0.010519   Batch Acc: 71.88
[Train] Epoch: 2 [77120/620022]    Loss: 0.011522   Batch Acc: 70.31
[Train] Epoch: 2 [77184/620022]    Loss: 0.009327   Batch Acc: 75.00
[Train] Epoch: 2 [77248/620022]    Loss: 0.010113   Batch Acc: 70.31
[Train] Epoch: 2 [77312/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 2 [77376/620022]    Loss: 0.008363   Batch Acc: 78.12
[Train] Epoch: 2 [77440/620022]    Loss: 0.008839   Batch Acc: 79.69
[Train] Epoch: 2 [77504/620022]    Loss: 0.007918   Batch Acc: 82.81
[Train] Epoch: 2 [77568/620022]    Loss: 0.009905   Batch Acc: 68.75
[Train] Epoch: 2 [77632/620022]    Loss: 0.008735   Batch Acc: 78.12
[Train] Epoch: 2 [77696/620022]    Loss: 0.006417   Batch Acc: 89.06
[Train] Epoch: 2 [77760/620022]    Loss: 0.008402   Batch Acc: 79.69
[Train] Epoch: 2 [77824/620022]    Loss: 0.009110   Batch Acc: 71.88
[Train] Epoch: 2 [77888/620022]    Loss: 0.009629   Batch Acc: 76.56
[Train] Epoch: 2 [77952/620022]    Loss: 0.006613   Batch Acc: 87.50
[Train] Epoch: 2 [78016/620022]    Loss: 0.012013   Batch Acc: 67.19
[Train] Epoch: 2 [78080/620022]    Loss: 0.007356   Batch Acc: 79.69
[Train] Epoch: 2 [78144/620022]    Loss: 0.008822   Batch Acc: 73.44
[Train] Epoch: 2 [78208/620022]    Loss: 0.009844   Batch Acc: 75.00
[Train] Epoch: 2 [78272/620022]    Loss: 0.007213   Batch Acc: 85.94
[Train] Epoch: 2 [78336/620022]    Loss: 0.008979   Batch Acc: 79.69
[Train] Epoch: 2 [78400/620022]    Loss: 0.007750   Batch Acc: 78.12
[Train] Epoch: 2 [78464/620022]    Loss: 0.010169   Batch Acc: 70.31
[Train] Epoch: 2 [78528/620022]    Loss: 0.008011   Batch Acc: 81.25
[Train] Epoch: 2 [78592/620022]    Loss: 0.008375   Batch Acc: 75.00
[Train] Epoch: 2 [78656/620022]    Loss: 0.007665   Batch Acc: 75.00
[Train] Epoch: 2 [78720/620022]    Loss: 0.008111   Batch Acc: 84.38
[Train] Epoch: 2 [78784/620022]    Loss: 0.009430   Batch Acc: 75.00
[Train] Epoch: 2 [78848/620022]    Loss: 0.006893   Batch Acc: 87.50
[Train] Epoch: 2 [78912/620022]    Loss: 0.008992   Batch Acc: 78.12
[Train] Epoch: 2 [78976/620022]    Loss: 0.007871   Batch Acc: 82.81
[Train] Epoch: 2 [79040/620022]    Loss: 0.010429   Batch Acc: 71.88
[Train] Epoch: 2 [79104/620022]    Loss: 0.009021   Batch Acc: 79.69
[Train] Epoch: 2 [79168/620022]    Loss: 0.008146   Batch Acc: 78.12
[Train] Epoch: 2 [79232/620022]    Loss: 0.008390   Batch Acc: 79.69
[Train] Epoch: 2 [79296/620022]    Loss: 0.009445   Batch Acc: 79.69
[Train] Epoch: 2 [79360/620022]    Loss: 0.011653   Batch Acc: 65.62
[Train] Epoch: 2 [79424/620022]    Loss: 0.009635   Batch Acc: 73.44
[Train] Epoch: 2 [79488/620022]    Loss: 0.007905   Batch Acc: 76.56
[Train] Epoch: 2 [79552/620022]    Loss: 0.008234   Batch Acc: 78.12
[Train] Epoch: 2 [79616/620022]    Loss: 0.008195   Batch Acc: 78.12
[Train] Epoch: 2 [79680/620022]    Loss: 0.007588   Batch Acc: 82.81
[Train] Epoch: 2 [79744/620022]    Loss: 0.007261   Batch Acc: 79.69
[Train] Epoch: 2 [79808/620022]    Loss: 0.009384   Batch Acc: 71.88
[Train] Epoch: 2 [79872/620022]    Loss: 0.009463   Batch Acc: 75.00
[Train] Epoch: 2 [79936/620022]    Loss: 0.007168   Batch Acc: 81.25
[Train] Epoch: 2 [80000/620022]    Loss: 0.005853   Batch Acc: 85.94
[Train] Epoch: 2 [80064/620022]    Loss: 0.010820   Batch Acc: 76.56
[Train] Epoch: 2 [80128/620022]    Loss: 0.008397   Batch Acc: 82.81
[Train] Epoch: 2 [80192/620022]    Loss: 0.005742   Batch Acc: 89.06
[Train] Epoch: 2 [80256/620022]    Loss: 0.008703   Batch Acc: 78.12
[Train] Epoch: 2 [80320/620022]    Loss: 0.010764   Batch Acc: 75.00
[Train] Epoch: 2 [80384/620022]    Loss: 0.010824   Batch Acc: 68.75
[Train] Epoch: 2 [80448/620022]    Loss: 0.009601   Batch Acc: 75.00
[Train] Epoch: 2 [80512/620022]    Loss: 0.007590   Batch Acc: 82.81
[Train] Epoch: 2 [80576/620022]    Loss: 0.008004   Batch Acc: 79.69
[Train] Epoch: 2 [80640/620022]    Loss: 0.009032   Batch Acc: 75.00
[Train] Epoch: 2 [80704/620022]    Loss: 0.010990   Batch Acc: 70.31
[Train] Epoch: 2 [80768/620022]    Loss: 0.008235   Batch Acc: 81.25
[Train] Epoch: 2 [80832/620022]    Loss: 0.007344   Batch Acc: 85.94
[Train] Epoch: 2 [80896/620022]    Loss: 0.009168   Batch Acc: 70.31
[Train] Epoch: 2 [80960/620022]    Loss: 0.007011   Batch Acc: 82.81
[Train] Epoch: 2 [81024/620022]    Loss: 0.008721   Batch Acc: 82.81
[Train] Epoch: 2 [81088/620022]    Loss: 0.009241   Batch Acc: 76.56
[Train] Epoch: 2 [81152/620022]    Loss: 0.008897   Batch Acc: 81.25
[Train] Epoch: 2 [81216/620022]    Loss: 0.010521   Batch Acc: 68.75
[Train] Epoch: 2 [81280/620022]    Loss: 0.008591   Batch Acc: 76.56
[Train] Epoch: 2 [81344/620022]    Loss: 0.008848   Batch Acc: 82.81
[Train] Epoch: 2 [81408/620022]    Loss: 0.008044   Batch Acc: 76.56
[Train] Epoch: 2 [81472/620022]    Loss: 0.006625   Batch Acc: 84.38
[Train] Epoch: 2 [81536/620022]    Loss: 0.009590   Batch Acc: 71.88
[Train] Epoch: 2 [81600/620022]    Loss: 0.008945   Batch Acc: 78.12
[Train] Epoch: 2 [81664/620022]    Loss: 0.005896   Batch Acc: 90.62
[Train] Epoch: 2 [81728/620022]    Loss: 0.011239   Batch Acc: 71.88
[Train] Epoch: 2 [81792/620022]    Loss: 0.008769   Batch Acc: 75.00
[Train] Epoch: 2 [81856/620022]    Loss: 0.006939   Batch Acc: 85.94
[Train] Epoch: 2 [81920/620022]    Loss: 0.008864   Batch Acc: 76.56
[Train] Epoch: 2 [81984/620022]    Loss: 0.007734   Batch Acc: 85.94
[Train] Epoch: 2 [82048/620022]    Loss: 0.011249   Batch Acc: 73.44
[Train] Epoch: 2 [82112/620022]    Loss: 0.007336   Batch Acc: 84.38
[Train] Epoch: 2 [82176/620022]    Loss: 0.008187   Batch Acc: 76.56
[Train] Epoch: 2 [82240/620022]    Loss: 0.008143   Batch Acc: 78.12
[Train] Epoch: 2 [82304/620022]    Loss: 0.007489   Batch Acc: 78.12
[Train] Epoch: 2 [82368/620022]    Loss: 0.008355   Batch Acc: 81.25
[Train] Epoch: 2 [82432/620022]    Loss: 0.008005   Batch Acc: 75.00
[Train] Epoch: 2 [82496/620022]    Loss: 0.007459   Batch Acc: 84.38
[Train] Epoch: 2 [82560/620022]    Loss: 0.010481   Batch Acc: 71.88
[Train] Epoch: 2 [82624/620022]    Loss: 0.007849   Batch Acc: 75.00
[Train] Epoch: 2 [82688/620022]    Loss: 0.008500   Batch Acc: 76.56
[Train] Epoch: 2 [82752/620022]    Loss: 0.007809   Batch Acc: 76.56
[Train] Epoch: 2 [82816/620022]    Loss: 0.006877   Batch Acc: 85.94
[Train] Epoch: 2 [82880/620022]    Loss: 0.012389   Batch Acc: 65.62
[Train] Epoch: 2 [82944/620022]    Loss: 0.008110   Batch Acc: 76.56
[Train] Epoch: 2 [83008/620022]    Loss: 0.007572   Batch Acc: 81.25
[Train] Epoch: 2 [83072/620022]    Loss: 0.007627   Batch Acc: 82.81
[Train] Epoch: 2 [83136/620022]    Loss: 0.009005   Batch Acc: 79.69
[Train] Epoch: 2 [83200/620022]    Loss: 0.009369   Batch Acc: 75.00
[Train] Epoch: 2 [83264/620022]    Loss: 0.009693   Batch Acc: 76.56
[Train] Epoch: 2 [83328/620022]    Loss: 0.009939   Batch Acc: 64.06
[Train] Epoch: 2 [83392/620022]    Loss: 0.008792   Batch Acc: 70.31
[Train] Epoch: 2 [83456/620022]    Loss: 0.010208   Batch Acc: 73.44
[Train] Epoch: 2 [83520/620022]    Loss: 0.007320   Batch Acc: 78.12
[Train] Epoch: 2 [83584/620022]    Loss: 0.009509   Batch Acc: 79.69
[Train] Epoch: 2 [83648/620022]    Loss: 0.009829   Batch Acc: 76.56
[Train] Epoch: 2 [83712/620022]    Loss: 0.009345   Batch Acc: 79.69
[Train] Epoch: 2 [83776/620022]    Loss: 0.009812   Batch Acc: 78.12
[Train] Epoch: 2 [83840/620022]    Loss: 0.008274   Batch Acc: 79.69
[Train] Epoch: 2 [83904/620022]    Loss: 0.008507   Batch Acc: 78.12
[Train] Epoch: 2 [83968/620022]    Loss: 0.007396   Batch Acc: 85.94
[Train] Epoch: 2 [84032/620022]    Loss: 0.009778   Batch Acc: 71.88
[Train] Epoch: 2 [84096/620022]    Loss: 0.007179   Batch Acc: 81.25
[Train] Epoch: 2 [84160/620022]    Loss: 0.009670   Batch Acc: 73.44
[Train] Epoch: 2 [84224/620022]    Loss: 0.009317   Batch Acc: 73.44
[Train] Epoch: 2 [84288/620022]    Loss: 0.009716   Batch Acc: 75.00
[Train] Epoch: 2 [84352/620022]    Loss: 0.007993   Batch Acc: 79.69
[Train] Epoch: 2 [84416/620022]    Loss: 0.007853   Batch Acc: 84.38
[Train] Epoch: 2 [84480/620022]    Loss: 0.005542   Batch Acc: 89.06
[Train] Epoch: 2 [84544/620022]    Loss: 0.010289   Batch Acc: 62.50
[Train] Epoch: 2 [84608/620022]    Loss: 0.009336   Batch Acc: 84.38
[Train] Epoch: 2 [84672/620022]    Loss: 0.012426   Batch Acc: 62.50
[Train] Epoch: 2 [84736/620022]    Loss: 0.011122   Batch Acc: 67.19
[Train] Epoch: 2 [84800/620022]    Loss: 0.007011   Batch Acc: 85.94
[Train] Epoch: 2 [84864/620022]    Loss: 0.009518   Batch Acc: 76.56
[Train] Epoch: 2 [84928/620022]    Loss: 0.009414   Batch Acc: 75.00
[Train] Epoch: 2 [84992/620022]    Loss: 0.009401   Batch Acc: 73.44
[Train] Epoch: 2 [85056/620022]    Loss: 0.009450   Batch Acc: 73.44
[Train] Epoch: 2 [85120/620022]    Loss: 0.009707   Batch Acc: 71.88
[Train] Epoch: 2 [85184/620022]    Loss: 0.007461   Batch Acc: 81.25
[Train] Epoch: 2 [85248/620022]    Loss: 0.008313   Batch Acc: 81.25
[Train] Epoch: 2 [85312/620022]    Loss: 0.007884   Batch Acc: 76.56
[Train] Epoch: 2 [85376/620022]    Loss: 0.008330   Batch Acc: 81.25
[Train] Epoch: 2 [85440/620022]    Loss: 0.006435   Batch Acc: 85.94
[Train] Epoch: 2 [85504/620022]    Loss: 0.008177   Batch Acc: 79.69
[Train] Epoch: 2 [85568/620022]    Loss: 0.009286   Batch Acc: 73.44
[Train] Epoch: 2 [85632/620022]    Loss: 0.007892   Batch Acc: 81.25
[Train] Epoch: 2 [85696/620022]    Loss: 0.008533   Batch Acc: 82.81
[Train] Epoch: 2 [85760/620022]    Loss: 0.007445   Batch Acc: 78.12
[Train] Epoch: 2 [85824/620022]    Loss: 0.007848   Batch Acc: 82.81
[Train] Epoch: 2 [85888/620022]    Loss: 0.007826   Batch Acc: 81.25
[Train] Epoch: 2 [85952/620022]    Loss: 0.010086   Batch Acc: 71.88
[Train] Epoch: 2 [86016/620022]    Loss: 0.007258   Batch Acc: 82.81
[Train] Epoch: 2 [86080/620022]    Loss: 0.006965   Batch Acc: 84.38
[Train] Epoch: 2 [86144/620022]    Loss: 0.006761   Batch Acc: 84.38
[Train] Epoch: 2 [86208/620022]    Loss: 0.006986   Batch Acc: 84.38
[Train] Epoch: 2 [86272/620022]    Loss: 0.009632   Batch Acc: 75.00
[Train] Epoch: 2 [86336/620022]    Loss: 0.008472   Batch Acc: 82.81
[Train] Epoch: 2 [86400/620022]    Loss: 0.007365   Batch Acc: 81.25
[Train] Epoch: 2 [86464/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 2 [86528/620022]    Loss: 0.006947   Batch Acc: 85.94
[Train] Epoch: 2 [86592/620022]    Loss: 0.007819   Batch Acc: 81.25
[Train] Epoch: 2 [86656/620022]    Loss: 0.009303   Batch Acc: 78.12
[Train] Epoch: 2 [86720/620022]    Loss: 0.009320   Batch Acc: 70.31
[Train] Epoch: 2 [86784/620022]    Loss: 0.006131   Batch Acc: 82.81
[Train] Epoch: 2 [86848/620022]    Loss: 0.008627   Batch Acc: 78.12
[Train] Epoch: 2 [86912/620022]    Loss: 0.010303   Batch Acc: 75.00
[Train] Epoch: 2 [86976/620022]    Loss: 0.006509   Batch Acc: 84.38
[Train] Epoch: 2 [87040/620022]    Loss: 0.007582   Batch Acc: 85.94
[Train] Epoch: 2 [87104/620022]    Loss: 0.008145   Batch Acc: 78.12
[Train] Epoch: 2 [87168/620022]    Loss: 0.006110   Batch Acc: 85.94
[Train] Epoch: 2 [87232/620022]    Loss: 0.007971   Batch Acc: 79.69
[Train] Epoch: 2 [87296/620022]    Loss: 0.010270   Batch Acc: 71.88
[Train] Epoch: 2 [87360/620022]    Loss: 0.007576   Batch Acc: 79.69
[Train] Epoch: 2 [87424/620022]    Loss: 0.008237   Batch Acc: 84.38
[Train] Epoch: 2 [87488/620022]    Loss: 0.006694   Batch Acc: 81.25
[Train] Epoch: 2 [87552/620022]    Loss: 0.006922   Batch Acc: 84.38
[Train] Epoch: 2 [87616/620022]    Loss: 0.007683   Batch Acc: 82.81
[Train] Epoch: 2 [87680/620022]    Loss: 0.008236   Batch Acc: 75.00
[Train] Epoch: 2 [87744/620022]    Loss: 0.007909   Batch Acc: 78.12
[Train] Epoch: 2 [87808/620022]    Loss: 0.007493   Batch Acc: 78.12
[Train] Epoch: 2 [87872/620022]    Loss: 0.008632   Batch Acc: 81.25
[Train] Epoch: 2 [87936/620022]    Loss: 0.007583   Batch Acc: 82.81
[Train] Epoch: 2 [88000/620022]    Loss: 0.009346   Batch Acc: 76.56
[Train] Epoch: 2 [88064/620022]    Loss: 0.006762   Batch Acc: 84.38
[Train] Epoch: 2 [88128/620022]    Loss: 0.008397   Batch Acc: 76.56
[Train] Epoch: 2 [88192/620022]    Loss: 0.009007   Batch Acc: 79.69
[Train] Epoch: 2 [88256/620022]    Loss: 0.009036   Batch Acc: 79.69
[Train] Epoch: 2 [88320/620022]    Loss: 0.007543   Batch Acc: 85.94
[Train] Epoch: 2 [88384/620022]    Loss: 0.006559   Batch Acc: 87.50
[Train] Epoch: 2 [88448/620022]    Loss: 0.007372   Batch Acc: 76.56
[Train] Epoch: 2 [88512/620022]    Loss: 0.008941   Batch Acc: 71.88
[Train] Epoch: 2 [88576/620022]    Loss: 0.008271   Batch Acc: 78.12
[Train] Epoch: 2 [88640/620022]    Loss: 0.009117   Batch Acc: 76.56
[Train] Epoch: 2 [88704/620022]    Loss: 0.006801   Batch Acc: 87.50
[Train] Epoch: 2 [88768/620022]    Loss: 0.006922   Batch Acc: 82.81
[Train] Epoch: 2 [88832/620022]    Loss: 0.008641   Batch Acc: 81.25
[Train] Epoch: 2 [88896/620022]    Loss: 0.008661   Batch Acc: 78.12
[Train] Epoch: 2 [88960/620022]    Loss: 0.008123   Batch Acc: 81.25
[Train] Epoch: 2 [89024/620022]    Loss: 0.010308   Batch Acc: 70.31
[Train] Epoch: 2 [89088/620022]    Loss: 0.008289   Batch Acc: 76.56
[Train] Epoch: 2 [89152/620022]    Loss: 0.009134   Batch Acc: 76.56
[Train] Epoch: 2 [89216/620022]    Loss: 0.009242   Batch Acc: 71.88
[Train] Epoch: 2 [89280/620022]    Loss: 0.008363   Batch Acc: 79.69
[Train] Epoch: 2 [89344/620022]    Loss: 0.007350   Batch Acc: 81.25
[Train] Epoch: 2 [89408/620022]    Loss: 0.007918   Batch Acc: 84.38
[Train] Epoch: 2 [89472/620022]    Loss: 0.006680   Batch Acc: 89.06
[Train] Epoch: 2 [89536/620022]    Loss: 0.008587   Batch Acc: 76.56
[Train] Epoch: 2 [89600/620022]    Loss: 0.007107   Batch Acc: 85.94
[Train] Epoch: 2 [89664/620022]    Loss: 0.008440   Batch Acc: 82.81
[Train] Epoch: 2 [89728/620022]    Loss: 0.007802   Batch Acc: 73.44
[Train] Epoch: 2 [89792/620022]    Loss: 0.006715   Batch Acc: 85.94
[Train] Epoch: 2 [89856/620022]    Loss: 0.008426   Batch Acc: 79.69
[Train] Epoch: 2 [89920/620022]    Loss: 0.008256   Batch Acc: 75.00
[Train] Epoch: 2 [89984/620022]    Loss: 0.009504   Batch Acc: 73.44
[Train] Epoch: 2 [90048/620022]    Loss: 0.006731   Batch Acc: 84.38
[Train] Epoch: 2 [90112/620022]    Loss: 0.009844   Batch Acc: 70.31
[Train] Epoch: 2 [90176/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 2 [90240/620022]    Loss: 0.012679   Batch Acc: 70.31
[Train] Epoch: 2 [90304/620022]    Loss: 0.008994   Batch Acc: 71.88
[Train] Epoch: 2 [90368/620022]    Loss: 0.008882   Batch Acc: 79.69
[Train] Epoch: 2 [90432/620022]    Loss: 0.007512   Batch Acc: 76.56
[Train] Epoch: 2 [90496/620022]    Loss: 0.007606   Batch Acc: 79.69
[Train] Epoch: 2 [90560/620022]    Loss: 0.008081   Batch Acc: 84.38
[Train] Epoch: 2 [90624/620022]    Loss: 0.007253   Batch Acc: 81.25
[Train] Epoch: 2 [90688/620022]    Loss: 0.008713   Batch Acc: 75.00
[Train] Epoch: 2 [90752/620022]    Loss: 0.007443   Batch Acc: 84.38
[Train] Epoch: 2 [90816/620022]    Loss: 0.010259   Batch Acc: 70.31
[Train] Epoch: 2 [90880/620022]    Loss: 0.009932   Batch Acc: 73.44
[Train] Epoch: 2 [90944/620022]    Loss: 0.011357   Batch Acc: 65.62
[Train] Epoch: 2 [91008/620022]    Loss: 0.010470   Batch Acc: 75.00
[Train] Epoch: 2 [91072/620022]    Loss: 0.008245   Batch Acc: 76.56
[Train] Epoch: 2 [91136/620022]    Loss: 0.006596   Batch Acc: 84.38
[Train] Epoch: 2 [91200/620022]    Loss: 0.010410   Batch Acc: 73.44
[Train] Epoch: 2 [91264/620022]    Loss: 0.008827   Batch Acc: 73.44
[Train] Epoch: 2 [91328/620022]    Loss: 0.008606   Batch Acc: 78.12
[Train] Epoch: 2 [91392/620022]    Loss: 0.009037   Batch Acc: 71.88
[Train] Epoch: 2 [91456/620022]    Loss: 0.008070   Batch Acc: 73.44
[Train] Epoch: 2 [91520/620022]    Loss: 0.008353   Batch Acc: 81.25
[Train] Epoch: 2 [91584/620022]    Loss: 0.007538   Batch Acc: 82.81
[Train] Epoch: 2 [91648/620022]    Loss: 0.007508   Batch Acc: 82.81
[Train] Epoch: 2 [91712/620022]    Loss: 0.007196   Batch Acc: 84.38
[Train] Epoch: 2 [91776/620022]    Loss: 0.007389   Batch Acc: 85.94
[Train] Epoch: 2 [91840/620022]    Loss: 0.010114   Batch Acc: 71.88
[Train] Epoch: 2 [91904/620022]    Loss: 0.009348   Batch Acc: 73.44
[Train] Epoch: 2 [91968/620022]    Loss: 0.007680   Batch Acc: 78.12
[Train] Epoch: 2 [92032/620022]    Loss: 0.006530   Batch Acc: 87.50
[Train] Epoch: 2 [92096/620022]    Loss: 0.007590   Batch Acc: 84.38
[Train] Epoch: 2 [92160/620022]    Loss: 0.007793   Batch Acc: 81.25
[Train] Epoch: 2 [92224/620022]    Loss: 0.009304   Batch Acc: 68.75
[Train] Epoch: 2 [92288/620022]    Loss: 0.011151   Batch Acc: 73.44
[Train] Epoch: 2 [92352/620022]    Loss: 0.010738   Batch Acc: 70.31
[Train] Epoch: 2 [92416/620022]    Loss: 0.009225   Batch Acc: 75.00
[Train] Epoch: 2 [92480/620022]    Loss: 0.007438   Batch Acc: 84.38
[Train] Epoch: 2 [92544/620022]    Loss: 0.008413   Batch Acc: 76.56
[Train] Epoch: 2 [92608/620022]    Loss: 0.012587   Batch Acc: 62.50
[Train] Epoch: 2 [92672/620022]    Loss: 0.009150   Batch Acc: 78.12
[Train] Epoch: 2 [92736/620022]    Loss: 0.007880   Batch Acc: 82.81
[Train] Epoch: 2 [92800/620022]    Loss: 0.007976   Batch Acc: 85.94
[Train] Epoch: 2 [92864/620022]    Loss: 0.007901   Batch Acc: 81.25
[Train] Epoch: 2 [92928/620022]    Loss: 0.007706   Batch Acc: 76.56
[Train] Epoch: 2 [92992/620022]    Loss: 0.008425   Batch Acc: 81.25
[Train] Epoch: 2 [93056/620022]    Loss: 0.006598   Batch Acc: 85.94
[Train] Epoch: 2 [93120/620022]    Loss: 0.007237   Batch Acc: 84.38
[Train] Epoch: 2 [93184/620022]    Loss: 0.010649   Batch Acc: 73.44
[Train] Epoch: 2 [93248/620022]    Loss: 0.006734   Batch Acc: 87.50
[Train] Epoch: 2 [93312/620022]    Loss: 0.006783   Batch Acc: 84.38
[Train] Epoch: 2 [93376/620022]    Loss: 0.009506   Batch Acc: 73.44
[Train] Epoch: 2 [93440/620022]    Loss: 0.008212   Batch Acc: 75.00
[Train] Epoch: 2 [93504/620022]    Loss: 0.009253   Batch Acc: 79.69
[Train] Epoch: 2 [93568/620022]    Loss: 0.008234   Batch Acc: 81.25
[Train] Epoch: 2 [93632/620022]    Loss: 0.007593   Batch Acc: 79.69
[Train] Epoch: 2 [93696/620022]    Loss: 0.008733   Batch Acc: 78.12
[Train] Epoch: 2 [93760/620022]    Loss: 0.008507   Batch Acc: 76.56
[Train] Epoch: 2 [93824/620022]    Loss: 0.008113   Batch Acc: 79.69
[Train] Epoch: 2 [93888/620022]    Loss: 0.008854   Batch Acc: 76.56
[Train] Epoch: 2 [93952/620022]    Loss: 0.008592   Batch Acc: 82.81
[Train] Epoch: 2 [94016/620022]    Loss: 0.008953   Batch Acc: 75.00
[Train] Epoch: 2 [94080/620022]    Loss: 0.008046   Batch Acc: 82.81
[Train] Epoch: 2 [94144/620022]    Loss: 0.006549   Batch Acc: 87.50
[Train] Epoch: 2 [94208/620022]    Loss: 0.008347   Batch Acc: 78.12
[Train] Epoch: 2 [94272/620022]    Loss: 0.009856   Batch Acc: 73.44
[Train] Epoch: 2 [94336/620022]    Loss: 0.008345   Batch Acc: 75.00
[Train] Epoch: 2 [94400/620022]    Loss: 0.012077   Batch Acc: 62.50
[Train] Epoch: 2 [94464/620022]    Loss: 0.007883   Batch Acc: 84.38
[Train] Epoch: 2 [94528/620022]    Loss: 0.012110   Batch Acc: 67.19
[Train] Epoch: 2 [94592/620022]    Loss: 0.007232   Batch Acc: 81.25
[Train] Epoch: 2 [94656/620022]    Loss: 0.008763   Batch Acc: 78.12
[Train] Epoch: 2 [94720/620022]    Loss: 0.008990   Batch Acc: 79.69
[Train] Epoch: 2 [94784/620022]    Loss: 0.008167   Batch Acc: 79.69
[Train] Epoch: 2 [94848/620022]    Loss: 0.008964   Batch Acc: 78.12
[Train] Epoch: 2 [94912/620022]    Loss: 0.009541   Batch Acc: 76.56
[Train] Epoch: 2 [94976/620022]    Loss: 0.009652   Batch Acc: 78.12
[Train] Epoch: 2 [95040/620022]    Loss: 0.009387   Batch Acc: 75.00
[Train] Epoch: 2 [95104/620022]    Loss: 0.011459   Batch Acc: 68.75
[Train] Epoch: 2 [95168/620022]    Loss: 0.009395   Batch Acc: 70.31
[Train] Epoch: 2 [95232/620022]    Loss: 0.010061   Batch Acc: 79.69
[Train] Epoch: 2 [95296/620022]    Loss: 0.007727   Batch Acc: 81.25
[Train] Epoch: 2 [95360/620022]    Loss: 0.011339   Batch Acc: 73.44
[Train] Epoch: 2 [95424/620022]    Loss: 0.008280   Batch Acc: 78.12
[Train] Epoch: 2 [95488/620022]    Loss: 0.009616   Batch Acc: 76.56
[Train] Epoch: 2 [95552/620022]    Loss: 0.006831   Batch Acc: 82.81
[Train] Epoch: 2 [95616/620022]    Loss: 0.010018   Batch Acc: 71.88
[Train] Epoch: 2 [95680/620022]    Loss: 0.009097   Batch Acc: 76.56
[Train] Epoch: 2 [95744/620022]    Loss: 0.006651   Batch Acc: 84.38
[Train] Epoch: 2 [95808/620022]    Loss: 0.008266   Batch Acc: 78.12
[Train] Epoch: 2 [95872/620022]    Loss: 0.010295   Batch Acc: 68.75
[Train] Epoch: 2 [95936/620022]    Loss: 0.006741   Batch Acc: 84.38
[Train] Epoch: 2 [96000/620022]    Loss: 0.008163   Batch Acc: 78.12
[Train] Epoch: 2 [96064/620022]    Loss: 0.009313   Batch Acc: 73.44
[Train] Epoch: 2 [96128/620022]    Loss: 0.007633   Batch Acc: 75.00
[Train] Epoch: 2 [96192/620022]    Loss: 0.008055   Batch Acc: 81.25
[Train] Epoch: 2 [96256/620022]    Loss: 0.008116   Batch Acc: 84.38
[Train] Epoch: 2 [96320/620022]    Loss: 0.011984   Batch Acc: 67.19
[Train] Epoch: 2 [96384/620022]    Loss: 0.010175   Batch Acc: 71.88
[Train] Epoch: 2 [96448/620022]    Loss: 0.007587   Batch Acc: 79.69
[Train] Epoch: 2 [96512/620022]    Loss: 0.008857   Batch Acc: 73.44
[Train] Epoch: 2 [96576/620022]    Loss: 0.010007   Batch Acc: 67.19
[Train] Epoch: 2 [96640/620022]    Loss: 0.009516   Batch Acc: 76.56
[Train] Epoch: 2 [96704/620022]    Loss: 0.006855   Batch Acc: 84.38
[Train] Epoch: 2 [96768/620022]    Loss: 0.008101   Batch Acc: 76.56
[Train] Epoch: 2 [96832/620022]    Loss: 0.008491   Batch Acc: 79.69
[Train] Epoch: 2 [96896/620022]    Loss: 0.008204   Batch Acc: 82.81
[Train] Epoch: 2 [96960/620022]    Loss: 0.007001   Batch Acc: 82.81
[Train] Epoch: 2 [97024/620022]    Loss: 0.009383   Batch Acc: 73.44
[Train] Epoch: 2 [97088/620022]    Loss: 0.008693   Batch Acc: 76.56
[Train] Epoch: 2 [97152/620022]    Loss: 0.006451   Batch Acc: 89.06
[Train] Epoch: 2 [97216/620022]    Loss: 0.009762   Batch Acc: 70.31
[Train] Epoch: 2 [97280/620022]    Loss: 0.008236   Batch Acc: 76.56
[Train] Epoch: 2 [97344/620022]    Loss: 0.009729   Batch Acc: 75.00
[Train] Epoch: 2 [97408/620022]    Loss: 0.007304   Batch Acc: 85.94
[Train] Epoch: 2 [97472/620022]    Loss: 0.010236   Batch Acc: 67.19
[Train] Epoch: 2 [97536/620022]    Loss: 0.007673   Batch Acc: 76.56
[Train] Epoch: 2 [97600/620022]    Loss: 0.008926   Batch Acc: 78.12
[Train] Epoch: 2 [97664/620022]    Loss: 0.007312   Batch Acc: 84.38
[Train] Epoch: 2 [97728/620022]    Loss: 0.011183   Batch Acc: 71.88
[Train] Epoch: 2 [97792/620022]    Loss: 0.008526   Batch Acc: 78.12
[Train] Epoch: 2 [97856/620022]    Loss: 0.009714   Batch Acc: 76.56
[Train] Epoch: 2 [97920/620022]    Loss: 0.010151   Batch Acc: 75.00
[Train] Epoch: 2 [97984/620022]    Loss: 0.009085   Batch Acc: 70.31
[Train] Epoch: 2 [98048/620022]    Loss: 0.008596   Batch Acc: 78.12
[Train] Epoch: 2 [98112/620022]    Loss: 0.009706   Batch Acc: 76.56
[Train] Epoch: 2 [98176/620022]    Loss: 0.008344   Batch Acc: 79.69
[Train] Epoch: 2 [98240/620022]    Loss: 0.009844   Batch Acc: 78.12
[Train] Epoch: 2 [98304/620022]    Loss: 0.006842   Batch Acc: 87.50
[Train] Epoch: 2 [98368/620022]    Loss: 0.010171   Batch Acc: 73.44
[Train] Epoch: 2 [98432/620022]    Loss: 0.009105   Batch Acc: 71.88
[Train] Epoch: 2 [98496/620022]    Loss: 0.007795   Batch Acc: 75.00
[Train] Epoch: 2 [98560/620022]    Loss: 0.009847   Batch Acc: 71.88
[Train] Epoch: 2 [98624/620022]    Loss: 0.006825   Batch Acc: 84.38
[Train] Epoch: 2 [98688/620022]    Loss: 0.007967   Batch Acc: 78.12
[Train] Epoch: 2 [98752/620022]    Loss: 0.006875   Batch Acc: 85.94
[Train] Epoch: 2 [98816/620022]    Loss: 0.008570   Batch Acc: 76.56
[Train] Epoch: 2 [98880/620022]    Loss: 0.008928   Batch Acc: 79.69
[Train] Epoch: 2 [98944/620022]    Loss: 0.008972   Batch Acc: 78.12
[Train] Epoch: 2 [99008/620022]    Loss: 0.006841   Batch Acc: 87.50
[Train] Epoch: 2 [99072/620022]    Loss: 0.008815   Batch Acc: 73.44
[Train] Epoch: 2 [99136/620022]    Loss: 0.009661   Batch Acc: 73.44
[Train] Epoch: 2 [99200/620022]    Loss: 0.009609   Batch Acc: 79.69
[Train] Epoch: 2 [99264/620022]    Loss: 0.008381   Batch Acc: 73.44
[Train] Epoch: 2 [99328/620022]    Loss: 0.009962   Batch Acc: 75.00
[Train] Epoch: 2 [99392/620022]    Loss: 0.010063   Batch Acc: 75.00
[Train] Epoch: 2 [99456/620022]    Loss: 0.006923   Batch Acc: 81.25
[Train] Epoch: 2 [99520/620022]    Loss: 0.006676   Batch Acc: 82.81
[Train] Epoch: 2 [99584/620022]    Loss: 0.010194   Batch Acc: 73.44
[Train] Epoch: 2 [99648/620022]    Loss: 0.008195   Batch Acc: 76.56
[Train] Epoch: 2 [99712/620022]    Loss: 0.009482   Batch Acc: 78.12
[Train] Epoch: 2 [99776/620022]    Loss: 0.009789   Batch Acc: 75.00
[Train] Epoch: 2 [99840/620022]    Loss: 0.011410   Batch Acc: 71.88
[Train] Epoch: 2 [99904/620022]    Loss: 0.007637   Batch Acc: 79.69
[Train] Epoch: 2 [99968/620022]    Loss: 0.007734   Batch Acc: 81.25
[Train] Epoch: 2 [100032/620022]    Loss: 0.008868   Batch Acc: 75.00
[Train] Epoch: 2 [100096/620022]    Loss: 0.008071   Batch Acc: 78.12
[Train] Epoch: 2 [100160/620022]    Loss: 0.008005   Batch Acc: 79.69
[Train] Epoch: 2 [100224/620022]    Loss: 0.006239   Batch Acc: 85.94
[Train] Epoch: 2 [100288/620022]    Loss: 0.009888   Batch Acc: 79.69
[Train] Epoch: 2 [100352/620022]    Loss: 0.008300   Batch Acc: 76.56
[Train] Epoch: 2 [100416/620022]    Loss: 0.007649   Batch Acc: 84.38
[Train] Epoch: 2 [100480/620022]    Loss: 0.010550   Batch Acc: 68.75
[Train] Epoch: 2 [100544/620022]    Loss: 0.006949   Batch Acc: 81.25
[Train] Epoch: 2 [100608/620022]    Loss: 0.009363   Batch Acc: 73.44
[Train] Epoch: 2 [100672/620022]    Loss: 0.009070   Batch Acc: 76.56
[Train] Epoch: 2 [100736/620022]    Loss: 0.008240   Batch Acc: 75.00
[Train] Epoch: 2 [100800/620022]    Loss: 0.009366   Batch Acc: 73.44
[Train] Epoch: 2 [100864/620022]    Loss: 0.009122   Batch Acc: 70.31
[Train] Epoch: 2 [100928/620022]    Loss: 0.012347   Batch Acc: 67.19
[Train] Epoch: 2 [100992/620022]    Loss: 0.008693   Batch Acc: 78.12
[Train] Epoch: 2 [101056/620022]    Loss: 0.007831   Batch Acc: 76.56
[Train] Epoch: 2 [101120/620022]    Loss: 0.008081   Batch Acc: 78.12
[Train] Epoch: 2 [101184/620022]    Loss: 0.007487   Batch Acc: 84.38
[Train] Epoch: 2 [101248/620022]    Loss: 0.008278   Batch Acc: 79.69
[Train] Epoch: 2 [101312/620022]    Loss: 0.008867   Batch Acc: 73.44
[Train] Epoch: 2 [101376/620022]    Loss: 0.007820   Batch Acc: 81.25
[Train] Epoch: 2 [101440/620022]    Loss: 0.008170   Batch Acc: 82.81
[Train] Epoch: 2 [101504/620022]    Loss: 0.007268   Batch Acc: 82.81
[Train] Epoch: 2 [101568/620022]    Loss: 0.010837   Batch Acc: 73.44
[Train] Epoch: 2 [101632/620022]    Loss: 0.007172   Batch Acc: 84.38
[Train] Epoch: 2 [101696/620022]    Loss: 0.008766   Batch Acc: 76.56
[Train] Epoch: 2 [101760/620022]    Loss: 0.008616   Batch Acc: 73.44
[Train] Epoch: 2 [101824/620022]    Loss: 0.008253   Batch Acc: 79.69
[Train] Epoch: 2 [101888/620022]    Loss: 0.005464   Batch Acc: 89.06
[Train] Epoch: 2 [101952/620022]    Loss: 0.008723   Batch Acc: 78.12
[Train] Epoch: 2 [102016/620022]    Loss: 0.007002   Batch Acc: 82.81
[Train] Epoch: 2 [102080/620022]    Loss: 0.007953   Batch Acc: 78.12
[Train] Epoch: 2 [102144/620022]    Loss: 0.008907   Batch Acc: 79.69
[Train] Epoch: 2 [102208/620022]    Loss: 0.010191   Batch Acc: 70.31
[Train] Epoch: 2 [102272/620022]    Loss: 0.008282   Batch Acc: 81.25
[Train] Epoch: 2 [102336/620022]    Loss: 0.007015   Batch Acc: 84.38
[Train] Epoch: 2 [102400/620022]    Loss: 0.009233   Batch Acc: 76.56
[Train] Epoch: 2 [102464/620022]    Loss: 0.009523   Batch Acc: 75.00
[Train] Epoch: 2 [102528/620022]    Loss: 0.005451   Batch Acc: 89.06
[Train] Epoch: 2 [102592/620022]    Loss: 0.008894   Batch Acc: 71.88
[Train] Epoch: 2 [102656/620022]    Loss: 0.007599   Batch Acc: 71.88
[Train] Epoch: 2 [102720/620022]    Loss: 0.010037   Batch Acc: 73.44
[Train] Epoch: 2 [102784/620022]    Loss: 0.009993   Batch Acc: 70.31
[Train] Epoch: 2 [102848/620022]    Loss: 0.007839   Batch Acc: 78.12
[Train] Epoch: 2 [102912/620022]    Loss: 0.009920   Batch Acc: 76.56
[Train] Epoch: 2 [102976/620022]    Loss: 0.008984   Batch Acc: 71.88
[Train] Epoch: 2 [103040/620022]    Loss: 0.008869   Batch Acc: 79.69
[Train] Epoch: 2 [103104/620022]    Loss: 0.007701   Batch Acc: 82.81
[Train] Epoch: 2 [103168/620022]    Loss: 0.009576   Batch Acc: 76.56
[Train] Epoch: 2 [103232/620022]    Loss: 0.011319   Batch Acc: 70.31
[Train] Epoch: 2 [103296/620022]    Loss: 0.009195   Batch Acc: 73.44
[Train] Epoch: 2 [103360/620022]    Loss: 0.008907   Batch Acc: 78.12
[Train] Epoch: 2 [103424/620022]    Loss: 0.008536   Batch Acc: 76.56
[Train] Epoch: 2 [103488/620022]    Loss: 0.009150   Batch Acc: 79.69
[Train] Epoch: 2 [103552/620022]    Loss: 0.007517   Batch Acc: 78.12
[Train] Epoch: 2 [103616/620022]    Loss: 0.008324   Batch Acc: 81.25
[Train] Epoch: 2 [103680/620022]    Loss: 0.008277   Batch Acc: 78.12
[Train] Epoch: 2 [103744/620022]    Loss: 0.011458   Batch Acc: 67.19
[Train] Epoch: 2 [103808/620022]    Loss: 0.009923   Batch Acc: 75.00
[Train] Epoch: 2 [103872/620022]    Loss: 0.010498   Batch Acc: 73.44
[Train] Epoch: 2 [103936/620022]    Loss: 0.008074   Batch Acc: 81.25
[Train] Epoch: 2 [104000/620022]    Loss: 0.005265   Batch Acc: 89.06
[Train] Epoch: 2 [104064/620022]    Loss: 0.007853   Batch Acc: 82.81
[Train] Epoch: 2 [104128/620022]    Loss: 0.007711   Batch Acc: 78.12
[Train] Epoch: 2 [104192/620022]    Loss: 0.009333   Batch Acc: 75.00
[Train] Epoch: 2 [104256/620022]    Loss: 0.006527   Batch Acc: 81.25
[Train] Epoch: 2 [104320/620022]    Loss: 0.007572   Batch Acc: 81.25
[Train] Epoch: 2 [104384/620022]    Loss: 0.008088   Batch Acc: 84.38
[Train] Epoch: 2 [104448/620022]    Loss: 0.009694   Batch Acc: 76.56
[Train] Epoch: 2 [104512/620022]    Loss: 0.009163   Batch Acc: 75.00
[Train] Epoch: 2 [104576/620022]    Loss: 0.008330   Batch Acc: 81.25
[Train] Epoch: 2 [104640/620022]    Loss: 0.009014   Batch Acc: 81.25
[Train] Epoch: 2 [104704/620022]    Loss: 0.006666   Batch Acc: 85.94
[Train] Epoch: 2 [104768/620022]    Loss: 0.009248   Batch Acc: 78.12
[Train] Epoch: 2 [104832/620022]    Loss: 0.008193   Batch Acc: 78.12
[Train] Epoch: 2 [104896/620022]    Loss: 0.007055   Batch Acc: 81.25
[Train] Epoch: 2 [104960/620022]    Loss: 0.007080   Batch Acc: 92.19
[Train] Epoch: 2 [105024/620022]    Loss: 0.008131   Batch Acc: 78.12
[Train] Epoch: 2 [105088/620022]    Loss: 0.009237   Batch Acc: 75.00
[Train] Epoch: 2 [105152/620022]    Loss: 0.009061   Batch Acc: 78.12
[Train] Epoch: 2 [105216/620022]    Loss: 0.007547   Batch Acc: 79.69
[Train] Epoch: 2 [105280/620022]    Loss: 0.009722   Batch Acc: 79.69
[Train] Epoch: 2 [105344/620022]    Loss: 0.006312   Batch Acc: 84.38
[Train] Epoch: 2 [105408/620022]    Loss: 0.008177   Batch Acc: 76.56
[Train] Epoch: 2 [105472/620022]    Loss: 0.010194   Batch Acc: 76.56
[Train] Epoch: 2 [105536/620022]    Loss: 0.008057   Batch Acc: 85.94
[Train] Epoch: 2 [105600/620022]    Loss: 0.009418   Batch Acc: 78.12
[Train] Epoch: 2 [105664/620022]    Loss: 0.007817   Batch Acc: 84.38
[Train] Epoch: 2 [105728/620022]    Loss: 0.010611   Batch Acc: 64.06
[Train] Epoch: 2 [105792/620022]    Loss: 0.007873   Batch Acc: 79.69
[Train] Epoch: 2 [105856/620022]    Loss: 0.006275   Batch Acc: 85.94
[Train] Epoch: 2 [105920/620022]    Loss: 0.009360   Batch Acc: 68.75
[Train] Epoch: 2 [105984/620022]    Loss: 0.009979   Batch Acc: 71.88
[Train] Epoch: 2 [106048/620022]    Loss: 0.008216   Batch Acc: 84.38
[Train] Epoch: 2 [106112/620022]    Loss: 0.009850   Batch Acc: 71.88
[Train] Epoch: 2 [106176/620022]    Loss: 0.006772   Batch Acc: 82.81
[Train] Epoch: 2 [106240/620022]    Loss: 0.009296   Batch Acc: 78.12
[Train] Epoch: 2 [106304/620022]    Loss: 0.010804   Batch Acc: 71.88
[Train] Epoch: 2 [106368/620022]    Loss: 0.008687   Batch Acc: 82.81
[Train] Epoch: 2 [106432/620022]    Loss: 0.008191   Batch Acc: 79.69
[Train] Epoch: 2 [106496/620022]    Loss: 0.008984   Batch Acc: 73.44
[Train] Epoch: 2 [106560/620022]    Loss: 0.006097   Batch Acc: 82.81
[Train] Epoch: 2 [106624/620022]    Loss: 0.010484   Batch Acc: 70.31
[Train] Epoch: 2 [106688/620022]    Loss: 0.008068   Batch Acc: 78.12
[Train] Epoch: 2 [106752/620022]    Loss: 0.009378   Batch Acc: 73.44
[Train] Epoch: 2 [106816/620022]    Loss: 0.009408   Batch Acc: 75.00
[Train] Epoch: 2 [106880/620022]    Loss: 0.007246   Batch Acc: 84.38
[Train] Epoch: 2 [106944/620022]    Loss: 0.005387   Batch Acc: 93.75
[Train] Epoch: 2 [107008/620022]    Loss: 0.007505   Batch Acc: 76.56
[Train] Epoch: 2 [107072/620022]    Loss: 0.007305   Batch Acc: 84.38
[Train] Epoch: 2 [107136/620022]    Loss: 0.010537   Batch Acc: 71.88
[Train] Epoch: 2 [107200/620022]    Loss: 0.007737   Batch Acc: 79.69
[Train] Epoch: 2 [107264/620022]    Loss: 0.008370   Batch Acc: 82.81
[Train] Epoch: 2 [107328/620022]    Loss: 0.009650   Batch Acc: 78.12
[Train] Epoch: 2 [107392/620022]    Loss: 0.006906   Batch Acc: 81.25
[Train] Epoch: 2 [107456/620022]    Loss: 0.009614   Batch Acc: 75.00
[Train] Epoch: 2 [107520/620022]    Loss: 0.006828   Batch Acc: 82.81
[Train] Epoch: 2 [107584/620022]    Loss: 0.008231   Batch Acc: 78.12
[Train] Epoch: 2 [107648/620022]    Loss: 0.011936   Batch Acc: 68.75
[Train] Epoch: 2 [107712/620022]    Loss: 0.008057   Batch Acc: 82.81
[Train] Epoch: 2 [107776/620022]    Loss: 0.012126   Batch Acc: 70.31
[Train] Epoch: 2 [107840/620022]    Loss: 0.006583   Batch Acc: 84.38
[Train] Epoch: 2 [107904/620022]    Loss: 0.008752   Batch Acc: 81.25
[Train] Epoch: 2 [107968/620022]    Loss: 0.006087   Batch Acc: 89.06
[Train] Epoch: 2 [108032/620022]    Loss: 0.009100   Batch Acc: 82.81
[Train] Epoch: 2 [108096/620022]    Loss: 0.009660   Batch Acc: 78.12
[Train] Epoch: 2 [108160/620022]    Loss: 0.006479   Batch Acc: 87.50
[Train] Epoch: 2 [108224/620022]    Loss: 0.009637   Batch Acc: 76.56
[Train] Epoch: 2 [108288/620022]    Loss: 0.008394   Batch Acc: 78.12
[Train] Epoch: 2 [108352/620022]    Loss: 0.011847   Batch Acc: 70.31
[Train] Epoch: 2 [108416/620022]    Loss: 0.009086   Batch Acc: 76.56
[Train] Epoch: 2 [108480/620022]    Loss: 0.008429   Batch Acc: 76.56
[Train] Epoch: 2 [108544/620022]    Loss: 0.008398   Batch Acc: 85.94
[Train] Epoch: 2 [108608/620022]    Loss: 0.007614   Batch Acc: 76.56
[Train] Epoch: 2 [108672/620022]    Loss: 0.008740   Batch Acc: 76.56
[Train] Epoch: 2 [108736/620022]    Loss: 0.007714   Batch Acc: 79.69
[Train] Epoch: 2 [108800/620022]    Loss: 0.009926   Batch Acc: 78.12
[Train] Epoch: 2 [108864/620022]    Loss: 0.007959   Batch Acc: 81.25
[Train] Epoch: 2 [108928/620022]    Loss: 0.009240   Batch Acc: 76.56
[Train] Epoch: 2 [108992/620022]    Loss: 0.008729   Batch Acc: 76.56
[Train] Epoch: 2 [109056/620022]    Loss: 0.009814   Batch Acc: 73.44
[Train] Epoch: 2 [109120/620022]    Loss: 0.007751   Batch Acc: 82.81
[Train] Epoch: 2 [109184/620022]    Loss: 0.006013   Batch Acc: 87.50
[Train] Epoch: 2 [109248/620022]    Loss: 0.007482   Batch Acc: 75.00
[Train] Epoch: 2 [109312/620022]    Loss: 0.011403   Batch Acc: 67.19
[Train] Epoch: 2 [109376/620022]    Loss: 0.009285   Batch Acc: 79.69
[Train] Epoch: 2 [109440/620022]    Loss: 0.009341   Batch Acc: 82.81
[Train] Epoch: 2 [109504/620022]    Loss: 0.007387   Batch Acc: 78.12
[Train] Epoch: 2 [109568/620022]    Loss: 0.009284   Batch Acc: 73.44
[Train] Epoch: 2 [109632/620022]    Loss: 0.008683   Batch Acc: 76.56
[Train] Epoch: 2 [109696/620022]    Loss: 0.009326   Batch Acc: 73.44
[Train] Epoch: 2 [109760/620022]    Loss: 0.008324   Batch Acc: 79.69
[Train] Epoch: 2 [109824/620022]    Loss: 0.009806   Batch Acc: 78.12
[Train] Epoch: 2 [109888/620022]    Loss: 0.008245   Batch Acc: 85.94
[Train] Epoch: 2 [109952/620022]    Loss: 0.009024   Batch Acc: 73.44
[Train] Epoch: 2 [110016/620022]    Loss: 0.006641   Batch Acc: 84.38
[Train] Epoch: 2 [110080/620022]    Loss: 0.009323   Batch Acc: 71.88
[Train] Epoch: 2 [110144/620022]    Loss: 0.008538   Batch Acc: 78.12
[Train] Epoch: 2 [110208/620022]    Loss: 0.008273   Batch Acc: 79.69
[Train] Epoch: 2 [110272/620022]    Loss: 0.009319   Batch Acc: 78.12
[Train] Epoch: 2 [110336/620022]    Loss: 0.007426   Batch Acc: 85.94
[Train] Epoch: 2 [110400/620022]    Loss: 0.008875   Batch Acc: 75.00
[Train] Epoch: 2 [110464/620022]    Loss: 0.008249   Batch Acc: 79.69
[Train] Epoch: 2 [110528/620022]    Loss: 0.010925   Batch Acc: 70.31
[Train] Epoch: 2 [110592/620022]    Loss: 0.009396   Batch Acc: 76.56
[Train] Epoch: 2 [110656/620022]    Loss: 0.007095   Batch Acc: 87.50
[Train] Epoch: 2 [110720/620022]    Loss: 0.006575   Batch Acc: 82.81
[Train] Epoch: 2 [110784/620022]    Loss: 0.007869   Batch Acc: 79.69
[Train] Epoch: 2 [110848/620022]    Loss: 0.007406   Batch Acc: 78.12
[Train] Epoch: 2 [110912/620022]    Loss: 0.007834   Batch Acc: 81.25
[Train] Epoch: 2 [110976/620022]    Loss: 0.009279   Batch Acc: 75.00
[Train] Epoch: 2 [111040/620022]    Loss: 0.010590   Batch Acc: 68.75
[Train] Epoch: 2 [111104/620022]    Loss: 0.004561   Batch Acc: 95.31
[Train] Epoch: 2 [111168/620022]    Loss: 0.007909   Batch Acc: 82.81
[Train] Epoch: 2 [111232/620022]    Loss: 0.009670   Batch Acc: 73.44
[Train] Epoch: 2 [111296/620022]    Loss: 0.009639   Batch Acc: 76.56
[Train] Epoch: 2 [111360/620022]    Loss: 0.008784   Batch Acc: 76.56
[Train] Epoch: 2 [111424/620022]    Loss: 0.010006   Batch Acc: 75.00
[Train] Epoch: 2 [111488/620022]    Loss: 0.010716   Batch Acc: 67.19
[Train] Epoch: 2 [111552/620022]    Loss: 0.008020   Batch Acc: 78.12
[Train] Epoch: 2 [111616/620022]    Loss: 0.011517   Batch Acc: 71.88
[Train] Epoch: 2 [111680/620022]    Loss: 0.009478   Batch Acc: 75.00
[Train] Epoch: 2 [111744/620022]    Loss: 0.009663   Batch Acc: 78.12
[Train] Epoch: 2 [111808/620022]    Loss: 0.010501   Batch Acc: 73.44
[Train] Epoch: 2 [111872/620022]    Loss: 0.007545   Batch Acc: 81.25
[Train] Epoch: 2 [111936/620022]    Loss: 0.008938   Batch Acc: 76.56
[Train] Epoch: 2 [112000/620022]    Loss: 0.005856   Batch Acc: 87.50
[Train] Epoch: 2 [112064/620022]    Loss: 0.009638   Batch Acc: 76.56
[Train] Epoch: 2 [112128/620022]    Loss: 0.009870   Batch Acc: 79.69
[Train] Epoch: 2 [112192/620022]    Loss: 0.009593   Batch Acc: 73.44
[Train] Epoch: 2 [112256/620022]    Loss: 0.011797   Batch Acc: 68.75
[Train] Epoch: 2 [112320/620022]    Loss: 0.008502   Batch Acc: 71.88
[Train] Epoch: 2 [112384/620022]    Loss: 0.006569   Batch Acc: 85.94
[Train] Epoch: 2 [112448/620022]    Loss: 0.008926   Batch Acc: 79.69
[Train] Epoch: 2 [112512/620022]    Loss: 0.006994   Batch Acc: 84.38
[Train] Epoch: 2 [112576/620022]    Loss: 0.007973   Batch Acc: 71.88
[Train] Epoch: 2 [112640/620022]    Loss: 0.008976   Batch Acc: 78.12
[Train] Epoch: 2 [112704/620022]    Loss: 0.009977   Batch Acc: 73.44
[Train] Epoch: 2 [112768/620022]    Loss: 0.007655   Batch Acc: 81.25
[Train] Epoch: 2 [112832/620022]    Loss: 0.011096   Batch Acc: 67.19
[Train] Epoch: 2 [112896/620022]    Loss: 0.009162   Batch Acc: 76.56
[Train] Epoch: 2 [112960/620022]    Loss: 0.007896   Batch Acc: 84.38
[Train] Epoch: 2 [113024/620022]    Loss: 0.008396   Batch Acc: 78.12
[Train] Epoch: 2 [113088/620022]    Loss: 0.009232   Batch Acc: 78.12
[Train] Epoch: 2 [113152/620022]    Loss: 0.009013   Batch Acc: 81.25
[Train] Epoch: 2 [113216/620022]    Loss: 0.008457   Batch Acc: 76.56
[Train] Epoch: 2 [113280/620022]    Loss: 0.011228   Batch Acc: 68.75
[Train] Epoch: 2 [113344/620022]    Loss: 0.008786   Batch Acc: 78.12
[Train] Epoch: 2 [113408/620022]    Loss: 0.008062   Batch Acc: 76.56
[Train] Epoch: 2 [113472/620022]    Loss: 0.007766   Batch Acc: 81.25
[Train] Epoch: 2 [113536/620022]    Loss: 0.008052   Batch Acc: 75.00
[Train] Epoch: 2 [113600/620022]    Loss: 0.009817   Batch Acc: 78.12
[Train] Epoch: 2 [113664/620022]    Loss: 0.005857   Batch Acc: 90.62
[Train] Epoch: 2 [113728/620022]    Loss: 0.008515   Batch Acc: 78.12
[Train] Epoch: 2 [113792/620022]    Loss: 0.006365   Batch Acc: 92.19
[Train] Epoch: 2 [113856/620022]    Loss: 0.008692   Batch Acc: 81.25
[Train] Epoch: 2 [113920/620022]    Loss: 0.010912   Batch Acc: 67.19
[Train] Epoch: 2 [113984/620022]    Loss: 0.008271   Batch Acc: 78.12
[Train] Epoch: 2 [114048/620022]    Loss: 0.007891   Batch Acc: 78.12
[Train] Epoch: 2 [114112/620022]    Loss: 0.006468   Batch Acc: 85.94
[Train] Epoch: 2 [114176/620022]    Loss: 0.011236   Batch Acc: 73.44
[Train] Epoch: 2 [114240/620022]    Loss: 0.008044   Batch Acc: 78.12
[Train] Epoch: 2 [114304/620022]    Loss: 0.008393   Batch Acc: 81.25
[Train] Epoch: 2 [114368/620022]    Loss: 0.008527   Batch Acc: 75.00
[Train] Epoch: 2 [114432/620022]    Loss: 0.008334   Batch Acc: 78.12
[Train] Epoch: 2 [114496/620022]    Loss: 0.009361   Batch Acc: 79.69
[Train] Epoch: 2 [114560/620022]    Loss: 0.007418   Batch Acc: 84.38
[Train] Epoch: 2 [114624/620022]    Loss: 0.008278   Batch Acc: 76.56
[Train] Epoch: 2 [114688/620022]    Loss: 0.007676   Batch Acc: 81.25
[Train] Epoch: 2 [114752/620022]    Loss: 0.006539   Batch Acc: 89.06
[Train] Epoch: 2 [114816/620022]    Loss: 0.008631   Batch Acc: 79.69
[Train] Epoch: 2 [114880/620022]    Loss: 0.008093   Batch Acc: 81.25
[Train] Epoch: 2 [114944/620022]    Loss: 0.007455   Batch Acc: 78.12
[Train] Epoch: 2 [115008/620022]    Loss: 0.010840   Batch Acc: 71.88
[Train] Epoch: 2 [115072/620022]    Loss: 0.009586   Batch Acc: 79.69
[Train] Epoch: 2 [115136/620022]    Loss: 0.006909   Batch Acc: 82.81
[Train] Epoch: 2 [115200/620022]    Loss: 0.007179   Batch Acc: 82.81
[Train] Epoch: 2 [115264/620022]    Loss: 0.007551   Batch Acc: 79.69
[Train] Epoch: 2 [115328/620022]    Loss: 0.007121   Batch Acc: 81.25
[Train] Epoch: 2 [115392/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 2 [115456/620022]    Loss: 0.009188   Batch Acc: 79.69
[Train] Epoch: 2 [115520/620022]    Loss: 0.010531   Batch Acc: 67.19
[Train] Epoch: 2 [115584/620022]    Loss: 0.008050   Batch Acc: 79.69
[Train] Epoch: 2 [115648/620022]    Loss: 0.009893   Batch Acc: 73.44
[Train] Epoch: 2 [115712/620022]    Loss: 0.008700   Batch Acc: 78.12
[Train] Epoch: 2 [115776/620022]    Loss: 0.007332   Batch Acc: 84.38
[Train] Epoch: 2 [115840/620022]    Loss: 0.009739   Batch Acc: 71.88
[Train] Epoch: 2 [115904/620022]    Loss: 0.009933   Batch Acc: 75.00
[Train] Epoch: 2 [115968/620022]    Loss: 0.007626   Batch Acc: 84.38
[Train] Epoch: 2 [116032/620022]    Loss: 0.009320   Batch Acc: 81.25
[Train] Epoch: 2 [116096/620022]    Loss: 0.008141   Batch Acc: 82.81
[Train] Epoch: 2 [116160/620022]    Loss: 0.007572   Batch Acc: 84.38
[Train] Epoch: 2 [116224/620022]    Loss: 0.007074   Batch Acc: 87.50
[Train] Epoch: 2 [116288/620022]    Loss: 0.010514   Batch Acc: 76.56
[Train] Epoch: 2 [116352/620022]    Loss: 0.007259   Batch Acc: 87.50
[Train] Epoch: 2 [116416/620022]    Loss: 0.008277   Batch Acc: 79.69
[Train] Epoch: 2 [116480/620022]    Loss: 0.007590   Batch Acc: 75.00
[Train] Epoch: 2 [116544/620022]    Loss: 0.008143   Batch Acc: 81.25
[Train] Epoch: 2 [116608/620022]    Loss: 0.008228   Batch Acc: 76.56
[Train] Epoch: 2 [116672/620022]    Loss: 0.010621   Batch Acc: 71.88
[Train] Epoch: 2 [116736/620022]    Loss: 0.006139   Batch Acc: 82.81
[Train] Epoch: 2 [116800/620022]    Loss: 0.008754   Batch Acc: 81.25
[Train] Epoch: 2 [116864/620022]    Loss: 0.010693   Batch Acc: 67.19
[Train] Epoch: 2 [116928/620022]    Loss: 0.009573   Batch Acc: 76.56
[Train] Epoch: 2 [116992/620022]    Loss: 0.009776   Batch Acc: 67.19
[Train] Epoch: 2 [117056/620022]    Loss: 0.010631   Batch Acc: 68.75
[Train] Epoch: 2 [117120/620022]    Loss: 0.009951   Batch Acc: 70.31
[Train] Epoch: 2 [117184/620022]    Loss: 0.010565   Batch Acc: 73.44
[Train] Epoch: 2 [117248/620022]    Loss: 0.011562   Batch Acc: 64.06
[Train] Epoch: 2 [117312/620022]    Loss: 0.010374   Batch Acc: 71.88
[Train] Epoch: 2 [117376/620022]    Loss: 0.010163   Batch Acc: 75.00
[Train] Epoch: 2 [117440/620022]    Loss: 0.009825   Batch Acc: 78.12
[Train] Epoch: 2 [117504/620022]    Loss: 0.006588   Batch Acc: 84.38
[Train] Epoch: 2 [117568/620022]    Loss: 0.009565   Batch Acc: 78.12
[Train] Epoch: 2 [117632/620022]    Loss: 0.006477   Batch Acc: 89.06
[Train] Epoch: 2 [117696/620022]    Loss: 0.009744   Batch Acc: 76.56
[Train] Epoch: 2 [117760/620022]    Loss: 0.010290   Batch Acc: 73.44
[Train] Epoch: 2 [117824/620022]    Loss: 0.009003   Batch Acc: 73.44
[Train] Epoch: 2 [117888/620022]    Loss: 0.008727   Batch Acc: 78.12
[Train] Epoch: 2 [117952/620022]    Loss: 0.008266   Batch Acc: 73.44
[Train] Epoch: 2 [118016/620022]    Loss: 0.007706   Batch Acc: 78.12
[Train] Epoch: 2 [118080/620022]    Loss: 0.008422   Batch Acc: 81.25
[Train] Epoch: 2 [118144/620022]    Loss: 0.007143   Batch Acc: 82.81
[Train] Epoch: 2 [118208/620022]    Loss: 0.009814   Batch Acc: 75.00
[Train] Epoch: 2 [118272/620022]    Loss: 0.006880   Batch Acc: 85.94
[Train] Epoch: 2 [118336/620022]    Loss: 0.011397   Batch Acc: 70.31
[Train] Epoch: 2 [118400/620022]    Loss: 0.009994   Batch Acc: 73.44
[Train] Epoch: 2 [118464/620022]    Loss: 0.007999   Batch Acc: 79.69
[Train] Epoch: 2 [118528/620022]    Loss: 0.009981   Batch Acc: 78.12
[Train] Epoch: 2 [118592/620022]    Loss: 0.008540   Batch Acc: 75.00
[Train] Epoch: 2 [118656/620022]    Loss: 0.007038   Batch Acc: 79.69
[Train] Epoch: 2 [118720/620022]    Loss: 0.007092   Batch Acc: 79.69
[Train] Epoch: 2 [118784/620022]    Loss: 0.007039   Batch Acc: 84.38
[Train] Epoch: 2 [118848/620022]    Loss: 0.009875   Batch Acc: 71.88
[Train] Epoch: 2 [118912/620022]    Loss: 0.008978   Batch Acc: 75.00
[Train] Epoch: 2 [118976/620022]    Loss: 0.007213   Batch Acc: 81.25
[Train] Epoch: 2 [119040/620022]    Loss: 0.008173   Batch Acc: 82.81
[Train] Epoch: 2 [119104/620022]    Loss: 0.009264   Batch Acc: 76.56
[Train] Epoch: 2 [119168/620022]    Loss: 0.007955   Batch Acc: 84.38
[Train] Epoch: 2 [119232/620022]    Loss: 0.009068   Batch Acc: 75.00
[Train] Epoch: 2 [119296/620022]    Loss: 0.007374   Batch Acc: 81.25
[Train] Epoch: 2 [119360/620022]    Loss: 0.011940   Batch Acc: 68.75
[Train] Epoch: 2 [119424/620022]    Loss: 0.008784   Batch Acc: 76.56
[Train] Epoch: 2 [119488/620022]    Loss: 0.007897   Batch Acc: 78.12
[Train] Epoch: 2 [119552/620022]    Loss: 0.008531   Batch Acc: 78.12
[Train] Epoch: 2 [119616/620022]    Loss: 0.009430   Batch Acc: 76.56
[Train] Epoch: 2 [119680/620022]    Loss: 0.009229   Batch Acc: 76.56
[Train] Epoch: 2 [119744/620022]    Loss: 0.008231   Batch Acc: 76.56
[Train] Epoch: 2 [119808/620022]    Loss: 0.009551   Batch Acc: 78.12
[Train] Epoch: 2 [119872/620022]    Loss: 0.007468   Batch Acc: 85.94
[Train] Epoch: 2 [119936/620022]    Loss: 0.007220   Batch Acc: 82.81
[Train] Epoch: 2 [120000/620022]    Loss: 0.009186   Batch Acc: 71.88
[Train] Epoch: 2 [120064/620022]    Loss: 0.010173   Batch Acc: 71.88
[Train] Epoch: 2 [120128/620022]    Loss: 0.008287   Batch Acc: 82.81
[Train] Epoch: 2 [120192/620022]    Loss: 0.010538   Batch Acc: 71.88
[Train] Epoch: 2 [120256/620022]    Loss: 0.007189   Batch Acc: 84.38
[Train] Epoch: 2 [120320/620022]    Loss: 0.007969   Batch Acc: 79.69
[Train] Epoch: 2 [120384/620022]    Loss: 0.007929   Batch Acc: 81.25
[Train] Epoch: 2 [120448/620022]    Loss: 0.009507   Batch Acc: 70.31
[Train] Epoch: 2 [120512/620022]    Loss: 0.009729   Batch Acc: 68.75
[Train] Epoch: 2 [120576/620022]    Loss: 0.007634   Batch Acc: 81.25
[Train] Epoch: 2 [120640/620022]    Loss: 0.009710   Batch Acc: 78.12
[Train] Epoch: 2 [120704/620022]    Loss: 0.010861   Batch Acc: 68.75
[Train] Epoch: 2 [120768/620022]    Loss: 0.008675   Batch Acc: 81.25
[Train] Epoch: 2 [120832/620022]    Loss: 0.007076   Batch Acc: 85.94
[Train] Epoch: 2 [120896/620022]    Loss: 0.007855   Batch Acc: 81.25
[Train] Epoch: 2 [120960/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 2 [121024/620022]    Loss: 0.009092   Batch Acc: 81.25
[Train] Epoch: 2 [121088/620022]    Loss: 0.009177   Batch Acc: 81.25
[Train] Epoch: 2 [121152/620022]    Loss: 0.007341   Batch Acc: 81.25
[Train] Epoch: 2 [121216/620022]    Loss: 0.010421   Batch Acc: 75.00
[Train] Epoch: 2 [121280/620022]    Loss: 0.008028   Batch Acc: 84.38
[Train] Epoch: 2 [121344/620022]    Loss: 0.007455   Batch Acc: 81.25
[Train] Epoch: 2 [121408/620022]    Loss: 0.009645   Batch Acc: 71.88
[Train] Epoch: 2 [121472/620022]    Loss: 0.008449   Batch Acc: 78.12
[Train] Epoch: 2 [121536/620022]    Loss: 0.008082   Batch Acc: 81.25
[Train] Epoch: 2 [121600/620022]    Loss: 0.010423   Batch Acc: 68.75
[Train] Epoch: 2 [121664/620022]    Loss: 0.011281   Batch Acc: 71.88
[Train] Epoch: 2 [121728/620022]    Loss: 0.010651   Batch Acc: 71.88
[Train] Epoch: 2 [121792/620022]    Loss: 0.008783   Batch Acc: 76.56
[Train] Epoch: 2 [121856/620022]    Loss: 0.011136   Batch Acc: 73.44
[Train] Epoch: 2 [121920/620022]    Loss: 0.009511   Batch Acc: 78.12
[Train] Epoch: 2 [121984/620022]    Loss: 0.009352   Batch Acc: 78.12
[Train] Epoch: 2 [122048/620022]    Loss: 0.008181   Batch Acc: 78.12
[Train] Epoch: 2 [122112/620022]    Loss: 0.007678   Batch Acc: 85.94
[Train] Epoch: 2 [122176/620022]    Loss: 0.008403   Batch Acc: 79.69
[Train] Epoch: 2 [122240/620022]    Loss: 0.010607   Batch Acc: 75.00
[Train] Epoch: 2 [122304/620022]    Loss: 0.009069   Batch Acc: 73.44
[Train] Epoch: 2 [122368/620022]    Loss: 0.009303   Batch Acc: 73.44
[Train] Epoch: 2 [122432/620022]    Loss: 0.007090   Batch Acc: 85.94
[Train] Epoch: 2 [122496/620022]    Loss: 0.007588   Batch Acc: 81.25
[Train] Epoch: 2 [122560/620022]    Loss: 0.008889   Batch Acc: 81.25
[Train] Epoch: 2 [122624/620022]    Loss: 0.009006   Batch Acc: 71.88
[Train] Epoch: 2 [122688/620022]    Loss: 0.008652   Batch Acc: 78.12
[Train] Epoch: 2 [122752/620022]    Loss: 0.006989   Batch Acc: 81.25
[Train] Epoch: 2 [122816/620022]    Loss: 0.009492   Batch Acc: 75.00
[Train] Epoch: 2 [122880/620022]    Loss: 0.010959   Batch Acc: 75.00
[Train] Epoch: 2 [122944/620022]    Loss: 0.008871   Batch Acc: 81.25
[Train] Epoch: 2 [123008/620022]    Loss: 0.008316   Batch Acc: 75.00
[Train] Epoch: 2 [123072/620022]    Loss: 0.008777   Batch Acc: 75.00
[Train] Epoch: 2 [123136/620022]    Loss: 0.006845   Batch Acc: 89.06
[Train] Epoch: 2 [123200/620022]    Loss: 0.008687   Batch Acc: 82.81
[Train] Epoch: 2 [123264/620022]    Loss: 0.008682   Batch Acc: 75.00
[Train] Epoch: 2 [123328/620022]    Loss: 0.008653   Batch Acc: 76.56
[Train] Epoch: 2 [123392/620022]    Loss: 0.012225   Batch Acc: 64.06
[Train] Epoch: 2 [123456/620022]    Loss: 0.008245   Batch Acc: 78.12
[Train] Epoch: 2 [123520/620022]    Loss: 0.008228   Batch Acc: 81.25
[Train] Epoch: 2 [123584/620022]    Loss: 0.008661   Batch Acc: 71.88
[Train] Epoch: 2 [123648/620022]    Loss: 0.009974   Batch Acc: 70.31
[Train] Epoch: 2 [123712/620022]    Loss: 0.011969   Batch Acc: 70.31
[Train] Epoch: 2 [123776/620022]    Loss: 0.007821   Batch Acc: 81.25
[Train] Epoch: 2 [123840/620022]    Loss: 0.009004   Batch Acc: 76.56
[Train] Epoch: 2 [123904/620022]    Loss: 0.008913   Batch Acc: 73.44
[Train] Epoch: 2 [123968/620022]    Loss: 0.006899   Batch Acc: 84.38
[Train] Epoch: 2 [124032/620022]    Loss: 0.011343   Batch Acc: 70.31
[Train] Epoch: 2 [124096/620022]    Loss: 0.008438   Batch Acc: 73.44
[Train] Epoch: 2 [124160/620022]    Loss: 0.008809   Batch Acc: 76.56
[Train] Epoch: 2 [124224/620022]    Loss: 0.008988   Batch Acc: 78.12
[Train] Epoch: 2 [124288/620022]    Loss: 0.009681   Batch Acc: 75.00
[Train] Epoch: 2 [124352/620022]    Loss: 0.008455   Batch Acc: 82.81
[Train] Epoch: 2 [124416/620022]    Loss: 0.008406   Batch Acc: 76.56
[Train] Epoch: 2 [124480/620022]    Loss: 0.008295   Batch Acc: 79.69
[Train] Epoch: 2 [124544/620022]    Loss: 0.008157   Batch Acc: 81.25
[Train] Epoch: 2 [124608/620022]    Loss: 0.008460   Batch Acc: 79.69
[Train] Epoch: 2 [124672/620022]    Loss: 0.011766   Batch Acc: 62.50
[Train] Epoch: 2 [124736/620022]    Loss: 0.009379   Batch Acc: 75.00
[Train] Epoch: 2 [124800/620022]    Loss: 0.010136   Batch Acc: 73.44
[Train] Epoch: 2 [124864/620022]    Loss: 0.012373   Batch Acc: 62.50
[Train] Epoch: 2 [124928/620022]    Loss: 0.007466   Batch Acc: 81.25
[Train] Epoch: 2 [124992/620022]    Loss: 0.008210   Batch Acc: 79.69
[Train] Epoch: 2 [125056/620022]    Loss: 0.008707   Batch Acc: 76.56
[Train] Epoch: 2 [125120/620022]    Loss: 0.010110   Batch Acc: 73.44
[Train] Epoch: 2 [125184/620022]    Loss: 0.008273   Batch Acc: 73.44
[Train] Epoch: 2 [125248/620022]    Loss: 0.006934   Batch Acc: 84.38
[Train] Epoch: 2 [125312/620022]    Loss: 0.010373   Batch Acc: 76.56
[Train] Epoch: 2 [125376/620022]    Loss: 0.009014   Batch Acc: 71.88
[Train] Epoch: 2 [125440/620022]    Loss: 0.010576   Batch Acc: 65.62
[Train] Epoch: 2 [125504/620022]    Loss: 0.009465   Batch Acc: 78.12
[Train] Epoch: 2 [125568/620022]    Loss: 0.010046   Batch Acc: 73.44
[Train] Epoch: 2 [125632/620022]    Loss: 0.008514   Batch Acc: 76.56
[Train] Epoch: 2 [125696/620022]    Loss: 0.007805   Batch Acc: 82.81
[Train] Epoch: 2 [125760/620022]    Loss: 0.009816   Batch Acc: 76.56
[Train] Epoch: 2 [125824/620022]    Loss: 0.010455   Batch Acc: 70.31
[Train] Epoch: 2 [125888/620022]    Loss: 0.008596   Batch Acc: 79.69
[Train] Epoch: 2 [125952/620022]    Loss: 0.009935   Batch Acc: 73.44
[Train] Epoch: 2 [126016/620022]    Loss: 0.006792   Batch Acc: 87.50
[Train] Epoch: 2 [126080/620022]    Loss: 0.009927   Batch Acc: 73.44
[Train] Epoch: 2 [126144/620022]    Loss: 0.008971   Batch Acc: 78.12
[Train] Epoch: 2 [126208/620022]    Loss: 0.009339   Batch Acc: 73.44
[Train] Epoch: 2 [126272/620022]    Loss: 0.008908   Batch Acc: 76.56
[Train] Epoch: 2 [126336/620022]    Loss: 0.008018   Batch Acc: 81.25
[Train] Epoch: 2 [126400/620022]    Loss: 0.008316   Batch Acc: 84.38
[Train] Epoch: 2 [126464/620022]    Loss: 0.009932   Batch Acc: 79.69
[Train] Epoch: 2 [126528/620022]    Loss: 0.008705   Batch Acc: 76.56
[Train] Epoch: 2 [126592/620022]    Loss: 0.010548   Batch Acc: 70.31
[Train] Epoch: 2 [126656/620022]    Loss: 0.009403   Batch Acc: 71.88
[Train] Epoch: 2 [126720/620022]    Loss: 0.009574   Batch Acc: 71.88
[Train] Epoch: 2 [126784/620022]    Loss: 0.008291   Batch Acc: 78.12
[Train] Epoch: 2 [126848/620022]    Loss: 0.011978   Batch Acc: 60.94
[Train] Epoch: 2 [126912/620022]    Loss: 0.009298   Batch Acc: 82.81
[Train] Epoch: 2 [126976/620022]    Loss: 0.009765   Batch Acc: 75.00
[Train] Epoch: 2 [127040/620022]    Loss: 0.008835   Batch Acc: 71.88
[Train] Epoch: 2 [127104/620022]    Loss: 0.006904   Batch Acc: 85.94
[Train] Epoch: 2 [127168/620022]    Loss: 0.007428   Batch Acc: 84.38
[Train] Epoch: 2 [127232/620022]    Loss: 0.009873   Batch Acc: 71.88
[Train] Epoch: 2 [127296/620022]    Loss: 0.008332   Batch Acc: 79.69
[Train] Epoch: 2 [127360/620022]    Loss: 0.008765   Batch Acc: 79.69
[Train] Epoch: 2 [127424/620022]    Loss: 0.009608   Batch Acc: 71.88
[Train] Epoch: 2 [127488/620022]    Loss: 0.009717   Batch Acc: 76.56
[Train] Epoch: 2 [127552/620022]    Loss: 0.006675   Batch Acc: 84.38
[Train] Epoch: 2 [127616/620022]    Loss: 0.008086   Batch Acc: 78.12
[Train] Epoch: 2 [127680/620022]    Loss: 0.008739   Batch Acc: 76.56
[Train] Epoch: 2 [127744/620022]    Loss: 0.007597   Batch Acc: 82.81
[Train] Epoch: 2 [127808/620022]    Loss: 0.007222   Batch Acc: 81.25
[Train] Epoch: 2 [127872/620022]    Loss: 0.008239   Batch Acc: 79.69
[Train] Epoch: 2 [127936/620022]    Loss: 0.010436   Batch Acc: 73.44
[Train] Epoch: 2 [128000/620022]    Loss: 0.009769   Batch Acc: 70.31
[Train] Epoch: 2 [128064/620022]    Loss: 0.009446   Batch Acc: 71.88
[Train] Epoch: 2 [128128/620022]    Loss: 0.008237   Batch Acc: 79.69
[Train] Epoch: 2 [128192/620022]    Loss: 0.007700   Batch Acc: 81.25
[Train] Epoch: 2 [128256/620022]    Loss: 0.007797   Batch Acc: 81.25
[Train] Epoch: 2 [128320/620022]    Loss: 0.007872   Batch Acc: 79.69
[Train] Epoch: 2 [128384/620022]    Loss: 0.007314   Batch Acc: 79.69
[Train] Epoch: 2 [128448/620022]    Loss: 0.009727   Batch Acc: 75.00
[Train] Epoch: 2 [128512/620022]    Loss: 0.007995   Batch Acc: 82.81
[Train] Epoch: 2 [128576/620022]    Loss: 0.008750   Batch Acc: 79.69
[Train] Epoch: 2 [128640/620022]    Loss: 0.009575   Batch Acc: 78.12
[Train] Epoch: 2 [128704/620022]    Loss: 0.007949   Batch Acc: 82.81
[Train] Epoch: 2 [128768/620022]    Loss: 0.007889   Batch Acc: 75.00
[Train] Epoch: 2 [128832/620022]    Loss: 0.011210   Batch Acc: 71.88
[Train] Epoch: 2 [128896/620022]    Loss: 0.008023   Batch Acc: 79.69
[Train] Epoch: 2 [128960/620022]    Loss: 0.008305   Batch Acc: 81.25
[Train] Epoch: 2 [129024/620022]    Loss: 0.008189   Batch Acc: 82.81
[Train] Epoch: 2 [129088/620022]    Loss: 0.006892   Batch Acc: 85.94
[Train] Epoch: 2 [129152/620022]    Loss: 0.006482   Batch Acc: 90.62
[Train] Epoch: 2 [129216/620022]    Loss: 0.008951   Batch Acc: 78.12
[Train] Epoch: 2 [129280/620022]    Loss: 0.012645   Batch Acc: 67.19
[Train] Epoch: 2 [129344/620022]    Loss: 0.009025   Batch Acc: 78.12
[Train] Epoch: 2 [129408/620022]    Loss: 0.010411   Batch Acc: 75.00
[Train] Epoch: 2 [129472/620022]    Loss: 0.008043   Batch Acc: 78.12
[Train] Epoch: 2 [129536/620022]    Loss: 0.009712   Batch Acc: 75.00
[Train] Epoch: 2 [129600/620022]    Loss: 0.012006   Batch Acc: 70.31
[Train] Epoch: 2 [129664/620022]    Loss: 0.008942   Batch Acc: 79.69
[Train] Epoch: 2 [129728/620022]    Loss: 0.009721   Batch Acc: 82.81
[Train] Epoch: 2 [129792/620022]    Loss: 0.008197   Batch Acc: 79.69
[Train] Epoch: 2 [129856/620022]    Loss: 0.009147   Batch Acc: 79.69
[Train] Epoch: 2 [129920/620022]    Loss: 0.007444   Batch Acc: 81.25
[Train] Epoch: 2 [129984/620022]    Loss: 0.009660   Batch Acc: 78.12
[Train] Epoch: 2 [130048/620022]    Loss: 0.009784   Batch Acc: 71.88
[Train] Epoch: 2 [130112/620022]    Loss: 0.008853   Batch Acc: 78.12
[Train] Epoch: 2 [130176/620022]    Loss: 0.008583   Batch Acc: 78.12
[Train] Epoch: 2 [130240/620022]    Loss: 0.008005   Batch Acc: 78.12
[Train] Epoch: 2 [130304/620022]    Loss: 0.007588   Batch Acc: 81.25
[Train] Epoch: 2 [130368/620022]    Loss: 0.011366   Batch Acc: 71.88
[Train] Epoch: 2 [130432/620022]    Loss: 0.006926   Batch Acc: 84.38
[Train] Epoch: 2 [130496/620022]    Loss: 0.007457   Batch Acc: 85.94
[Train] Epoch: 2 [130560/620022]    Loss: 0.008794   Batch Acc: 76.56
[Train] Epoch: 2 [130624/620022]    Loss: 0.007649   Batch Acc: 79.69
[Train] Epoch: 2 [130688/620022]    Loss: 0.007917   Batch Acc: 79.69
[Train] Epoch: 2 [130752/620022]    Loss: 0.009791   Batch Acc: 75.00
[Train] Epoch: 2 [130816/620022]    Loss: 0.010162   Batch Acc: 75.00
[Train] Epoch: 2 [130880/620022]    Loss: 0.006315   Batch Acc: 87.50
[Train] Epoch: 2 [130944/620022]    Loss: 0.007280   Batch Acc: 79.69
[Train] Epoch: 2 [131008/620022]    Loss: 0.009220   Batch Acc: 81.25
[Train] Epoch: 2 [131072/620022]    Loss: 0.009217   Batch Acc: 75.00
[Train] Epoch: 2 [131136/620022]    Loss: 0.009558   Batch Acc: 68.75
[Train] Epoch: 2 [131200/620022]    Loss: 0.008844   Batch Acc: 73.44
[Train] Epoch: 2 [131264/620022]    Loss: 0.006987   Batch Acc: 87.50
[Train] Epoch: 2 [131328/620022]    Loss: 0.008515   Batch Acc: 78.12
[Train] Epoch: 2 [131392/620022]    Loss: 0.009378   Batch Acc: 76.56
[Train] Epoch: 2 [131456/620022]    Loss: 0.007030   Batch Acc: 84.38
[Train] Epoch: 2 [131520/620022]    Loss: 0.009222   Batch Acc: 65.62
[Train] Epoch: 2 [131584/620022]    Loss: 0.011656   Batch Acc: 71.88
[Train] Epoch: 2 [131648/620022]    Loss: 0.006844   Batch Acc: 84.38
[Train] Epoch: 2 [131712/620022]    Loss: 0.009647   Batch Acc: 70.31
[Train] Epoch: 2 [131776/620022]    Loss: 0.008557   Batch Acc: 76.56
[Train] Epoch: 2 [131840/620022]    Loss: 0.009489   Batch Acc: 79.69
[Train] Epoch: 2 [131904/620022]    Loss: 0.008953   Batch Acc: 75.00
[Train] Epoch: 2 [131968/620022]    Loss: 0.006892   Batch Acc: 85.94
[Train] Epoch: 2 [132032/620022]    Loss: 0.006805   Batch Acc: 84.38
[Train] Epoch: 2 [132096/620022]    Loss: 0.007179   Batch Acc: 85.94
[Train] Epoch: 2 [132160/620022]    Loss: 0.009296   Batch Acc: 73.44
[Train] Epoch: 2 [132224/620022]    Loss: 0.010293   Batch Acc: 73.44
[Train] Epoch: 2 [132288/620022]    Loss: 0.008685   Batch Acc: 76.56
[Train] Epoch: 2 [132352/620022]    Loss: 0.008263   Batch Acc: 81.25
[Train] Epoch: 2 [132416/620022]    Loss: 0.010072   Batch Acc: 75.00
[Train] Epoch: 2 [132480/620022]    Loss: 0.008294   Batch Acc: 76.56
[Train] Epoch: 2 [132544/620022]    Loss: 0.011018   Batch Acc: 67.19
[Train] Epoch: 2 [132608/620022]    Loss: 0.009748   Batch Acc: 67.19
[Train] Epoch: 2 [132672/620022]    Loss: 0.010181   Batch Acc: 76.56
[Train] Epoch: 2 [132736/620022]    Loss: 0.008532   Batch Acc: 70.31
[Train] Epoch: 2 [132800/620022]    Loss: 0.006848   Batch Acc: 81.25
[Train] Epoch: 2 [132864/620022]    Loss: 0.009997   Batch Acc: 73.44
[Train] Epoch: 2 [132928/620022]    Loss: 0.008256   Batch Acc: 78.12
[Train] Epoch: 2 [132992/620022]    Loss: 0.006782   Batch Acc: 84.38
[Train] Epoch: 2 [133056/620022]    Loss: 0.009850   Batch Acc: 71.88
[Train] Epoch: 2 [133120/620022]    Loss: 0.007483   Batch Acc: 76.56
[Train] Epoch: 2 [133184/620022]    Loss: 0.009556   Batch Acc: 73.44
[Train] Epoch: 2 [133248/620022]    Loss: 0.008425   Batch Acc: 76.56
[Train] Epoch: 2 [133312/620022]    Loss: 0.009899   Batch Acc: 73.44
[Train] Epoch: 2 [133376/620022]    Loss: 0.010030   Batch Acc: 75.00
[Train] Epoch: 2 [133440/620022]    Loss: 0.010162   Batch Acc: 76.56
[Train] Epoch: 2 [133504/620022]    Loss: 0.008955   Batch Acc: 75.00
[Train] Epoch: 2 [133568/620022]    Loss: 0.009782   Batch Acc: 79.69
[Train] Epoch: 2 [133632/620022]    Loss: 0.006956   Batch Acc: 79.69
[Train] Epoch: 2 [133696/620022]    Loss: 0.007727   Batch Acc: 75.00
[Train] Epoch: 2 [133760/620022]    Loss: 0.008561   Batch Acc: 84.38
[Train] Epoch: 2 [133824/620022]    Loss: 0.009377   Batch Acc: 78.12
[Train] Epoch: 2 [133888/620022]    Loss: 0.007856   Batch Acc: 79.69
[Train] Epoch: 2 [133952/620022]    Loss: 0.007884   Batch Acc: 79.69
[Train] Epoch: 2 [134016/620022]    Loss: 0.010353   Batch Acc: 71.88
[Train] Epoch: 2 [134080/620022]    Loss: 0.010512   Batch Acc: 73.44
[Train] Epoch: 2 [134144/620022]    Loss: 0.007292   Batch Acc: 82.81
[Train] Epoch: 2 [134208/620022]    Loss: 0.008055   Batch Acc: 82.81
[Train] Epoch: 2 [134272/620022]    Loss: 0.006931   Batch Acc: 82.81
[Train] Epoch: 2 [134336/620022]    Loss: 0.007992   Batch Acc: 76.56
[Train] Epoch: 2 [134400/620022]    Loss: 0.009172   Batch Acc: 76.56
[Train] Epoch: 2 [134464/620022]    Loss: 0.006234   Batch Acc: 89.06
[Train] Epoch: 2 [134528/620022]    Loss: 0.008164   Batch Acc: 76.56
[Train] Epoch: 2 [134592/620022]    Loss: 0.007753   Batch Acc: 81.25
[Train] Epoch: 2 [134656/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 2 [134720/620022]    Loss: 0.008176   Batch Acc: 76.56
[Train] Epoch: 2 [134784/620022]    Loss: 0.009609   Batch Acc: 73.44
[Train] Epoch: 2 [134848/620022]    Loss: 0.009759   Batch Acc: 75.00
[Train] Epoch: 2 [134912/620022]    Loss: 0.010020   Batch Acc: 71.88
[Train] Epoch: 2 [134976/620022]    Loss: 0.009222   Batch Acc: 73.44
[Train] Epoch: 2 [135040/620022]    Loss: 0.007959   Batch Acc: 81.25
[Train] Epoch: 2 [135104/620022]    Loss: 0.008174   Batch Acc: 81.25
[Train] Epoch: 2 [135168/620022]    Loss: 0.008040   Batch Acc: 79.69
[Train] Epoch: 2 [135232/620022]    Loss: 0.006427   Batch Acc: 84.38
[Train] Epoch: 2 [135296/620022]    Loss: 0.008516   Batch Acc: 81.25
[Train] Epoch: 2 [135360/620022]    Loss: 0.008314   Batch Acc: 75.00
[Train] Epoch: 2 [135424/620022]    Loss: 0.007129   Batch Acc: 84.38
[Train] Epoch: 2 [135488/620022]    Loss: 0.005738   Batch Acc: 84.38
[Train] Epoch: 2 [135552/620022]    Loss: 0.008385   Batch Acc: 81.25
[Train] Epoch: 2 [135616/620022]    Loss: 0.010014   Batch Acc: 73.44
[Train] Epoch: 2 [135680/620022]    Loss: 0.011702   Batch Acc: 70.31
[Train] Epoch: 2 [135744/620022]    Loss: 0.009169   Batch Acc: 75.00
[Train] Epoch: 2 [135808/620022]    Loss: 0.009098   Batch Acc: 75.00
[Train] Epoch: 2 [135872/620022]    Loss: 0.009061   Batch Acc: 73.44
[Train] Epoch: 2 [135936/620022]    Loss: 0.006365   Batch Acc: 84.38
[Train] Epoch: 2 [136000/620022]    Loss: 0.006614   Batch Acc: 81.25
[Train] Epoch: 2 [136064/620022]    Loss: 0.008108   Batch Acc: 75.00
[Train] Epoch: 2 [136128/620022]    Loss: 0.008761   Batch Acc: 79.69
[Train] Epoch: 2 [136192/620022]    Loss: 0.008386   Batch Acc: 76.56
[Train] Epoch: 2 [136256/620022]    Loss: 0.008364   Batch Acc: 75.00
[Train] Epoch: 2 [136320/620022]    Loss: 0.008490   Batch Acc: 75.00
[Train] Epoch: 2 [136384/620022]    Loss: 0.007789   Batch Acc: 84.38
[Train] Epoch: 2 [136448/620022]    Loss: 0.008452   Batch Acc: 84.38
[Train] Epoch: 2 [136512/620022]    Loss: 0.009604   Batch Acc: 71.88
[Train] Epoch: 2 [136576/620022]    Loss: 0.011410   Batch Acc: 68.75
[Train] Epoch: 2 [136640/620022]    Loss: 0.008661   Batch Acc: 78.12
[Train] Epoch: 2 [136704/620022]    Loss: 0.009302   Batch Acc: 75.00
[Train] Epoch: 2 [136768/620022]    Loss: 0.010121   Batch Acc: 75.00
[Train] Epoch: 2 [136832/620022]    Loss: 0.007643   Batch Acc: 71.88
[Train] Epoch: 2 [136896/620022]    Loss: 0.009375   Batch Acc: 71.88
[Train] Epoch: 2 [136960/620022]    Loss: 0.009057   Batch Acc: 79.69
[Train] Epoch: 2 [137024/620022]    Loss: 0.008515   Batch Acc: 79.69
[Train] Epoch: 2 [137088/620022]    Loss: 0.007768   Batch Acc: 81.25
[Train] Epoch: 2 [137152/620022]    Loss: 0.007045   Batch Acc: 87.50
[Train] Epoch: 2 [137216/620022]    Loss: 0.008475   Batch Acc: 79.69
[Train] Epoch: 2 [137280/620022]    Loss: 0.007846   Batch Acc: 79.69
[Train] Epoch: 2 [137344/620022]    Loss: 0.009542   Batch Acc: 75.00
[Train] Epoch: 2 [137408/620022]    Loss: 0.009044   Batch Acc: 79.69
[Train] Epoch: 2 [137472/620022]    Loss: 0.009121   Batch Acc: 79.69
[Train] Epoch: 2 [137536/620022]    Loss: 0.008875   Batch Acc: 75.00
[Train] Epoch: 2 [137600/620022]    Loss: 0.009697   Batch Acc: 71.88
[Train] Epoch: 2 [137664/620022]    Loss: 0.010222   Batch Acc: 70.31
[Train] Epoch: 2 [137728/620022]    Loss: 0.006545   Batch Acc: 84.38
[Train] Epoch: 2 [137792/620022]    Loss: 0.009478   Batch Acc: 79.69
[Train] Epoch: 2 [137856/620022]    Loss: 0.007340   Batch Acc: 76.56
[Train] Epoch: 2 [137920/620022]    Loss: 0.010145   Batch Acc: 75.00
[Train] Epoch: 2 [137984/620022]    Loss: 0.008429   Batch Acc: 78.12
[Train] Epoch: 2 [138048/620022]    Loss: 0.007997   Batch Acc: 79.69
[Train] Epoch: 2 [138112/620022]    Loss: 0.007551   Batch Acc: 81.25
[Train] Epoch: 2 [138176/620022]    Loss: 0.007713   Batch Acc: 82.81
[Train] Epoch: 2 [138240/620022]    Loss: 0.007903   Batch Acc: 75.00
[Train] Epoch: 2 [138304/620022]    Loss: 0.008574   Batch Acc: 76.56
[Train] Epoch: 2 [138368/620022]    Loss: 0.007176   Batch Acc: 84.38
[Train] Epoch: 2 [138432/620022]    Loss: 0.010236   Batch Acc: 73.44
[Train] Epoch: 2 [138496/620022]    Loss: 0.007711   Batch Acc: 84.38
[Train] Epoch: 2 [138560/620022]    Loss: 0.007288   Batch Acc: 79.69
[Train] Epoch: 2 [138624/620022]    Loss: 0.012498   Batch Acc: 68.75
[Train] Epoch: 2 [138688/620022]    Loss: 0.006492   Batch Acc: 82.81
[Train] Epoch: 2 [138752/620022]    Loss: 0.008670   Batch Acc: 81.25
[Train] Epoch: 2 [138816/620022]    Loss: 0.008048   Batch Acc: 78.12
[Train] Epoch: 2 [138880/620022]    Loss: 0.009250   Batch Acc: 76.56
[Train] Epoch: 2 [138944/620022]    Loss: 0.009968   Batch Acc: 70.31
[Train] Epoch: 2 [139008/620022]    Loss: 0.008005   Batch Acc: 84.38
[Train] Epoch: 2 [139072/620022]    Loss: 0.008599   Batch Acc: 73.44
[Train] Epoch: 2 [139136/620022]    Loss: 0.006247   Batch Acc: 87.50
[Train] Epoch: 2 [139200/620022]    Loss: 0.007513   Batch Acc: 78.12
[Train] Epoch: 2 [139264/620022]    Loss: 0.009534   Batch Acc: 75.00
[Train] Epoch: 2 [139328/620022]    Loss: 0.010580   Batch Acc: 73.44
[Train] Epoch: 2 [139392/620022]    Loss: 0.009802   Batch Acc: 76.56
[Train] Epoch: 2 [139456/620022]    Loss: 0.011737   Batch Acc: 64.06
[Train] Epoch: 2 [139520/620022]    Loss: 0.008699   Batch Acc: 81.25
[Train] Epoch: 2 [139584/620022]    Loss: 0.007335   Batch Acc: 76.56
[Train] Epoch: 2 [139648/620022]    Loss: 0.007902   Batch Acc: 81.25
[Train] Epoch: 2 [139712/620022]    Loss: 0.011389   Batch Acc: 64.06
[Train] Epoch: 2 [139776/620022]    Loss: 0.008695   Batch Acc: 75.00
[Train] Epoch: 2 [139840/620022]    Loss: 0.007822   Batch Acc: 79.69
[Train] Epoch: 2 [139904/620022]    Loss: 0.009169   Batch Acc: 78.12
[Train] Epoch: 2 [139968/620022]    Loss: 0.008789   Batch Acc: 78.12
[Train] Epoch: 2 [140032/620022]    Loss: 0.007432   Batch Acc: 81.25
[Train] Epoch: 2 [140096/620022]    Loss: 0.011229   Batch Acc: 71.88
[Train] Epoch: 2 [140160/620022]    Loss: 0.008647   Batch Acc: 79.69
[Train] Epoch: 2 [140224/620022]    Loss: 0.010174   Batch Acc: 76.56
[Train] Epoch: 2 [140288/620022]    Loss: 0.006497   Batch Acc: 81.25
[Train] Epoch: 2 [140352/620022]    Loss: 0.007861   Batch Acc: 79.69
[Train] Epoch: 2 [140416/620022]    Loss: 0.009128   Batch Acc: 75.00
[Train] Epoch: 2 [140480/620022]    Loss: 0.009458   Batch Acc: 73.44
[Train] Epoch: 2 [140544/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 2 [140608/620022]    Loss: 0.006473   Batch Acc: 85.94
[Train] Epoch: 2 [140672/620022]    Loss: 0.010255   Batch Acc: 71.88
[Train] Epoch: 2 [140736/620022]    Loss: 0.009010   Batch Acc: 76.56
[Train] Epoch: 2 [140800/620022]    Loss: 0.010861   Batch Acc: 71.88
[Train] Epoch: 2 [140864/620022]    Loss: 0.010305   Batch Acc: 75.00
[Train] Epoch: 2 [140928/620022]    Loss: 0.006560   Batch Acc: 79.69
[Train] Epoch: 2 [140992/620022]    Loss: 0.006490   Batch Acc: 84.38
[Train] Epoch: 2 [141056/620022]    Loss: 0.008207   Batch Acc: 79.69
[Train] Epoch: 2 [141120/620022]    Loss: 0.008934   Batch Acc: 75.00
[Train] Epoch: 2 [141184/620022]    Loss: 0.011445   Batch Acc: 73.44
[Train] Epoch: 2 [141248/620022]    Loss: 0.009967   Batch Acc: 73.44
[Train] Epoch: 2 [141312/620022]    Loss: 0.011307   Batch Acc: 68.75
[Train] Epoch: 2 [141376/620022]    Loss: 0.008446   Batch Acc: 79.69
[Train] Epoch: 2 [141440/620022]    Loss: 0.009971   Batch Acc: 75.00
[Train] Epoch: 2 [141504/620022]    Loss: 0.007767   Batch Acc: 78.12
[Train] Epoch: 2 [141568/620022]    Loss: 0.008653   Batch Acc: 76.56
[Train] Epoch: 2 [141632/620022]    Loss: 0.010912   Batch Acc: 65.62
[Train] Epoch: 2 [141696/620022]    Loss: 0.008807   Batch Acc: 78.12
[Train] Epoch: 2 [141760/620022]    Loss: 0.007496   Batch Acc: 78.12
[Train] Epoch: 2 [141824/620022]    Loss: 0.006634   Batch Acc: 87.50
[Train] Epoch: 2 [141888/620022]    Loss: 0.010037   Batch Acc: 68.75
[Train] Epoch: 2 [141952/620022]    Loss: 0.008334   Batch Acc: 82.81
[Train] Epoch: 2 [142016/620022]    Loss: 0.010860   Batch Acc: 71.88
[Train] Epoch: 2 [142080/620022]    Loss: 0.006555   Batch Acc: 85.94
[Train] Epoch: 2 [142144/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 2 [142208/620022]    Loss: 0.007961   Batch Acc: 79.69
[Train] Epoch: 2 [142272/620022]    Loss: 0.011186   Batch Acc: 71.88
[Train] Epoch: 2 [142336/620022]    Loss: 0.008778   Batch Acc: 78.12
[Train] Epoch: 2 [142400/620022]    Loss: 0.008094   Batch Acc: 78.12
[Train] Epoch: 2 [142464/620022]    Loss: 0.007605   Batch Acc: 85.94
[Train] Epoch: 2 [142528/620022]    Loss: 0.009211   Batch Acc: 81.25
[Train] Epoch: 2 [142592/620022]    Loss: 0.007990   Batch Acc: 79.69
[Train] Epoch: 2 [142656/620022]    Loss: 0.008089   Batch Acc: 79.69
[Train] Epoch: 2 [142720/620022]    Loss: 0.009810   Batch Acc: 76.56
[Train] Epoch: 2 [142784/620022]    Loss: 0.008780   Batch Acc: 81.25
[Train] Epoch: 2 [142848/620022]    Loss: 0.011242   Batch Acc: 71.88
[Train] Epoch: 2 [142912/620022]    Loss: 0.007420   Batch Acc: 84.38
[Train] Epoch: 2 [142976/620022]    Loss: 0.008630   Batch Acc: 76.56
[Train] Epoch: 2 [143040/620022]    Loss: 0.009948   Batch Acc: 75.00
[Train] Epoch: 2 [143104/620022]    Loss: 0.009521   Batch Acc: 70.31
[Train] Epoch: 2 [143168/620022]    Loss: 0.011209   Batch Acc: 68.75
[Train] Epoch: 2 [143232/620022]    Loss: 0.008703   Batch Acc: 78.12
[Train] Epoch: 2 [143296/620022]    Loss: 0.010381   Batch Acc: 67.19
[Train] Epoch: 2 [143360/620022]    Loss: 0.009314   Batch Acc: 78.12
[Train] Epoch: 2 [143424/620022]    Loss: 0.009938   Batch Acc: 71.88
[Train] Epoch: 2 [143488/620022]    Loss: 0.010519   Batch Acc: 67.19
[Train] Epoch: 2 [143552/620022]    Loss: 0.008577   Batch Acc: 82.81
[Train] Epoch: 2 [143616/620022]    Loss: 0.010451   Batch Acc: 73.44
[Train] Epoch: 2 [143680/620022]    Loss: 0.007394   Batch Acc: 81.25
[Train] Epoch: 2 [143744/620022]    Loss: 0.007416   Batch Acc: 81.25
[Train] Epoch: 2 [143808/620022]    Loss: 0.009059   Batch Acc: 73.44
[Train] Epoch: 2 [143872/620022]    Loss: 0.007561   Batch Acc: 82.81
[Train] Epoch: 2 [143936/620022]    Loss: 0.008724   Batch Acc: 79.69
[Train] Epoch: 2 [144000/620022]    Loss: 0.010722   Batch Acc: 79.69
[Train] Epoch: 2 [144064/620022]    Loss: 0.008697   Batch Acc: 71.88
[Train] Epoch: 2 [144128/620022]    Loss: 0.007487   Batch Acc: 79.69
[Train] Epoch: 2 [144192/620022]    Loss: 0.007536   Batch Acc: 84.38
[Train] Epoch: 2 [144256/620022]    Loss: 0.010843   Batch Acc: 78.12
[Train] Epoch: 2 [144320/620022]    Loss: 0.009665   Batch Acc: 71.88
[Train] Epoch: 2 [144384/620022]    Loss: 0.007481   Batch Acc: 84.38
[Train] Epoch: 2 [144448/620022]    Loss: 0.007951   Batch Acc: 82.81
[Train] Epoch: 2 [144512/620022]    Loss: 0.007831   Batch Acc: 89.06
[Train] Epoch: 2 [144576/620022]    Loss: 0.007832   Batch Acc: 78.12
[Train] Epoch: 2 [144640/620022]    Loss: 0.009927   Batch Acc: 75.00
[Train] Epoch: 2 [144704/620022]    Loss: 0.007317   Batch Acc: 82.81
[Train] Epoch: 2 [144768/620022]    Loss: 0.008783   Batch Acc: 75.00
[Train] Epoch: 2 [144832/620022]    Loss: 0.007600   Batch Acc: 81.25
[Train] Epoch: 2 [144896/620022]    Loss: 0.011138   Batch Acc: 73.44
[Train] Epoch: 2 [144960/620022]    Loss: 0.008667   Batch Acc: 76.56
[Train] Epoch: 2 [145024/620022]    Loss: 0.007219   Batch Acc: 81.25
[Train] Epoch: 2 [145088/620022]    Loss: 0.009197   Batch Acc: 81.25
[Train] Epoch: 2 [145152/620022]    Loss: 0.006252   Batch Acc: 87.50
[Train] Epoch: 2 [145216/620022]    Loss: 0.007207   Batch Acc: 79.69
[Train] Epoch: 2 [145280/620022]    Loss: 0.009820   Batch Acc: 68.75
[Train] Epoch: 2 [145344/620022]    Loss: 0.007696   Batch Acc: 79.69
[Train] Epoch: 2 [145408/620022]    Loss: 0.010194   Batch Acc: 70.31
[Train] Epoch: 2 [145472/620022]    Loss: 0.009020   Batch Acc: 81.25
[Train] Epoch: 2 [145536/620022]    Loss: 0.008873   Batch Acc: 75.00
[Train] Epoch: 2 [145600/620022]    Loss: 0.007441   Batch Acc: 79.69
[Train] Epoch: 2 [145664/620022]    Loss: 0.008609   Batch Acc: 82.81
[Train] Epoch: 2 [145728/620022]    Loss: 0.008660   Batch Acc: 73.44
[Train] Epoch: 2 [145792/620022]    Loss: 0.008037   Batch Acc: 76.56
[Train] Epoch: 2 [145856/620022]    Loss: 0.009629   Batch Acc: 75.00
[Train] Epoch: 2 [145920/620022]    Loss: 0.011411   Batch Acc: 67.19
[Train] Epoch: 2 [145984/620022]    Loss: 0.007614   Batch Acc: 79.69
[Train] Epoch: 2 [146048/620022]    Loss: 0.009705   Batch Acc: 75.00
[Train] Epoch: 2 [146112/620022]    Loss: 0.007842   Batch Acc: 75.00
[Train] Epoch: 2 [146176/620022]    Loss: 0.010430   Batch Acc: 67.19
[Train] Epoch: 2 [146240/620022]    Loss: 0.010244   Batch Acc: 67.19
[Train] Epoch: 2 [146304/620022]    Loss: 0.007499   Batch Acc: 81.25
[Train] Epoch: 2 [146368/620022]    Loss: 0.007147   Batch Acc: 81.25
[Train] Epoch: 2 [146432/620022]    Loss: 0.008030   Batch Acc: 75.00
[Train] Epoch: 2 [146496/620022]    Loss: 0.007550   Batch Acc: 76.56
[Train] Epoch: 2 [146560/620022]    Loss: 0.012046   Batch Acc: 65.62
[Train] Epoch: 2 [146624/620022]    Loss: 0.008217   Batch Acc: 78.12
[Train] Epoch: 2 [146688/620022]    Loss: 0.007587   Batch Acc: 82.81
[Train] Epoch: 2 [146752/620022]    Loss: 0.008805   Batch Acc: 78.12
[Train] Epoch: 2 [146816/620022]    Loss: 0.008557   Batch Acc: 79.69
[Train] Epoch: 2 [146880/620022]    Loss: 0.008029   Batch Acc: 79.69
[Train] Epoch: 2 [146944/620022]    Loss: 0.008251   Batch Acc: 79.69
[Train] Epoch: 2 [147008/620022]    Loss: 0.007215   Batch Acc: 79.69
[Train] Epoch: 2 [147072/620022]    Loss: 0.009135   Batch Acc: 76.56
[Train] Epoch: 2 [147136/620022]    Loss: 0.009280   Batch Acc: 71.88
[Train] Epoch: 2 [147200/620022]    Loss: 0.011357   Batch Acc: 71.88
[Train] Epoch: 2 [147264/620022]    Loss: 0.010781   Batch Acc: 71.88
[Train] Epoch: 2 [147328/620022]    Loss: 0.010061   Batch Acc: 76.56
[Train] Epoch: 2 [147392/620022]    Loss: 0.009812   Batch Acc: 76.56
[Train] Epoch: 2 [147456/620022]    Loss: 0.008565   Batch Acc: 81.25
[Train] Epoch: 2 [147520/620022]    Loss: 0.006313   Batch Acc: 92.19
[Train] Epoch: 2 [147584/620022]    Loss: 0.008126   Batch Acc: 79.69
[Train] Epoch: 2 [147648/620022]    Loss: 0.008488   Batch Acc: 75.00
[Train] Epoch: 2 [147712/620022]    Loss: 0.008075   Batch Acc: 79.69
[Train] Epoch: 2 [147776/620022]    Loss: 0.008130   Batch Acc: 81.25
[Train] Epoch: 2 [147840/620022]    Loss: 0.007642   Batch Acc: 81.25
[Train] Epoch: 2 [147904/620022]    Loss: 0.009204   Batch Acc: 78.12
[Train] Epoch: 2 [147968/620022]    Loss: 0.010811   Batch Acc: 67.19
[Train] Epoch: 2 [148032/620022]    Loss: 0.006435   Batch Acc: 84.38
[Train] Epoch: 2 [148096/620022]    Loss: 0.010491   Batch Acc: 73.44
[Train] Epoch: 2 [148160/620022]    Loss: 0.007093   Batch Acc: 84.38
[Train] Epoch: 2 [148224/620022]    Loss: 0.007238   Batch Acc: 82.81
[Train] Epoch: 2 [148288/620022]    Loss: 0.007799   Batch Acc: 76.56
[Train] Epoch: 2 [148352/620022]    Loss: 0.008998   Batch Acc: 78.12
[Train] Epoch: 2 [148416/620022]    Loss: 0.012024   Batch Acc: 68.75
[Train] Epoch: 2 [148480/620022]    Loss: 0.009916   Batch Acc: 75.00
[Train] Epoch: 2 [148544/620022]    Loss: 0.008912   Batch Acc: 79.69
[Train] Epoch: 2 [148608/620022]    Loss: 0.008523   Batch Acc: 78.12
[Train] Epoch: 2 [148672/620022]    Loss: 0.008863   Batch Acc: 76.56
[Train] Epoch: 2 [148736/620022]    Loss: 0.006841   Batch Acc: 87.50
[Train] Epoch: 2 [148800/620022]    Loss: 0.008375   Batch Acc: 82.81
[Train] Epoch: 2 [148864/620022]    Loss: 0.009544   Batch Acc: 82.81
[Train] Epoch: 2 [148928/620022]    Loss: 0.007300   Batch Acc: 73.44
[Train] Epoch: 2 [148992/620022]    Loss: 0.008965   Batch Acc: 79.69
[Train] Epoch: 2 [149056/620022]    Loss: 0.007517   Batch Acc: 81.25
[Train] Epoch: 2 [149120/620022]    Loss: 0.009181   Batch Acc: 73.44
[Train] Epoch: 2 [149184/620022]    Loss: 0.009712   Batch Acc: 71.88
[Train] Epoch: 2 [149248/620022]    Loss: 0.008253   Batch Acc: 79.69
[Train] Epoch: 2 [149312/620022]    Loss: 0.010912   Batch Acc: 71.88
[Train] Epoch: 2 [149376/620022]    Loss: 0.009599   Batch Acc: 73.44
[Train] Epoch: 2 [149440/620022]    Loss: 0.010230   Batch Acc: 71.88
[Train] Epoch: 2 [149504/620022]    Loss: 0.010307   Batch Acc: 75.00
[Train] Epoch: 2 [149568/620022]    Loss: 0.008451   Batch Acc: 75.00
[Train] Epoch: 2 [149632/620022]    Loss: 0.008124   Batch Acc: 81.25
[Train] Epoch: 2 [149696/620022]    Loss: 0.010231   Batch Acc: 71.88
[Train] Epoch: 2 [149760/620022]    Loss: 0.008740   Batch Acc: 76.56
[Train] Epoch: 2 [149824/620022]    Loss: 0.010033   Batch Acc: 76.56
[Train] Epoch: 2 [149888/620022]    Loss: 0.007766   Batch Acc: 75.00
[Train] Epoch: 2 [149952/620022]    Loss: 0.009751   Batch Acc: 78.12
[Train] Epoch: 2 [150016/620022]    Loss: 0.007293   Batch Acc: 84.38
[Train] Epoch: 2 [150080/620022]    Loss: 0.008228   Batch Acc: 81.25
[Train] Epoch: 2 [150144/620022]    Loss: 0.009189   Batch Acc: 78.12
[Train] Epoch: 2 [150208/620022]    Loss: 0.010870   Batch Acc: 71.88
[Train] Epoch: 2 [150272/620022]    Loss: 0.009993   Batch Acc: 71.88
[Train] Epoch: 2 [150336/620022]    Loss: 0.010532   Batch Acc: 71.88
[Train] Epoch: 2 [150400/620022]    Loss: 0.008129   Batch Acc: 76.56
[Train] Epoch: 2 [150464/620022]    Loss: 0.007207   Batch Acc: 85.94
[Train] Epoch: 2 [150528/620022]    Loss: 0.007872   Batch Acc: 84.38
[Train] Epoch: 2 [150592/620022]    Loss: 0.007904   Batch Acc: 79.69
[Train] Epoch: 2 [150656/620022]    Loss: 0.007981   Batch Acc: 79.69
[Train] Epoch: 2 [150720/620022]    Loss: 0.007351   Batch Acc: 81.25
[Train] Epoch: 2 [150784/620022]    Loss: 0.008913   Batch Acc: 76.56
[Train] Epoch: 2 [150848/620022]    Loss: 0.007997   Batch Acc: 81.25
[Train] Epoch: 2 [150912/620022]    Loss: 0.008672   Batch Acc: 75.00
[Train] Epoch: 2 [150976/620022]    Loss: 0.011100   Batch Acc: 68.75
[Train] Epoch: 2 [151040/620022]    Loss: 0.008791   Batch Acc: 81.25
[Train] Epoch: 2 [151104/620022]    Loss: 0.010071   Batch Acc: 73.44
[Train] Epoch: 2 [151168/620022]    Loss: 0.011215   Batch Acc: 73.44
[Train] Epoch: 2 [151232/620022]    Loss: 0.008523   Batch Acc: 79.69
[Train] Epoch: 2 [151296/620022]    Loss: 0.007922   Batch Acc: 79.69
[Train] Epoch: 2 [151360/620022]    Loss: 0.008621   Batch Acc: 73.44
[Train] Epoch: 2 [151424/620022]    Loss: 0.008033   Batch Acc: 78.12
[Train] Epoch: 2 [151488/620022]    Loss: 0.008735   Batch Acc: 78.12
[Train] Epoch: 2 [151552/620022]    Loss: 0.007796   Batch Acc: 76.56
[Train] Epoch: 2 [151616/620022]    Loss: 0.010456   Batch Acc: 73.44
[Train] Epoch: 2 [151680/620022]    Loss: 0.009085   Batch Acc: 75.00
[Train] Epoch: 2 [151744/620022]    Loss: 0.010780   Batch Acc: 70.31
[Train] Epoch: 2 [151808/620022]    Loss: 0.009150   Batch Acc: 79.69
[Train] Epoch: 2 [151872/620022]    Loss: 0.009428   Batch Acc: 71.88
[Train] Epoch: 2 [151936/620022]    Loss: 0.009681   Batch Acc: 67.19
[Train] Epoch: 2 [152000/620022]    Loss: 0.009273   Batch Acc: 78.12
[Train] Epoch: 2 [152064/620022]    Loss: 0.010695   Batch Acc: 68.75
[Train] Epoch: 2 [152128/620022]    Loss: 0.007450   Batch Acc: 81.25
[Train] Epoch: 2 [152192/620022]    Loss: 0.010337   Batch Acc: 78.12
[Train] Epoch: 2 [152256/620022]    Loss: 0.008727   Batch Acc: 78.12
[Train] Epoch: 2 [152320/620022]    Loss: 0.007200   Batch Acc: 81.25
[Train] Epoch: 2 [152384/620022]    Loss: 0.010094   Batch Acc: 79.69
[Train] Epoch: 2 [152448/620022]    Loss: 0.009044   Batch Acc: 75.00
[Train] Epoch: 2 [152512/620022]    Loss: 0.009350   Batch Acc: 71.88
[Train] Epoch: 2 [152576/620022]    Loss: 0.007564   Batch Acc: 78.12
[Train] Epoch: 2 [152640/620022]    Loss: 0.010217   Batch Acc: 73.44
[Train] Epoch: 2 [152704/620022]    Loss: 0.008202   Batch Acc: 73.44
[Train] Epoch: 2 [152768/620022]    Loss: 0.008121   Batch Acc: 81.25
[Train] Epoch: 2 [152832/620022]    Loss: 0.007004   Batch Acc: 82.81
[Train] Epoch: 2 [152896/620022]    Loss: 0.009366   Batch Acc: 79.69
[Train] Epoch: 2 [152960/620022]    Loss: 0.007778   Batch Acc: 84.38
[Train] Epoch: 2 [153024/620022]    Loss: 0.008711   Batch Acc: 78.12
[Train] Epoch: 2 [153088/620022]    Loss: 0.009450   Batch Acc: 75.00
[Train] Epoch: 2 [153152/620022]    Loss: 0.008498   Batch Acc: 81.25
[Train] Epoch: 2 [153216/620022]    Loss: 0.007029   Batch Acc: 82.81
[Train] Epoch: 2 [153280/620022]    Loss: 0.008836   Batch Acc: 79.69
[Train] Epoch: 2 [153344/620022]    Loss: 0.006804   Batch Acc: 85.94
[Train] Epoch: 2 [153408/620022]    Loss: 0.006851   Batch Acc: 85.94
[Train] Epoch: 2 [153472/620022]    Loss: 0.009056   Batch Acc: 79.69
[Train] Epoch: 2 [153536/620022]    Loss: 0.010969   Batch Acc: 76.56
[Train] Epoch: 2 [153600/620022]    Loss: 0.007542   Batch Acc: 81.25
[Train] Epoch: 2 [153664/620022]    Loss: 0.007045   Batch Acc: 81.25
[Train] Epoch: 2 [153728/620022]    Loss: 0.008112   Batch Acc: 81.25
[Train] Epoch: 2 [153792/620022]    Loss: 0.010014   Batch Acc: 75.00
[Train] Epoch: 2 [153856/620022]    Loss: 0.009727   Batch Acc: 79.69
[Train] Epoch: 2 [153920/620022]    Loss: 0.011666   Batch Acc: 70.31
[Train] Epoch: 2 [153984/620022]    Loss: 0.009419   Batch Acc: 71.88
[Train] Epoch: 2 [154048/620022]    Loss: 0.008259   Batch Acc: 79.69
[Train] Epoch: 2 [154112/620022]    Loss: 0.010679   Batch Acc: 71.88
[Train] Epoch: 2 [154176/620022]    Loss: 0.008233   Batch Acc: 75.00
[Train] Epoch: 2 [154240/620022]    Loss: 0.007800   Batch Acc: 82.81
[Train] Epoch: 2 [154304/620022]    Loss: 0.008885   Batch Acc: 70.31
[Train] Epoch: 2 [154368/620022]    Loss: 0.008282   Batch Acc: 81.25
[Train] Epoch: 2 [154432/620022]    Loss: 0.010099   Batch Acc: 73.44
[Train] Epoch: 2 [154496/620022]    Loss: 0.011077   Batch Acc: 71.88
[Train] Epoch: 2 [154560/620022]    Loss: 0.007151   Batch Acc: 82.81
[Train] Epoch: 2 [154624/620022]    Loss: 0.007443   Batch Acc: 82.81
[Train] Epoch: 2 [154688/620022]    Loss: 0.009549   Batch Acc: 70.31
[Train] Epoch: 2 [154752/620022]    Loss: 0.008119   Batch Acc: 75.00
[Train] Epoch: 2 [154816/620022]    Loss: 0.007926   Batch Acc: 82.81
[Train] Epoch: 2 [154880/620022]    Loss: 0.009615   Batch Acc: 76.56
[Train] Epoch: 2 [154944/620022]    Loss: 0.008997   Batch Acc: 73.44
[Train] Epoch: 2 [155008/620022]    Loss: 0.008504   Batch Acc: 81.25
[Train] Epoch: 2 [155072/620022]    Loss: 0.008065   Batch Acc: 76.56
[Train] Epoch: 2 [155136/620022]    Loss: 0.008419   Batch Acc: 75.00
[Train] Epoch: 2 [155200/620022]    Loss: 0.008291   Batch Acc: 78.12
[Train] Epoch: 2 [155264/620022]    Loss: 0.009461   Batch Acc: 81.25
[Train] Epoch: 2 [155328/620022]    Loss: 0.008005   Batch Acc: 81.25
[Train] Epoch: 2 [155392/620022]    Loss: 0.008648   Batch Acc: 75.00
[Train] Epoch: 2 [155456/620022]    Loss: 0.007747   Batch Acc: 82.81
[Train] Epoch: 2 [155520/620022]    Loss: 0.007814   Batch Acc: 84.38
[Train] Epoch: 2 [155584/620022]    Loss: 0.009879   Batch Acc: 70.31
[Train] Epoch: 2 [155648/620022]    Loss: 0.008970   Batch Acc: 73.44
[Train] Epoch: 2 [155712/620022]    Loss: 0.009580   Batch Acc: 78.12
[Train] Epoch: 2 [155776/620022]    Loss: 0.009070   Batch Acc: 75.00
[Train] Epoch: 2 [155840/620022]    Loss: 0.008097   Batch Acc: 79.69
[Train] Epoch: 2 [155904/620022]    Loss: 0.007357   Batch Acc: 81.25
[Train] Epoch: 2 [155968/620022]    Loss: 0.009349   Batch Acc: 75.00
[Train] Epoch: 2 [156032/620022]    Loss: 0.007739   Batch Acc: 82.81
[Train] Epoch: 2 [156096/620022]    Loss: 0.007220   Batch Acc: 82.81
[Train] Epoch: 2 [156160/620022]    Loss: 0.007413   Batch Acc: 79.69
[Train] Epoch: 2 [156224/620022]    Loss: 0.008044   Batch Acc: 78.12
[Train] Epoch: 2 [156288/620022]    Loss: 0.009544   Batch Acc: 78.12
[Train] Epoch: 2 [156352/620022]    Loss: 0.010795   Batch Acc: 71.88
[Train] Epoch: 2 [156416/620022]    Loss: 0.009179   Batch Acc: 75.00
[Train] Epoch: 2 [156480/620022]    Loss: 0.009603   Batch Acc: 78.12
[Train] Epoch: 2 [156544/620022]    Loss: 0.011129   Batch Acc: 65.62
[Train] Epoch: 2 [156608/620022]    Loss: 0.009790   Batch Acc: 78.12
[Train] Epoch: 2 [156672/620022]    Loss: 0.011588   Batch Acc: 67.19
[Train] Epoch: 2 [156736/620022]    Loss: 0.009105   Batch Acc: 81.25
[Train] Epoch: 2 [156800/620022]    Loss: 0.007194   Batch Acc: 81.25
[Train] Epoch: 2 [156864/620022]    Loss: 0.008776   Batch Acc: 75.00
[Train] Epoch: 2 [156928/620022]    Loss: 0.009153   Batch Acc: 73.44
[Train] Epoch: 2 [156992/620022]    Loss: 0.008822   Batch Acc: 76.56
[Train] Epoch: 2 [157056/620022]    Loss: 0.011056   Batch Acc: 68.75
[Train] Epoch: 2 [157120/620022]    Loss: 0.010374   Batch Acc: 68.75
[Train] Epoch: 2 [157184/620022]    Loss: 0.006725   Batch Acc: 82.81
[Train] Epoch: 2 [157248/620022]    Loss: 0.008985   Batch Acc: 78.12
[Train] Epoch: 2 [157312/620022]    Loss: 0.006704   Batch Acc: 89.06
[Train] Epoch: 2 [157376/620022]    Loss: 0.007351   Batch Acc: 82.81
[Train] Epoch: 2 [157440/620022]    Loss: 0.008982   Batch Acc: 81.25
[Train] Epoch: 2 [157504/620022]    Loss: 0.008138   Batch Acc: 76.56
[Train] Epoch: 2 [157568/620022]    Loss: 0.009922   Batch Acc: 70.31
[Train] Epoch: 2 [157632/620022]    Loss: 0.008985   Batch Acc: 81.25
[Train] Epoch: 2 [157696/620022]    Loss: 0.010328   Batch Acc: 70.31
[Train] Epoch: 2 [157760/620022]    Loss: 0.009187   Batch Acc: 76.56
[Train] Epoch: 2 [157824/620022]    Loss: 0.010508   Batch Acc: 73.44
[Train] Epoch: 2 [157888/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 2 [157952/620022]    Loss: 0.008119   Batch Acc: 82.81
[Train] Epoch: 2 [158016/620022]    Loss: 0.009765   Batch Acc: 71.88
[Train] Epoch: 2 [158080/620022]    Loss: 0.007607   Batch Acc: 78.12
[Train] Epoch: 2 [158144/620022]    Loss: 0.010966   Batch Acc: 73.44
[Train] Epoch: 2 [158208/620022]    Loss: 0.006713   Batch Acc: 85.94
[Train] Epoch: 2 [158272/620022]    Loss: 0.007333   Batch Acc: 82.81
[Train] Epoch: 2 [158336/620022]    Loss: 0.009930   Batch Acc: 76.56
[Train] Epoch: 2 [158400/620022]    Loss: 0.007718   Batch Acc: 78.12
[Train] Epoch: 2 [158464/620022]    Loss: 0.008074   Batch Acc: 84.38
[Train] Epoch: 2 [158528/620022]    Loss: 0.010939   Batch Acc: 73.44
[Train] Epoch: 2 [158592/620022]    Loss: 0.008071   Batch Acc: 85.94
[Train] Epoch: 2 [158656/620022]    Loss: 0.007127   Batch Acc: 82.81
[Train] Epoch: 2 [158720/620022]    Loss: 0.007371   Batch Acc: 79.69
[Train] Epoch: 2 [158784/620022]    Loss: 0.008556   Batch Acc: 76.56
[Train] Epoch: 2 [158848/620022]    Loss: 0.007526   Batch Acc: 79.69
[Train] Epoch: 2 [158912/620022]    Loss: 0.007828   Batch Acc: 85.94
[Train] Epoch: 2 [158976/620022]    Loss: 0.007762   Batch Acc: 79.69
[Train] Epoch: 2 [159040/620022]    Loss: 0.010912   Batch Acc: 75.00
[Train] Epoch: 2 [159104/620022]    Loss: 0.006684   Batch Acc: 89.06
[Train] Epoch: 2 [159168/620022]    Loss: 0.007342   Batch Acc: 85.94
[Train] Epoch: 2 [159232/620022]    Loss: 0.007970   Batch Acc: 79.69
[Train] Epoch: 2 [159296/620022]    Loss: 0.008662   Batch Acc: 73.44
[Train] Epoch: 2 [159360/620022]    Loss: 0.009141   Batch Acc: 79.69
[Train] Epoch: 2 [159424/620022]    Loss: 0.009620   Batch Acc: 70.31
[Train] Epoch: 2 [159488/620022]    Loss: 0.008296   Batch Acc: 79.69
[Train] Epoch: 2 [159552/620022]    Loss: 0.009105   Batch Acc: 76.56
[Train] Epoch: 2 [159616/620022]    Loss: 0.012010   Batch Acc: 62.50
[Train] Epoch: 2 [159680/620022]    Loss: 0.009717   Batch Acc: 78.12
[Train] Epoch: 2 [159744/620022]    Loss: 0.008637   Batch Acc: 76.56
[Train] Epoch: 2 [159808/620022]    Loss: 0.007102   Batch Acc: 82.81
[Train] Epoch: 2 [159872/620022]    Loss: 0.009185   Batch Acc: 76.56
[Train] Epoch: 2 [159936/620022]    Loss: 0.009612   Batch Acc: 79.69
[Train] Epoch: 2 [160000/620022]    Loss: 0.009702   Batch Acc: 73.44
[Train] Epoch: 2 [160064/620022]    Loss: 0.010714   Batch Acc: 73.44
[Train] Epoch: 2 [160128/620022]    Loss: 0.011069   Batch Acc: 68.75
[Train] Epoch: 2 [160192/620022]    Loss: 0.007960   Batch Acc: 79.69
[Train] Epoch: 2 [160256/620022]    Loss: 0.007965   Batch Acc: 81.25
[Train] Epoch: 2 [160320/620022]    Loss: 0.008972   Batch Acc: 82.81
[Train] Epoch: 2 [160384/620022]    Loss: 0.010099   Batch Acc: 79.69
[Train] Epoch: 2 [160448/620022]    Loss: 0.009631   Batch Acc: 78.12
[Train] Epoch: 2 [160512/620022]    Loss: 0.005721   Batch Acc: 87.50
[Train] Epoch: 2 [160576/620022]    Loss: 0.005227   Batch Acc: 93.75
[Train] Epoch: 2 [160640/620022]    Loss: 0.009263   Batch Acc: 76.56
[Train] Epoch: 2 [160704/620022]    Loss: 0.007378   Batch Acc: 84.38
[Train] Epoch: 2 [160768/620022]    Loss: 0.009205   Batch Acc: 73.44
[Train] Epoch: 2 [160832/620022]    Loss: 0.009556   Batch Acc: 78.12
[Train] Epoch: 2 [160896/620022]    Loss: 0.009100   Batch Acc: 76.56
[Train] Epoch: 2 [160960/620022]    Loss: 0.011273   Batch Acc: 68.75
[Train] Epoch: 2 [161024/620022]    Loss: 0.009220   Batch Acc: 76.56
[Train] Epoch: 2 [161088/620022]    Loss: 0.007311   Batch Acc: 89.06
[Train] Epoch: 2 [161152/620022]    Loss: 0.006509   Batch Acc: 87.50
[Train] Epoch: 2 [161216/620022]    Loss: 0.007878   Batch Acc: 81.25
[Train] Epoch: 2 [161280/620022]    Loss: 0.009261   Batch Acc: 81.25
[Train] Epoch: 2 [161344/620022]    Loss: 0.007589   Batch Acc: 85.94
[Train] Epoch: 2 [161408/620022]    Loss: 0.011765   Batch Acc: 68.75
[Train] Epoch: 2 [161472/620022]    Loss: 0.009719   Batch Acc: 71.88
[Train] Epoch: 2 [161536/620022]    Loss: 0.008437   Batch Acc: 73.44
[Train] Epoch: 2 [161600/620022]    Loss: 0.008740   Batch Acc: 79.69
[Train] Epoch: 2 [161664/620022]    Loss: 0.009164   Batch Acc: 71.88
[Train] Epoch: 2 [161728/620022]    Loss: 0.008207   Batch Acc: 81.25
[Train] Epoch: 2 [161792/620022]    Loss: 0.008239   Batch Acc: 82.81
[Train] Epoch: 2 [161856/620022]    Loss: 0.010928   Batch Acc: 67.19
[Train] Epoch: 2 [161920/620022]    Loss: 0.010057   Batch Acc: 78.12
[Train] Epoch: 2 [161984/620022]    Loss: 0.007842   Batch Acc: 84.38
[Train] Epoch: 2 [162048/620022]    Loss: 0.007628   Batch Acc: 82.81
[Train] Epoch: 2 [162112/620022]    Loss: 0.008540   Batch Acc: 81.25
[Train] Epoch: 2 [162176/620022]    Loss: 0.009456   Batch Acc: 78.12
[Train] Epoch: 2 [162240/620022]    Loss: 0.007993   Batch Acc: 84.38
[Train] Epoch: 2 [162304/620022]    Loss: 0.008831   Batch Acc: 78.12
[Train] Epoch: 2 [162368/620022]    Loss: 0.010220   Batch Acc: 70.31
[Train] Epoch: 2 [162432/620022]    Loss: 0.007139   Batch Acc: 82.81
[Train] Epoch: 2 [162496/620022]    Loss: 0.008724   Batch Acc: 79.69
[Train] Epoch: 2 [162560/620022]    Loss: 0.007294   Batch Acc: 75.00
[Train] Epoch: 2 [162624/620022]    Loss: 0.012618   Batch Acc: 62.50
[Train] Epoch: 2 [162688/620022]    Loss: 0.011261   Batch Acc: 71.88
[Train] Epoch: 2 [162752/620022]    Loss: 0.009437   Batch Acc: 71.88
[Train] Epoch: 2 [162816/620022]    Loss: 0.006095   Batch Acc: 89.06
[Train] Epoch: 2 [162880/620022]    Loss: 0.009262   Batch Acc: 73.44
[Train] Epoch: 2 [162944/620022]    Loss: 0.008766   Batch Acc: 73.44
[Train] Epoch: 2 [163008/620022]    Loss: 0.010246   Batch Acc: 73.44
[Train] Epoch: 2 [163072/620022]    Loss: 0.008166   Batch Acc: 82.81
[Train] Epoch: 2 [163136/620022]    Loss: 0.010212   Batch Acc: 73.44
[Train] Epoch: 2 [163200/620022]    Loss: 0.007082   Batch Acc: 79.69
[Train] Epoch: 2 [163264/620022]    Loss: 0.009585   Batch Acc: 78.12
[Train] Epoch: 2 [163328/620022]    Loss: 0.008889   Batch Acc: 79.69
[Train] Epoch: 2 [163392/620022]    Loss: 0.007766   Batch Acc: 85.94
[Train] Epoch: 2 [163456/620022]    Loss: 0.009100   Batch Acc: 76.56
[Train] Epoch: 2 [163520/620022]    Loss: 0.008611   Batch Acc: 76.56
[Train] Epoch: 2 [163584/620022]    Loss: 0.009562   Batch Acc: 70.31
[Train] Epoch: 2 [163648/620022]    Loss: 0.008743   Batch Acc: 78.12
[Train] Epoch: 2 [163712/620022]    Loss: 0.006622   Batch Acc: 81.25
[Train] Epoch: 2 [163776/620022]    Loss: 0.011255   Batch Acc: 76.56
[Train] Epoch: 2 [163840/620022]    Loss: 0.008455   Batch Acc: 81.25
[Train] Epoch: 2 [163904/620022]    Loss: 0.010267   Batch Acc: 71.88
[Train] Epoch: 2 [163968/620022]    Loss: 0.011988   Batch Acc: 70.31
[Train] Epoch: 2 [164032/620022]    Loss: 0.009289   Batch Acc: 76.56
[Train] Epoch: 2 [164096/620022]    Loss: 0.007653   Batch Acc: 79.69
[Train] Epoch: 2 [164160/620022]    Loss: 0.010555   Batch Acc: 71.88
[Train] Epoch: 2 [164224/620022]    Loss: 0.007781   Batch Acc: 89.06
[Train] Epoch: 2 [164288/620022]    Loss: 0.007436   Batch Acc: 84.38
[Train] Epoch: 2 [164352/620022]    Loss: 0.010442   Batch Acc: 67.19
[Train] Epoch: 2 [164416/620022]    Loss: 0.007578   Batch Acc: 81.25
[Train] Epoch: 2 [164480/620022]    Loss: 0.008278   Batch Acc: 79.69
[Train] Epoch: 2 [164544/620022]    Loss: 0.008747   Batch Acc: 75.00
[Train] Epoch: 2 [164608/620022]    Loss: 0.007780   Batch Acc: 78.12
[Train] Epoch: 2 [164672/620022]    Loss: 0.007161   Batch Acc: 76.56
[Train] Epoch: 2 [164736/620022]    Loss: 0.008534   Batch Acc: 78.12
[Train] Epoch: 2 [164800/620022]    Loss: 0.011927   Batch Acc: 70.31
[Train] Epoch: 2 [164864/620022]    Loss: 0.008724   Batch Acc: 81.25
[Train] Epoch: 2 [164928/620022]    Loss: 0.007414   Batch Acc: 81.25
[Train] Epoch: 2 [164992/620022]    Loss: 0.007445   Batch Acc: 82.81
[Train] Epoch: 2 [165056/620022]    Loss: 0.007828   Batch Acc: 78.12
[Train] Epoch: 2 [165120/620022]    Loss: 0.007907   Batch Acc: 81.25
[Train] Epoch: 2 [165184/620022]    Loss: 0.007124   Batch Acc: 79.69
[Train] Epoch: 2 [165248/620022]    Loss: 0.011358   Batch Acc: 65.62
[Train] Epoch: 2 [165312/620022]    Loss: 0.009811   Batch Acc: 71.88
[Train] Epoch: 2 [165376/620022]    Loss: 0.009275   Batch Acc: 78.12
[Train] Epoch: 2 [165440/620022]    Loss: 0.009323   Batch Acc: 79.69
[Train] Epoch: 2 [165504/620022]    Loss: 0.007664   Batch Acc: 78.12
[Train] Epoch: 2 [165568/620022]    Loss: 0.008442   Batch Acc: 78.12
[Train] Epoch: 2 [165632/620022]    Loss: 0.010057   Batch Acc: 71.88
[Train] Epoch: 2 [165696/620022]    Loss: 0.007552   Batch Acc: 84.38
[Train] Epoch: 2 [165760/620022]    Loss: 0.007877   Batch Acc: 79.69
[Train] Epoch: 2 [165824/620022]    Loss: 0.009841   Batch Acc: 71.88
[Train] Epoch: 2 [165888/620022]    Loss: 0.007549   Batch Acc: 79.69
[Train] Epoch: 2 [165952/620022]    Loss: 0.008651   Batch Acc: 79.69
[Train] Epoch: 2 [166016/620022]    Loss: 0.007925   Batch Acc: 82.81
[Train] Epoch: 2 [166080/620022]    Loss: 0.009275   Batch Acc: 79.69
[Train] Epoch: 2 [166144/620022]    Loss: 0.007885   Batch Acc: 81.25
[Train] Epoch: 2 [166208/620022]    Loss: 0.008264   Batch Acc: 79.69
[Train] Epoch: 2 [166272/620022]    Loss: 0.011860   Batch Acc: 68.75
[Train] Epoch: 2 [166336/620022]    Loss: 0.009474   Batch Acc: 76.56
[Train] Epoch: 2 [166400/620022]    Loss: 0.009217   Batch Acc: 73.44
[Train] Epoch: 2 [166464/620022]    Loss: 0.008513   Batch Acc: 76.56
[Train] Epoch: 2 [166528/620022]    Loss: 0.010008   Batch Acc: 78.12
[Train] Epoch: 2 [166592/620022]    Loss: 0.008966   Batch Acc: 78.12
[Train] Epoch: 2 [166656/620022]    Loss: 0.010648   Batch Acc: 71.88
[Train] Epoch: 2 [166720/620022]    Loss: 0.009097   Batch Acc: 73.44
[Train] Epoch: 2 [166784/620022]    Loss: 0.008141   Batch Acc: 76.56
[Train] Epoch: 2 [166848/620022]    Loss: 0.007526   Batch Acc: 84.38
[Train] Epoch: 2 [166912/620022]    Loss: 0.008697   Batch Acc: 78.12
[Train] Epoch: 2 [166976/620022]    Loss: 0.010916   Batch Acc: 65.62
[Train] Epoch: 2 [167040/620022]    Loss: 0.009951   Batch Acc: 70.31
[Train] Epoch: 2 [167104/620022]    Loss: 0.007795   Batch Acc: 75.00
[Train] Epoch: 2 [167168/620022]    Loss: 0.010529   Batch Acc: 71.88
[Train] Epoch: 2 [167232/620022]    Loss: 0.009735   Batch Acc: 76.56
[Train] Epoch: 2 [167296/620022]    Loss: 0.008814   Batch Acc: 78.12
[Train] Epoch: 2 [167360/620022]    Loss: 0.009311   Batch Acc: 81.25
[Train] Epoch: 2 [167424/620022]    Loss: 0.009834   Batch Acc: 73.44
[Train] Epoch: 2 [167488/620022]    Loss: 0.008197   Batch Acc: 76.56
[Train] Epoch: 2 [167552/620022]    Loss: 0.009288   Batch Acc: 76.56
[Train] Epoch: 2 [167616/620022]    Loss: 0.008218   Batch Acc: 79.69
[Train] Epoch: 2 [167680/620022]    Loss: 0.008696   Batch Acc: 78.12
[Train] Epoch: 2 [167744/620022]    Loss: 0.010921   Batch Acc: 68.75
[Train] Epoch: 2 [167808/620022]    Loss: 0.012533   Batch Acc: 64.06
[Train] Epoch: 2 [167872/620022]    Loss: 0.010800   Batch Acc: 67.19
[Train] Epoch: 2 [167936/620022]    Loss: 0.008748   Batch Acc: 79.69
[Train] Epoch: 2 [168000/620022]    Loss: 0.007356   Batch Acc: 82.81
[Train] Epoch: 2 [168064/620022]    Loss: 0.008297   Batch Acc: 81.25
[Train] Epoch: 2 [168128/620022]    Loss: 0.006946   Batch Acc: 79.69
[Train] Epoch: 2 [168192/620022]    Loss: 0.008554   Batch Acc: 79.69
[Train] Epoch: 2 [168256/620022]    Loss: 0.009709   Batch Acc: 75.00
[Train] Epoch: 2 [168320/620022]    Loss: 0.010791   Batch Acc: 65.62
[Train] Epoch: 2 [168384/620022]    Loss: 0.009685   Batch Acc: 76.56
[Train] Epoch: 2 [168448/620022]    Loss: 0.007039   Batch Acc: 78.12
[Train] Epoch: 2 [168512/620022]    Loss: 0.007878   Batch Acc: 78.12
[Train] Epoch: 2 [168576/620022]    Loss: 0.007701   Batch Acc: 78.12
[Train] Epoch: 2 [168640/620022]    Loss: 0.010626   Batch Acc: 73.44
[Train] Epoch: 2 [168704/620022]    Loss: 0.007669   Batch Acc: 82.81
[Train] Epoch: 2 [168768/620022]    Loss: 0.009425   Batch Acc: 82.81
[Train] Epoch: 2 [168832/620022]    Loss: 0.009237   Batch Acc: 76.56
[Train] Epoch: 2 [168896/620022]    Loss: 0.006964   Batch Acc: 81.25
[Train] Epoch: 2 [168960/620022]    Loss: 0.008654   Batch Acc: 79.69
[Train] Epoch: 2 [169024/620022]    Loss: 0.009237   Batch Acc: 81.25
[Train] Epoch: 2 [169088/620022]    Loss: 0.007056   Batch Acc: 84.38
[Train] Epoch: 2 [169152/620022]    Loss: 0.008322   Batch Acc: 81.25
[Train] Epoch: 2 [169216/620022]    Loss: 0.009301   Batch Acc: 73.44
[Train] Epoch: 2 [169280/620022]    Loss: 0.005372   Batch Acc: 85.94
[Train] Epoch: 2 [169344/620022]    Loss: 0.009110   Batch Acc: 75.00
[Train] Epoch: 2 [169408/620022]    Loss: 0.008536   Batch Acc: 81.25
[Train] Epoch: 2 [169472/620022]    Loss: 0.007818   Batch Acc: 87.50
[Train] Epoch: 2 [169536/620022]    Loss: 0.007057   Batch Acc: 84.38
[Train] Epoch: 2 [169600/620022]    Loss: 0.007418   Batch Acc: 84.38
[Train] Epoch: 2 [169664/620022]    Loss: 0.007924   Batch Acc: 78.12
[Train] Epoch: 2 [169728/620022]    Loss: 0.007764   Batch Acc: 84.38
[Train] Epoch: 2 [169792/620022]    Loss: 0.007752   Batch Acc: 81.25
[Train] Epoch: 2 [169856/620022]    Loss: 0.009675   Batch Acc: 73.44
[Train] Epoch: 2 [169920/620022]    Loss: 0.006277   Batch Acc: 92.19
[Train] Epoch: 2 [169984/620022]    Loss: 0.006452   Batch Acc: 87.50
[Train] Epoch: 2 [170048/620022]    Loss: 0.008718   Batch Acc: 78.12
[Train] Epoch: 2 [170112/620022]    Loss: 0.014057   Batch Acc: 60.94
[Train] Epoch: 2 [170176/620022]    Loss: 0.007790   Batch Acc: 76.56
[Train] Epoch: 2 [170240/620022]    Loss: 0.008976   Batch Acc: 73.44
[Train] Epoch: 2 [170304/620022]    Loss: 0.008393   Batch Acc: 70.31
[Train] Epoch: 2 [170368/620022]    Loss: 0.010085   Batch Acc: 75.00
[Train] Epoch: 2 [170432/620022]    Loss: 0.010177   Batch Acc: 75.00
[Train] Epoch: 2 [170496/620022]    Loss: 0.007199   Batch Acc: 87.50
[Train] Epoch: 2 [170560/620022]    Loss: 0.008001   Batch Acc: 81.25
[Train] Epoch: 2 [170624/620022]    Loss: 0.009852   Batch Acc: 73.44
[Train] Epoch: 2 [170688/620022]    Loss: 0.007990   Batch Acc: 79.69
[Train] Epoch: 2 [170752/620022]    Loss: 0.007160   Batch Acc: 79.69
[Train] Epoch: 2 [170816/620022]    Loss: 0.007655   Batch Acc: 82.81
[Train] Epoch: 2 [170880/620022]    Loss: 0.009295   Batch Acc: 73.44
[Train] Epoch: 2 [170944/620022]    Loss: 0.008292   Batch Acc: 87.50
[Train] Epoch: 2 [171008/620022]    Loss: 0.008423   Batch Acc: 79.69
[Train] Epoch: 2 [171072/620022]    Loss: 0.008270   Batch Acc: 79.69
[Train] Epoch: 2 [171136/620022]    Loss: 0.007102   Batch Acc: 85.94
[Train] Epoch: 2 [171200/620022]    Loss: 0.008140   Batch Acc: 78.12
[Train] Epoch: 2 [171264/620022]    Loss: 0.008448   Batch Acc: 78.12
[Train] Epoch: 2 [171328/620022]    Loss: 0.008344   Batch Acc: 76.56
[Train] Epoch: 2 [171392/620022]    Loss: 0.008898   Batch Acc: 76.56
[Train] Epoch: 2 [171456/620022]    Loss: 0.012851   Batch Acc: 70.31
[Train] Epoch: 2 [171520/620022]    Loss: 0.008655   Batch Acc: 78.12
[Train] Epoch: 2 [171584/620022]    Loss: 0.008836   Batch Acc: 81.25
[Train] Epoch: 2 [171648/620022]    Loss: 0.009241   Batch Acc: 76.56
[Train] Epoch: 2 [171712/620022]    Loss: 0.008154   Batch Acc: 81.25
[Train] Epoch: 2 [171776/620022]    Loss: 0.006973   Batch Acc: 81.25
[Train] Epoch: 2 [171840/620022]    Loss: 0.006516   Batch Acc: 81.25
[Train] Epoch: 2 [171904/620022]    Loss: 0.007652   Batch Acc: 79.69
[Train] Epoch: 2 [171968/620022]    Loss: 0.008851   Batch Acc: 79.69
[Train] Epoch: 2 [172032/620022]    Loss: 0.006822   Batch Acc: 84.38
[Train] Epoch: 2 [172096/620022]    Loss: 0.008715   Batch Acc: 76.56
[Train] Epoch: 2 [172160/620022]    Loss: 0.011048   Batch Acc: 71.88
[Train] Epoch: 2 [172224/620022]    Loss: 0.007952   Batch Acc: 78.12
[Train] Epoch: 2 [172288/620022]    Loss: 0.009506   Batch Acc: 67.19
[Train] Epoch: 2 [172352/620022]    Loss: 0.007993   Batch Acc: 78.12
[Train] Epoch: 2 [172416/620022]    Loss: 0.008444   Batch Acc: 71.88
[Train] Epoch: 2 [172480/620022]    Loss: 0.008156   Batch Acc: 84.38
[Train] Epoch: 2 [172544/620022]    Loss: 0.007979   Batch Acc: 81.25
[Train] Epoch: 2 [172608/620022]    Loss: 0.008446   Batch Acc: 81.25
[Train] Epoch: 2 [172672/620022]    Loss: 0.009453   Batch Acc: 78.12
[Train] Epoch: 2 [172736/620022]    Loss: 0.007186   Batch Acc: 89.06
[Train] Epoch: 2 [172800/620022]    Loss: 0.009817   Batch Acc: 75.00
[Train] Epoch: 2 [172864/620022]    Loss: 0.007129   Batch Acc: 82.81
[Train] Epoch: 2 [172928/620022]    Loss: 0.008115   Batch Acc: 79.69
[Train] Epoch: 2 [172992/620022]    Loss: 0.008724   Batch Acc: 78.12
[Train] Epoch: 2 [173056/620022]    Loss: 0.009207   Batch Acc: 78.12
[Train] Epoch: 2 [173120/620022]    Loss: 0.008277   Batch Acc: 82.81
[Train] Epoch: 2 [173184/620022]    Loss: 0.008029   Batch Acc: 82.81
[Train] Epoch: 2 [173248/620022]    Loss: 0.009109   Batch Acc: 73.44
[Train] Epoch: 2 [173312/620022]    Loss: 0.008853   Batch Acc: 73.44
[Train] Epoch: 2 [173376/620022]    Loss: 0.010548   Batch Acc: 67.19
[Train] Epoch: 2 [173440/620022]    Loss: 0.007397   Batch Acc: 79.69
[Train] Epoch: 2 [173504/620022]    Loss: 0.010235   Batch Acc: 71.88
[Train] Epoch: 2 [173568/620022]    Loss: 0.007522   Batch Acc: 82.81
[Train] Epoch: 2 [173632/620022]    Loss: 0.008337   Batch Acc: 78.12
[Train] Epoch: 2 [173696/620022]    Loss: 0.008488   Batch Acc: 78.12
[Train] Epoch: 2 [173760/620022]    Loss: 0.008722   Batch Acc: 76.56
[Train] Epoch: 2 [173824/620022]    Loss: 0.010837   Batch Acc: 78.12
[Train] Epoch: 2 [173888/620022]    Loss: 0.009066   Batch Acc: 78.12
[Train] Epoch: 2 [173952/620022]    Loss: 0.007959   Batch Acc: 79.69
[Train] Epoch: 2 [174016/620022]    Loss: 0.009952   Batch Acc: 71.88
[Train] Epoch: 2 [174080/620022]    Loss: 0.009511   Batch Acc: 73.44
[Train] Epoch: 2 [174144/620022]    Loss: 0.008259   Batch Acc: 75.00
[Train] Epoch: 2 [174208/620022]    Loss: 0.007285   Batch Acc: 79.69
[Train] Epoch: 2 [174272/620022]    Loss: 0.008441   Batch Acc: 79.69
[Train] Epoch: 2 [174336/620022]    Loss: 0.009343   Batch Acc: 78.12
[Train] Epoch: 2 [174400/620022]    Loss: 0.009078   Batch Acc: 76.56
[Train] Epoch: 2 [174464/620022]    Loss: 0.006875   Batch Acc: 82.81
[Train] Epoch: 2 [174528/620022]    Loss: 0.009265   Batch Acc: 75.00
[Train] Epoch: 2 [174592/620022]    Loss: 0.008492   Batch Acc: 78.12
[Train] Epoch: 2 [174656/620022]    Loss: 0.008648   Batch Acc: 79.69
[Train] Epoch: 2 [174720/620022]    Loss: 0.009090   Batch Acc: 76.56
[Train] Epoch: 2 [174784/620022]    Loss: 0.006151   Batch Acc: 84.38
[Train] Epoch: 2 [174848/620022]    Loss: 0.011978   Batch Acc: 68.75
[Train] Epoch: 2 [174912/620022]    Loss: 0.006966   Batch Acc: 82.81
[Train] Epoch: 2 [174976/620022]    Loss: 0.007856   Batch Acc: 79.69
[Train] Epoch: 2 [175040/620022]    Loss: 0.009793   Batch Acc: 73.44
[Train] Epoch: 2 [175104/620022]    Loss: 0.009253   Batch Acc: 82.81
[Train] Epoch: 2 [175168/620022]    Loss: 0.010531   Batch Acc: 73.44
[Train] Epoch: 2 [175232/620022]    Loss: 0.008498   Batch Acc: 85.94
[Train] Epoch: 2 [175296/620022]    Loss: 0.009476   Batch Acc: 76.56
[Train] Epoch: 2 [175360/620022]    Loss: 0.007478   Batch Acc: 85.94
[Train] Epoch: 2 [175424/620022]    Loss: 0.010491   Batch Acc: 75.00
[Train] Epoch: 2 [175488/620022]    Loss: 0.011545   Batch Acc: 70.31
[Train] Epoch: 2 [175552/620022]    Loss: 0.007880   Batch Acc: 79.69
[Train] Epoch: 2 [175616/620022]    Loss: 0.006773   Batch Acc: 84.38
[Train] Epoch: 2 [175680/620022]    Loss: 0.009561   Batch Acc: 73.44
[Train] Epoch: 2 [175744/620022]    Loss: 0.010518   Batch Acc: 67.19
[Train] Epoch: 2 [175808/620022]    Loss: 0.008677   Batch Acc: 78.12
[Train] Epoch: 2 [175872/620022]    Loss: 0.008226   Batch Acc: 81.25
[Train] Epoch: 2 [175936/620022]    Loss: 0.008133   Batch Acc: 82.81
[Train] Epoch: 2 [176000/620022]    Loss: 0.008327   Batch Acc: 81.25
[Train] Epoch: 2 [176064/620022]    Loss: 0.011972   Batch Acc: 68.75
[Train] Epoch: 2 [176128/620022]    Loss: 0.009518   Batch Acc: 75.00
[Train] Epoch: 2 [176192/620022]    Loss: 0.008957   Batch Acc: 73.44
[Train] Epoch: 2 [176256/620022]    Loss: 0.009209   Batch Acc: 78.12
[Train] Epoch: 2 [176320/620022]    Loss: 0.007632   Batch Acc: 82.81
[Train] Epoch: 2 [176384/620022]    Loss: 0.005702   Batch Acc: 89.06
[Train] Epoch: 2 [176448/620022]    Loss: 0.008063   Batch Acc: 76.56
[Train] Epoch: 2 [176512/620022]    Loss: 0.009683   Batch Acc: 76.56
[Train] Epoch: 2 [176576/620022]    Loss: 0.007255   Batch Acc: 89.06
[Train] Epoch: 2 [176640/620022]    Loss: 0.009560   Batch Acc: 81.25
[Train] Epoch: 2 [176704/620022]    Loss: 0.007886   Batch Acc: 84.38
[Train] Epoch: 2 [176768/620022]    Loss: 0.011644   Batch Acc: 67.19
[Train] Epoch: 2 [176832/620022]    Loss: 0.011727   Batch Acc: 65.62
[Train] Epoch: 2 [176896/620022]    Loss: 0.006701   Batch Acc: 85.94
[Train] Epoch: 2 [176960/620022]    Loss: 0.009369   Batch Acc: 73.44
[Train] Epoch: 2 [177024/620022]    Loss: 0.007656   Batch Acc: 79.69
[Train] Epoch: 2 [177088/620022]    Loss: 0.008689   Batch Acc: 78.12
[Train] Epoch: 2 [177152/620022]    Loss: 0.009170   Batch Acc: 75.00
[Train] Epoch: 2 [177216/620022]    Loss: 0.008923   Batch Acc: 71.88
[Train] Epoch: 2 [177280/620022]    Loss: 0.008260   Batch Acc: 78.12
[Train] Epoch: 2 [177344/620022]    Loss: 0.009426   Batch Acc: 70.31
[Train] Epoch: 2 [177408/620022]    Loss: 0.011491   Batch Acc: 70.31
[Train] Epoch: 2 [177472/620022]    Loss: 0.007391   Batch Acc: 78.12
[Train] Epoch: 2 [177536/620022]    Loss: 0.009287   Batch Acc: 73.44
[Train] Epoch: 2 [177600/620022]    Loss: 0.009402   Batch Acc: 75.00
[Train] Epoch: 2 [177664/620022]    Loss: 0.009023   Batch Acc: 75.00
[Train] Epoch: 2 [177728/620022]    Loss: 0.007745   Batch Acc: 78.12
[Train] Epoch: 2 [177792/620022]    Loss: 0.006649   Batch Acc: 84.38
[Train] Epoch: 2 [177856/620022]    Loss: 0.008589   Batch Acc: 78.12
[Train] Epoch: 2 [177920/620022]    Loss: 0.008348   Batch Acc: 76.56
[Train] Epoch: 2 [177984/620022]    Loss: 0.007753   Batch Acc: 82.81
[Train] Epoch: 2 [178048/620022]    Loss: 0.008794   Batch Acc: 79.69
[Train] Epoch: 2 [178112/620022]    Loss: 0.009487   Batch Acc: 71.88
[Train] Epoch: 2 [178176/620022]    Loss: 0.007245   Batch Acc: 84.38
[Train] Epoch: 2 [178240/620022]    Loss: 0.009006   Batch Acc: 73.44
[Train] Epoch: 2 [178304/620022]    Loss: 0.007627   Batch Acc: 81.25
[Train] Epoch: 2 [178368/620022]    Loss: 0.007619   Batch Acc: 76.56
[Train] Epoch: 2 [178432/620022]    Loss: 0.010062   Batch Acc: 75.00
[Train] Epoch: 2 [178496/620022]    Loss: 0.007302   Batch Acc: 84.38
[Train] Epoch: 2 [178560/620022]    Loss: 0.009812   Batch Acc: 78.12
[Train] Epoch: 2 [178624/620022]    Loss: 0.008805   Batch Acc: 76.56
[Train] Epoch: 2 [178688/620022]    Loss: 0.006595   Batch Acc: 82.81
[Train] Epoch: 2 [178752/620022]    Loss: 0.007932   Batch Acc: 81.25
[Train] Epoch: 2 [178816/620022]    Loss: 0.008931   Batch Acc: 76.56
[Train] Epoch: 2 [178880/620022]    Loss: 0.008795   Batch Acc: 79.69
[Train] Epoch: 2 [178944/620022]    Loss: 0.008777   Batch Acc: 73.44
[Train] Epoch: 2 [179008/620022]    Loss: 0.008381   Batch Acc: 75.00
[Train] Epoch: 2 [179072/620022]    Loss: 0.010479   Batch Acc: 71.88
[Train] Epoch: 2 [179136/620022]    Loss: 0.008324   Batch Acc: 79.69
[Train] Epoch: 2 [179200/620022]    Loss: 0.007511   Batch Acc: 85.94
[Train] Epoch: 2 [179264/620022]    Loss: 0.008230   Batch Acc: 78.12
[Train] Epoch: 2 [179328/620022]    Loss: 0.007806   Batch Acc: 76.56
[Train] Epoch: 2 [179392/620022]    Loss: 0.009523   Batch Acc: 75.00
[Train] Epoch: 2 [179456/620022]    Loss: 0.010746   Batch Acc: 71.88
[Train] Epoch: 2 [179520/620022]    Loss: 0.006063   Batch Acc: 85.94
[Train] Epoch: 2 [179584/620022]    Loss: 0.008872   Batch Acc: 76.56
[Train] Epoch: 2 [179648/620022]    Loss: 0.007559   Batch Acc: 87.50
[Train] Epoch: 2 [179712/620022]    Loss: 0.007700   Batch Acc: 70.31
[Train] Epoch: 2 [179776/620022]    Loss: 0.008431   Batch Acc: 79.69
[Train] Epoch: 2 [179840/620022]    Loss: 0.010777   Batch Acc: 71.88
[Train] Epoch: 2 [179904/620022]    Loss: 0.008602   Batch Acc: 73.44
[Train] Epoch: 2 [179968/620022]    Loss: 0.010078   Batch Acc: 75.00
[Train] Epoch: 2 [180032/620022]    Loss: 0.010468   Batch Acc: 71.88
[Train] Epoch: 2 [180096/620022]    Loss: 0.009736   Batch Acc: 71.88
[Train] Epoch: 2 [180160/620022]    Loss: 0.012569   Batch Acc: 65.62
[Train] Epoch: 2 [180224/620022]    Loss: 0.009421   Batch Acc: 73.44
[Train] Epoch: 2 [180288/620022]    Loss: 0.011484   Batch Acc: 65.62
[Train] Epoch: 2 [180352/620022]    Loss: 0.009567   Batch Acc: 68.75
[Train] Epoch: 2 [180416/620022]    Loss: 0.008794   Batch Acc: 82.81
[Train] Epoch: 2 [180480/620022]    Loss: 0.006539   Batch Acc: 82.81
[Train] Epoch: 2 [180544/620022]    Loss: 0.007286   Batch Acc: 81.25
[Train] Epoch: 2 [180608/620022]    Loss: 0.009953   Batch Acc: 70.31
[Train] Epoch: 2 [180672/620022]    Loss: 0.008775   Batch Acc: 81.25
[Train] Epoch: 2 [180736/620022]    Loss: 0.006580   Batch Acc: 84.38
[Train] Epoch: 2 [180800/620022]    Loss: 0.009262   Batch Acc: 78.12
[Train] Epoch: 2 [180864/620022]    Loss: 0.006956   Batch Acc: 79.69
[Train] Epoch: 2 [180928/620022]    Loss: 0.010124   Batch Acc: 73.44
[Train] Epoch: 2 [180992/620022]    Loss: 0.006103   Batch Acc: 82.81
[Train] Epoch: 2 [181056/620022]    Loss: 0.008139   Batch Acc: 82.81
[Train] Epoch: 2 [181120/620022]    Loss: 0.007324   Batch Acc: 84.38
[Train] Epoch: 2 [181184/620022]    Loss: 0.007754   Batch Acc: 79.69
[Train] Epoch: 2 [181248/620022]    Loss: 0.006305   Batch Acc: 85.94
[Train] Epoch: 2 [181312/620022]    Loss: 0.008257   Batch Acc: 73.44
[Train] Epoch: 2 [181376/620022]    Loss: 0.008917   Batch Acc: 79.69
[Train] Epoch: 2 [181440/620022]    Loss: 0.010426   Batch Acc: 75.00
[Train] Epoch: 2 [181504/620022]    Loss: 0.006213   Batch Acc: 90.62
[Train] Epoch: 2 [181568/620022]    Loss: 0.007282   Batch Acc: 84.38
[Train] Epoch: 2 [181632/620022]    Loss: 0.010238   Batch Acc: 70.31
[Train] Epoch: 2 [181696/620022]    Loss: 0.009125   Batch Acc: 78.12
[Train] Epoch: 2 [181760/620022]    Loss: 0.009651   Batch Acc: 78.12
[Train] Epoch: 2 [181824/620022]    Loss: 0.006735   Batch Acc: 84.38
[Train] Epoch: 2 [181888/620022]    Loss: 0.008574   Batch Acc: 81.25
[Train] Epoch: 2 [181952/620022]    Loss: 0.009248   Batch Acc: 76.56
[Train] Epoch: 2 [182016/620022]    Loss: 0.007896   Batch Acc: 79.69
[Train] Epoch: 2 [182080/620022]    Loss: 0.008170   Batch Acc: 82.81
[Train] Epoch: 2 [182144/620022]    Loss: 0.006913   Batch Acc: 84.38
[Train] Epoch: 2 [182208/620022]    Loss: 0.012047   Batch Acc: 64.06
[Train] Epoch: 2 [182272/620022]    Loss: 0.010403   Batch Acc: 70.31
[Train] Epoch: 2 [182336/620022]    Loss: 0.007955   Batch Acc: 79.69
[Train] Epoch: 2 [182400/620022]    Loss: 0.008043   Batch Acc: 82.81
[Train] Epoch: 2 [182464/620022]    Loss: 0.009145   Batch Acc: 76.56
[Train] Epoch: 2 [182528/620022]    Loss: 0.009074   Batch Acc: 78.12
[Train] Epoch: 2 [182592/620022]    Loss: 0.007936   Batch Acc: 79.69
[Train] Epoch: 2 [182656/620022]    Loss: 0.008134   Batch Acc: 82.81
[Train] Epoch: 2 [182720/620022]    Loss: 0.008432   Batch Acc: 81.25
[Train] Epoch: 2 [182784/620022]    Loss: 0.007897   Batch Acc: 81.25
[Train] Epoch: 2 [182848/620022]    Loss: 0.009917   Batch Acc: 71.88
[Train] Epoch: 2 [182912/620022]    Loss: 0.008342   Batch Acc: 82.81
[Train] Epoch: 2 [182976/620022]    Loss: 0.008355   Batch Acc: 78.12
[Train] Epoch: 2 [183040/620022]    Loss: 0.006534   Batch Acc: 82.81
[Train] Epoch: 2 [183104/620022]    Loss: 0.008992   Batch Acc: 71.88
[Train] Epoch: 2 [183168/620022]    Loss: 0.008274   Batch Acc: 75.00
[Train] Epoch: 2 [183232/620022]    Loss: 0.009962   Batch Acc: 71.88
[Train] Epoch: 2 [183296/620022]    Loss: 0.009005   Batch Acc: 76.56
[Train] Epoch: 2 [183360/620022]    Loss: 0.010384   Batch Acc: 76.56
[Train] Epoch: 2 [183424/620022]    Loss: 0.008012   Batch Acc: 85.94
[Train] Epoch: 2 [183488/620022]    Loss: 0.010300   Batch Acc: 73.44
[Train] Epoch: 2 [183552/620022]    Loss: 0.008497   Batch Acc: 79.69
[Train] Epoch: 2 [183616/620022]    Loss: 0.009712   Batch Acc: 78.12
[Train] Epoch: 2 [183680/620022]    Loss: 0.008956   Batch Acc: 79.69
[Train] Epoch: 2 [183744/620022]    Loss: 0.010207   Batch Acc: 75.00
[Train] Epoch: 2 [183808/620022]    Loss: 0.009136   Batch Acc: 75.00
[Train] Epoch: 2 [183872/620022]    Loss: 0.009287   Batch Acc: 73.44
[Train] Epoch: 2 [183936/620022]    Loss: 0.008494   Batch Acc: 81.25
[Train] Epoch: 2 [184000/620022]    Loss: 0.008837   Batch Acc: 71.88
[Train] Epoch: 2 [184064/620022]    Loss: 0.007905   Batch Acc: 78.12
[Train] Epoch: 2 [184128/620022]    Loss: 0.008702   Batch Acc: 78.12
[Train] Epoch: 2 [184192/620022]    Loss: 0.008225   Batch Acc: 81.25
[Train] Epoch: 2 [184256/620022]    Loss: 0.008616   Batch Acc: 76.56
[Train] Epoch: 2 [184320/620022]    Loss: 0.007697   Batch Acc: 78.12
[Train] Epoch: 2 [184384/620022]    Loss: 0.008840   Batch Acc: 79.69
[Train] Epoch: 2 [184448/620022]    Loss: 0.007805   Batch Acc: 78.12
[Train] Epoch: 2 [184512/620022]    Loss: 0.010291   Batch Acc: 73.44
[Train] Epoch: 2 [184576/620022]    Loss: 0.008610   Batch Acc: 81.25
[Train] Epoch: 2 [184640/620022]    Loss: 0.009882   Batch Acc: 73.44
[Train] Epoch: 2 [184704/620022]    Loss: 0.009705   Batch Acc: 76.56
[Train] Epoch: 2 [184768/620022]    Loss: 0.007919   Batch Acc: 84.38
[Train] Epoch: 2 [184832/620022]    Loss: 0.009789   Batch Acc: 76.56
[Train] Epoch: 2 [184896/620022]    Loss: 0.009142   Batch Acc: 76.56
[Train] Epoch: 2 [184960/620022]    Loss: 0.007991   Batch Acc: 81.25
[Train] Epoch: 2 [185024/620022]    Loss: 0.007532   Batch Acc: 84.38
[Train] Epoch: 2 [185088/620022]    Loss: 0.009266   Batch Acc: 79.69
[Train] Epoch: 2 [185152/620022]    Loss: 0.008325   Batch Acc: 81.25
[Train] Epoch: 2 [185216/620022]    Loss: 0.009923   Batch Acc: 70.31
[Train] Epoch: 2 [185280/620022]    Loss: 0.007482   Batch Acc: 76.56
[Train] Epoch: 2 [185344/620022]    Loss: 0.007612   Batch Acc: 84.38
[Train] Epoch: 2 [185408/620022]    Loss: 0.008903   Batch Acc: 70.31
[Train] Epoch: 2 [185472/620022]    Loss: 0.010202   Batch Acc: 71.88
[Train] Epoch: 2 [185536/620022]    Loss: 0.011673   Batch Acc: 67.19
[Train] Epoch: 2 [185600/620022]    Loss: 0.008101   Batch Acc: 87.50
[Train] Epoch: 2 [185664/620022]    Loss: 0.006175   Batch Acc: 89.06
[Train] Epoch: 2 [185728/620022]    Loss: 0.007837   Batch Acc: 79.69
[Train] Epoch: 2 [185792/620022]    Loss: 0.009106   Batch Acc: 84.38
[Train] Epoch: 2 [185856/620022]    Loss: 0.006005   Batch Acc: 85.94
[Train] Epoch: 2 [185920/620022]    Loss: 0.012114   Batch Acc: 76.56
[Train] Epoch: 2 [185984/620022]    Loss: 0.008488   Batch Acc: 76.56
[Train] Epoch: 2 [186048/620022]    Loss: 0.008894   Batch Acc: 78.12
[Train] Epoch: 2 [186112/620022]    Loss: 0.009514   Batch Acc: 76.56
[Train] Epoch: 2 [186176/620022]    Loss: 0.007638   Batch Acc: 76.56
[Train] Epoch: 2 [186240/620022]    Loss: 0.008310   Batch Acc: 82.81
[Train] Epoch: 2 [186304/620022]    Loss: 0.008510   Batch Acc: 81.25
[Train] Epoch: 2 [186368/620022]    Loss: 0.007889   Batch Acc: 79.69
[Train] Epoch: 2 [186432/620022]    Loss: 0.008776   Batch Acc: 78.12
[Train] Epoch: 2 [186496/620022]    Loss: 0.006697   Batch Acc: 90.62
[Train] Epoch: 2 [186560/620022]    Loss: 0.008336   Batch Acc: 79.69
[Train] Epoch: 2 [186624/620022]    Loss: 0.005790   Batch Acc: 87.50
[Train] Epoch: 2 [186688/620022]    Loss: 0.008334   Batch Acc: 79.69
[Train] Epoch: 2 [186752/620022]    Loss: 0.006912   Batch Acc: 85.94
[Train] Epoch: 2 [186816/620022]    Loss: 0.008381   Batch Acc: 78.12
[Train] Epoch: 2 [186880/620022]    Loss: 0.009226   Batch Acc: 78.12
[Train] Epoch: 2 [186944/620022]    Loss: 0.008302   Batch Acc: 79.69
[Train] Epoch: 2 [187008/620022]    Loss: 0.008305   Batch Acc: 75.00
[Train] Epoch: 2 [187072/620022]    Loss: 0.009021   Batch Acc: 75.00
[Train] Epoch: 2 [187136/620022]    Loss: 0.008600   Batch Acc: 82.81
[Train] Epoch: 2 [187200/620022]    Loss: 0.011268   Batch Acc: 67.19
[Train] Epoch: 2 [187264/620022]    Loss: 0.009886   Batch Acc: 79.69
[Train] Epoch: 2 [187328/620022]    Loss: 0.007178   Batch Acc: 81.25
[Train] Epoch: 2 [187392/620022]    Loss: 0.010143   Batch Acc: 68.75
[Train] Epoch: 2 [187456/620022]    Loss: 0.007830   Batch Acc: 85.94
[Train] Epoch: 2 [187520/620022]    Loss: 0.008249   Batch Acc: 78.12
[Train] Epoch: 2 [187584/620022]    Loss: 0.009322   Batch Acc: 79.69
[Train] Epoch: 2 [187648/620022]    Loss: 0.008005   Batch Acc: 82.81
[Train] Epoch: 2 [187712/620022]    Loss: 0.006779   Batch Acc: 84.38
[Train] Epoch: 2 [187776/620022]    Loss: 0.011317   Batch Acc: 70.31
[Train] Epoch: 2 [187840/620022]    Loss: 0.009981   Batch Acc: 70.31
[Train] Epoch: 2 [187904/620022]    Loss: 0.009009   Batch Acc: 78.12
[Train] Epoch: 2 [187968/620022]    Loss: 0.009662   Batch Acc: 73.44
[Train] Epoch: 2 [188032/620022]    Loss: 0.011381   Batch Acc: 71.88
[Train] Epoch: 2 [188096/620022]    Loss: 0.010607   Batch Acc: 75.00
[Train] Epoch: 2 [188160/620022]    Loss: 0.008449   Batch Acc: 81.25
[Train] Epoch: 2 [188224/620022]    Loss: 0.009812   Batch Acc: 73.44
[Train] Epoch: 2 [188288/620022]    Loss: 0.007067   Batch Acc: 84.38
[Train] Epoch: 2 [188352/620022]    Loss: 0.008952   Batch Acc: 79.69
[Train] Epoch: 2 [188416/620022]    Loss: 0.009122   Batch Acc: 71.88
[Train] Epoch: 2 [188480/620022]    Loss: 0.008674   Batch Acc: 75.00
[Train] Epoch: 2 [188544/620022]    Loss: 0.008531   Batch Acc: 79.69
[Train] Epoch: 2 [188608/620022]    Loss: 0.007939   Batch Acc: 76.56
[Train] Epoch: 2 [188672/620022]    Loss: 0.010357   Batch Acc: 68.75
[Train] Epoch: 2 [188736/620022]    Loss: 0.008136   Batch Acc: 79.69
[Train] Epoch: 2 [188800/620022]    Loss: 0.008164   Batch Acc: 84.38
[Train] Epoch: 2 [188864/620022]    Loss: 0.009795   Batch Acc: 71.88
[Train] Epoch: 2 [188928/620022]    Loss: 0.007776   Batch Acc: 82.81
[Train] Epoch: 2 [188992/620022]    Loss: 0.007892   Batch Acc: 79.69
[Train] Epoch: 2 [189056/620022]    Loss: 0.008737   Batch Acc: 73.44
[Train] Epoch: 2 [189120/620022]    Loss: 0.009288   Batch Acc: 71.88
[Train] Epoch: 2 [189184/620022]    Loss: 0.009698   Batch Acc: 75.00
[Train] Epoch: 2 [189248/620022]    Loss: 0.008891   Batch Acc: 78.12
[Train] Epoch: 2 [189312/620022]    Loss: 0.009794   Batch Acc: 73.44
[Train] Epoch: 2 [189376/620022]    Loss: 0.007896   Batch Acc: 84.38
[Train] Epoch: 2 [189440/620022]    Loss: 0.008295   Batch Acc: 81.25
[Train] Epoch: 2 [189504/620022]    Loss: 0.006915   Batch Acc: 85.94
[Train] Epoch: 2 [189568/620022]    Loss: 0.010092   Batch Acc: 70.31
[Train] Epoch: 2 [189632/620022]    Loss: 0.007054   Batch Acc: 87.50
[Train] Epoch: 2 [189696/620022]    Loss: 0.009763   Batch Acc: 70.31
[Train] Epoch: 2 [189760/620022]    Loss: 0.010761   Batch Acc: 70.31
[Train] Epoch: 2 [189824/620022]    Loss: 0.007356   Batch Acc: 81.25
[Train] Epoch: 2 [189888/620022]    Loss: 0.009551   Batch Acc: 68.75
[Train] Epoch: 2 [189952/620022]    Loss: 0.008608   Batch Acc: 79.69
[Train] Epoch: 2 [190016/620022]    Loss: 0.007662   Batch Acc: 78.12
[Train] Epoch: 2 [190080/620022]    Loss: 0.008662   Batch Acc: 76.56
[Train] Epoch: 2 [190144/620022]    Loss: 0.008187   Batch Acc: 82.81
[Train] Epoch: 2 [190208/620022]    Loss: 0.009153   Batch Acc: 71.88
[Train] Epoch: 2 [190272/620022]    Loss: 0.012171   Batch Acc: 64.06
[Train] Epoch: 2 [190336/620022]    Loss: 0.008913   Batch Acc: 71.88
[Train] Epoch: 2 [190400/620022]    Loss: 0.008029   Batch Acc: 79.69
[Train] Epoch: 2 [190464/620022]    Loss: 0.007374   Batch Acc: 85.94
[Train] Epoch: 2 [190528/620022]    Loss: 0.007169   Batch Acc: 82.81
[Train] Epoch: 2 [190592/620022]    Loss: 0.010817   Batch Acc: 76.56
[Train] Epoch: 2 [190656/620022]    Loss: 0.008320   Batch Acc: 79.69
[Train] Epoch: 2 [190720/620022]    Loss: 0.008123   Batch Acc: 84.38
[Train] Epoch: 2 [190784/620022]    Loss: 0.007560   Batch Acc: 78.12
[Train] Epoch: 2 [190848/620022]    Loss: 0.008387   Batch Acc: 79.69
[Train] Epoch: 2 [190912/620022]    Loss: 0.010712   Batch Acc: 79.69
[Train] Epoch: 2 [190976/620022]    Loss: 0.008724   Batch Acc: 76.56
[Train] Epoch: 2 [191040/620022]    Loss: 0.010610   Batch Acc: 65.62
[Train] Epoch: 2 [191104/620022]    Loss: 0.007513   Batch Acc: 81.25
[Train] Epoch: 2 [191168/620022]    Loss: 0.008392   Batch Acc: 79.69
[Train] Epoch: 2 [191232/620022]    Loss: 0.009152   Batch Acc: 75.00
[Train] Epoch: 2 [191296/620022]    Loss: 0.008631   Batch Acc: 76.56
[Train] Epoch: 2 [191360/620022]    Loss: 0.007221   Batch Acc: 82.81
[Train] Epoch: 2 [191424/620022]    Loss: 0.009436   Batch Acc: 79.69
[Train] Epoch: 2 [191488/620022]    Loss: 0.009774   Batch Acc: 71.88
[Train] Epoch: 2 [191552/620022]    Loss: 0.008235   Batch Acc: 76.56
[Train] Epoch: 2 [191616/620022]    Loss: 0.006871   Batch Acc: 79.69
[Train] Epoch: 2 [191680/620022]    Loss: 0.010498   Batch Acc: 71.88
[Train] Epoch: 2 [191744/620022]    Loss: 0.009869   Batch Acc: 78.12
[Train] Epoch: 2 [191808/620022]    Loss: 0.008507   Batch Acc: 78.12
[Train] Epoch: 2 [191872/620022]    Loss: 0.008557   Batch Acc: 79.69
[Train] Epoch: 2 [191936/620022]    Loss: 0.007650   Batch Acc: 82.81
[Train] Epoch: 2 [192000/620022]    Loss: 0.010443   Batch Acc: 73.44
[Train] Epoch: 2 [192064/620022]    Loss: 0.007978   Batch Acc: 75.00
[Train] Epoch: 2 [192128/620022]    Loss: 0.008332   Batch Acc: 79.69
[Train] Epoch: 2 [192192/620022]    Loss: 0.008427   Batch Acc: 81.25
[Train] Epoch: 2 [192256/620022]    Loss: 0.007035   Batch Acc: 82.81
[Train] Epoch: 2 [192320/620022]    Loss: 0.007900   Batch Acc: 81.25
[Train] Epoch: 2 [192384/620022]    Loss: 0.008572   Batch Acc: 79.69
[Train] Epoch: 2 [192448/620022]    Loss: 0.009118   Batch Acc: 76.56
[Train] Epoch: 2 [192512/620022]    Loss: 0.011132   Batch Acc: 67.19
[Train] Epoch: 2 [192576/620022]    Loss: 0.007468   Batch Acc: 81.25
[Train] Epoch: 2 [192640/620022]    Loss: 0.007821   Batch Acc: 78.12
[Train] Epoch: 2 [192704/620022]    Loss: 0.012035   Batch Acc: 60.94
[Train] Epoch: 2 [192768/620022]    Loss: 0.010251   Batch Acc: 71.88
[Train] Epoch: 2 [192832/620022]    Loss: 0.008870   Batch Acc: 78.12
[Train] Epoch: 2 [192896/620022]    Loss: 0.008501   Batch Acc: 78.12
[Train] Epoch: 2 [192960/620022]    Loss: 0.007906   Batch Acc: 78.12
[Train] Epoch: 2 [193024/620022]    Loss: 0.008548   Batch Acc: 73.44
[Train] Epoch: 2 [193088/620022]    Loss: 0.008232   Batch Acc: 82.81
[Train] Epoch: 2 [193152/620022]    Loss: 0.009259   Batch Acc: 79.69
[Train] Epoch: 2 [193216/620022]    Loss: 0.010126   Batch Acc: 71.88
[Train] Epoch: 2 [193280/620022]    Loss: 0.007836   Batch Acc: 82.81
[Train] Epoch: 2 [193344/620022]    Loss: 0.009501   Batch Acc: 79.69
[Train] Epoch: 2 [193408/620022]    Loss: 0.008938   Batch Acc: 78.12
[Train] Epoch: 2 [193472/620022]    Loss: 0.007681   Batch Acc: 81.25
[Train] Epoch: 2 [193536/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 2 [193600/620022]    Loss: 0.009386   Batch Acc: 68.75
[Train] Epoch: 2 [193664/620022]    Loss: 0.008211   Batch Acc: 75.00
[Train] Epoch: 2 [193728/620022]    Loss: 0.009156   Batch Acc: 76.56
[Train] Epoch: 2 [193792/620022]    Loss: 0.009039   Batch Acc: 76.56
[Train] Epoch: 2 [193856/620022]    Loss: 0.006804   Batch Acc: 85.94
[Train] Epoch: 2 [193920/620022]    Loss: 0.007986   Batch Acc: 81.25
[Train] Epoch: 2 [193984/620022]    Loss: 0.011034   Batch Acc: 76.56
[Train] Epoch: 2 [194048/620022]    Loss: 0.009422   Batch Acc: 76.56
[Train] Epoch: 2 [194112/620022]    Loss: 0.011432   Batch Acc: 64.06
[Train] Epoch: 2 [194176/620022]    Loss: 0.008052   Batch Acc: 76.56
[Train] Epoch: 2 [194240/620022]    Loss: 0.009006   Batch Acc: 75.00
[Train] Epoch: 2 [194304/620022]    Loss: 0.008431   Batch Acc: 84.38
[Train] Epoch: 2 [194368/620022]    Loss: 0.009114   Batch Acc: 76.56
[Train] Epoch: 2 [194432/620022]    Loss: 0.008376   Batch Acc: 84.38
[Train] Epoch: 2 [194496/620022]    Loss: 0.010461   Batch Acc: 71.88
[Train] Epoch: 2 [194560/620022]    Loss: 0.008343   Batch Acc: 71.88
[Train] Epoch: 2 [194624/620022]    Loss: 0.007835   Batch Acc: 81.25
[Train] Epoch: 2 [194688/620022]    Loss: 0.005732   Batch Acc: 84.38
[Train] Epoch: 2 [194752/620022]    Loss: 0.009168   Batch Acc: 71.88
[Train] Epoch: 2 [194816/620022]    Loss: 0.009832   Batch Acc: 76.56
[Train] Epoch: 2 [194880/620022]    Loss: 0.007496   Batch Acc: 79.69
[Train] Epoch: 2 [194944/620022]    Loss: 0.010622   Batch Acc: 73.44
[Train] Epoch: 2 [195008/620022]    Loss: 0.007940   Batch Acc: 79.69
[Train] Epoch: 2 [195072/620022]    Loss: 0.011331   Batch Acc: 65.62
[Train] Epoch: 2 [195136/620022]    Loss: 0.008213   Batch Acc: 81.25
[Train] Epoch: 2 [195200/620022]    Loss: 0.008594   Batch Acc: 79.69
[Train] Epoch: 2 [195264/620022]    Loss: 0.007456   Batch Acc: 85.94
[Train] Epoch: 2 [195328/620022]    Loss: 0.008696   Batch Acc: 73.44
[Train] Epoch: 2 [195392/620022]    Loss: 0.008550   Batch Acc: 79.69
[Train] Epoch: 2 [195456/620022]    Loss: 0.010298   Batch Acc: 70.31
[Train] Epoch: 2 [195520/620022]    Loss: 0.009272   Batch Acc: 70.31
[Train] Epoch: 2 [195584/620022]    Loss: 0.009521   Batch Acc: 75.00
[Train] Epoch: 2 [195648/620022]    Loss: 0.008926   Batch Acc: 75.00
[Train] Epoch: 2 [195712/620022]    Loss: 0.007423   Batch Acc: 78.12
[Train] Epoch: 2 [195776/620022]    Loss: 0.010735   Batch Acc: 68.75
[Train] Epoch: 2 [195840/620022]    Loss: 0.010293   Batch Acc: 70.31
[Train] Epoch: 2 [195904/620022]    Loss: 0.010819   Batch Acc: 68.75
[Train] Epoch: 2 [195968/620022]    Loss: 0.009429   Batch Acc: 75.00
[Train] Epoch: 2 [196032/620022]    Loss: 0.010130   Batch Acc: 75.00
[Train] Epoch: 2 [196096/620022]    Loss: 0.009376   Batch Acc: 78.12
[Train] Epoch: 2 [196160/620022]    Loss: 0.007486   Batch Acc: 81.25
[Train] Epoch: 2 [196224/620022]    Loss: 0.007627   Batch Acc: 81.25
[Train] Epoch: 2 [196288/620022]    Loss: 0.010164   Batch Acc: 68.75
[Train] Epoch: 2 [196352/620022]    Loss: 0.007879   Batch Acc: 84.38
[Train] Epoch: 2 [196416/620022]    Loss: 0.010816   Batch Acc: 73.44
[Train] Epoch: 2 [196480/620022]    Loss: 0.009467   Batch Acc: 78.12
[Train] Epoch: 2 [196544/620022]    Loss: 0.009164   Batch Acc: 78.12
[Train] Epoch: 2 [196608/620022]    Loss: 0.006911   Batch Acc: 85.94
[Train] Epoch: 2 [196672/620022]    Loss: 0.007349   Batch Acc: 84.38
[Train] Epoch: 2 [196736/620022]    Loss: 0.008460   Batch Acc: 84.38
[Train] Epoch: 2 [196800/620022]    Loss: 0.007092   Batch Acc: 84.38
[Train] Epoch: 2 [196864/620022]    Loss: 0.008617   Batch Acc: 81.25
[Train] Epoch: 2 [196928/620022]    Loss: 0.007942   Batch Acc: 79.69
[Train] Epoch: 2 [196992/620022]    Loss: 0.008962   Batch Acc: 79.69
[Train] Epoch: 2 [197056/620022]    Loss: 0.008759   Batch Acc: 84.38
[Train] Epoch: 2 [197120/620022]    Loss: 0.009822   Batch Acc: 70.31
[Train] Epoch: 2 [197184/620022]    Loss: 0.008674   Batch Acc: 81.25
[Train] Epoch: 2 [197248/620022]    Loss: 0.006890   Batch Acc: 84.38
[Train] Epoch: 2 [197312/620022]    Loss: 0.008301   Batch Acc: 73.44
[Train] Epoch: 2 [197376/620022]    Loss: 0.008321   Batch Acc: 76.56
[Train] Epoch: 2 [197440/620022]    Loss: 0.008523   Batch Acc: 76.56
[Train] Epoch: 2 [197504/620022]    Loss: 0.009049   Batch Acc: 79.69
[Train] Epoch: 2 [197568/620022]    Loss: 0.009315   Batch Acc: 78.12
[Train] Epoch: 2 [197632/620022]    Loss: 0.009643   Batch Acc: 73.44
[Train] Epoch: 2 [197696/620022]    Loss: 0.007652   Batch Acc: 84.38
[Train] Epoch: 2 [197760/620022]    Loss: 0.008327   Batch Acc: 79.69
[Train] Epoch: 2 [197824/620022]    Loss: 0.009541   Batch Acc: 78.12
[Train] Epoch: 2 [197888/620022]    Loss: 0.010214   Batch Acc: 68.75
[Train] Epoch: 2 [197952/620022]    Loss: 0.009187   Batch Acc: 79.69
[Train] Epoch: 2 [198016/620022]    Loss: 0.008831   Batch Acc: 75.00
[Train] Epoch: 2 [198080/620022]    Loss: 0.007440   Batch Acc: 84.38
[Train] Epoch: 2 [198144/620022]    Loss: 0.007967   Batch Acc: 84.38
[Train] Epoch: 2 [198208/620022]    Loss: 0.007951   Batch Acc: 81.25
[Train] Epoch: 2 [198272/620022]    Loss: 0.005969   Batch Acc: 87.50
[Train] Epoch: 2 [198336/620022]    Loss: 0.007804   Batch Acc: 82.81
[Train] Epoch: 2 [198400/620022]    Loss: 0.009377   Batch Acc: 73.44
[Train] Epoch: 2 [198464/620022]    Loss: 0.009306   Batch Acc: 71.88
[Train] Epoch: 2 [198528/620022]    Loss: 0.006719   Batch Acc: 81.25
[Train] Epoch: 2 [198592/620022]    Loss: 0.007899   Batch Acc: 82.81
[Train] Epoch: 2 [198656/620022]    Loss: 0.009230   Batch Acc: 73.44
[Train] Epoch: 2 [198720/620022]    Loss: 0.008734   Batch Acc: 78.12
[Train] Epoch: 2 [198784/620022]    Loss: 0.009520   Batch Acc: 75.00
[Train] Epoch: 2 [198848/620022]    Loss: 0.008914   Batch Acc: 75.00
[Train] Epoch: 2 [198912/620022]    Loss: 0.006851   Batch Acc: 85.94
[Train] Epoch: 2 [198976/620022]    Loss: 0.009356   Batch Acc: 71.88
[Train] Epoch: 2 [199040/620022]    Loss: 0.009237   Batch Acc: 76.56
[Train] Epoch: 2 [199104/620022]    Loss: 0.009259   Batch Acc: 76.56
[Train] Epoch: 2 [199168/620022]    Loss: 0.008685   Batch Acc: 76.56
[Train] Epoch: 2 [199232/620022]    Loss: 0.008378   Batch Acc: 81.25
[Train] Epoch: 2 [199296/620022]    Loss: 0.008289   Batch Acc: 76.56
[Train] Epoch: 2 [199360/620022]    Loss: 0.008229   Batch Acc: 79.69
[Train] Epoch: 2 [199424/620022]    Loss: 0.006855   Batch Acc: 79.69
[Train] Epoch: 2 [199488/620022]    Loss: 0.012489   Batch Acc: 68.75
[Train] Epoch: 2 [199552/620022]    Loss: 0.006770   Batch Acc: 85.94
[Train] Epoch: 2 [199616/620022]    Loss: 0.007294   Batch Acc: 82.81
[Train] Epoch: 2 [199680/620022]    Loss: 0.007750   Batch Acc: 82.81
[Train] Epoch: 2 [199744/620022]    Loss: 0.007005   Batch Acc: 81.25
[Train] Epoch: 2 [199808/620022]    Loss: 0.007507   Batch Acc: 78.12
[Train] Epoch: 2 [199872/620022]    Loss: 0.007050   Batch Acc: 81.25
[Train] Epoch: 2 [199936/620022]    Loss: 0.008669   Batch Acc: 79.69
[Train] Epoch: 2 [200000/620022]    Loss: 0.008862   Batch Acc: 75.00
[Train] Epoch: 2 [200064/620022]    Loss: 0.008311   Batch Acc: 79.69
[Train] Epoch: 2 [200128/620022]    Loss: 0.009428   Batch Acc: 82.81
[Train] Epoch: 2 [200192/620022]    Loss: 0.010748   Batch Acc: 67.19
[Train] Epoch: 2 [200256/620022]    Loss: 0.009127   Batch Acc: 79.69
[Train] Epoch: 2 [200320/620022]    Loss: 0.007835   Batch Acc: 81.25
[Train] Epoch: 2 [200384/620022]    Loss: 0.009004   Batch Acc: 81.25
[Train] Epoch: 2 [200448/620022]    Loss: 0.009006   Batch Acc: 71.88
[Train] Epoch: 2 [200512/620022]    Loss: 0.014353   Batch Acc: 60.94
[Train] Epoch: 2 [200576/620022]    Loss: 0.006203   Batch Acc: 87.50
[Train] Epoch: 2 [200640/620022]    Loss: 0.007885   Batch Acc: 82.81
[Train] Epoch: 2 [200704/620022]    Loss: 0.007672   Batch Acc: 75.00
[Train] Epoch: 2 [200768/620022]    Loss: 0.005826   Batch Acc: 87.50
[Train] Epoch: 2 [200832/620022]    Loss: 0.008240   Batch Acc: 76.56
[Train] Epoch: 2 [200896/620022]    Loss: 0.010621   Batch Acc: 73.44
[Train] Epoch: 2 [200960/620022]    Loss: 0.012864   Batch Acc: 59.38
[Train] Epoch: 2 [201024/620022]    Loss: 0.008955   Batch Acc: 79.69
[Train] Epoch: 2 [201088/620022]    Loss: 0.007926   Batch Acc: 82.81
[Train] Epoch: 2 [201152/620022]    Loss: 0.008215   Batch Acc: 75.00
[Train] Epoch: 2 [201216/620022]    Loss: 0.012134   Batch Acc: 68.75
[Train] Epoch: 2 [201280/620022]    Loss: 0.010535   Batch Acc: 75.00
[Train] Epoch: 2 [201344/620022]    Loss: 0.008764   Batch Acc: 78.12
[Train] Epoch: 2 [201408/620022]    Loss: 0.011627   Batch Acc: 67.19
[Train] Epoch: 2 [201472/620022]    Loss: 0.006579   Batch Acc: 89.06
[Train] Epoch: 2 [201536/620022]    Loss: 0.006120   Batch Acc: 84.38
[Train] Epoch: 2 [201600/620022]    Loss: 0.007449   Batch Acc: 76.56
[Train] Epoch: 2 [201664/620022]    Loss: 0.009114   Batch Acc: 76.56
[Train] Epoch: 2 [201728/620022]    Loss: 0.008116   Batch Acc: 76.56
[Train] Epoch: 2 [201792/620022]    Loss: 0.014082   Batch Acc: 67.19
[Train] Epoch: 2 [201856/620022]    Loss: 0.008598   Batch Acc: 78.12
[Train] Epoch: 2 [201920/620022]    Loss: 0.006822   Batch Acc: 81.25
[Train] Epoch: 2 [201984/620022]    Loss: 0.005949   Batch Acc: 87.50
[Train] Epoch: 2 [202048/620022]    Loss: 0.009290   Batch Acc: 78.12
[Train] Epoch: 2 [202112/620022]    Loss: 0.008294   Batch Acc: 79.69
[Train] Epoch: 2 [202176/620022]    Loss: 0.009483   Batch Acc: 75.00
[Train] Epoch: 2 [202240/620022]    Loss: 0.007931   Batch Acc: 87.50
[Train] Epoch: 2 [202304/620022]    Loss: 0.008063   Batch Acc: 84.38
[Train] Epoch: 2 [202368/620022]    Loss: 0.008408   Batch Acc: 75.00
[Train] Epoch: 2 [202432/620022]    Loss: 0.009521   Batch Acc: 76.56
[Train] Epoch: 2 [202496/620022]    Loss: 0.006896   Batch Acc: 84.38
[Train] Epoch: 2 [202560/620022]    Loss: 0.009516   Batch Acc: 78.12
[Train] Epoch: 2 [202624/620022]    Loss: 0.008366   Batch Acc: 75.00
[Train] Epoch: 2 [202688/620022]    Loss: 0.010589   Batch Acc: 75.00
[Train] Epoch: 2 [202752/620022]    Loss: 0.008688   Batch Acc: 78.12
[Train] Epoch: 2 [202816/620022]    Loss: 0.009272   Batch Acc: 75.00
[Train] Epoch: 2 [202880/620022]    Loss: 0.008472   Batch Acc: 75.00
[Train] Epoch: 2 [202944/620022]    Loss: 0.008128   Batch Acc: 79.69
[Train] Epoch: 2 [203008/620022]    Loss: 0.009316   Batch Acc: 73.44
[Train] Epoch: 2 [203072/620022]    Loss: 0.007737   Batch Acc: 73.44
[Train] Epoch: 2 [203136/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 2 [203200/620022]    Loss: 0.007401   Batch Acc: 81.25
[Train] Epoch: 2 [203264/620022]    Loss: 0.008042   Batch Acc: 78.12
[Train] Epoch: 2 [203328/620022]    Loss: 0.010040   Batch Acc: 73.44
[Train] Epoch: 2 [203392/620022]    Loss: 0.009845   Batch Acc: 73.44
[Train] Epoch: 2 [203456/620022]    Loss: 0.007968   Batch Acc: 79.69
[Train] Epoch: 2 [203520/620022]    Loss: 0.009469   Batch Acc: 75.00
[Train] Epoch: 2 [203584/620022]    Loss: 0.008125   Batch Acc: 81.25
[Train] Epoch: 2 [203648/620022]    Loss: 0.010478   Batch Acc: 76.56
[Train] Epoch: 2 [203712/620022]    Loss: 0.008300   Batch Acc: 75.00
[Train] Epoch: 2 [203776/620022]    Loss: 0.009267   Batch Acc: 81.25
[Train] Epoch: 2 [203840/620022]    Loss: 0.007021   Batch Acc: 79.69
[Train] Epoch: 2 [203904/620022]    Loss: 0.008039   Batch Acc: 82.81
[Train] Epoch: 2 [203968/620022]    Loss: 0.008269   Batch Acc: 79.69
[Train] Epoch: 2 [204032/620022]    Loss: 0.009515   Batch Acc: 75.00
[Train] Epoch: 2 [204096/620022]    Loss: 0.008406   Batch Acc: 75.00
[Train] Epoch: 2 [204160/620022]    Loss: 0.011862   Batch Acc: 70.31
[Train] Epoch: 2 [204224/620022]    Loss: 0.006480   Batch Acc: 84.38
[Train] Epoch: 2 [204288/620022]    Loss: 0.007760   Batch Acc: 78.12
[Train] Epoch: 2 [204352/620022]    Loss: 0.008657   Batch Acc: 76.56
[Train] Epoch: 2 [204416/620022]    Loss: 0.008221   Batch Acc: 79.69
[Train] Epoch: 2 [204480/620022]    Loss: 0.008739   Batch Acc: 75.00
[Train] Epoch: 2 [204544/620022]    Loss: 0.008560   Batch Acc: 79.69
[Train] Epoch: 2 [204608/620022]    Loss: 0.010785   Batch Acc: 70.31
[Train] Epoch: 2 [204672/620022]    Loss: 0.009464   Batch Acc: 75.00
[Train] Epoch: 2 [204736/620022]    Loss: 0.010063   Batch Acc: 65.62
[Train] Epoch: 2 [204800/620022]    Loss: 0.008453   Batch Acc: 79.69
[Train] Epoch: 2 [204864/620022]    Loss: 0.006688   Batch Acc: 89.06
[Train] Epoch: 2 [204928/620022]    Loss: 0.010758   Batch Acc: 68.75
[Train] Epoch: 2 [204992/620022]    Loss: 0.008072   Batch Acc: 78.12
[Train] Epoch: 2 [205056/620022]    Loss: 0.007531   Batch Acc: 85.94
[Train] Epoch: 2 [205120/620022]    Loss: 0.007065   Batch Acc: 85.94
[Train] Epoch: 2 [205184/620022]    Loss: 0.008905   Batch Acc: 79.69
[Train] Epoch: 2 [205248/620022]    Loss: 0.008844   Batch Acc: 78.12
[Train] Epoch: 2 [205312/620022]    Loss: 0.011733   Batch Acc: 73.44
[Train] Epoch: 2 [205376/620022]    Loss: 0.007496   Batch Acc: 81.25
[Train] Epoch: 2 [205440/620022]    Loss: 0.007884   Batch Acc: 81.25
[Train] Epoch: 2 [205504/620022]    Loss: 0.007115   Batch Acc: 85.94
[Train] Epoch: 2 [205568/620022]    Loss: 0.009264   Batch Acc: 78.12
[Train] Epoch: 2 [205632/620022]    Loss: 0.008910   Batch Acc: 75.00
[Train] Epoch: 2 [205696/620022]    Loss: 0.008472   Batch Acc: 82.81
[Train] Epoch: 2 [205760/620022]    Loss: 0.008975   Batch Acc: 79.69
[Train] Epoch: 2 [205824/620022]    Loss: 0.007026   Batch Acc: 85.94
[Train] Epoch: 2 [205888/620022]    Loss: 0.009781   Batch Acc: 76.56
[Train] Epoch: 2 [205952/620022]    Loss: 0.007894   Batch Acc: 81.25
[Train] Epoch: 2 [206016/620022]    Loss: 0.012473   Batch Acc: 57.81
[Train] Epoch: 2 [206080/620022]    Loss: 0.009466   Batch Acc: 73.44
[Train] Epoch: 2 [206144/620022]    Loss: 0.008912   Batch Acc: 75.00
[Train] Epoch: 2 [206208/620022]    Loss: 0.006776   Batch Acc: 84.38
[Train] Epoch: 2 [206272/620022]    Loss: 0.007432   Batch Acc: 82.81
[Train] Epoch: 2 [206336/620022]    Loss: 0.009888   Batch Acc: 71.88
[Train] Epoch: 2 [206400/620022]    Loss: 0.009616   Batch Acc: 73.44
[Train] Epoch: 2 [206464/620022]    Loss: 0.008626   Batch Acc: 73.44
[Train] Epoch: 2 [206528/620022]    Loss: 0.008091   Batch Acc: 76.56
[Train] Epoch: 2 [206592/620022]    Loss: 0.007197   Batch Acc: 81.25
[Train] Epoch: 2 [206656/620022]    Loss: 0.011243   Batch Acc: 70.31
[Train] Epoch: 2 [206720/620022]    Loss: 0.009957   Batch Acc: 75.00
[Train] Epoch: 2 [206784/620022]    Loss: 0.007284   Batch Acc: 78.12
[Train] Epoch: 2 [206848/620022]    Loss: 0.007176   Batch Acc: 85.94
[Train] Epoch: 2 [206912/620022]    Loss: 0.008297   Batch Acc: 76.56
[Train] Epoch: 2 [206976/620022]    Loss: 0.007200   Batch Acc: 85.94
[Train] Epoch: 2 [207040/620022]    Loss: 0.009042   Batch Acc: 78.12
[Train] Epoch: 2 [207104/620022]    Loss: 0.008659   Batch Acc: 81.25
[Train] Epoch: 2 [207168/620022]    Loss: 0.009542   Batch Acc: 75.00
[Train] Epoch: 2 [207232/620022]    Loss: 0.007072   Batch Acc: 81.25
[Train] Epoch: 2 [207296/620022]    Loss: 0.009061   Batch Acc: 78.12
[Train] Epoch: 2 [207360/620022]    Loss: 0.008297   Batch Acc: 84.38
[Train] Epoch: 2 [207424/620022]    Loss: 0.008678   Batch Acc: 76.56
[Train] Epoch: 2 [207488/620022]    Loss: 0.006390   Batch Acc: 85.94
[Train] Epoch: 2 [207552/620022]    Loss: 0.007123   Batch Acc: 79.69
[Train] Epoch: 2 [207616/620022]    Loss: 0.008311   Batch Acc: 78.12
[Train] Epoch: 2 [207680/620022]    Loss: 0.009586   Batch Acc: 79.69
[Train] Epoch: 2 [207744/620022]    Loss: 0.009132   Batch Acc: 76.56
[Train] Epoch: 2 [207808/620022]    Loss: 0.007591   Batch Acc: 82.81
[Train] Epoch: 2 [207872/620022]    Loss: 0.009250   Batch Acc: 75.00
[Train] Epoch: 2 [207936/620022]    Loss: 0.008869   Batch Acc: 73.44
[Train] Epoch: 2 [208000/620022]    Loss: 0.008125   Batch Acc: 76.56
[Train] Epoch: 2 [208064/620022]    Loss: 0.008676   Batch Acc: 81.25
[Train] Epoch: 2 [208128/620022]    Loss: 0.007235   Batch Acc: 81.25
[Train] Epoch: 2 [208192/620022]    Loss: 0.010575   Batch Acc: 75.00
[Train] Epoch: 2 [208256/620022]    Loss: 0.008345   Batch Acc: 79.69
[Train] Epoch: 2 [208320/620022]    Loss: 0.008366   Batch Acc: 78.12
[Train] Epoch: 2 [208384/620022]    Loss: 0.008072   Batch Acc: 76.56
[Train] Epoch: 2 [208448/620022]    Loss: 0.009442   Batch Acc: 71.88
[Train] Epoch: 2 [208512/620022]    Loss: 0.010141   Batch Acc: 73.44
[Train] Epoch: 2 [208576/620022]    Loss: 0.009681   Batch Acc: 78.12
[Train] Epoch: 2 [208640/620022]    Loss: 0.008548   Batch Acc: 79.69
[Train] Epoch: 2 [208704/620022]    Loss: 0.006839   Batch Acc: 84.38
[Train] Epoch: 2 [208768/620022]    Loss: 0.007286   Batch Acc: 85.94
[Train] Epoch: 2 [208832/620022]    Loss: 0.007904   Batch Acc: 82.81
[Train] Epoch: 2 [208896/620022]    Loss: 0.007755   Batch Acc: 81.25
[Train] Epoch: 2 [208960/620022]    Loss: 0.008139   Batch Acc: 82.81
[Train] Epoch: 2 [209024/620022]    Loss: 0.009089   Batch Acc: 75.00
[Train] Epoch: 2 [209088/620022]    Loss: 0.008087   Batch Acc: 82.81
[Train] Epoch: 2 [209152/620022]    Loss: 0.008749   Batch Acc: 75.00
[Train] Epoch: 2 [209216/620022]    Loss: 0.008194   Batch Acc: 76.56
[Train] Epoch: 2 [209280/620022]    Loss: 0.009601   Batch Acc: 75.00
[Train] Epoch: 2 [209344/620022]    Loss: 0.009048   Batch Acc: 78.12
[Train] Epoch: 2 [209408/620022]    Loss: 0.010038   Batch Acc: 71.88
[Train] Epoch: 2 [209472/620022]    Loss: 0.008564   Batch Acc: 78.12
[Train] Epoch: 2 [209536/620022]    Loss: 0.006858   Batch Acc: 84.38
[Train] Epoch: 2 [209600/620022]    Loss: 0.006853   Batch Acc: 84.38
[Train] Epoch: 2 [209664/620022]    Loss: 0.007287   Batch Acc: 85.94
[Train] Epoch: 2 [209728/620022]    Loss: 0.009223   Batch Acc: 78.12
[Train] Epoch: 2 [209792/620022]    Loss: 0.009491   Batch Acc: 70.31
[Train] Epoch: 2 [209856/620022]    Loss: 0.008598   Batch Acc: 73.44
[Train] Epoch: 2 [209920/620022]    Loss: 0.008063   Batch Acc: 79.69
[Train] Epoch: 2 [209984/620022]    Loss: 0.008844   Batch Acc: 79.69
[Train] Epoch: 2 [210048/620022]    Loss: 0.009363   Batch Acc: 76.56
[Train] Epoch: 2 [210112/620022]    Loss: 0.009257   Batch Acc: 78.12
[Train] Epoch: 2 [210176/620022]    Loss: 0.010248   Batch Acc: 76.56
[Train] Epoch: 2 [210240/620022]    Loss: 0.008820   Batch Acc: 73.44
[Train] Epoch: 2 [210304/620022]    Loss: 0.008944   Batch Acc: 79.69
[Train] Epoch: 2 [210368/620022]    Loss: 0.009780   Batch Acc: 78.12
[Train] Epoch: 2 [210432/620022]    Loss: 0.009303   Batch Acc: 71.88
[Train] Epoch: 2 [210496/620022]    Loss: 0.007385   Batch Acc: 85.94
[Train] Epoch: 2 [210560/620022]    Loss: 0.007190   Batch Acc: 81.25
[Train] Epoch: 2 [210624/620022]    Loss: 0.008338   Batch Acc: 75.00
[Train] Epoch: 2 [210688/620022]    Loss: 0.008912   Batch Acc: 76.56
[Train] Epoch: 2 [210752/620022]    Loss: 0.009184   Batch Acc: 75.00
[Train] Epoch: 2 [210816/620022]    Loss: 0.009985   Batch Acc: 71.88
[Train] Epoch: 2 [210880/620022]    Loss: 0.007333   Batch Acc: 84.38
[Train] Epoch: 2 [210944/620022]    Loss: 0.009598   Batch Acc: 70.31
[Train] Epoch: 2 [211008/620022]    Loss: 0.009589   Batch Acc: 73.44
[Train] Epoch: 2 [211072/620022]    Loss: 0.009736   Batch Acc: 71.88
[Train] Epoch: 2 [211136/620022]    Loss: 0.008079   Batch Acc: 75.00
[Train] Epoch: 2 [211200/620022]    Loss: 0.007575   Batch Acc: 78.12
[Train] Epoch: 2 [211264/620022]    Loss: 0.008422   Batch Acc: 78.12
[Train] Epoch: 2 [211328/620022]    Loss: 0.009051   Batch Acc: 75.00
[Train] Epoch: 2 [211392/620022]    Loss: 0.007823   Batch Acc: 71.88
[Train] Epoch: 2 [211456/620022]    Loss: 0.009170   Batch Acc: 76.56
[Train] Epoch: 2 [211520/620022]    Loss: 0.008720   Batch Acc: 75.00
[Train] Epoch: 2 [211584/620022]    Loss: 0.009933   Batch Acc: 70.31
[Train] Epoch: 2 [211648/620022]    Loss: 0.008502   Batch Acc: 78.12
[Train] Epoch: 2 [211712/620022]    Loss: 0.008856   Batch Acc: 68.75
[Train] Epoch: 2 [211776/620022]    Loss: 0.010491   Batch Acc: 71.88
[Train] Epoch: 2 [211840/620022]    Loss: 0.009620   Batch Acc: 68.75
[Train] Epoch: 2 [211904/620022]    Loss: 0.007424   Batch Acc: 78.12
[Train] Epoch: 2 [211968/620022]    Loss: 0.012109   Batch Acc: 70.31
[Train] Epoch: 2 [212032/620022]    Loss: 0.006186   Batch Acc: 84.38
[Train] Epoch: 2 [212096/620022]    Loss: 0.006139   Batch Acc: 85.94
[Train] Epoch: 2 [212160/620022]    Loss: 0.012034   Batch Acc: 73.44
[Train] Epoch: 2 [212224/620022]    Loss: 0.008725   Batch Acc: 79.69
[Train] Epoch: 2 [212288/620022]    Loss: 0.008916   Batch Acc: 81.25
[Train] Epoch: 2 [212352/620022]    Loss: 0.007817   Batch Acc: 78.12
[Train] Epoch: 2 [212416/620022]    Loss: 0.008620   Batch Acc: 75.00
[Train] Epoch: 2 [212480/620022]    Loss: 0.006606   Batch Acc: 87.50
[Train] Epoch: 2 [212544/620022]    Loss: 0.011124   Batch Acc: 71.88
[Train] Epoch: 2 [212608/620022]    Loss: 0.008393   Batch Acc: 79.69
[Train] Epoch: 2 [212672/620022]    Loss: 0.008740   Batch Acc: 82.81
[Train] Epoch: 2 [212736/620022]    Loss: 0.008230   Batch Acc: 81.25
[Train] Epoch: 2 [212800/620022]    Loss: 0.008522   Batch Acc: 79.69
[Train] Epoch: 2 [212864/620022]    Loss: 0.009933   Batch Acc: 78.12
[Train] Epoch: 2 [212928/620022]    Loss: 0.009041   Batch Acc: 81.25
[Train] Epoch: 2 [212992/620022]    Loss: 0.008039   Batch Acc: 79.69
[Train] Epoch: 2 [213056/620022]    Loss: 0.008218   Batch Acc: 79.69
[Train] Epoch: 2 [213120/620022]    Loss: 0.007656   Batch Acc: 81.25
[Train] Epoch: 2 [213184/620022]    Loss: 0.006761   Batch Acc: 85.94
[Train] Epoch: 2 [213248/620022]    Loss: 0.007184   Batch Acc: 84.38
[Train] Epoch: 2 [213312/620022]    Loss: 0.008384   Batch Acc: 78.12
[Train] Epoch: 2 [213376/620022]    Loss: 0.011062   Batch Acc: 68.75
[Train] Epoch: 2 [213440/620022]    Loss: 0.008457   Batch Acc: 82.81
[Train] Epoch: 2 [213504/620022]    Loss: 0.008095   Batch Acc: 75.00
[Train] Epoch: 2 [213568/620022]    Loss: 0.007515   Batch Acc: 81.25
[Train] Epoch: 2 [213632/620022]    Loss: 0.011024   Batch Acc: 65.62
[Train] Epoch: 2 [213696/620022]    Loss: 0.008496   Batch Acc: 76.56
[Train] Epoch: 2 [213760/620022]    Loss: 0.008998   Batch Acc: 78.12
[Train] Epoch: 2 [213824/620022]    Loss: 0.010695   Batch Acc: 70.31
[Train] Epoch: 2 [213888/620022]    Loss: 0.008601   Batch Acc: 79.69
[Train] Epoch: 2 [213952/620022]    Loss: 0.009884   Batch Acc: 73.44
[Train] Epoch: 2 [214016/620022]    Loss: 0.007920   Batch Acc: 78.12
[Train] Epoch: 2 [214080/620022]    Loss: 0.007915   Batch Acc: 81.25
[Train] Epoch: 2 [214144/620022]    Loss: 0.007373   Batch Acc: 81.25
[Train] Epoch: 2 [214208/620022]    Loss: 0.006073   Batch Acc: 89.06
[Train] Epoch: 2 [214272/620022]    Loss: 0.007687   Batch Acc: 78.12
[Train] Epoch: 2 [214336/620022]    Loss: 0.008681   Batch Acc: 81.25
[Train] Epoch: 2 [214400/620022]    Loss: 0.009723   Batch Acc: 73.44
[Train] Epoch: 2 [214464/620022]    Loss: 0.007832   Batch Acc: 81.25
[Train] Epoch: 2 [214528/620022]    Loss: 0.009677   Batch Acc: 78.12
[Train] Epoch: 2 [214592/620022]    Loss: 0.008706   Batch Acc: 82.81
[Train] Epoch: 2 [214656/620022]    Loss: 0.008244   Batch Acc: 81.25
[Train] Epoch: 2 [214720/620022]    Loss: 0.008680   Batch Acc: 79.69
[Train] Epoch: 2 [214784/620022]    Loss: 0.008424   Batch Acc: 82.81
[Train] Epoch: 2 [214848/620022]    Loss: 0.005927   Batch Acc: 85.94
[Train] Epoch: 2 [214912/620022]    Loss: 0.009227   Batch Acc: 79.69
[Train] Epoch: 2 [214976/620022]    Loss: 0.008199   Batch Acc: 79.69
[Train] Epoch: 2 [215040/620022]    Loss: 0.009012   Batch Acc: 76.56
[Train] Epoch: 2 [215104/620022]    Loss: 0.008076   Batch Acc: 79.69
[Train] Epoch: 2 [215168/620022]    Loss: 0.008209   Batch Acc: 81.25
[Train] Epoch: 2 [215232/620022]    Loss: 0.008617   Batch Acc: 76.56
[Train] Epoch: 2 [215296/620022]    Loss: 0.007293   Batch Acc: 82.81
[Train] Epoch: 2 [215360/620022]    Loss: 0.007560   Batch Acc: 81.25
[Train] Epoch: 2 [215424/620022]    Loss: 0.008301   Batch Acc: 78.12
[Train] Epoch: 2 [215488/620022]    Loss: 0.007177   Batch Acc: 81.25
[Train] Epoch: 2 [215552/620022]    Loss: 0.008285   Batch Acc: 75.00
[Train] Epoch: 2 [215616/620022]    Loss: 0.007990   Batch Acc: 78.12
[Train] Epoch: 2 [215680/620022]    Loss: 0.010340   Batch Acc: 73.44
[Train] Epoch: 2 [215744/620022]    Loss: 0.007096   Batch Acc: 82.81
[Train] Epoch: 2 [215808/620022]    Loss: 0.009676   Batch Acc: 68.75
[Train] Epoch: 2 [215872/620022]    Loss: 0.008780   Batch Acc: 76.56
[Train] Epoch: 2 [215936/620022]    Loss: 0.009551   Batch Acc: 75.00
[Train] Epoch: 2 [216000/620022]    Loss: 0.006454   Batch Acc: 82.81
[Train] Epoch: 2 [216064/620022]    Loss: 0.005928   Batch Acc: 87.50
[Train] Epoch: 2 [216128/620022]    Loss: 0.008606   Batch Acc: 79.69
[Train] Epoch: 2 [216192/620022]    Loss: 0.006609   Batch Acc: 82.81
[Train] Epoch: 2 [216256/620022]    Loss: 0.009684   Batch Acc: 71.88
[Train] Epoch: 2 [216320/620022]    Loss: 0.006545   Batch Acc: 84.38
[Train] Epoch: 2 [216384/620022]    Loss: 0.010015   Batch Acc: 71.88
[Train] Epoch: 2 [216448/620022]    Loss: 0.010143   Batch Acc: 76.56
[Train] Epoch: 2 [216512/620022]    Loss: 0.007106   Batch Acc: 81.25
[Train] Epoch: 2 [216576/620022]    Loss: 0.007170   Batch Acc: 85.94
[Train] Epoch: 2 [216640/620022]    Loss: 0.010556   Batch Acc: 75.00
[Train] Epoch: 2 [216704/620022]    Loss: 0.008259   Batch Acc: 82.81
[Train] Epoch: 2 [216768/620022]    Loss: 0.007812   Batch Acc: 84.38
[Train] Epoch: 2 [216832/620022]    Loss: 0.005675   Batch Acc: 85.94
[Train] Epoch: 2 [216896/620022]    Loss: 0.009501   Batch Acc: 73.44
[Train] Epoch: 2 [216960/620022]    Loss: 0.009467   Batch Acc: 71.88
[Train] Epoch: 2 [217024/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 2 [217088/620022]    Loss: 0.008637   Batch Acc: 75.00
[Train] Epoch: 2 [217152/620022]    Loss: 0.007242   Batch Acc: 82.81
[Train] Epoch: 2 [217216/620022]    Loss: 0.008346   Batch Acc: 81.25
[Train] Epoch: 2 [217280/620022]    Loss: 0.006481   Batch Acc: 85.94
[Train] Epoch: 2 [217344/620022]    Loss: 0.010179   Batch Acc: 76.56
[Train] Epoch: 2 [217408/620022]    Loss: 0.007667   Batch Acc: 84.38
[Train] Epoch: 2 [217472/620022]    Loss: 0.007909   Batch Acc: 78.12
[Train] Epoch: 2 [217536/620022]    Loss: 0.006439   Batch Acc: 85.94
[Train] Epoch: 2 [217600/620022]    Loss: 0.010989   Batch Acc: 73.44
[Train] Epoch: 2 [217664/620022]    Loss: 0.011909   Batch Acc: 65.62
[Train] Epoch: 2 [217728/620022]    Loss: 0.010162   Batch Acc: 71.88
[Train] Epoch: 2 [217792/620022]    Loss: 0.009768   Batch Acc: 71.88
[Train] Epoch: 2 [217856/620022]    Loss: 0.010988   Batch Acc: 75.00
[Train] Epoch: 2 [217920/620022]    Loss: 0.010547   Batch Acc: 71.88
[Train] Epoch: 2 [217984/620022]    Loss: 0.008881   Batch Acc: 78.12
[Train] Epoch: 2 [218048/620022]    Loss: 0.007836   Batch Acc: 76.56
[Train] Epoch: 2 [218112/620022]    Loss: 0.007726   Batch Acc: 82.81
[Train] Epoch: 2 [218176/620022]    Loss: 0.007729   Batch Acc: 79.69
[Train] Epoch: 2 [218240/620022]    Loss: 0.008969   Batch Acc: 76.56
[Train] Epoch: 2 [218304/620022]    Loss: 0.007871   Batch Acc: 79.69
[Train] Epoch: 2 [218368/620022]    Loss: 0.009757   Batch Acc: 75.00
[Train] Epoch: 2 [218432/620022]    Loss: 0.009426   Batch Acc: 79.69
[Train] Epoch: 2 [218496/620022]    Loss: 0.007711   Batch Acc: 81.25
[Train] Epoch: 2 [218560/620022]    Loss: 0.007127   Batch Acc: 81.25
[Train] Epoch: 2 [218624/620022]    Loss: 0.007452   Batch Acc: 78.12
[Train] Epoch: 2 [218688/620022]    Loss: 0.009230   Batch Acc: 78.12
[Train] Epoch: 2 [218752/620022]    Loss: 0.007361   Batch Acc: 82.81
[Train] Epoch: 2 [218816/620022]    Loss: 0.009441   Batch Acc: 75.00
[Train] Epoch: 2 [218880/620022]    Loss: 0.011182   Batch Acc: 71.88
[Train] Epoch: 2 [218944/620022]    Loss: 0.007893   Batch Acc: 82.81
[Train] Epoch: 2 [219008/620022]    Loss: 0.007865   Batch Acc: 82.81
[Train] Epoch: 2 [219072/620022]    Loss: 0.010189   Batch Acc: 70.31
[Train] Epoch: 2 [219136/620022]    Loss: 0.007656   Batch Acc: 79.69
[Train] Epoch: 2 [219200/620022]    Loss: 0.007734   Batch Acc: 79.69
[Train] Epoch: 2 [219264/620022]    Loss: 0.008995   Batch Acc: 67.19
[Train] Epoch: 2 [219328/620022]    Loss: 0.008033   Batch Acc: 82.81
[Train] Epoch: 2 [219392/620022]    Loss: 0.007828   Batch Acc: 82.81
[Train] Epoch: 2 [219456/620022]    Loss: 0.009332   Batch Acc: 76.56
[Train] Epoch: 2 [219520/620022]    Loss: 0.008713   Batch Acc: 76.56
[Train] Epoch: 2 [219584/620022]    Loss: 0.010062   Batch Acc: 76.56
[Train] Epoch: 2 [219648/620022]    Loss: 0.008451   Batch Acc: 78.12
[Train] Epoch: 2 [219712/620022]    Loss: 0.007155   Batch Acc: 78.12
[Train] Epoch: 2 [219776/620022]    Loss: 0.006633   Batch Acc: 85.94
[Train] Epoch: 2 [219840/620022]    Loss: 0.009955   Batch Acc: 75.00
[Train] Epoch: 2 [219904/620022]    Loss: 0.007215   Batch Acc: 81.25
[Train] Epoch: 2 [219968/620022]    Loss: 0.009953   Batch Acc: 75.00
[Train] Epoch: 2 [220032/620022]    Loss: 0.009571   Batch Acc: 73.44
[Train] Epoch: 2 [220096/620022]    Loss: 0.008647   Batch Acc: 75.00
[Train] Epoch: 2 [220160/620022]    Loss: 0.008805   Batch Acc: 71.88
[Train] Epoch: 2 [220224/620022]    Loss: 0.008298   Batch Acc: 75.00
[Train] Epoch: 2 [220288/620022]    Loss: 0.006930   Batch Acc: 79.69
[Train] Epoch: 2 [220352/620022]    Loss: 0.007670   Batch Acc: 78.12
[Train] Epoch: 2 [220416/620022]    Loss: 0.009955   Batch Acc: 79.69
[Train] Epoch: 2 [220480/620022]    Loss: 0.009216   Batch Acc: 79.69
[Train] Epoch: 2 [220544/620022]    Loss: 0.008809   Batch Acc: 75.00
[Train] Epoch: 2 [220608/620022]    Loss: 0.007809   Batch Acc: 78.12
[Train] Epoch: 2 [220672/620022]    Loss: 0.008371   Batch Acc: 81.25
[Train] Epoch: 2 [220736/620022]    Loss: 0.011489   Batch Acc: 71.88
[Train] Epoch: 2 [220800/620022]    Loss: 0.009764   Batch Acc: 76.56
[Train] Epoch: 2 [220864/620022]    Loss: 0.008224   Batch Acc: 76.56
[Train] Epoch: 2 [220928/620022]    Loss: 0.009303   Batch Acc: 68.75
[Train] Epoch: 2 [220992/620022]    Loss: 0.009463   Batch Acc: 76.56
[Train] Epoch: 2 [221056/620022]    Loss: 0.007286   Batch Acc: 84.38
[Train] Epoch: 2 [221120/620022]    Loss: 0.010163   Batch Acc: 78.12
[Train] Epoch: 2 [221184/620022]    Loss: 0.010333   Batch Acc: 73.44
[Train] Epoch: 2 [221248/620022]    Loss: 0.008579   Batch Acc: 76.56
[Train] Epoch: 2 [221312/620022]    Loss: 0.011138   Batch Acc: 68.75
[Train] Epoch: 2 [221376/620022]    Loss: 0.010970   Batch Acc: 73.44
[Train] Epoch: 2 [221440/620022]    Loss: 0.008626   Batch Acc: 79.69
[Train] Epoch: 2 [221504/620022]    Loss: 0.009897   Batch Acc: 75.00
[Train] Epoch: 2 [221568/620022]    Loss: 0.006643   Batch Acc: 82.81
[Train] Epoch: 2 [221632/620022]    Loss: 0.009070   Batch Acc: 75.00
[Train] Epoch: 2 [221696/620022]    Loss: 0.010623   Batch Acc: 75.00
[Train] Epoch: 2 [221760/620022]    Loss: 0.008937   Batch Acc: 76.56
[Train] Epoch: 2 [221824/620022]    Loss: 0.008071   Batch Acc: 76.56
[Train] Epoch: 2 [221888/620022]    Loss: 0.008646   Batch Acc: 76.56
[Train] Epoch: 2 [221952/620022]    Loss: 0.007704   Batch Acc: 79.69
[Train] Epoch: 2 [222016/620022]    Loss: 0.006667   Batch Acc: 81.25
[Train] Epoch: 2 [222080/620022]    Loss: 0.006961   Batch Acc: 78.12
[Train] Epoch: 2 [222144/620022]    Loss: 0.008013   Batch Acc: 81.25
[Train] Epoch: 2 [222208/620022]    Loss: 0.009770   Batch Acc: 70.31
[Train] Epoch: 2 [222272/620022]    Loss: 0.006757   Batch Acc: 84.38
[Train] Epoch: 2 [222336/620022]    Loss: 0.007728   Batch Acc: 82.81
[Train] Epoch: 2 [222400/620022]    Loss: 0.010307   Batch Acc: 75.00
[Train] Epoch: 2 [222464/620022]    Loss: 0.008501   Batch Acc: 82.81
[Train] Epoch: 2 [222528/620022]    Loss: 0.008312   Batch Acc: 79.69
[Train] Epoch: 2 [222592/620022]    Loss: 0.008963   Batch Acc: 70.31
[Train] Epoch: 2 [222656/620022]    Loss: 0.009234   Batch Acc: 73.44
[Train] Epoch: 2 [222720/620022]    Loss: 0.010915   Batch Acc: 78.12
[Train] Epoch: 2 [222784/620022]    Loss: 0.007821   Batch Acc: 78.12
[Train] Epoch: 2 [222848/620022]    Loss: 0.009329   Batch Acc: 76.56
[Train] Epoch: 2 [222912/620022]    Loss: 0.007715   Batch Acc: 76.56
[Train] Epoch: 2 [222976/620022]    Loss: 0.009110   Batch Acc: 75.00
[Train] Epoch: 2 [223040/620022]    Loss: 0.007318   Batch Acc: 82.81
[Train] Epoch: 2 [223104/620022]    Loss: 0.010124   Batch Acc: 70.31
[Train] Epoch: 2 [223168/620022]    Loss: 0.012453   Batch Acc: 65.62
[Train] Epoch: 2 [223232/620022]    Loss: 0.008097   Batch Acc: 82.81
[Train] Epoch: 2 [223296/620022]    Loss: 0.009535   Batch Acc: 73.44
[Train] Epoch: 2 [223360/620022]    Loss: 0.008356   Batch Acc: 76.56
[Train] Epoch: 2 [223424/620022]    Loss: 0.007969   Batch Acc: 79.69
[Train] Epoch: 2 [223488/620022]    Loss: 0.011521   Batch Acc: 73.44
[Train] Epoch: 2 [223552/620022]    Loss: 0.007923   Batch Acc: 84.38
[Train] Epoch: 2 [223616/620022]    Loss: 0.011098   Batch Acc: 71.88
[Train] Epoch: 2 [223680/620022]    Loss: 0.009754   Batch Acc: 79.69
[Train] Epoch: 2 [223744/620022]    Loss: 0.008489   Batch Acc: 79.69
[Train] Epoch: 2 [223808/620022]    Loss: 0.009886   Batch Acc: 79.69
[Train] Epoch: 2 [223872/620022]    Loss: 0.007421   Batch Acc: 79.69
[Train] Epoch: 2 [223936/620022]    Loss: 0.010514   Batch Acc: 73.44
[Train] Epoch: 2 [224000/620022]    Loss: 0.008747   Batch Acc: 81.25
[Train] Epoch: 2 [224064/620022]    Loss: 0.010673   Batch Acc: 76.56
[Train] Epoch: 2 [224128/620022]    Loss: 0.010275   Batch Acc: 70.31
[Train] Epoch: 2 [224192/620022]    Loss: 0.008562   Batch Acc: 78.12
[Train] Epoch: 2 [224256/620022]    Loss: 0.006204   Batch Acc: 84.38
[Train] Epoch: 2 [224320/620022]    Loss: 0.006644   Batch Acc: 87.50
[Train] Epoch: 2 [224384/620022]    Loss: 0.009906   Batch Acc: 76.56
[Train] Epoch: 2 [224448/620022]    Loss: 0.011253   Batch Acc: 67.19
[Train] Epoch: 2 [224512/620022]    Loss: 0.007588   Batch Acc: 82.81
[Train] Epoch: 2 [224576/620022]    Loss: 0.010165   Batch Acc: 70.31
[Train] Epoch: 2 [224640/620022]    Loss: 0.010971   Batch Acc: 75.00
[Train] Epoch: 2 [224704/620022]    Loss: 0.009267   Batch Acc: 79.69
[Train] Epoch: 2 [224768/620022]    Loss: 0.008394   Batch Acc: 78.12
[Train] Epoch: 2 [224832/620022]    Loss: 0.009566   Batch Acc: 76.56
[Train] Epoch: 2 [224896/620022]    Loss: 0.007818   Batch Acc: 78.12
[Train] Epoch: 2 [224960/620022]    Loss: 0.008329   Batch Acc: 79.69
[Train] Epoch: 2 [225024/620022]    Loss: 0.007239   Batch Acc: 84.38
[Train] Epoch: 2 [225088/620022]    Loss: 0.008613   Batch Acc: 79.69
[Train] Epoch: 2 [225152/620022]    Loss: 0.008649   Batch Acc: 79.69
[Train] Epoch: 2 [225216/620022]    Loss: 0.010226   Batch Acc: 76.56
[Train] Epoch: 2 [225280/620022]    Loss: 0.009739   Batch Acc: 75.00
[Train] Epoch: 2 [225344/620022]    Loss: 0.007434   Batch Acc: 79.69
[Train] Epoch: 2 [225408/620022]    Loss: 0.007945   Batch Acc: 79.69
[Train] Epoch: 2 [225472/620022]    Loss: 0.008979   Batch Acc: 76.56
[Train] Epoch: 2 [225536/620022]    Loss: 0.008992   Batch Acc: 75.00
[Train] Epoch: 2 [225600/620022]    Loss: 0.009756   Batch Acc: 70.31
[Train] Epoch: 2 [225664/620022]    Loss: 0.008618   Batch Acc: 81.25
[Train] Epoch: 2 [225728/620022]    Loss: 0.008714   Batch Acc: 78.12
[Train] Epoch: 2 [225792/620022]    Loss: 0.006871   Batch Acc: 84.38
[Train] Epoch: 2 [225856/620022]    Loss: 0.009860   Batch Acc: 70.31
[Train] Epoch: 2 [225920/620022]    Loss: 0.009077   Batch Acc: 76.56
[Train] Epoch: 2 [225984/620022]    Loss: 0.010013   Batch Acc: 71.88
[Train] Epoch: 2 [226048/620022]    Loss: 0.007034   Batch Acc: 79.69
[Train] Epoch: 2 [226112/620022]    Loss: 0.008350   Batch Acc: 78.12
[Train] Epoch: 2 [226176/620022]    Loss: 0.008016   Batch Acc: 79.69
[Train] Epoch: 2 [226240/620022]    Loss: 0.009254   Batch Acc: 78.12
[Train] Epoch: 2 [226304/620022]    Loss: 0.005785   Batch Acc: 87.50
[Train] Epoch: 2 [226368/620022]    Loss: 0.008309   Batch Acc: 81.25
[Train] Epoch: 2 [226432/620022]    Loss: 0.006963   Batch Acc: 84.38
[Train] Epoch: 2 [226496/620022]    Loss: 0.006800   Batch Acc: 81.25
[Train] Epoch: 2 [226560/620022]    Loss: 0.010092   Batch Acc: 70.31
[Train] Epoch: 2 [226624/620022]    Loss: 0.008783   Batch Acc: 76.56
[Train] Epoch: 2 [226688/620022]    Loss: 0.009666   Batch Acc: 76.56
[Train] Epoch: 2 [226752/620022]    Loss: 0.009268   Batch Acc: 71.88
[Train] Epoch: 2 [226816/620022]    Loss: 0.007699   Batch Acc: 76.56
[Train] Epoch: 2 [226880/620022]    Loss: 0.010785   Batch Acc: 68.75
[Train] Epoch: 2 [226944/620022]    Loss: 0.008787   Batch Acc: 81.25
[Train] Epoch: 2 [227008/620022]    Loss: 0.009279   Batch Acc: 78.12
[Train] Epoch: 2 [227072/620022]    Loss: 0.011514   Batch Acc: 65.62
[Train] Epoch: 2 [227136/620022]    Loss: 0.010576   Batch Acc: 68.75
[Train] Epoch: 2 [227200/620022]    Loss: 0.008909   Batch Acc: 73.44
[Train] Epoch: 2 [227264/620022]    Loss: 0.007399   Batch Acc: 81.25
[Train] Epoch: 2 [227328/620022]    Loss: 0.008028   Batch Acc: 79.69
[Train] Epoch: 2 [227392/620022]    Loss: 0.009079   Batch Acc: 75.00
[Train] Epoch: 2 [227456/620022]    Loss: 0.009919   Batch Acc: 75.00
[Train] Epoch: 2 [227520/620022]    Loss: 0.011010   Batch Acc: 71.88
[Train] Epoch: 2 [227584/620022]    Loss: 0.006887   Batch Acc: 82.81
[Train] Epoch: 2 [227648/620022]    Loss: 0.009799   Batch Acc: 75.00
[Train] Epoch: 2 [227712/620022]    Loss: 0.010822   Batch Acc: 68.75
[Train] Epoch: 2 [227776/620022]    Loss: 0.010396   Batch Acc: 73.44
[Train] Epoch: 2 [227840/620022]    Loss: 0.007451   Batch Acc: 84.38
[Train] Epoch: 2 [227904/620022]    Loss: 0.007745   Batch Acc: 82.81
[Train] Epoch: 2 [227968/620022]    Loss: 0.007739   Batch Acc: 84.38
[Train] Epoch: 2 [228032/620022]    Loss: 0.007960   Batch Acc: 78.12
[Train] Epoch: 2 [228096/620022]    Loss: 0.009912   Batch Acc: 75.00
[Train] Epoch: 2 [228160/620022]    Loss: 0.006701   Batch Acc: 92.19
[Train] Epoch: 2 [228224/620022]    Loss: 0.007862   Batch Acc: 79.69
[Train] Epoch: 2 [228288/620022]    Loss: 0.007527   Batch Acc: 79.69
[Train] Epoch: 2 [228352/620022]    Loss: 0.010997   Batch Acc: 76.56
[Train] Epoch: 2 [228416/620022]    Loss: 0.007863   Batch Acc: 81.25
[Train] Epoch: 2 [228480/620022]    Loss: 0.009184   Batch Acc: 76.56
[Train] Epoch: 2 [228544/620022]    Loss: 0.007988   Batch Acc: 81.25
[Train] Epoch: 2 [228608/620022]    Loss: 0.011753   Batch Acc: 68.75
[Train] Epoch: 2 [228672/620022]    Loss: 0.009664   Batch Acc: 79.69
[Train] Epoch: 2 [228736/620022]    Loss: 0.009078   Batch Acc: 70.31
[Train] Epoch: 2 [228800/620022]    Loss: 0.007219   Batch Acc: 81.25
[Train] Epoch: 2 [228864/620022]    Loss: 0.007899   Batch Acc: 81.25
[Train] Epoch: 2 [228928/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 2 [228992/620022]    Loss: 0.008595   Batch Acc: 76.56
[Train] Epoch: 2 [229056/620022]    Loss: 0.007169   Batch Acc: 82.81
[Train] Epoch: 2 [229120/620022]    Loss: 0.007463   Batch Acc: 82.81
[Train] Epoch: 2 [229184/620022]    Loss: 0.007860   Batch Acc: 79.69
[Train] Epoch: 2 [229248/620022]    Loss: 0.008696   Batch Acc: 78.12
[Train] Epoch: 2 [229312/620022]    Loss: 0.007513   Batch Acc: 87.50
[Train] Epoch: 2 [229376/620022]    Loss: 0.010485   Batch Acc: 70.31
[Train] Epoch: 2 [229440/620022]    Loss: 0.008666   Batch Acc: 79.69
[Train] Epoch: 2 [229504/620022]    Loss: 0.008536   Batch Acc: 79.69
[Train] Epoch: 2 [229568/620022]    Loss: 0.007560   Batch Acc: 82.81
[Train] Epoch: 2 [229632/620022]    Loss: 0.010198   Batch Acc: 81.25
[Train] Epoch: 2 [229696/620022]    Loss: 0.012140   Batch Acc: 67.19
[Train] Epoch: 2 [229760/620022]    Loss: 0.008350   Batch Acc: 73.44
[Train] Epoch: 2 [229824/620022]    Loss: 0.012087   Batch Acc: 65.62
[Train] Epoch: 2 [229888/620022]    Loss: 0.009420   Batch Acc: 79.69
[Train] Epoch: 2 [229952/620022]    Loss: 0.009236   Batch Acc: 75.00
[Train] Epoch: 2 [230016/620022]    Loss: 0.007450   Batch Acc: 82.81
[Train] Epoch: 2 [230080/620022]    Loss: 0.009007   Batch Acc: 68.75
[Train] Epoch: 2 [230144/620022]    Loss: 0.009213   Batch Acc: 78.12
[Train] Epoch: 2 [230208/620022]    Loss: 0.010143   Batch Acc: 68.75
[Train] Epoch: 2 [230272/620022]    Loss: 0.008552   Batch Acc: 78.12
[Train] Epoch: 2 [230336/620022]    Loss: 0.008768   Batch Acc: 84.38
[Train] Epoch: 2 [230400/620022]    Loss: 0.008843   Batch Acc: 76.56
[Train] Epoch: 2 [230464/620022]    Loss: 0.009434   Batch Acc: 73.44
[Train] Epoch: 2 [230528/620022]    Loss: 0.007620   Batch Acc: 78.12
[Train] Epoch: 2 [230592/620022]    Loss: 0.007540   Batch Acc: 84.38
[Train] Epoch: 2 [230656/620022]    Loss: 0.008131   Batch Acc: 85.94
[Train] Epoch: 2 [230720/620022]    Loss: 0.008373   Batch Acc: 71.88
[Train] Epoch: 2 [230784/620022]    Loss: 0.009831   Batch Acc: 73.44
[Train] Epoch: 2 [230848/620022]    Loss: 0.006828   Batch Acc: 81.25
[Train] Epoch: 2 [230912/620022]    Loss: 0.009646   Batch Acc: 71.88
[Train] Epoch: 2 [230976/620022]    Loss: 0.009338   Batch Acc: 78.12
[Train] Epoch: 2 [231040/620022]    Loss: 0.008645   Batch Acc: 78.12
[Train] Epoch: 2 [231104/620022]    Loss: 0.008450   Batch Acc: 73.44
[Train] Epoch: 2 [231168/620022]    Loss: 0.007662   Batch Acc: 82.81
[Train] Epoch: 2 [231232/620022]    Loss: 0.009448   Batch Acc: 75.00
[Train] Epoch: 2 [231296/620022]    Loss: 0.008961   Batch Acc: 76.56
[Train] Epoch: 2 [231360/620022]    Loss: 0.006934   Batch Acc: 82.81
[Train] Epoch: 2 [231424/620022]    Loss: 0.009023   Batch Acc: 81.25
[Train] Epoch: 2 [231488/620022]    Loss: 0.008179   Batch Acc: 79.69
[Train] Epoch: 2 [231552/620022]    Loss: 0.007815   Batch Acc: 79.69
[Train] Epoch: 2 [231616/620022]    Loss: 0.008979   Batch Acc: 76.56
[Train] Epoch: 2 [231680/620022]    Loss: 0.009236   Batch Acc: 73.44
[Train] Epoch: 2 [231744/620022]    Loss: 0.009227   Batch Acc: 78.12
[Train] Epoch: 2 [231808/620022]    Loss: 0.006213   Batch Acc: 87.50
[Train] Epoch: 2 [231872/620022]    Loss: 0.007504   Batch Acc: 78.12
[Train] Epoch: 2 [231936/620022]    Loss: 0.008598   Batch Acc: 78.12
[Train] Epoch: 2 [232000/620022]    Loss: 0.007126   Batch Acc: 84.38
[Train] Epoch: 2 [232064/620022]    Loss: 0.011259   Batch Acc: 73.44
[Train] Epoch: 2 [232128/620022]    Loss: 0.010041   Batch Acc: 68.75
[Train] Epoch: 2 [232192/620022]    Loss: 0.008364   Batch Acc: 79.69
[Train] Epoch: 2 [232256/620022]    Loss: 0.008709   Batch Acc: 75.00
[Train] Epoch: 2 [232320/620022]    Loss: 0.008144   Batch Acc: 76.56
[Train] Epoch: 2 [232384/620022]    Loss: 0.008401   Batch Acc: 78.12
[Train] Epoch: 2 [232448/620022]    Loss: 0.006492   Batch Acc: 84.38
[Train] Epoch: 2 [232512/620022]    Loss: 0.008205   Batch Acc: 78.12
[Train] Epoch: 2 [232576/620022]    Loss: 0.009646   Batch Acc: 75.00
[Train] Epoch: 2 [232640/620022]    Loss: 0.009155   Batch Acc: 81.25
[Train] Epoch: 2 [232704/620022]    Loss: 0.009771   Batch Acc: 71.88
[Train] Epoch: 2 [232768/620022]    Loss: 0.010265   Batch Acc: 68.75
[Train] Epoch: 2 [232832/620022]    Loss: 0.013433   Batch Acc: 65.62
[Train] Epoch: 2 [232896/620022]    Loss: 0.008572   Batch Acc: 73.44
[Train] Epoch: 2 [232960/620022]    Loss: 0.010219   Batch Acc: 73.44
[Train] Epoch: 2 [233024/620022]    Loss: 0.006762   Batch Acc: 84.38
[Train] Epoch: 2 [233088/620022]    Loss: 0.006667   Batch Acc: 82.81
[Train] Epoch: 2 [233152/620022]    Loss: 0.012638   Batch Acc: 71.88
[Train] Epoch: 2 [233216/620022]    Loss: 0.009325   Batch Acc: 76.56
[Train] Epoch: 2 [233280/620022]    Loss: 0.009509   Batch Acc: 76.56
[Train] Epoch: 2 [233344/620022]    Loss: 0.007138   Batch Acc: 81.25
[Train] Epoch: 2 [233408/620022]    Loss: 0.008563   Batch Acc: 82.81
[Train] Epoch: 2 [233472/620022]    Loss: 0.008354   Batch Acc: 76.56
[Train] Epoch: 2 [233536/620022]    Loss: 0.008211   Batch Acc: 81.25
[Train] Epoch: 2 [233600/620022]    Loss: 0.008175   Batch Acc: 78.12
[Train] Epoch: 2 [233664/620022]    Loss: 0.010429   Batch Acc: 70.31
[Train] Epoch: 2 [233728/620022]    Loss: 0.008300   Batch Acc: 76.56
[Train] Epoch: 2 [233792/620022]    Loss: 0.006727   Batch Acc: 89.06
[Train] Epoch: 2 [233856/620022]    Loss: 0.009842   Batch Acc: 76.56
[Train] Epoch: 2 [233920/620022]    Loss: 0.007331   Batch Acc: 82.81
[Train] Epoch: 2 [233984/620022]    Loss: 0.009699   Batch Acc: 73.44
[Train] Epoch: 2 [234048/620022]    Loss: 0.007718   Batch Acc: 81.25
[Train] Epoch: 2 [234112/620022]    Loss: 0.006873   Batch Acc: 89.06
[Train] Epoch: 2 [234176/620022]    Loss: 0.011713   Batch Acc: 70.31
[Train] Epoch: 2 [234240/620022]    Loss: 0.009013   Batch Acc: 78.12
[Train] Epoch: 2 [234304/620022]    Loss: 0.007694   Batch Acc: 84.38
[Train] Epoch: 2 [234368/620022]    Loss: 0.007832   Batch Acc: 84.38
[Train] Epoch: 2 [234432/620022]    Loss: 0.010039   Batch Acc: 67.19
[Train] Epoch: 2 [234496/620022]    Loss: 0.011294   Batch Acc: 67.19
[Train] Epoch: 2 [234560/620022]    Loss: 0.009517   Batch Acc: 76.56
[Train] Epoch: 2 [234624/620022]    Loss: 0.009689   Batch Acc: 76.56
[Train] Epoch: 2 [234688/620022]    Loss: 0.009123   Batch Acc: 81.25
[Train] Epoch: 2 [234752/620022]    Loss: 0.009685   Batch Acc: 81.25
[Train] Epoch: 2 [234816/620022]    Loss: 0.008226   Batch Acc: 81.25
[Train] Epoch: 2 [234880/620022]    Loss: 0.008226   Batch Acc: 79.69
[Train] Epoch: 2 [234944/620022]    Loss: 0.010076   Batch Acc: 70.31
[Train] Epoch: 2 [235008/620022]    Loss: 0.008561   Batch Acc: 78.12
[Train] Epoch: 2 [235072/620022]    Loss: 0.008096   Batch Acc: 81.25
[Train] Epoch: 2 [235136/620022]    Loss: 0.009955   Batch Acc: 73.44
[Train] Epoch: 2 [235200/620022]    Loss: 0.008661   Batch Acc: 78.12
[Train] Epoch: 2 [235264/620022]    Loss: 0.009612   Batch Acc: 75.00
[Train] Epoch: 2 [235328/620022]    Loss: 0.008089   Batch Acc: 78.12
[Train] Epoch: 2 [235392/620022]    Loss: 0.013562   Batch Acc: 54.69
[Train] Epoch: 2 [235456/620022]    Loss: 0.008491   Batch Acc: 76.56
[Train] Epoch: 2 [235520/620022]    Loss: 0.007117   Batch Acc: 84.38
[Train] Epoch: 2 [235584/620022]    Loss: 0.005209   Batch Acc: 89.06
[Train] Epoch: 2 [235648/620022]    Loss: 0.007745   Batch Acc: 81.25
[Train] Epoch: 2 [235712/620022]    Loss: 0.008260   Batch Acc: 75.00
[Train] Epoch: 2 [235776/620022]    Loss: 0.009301   Batch Acc: 73.44
[Train] Epoch: 2 [235840/620022]    Loss: 0.010030   Batch Acc: 73.44
[Train] Epoch: 2 [235904/620022]    Loss: 0.008191   Batch Acc: 78.12
[Train] Epoch: 2 [235968/620022]    Loss: 0.008250   Batch Acc: 81.25
[Train] Epoch: 2 [236032/620022]    Loss: 0.007848   Batch Acc: 79.69
[Train] Epoch: 2 [236096/620022]    Loss: 0.009094   Batch Acc: 76.56
[Train] Epoch: 2 [236160/620022]    Loss: 0.006860   Batch Acc: 84.38
[Train] Epoch: 2 [236224/620022]    Loss: 0.009807   Batch Acc: 73.44
[Train] Epoch: 2 [236288/620022]    Loss: 0.008756   Batch Acc: 79.69
[Train] Epoch: 2 [236352/620022]    Loss: 0.008078   Batch Acc: 79.69
[Train] Epoch: 2 [236416/620022]    Loss: 0.006541   Batch Acc: 79.69
[Train] Epoch: 2 [236480/620022]    Loss: 0.008229   Batch Acc: 76.56
[Train] Epoch: 2 [236544/620022]    Loss: 0.007539   Batch Acc: 84.38
[Train] Epoch: 2 [236608/620022]    Loss: 0.010519   Batch Acc: 70.31
[Train] Epoch: 2 [236672/620022]    Loss: 0.008569   Batch Acc: 79.69
[Train] Epoch: 2 [236736/620022]    Loss: 0.011263   Batch Acc: 70.31
[Train] Epoch: 2 [236800/620022]    Loss: 0.006605   Batch Acc: 84.38
[Train] Epoch: 2 [236864/620022]    Loss: 0.008995   Batch Acc: 78.12
[Train] Epoch: 2 [236928/620022]    Loss: 0.010921   Batch Acc: 75.00
[Train] Epoch: 2 [236992/620022]    Loss: 0.008863   Batch Acc: 81.25
[Train] Epoch: 2 [237056/620022]    Loss: 0.008021   Batch Acc: 81.25
[Train] Epoch: 2 [237120/620022]    Loss: 0.009023   Batch Acc: 75.00
[Train] Epoch: 2 [237184/620022]    Loss: 0.008809   Batch Acc: 76.56
[Train] Epoch: 2 [237248/620022]    Loss: 0.007605   Batch Acc: 82.81
[Train] Epoch: 2 [237312/620022]    Loss: 0.007763   Batch Acc: 82.81
[Train] Epoch: 2 [237376/620022]    Loss: 0.007020   Batch Acc: 81.25
[Train] Epoch: 2 [237440/620022]    Loss: 0.007594   Batch Acc: 79.69
[Train] Epoch: 2 [237504/620022]    Loss: 0.008514   Batch Acc: 81.25
[Train] Epoch: 2 [237568/620022]    Loss: 0.008902   Batch Acc: 81.25
[Train] Epoch: 2 [237632/620022]    Loss: 0.008205   Batch Acc: 73.44
[Train] Epoch: 2 [237696/620022]    Loss: 0.007632   Batch Acc: 84.38
[Train] Epoch: 2 [237760/620022]    Loss: 0.008045   Batch Acc: 81.25
[Train] Epoch: 2 [237824/620022]    Loss: 0.008750   Batch Acc: 75.00
[Train] Epoch: 2 [237888/620022]    Loss: 0.009591   Batch Acc: 79.69
[Train] Epoch: 2 [237952/620022]    Loss: 0.008824   Batch Acc: 75.00
[Train] Epoch: 2 [238016/620022]    Loss: 0.008455   Batch Acc: 82.81
[Train] Epoch: 2 [238080/620022]    Loss: 0.007608   Batch Acc: 82.81
[Train] Epoch: 2 [238144/620022]    Loss: 0.009428   Batch Acc: 75.00
[Train] Epoch: 2 [238208/620022]    Loss: 0.007249   Batch Acc: 82.81
[Train] Epoch: 2 [238272/620022]    Loss: 0.007692   Batch Acc: 89.06
[Train] Epoch: 2 [238336/620022]    Loss: 0.010485   Batch Acc: 68.75
[Train] Epoch: 2 [238400/620022]    Loss: 0.007939   Batch Acc: 78.12
[Train] Epoch: 2 [238464/620022]    Loss: 0.006627   Batch Acc: 87.50
[Train] Epoch: 2 [238528/620022]    Loss: 0.008758   Batch Acc: 79.69
[Train] Epoch: 2 [238592/620022]    Loss: 0.012721   Batch Acc: 60.94
[Train] Epoch: 2 [238656/620022]    Loss: 0.007800   Batch Acc: 78.12
[Train] Epoch: 2 [238720/620022]    Loss: 0.010248   Batch Acc: 75.00
[Train] Epoch: 2 [238784/620022]    Loss: 0.009875   Batch Acc: 68.75
[Train] Epoch: 2 [238848/620022]    Loss: 0.007778   Batch Acc: 78.12
[Train] Epoch: 2 [238912/620022]    Loss: 0.008102   Batch Acc: 71.88
[Train] Epoch: 2 [238976/620022]    Loss: 0.008589   Batch Acc: 78.12
[Train] Epoch: 2 [239040/620022]    Loss: 0.007853   Batch Acc: 79.69
[Train] Epoch: 2 [239104/620022]    Loss: 0.006801   Batch Acc: 81.25
[Train] Epoch: 2 [239168/620022]    Loss: 0.006728   Batch Acc: 82.81
[Train] Epoch: 2 [239232/620022]    Loss: 0.008997   Batch Acc: 75.00
[Train] Epoch: 2 [239296/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 2 [239360/620022]    Loss: 0.008541   Batch Acc: 81.25
[Train] Epoch: 2 [239424/620022]    Loss: 0.008770   Batch Acc: 76.56
[Train] Epoch: 2 [239488/620022]    Loss: 0.007007   Batch Acc: 87.50
[Train] Epoch: 2 [239552/620022]    Loss: 0.009721   Batch Acc: 68.75
[Train] Epoch: 2 [239616/620022]    Loss: 0.008816   Batch Acc: 76.56
[Train] Epoch: 2 [239680/620022]    Loss: 0.009296   Batch Acc: 79.69
[Train] Epoch: 2 [239744/620022]    Loss: 0.009162   Batch Acc: 82.81
[Train] Epoch: 2 [239808/620022]    Loss: 0.008877   Batch Acc: 75.00
[Train] Epoch: 2 [239872/620022]    Loss: 0.008837   Batch Acc: 81.25
[Train] Epoch: 2 [239936/620022]    Loss: 0.007360   Batch Acc: 82.81
[Train] Epoch: 2 [240000/620022]    Loss: 0.008747   Batch Acc: 76.56
[Train] Epoch: 2 [240064/620022]    Loss: 0.009349   Batch Acc: 73.44
[Train] Epoch: 2 [240128/620022]    Loss: 0.010384   Batch Acc: 75.00
[Train] Epoch: 2 [240192/620022]    Loss: 0.009770   Batch Acc: 71.88
[Train] Epoch: 2 [240256/620022]    Loss: 0.005957   Batch Acc: 89.06
[Train] Epoch: 2 [240320/620022]    Loss: 0.008463   Batch Acc: 81.25
[Train] Epoch: 2 [240384/620022]    Loss: 0.007480   Batch Acc: 81.25
[Train] Epoch: 2 [240448/620022]    Loss: 0.007064   Batch Acc: 84.38
[Train] Epoch: 2 [240512/620022]    Loss: 0.008888   Batch Acc: 76.56
[Train] Epoch: 2 [240576/620022]    Loss: 0.006675   Batch Acc: 82.81
[Train] Epoch: 2 [240640/620022]    Loss: 0.008840   Batch Acc: 71.88
[Train] Epoch: 2 [240704/620022]    Loss: 0.007577   Batch Acc: 81.25
[Train] Epoch: 2 [240768/620022]    Loss: 0.007607   Batch Acc: 82.81
[Train] Epoch: 2 [240832/620022]    Loss: 0.008489   Batch Acc: 73.44
[Train] Epoch: 2 [240896/620022]    Loss: 0.006555   Batch Acc: 84.38
[Train] Epoch: 2 [240960/620022]    Loss: 0.008840   Batch Acc: 78.12
[Train] Epoch: 2 [241024/620022]    Loss: 0.009334   Batch Acc: 68.75
[Train] Epoch: 2 [241088/620022]    Loss: 0.006782   Batch Acc: 85.94
[Train] Epoch: 2 [241152/620022]    Loss: 0.007132   Batch Acc: 82.81
[Train] Epoch: 2 [241216/620022]    Loss: 0.011815   Batch Acc: 68.75
[Train] Epoch: 2 [241280/620022]    Loss: 0.009261   Batch Acc: 71.88
[Train] Epoch: 2 [241344/620022]    Loss: 0.009795   Batch Acc: 73.44
[Train] Epoch: 2 [241408/620022]    Loss: 0.009321   Batch Acc: 76.56
[Train] Epoch: 2 [241472/620022]    Loss: 0.008474   Batch Acc: 75.00
[Train] Epoch: 2 [241536/620022]    Loss: 0.007954   Batch Acc: 78.12
[Train] Epoch: 2 [241600/620022]    Loss: 0.010749   Batch Acc: 73.44
[Train] Epoch: 2 [241664/620022]    Loss: 0.007498   Batch Acc: 79.69
[Train] Epoch: 2 [241728/620022]    Loss: 0.009433   Batch Acc: 71.88
[Train] Epoch: 2 [241792/620022]    Loss: 0.008559   Batch Acc: 79.69
[Train] Epoch: 2 [241856/620022]    Loss: 0.009376   Batch Acc: 75.00
[Train] Epoch: 2 [241920/620022]    Loss: 0.008639   Batch Acc: 75.00
[Train] Epoch: 2 [241984/620022]    Loss: 0.008616   Batch Acc: 79.69
[Train] Epoch: 2 [242048/620022]    Loss: 0.009186   Batch Acc: 75.00
[Train] Epoch: 2 [242112/620022]    Loss: 0.007766   Batch Acc: 84.38
[Train] Epoch: 2 [242176/620022]    Loss: 0.009605   Batch Acc: 79.69
[Train] Epoch: 2 [242240/620022]    Loss: 0.007877   Batch Acc: 78.12
[Train] Epoch: 2 [242304/620022]    Loss: 0.008988   Batch Acc: 75.00
[Train] Epoch: 2 [242368/620022]    Loss: 0.010165   Batch Acc: 71.88
[Train] Epoch: 2 [242432/620022]    Loss: 0.008480   Batch Acc: 82.81
[Train] Epoch: 2 [242496/620022]    Loss: 0.007813   Batch Acc: 84.38
[Train] Epoch: 2 [242560/620022]    Loss: 0.010423   Batch Acc: 71.88
[Train] Epoch: 2 [242624/620022]    Loss: 0.007705   Batch Acc: 82.81
[Train] Epoch: 2 [242688/620022]    Loss: 0.009640   Batch Acc: 76.56
[Train] Epoch: 2 [242752/620022]    Loss: 0.009625   Batch Acc: 78.12
[Train] Epoch: 2 [242816/620022]    Loss: 0.007169   Batch Acc: 84.38
[Train] Epoch: 2 [242880/620022]    Loss: 0.009936   Batch Acc: 73.44
[Train] Epoch: 2 [242944/620022]    Loss: 0.008370   Batch Acc: 78.12
[Train] Epoch: 2 [243008/620022]    Loss: 0.010047   Batch Acc: 79.69
[Train] Epoch: 2 [243072/620022]    Loss: 0.007224   Batch Acc: 79.69
[Train] Epoch: 2 [243136/620022]    Loss: 0.009771   Batch Acc: 76.56
[Train] Epoch: 2 [243200/620022]    Loss: 0.009507   Batch Acc: 73.44
[Train] Epoch: 2 [243264/620022]    Loss: 0.007232   Batch Acc: 82.81
[Train] Epoch: 2 [243328/620022]    Loss: 0.008266   Batch Acc: 73.44
[Train] Epoch: 2 [243392/620022]    Loss: 0.010133   Batch Acc: 70.31
[Train] Epoch: 2 [243456/620022]    Loss: 0.011239   Batch Acc: 70.31
[Train] Epoch: 2 [243520/620022]    Loss: 0.007465   Batch Acc: 82.81
[Train] Epoch: 2 [243584/620022]    Loss: 0.010388   Batch Acc: 68.75
[Train] Epoch: 2 [243648/620022]    Loss: 0.006848   Batch Acc: 85.94
[Train] Epoch: 2 [243712/620022]    Loss: 0.009480   Batch Acc: 73.44
[Train] Epoch: 2 [243776/620022]    Loss: 0.008347   Batch Acc: 81.25
[Train] Epoch: 2 [243840/620022]    Loss: 0.007642   Batch Acc: 84.38
[Train] Epoch: 2 [243904/620022]    Loss: 0.010642   Batch Acc: 70.31
[Train] Epoch: 2 [243968/620022]    Loss: 0.005170   Batch Acc: 90.62
[Train] Epoch: 2 [244032/620022]    Loss: 0.009005   Batch Acc: 76.56
[Train] Epoch: 2 [244096/620022]    Loss: 0.006651   Batch Acc: 84.38
[Train] Epoch: 2 [244160/620022]    Loss: 0.007368   Batch Acc: 78.12
[Train] Epoch: 2 [244224/620022]    Loss: 0.008469   Batch Acc: 75.00
[Train] Epoch: 2 [244288/620022]    Loss: 0.008254   Batch Acc: 84.38
[Train] Epoch: 2 [244352/620022]    Loss: 0.009762   Batch Acc: 76.56
[Train] Epoch: 2 [244416/620022]    Loss: 0.008697   Batch Acc: 78.12
[Train] Epoch: 2 [244480/620022]    Loss: 0.011384   Batch Acc: 70.31
[Train] Epoch: 2 [244544/620022]    Loss: 0.008955   Batch Acc: 75.00
[Train] Epoch: 2 [244608/620022]    Loss: 0.009738   Batch Acc: 75.00
[Train] Epoch: 2 [244672/620022]    Loss: 0.009508   Batch Acc: 75.00
[Train] Epoch: 2 [244736/620022]    Loss: 0.009413   Batch Acc: 75.00
[Train] Epoch: 2 [244800/620022]    Loss: 0.009515   Batch Acc: 73.44
[Train] Epoch: 2 [244864/620022]    Loss: 0.007007   Batch Acc: 89.06
[Train] Epoch: 2 [244928/620022]    Loss: 0.009835   Batch Acc: 79.69
[Train] Epoch: 2 [244992/620022]    Loss: 0.007303   Batch Acc: 81.25
[Train] Epoch: 2 [245056/620022]    Loss: 0.007797   Batch Acc: 81.25
[Train] Epoch: 2 [245120/620022]    Loss: 0.007812   Batch Acc: 79.69
[Train] Epoch: 2 [245184/620022]    Loss: 0.008830   Batch Acc: 81.25
[Train] Epoch: 2 [245248/620022]    Loss: 0.010689   Batch Acc: 70.31
[Train] Epoch: 2 [245312/620022]    Loss: 0.009348   Batch Acc: 73.44
[Train] Epoch: 2 [245376/620022]    Loss: 0.010095   Batch Acc: 76.56
[Train] Epoch: 2 [245440/620022]    Loss: 0.009724   Batch Acc: 78.12
[Train] Epoch: 2 [245504/620022]    Loss: 0.008981   Batch Acc: 75.00
[Train] Epoch: 2 [245568/620022]    Loss: 0.009764   Batch Acc: 73.44
[Train] Epoch: 2 [245632/620022]    Loss: 0.010856   Batch Acc: 65.62
[Train] Epoch: 2 [245696/620022]    Loss: 0.010160   Batch Acc: 73.44
[Train] Epoch: 2 [245760/620022]    Loss: 0.006336   Batch Acc: 85.94
[Train] Epoch: 2 [245824/620022]    Loss: 0.007991   Batch Acc: 79.69
[Train] Epoch: 2 [245888/620022]    Loss: 0.009499   Batch Acc: 76.56
[Train] Epoch: 2 [245952/620022]    Loss: 0.009434   Batch Acc: 78.12
[Train] Epoch: 2 [246016/620022]    Loss: 0.010611   Batch Acc: 71.88
[Train] Epoch: 2 [246080/620022]    Loss: 0.008699   Batch Acc: 78.12
[Train] Epoch: 2 [246144/620022]    Loss: 0.008272   Batch Acc: 76.56
[Train] Epoch: 2 [246208/620022]    Loss: 0.008010   Batch Acc: 82.81
[Train] Epoch: 2 [246272/620022]    Loss: 0.007942   Batch Acc: 81.25
[Train] Epoch: 2 [246336/620022]    Loss: 0.008223   Batch Acc: 73.44
[Train] Epoch: 2 [246400/620022]    Loss: 0.008105   Batch Acc: 70.31
[Train] Epoch: 2 [246464/620022]    Loss: 0.006598   Batch Acc: 85.94
[Train] Epoch: 2 [246528/620022]    Loss: 0.010486   Batch Acc: 76.56
[Train] Epoch: 2 [246592/620022]    Loss: 0.007523   Batch Acc: 84.38
[Train] Epoch: 2 [246656/620022]    Loss: 0.009789   Batch Acc: 71.88
[Train] Epoch: 2 [246720/620022]    Loss: 0.010322   Batch Acc: 70.31
[Train] Epoch: 2 [246784/620022]    Loss: 0.007343   Batch Acc: 82.81
[Train] Epoch: 2 [246848/620022]    Loss: 0.007562   Batch Acc: 84.38
[Train] Epoch: 2 [246912/620022]    Loss: 0.008233   Batch Acc: 75.00
[Train] Epoch: 2 [246976/620022]    Loss: 0.007000   Batch Acc: 82.81
[Train] Epoch: 2 [247040/620022]    Loss: 0.005158   Batch Acc: 90.62
[Train] Epoch: 2 [247104/620022]    Loss: 0.009879   Batch Acc: 68.75
[Train] Epoch: 2 [247168/620022]    Loss: 0.008126   Batch Acc: 78.12
[Train] Epoch: 2 [247232/620022]    Loss: 0.009205   Batch Acc: 82.81
[Train] Epoch: 2 [247296/620022]    Loss: 0.008760   Batch Acc: 81.25
[Train] Epoch: 2 [247360/620022]    Loss: 0.008581   Batch Acc: 78.12
[Train] Epoch: 2 [247424/620022]    Loss: 0.008541   Batch Acc: 78.12
[Train] Epoch: 2 [247488/620022]    Loss: 0.007917   Batch Acc: 81.25
[Train] Epoch: 2 [247552/620022]    Loss: 0.010664   Batch Acc: 75.00
[Train] Epoch: 2 [247616/620022]    Loss: 0.006598   Batch Acc: 85.94
[Train] Epoch: 2 [247680/620022]    Loss: 0.007182   Batch Acc: 82.81
[Train] Epoch: 2 [247744/620022]    Loss: 0.008467   Batch Acc: 78.12
[Train] Epoch: 2 [247808/620022]    Loss: 0.006882   Batch Acc: 79.69
[Train] Epoch: 2 [247872/620022]    Loss: 0.006675   Batch Acc: 81.25
[Train] Epoch: 2 [247936/620022]    Loss: 0.010957   Batch Acc: 75.00
[Train] Epoch: 2 [248000/620022]    Loss: 0.008580   Batch Acc: 81.25
[Train] Epoch: 2 [248064/620022]    Loss: 0.007979   Batch Acc: 84.38
[Train] Epoch: 2 [248128/620022]    Loss: 0.008330   Batch Acc: 73.44
[Train] Epoch: 2 [248192/620022]    Loss: 0.006826   Batch Acc: 82.81
[Train] Epoch: 2 [248256/620022]    Loss: 0.006886   Batch Acc: 84.38
[Train] Epoch: 2 [248320/620022]    Loss: 0.010931   Batch Acc: 65.62
[Train] Epoch: 2 [248384/620022]    Loss: 0.010601   Batch Acc: 67.19
[Train] Epoch: 2 [248448/620022]    Loss: 0.008202   Batch Acc: 79.69
[Train] Epoch: 2 [248512/620022]    Loss: 0.008041   Batch Acc: 81.25
[Train] Epoch: 2 [248576/620022]    Loss: 0.010941   Batch Acc: 70.31
[Train] Epoch: 2 [248640/620022]    Loss: 0.008309   Batch Acc: 81.25
[Train] Epoch: 2 [248704/620022]    Loss: 0.007383   Batch Acc: 84.38
[Train] Epoch: 2 [248768/620022]    Loss: 0.007427   Batch Acc: 82.81
[Train] Epoch: 2 [248832/620022]    Loss: 0.008702   Batch Acc: 81.25
[Train] Epoch: 2 [248896/620022]    Loss: 0.007852   Batch Acc: 84.38
[Train] Epoch: 2 [248960/620022]    Loss: 0.008477   Batch Acc: 79.69
[Train] Epoch: 2 [249024/620022]    Loss: 0.010976   Batch Acc: 78.12
[Train] Epoch: 2 [249088/620022]    Loss: 0.011279   Batch Acc: 71.88
[Train] Epoch: 2 [249152/620022]    Loss: 0.006785   Batch Acc: 78.12
[Train] Epoch: 2 [249216/620022]    Loss: 0.008145   Batch Acc: 79.69
[Train] Epoch: 2 [249280/620022]    Loss: 0.007358   Batch Acc: 78.12
[Train] Epoch: 2 [249344/620022]    Loss: 0.009788   Batch Acc: 75.00
[Train] Epoch: 2 [249408/620022]    Loss: 0.007133   Batch Acc: 78.12
[Train] Epoch: 2 [249472/620022]    Loss: 0.011263   Batch Acc: 75.00
[Train] Epoch: 2 [249536/620022]    Loss: 0.008539   Batch Acc: 76.56
[Train] Epoch: 2 [249600/620022]    Loss: 0.008617   Batch Acc: 79.69
[Train] Epoch: 2 [249664/620022]    Loss: 0.008239   Batch Acc: 82.81
[Train] Epoch: 2 [249728/620022]    Loss: 0.007657   Batch Acc: 73.44
[Train] Epoch: 2 [249792/620022]    Loss: 0.008038   Batch Acc: 78.12
[Train] Epoch: 2 [249856/620022]    Loss: 0.008110   Batch Acc: 78.12
[Train] Epoch: 2 [249920/620022]    Loss: 0.008209   Batch Acc: 79.69
[Train] Epoch: 2 [249984/620022]    Loss: 0.007715   Batch Acc: 84.38
[Train] Epoch: 2 [250048/620022]    Loss: 0.006906   Batch Acc: 84.38
[Train] Epoch: 2 [250112/620022]    Loss: 0.008407   Batch Acc: 76.56
[Train] Epoch: 2 [250176/620022]    Loss: 0.008886   Batch Acc: 76.56
[Train] Epoch: 2 [250240/620022]    Loss: 0.010843   Batch Acc: 70.31
[Train] Epoch: 2 [250304/620022]    Loss: 0.008782   Batch Acc: 76.56
[Train] Epoch: 2 [250368/620022]    Loss: 0.007328   Batch Acc: 79.69
[Train] Epoch: 2 [250432/620022]    Loss: 0.009201   Batch Acc: 73.44
[Train] Epoch: 2 [250496/620022]    Loss: 0.008160   Batch Acc: 78.12
[Train] Epoch: 2 [250560/620022]    Loss: 0.008384   Batch Acc: 78.12
[Train] Epoch: 2 [250624/620022]    Loss: 0.009750   Batch Acc: 75.00
[Train] Epoch: 2 [250688/620022]    Loss: 0.009755   Batch Acc: 71.88
[Train] Epoch: 2 [250752/620022]    Loss: 0.007199   Batch Acc: 81.25
[Train] Epoch: 2 [250816/620022]    Loss: 0.007120   Batch Acc: 79.69
[Train] Epoch: 2 [250880/620022]    Loss: 0.007616   Batch Acc: 78.12
[Train] Epoch: 2 [250944/620022]    Loss: 0.008245   Batch Acc: 78.12
[Train] Epoch: 2 [251008/620022]    Loss: 0.007340   Batch Acc: 81.25
[Train] Epoch: 2 [251072/620022]    Loss: 0.007105   Batch Acc: 81.25
[Train] Epoch: 2 [251136/620022]    Loss: 0.009422   Batch Acc: 73.44
[Train] Epoch: 2 [251200/620022]    Loss: 0.006868   Batch Acc: 90.62
[Train] Epoch: 2 [251264/620022]    Loss: 0.008160   Batch Acc: 85.94
[Train] Epoch: 2 [251328/620022]    Loss: 0.010051   Batch Acc: 71.88
[Train] Epoch: 2 [251392/620022]    Loss: 0.007551   Batch Acc: 84.38
[Train] Epoch: 2 [251456/620022]    Loss: 0.006935   Batch Acc: 87.50
[Train] Epoch: 2 [251520/620022]    Loss: 0.009797   Batch Acc: 76.56
[Train] Epoch: 2 [251584/620022]    Loss: 0.010280   Batch Acc: 78.12
[Train] Epoch: 2 [251648/620022]    Loss: 0.008625   Batch Acc: 78.12
[Train] Epoch: 2 [251712/620022]    Loss: 0.008726   Batch Acc: 73.44
[Train] Epoch: 2 [251776/620022]    Loss: 0.009220   Batch Acc: 75.00
[Train] Epoch: 2 [251840/620022]    Loss: 0.006716   Batch Acc: 84.38
[Train] Epoch: 2 [251904/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 2 [251968/620022]    Loss: 0.009777   Batch Acc: 73.44
[Train] Epoch: 2 [252032/620022]    Loss: 0.006794   Batch Acc: 79.69
[Train] Epoch: 2 [252096/620022]    Loss: 0.008699   Batch Acc: 78.12
[Train] Epoch: 2 [252160/620022]    Loss: 0.009017   Batch Acc: 73.44
[Train] Epoch: 2 [252224/620022]    Loss: 0.008660   Batch Acc: 75.00
[Train] Epoch: 2 [252288/620022]    Loss: 0.009787   Batch Acc: 71.88
[Train] Epoch: 2 [252352/620022]    Loss: 0.007119   Batch Acc: 85.94
[Train] Epoch: 2 [252416/620022]    Loss: 0.008630   Batch Acc: 79.69
[Train] Epoch: 2 [252480/620022]    Loss: 0.009865   Batch Acc: 71.88
[Train] Epoch: 2 [252544/620022]    Loss: 0.010121   Batch Acc: 68.75
[Train] Epoch: 2 [252608/620022]    Loss: 0.008107   Batch Acc: 79.69
[Train] Epoch: 2 [252672/620022]    Loss: 0.008386   Batch Acc: 76.56
[Train] Epoch: 2 [252736/620022]    Loss: 0.007939   Batch Acc: 78.12
[Train] Epoch: 2 [252800/620022]    Loss: 0.007307   Batch Acc: 84.38
[Train] Epoch: 2 [252864/620022]    Loss: 0.009165   Batch Acc: 82.81
[Train] Epoch: 2 [252928/620022]    Loss: 0.008037   Batch Acc: 73.44
[Train] Epoch: 2 [252992/620022]    Loss: 0.005137   Batch Acc: 93.75
[Train] Epoch: 2 [253056/620022]    Loss: 0.007641   Batch Acc: 82.81
[Train] Epoch: 2 [253120/620022]    Loss: 0.009205   Batch Acc: 75.00
[Train] Epoch: 2 [253184/620022]    Loss: 0.006732   Batch Acc: 89.06
[Train] Epoch: 2 [253248/620022]    Loss: 0.008899   Batch Acc: 75.00
[Train] Epoch: 2 [253312/620022]    Loss: 0.008475   Batch Acc: 75.00
[Train] Epoch: 2 [253376/620022]    Loss: 0.008338   Batch Acc: 73.44
[Train] Epoch: 2 [253440/620022]    Loss: 0.008693   Batch Acc: 75.00
[Train] Epoch: 2 [253504/620022]    Loss: 0.011272   Batch Acc: 68.75
[Train] Epoch: 2 [253568/620022]    Loss: 0.008262   Batch Acc: 81.25
[Train] Epoch: 2 [253632/620022]    Loss: 0.007297   Batch Acc: 87.50
[Train] Epoch: 2 [253696/620022]    Loss: 0.006448   Batch Acc: 87.50
[Train] Epoch: 2 [253760/620022]    Loss: 0.007417   Batch Acc: 84.38
[Train] Epoch: 2 [253824/620022]    Loss: 0.006806   Batch Acc: 89.06
[Train] Epoch: 2 [253888/620022]    Loss: 0.008606   Batch Acc: 73.44
[Train] Epoch: 2 [253952/620022]    Loss: 0.007357   Batch Acc: 84.38
[Train] Epoch: 2 [254016/620022]    Loss: 0.008564   Batch Acc: 84.38
[Train] Epoch: 2 [254080/620022]    Loss: 0.007362   Batch Acc: 81.25
[Train] Epoch: 2 [254144/620022]    Loss: 0.009148   Batch Acc: 76.56
[Train] Epoch: 2 [254208/620022]    Loss: 0.009263   Batch Acc: 71.88
[Train] Epoch: 2 [254272/620022]    Loss: 0.006567   Batch Acc: 85.94
[Train] Epoch: 2 [254336/620022]    Loss: 0.009063   Batch Acc: 73.44
[Train] Epoch: 2 [254400/620022]    Loss: 0.008289   Batch Acc: 82.81
[Train] Epoch: 2 [254464/620022]    Loss: 0.009563   Batch Acc: 78.12
[Train] Epoch: 2 [254528/620022]    Loss: 0.008618   Batch Acc: 81.25
[Train] Epoch: 2 [254592/620022]    Loss: 0.007277   Batch Acc: 81.25
[Train] Epoch: 2 [254656/620022]    Loss: 0.007489   Batch Acc: 81.25
[Train] Epoch: 2 [254720/620022]    Loss: 0.007781   Batch Acc: 81.25
[Train] Epoch: 2 [254784/620022]    Loss: 0.009264   Batch Acc: 75.00
[Train] Epoch: 2 [254848/620022]    Loss: 0.009786   Batch Acc: 78.12
[Train] Epoch: 2 [254912/620022]    Loss: 0.011645   Batch Acc: 67.19
[Train] Epoch: 2 [254976/620022]    Loss: 0.006997   Batch Acc: 82.81
[Train] Epoch: 2 [255040/620022]    Loss: 0.008609   Batch Acc: 71.88
[Train] Epoch: 2 [255104/620022]    Loss: 0.009239   Batch Acc: 81.25
[Train] Epoch: 2 [255168/620022]    Loss: 0.008979   Batch Acc: 73.44
[Train] Epoch: 2 [255232/620022]    Loss: 0.007505   Batch Acc: 84.38
[Train] Epoch: 2 [255296/620022]    Loss: 0.008616   Batch Acc: 76.56
[Train] Epoch: 2 [255360/620022]    Loss: 0.007133   Batch Acc: 81.25
[Train] Epoch: 2 [255424/620022]    Loss: 0.008670   Batch Acc: 76.56
[Train] Epoch: 2 [255488/620022]    Loss: 0.007453   Batch Acc: 84.38
[Train] Epoch: 2 [255552/620022]    Loss: 0.007637   Batch Acc: 81.25
[Train] Epoch: 2 [255616/620022]    Loss: 0.010287   Batch Acc: 75.00
[Train] Epoch: 2 [255680/620022]    Loss: 0.007776   Batch Acc: 81.25
[Train] Epoch: 2 [255744/620022]    Loss: 0.007245   Batch Acc: 81.25
[Train] Epoch: 2 [255808/620022]    Loss: 0.010856   Batch Acc: 73.44
[Train] Epoch: 2 [255872/620022]    Loss: 0.011748   Batch Acc: 64.06
[Train] Epoch: 2 [255936/620022]    Loss: 0.006788   Batch Acc: 82.81
[Train] Epoch: 2 [256000/620022]    Loss: 0.010559   Batch Acc: 75.00
[Train] Epoch: 2 [256064/620022]    Loss: 0.008184   Batch Acc: 82.81
[Train] Epoch: 2 [256128/620022]    Loss: 0.008922   Batch Acc: 78.12
[Train] Epoch: 2 [256192/620022]    Loss: 0.009173   Batch Acc: 79.69
[Train] Epoch: 2 [256256/620022]    Loss: 0.009248   Batch Acc: 75.00
[Train] Epoch: 2 [256320/620022]    Loss: 0.008112   Batch Acc: 84.38
[Train] Epoch: 2 [256384/620022]    Loss: 0.009230   Batch Acc: 76.56
[Train] Epoch: 2 [256448/620022]    Loss: 0.009044   Batch Acc: 71.88
[Train] Epoch: 2 [256512/620022]    Loss: 0.009605   Batch Acc: 73.44
[Train] Epoch: 2 [256576/620022]    Loss: 0.010205   Batch Acc: 75.00
[Train] Epoch: 2 [256640/620022]    Loss: 0.007886   Batch Acc: 79.69
[Train] Epoch: 2 [256704/620022]    Loss: 0.007121   Batch Acc: 84.38
[Train] Epoch: 2 [256768/620022]    Loss: 0.008711   Batch Acc: 79.69
[Train] Epoch: 2 [256832/620022]    Loss: 0.007188   Batch Acc: 85.94
[Train] Epoch: 2 [256896/620022]    Loss: 0.009457   Batch Acc: 73.44
[Train] Epoch: 2 [256960/620022]    Loss: 0.009481   Batch Acc: 73.44
[Train] Epoch: 2 [257024/620022]    Loss: 0.008742   Batch Acc: 79.69
[Train] Epoch: 2 [257088/620022]    Loss: 0.008677   Batch Acc: 76.56
[Train] Epoch: 2 [257152/620022]    Loss: 0.008187   Batch Acc: 79.69
[Train] Epoch: 2 [257216/620022]    Loss: 0.007914   Batch Acc: 76.56
[Train] Epoch: 2 [257280/620022]    Loss: 0.006945   Batch Acc: 84.38
[Train] Epoch: 2 [257344/620022]    Loss: 0.008787   Batch Acc: 75.00
[Train] Epoch: 2 [257408/620022]    Loss: 0.008212   Batch Acc: 78.12
[Train] Epoch: 2 [257472/620022]    Loss: 0.009075   Batch Acc: 78.12
[Train] Epoch: 2 [257536/620022]    Loss: 0.008848   Batch Acc: 78.12
[Train] Epoch: 2 [257600/620022]    Loss: 0.009246   Batch Acc: 70.31
[Train] Epoch: 2 [257664/620022]    Loss: 0.010828   Batch Acc: 73.44
[Train] Epoch: 2 [257728/620022]    Loss: 0.006191   Batch Acc: 85.94
[Train] Epoch: 2 [257792/620022]    Loss: 0.010662   Batch Acc: 71.88
[Train] Epoch: 2 [257856/620022]    Loss: 0.010754   Batch Acc: 70.31
[Train] Epoch: 2 [257920/620022]    Loss: 0.010352   Batch Acc: 71.88
[Train] Epoch: 2 [257984/620022]    Loss: 0.010498   Batch Acc: 75.00
[Train] Epoch: 2 [258048/620022]    Loss: 0.006860   Batch Acc: 81.25
[Train] Epoch: 2 [258112/620022]    Loss: 0.008519   Batch Acc: 81.25
[Train] Epoch: 2 [258176/620022]    Loss: 0.007313   Batch Acc: 85.94
[Train] Epoch: 2 [258240/620022]    Loss: 0.008531   Batch Acc: 78.12
[Train] Epoch: 2 [258304/620022]    Loss: 0.009713   Batch Acc: 76.56
[Train] Epoch: 2 [258368/620022]    Loss: 0.008301   Batch Acc: 79.69
[Train] Epoch: 2 [258432/620022]    Loss: 0.009032   Batch Acc: 75.00
[Train] Epoch: 2 [258496/620022]    Loss: 0.008262   Batch Acc: 79.69
[Train] Epoch: 2 [258560/620022]    Loss: 0.009715   Batch Acc: 71.88
[Train] Epoch: 2 [258624/620022]    Loss: 0.007450   Batch Acc: 79.69
[Train] Epoch: 2 [258688/620022]    Loss: 0.009186   Batch Acc: 75.00
[Train] Epoch: 2 [258752/620022]    Loss: 0.009400   Batch Acc: 73.44
[Train] Epoch: 2 [258816/620022]    Loss: 0.009113   Batch Acc: 78.12
[Train] Epoch: 2 [258880/620022]    Loss: 0.008431   Batch Acc: 82.81
[Train] Epoch: 2 [258944/620022]    Loss: 0.009802   Batch Acc: 70.31
[Train] Epoch: 2 [259008/620022]    Loss: 0.009595   Batch Acc: 70.31
[Train] Epoch: 2 [259072/620022]    Loss: 0.006770   Batch Acc: 85.94
[Train] Epoch: 2 [259136/620022]    Loss: 0.008018   Batch Acc: 78.12
[Train] Epoch: 2 [259200/620022]    Loss: 0.010371   Batch Acc: 75.00
[Train] Epoch: 2 [259264/620022]    Loss: 0.009303   Batch Acc: 68.75
[Train] Epoch: 2 [259328/620022]    Loss: 0.009528   Batch Acc: 73.44
[Train] Epoch: 2 [259392/620022]    Loss: 0.009566   Batch Acc: 75.00
[Train] Epoch: 2 [259456/620022]    Loss: 0.010159   Batch Acc: 68.75
[Train] Epoch: 2 [259520/620022]    Loss: 0.006715   Batch Acc: 84.38
[Train] Epoch: 2 [259584/620022]    Loss: 0.006467   Batch Acc: 82.81
[Train] Epoch: 2 [259648/620022]    Loss: 0.009238   Batch Acc: 75.00
[Train] Epoch: 2 [259712/620022]    Loss: 0.006074   Batch Acc: 89.06
[Train] Epoch: 2 [259776/620022]    Loss: 0.010779   Batch Acc: 73.44
[Train] Epoch: 2 [259840/620022]    Loss: 0.010361   Batch Acc: 70.31
[Train] Epoch: 2 [259904/620022]    Loss: 0.009412   Batch Acc: 81.25
[Train] Epoch: 2 [259968/620022]    Loss: 0.009771   Batch Acc: 73.44
[Train] Epoch: 2 [260032/620022]    Loss: 0.009569   Batch Acc: 73.44
[Train] Epoch: 2 [260096/620022]    Loss: 0.009604   Batch Acc: 76.56
[Train] Epoch: 2 [260160/620022]    Loss: 0.010433   Batch Acc: 70.31
[Train] Epoch: 2 [260224/620022]    Loss: 0.007261   Batch Acc: 81.25
[Train] Epoch: 2 [260288/620022]    Loss: 0.009504   Batch Acc: 71.88
[Train] Epoch: 2 [260352/620022]    Loss: 0.008434   Batch Acc: 75.00
[Train] Epoch: 2 [260416/620022]    Loss: 0.010127   Batch Acc: 73.44
[Train] Epoch: 2 [260480/620022]    Loss: 0.009071   Batch Acc: 70.31
[Train] Epoch: 2 [260544/620022]    Loss: 0.006882   Batch Acc: 81.25
[Train] Epoch: 2 [260608/620022]    Loss: 0.008902   Batch Acc: 78.12
[Train] Epoch: 2 [260672/620022]    Loss: 0.008664   Batch Acc: 76.56
[Train] Epoch: 2 [260736/620022]    Loss: 0.008968   Batch Acc: 71.88
[Train] Epoch: 2 [260800/620022]    Loss: 0.007370   Batch Acc: 82.81
[Train] Epoch: 2 [260864/620022]    Loss: 0.009879   Batch Acc: 76.56
[Train] Epoch: 2 [260928/620022]    Loss: 0.009442   Batch Acc: 78.12
[Train] Epoch: 2 [260992/620022]    Loss: 0.007574   Batch Acc: 81.25
[Train] Epoch: 2 [261056/620022]    Loss: 0.008011   Batch Acc: 76.56
[Train] Epoch: 2 [261120/620022]    Loss: 0.008949   Batch Acc: 78.12
[Train] Epoch: 2 [261184/620022]    Loss: 0.007718   Batch Acc: 85.94
[Train] Epoch: 2 [261248/620022]    Loss: 0.008458   Batch Acc: 81.25
[Train] Epoch: 2 [261312/620022]    Loss: 0.006828   Batch Acc: 90.62
[Train] Epoch: 2 [261376/620022]    Loss: 0.011688   Batch Acc: 68.75
[Train] Epoch: 2 [261440/620022]    Loss: 0.008586   Batch Acc: 75.00
[Train] Epoch: 2 [261504/620022]    Loss: 0.010173   Batch Acc: 78.12
[Train] Epoch: 2 [261568/620022]    Loss: 0.007124   Batch Acc: 78.12
[Train] Epoch: 2 [261632/620022]    Loss: 0.008547   Batch Acc: 78.12
[Train] Epoch: 2 [261696/620022]    Loss: 0.007800   Batch Acc: 78.12
[Train] Epoch: 2 [261760/620022]    Loss: 0.007610   Batch Acc: 79.69
[Train] Epoch: 2 [261824/620022]    Loss: 0.007826   Batch Acc: 81.25
[Train] Epoch: 2 [261888/620022]    Loss: 0.007881   Batch Acc: 81.25
[Train] Epoch: 2 [261952/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 2 [262016/620022]    Loss: 0.009402   Batch Acc: 82.81
[Train] Epoch: 2 [262080/620022]    Loss: 0.007073   Batch Acc: 87.50
[Train] Epoch: 2 [262144/620022]    Loss: 0.010800   Batch Acc: 68.75
[Train] Epoch: 2 [262208/620022]    Loss: 0.010241   Batch Acc: 71.88
[Train] Epoch: 2 [262272/620022]    Loss: 0.008315   Batch Acc: 76.56
[Train] Epoch: 2 [262336/620022]    Loss: 0.011408   Batch Acc: 70.31
[Train] Epoch: 2 [262400/620022]    Loss: 0.008003   Batch Acc: 81.25
[Train] Epoch: 2 [262464/620022]    Loss: 0.008437   Batch Acc: 81.25
[Train] Epoch: 2 [262528/620022]    Loss: 0.008503   Batch Acc: 78.12
[Train] Epoch: 2 [262592/620022]    Loss: 0.009808   Batch Acc: 71.88
[Train] Epoch: 2 [262656/620022]    Loss: 0.009354   Batch Acc: 76.56
[Train] Epoch: 2 [262720/620022]    Loss: 0.008046   Batch Acc: 82.81
[Train] Epoch: 2 [262784/620022]    Loss: 0.010748   Batch Acc: 68.75
[Train] Epoch: 2 [262848/620022]    Loss: 0.008711   Batch Acc: 79.69
[Train] Epoch: 2 [262912/620022]    Loss: 0.008105   Batch Acc: 85.94
[Train] Epoch: 2 [262976/620022]    Loss: 0.009422   Batch Acc: 82.81
[Train] Epoch: 2 [263040/620022]    Loss: 0.006797   Batch Acc: 84.38
[Train] Epoch: 2 [263104/620022]    Loss: 0.008607   Batch Acc: 78.12
[Train] Epoch: 2 [263168/620022]    Loss: 0.009117   Batch Acc: 79.69
[Train] Epoch: 2 [263232/620022]    Loss: 0.009990   Batch Acc: 70.31
[Train] Epoch: 2 [263296/620022]    Loss: 0.008570   Batch Acc: 73.44
[Train] Epoch: 2 [263360/620022]    Loss: 0.007936   Batch Acc: 79.69
[Train] Epoch: 2 [263424/620022]    Loss: 0.007531   Batch Acc: 79.69
[Train] Epoch: 2 [263488/620022]    Loss: 0.009393   Batch Acc: 76.56
[Train] Epoch: 2 [263552/620022]    Loss: 0.008981   Batch Acc: 68.75
[Train] Epoch: 2 [263616/620022]    Loss: 0.009495   Batch Acc: 76.56
[Train] Epoch: 2 [263680/620022]    Loss: 0.010426   Batch Acc: 75.00
[Train] Epoch: 2 [263744/620022]    Loss: 0.008468   Batch Acc: 78.12
[Train] Epoch: 2 [263808/620022]    Loss: 0.006607   Batch Acc: 82.81
[Train] Epoch: 2 [263872/620022]    Loss: 0.007801   Batch Acc: 78.12
[Train] Epoch: 2 [263936/620022]    Loss: 0.007621   Batch Acc: 84.38
[Train] Epoch: 2 [264000/620022]    Loss: 0.007722   Batch Acc: 75.00
[Train] Epoch: 2 [264064/620022]    Loss: 0.007193   Batch Acc: 84.38
[Train] Epoch: 2 [264128/620022]    Loss: 0.008396   Batch Acc: 76.56
[Train] Epoch: 2 [264192/620022]    Loss: 0.008801   Batch Acc: 79.69
[Train] Epoch: 2 [264256/620022]    Loss: 0.009710   Batch Acc: 76.56
[Train] Epoch: 2 [264320/620022]    Loss: 0.005150   Batch Acc: 92.19
[Train] Epoch: 2 [264384/620022]    Loss: 0.008764   Batch Acc: 76.56
[Train] Epoch: 2 [264448/620022]    Loss: 0.009688   Batch Acc: 68.75
[Train] Epoch: 2 [264512/620022]    Loss: 0.008471   Batch Acc: 76.56
[Train] Epoch: 2 [264576/620022]    Loss: 0.007917   Batch Acc: 79.69
[Train] Epoch: 2 [264640/620022]    Loss: 0.008539   Batch Acc: 76.56
[Train] Epoch: 2 [264704/620022]    Loss: 0.011081   Batch Acc: 73.44
[Train] Epoch: 2 [264768/620022]    Loss: 0.006842   Batch Acc: 84.38
[Train] Epoch: 2 [264832/620022]    Loss: 0.009263   Batch Acc: 73.44
[Train] Epoch: 2 [264896/620022]    Loss: 0.008744   Batch Acc: 78.12
[Train] Epoch: 2 [264960/620022]    Loss: 0.008610   Batch Acc: 81.25
[Train] Epoch: 2 [265024/620022]    Loss: 0.008620   Batch Acc: 79.69
[Train] Epoch: 2 [265088/620022]    Loss: 0.008082   Batch Acc: 82.81
[Train] Epoch: 2 [265152/620022]    Loss: 0.008913   Batch Acc: 75.00
[Train] Epoch: 2 [265216/620022]    Loss: 0.011656   Batch Acc: 67.19
[Train] Epoch: 2 [265280/620022]    Loss: 0.009686   Batch Acc: 76.56
[Train] Epoch: 2 [265344/620022]    Loss: 0.009212   Batch Acc: 79.69
[Train] Epoch: 2 [265408/620022]    Loss: 0.009352   Batch Acc: 76.56
[Train] Epoch: 2 [265472/620022]    Loss: 0.009229   Batch Acc: 79.69
[Train] Epoch: 2 [265536/620022]    Loss: 0.006942   Batch Acc: 79.69
[Train] Epoch: 2 [265600/620022]    Loss: 0.010793   Batch Acc: 71.88
[Train] Epoch: 2 [265664/620022]    Loss: 0.008119   Batch Acc: 79.69
[Train] Epoch: 2 [265728/620022]    Loss: 0.007852   Batch Acc: 81.25
[Train] Epoch: 2 [265792/620022]    Loss: 0.008594   Batch Acc: 79.69
[Train] Epoch: 2 [265856/620022]    Loss: 0.008938   Batch Acc: 75.00
[Train] Epoch: 2 [265920/620022]    Loss: 0.012502   Batch Acc: 71.88
[Train] Epoch: 2 [265984/620022]    Loss: 0.009061   Batch Acc: 78.12
[Train] Epoch: 2 [266048/620022]    Loss: 0.008428   Batch Acc: 78.12
[Train] Epoch: 2 [266112/620022]    Loss: 0.008891   Batch Acc: 76.56
[Train] Epoch: 2 [266176/620022]    Loss: 0.007083   Batch Acc: 81.25
[Train] Epoch: 2 [266240/620022]    Loss: 0.007281   Batch Acc: 82.81
[Train] Epoch: 2 [266304/620022]    Loss: 0.008548   Batch Acc: 75.00
[Train] Epoch: 2 [266368/620022]    Loss: 0.007915   Batch Acc: 82.81
[Train] Epoch: 2 [266432/620022]    Loss: 0.007556   Batch Acc: 79.69
[Train] Epoch: 2 [266496/620022]    Loss: 0.008312   Batch Acc: 81.25
[Train] Epoch: 2 [266560/620022]    Loss: 0.010415   Batch Acc: 67.19
[Train] Epoch: 2 [266624/620022]    Loss: 0.009510   Batch Acc: 76.56
[Train] Epoch: 2 [266688/620022]    Loss: 0.007834   Batch Acc: 82.81
[Train] Epoch: 2 [266752/620022]    Loss: 0.006977   Batch Acc: 87.50
[Train] Epoch: 2 [266816/620022]    Loss: 0.008747   Batch Acc: 79.69
[Train] Epoch: 2 [266880/620022]    Loss: 0.010542   Batch Acc: 64.06
[Train] Epoch: 2 [266944/620022]    Loss: 0.009612   Batch Acc: 71.88
[Train] Epoch: 2 [267008/620022]    Loss: 0.010578   Batch Acc: 73.44
[Train] Epoch: 2 [267072/620022]    Loss: 0.008126   Batch Acc: 82.81
[Train] Epoch: 2 [267136/620022]    Loss: 0.008567   Batch Acc: 78.12
[Train] Epoch: 2 [267200/620022]    Loss: 0.008601   Batch Acc: 82.81
[Train] Epoch: 2 [267264/620022]    Loss: 0.010632   Batch Acc: 73.44
[Train] Epoch: 2 [267328/620022]    Loss: 0.009590   Batch Acc: 78.12
[Train] Epoch: 2 [267392/620022]    Loss: 0.009616   Batch Acc: 75.00
[Train] Epoch: 2 [267456/620022]    Loss: 0.009590   Batch Acc: 75.00
[Train] Epoch: 2 [267520/620022]    Loss: 0.008916   Batch Acc: 76.56
[Train] Epoch: 2 [267584/620022]    Loss: 0.008431   Batch Acc: 79.69
[Train] Epoch: 2 [267648/620022]    Loss: 0.010091   Batch Acc: 79.69
[Train] Epoch: 2 [267712/620022]    Loss: 0.008675   Batch Acc: 75.00
[Train] Epoch: 2 [267776/620022]    Loss: 0.008481   Batch Acc: 76.56
[Train] Epoch: 2 [267840/620022]    Loss: 0.007802   Batch Acc: 81.25
[Train] Epoch: 2 [267904/620022]    Loss: 0.006976   Batch Acc: 84.38
[Train] Epoch: 2 [267968/620022]    Loss: 0.010085   Batch Acc: 70.31
[Train] Epoch: 2 [268032/620022]    Loss: 0.007691   Batch Acc: 82.81
[Train] Epoch: 2 [268096/620022]    Loss: 0.010039   Batch Acc: 75.00
[Train] Epoch: 2 [268160/620022]    Loss: 0.008899   Batch Acc: 81.25
[Train] Epoch: 2 [268224/620022]    Loss: 0.007906   Batch Acc: 82.81
[Train] Epoch: 2 [268288/620022]    Loss: 0.008152   Batch Acc: 79.69
[Train] Epoch: 2 [268352/620022]    Loss: 0.009889   Batch Acc: 75.00
[Train] Epoch: 2 [268416/620022]    Loss: 0.009793   Batch Acc: 79.69
[Train] Epoch: 2 [268480/620022]    Loss: 0.007706   Batch Acc: 81.25
[Train] Epoch: 2 [268544/620022]    Loss: 0.008355   Batch Acc: 75.00
[Train] Epoch: 2 [268608/620022]    Loss: 0.007724   Batch Acc: 82.81
[Train] Epoch: 2 [268672/620022]    Loss: 0.007749   Batch Acc: 73.44
[Train] Epoch: 2 [268736/620022]    Loss: 0.007178   Batch Acc: 81.25
[Train] Epoch: 2 [268800/620022]    Loss: 0.009352   Batch Acc: 79.69
[Train] Epoch: 2 [268864/620022]    Loss: 0.011025   Batch Acc: 68.75
[Train] Epoch: 2 [268928/620022]    Loss: 0.010973   Batch Acc: 71.88
[Train] Epoch: 2 [268992/620022]    Loss: 0.008647   Batch Acc: 76.56
[Train] Epoch: 2 [269056/620022]    Loss: 0.008175   Batch Acc: 79.69
[Train] Epoch: 2 [269120/620022]    Loss: 0.009228   Batch Acc: 73.44
[Train] Epoch: 2 [269184/620022]    Loss: 0.008279   Batch Acc: 78.12
[Train] Epoch: 2 [269248/620022]    Loss: 0.009628   Batch Acc: 71.88
[Train] Epoch: 2 [269312/620022]    Loss: 0.010829   Batch Acc: 68.75
[Train] Epoch: 2 [269376/620022]    Loss: 0.009525   Batch Acc: 71.88
[Train] Epoch: 2 [269440/620022]    Loss: 0.008582   Batch Acc: 78.12
[Train] Epoch: 2 [269504/620022]    Loss: 0.007677   Batch Acc: 81.25
[Train] Epoch: 2 [269568/620022]    Loss: 0.008465   Batch Acc: 79.69
[Train] Epoch: 2 [269632/620022]    Loss: 0.008721   Batch Acc: 81.25
[Train] Epoch: 2 [269696/620022]    Loss: 0.009361   Batch Acc: 81.25
[Train] Epoch: 2 [269760/620022]    Loss: 0.007711   Batch Acc: 78.12
[Train] Epoch: 2 [269824/620022]    Loss: 0.009234   Batch Acc: 76.56
[Train] Epoch: 2 [269888/620022]    Loss: 0.008226   Batch Acc: 82.81
[Train] Epoch: 2 [269952/620022]    Loss: 0.008853   Batch Acc: 73.44
[Train] Epoch: 2 [270016/620022]    Loss: 0.007504   Batch Acc: 82.81
[Train] Epoch: 2 [270080/620022]    Loss: 0.007190   Batch Acc: 82.81
[Train] Epoch: 2 [270144/620022]    Loss: 0.009113   Batch Acc: 79.69
[Train] Epoch: 2 [270208/620022]    Loss: 0.007536   Batch Acc: 84.38
[Train] Epoch: 2 [270272/620022]    Loss: 0.008358   Batch Acc: 78.12
[Train] Epoch: 2 [270336/620022]    Loss: 0.011885   Batch Acc: 62.50
[Train] Epoch: 2 [270400/620022]    Loss: 0.009857   Batch Acc: 71.88
[Train] Epoch: 2 [270464/620022]    Loss: 0.008620   Batch Acc: 84.38
[Train] Epoch: 2 [270528/620022]    Loss: 0.008948   Batch Acc: 79.69
[Train] Epoch: 2 [270592/620022]    Loss: 0.006855   Batch Acc: 79.69
[Train] Epoch: 2 [270656/620022]    Loss: 0.007026   Batch Acc: 84.38
[Train] Epoch: 2 [270720/620022]    Loss: 0.009476   Batch Acc: 71.88
[Train] Epoch: 2 [270784/620022]    Loss: 0.009036   Batch Acc: 73.44
[Train] Epoch: 2 [270848/620022]    Loss: 0.008132   Batch Acc: 81.25
[Train] Epoch: 2 [270912/620022]    Loss: 0.009668   Batch Acc: 76.56
[Train] Epoch: 2 [270976/620022]    Loss: 0.007133   Batch Acc: 82.81
[Train] Epoch: 2 [271040/620022]    Loss: 0.009827   Batch Acc: 75.00
[Train] Epoch: 2 [271104/620022]    Loss: 0.007381   Batch Acc: 81.25
[Train] Epoch: 2 [271168/620022]    Loss: 0.008288   Batch Acc: 81.25
[Train] Epoch: 2 [271232/620022]    Loss: 0.012284   Batch Acc: 71.88
[Train] Epoch: 2 [271296/620022]    Loss: 0.006969   Batch Acc: 81.25
[Train] Epoch: 2 [271360/620022]    Loss: 0.008214   Batch Acc: 75.00
[Train] Epoch: 2 [271424/620022]    Loss: 0.009361   Batch Acc: 71.88
[Train] Epoch: 2 [271488/620022]    Loss: 0.009294   Batch Acc: 73.44
[Train] Epoch: 2 [271552/620022]    Loss: 0.007675   Batch Acc: 78.12
[Train] Epoch: 2 [271616/620022]    Loss: 0.009284   Batch Acc: 68.75
[Train] Epoch: 2 [271680/620022]    Loss: 0.008547   Batch Acc: 76.56
[Train] Epoch: 2 [271744/620022]    Loss: 0.007445   Batch Acc: 89.06
[Train] Epoch: 2 [271808/620022]    Loss: 0.006453   Batch Acc: 82.81
[Train] Epoch: 2 [271872/620022]    Loss: 0.009466   Batch Acc: 75.00
[Train] Epoch: 2 [271936/620022]    Loss: 0.008381   Batch Acc: 81.25
[Train] Epoch: 2 [272000/620022]    Loss: 0.007248   Batch Acc: 82.81
[Train] Epoch: 2 [272064/620022]    Loss: 0.008792   Batch Acc: 75.00
[Train] Epoch: 2 [272128/620022]    Loss: 0.006750   Batch Acc: 87.50
[Train] Epoch: 2 [272192/620022]    Loss: 0.007445   Batch Acc: 79.69
[Train] Epoch: 2 [272256/620022]    Loss: 0.006548   Batch Acc: 92.19
[Train] Epoch: 2 [272320/620022]    Loss: 0.009800   Batch Acc: 75.00
[Train] Epoch: 2 [272384/620022]    Loss: 0.007067   Batch Acc: 85.94
[Train] Epoch: 2 [272448/620022]    Loss: 0.008361   Batch Acc: 85.94
[Train] Epoch: 2 [272512/620022]    Loss: 0.007799   Batch Acc: 81.25
[Train] Epoch: 2 [272576/620022]    Loss: 0.009337   Batch Acc: 75.00
[Train] Epoch: 2 [272640/620022]    Loss: 0.008516   Batch Acc: 79.69
[Train] Epoch: 2 [272704/620022]    Loss: 0.009249   Batch Acc: 78.12
[Train] Epoch: 2 [272768/620022]    Loss: 0.009899   Batch Acc: 79.69
[Train] Epoch: 2 [272832/620022]    Loss: 0.008036   Batch Acc: 79.69
[Train] Epoch: 2 [272896/620022]    Loss: 0.008809   Batch Acc: 81.25
[Train] Epoch: 2 [272960/620022]    Loss: 0.010262   Batch Acc: 73.44
[Train] Epoch: 2 [273024/620022]    Loss: 0.010488   Batch Acc: 68.75
[Train] Epoch: 2 [273088/620022]    Loss: 0.008874   Batch Acc: 73.44
[Train] Epoch: 2 [273152/620022]    Loss: 0.010748   Batch Acc: 73.44
[Train] Epoch: 2 [273216/620022]    Loss: 0.010919   Batch Acc: 78.12
[Train] Epoch: 2 [273280/620022]    Loss: 0.007137   Batch Acc: 87.50
[Train] Epoch: 2 [273344/620022]    Loss: 0.009418   Batch Acc: 75.00
[Train] Epoch: 2 [273408/620022]    Loss: 0.007621   Batch Acc: 79.69
[Train] Epoch: 2 [273472/620022]    Loss: 0.007671   Batch Acc: 81.25
[Train] Epoch: 2 [273536/620022]    Loss: 0.011263   Batch Acc: 71.88
[Train] Epoch: 2 [273600/620022]    Loss: 0.008676   Batch Acc: 78.12
[Train] Epoch: 2 [273664/620022]    Loss: 0.010000   Batch Acc: 78.12
[Train] Epoch: 2 [273728/620022]    Loss: 0.008119   Batch Acc: 79.69
[Train] Epoch: 2 [273792/620022]    Loss: 0.009264   Batch Acc: 76.56
[Train] Epoch: 2 [273856/620022]    Loss: 0.007333   Batch Acc: 81.25
[Train] Epoch: 2 [273920/620022]    Loss: 0.008099   Batch Acc: 84.38
[Train] Epoch: 2 [273984/620022]    Loss: 0.009898   Batch Acc: 76.56
[Train] Epoch: 2 [274048/620022]    Loss: 0.009824   Batch Acc: 73.44
[Train] Epoch: 2 [274112/620022]    Loss: 0.010616   Batch Acc: 76.56
[Train] Epoch: 2 [274176/620022]    Loss: 0.009274   Batch Acc: 71.88
[Train] Epoch: 2 [274240/620022]    Loss: 0.007031   Batch Acc: 82.81
[Train] Epoch: 2 [274304/620022]    Loss: 0.008105   Batch Acc: 81.25
[Train] Epoch: 2 [274368/620022]    Loss: 0.006480   Batch Acc: 85.94
[Train] Epoch: 2 [274432/620022]    Loss: 0.008902   Batch Acc: 78.12
[Train] Epoch: 2 [274496/620022]    Loss: 0.008510   Batch Acc: 78.12
[Train] Epoch: 2 [274560/620022]    Loss: 0.008482   Batch Acc: 82.81
[Train] Epoch: 2 [274624/620022]    Loss: 0.009893   Batch Acc: 78.12
[Train] Epoch: 2 [274688/620022]    Loss: 0.008972   Batch Acc: 73.44
[Train] Epoch: 2 [274752/620022]    Loss: 0.007844   Batch Acc: 81.25
[Train] Epoch: 2 [274816/620022]    Loss: 0.008344   Batch Acc: 82.81
[Train] Epoch: 2 [274880/620022]    Loss: 0.010555   Batch Acc: 73.44
[Train] Epoch: 2 [274944/620022]    Loss: 0.008684   Batch Acc: 79.69
[Train] Epoch: 2 [275008/620022]    Loss: 0.008109   Batch Acc: 81.25
[Train] Epoch: 2 [275072/620022]    Loss: 0.009342   Batch Acc: 76.56
[Train] Epoch: 2 [275136/620022]    Loss: 0.008734   Batch Acc: 76.56
[Train] Epoch: 2 [275200/620022]    Loss: 0.011631   Batch Acc: 67.19
[Train] Epoch: 2 [275264/620022]    Loss: 0.009896   Batch Acc: 75.00
[Train] Epoch: 2 [275328/620022]    Loss: 0.011249   Batch Acc: 71.88
[Train] Epoch: 2 [275392/620022]    Loss: 0.008151   Batch Acc: 82.81
[Train] Epoch: 2 [275456/620022]    Loss: 0.009806   Batch Acc: 75.00
[Train] Epoch: 2 [275520/620022]    Loss: 0.008814   Batch Acc: 79.69
[Train] Epoch: 2 [275584/620022]    Loss: 0.006666   Batch Acc: 82.81
[Train] Epoch: 2 [275648/620022]    Loss: 0.008103   Batch Acc: 79.69
[Train] Epoch: 2 [275712/620022]    Loss: 0.007157   Batch Acc: 84.38
[Train] Epoch: 2 [275776/620022]    Loss: 0.005990   Batch Acc: 87.50
[Train] Epoch: 2 [275840/620022]    Loss: 0.009311   Batch Acc: 75.00
[Train] Epoch: 2 [275904/620022]    Loss: 0.007592   Batch Acc: 82.81
[Train] Epoch: 2 [275968/620022]    Loss: 0.006815   Batch Acc: 87.50
[Train] Epoch: 2 [276032/620022]    Loss: 0.008785   Batch Acc: 81.25
[Train] Epoch: 2 [276096/620022]    Loss: 0.006444   Batch Acc: 87.50
[Train] Epoch: 2 [276160/620022]    Loss: 0.009893   Batch Acc: 67.19
[Train] Epoch: 2 [276224/620022]    Loss: 0.008293   Batch Acc: 85.94
[Train] Epoch: 2 [276288/620022]    Loss: 0.008473   Batch Acc: 79.69
[Train] Epoch: 2 [276352/620022]    Loss: 0.008929   Batch Acc: 73.44
[Train] Epoch: 2 [276416/620022]    Loss: 0.008460   Batch Acc: 78.12
[Train] Epoch: 2 [276480/620022]    Loss: 0.008379   Batch Acc: 82.81
[Train] Epoch: 2 [276544/620022]    Loss: 0.012040   Batch Acc: 62.50
[Train] Epoch: 2 [276608/620022]    Loss: 0.008292   Batch Acc: 81.25
[Train] Epoch: 2 [276672/620022]    Loss: 0.009931   Batch Acc: 76.56
[Train] Epoch: 2 [276736/620022]    Loss: 0.009575   Batch Acc: 73.44
[Train] Epoch: 2 [276800/620022]    Loss: 0.007450   Batch Acc: 85.94
[Train] Epoch: 2 [276864/620022]    Loss: 0.010033   Batch Acc: 65.62
[Train] Epoch: 2 [276928/620022]    Loss: 0.005693   Batch Acc: 93.75
[Train] Epoch: 2 [276992/620022]    Loss: 0.008035   Batch Acc: 82.81
[Train] Epoch: 2 [277056/620022]    Loss: 0.009117   Batch Acc: 71.88
[Train] Epoch: 2 [277120/620022]    Loss: 0.008020   Batch Acc: 84.38
[Train] Epoch: 2 [277184/620022]    Loss: 0.007263   Batch Acc: 82.81
[Train] Epoch: 2 [277248/620022]    Loss: 0.007194   Batch Acc: 81.25
[Train] Epoch: 2 [277312/620022]    Loss: 0.009538   Batch Acc: 76.56
[Train] Epoch: 2 [277376/620022]    Loss: 0.006588   Batch Acc: 82.81
[Train] Epoch: 2 [277440/620022]    Loss: 0.009153   Batch Acc: 75.00
[Train] Epoch: 2 [277504/620022]    Loss: 0.010111   Batch Acc: 70.31
[Train] Epoch: 2 [277568/620022]    Loss: 0.007164   Batch Acc: 82.81
[Train] Epoch: 2 [277632/620022]    Loss: 0.009250   Batch Acc: 75.00
[Train] Epoch: 2 [277696/620022]    Loss: 0.007669   Batch Acc: 84.38
[Train] Epoch: 2 [277760/620022]    Loss: 0.009694   Batch Acc: 78.12
[Train] Epoch: 2 [277824/620022]    Loss: 0.010602   Batch Acc: 73.44
[Train] Epoch: 2 [277888/620022]    Loss: 0.007162   Batch Acc: 82.81
[Train] Epoch: 2 [277952/620022]    Loss: 0.011735   Batch Acc: 68.75
[Train] Epoch: 2 [278016/620022]    Loss: 0.010119   Batch Acc: 76.56
[Train] Epoch: 2 [278080/620022]    Loss: 0.007332   Batch Acc: 82.81
[Train] Epoch: 2 [278144/620022]    Loss: 0.009846   Batch Acc: 75.00
[Train] Epoch: 2 [278208/620022]    Loss: 0.008969   Batch Acc: 71.88
[Train] Epoch: 2 [278272/620022]    Loss: 0.009184   Batch Acc: 73.44
[Train] Epoch: 2 [278336/620022]    Loss: 0.008320   Batch Acc: 79.69
[Train] Epoch: 2 [278400/620022]    Loss: 0.007458   Batch Acc: 87.50
[Train] Epoch: 2 [278464/620022]    Loss: 0.008484   Batch Acc: 78.12
[Train] Epoch: 2 [278528/620022]    Loss: 0.011366   Batch Acc: 68.75
[Train] Epoch: 2 [278592/620022]    Loss: 0.008430   Batch Acc: 79.69
[Train] Epoch: 2 [278656/620022]    Loss: 0.006201   Batch Acc: 85.94
[Train] Epoch: 2 [278720/620022]    Loss: 0.006819   Batch Acc: 89.06
[Train] Epoch: 2 [278784/620022]    Loss: 0.009672   Batch Acc: 71.88
[Train] Epoch: 2 [278848/620022]    Loss: 0.011222   Batch Acc: 68.75
[Train] Epoch: 2 [278912/620022]    Loss: 0.009322   Batch Acc: 75.00
[Train] Epoch: 2 [278976/620022]    Loss: 0.008726   Batch Acc: 85.94
[Train] Epoch: 2 [279040/620022]    Loss: 0.010794   Batch Acc: 70.31
[Train] Epoch: 2 [279104/620022]    Loss: 0.007277   Batch Acc: 81.25
[Train] Epoch: 2 [279168/620022]    Loss: 0.008698   Batch Acc: 76.56
[Train] Epoch: 2 [279232/620022]    Loss: 0.009835   Batch Acc: 73.44
[Train] Epoch: 2 [279296/620022]    Loss: 0.008749   Batch Acc: 76.56
[Train] Epoch: 2 [279360/620022]    Loss: 0.009279   Batch Acc: 75.00
[Train] Epoch: 2 [279424/620022]    Loss: 0.007746   Batch Acc: 84.38
[Train] Epoch: 2 [279488/620022]    Loss: 0.009265   Batch Acc: 73.44
[Train] Epoch: 2 [279552/620022]    Loss: 0.008732   Batch Acc: 78.12
[Train] Epoch: 2 [279616/620022]    Loss: 0.007383   Batch Acc: 79.69
[Train] Epoch: 2 [279680/620022]    Loss: 0.008384   Batch Acc: 78.12
[Train] Epoch: 2 [279744/620022]    Loss: 0.007613   Batch Acc: 82.81
[Train] Epoch: 2 [279808/620022]    Loss: 0.007253   Batch Acc: 85.94
[Train] Epoch: 2 [279872/620022]    Loss: 0.006120   Batch Acc: 89.06
[Train] Epoch: 2 [279936/620022]    Loss: 0.011427   Batch Acc: 71.88
[Train] Epoch: 2 [280000/620022]    Loss: 0.011793   Batch Acc: 60.94
[Train] Epoch: 2 [280064/620022]    Loss: 0.006481   Batch Acc: 84.38
[Train] Epoch: 2 [280128/620022]    Loss: 0.007312   Batch Acc: 84.38
[Train] Epoch: 2 [280192/620022]    Loss: 0.010053   Batch Acc: 76.56
[Train] Epoch: 2 [280256/620022]    Loss: 0.008336   Batch Acc: 79.69
[Train] Epoch: 2 [280320/620022]    Loss: 0.010719   Batch Acc: 65.62
[Train] Epoch: 2 [280384/620022]    Loss: 0.009876   Batch Acc: 71.88
[Train] Epoch: 2 [280448/620022]    Loss: 0.007478   Batch Acc: 81.25
[Train] Epoch: 2 [280512/620022]    Loss: 0.006729   Batch Acc: 81.25
[Train] Epoch: 2 [280576/620022]    Loss: 0.008449   Batch Acc: 79.69
[Train] Epoch: 2 [280640/620022]    Loss: 0.009571   Batch Acc: 78.12
[Train] Epoch: 2 [280704/620022]    Loss: 0.007430   Batch Acc: 81.25
[Train] Epoch: 2 [280768/620022]    Loss: 0.009128   Batch Acc: 78.12
[Train] Epoch: 2 [280832/620022]    Loss: 0.006464   Batch Acc: 85.94
[Train] Epoch: 2 [280896/620022]    Loss: 0.009040   Batch Acc: 76.56
[Train] Epoch: 2 [280960/620022]    Loss: 0.009783   Batch Acc: 79.69
[Train] Epoch: 2 [281024/620022]    Loss: 0.008432   Batch Acc: 78.12
[Train] Epoch: 2 [281088/620022]    Loss: 0.007014   Batch Acc: 81.25
[Train] Epoch: 2 [281152/620022]    Loss: 0.009947   Batch Acc: 67.19
[Train] Epoch: 2 [281216/620022]    Loss: 0.007804   Batch Acc: 84.38
[Train] Epoch: 2 [281280/620022]    Loss: 0.009260   Batch Acc: 76.56
[Train] Epoch: 2 [281344/620022]    Loss: 0.008800   Batch Acc: 76.56
[Train] Epoch: 2 [281408/620022]    Loss: 0.009552   Batch Acc: 76.56
[Train] Epoch: 2 [281472/620022]    Loss: 0.007982   Batch Acc: 84.38
[Train] Epoch: 2 [281536/620022]    Loss: 0.007327   Batch Acc: 78.12
[Train] Epoch: 2 [281600/620022]    Loss: 0.009441   Batch Acc: 73.44
[Train] Epoch: 2 [281664/620022]    Loss: 0.011297   Batch Acc: 67.19
[Train] Epoch: 2 [281728/620022]    Loss: 0.009126   Batch Acc: 79.69
[Train] Epoch: 2 [281792/620022]    Loss: 0.008452   Batch Acc: 81.25
[Train] Epoch: 2 [281856/620022]    Loss: 0.009592   Batch Acc: 78.12
[Train] Epoch: 2 [281920/620022]    Loss: 0.009068   Batch Acc: 68.75
[Train] Epoch: 2 [281984/620022]    Loss: 0.006032   Batch Acc: 89.06
[Train] Epoch: 2 [282048/620022]    Loss: 0.008200   Batch Acc: 79.69
[Train] Epoch: 2 [282112/620022]    Loss: 0.005318   Batch Acc: 87.50
[Train] Epoch: 2 [282176/620022]    Loss: 0.008126   Batch Acc: 79.69
[Train] Epoch: 2 [282240/620022]    Loss: 0.008775   Batch Acc: 76.56
[Train] Epoch: 2 [282304/620022]    Loss: 0.009371   Batch Acc: 73.44
[Train] Epoch: 2 [282368/620022]    Loss: 0.008357   Batch Acc: 76.56
[Train] Epoch: 2 [282432/620022]    Loss: 0.010419   Batch Acc: 78.12
[Train] Epoch: 2 [282496/620022]    Loss: 0.007261   Batch Acc: 84.38
[Train] Epoch: 2 [282560/620022]    Loss: 0.007838   Batch Acc: 84.38
[Train] Epoch: 2 [282624/620022]    Loss: 0.007914   Batch Acc: 79.69
[Train] Epoch: 2 [282688/620022]    Loss: 0.007654   Batch Acc: 81.25
[Train] Epoch: 2 [282752/620022]    Loss: 0.008679   Batch Acc: 71.88
[Train] Epoch: 2 [282816/620022]    Loss: 0.008445   Batch Acc: 79.69
[Train] Epoch: 2 [282880/620022]    Loss: 0.009484   Batch Acc: 73.44
[Train] Epoch: 2 [282944/620022]    Loss: 0.008326   Batch Acc: 81.25
[Train] Epoch: 2 [283008/620022]    Loss: 0.008655   Batch Acc: 78.12
[Train] Epoch: 2 [283072/620022]    Loss: 0.007405   Batch Acc: 76.56
[Train] Epoch: 2 [283136/620022]    Loss: 0.011719   Batch Acc: 65.62
[Train] Epoch: 2 [283200/620022]    Loss: 0.010257   Batch Acc: 79.69
[Train] Epoch: 2 [283264/620022]    Loss: 0.007534   Batch Acc: 84.38
[Train] Epoch: 2 [283328/620022]    Loss: 0.009231   Batch Acc: 78.12
[Train] Epoch: 2 [283392/620022]    Loss: 0.009334   Batch Acc: 78.12
[Train] Epoch: 2 [283456/620022]    Loss: 0.007381   Batch Acc: 79.69
[Train] Epoch: 2 [283520/620022]    Loss: 0.008729   Batch Acc: 82.81
[Train] Epoch: 2 [283584/620022]    Loss: 0.008690   Batch Acc: 75.00
[Train] Epoch: 2 [283648/620022]    Loss: 0.005950   Batch Acc: 87.50
[Train] Epoch: 2 [283712/620022]    Loss: 0.007119   Batch Acc: 81.25
[Train] Epoch: 2 [283776/620022]    Loss: 0.008153   Batch Acc: 79.69
[Train] Epoch: 2 [283840/620022]    Loss: 0.010158   Batch Acc: 75.00
[Train] Epoch: 2 [283904/620022]    Loss: 0.008745   Batch Acc: 71.88
[Train] Epoch: 2 [283968/620022]    Loss: 0.007749   Batch Acc: 87.50
[Train] Epoch: 2 [284032/620022]    Loss: 0.008946   Batch Acc: 81.25
[Train] Epoch: 2 [284096/620022]    Loss: 0.006721   Batch Acc: 82.81
[Train] Epoch: 2 [284160/620022]    Loss: 0.010573   Batch Acc: 67.19
[Train] Epoch: 2 [284224/620022]    Loss: 0.008528   Batch Acc: 70.31
[Train] Epoch: 2 [284288/620022]    Loss: 0.007845   Batch Acc: 81.25
[Train] Epoch: 2 [284352/620022]    Loss: 0.009085   Batch Acc: 73.44
[Train] Epoch: 2 [284416/620022]    Loss: 0.007399   Batch Acc: 81.25
[Train] Epoch: 2 [284480/620022]    Loss: 0.009050   Batch Acc: 70.31
[Train] Epoch: 2 [284544/620022]    Loss: 0.010717   Batch Acc: 70.31
[Train] Epoch: 2 [284608/620022]    Loss: 0.006808   Batch Acc: 82.81
[Train] Epoch: 2 [284672/620022]    Loss: 0.007919   Batch Acc: 84.38
[Train] Epoch: 2 [284736/620022]    Loss: 0.009003   Batch Acc: 68.75
[Train] Epoch: 2 [284800/620022]    Loss: 0.009827   Batch Acc: 73.44
[Train] Epoch: 2 [284864/620022]    Loss: 0.009357   Batch Acc: 79.69
[Train] Epoch: 2 [284928/620022]    Loss: 0.008961   Batch Acc: 78.12
[Train] Epoch: 2 [284992/620022]    Loss: 0.008136   Batch Acc: 82.81
[Train] Epoch: 2 [285056/620022]    Loss: 0.010042   Batch Acc: 71.88
[Train] Epoch: 2 [285120/620022]    Loss: 0.009868   Batch Acc: 67.19
[Train] Epoch: 2 [285184/620022]    Loss: 0.009317   Batch Acc: 76.56
[Train] Epoch: 2 [285248/620022]    Loss: 0.008573   Batch Acc: 82.81
[Train] Epoch: 2 [285312/620022]    Loss: 0.006982   Batch Acc: 89.06
[Train] Epoch: 2 [285376/620022]    Loss: 0.009135   Batch Acc: 79.69
[Train] Epoch: 2 [285440/620022]    Loss: 0.008962   Batch Acc: 73.44
[Train] Epoch: 2 [285504/620022]    Loss: 0.008179   Batch Acc: 78.12
[Train] Epoch: 2 [285568/620022]    Loss: 0.008591   Batch Acc: 81.25
[Train] Epoch: 2 [285632/620022]    Loss: 0.008925   Batch Acc: 73.44
[Train] Epoch: 2 [285696/620022]    Loss: 0.008195   Batch Acc: 75.00
[Train] Epoch: 2 [285760/620022]    Loss: 0.008194   Batch Acc: 78.12
[Train] Epoch: 2 [285824/620022]    Loss: 0.007700   Batch Acc: 82.81
[Train] Epoch: 2 [285888/620022]    Loss: 0.010014   Batch Acc: 70.31
[Train] Epoch: 2 [285952/620022]    Loss: 0.007932   Batch Acc: 85.94
[Train] Epoch: 2 [286016/620022]    Loss: 0.007713   Batch Acc: 81.25
[Train] Epoch: 2 [286080/620022]    Loss: 0.010674   Batch Acc: 73.44
[Train] Epoch: 2 [286144/620022]    Loss: 0.008375   Batch Acc: 78.12
[Train] Epoch: 2 [286208/620022]    Loss: 0.011775   Batch Acc: 73.44
[Train] Epoch: 2 [286272/620022]    Loss: 0.009403   Batch Acc: 73.44
[Train] Epoch: 2 [286336/620022]    Loss: 0.009164   Batch Acc: 78.12
[Train] Epoch: 2 [286400/620022]    Loss: 0.006129   Batch Acc: 84.38
[Train] Epoch: 2 [286464/620022]    Loss: 0.006796   Batch Acc: 82.81
[Train] Epoch: 2 [286528/620022]    Loss: 0.008556   Batch Acc: 79.69
[Train] Epoch: 2 [286592/620022]    Loss: 0.008553   Batch Acc: 78.12
[Train] Epoch: 2 [286656/620022]    Loss: 0.007579   Batch Acc: 81.25
[Train] Epoch: 2 [286720/620022]    Loss: 0.008121   Batch Acc: 73.44
[Train] Epoch: 2 [286784/620022]    Loss: 0.009105   Batch Acc: 71.88
[Train] Epoch: 2 [286848/620022]    Loss: 0.009371   Batch Acc: 71.88
[Train] Epoch: 2 [286912/620022]    Loss: 0.008833   Batch Acc: 79.69
[Train] Epoch: 2 [286976/620022]    Loss: 0.009429   Batch Acc: 70.31
[Train] Epoch: 2 [287040/620022]    Loss: 0.008697   Batch Acc: 76.56
[Train] Epoch: 2 [287104/620022]    Loss: 0.008556   Batch Acc: 78.12
[Train] Epoch: 2 [287168/620022]    Loss: 0.006858   Batch Acc: 84.38
[Train] Epoch: 2 [287232/620022]    Loss: 0.007890   Batch Acc: 84.38
[Train] Epoch: 2 [287296/620022]    Loss: 0.006383   Batch Acc: 89.06
[Train] Epoch: 2 [287360/620022]    Loss: 0.007735   Batch Acc: 82.81
[Train] Epoch: 2 [287424/620022]    Loss: 0.011061   Batch Acc: 71.88
[Train] Epoch: 2 [287488/620022]    Loss: 0.008391   Batch Acc: 78.12
[Train] Epoch: 2 [287552/620022]    Loss: 0.009073   Batch Acc: 75.00
[Train] Epoch: 2 [287616/620022]    Loss: 0.008817   Batch Acc: 79.69
[Train] Epoch: 2 [287680/620022]    Loss: 0.009785   Batch Acc: 81.25
[Train] Epoch: 2 [287744/620022]    Loss: 0.011515   Batch Acc: 67.19
[Train] Epoch: 2 [287808/620022]    Loss: 0.007897   Batch Acc: 79.69
[Train] Epoch: 2 [287872/620022]    Loss: 0.007804   Batch Acc: 81.25
[Train] Epoch: 2 [287936/620022]    Loss: 0.006659   Batch Acc: 82.81
[Train] Epoch: 2 [288000/620022]    Loss: 0.008799   Batch Acc: 79.69
[Train] Epoch: 2 [288064/620022]    Loss: 0.007982   Batch Acc: 84.38
[Train] Epoch: 2 [288128/620022]    Loss: 0.007943   Batch Acc: 81.25
[Train] Epoch: 2 [288192/620022]    Loss: 0.006259   Batch Acc: 82.81
[Train] Epoch: 2 [288256/620022]    Loss: 0.009670   Batch Acc: 75.00
[Train] Epoch: 2 [288320/620022]    Loss: 0.005840   Batch Acc: 87.50
[Train] Epoch: 2 [288384/620022]    Loss: 0.006669   Batch Acc: 84.38
[Train] Epoch: 2 [288448/620022]    Loss: 0.008123   Batch Acc: 81.25
[Train] Epoch: 2 [288512/620022]    Loss: 0.007439   Batch Acc: 81.25
[Train] Epoch: 2 [288576/620022]    Loss: 0.006375   Batch Acc: 87.50
[Train] Epoch: 2 [288640/620022]    Loss: 0.007053   Batch Acc: 85.94
[Train] Epoch: 2 [288704/620022]    Loss: 0.008387   Batch Acc: 85.94
[Train] Epoch: 2 [288768/620022]    Loss: 0.008222   Batch Acc: 79.69
[Train] Epoch: 2 [288832/620022]    Loss: 0.008064   Batch Acc: 79.69
[Train] Epoch: 2 [288896/620022]    Loss: 0.007278   Batch Acc: 82.81
[Train] Epoch: 2 [288960/620022]    Loss: 0.013027   Batch Acc: 60.94
[Train] Epoch: 2 [289024/620022]    Loss: 0.006142   Batch Acc: 89.06
[Train] Epoch: 2 [289088/620022]    Loss: 0.007291   Batch Acc: 78.12
[Train] Epoch: 2 [289152/620022]    Loss: 0.009956   Batch Acc: 78.12
[Train] Epoch: 2 [289216/620022]    Loss: 0.008625   Batch Acc: 73.44
[Train] Epoch: 2 [289280/620022]    Loss: 0.006763   Batch Acc: 85.94
[Train] Epoch: 2 [289344/620022]    Loss: 0.009601   Batch Acc: 75.00
[Train] Epoch: 2 [289408/620022]    Loss: 0.009325   Batch Acc: 75.00
[Train] Epoch: 2 [289472/620022]    Loss: 0.011005   Batch Acc: 68.75
[Train] Epoch: 2 [289536/620022]    Loss: 0.008514   Batch Acc: 82.81
[Train] Epoch: 2 [289600/620022]    Loss: 0.009673   Batch Acc: 78.12
[Train] Epoch: 2 [289664/620022]    Loss: 0.009402   Batch Acc: 76.56
[Train] Epoch: 2 [289728/620022]    Loss: 0.009293   Batch Acc: 76.56
[Train] Epoch: 2 [289792/620022]    Loss: 0.006348   Batch Acc: 87.50
[Train] Epoch: 2 [289856/620022]    Loss: 0.006081   Batch Acc: 85.94
[Train] Epoch: 2 [289920/620022]    Loss: 0.008302   Batch Acc: 79.69
[Train] Epoch: 2 [289984/620022]    Loss: 0.008295   Batch Acc: 75.00
[Train] Epoch: 2 [290048/620022]    Loss: 0.008175   Batch Acc: 78.12
[Train] Epoch: 2 [290112/620022]    Loss: 0.007026   Batch Acc: 82.81
[Train] Epoch: 2 [290176/620022]    Loss: 0.010494   Batch Acc: 76.56
[Train] Epoch: 2 [290240/620022]    Loss: 0.006617   Batch Acc: 87.50
[Train] Epoch: 2 [290304/620022]    Loss: 0.007892   Batch Acc: 75.00
[Train] Epoch: 2 [290368/620022]    Loss: 0.009257   Batch Acc: 81.25
[Train] Epoch: 2 [290432/620022]    Loss: 0.009240   Batch Acc: 65.62
[Train] Epoch: 2 [290496/620022]    Loss: 0.009674   Batch Acc: 76.56
[Train] Epoch: 2 [290560/620022]    Loss: 0.007813   Batch Acc: 84.38
[Train] Epoch: 2 [290624/620022]    Loss: 0.008004   Batch Acc: 81.25
[Train] Epoch: 2 [290688/620022]    Loss: 0.009569   Batch Acc: 71.88
[Train] Epoch: 2 [290752/620022]    Loss: 0.009976   Batch Acc: 67.19
[Train] Epoch: 2 [290816/620022]    Loss: 0.010763   Batch Acc: 62.50
[Train] Epoch: 2 [290880/620022]    Loss: 0.009806   Batch Acc: 79.69
[Train] Epoch: 2 [290944/620022]    Loss: 0.008509   Batch Acc: 79.69
[Train] Epoch: 2 [291008/620022]    Loss: 0.010159   Batch Acc: 68.75
[Train] Epoch: 2 [291072/620022]    Loss: 0.009940   Batch Acc: 82.81
[Train] Epoch: 2 [291136/620022]    Loss: 0.007717   Batch Acc: 81.25
[Train] Epoch: 2 [291200/620022]    Loss: 0.008323   Batch Acc: 81.25
[Train] Epoch: 2 [291264/620022]    Loss: 0.007155   Batch Acc: 81.25
[Train] Epoch: 2 [291328/620022]    Loss: 0.008835   Batch Acc: 78.12
[Train] Epoch: 2 [291392/620022]    Loss: 0.009519   Batch Acc: 71.88
[Train] Epoch: 2 [291456/620022]    Loss: 0.009473   Batch Acc: 75.00
[Train] Epoch: 2 [291520/620022]    Loss: 0.009769   Batch Acc: 70.31
[Train] Epoch: 2 [291584/620022]    Loss: 0.006371   Batch Acc: 84.38
[Train] Epoch: 2 [291648/620022]    Loss: 0.008578   Batch Acc: 79.69
[Train] Epoch: 2 [291712/620022]    Loss: 0.009028   Batch Acc: 78.12
[Train] Epoch: 2 [291776/620022]    Loss: 0.010229   Batch Acc: 73.44
[Train] Epoch: 2 [291840/620022]    Loss: 0.006831   Batch Acc: 81.25
[Train] Epoch: 2 [291904/620022]    Loss: 0.008238   Batch Acc: 81.25
[Train] Epoch: 2 [291968/620022]    Loss: 0.009704   Batch Acc: 76.56
[Train] Epoch: 2 [292032/620022]    Loss: 0.007993   Batch Acc: 78.12
[Train] Epoch: 2 [292096/620022]    Loss: 0.007077   Batch Acc: 82.81
[Train] Epoch: 2 [292160/620022]    Loss: 0.011715   Batch Acc: 67.19
[Train] Epoch: 2 [292224/620022]    Loss: 0.006754   Batch Acc: 79.69
[Train] Epoch: 2 [292288/620022]    Loss: 0.010695   Batch Acc: 73.44
[Train] Epoch: 2 [292352/620022]    Loss: 0.007628   Batch Acc: 76.56
[Train] Epoch: 2 [292416/620022]    Loss: 0.010493   Batch Acc: 67.19
[Train] Epoch: 2 [292480/620022]    Loss: 0.009563   Batch Acc: 78.12
[Train] Epoch: 2 [292544/620022]    Loss: 0.007224   Batch Acc: 79.69
[Train] Epoch: 2 [292608/620022]    Loss: 0.012181   Batch Acc: 64.06
[Train] Epoch: 2 [292672/620022]    Loss: 0.009894   Batch Acc: 76.56
[Train] Epoch: 2 [292736/620022]    Loss: 0.010360   Batch Acc: 67.19
[Train] Epoch: 2 [292800/620022]    Loss: 0.009487   Batch Acc: 82.81
[Train] Epoch: 2 [292864/620022]    Loss: 0.007629   Batch Acc: 81.25
[Train] Epoch: 2 [292928/620022]    Loss: 0.011642   Batch Acc: 75.00
[Train] Epoch: 2 [292992/620022]    Loss: 0.011677   Batch Acc: 71.88
[Train] Epoch: 2 [293056/620022]    Loss: 0.006934   Batch Acc: 82.81
[Train] Epoch: 2 [293120/620022]    Loss: 0.009889   Batch Acc: 73.44
[Train] Epoch: 2 [293184/620022]    Loss: 0.010333   Batch Acc: 79.69
[Train] Epoch: 2 [293248/620022]    Loss: 0.008705   Batch Acc: 75.00
[Train] Epoch: 2 [293312/620022]    Loss: 0.009589   Batch Acc: 76.56
[Train] Epoch: 2 [293376/620022]    Loss: 0.009087   Batch Acc: 78.12
[Train] Epoch: 2 [293440/620022]    Loss: 0.007556   Batch Acc: 78.12
[Train] Epoch: 2 [293504/620022]    Loss: 0.007992   Batch Acc: 81.25
[Train] Epoch: 2 [293568/620022]    Loss: 0.008465   Batch Acc: 76.56
[Train] Epoch: 2 [293632/620022]    Loss: 0.008775   Batch Acc: 79.69
[Train] Epoch: 2 [293696/620022]    Loss: 0.008554   Batch Acc: 78.12
[Train] Epoch: 2 [293760/620022]    Loss: 0.008787   Batch Acc: 70.31
[Train] Epoch: 2 [293824/620022]    Loss: 0.008473   Batch Acc: 79.69
[Train] Epoch: 2 [293888/620022]    Loss: 0.007597   Batch Acc: 81.25
[Train] Epoch: 2 [293952/620022]    Loss: 0.007902   Batch Acc: 82.81
[Train] Epoch: 2 [294016/620022]    Loss: 0.007085   Batch Acc: 84.38
[Train] Epoch: 2 [294080/620022]    Loss: 0.008316   Batch Acc: 81.25
[Train] Epoch: 2 [294144/620022]    Loss: 0.007742   Batch Acc: 81.25
[Train] Epoch: 2 [294208/620022]    Loss: 0.007020   Batch Acc: 79.69
[Train] Epoch: 2 [294272/620022]    Loss: 0.007202   Batch Acc: 76.56
[Train] Epoch: 2 [294336/620022]    Loss: 0.007318   Batch Acc: 85.94
[Train] Epoch: 2 [294400/620022]    Loss: 0.007729   Batch Acc: 84.38
[Train] Epoch: 2 [294464/620022]    Loss: 0.006796   Batch Acc: 79.69
[Train] Epoch: 2 [294528/620022]    Loss: 0.010461   Batch Acc: 81.25
[Train] Epoch: 2 [294592/620022]    Loss: 0.011566   Batch Acc: 71.88
[Train] Epoch: 2 [294656/620022]    Loss: 0.009451   Batch Acc: 78.12
[Train] Epoch: 2 [294720/620022]    Loss: 0.010033   Batch Acc: 79.69
[Train] Epoch: 2 [294784/620022]    Loss: 0.009658   Batch Acc: 70.31
[Train] Epoch: 2 [294848/620022]    Loss: 0.007749   Batch Acc: 82.81
[Train] Epoch: 2 [294912/620022]    Loss: 0.009342   Batch Acc: 67.19
[Train] Epoch: 2 [294976/620022]    Loss: 0.006832   Batch Acc: 84.38
[Train] Epoch: 2 [295040/620022]    Loss: 0.007118   Batch Acc: 82.81
[Train] Epoch: 2 [295104/620022]    Loss: 0.010608   Batch Acc: 71.88
[Train] Epoch: 2 [295168/620022]    Loss: 0.010583   Batch Acc: 67.19
[Train] Epoch: 2 [295232/620022]    Loss: 0.009600   Batch Acc: 76.56
[Train] Epoch: 2 [295296/620022]    Loss: 0.007776   Batch Acc: 82.81
[Train] Epoch: 2 [295360/620022]    Loss: 0.007236   Batch Acc: 85.94
[Train] Epoch: 2 [295424/620022]    Loss: 0.008731   Batch Acc: 73.44
[Train] Epoch: 2 [295488/620022]    Loss: 0.009720   Batch Acc: 73.44
[Train] Epoch: 2 [295552/620022]    Loss: 0.009589   Batch Acc: 79.69
[Train] Epoch: 2 [295616/620022]    Loss: 0.009027   Batch Acc: 73.44
[Train] Epoch: 2 [295680/620022]    Loss: 0.010826   Batch Acc: 68.75
[Train] Epoch: 2 [295744/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 2 [295808/620022]    Loss: 0.008572   Batch Acc: 78.12
[Train] Epoch: 2 [295872/620022]    Loss: 0.008542   Batch Acc: 79.69
[Train] Epoch: 2 [295936/620022]    Loss: 0.007636   Batch Acc: 79.69
[Train] Epoch: 2 [296000/620022]    Loss: 0.006722   Batch Acc: 84.38
[Train] Epoch: 2 [296064/620022]    Loss: 0.007867   Batch Acc: 82.81
[Train] Epoch: 2 [296128/620022]    Loss: 0.009674   Batch Acc: 75.00
[Train] Epoch: 2 [296192/620022]    Loss: 0.008319   Batch Acc: 82.81
[Train] Epoch: 2 [296256/620022]    Loss: 0.007991   Batch Acc: 79.69
[Train] Epoch: 2 [296320/620022]    Loss: 0.007248   Batch Acc: 79.69
[Train] Epoch: 2 [296384/620022]    Loss: 0.007182   Batch Acc: 85.94
[Train] Epoch: 2 [296448/620022]    Loss: 0.010065   Batch Acc: 78.12
[Train] Epoch: 2 [296512/620022]    Loss: 0.007276   Batch Acc: 82.81
[Train] Epoch: 2 [296576/620022]    Loss: 0.006644   Batch Acc: 79.69
[Train] Epoch: 2 [296640/620022]    Loss: 0.008100   Batch Acc: 84.38
[Train] Epoch: 2 [296704/620022]    Loss: 0.009004   Batch Acc: 78.12
[Train] Epoch: 2 [296768/620022]    Loss: 0.008804   Batch Acc: 84.38
[Train] Epoch: 2 [296832/620022]    Loss: 0.008156   Batch Acc: 76.56
[Train] Epoch: 2 [296896/620022]    Loss: 0.008403   Batch Acc: 73.44
[Train] Epoch: 2 [296960/620022]    Loss: 0.009196   Batch Acc: 78.12
[Train] Epoch: 2 [297024/620022]    Loss: 0.006217   Batch Acc: 82.81
[Train] Epoch: 2 [297088/620022]    Loss: 0.008344   Batch Acc: 76.56
[Train] Epoch: 2 [297152/620022]    Loss: 0.008011   Batch Acc: 79.69
[Train] Epoch: 2 [297216/620022]    Loss: 0.007826   Batch Acc: 76.56
[Train] Epoch: 2 [297280/620022]    Loss: 0.006367   Batch Acc: 87.50
[Train] Epoch: 2 [297344/620022]    Loss: 0.006982   Batch Acc: 79.69
[Train] Epoch: 2 [297408/620022]    Loss: 0.007535   Batch Acc: 82.81
[Train] Epoch: 2 [297472/620022]    Loss: 0.010213   Batch Acc: 76.56
[Train] Epoch: 2 [297536/620022]    Loss: 0.009217   Batch Acc: 73.44
[Train] Epoch: 2 [297600/620022]    Loss: 0.009549   Batch Acc: 73.44
[Train] Epoch: 2 [297664/620022]    Loss: 0.009199   Batch Acc: 76.56
[Train] Epoch: 2 [297728/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 2 [297792/620022]    Loss: 0.007287   Batch Acc: 81.25
[Train] Epoch: 2 [297856/620022]    Loss: 0.007185   Batch Acc: 82.81
[Train] Epoch: 2 [297920/620022]    Loss: 0.007232   Batch Acc: 82.81
[Train] Epoch: 2 [297984/620022]    Loss: 0.011310   Batch Acc: 68.75
[Train] Epoch: 2 [298048/620022]    Loss: 0.009204   Batch Acc: 78.12
[Train] Epoch: 2 [298112/620022]    Loss: 0.009613   Batch Acc: 81.25
[Train] Epoch: 2 [298176/620022]    Loss: 0.008904   Batch Acc: 78.12
[Train] Epoch: 2 [298240/620022]    Loss: 0.008716   Batch Acc: 79.69
[Train] Epoch: 2 [298304/620022]    Loss: 0.009993   Batch Acc: 76.56
[Train] Epoch: 2 [298368/620022]    Loss: 0.009337   Batch Acc: 79.69
[Train] Epoch: 2 [298432/620022]    Loss: 0.007803   Batch Acc: 84.38
[Train] Epoch: 2 [298496/620022]    Loss: 0.007307   Batch Acc: 79.69
[Train] Epoch: 2 [298560/620022]    Loss: 0.009619   Batch Acc: 73.44
[Train] Epoch: 2 [298624/620022]    Loss: 0.007459   Batch Acc: 82.81
[Train] Epoch: 2 [298688/620022]    Loss: 0.006116   Batch Acc: 89.06
[Train] Epoch: 2 [298752/620022]    Loss: 0.008811   Batch Acc: 70.31
[Train] Epoch: 2 [298816/620022]    Loss: 0.007528   Batch Acc: 76.56
[Train] Epoch: 2 [298880/620022]    Loss: 0.010223   Batch Acc: 73.44
[Train] Epoch: 2 [298944/620022]    Loss: 0.007208   Batch Acc: 84.38
[Train] Epoch: 2 [299008/620022]    Loss: 0.008041   Batch Acc: 78.12
[Train] Epoch: 2 [299072/620022]    Loss: 0.008762   Batch Acc: 75.00
[Train] Epoch: 2 [299136/620022]    Loss: 0.005801   Batch Acc: 87.50
[Train] Epoch: 2 [299200/620022]    Loss: 0.006608   Batch Acc: 85.94
[Train] Epoch: 2 [299264/620022]    Loss: 0.006521   Batch Acc: 84.38
[Train] Epoch: 2 [299328/620022]    Loss: 0.006928   Batch Acc: 82.81
[Train] Epoch: 2 [299392/620022]    Loss: 0.011088   Batch Acc: 71.88
[Train] Epoch: 2 [299456/620022]    Loss: 0.010385   Batch Acc: 71.88
[Train] Epoch: 2 [299520/620022]    Loss: 0.008508   Batch Acc: 70.31
[Train] Epoch: 2 [299584/620022]    Loss: 0.008842   Batch Acc: 79.69
[Train] Epoch: 2 [299648/620022]    Loss: 0.007809   Batch Acc: 84.38
[Train] Epoch: 2 [299712/620022]    Loss: 0.008129   Batch Acc: 81.25
[Train] Epoch: 2 [299776/620022]    Loss: 0.005038   Batch Acc: 90.62
[Train] Epoch: 2 [299840/620022]    Loss: 0.007121   Batch Acc: 84.38
[Train] Epoch: 2 [299904/620022]    Loss: 0.009110   Batch Acc: 79.69
[Train] Epoch: 2 [299968/620022]    Loss: 0.007754   Batch Acc: 89.06
[Train] Epoch: 2 [300032/620022]    Loss: 0.010309   Batch Acc: 78.12
[Train] Epoch: 2 [300096/620022]    Loss: 0.007454   Batch Acc: 81.25
[Train] Epoch: 2 [300160/620022]    Loss: 0.006695   Batch Acc: 89.06
[Train] Epoch: 2 [300224/620022]    Loss: 0.007908   Batch Acc: 81.25
[Train] Epoch: 2 [300288/620022]    Loss: 0.007346   Batch Acc: 81.25
[Train] Epoch: 2 [300352/620022]    Loss: 0.010065   Batch Acc: 70.31
[Train] Epoch: 2 [300416/620022]    Loss: 0.007656   Batch Acc: 79.69
[Train] Epoch: 2 [300480/620022]    Loss: 0.010891   Batch Acc: 75.00
[Train] Epoch: 2 [300544/620022]    Loss: 0.006649   Batch Acc: 85.94
[Train] Epoch: 2 [300608/620022]    Loss: 0.010750   Batch Acc: 70.31
[Train] Epoch: 2 [300672/620022]    Loss: 0.009686   Batch Acc: 71.88
[Train] Epoch: 2 [300736/620022]    Loss: 0.008036   Batch Acc: 81.25
[Train] Epoch: 2 [300800/620022]    Loss: 0.010343   Batch Acc: 75.00
[Train] Epoch: 2 [300864/620022]    Loss: 0.007356   Batch Acc: 84.38
[Train] Epoch: 2 [300928/620022]    Loss: 0.009314   Batch Acc: 82.81
[Train] Epoch: 2 [300992/620022]    Loss: 0.007552   Batch Acc: 79.69
[Train] Epoch: 2 [301056/620022]    Loss: 0.010030   Batch Acc: 73.44
[Train] Epoch: 2 [301120/620022]    Loss: 0.008092   Batch Acc: 78.12
[Train] Epoch: 2 [301184/620022]    Loss: 0.010215   Batch Acc: 64.06
[Train] Epoch: 2 [301248/620022]    Loss: 0.008995   Batch Acc: 75.00
[Train] Epoch: 2 [301312/620022]    Loss: 0.007980   Batch Acc: 79.69
[Train] Epoch: 2 [301376/620022]    Loss: 0.006579   Batch Acc: 82.81
[Train] Epoch: 2 [301440/620022]    Loss: 0.010695   Batch Acc: 76.56
[Train] Epoch: 2 [301504/620022]    Loss: 0.006860   Batch Acc: 79.69
[Train] Epoch: 2 [301568/620022]    Loss: 0.008255   Batch Acc: 73.44
[Train] Epoch: 2 [301632/620022]    Loss: 0.007976   Batch Acc: 81.25
[Train] Epoch: 2 [301696/620022]    Loss: 0.007501   Batch Acc: 81.25
[Train] Epoch: 2 [301760/620022]    Loss: 0.009710   Batch Acc: 71.88
[Train] Epoch: 2 [301824/620022]    Loss: 0.007729   Batch Acc: 82.81
[Train] Epoch: 2 [301888/620022]    Loss: 0.008396   Batch Acc: 73.44
[Train] Epoch: 2 [301952/620022]    Loss: 0.007903   Batch Acc: 82.81
[Train] Epoch: 2 [302016/620022]    Loss: 0.009613   Batch Acc: 75.00
[Train] Epoch: 2 [302080/620022]    Loss: 0.010024   Batch Acc: 70.31
[Train] Epoch: 2 [302144/620022]    Loss: 0.011931   Batch Acc: 68.75
[Train] Epoch: 2 [302208/620022]    Loss: 0.007490   Batch Acc: 84.38
[Train] Epoch: 2 [302272/620022]    Loss: 0.008124   Batch Acc: 81.25
[Train] Epoch: 2 [302336/620022]    Loss: 0.009239   Batch Acc: 71.88
[Train] Epoch: 2 [302400/620022]    Loss: 0.011093   Batch Acc: 75.00
[Train] Epoch: 2 [302464/620022]    Loss: 0.009714   Batch Acc: 76.56
[Train] Epoch: 2 [302528/620022]    Loss: 0.007296   Batch Acc: 85.94
[Train] Epoch: 2 [302592/620022]    Loss: 0.010030   Batch Acc: 70.31
[Train] Epoch: 2 [302656/620022]    Loss: 0.007733   Batch Acc: 79.69
[Train] Epoch: 2 [302720/620022]    Loss: 0.007799   Batch Acc: 81.25
[Train] Epoch: 2 [302784/620022]    Loss: 0.007194   Batch Acc: 81.25
[Train] Epoch: 2 [302848/620022]    Loss: 0.010198   Batch Acc: 75.00
[Train] Epoch: 2 [302912/620022]    Loss: 0.008852   Batch Acc: 82.81
[Train] Epoch: 2 [302976/620022]    Loss: 0.010815   Batch Acc: 65.62
[Train] Epoch: 2 [303040/620022]    Loss: 0.008608   Batch Acc: 73.44
[Train] Epoch: 2 [303104/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 2 [303168/620022]    Loss: 0.008165   Batch Acc: 78.12
[Train] Epoch: 2 [303232/620022]    Loss: 0.008434   Batch Acc: 81.25
[Train] Epoch: 2 [303296/620022]    Loss: 0.005855   Batch Acc: 89.06
[Train] Epoch: 2 [303360/620022]    Loss: 0.009734   Batch Acc: 78.12
[Train] Epoch: 2 [303424/620022]    Loss: 0.008413   Batch Acc: 71.88
[Train] Epoch: 2 [303488/620022]    Loss: 0.008092   Batch Acc: 84.38
[Train] Epoch: 2 [303552/620022]    Loss: 0.008740   Batch Acc: 78.12
[Train] Epoch: 2 [303616/620022]    Loss: 0.008127   Batch Acc: 76.56
[Train] Epoch: 2 [303680/620022]    Loss: 0.009532   Batch Acc: 75.00
[Train] Epoch: 2 [303744/620022]    Loss: 0.011490   Batch Acc: 68.75
[Train] Epoch: 2 [303808/620022]    Loss: 0.009015   Batch Acc: 78.12
[Train] Epoch: 2 [303872/620022]    Loss: 0.009983   Batch Acc: 73.44
[Train] Epoch: 2 [303936/620022]    Loss: 0.007234   Batch Acc: 85.94
[Train] Epoch: 2 [304000/620022]    Loss: 0.008196   Batch Acc: 75.00
[Train] Epoch: 2 [304064/620022]    Loss: 0.009525   Batch Acc: 81.25
[Train] Epoch: 2 [304128/620022]    Loss: 0.009259   Batch Acc: 76.56
[Train] Epoch: 2 [304192/620022]    Loss: 0.007817   Batch Acc: 82.81
[Train] Epoch: 2 [304256/620022]    Loss: 0.008471   Batch Acc: 75.00
[Train] Epoch: 2 [304320/620022]    Loss: 0.007370   Batch Acc: 82.81
[Train] Epoch: 2 [304384/620022]    Loss: 0.008368   Batch Acc: 76.56
[Train] Epoch: 2 [304448/620022]    Loss: 0.006781   Batch Acc: 84.38
[Train] Epoch: 2 [304512/620022]    Loss: 0.009031   Batch Acc: 76.56
[Train] Epoch: 2 [304576/620022]    Loss: 0.007014   Batch Acc: 81.25
[Train] Epoch: 2 [304640/620022]    Loss: 0.009351   Batch Acc: 75.00
[Train] Epoch: 2 [304704/620022]    Loss: 0.006070   Batch Acc: 87.50
[Train] Epoch: 2 [304768/620022]    Loss: 0.010328   Batch Acc: 73.44
[Train] Epoch: 2 [304832/620022]    Loss: 0.007788   Batch Acc: 81.25
[Train] Epoch: 2 [304896/620022]    Loss: 0.007737   Batch Acc: 82.81
[Train] Epoch: 2 [304960/620022]    Loss: 0.007778   Batch Acc: 82.81
[Train] Epoch: 2 [305024/620022]    Loss: 0.008296   Batch Acc: 79.69
[Train] Epoch: 2 [305088/620022]    Loss: 0.007810   Batch Acc: 79.69
[Train] Epoch: 2 [305152/620022]    Loss: 0.008987   Batch Acc: 76.56
[Train] Epoch: 2 [305216/620022]    Loss: 0.007480   Batch Acc: 81.25
[Train] Epoch: 2 [305280/620022]    Loss: 0.008573   Batch Acc: 71.88
[Train] Epoch: 2 [305344/620022]    Loss: 0.009820   Batch Acc: 79.69
[Train] Epoch: 2 [305408/620022]    Loss: 0.007004   Batch Acc: 82.81
[Train] Epoch: 2 [305472/620022]    Loss: 0.010620   Batch Acc: 76.56
[Train] Epoch: 2 [305536/620022]    Loss: 0.007014   Batch Acc: 84.38
[Train] Epoch: 2 [305600/620022]    Loss: 0.007929   Batch Acc: 84.38
[Train] Epoch: 2 [305664/620022]    Loss: 0.007155   Batch Acc: 82.81
[Train] Epoch: 2 [305728/620022]    Loss: 0.009469   Batch Acc: 76.56
[Train] Epoch: 2 [305792/620022]    Loss: 0.007659   Batch Acc: 82.81
[Train] Epoch: 2 [305856/620022]    Loss: 0.008457   Batch Acc: 81.25
[Train] Epoch: 2 [305920/620022]    Loss: 0.009124   Batch Acc: 78.12
[Train] Epoch: 2 [305984/620022]    Loss: 0.008289   Batch Acc: 76.56
[Train] Epoch: 2 [306048/620022]    Loss: 0.006803   Batch Acc: 84.38
[Train] Epoch: 2 [306112/620022]    Loss: 0.006580   Batch Acc: 85.94
[Train] Epoch: 2 [306176/620022]    Loss: 0.006796   Batch Acc: 84.38
[Train] Epoch: 2 [306240/620022]    Loss: 0.006912   Batch Acc: 84.38
[Train] Epoch: 2 [306304/620022]    Loss: 0.009795   Batch Acc: 76.56
[Train] Epoch: 2 [306368/620022]    Loss: 0.007854   Batch Acc: 81.25
[Train] Epoch: 2 [306432/620022]    Loss: 0.009301   Batch Acc: 76.56
[Train] Epoch: 2 [306496/620022]    Loss: 0.008293   Batch Acc: 76.56
[Train] Epoch: 2 [306560/620022]    Loss: 0.008201   Batch Acc: 79.69
[Train] Epoch: 2 [306624/620022]    Loss: 0.007705   Batch Acc: 84.38
[Train] Epoch: 2 [306688/620022]    Loss: 0.008752   Batch Acc: 79.69
[Train] Epoch: 2 [306752/620022]    Loss: 0.007498   Batch Acc: 79.69
[Train] Epoch: 2 [306816/620022]    Loss: 0.008700   Batch Acc: 79.69
[Train] Epoch: 2 [306880/620022]    Loss: 0.009339   Batch Acc: 73.44
[Train] Epoch: 2 [306944/620022]    Loss: 0.008891   Batch Acc: 81.25
[Train] Epoch: 2 [307008/620022]    Loss: 0.009260   Batch Acc: 73.44
[Train] Epoch: 2 [307072/620022]    Loss: 0.006726   Batch Acc: 84.38
[Train] Epoch: 2 [307136/620022]    Loss: 0.007860   Batch Acc: 79.69
[Train] Epoch: 2 [307200/620022]    Loss: 0.010437   Batch Acc: 75.00
[Train] Epoch: 2 [307264/620022]    Loss: 0.007681   Batch Acc: 82.81
[Train] Epoch: 2 [307328/620022]    Loss: 0.008261   Batch Acc: 76.56
[Train] Epoch: 2 [307392/620022]    Loss: 0.008597   Batch Acc: 73.44
[Train] Epoch: 2 [307456/620022]    Loss: 0.008086   Batch Acc: 82.81
[Train] Epoch: 2 [307520/620022]    Loss: 0.009104   Batch Acc: 76.56
[Train] Epoch: 2 [307584/620022]    Loss: 0.009106   Batch Acc: 75.00
[Train] Epoch: 2 [307648/620022]    Loss: 0.007136   Batch Acc: 82.81
[Train] Epoch: 2 [307712/620022]    Loss: 0.007955   Batch Acc: 81.25
[Train] Epoch: 2 [307776/620022]    Loss: 0.007924   Batch Acc: 79.69
[Train] Epoch: 2 [307840/620022]    Loss: 0.010472   Batch Acc: 73.44
[Train] Epoch: 2 [307904/620022]    Loss: 0.006793   Batch Acc: 84.38
[Train] Epoch: 2 [307968/620022]    Loss: 0.007304   Batch Acc: 78.12
[Train] Epoch: 2 [308032/620022]    Loss: 0.009700   Batch Acc: 71.88
[Train] Epoch: 2 [308096/620022]    Loss: 0.008824   Batch Acc: 81.25
[Train] Epoch: 2 [308160/620022]    Loss: 0.009385   Batch Acc: 75.00
[Train] Epoch: 2 [308224/620022]    Loss: 0.007421   Batch Acc: 79.69
[Train] Epoch: 2 [308288/620022]    Loss: 0.009768   Batch Acc: 75.00
[Train] Epoch: 2 [308352/620022]    Loss: 0.010311   Batch Acc: 79.69
[Train] Epoch: 2 [308416/620022]    Loss: 0.009543   Batch Acc: 71.88
[Train] Epoch: 2 [308480/620022]    Loss: 0.009514   Batch Acc: 76.56
[Train] Epoch: 2 [308544/620022]    Loss: 0.008272   Batch Acc: 79.69
[Train] Epoch: 2 [308608/620022]    Loss: 0.008555   Batch Acc: 82.81
[Train] Epoch: 2 [308672/620022]    Loss: 0.008797   Batch Acc: 78.12
[Train] Epoch: 2 [308736/620022]    Loss: 0.008400   Batch Acc: 78.12
[Train] Epoch: 2 [308800/620022]    Loss: 0.009207   Batch Acc: 79.69
[Train] Epoch: 2 [308864/620022]    Loss: 0.011387   Batch Acc: 68.75
[Train] Epoch: 2 [308928/620022]    Loss: 0.007157   Batch Acc: 85.94
[Train] Epoch: 2 [308992/620022]    Loss: 0.009387   Batch Acc: 79.69
[Train] Epoch: 2 [309056/620022]    Loss: 0.010192   Batch Acc: 73.44
[Train] Epoch: 2 [309120/620022]    Loss: 0.009188   Batch Acc: 78.12
[Train] Epoch: 2 [309184/620022]    Loss: 0.010527   Batch Acc: 73.44
[Train] Epoch: 2 [309248/620022]    Loss: 0.007184   Batch Acc: 82.81
[Train] Epoch: 2 [309312/620022]    Loss: 0.007771   Batch Acc: 82.81
[Train] Epoch: 2 [309376/620022]    Loss: 0.005547   Batch Acc: 85.94
[Train] Epoch: 2 [309440/620022]    Loss: 0.009820   Batch Acc: 68.75
[Train] Epoch: 2 [309504/620022]    Loss: 0.010179   Batch Acc: 73.44
[Train] Epoch: 2 [309568/620022]    Loss: 0.010759   Batch Acc: 68.75
[Train] Epoch: 2 [309632/620022]    Loss: 0.006122   Batch Acc: 89.06
[Train] Epoch: 2 [309696/620022]    Loss: 0.008413   Batch Acc: 81.25
[Train] Epoch: 2 [309760/620022]    Loss: 0.009908   Batch Acc: 68.75
[Train] Epoch: 2 [309824/620022]    Loss: 0.010916   Batch Acc: 65.62
[Train] Epoch: 2 [309888/620022]    Loss: 0.008030   Batch Acc: 78.12
[Train] Epoch: 2 [309952/620022]    Loss: 0.009789   Batch Acc: 78.12
[Train] Epoch: 2 [310016/620022]    Loss: 0.007843   Batch Acc: 81.25
[Train] Epoch: 2 [310080/620022]    Loss: 0.010135   Batch Acc: 73.44
[Train] Epoch: 2 [310144/620022]    Loss: 0.010804   Batch Acc: 67.19
[Train] Epoch: 2 [310208/620022]    Loss: 0.007896   Batch Acc: 78.12
[Train] Epoch: 2 [310272/620022]    Loss: 0.008057   Batch Acc: 79.69
[Train] Epoch: 2 [310336/620022]    Loss: 0.007528   Batch Acc: 84.38
[Train] Epoch: 2 [310400/620022]    Loss: 0.011012   Batch Acc: 73.44
[Train] Epoch: 2 [310464/620022]    Loss: 0.006096   Batch Acc: 87.50
[Train] Epoch: 2 [310528/620022]    Loss: 0.009027   Batch Acc: 78.12
[Train] Epoch: 2 [310592/620022]    Loss: 0.008379   Batch Acc: 71.88
[Train] Epoch: 2 [310656/620022]    Loss: 0.010697   Batch Acc: 71.88
[Train] Epoch: 2 [310720/620022]    Loss: 0.009604   Batch Acc: 79.69
[Train] Epoch: 2 [310784/620022]    Loss: 0.008722   Batch Acc: 78.12
[Train] Epoch: 2 [310848/620022]    Loss: 0.007350   Batch Acc: 85.94
[Train] Epoch: 2 [310912/620022]    Loss: 0.007115   Batch Acc: 79.69
[Train] Epoch: 2 [310976/620022]    Loss: 0.008189   Batch Acc: 84.38
[Train] Epoch: 2 [311040/620022]    Loss: 0.006774   Batch Acc: 85.94
[Train] Epoch: 2 [311104/620022]    Loss: 0.008139   Batch Acc: 78.12
[Train] Epoch: 2 [311168/620022]    Loss: 0.010289   Batch Acc: 81.25
[Train] Epoch: 2 [311232/620022]    Loss: 0.008005   Batch Acc: 81.25
[Train] Epoch: 2 [311296/620022]    Loss: 0.009252   Batch Acc: 78.12
[Train] Epoch: 2 [311360/620022]    Loss: 0.009651   Batch Acc: 73.44
[Train] Epoch: 2 [311424/620022]    Loss: 0.010113   Batch Acc: 75.00
[Train] Epoch: 2 [311488/620022]    Loss: 0.011191   Batch Acc: 73.44
[Train] Epoch: 2 [311552/620022]    Loss: 0.009384   Batch Acc: 79.69
[Train] Epoch: 2 [311616/620022]    Loss: 0.007794   Batch Acc: 84.38
[Train] Epoch: 2 [311680/620022]    Loss: 0.007888   Batch Acc: 82.81
[Train] Epoch: 2 [311744/620022]    Loss: 0.009121   Batch Acc: 78.12
[Train] Epoch: 2 [311808/620022]    Loss: 0.008750   Batch Acc: 78.12
[Train] Epoch: 2 [311872/620022]    Loss: 0.007445   Batch Acc: 79.69
[Train] Epoch: 2 [311936/620022]    Loss: 0.010789   Batch Acc: 67.19
[Train] Epoch: 2 [312000/620022]    Loss: 0.010017   Batch Acc: 78.12
[Train] Epoch: 2 [312064/620022]    Loss: 0.007413   Batch Acc: 81.25
[Train] Epoch: 2 [312128/620022]    Loss: 0.007636   Batch Acc: 82.81
[Train] Epoch: 2 [312192/620022]    Loss: 0.008244   Batch Acc: 78.12
[Train] Epoch: 2 [312256/620022]    Loss: 0.009284   Batch Acc: 81.25
[Train] Epoch: 2 [312320/620022]    Loss: 0.007239   Batch Acc: 84.38
[Train] Epoch: 2 [312384/620022]    Loss: 0.008645   Batch Acc: 78.12
[Train] Epoch: 2 [312448/620022]    Loss: 0.008709   Batch Acc: 84.38
[Train] Epoch: 2 [312512/620022]    Loss: 0.006531   Batch Acc: 82.81
[Train] Epoch: 2 [312576/620022]    Loss: 0.010826   Batch Acc: 68.75
[Train] Epoch: 2 [312640/620022]    Loss: 0.009478   Batch Acc: 76.56
[Train] Epoch: 2 [312704/620022]    Loss: 0.010189   Batch Acc: 75.00
[Train] Epoch: 2 [312768/620022]    Loss: 0.008662   Batch Acc: 79.69
[Train] Epoch: 2 [312832/620022]    Loss: 0.010207   Batch Acc: 70.31
[Train] Epoch: 2 [312896/620022]    Loss: 0.007140   Batch Acc: 79.69
[Train] Epoch: 2 [312960/620022]    Loss: 0.007211   Batch Acc: 82.81
[Train] Epoch: 2 [313024/620022]    Loss: 0.006092   Batch Acc: 90.62
[Train] Epoch: 2 [313088/620022]    Loss: 0.006171   Batch Acc: 85.94
[Train] Epoch: 2 [313152/620022]    Loss: 0.008765   Batch Acc: 78.12
[Train] Epoch: 2 [313216/620022]    Loss: 0.008438   Batch Acc: 71.88
[Train] Epoch: 2 [313280/620022]    Loss: 0.006697   Batch Acc: 85.94
[Train] Epoch: 2 [313344/620022]    Loss: 0.008490   Batch Acc: 76.56
[Train] Epoch: 2 [313408/620022]    Loss: 0.008989   Batch Acc: 73.44
[Train] Epoch: 2 [313472/620022]    Loss: 0.008200   Batch Acc: 81.25
[Train] Epoch: 2 [313536/620022]    Loss: 0.008345   Batch Acc: 79.69
[Train] Epoch: 2 [313600/620022]    Loss: 0.007907   Batch Acc: 78.12
[Train] Epoch: 2 [313664/620022]    Loss: 0.011948   Batch Acc: 62.50
[Train] Epoch: 2 [313728/620022]    Loss: 0.007354   Batch Acc: 79.69
[Train] Epoch: 2 [313792/620022]    Loss: 0.006991   Batch Acc: 90.62
[Train] Epoch: 2 [313856/620022]    Loss: 0.008399   Batch Acc: 76.56
[Train] Epoch: 2 [313920/620022]    Loss: 0.007859   Batch Acc: 73.44
[Train] Epoch: 2 [313984/620022]    Loss: 0.011162   Batch Acc: 71.88
[Train] Epoch: 2 [314048/620022]    Loss: 0.006311   Batch Acc: 82.81
[Train] Epoch: 2 [314112/620022]    Loss: 0.007121   Batch Acc: 85.94
[Train] Epoch: 2 [314176/620022]    Loss: 0.009526   Batch Acc: 71.88
[Train] Epoch: 2 [314240/620022]    Loss: 0.009216   Batch Acc: 78.12
[Train] Epoch: 2 [314304/620022]    Loss: 0.008547   Batch Acc: 76.56
[Train] Epoch: 2 [314368/620022]    Loss: 0.009929   Batch Acc: 73.44
[Train] Epoch: 2 [314432/620022]    Loss: 0.007050   Batch Acc: 84.38
[Train] Epoch: 2 [314496/620022]    Loss: 0.007284   Batch Acc: 84.38
[Train] Epoch: 2 [314560/620022]    Loss: 0.008704   Batch Acc: 75.00
[Train] Epoch: 2 [314624/620022]    Loss: 0.007833   Batch Acc: 76.56
[Train] Epoch: 2 [314688/620022]    Loss: 0.009605   Batch Acc: 76.56
[Train] Epoch: 2 [314752/620022]    Loss: 0.009154   Batch Acc: 70.31
[Train] Epoch: 2 [314816/620022]    Loss: 0.007839   Batch Acc: 76.56
[Train] Epoch: 2 [314880/620022]    Loss: 0.007705   Batch Acc: 79.69
[Train] Epoch: 2 [314944/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 2 [315008/620022]    Loss: 0.009099   Batch Acc: 81.25
[Train] Epoch: 2 [315072/620022]    Loss: 0.012071   Batch Acc: 62.50
[Train] Epoch: 2 [315136/620022]    Loss: 0.007898   Batch Acc: 81.25
[Train] Epoch: 2 [315200/620022]    Loss: 0.007684   Batch Acc: 78.12
[Train] Epoch: 2 [315264/620022]    Loss: 0.010296   Batch Acc: 70.31
[Train] Epoch: 2 [315328/620022]    Loss: 0.008487   Batch Acc: 79.69
[Train] Epoch: 2 [315392/620022]    Loss: 0.007903   Batch Acc: 78.12
[Train] Epoch: 2 [315456/620022]    Loss: 0.010618   Batch Acc: 76.56
[Train] Epoch: 2 [315520/620022]    Loss: 0.008099   Batch Acc: 79.69
[Train] Epoch: 2 [315584/620022]    Loss: 0.006427   Batch Acc: 84.38
[Train] Epoch: 2 [315648/620022]    Loss: 0.010263   Batch Acc: 71.88
[Train] Epoch: 2 [315712/620022]    Loss: 0.008004   Batch Acc: 78.12
[Train] Epoch: 2 [315776/620022]    Loss: 0.007723   Batch Acc: 81.25
[Train] Epoch: 2 [315840/620022]    Loss: 0.007973   Batch Acc: 81.25
[Train] Epoch: 2 [315904/620022]    Loss: 0.008709   Batch Acc: 75.00
[Train] Epoch: 2 [315968/620022]    Loss: 0.009758   Batch Acc: 78.12
[Train] Epoch: 2 [316032/620022]    Loss: 0.009721   Batch Acc: 75.00
[Train] Epoch: 2 [316096/620022]    Loss: 0.013242   Batch Acc: 64.06
[Train] Epoch: 2 [316160/620022]    Loss: 0.006928   Batch Acc: 78.12
[Train] Epoch: 2 [316224/620022]    Loss: 0.007641   Batch Acc: 81.25
[Train] Epoch: 2 [316288/620022]    Loss: 0.008064   Batch Acc: 78.12
[Train] Epoch: 2 [316352/620022]    Loss: 0.008167   Batch Acc: 76.56
[Train] Epoch: 2 [316416/620022]    Loss: 0.009000   Batch Acc: 78.12
[Train] Epoch: 2 [316480/620022]    Loss: 0.008315   Batch Acc: 76.56
[Train] Epoch: 2 [316544/620022]    Loss: 0.008443   Batch Acc: 79.69
[Train] Epoch: 2 [316608/620022]    Loss: 0.009906   Batch Acc: 79.69
[Train] Epoch: 2 [316672/620022]    Loss: 0.009310   Batch Acc: 75.00
[Train] Epoch: 2 [316736/620022]    Loss: 0.005866   Batch Acc: 85.94
[Train] Epoch: 2 [316800/620022]    Loss: 0.009120   Batch Acc: 76.56
[Train] Epoch: 2 [316864/620022]    Loss: 0.011723   Batch Acc: 70.31
[Train] Epoch: 2 [316928/620022]    Loss: 0.008199   Batch Acc: 75.00
[Train] Epoch: 2 [316992/620022]    Loss: 0.010219   Batch Acc: 73.44
[Train] Epoch: 2 [317056/620022]    Loss: 0.007249   Batch Acc: 85.94
[Train] Epoch: 2 [317120/620022]    Loss: 0.009665   Batch Acc: 70.31
[Train] Epoch: 2 [317184/620022]    Loss: 0.007760   Batch Acc: 79.69
[Train] Epoch: 2 [317248/620022]    Loss: 0.009276   Batch Acc: 73.44
[Train] Epoch: 2 [317312/620022]    Loss: 0.008264   Batch Acc: 79.69
[Train] Epoch: 2 [317376/620022]    Loss: 0.010699   Batch Acc: 70.31
[Train] Epoch: 2 [317440/620022]    Loss: 0.009713   Batch Acc: 70.31
[Train] Epoch: 2 [317504/620022]    Loss: 0.007532   Batch Acc: 82.81
[Train] Epoch: 2 [317568/620022]    Loss: 0.006872   Batch Acc: 85.94
[Train] Epoch: 2 [317632/620022]    Loss: 0.010698   Batch Acc: 76.56
[Train] Epoch: 2 [317696/620022]    Loss: 0.009562   Batch Acc: 71.88
[Train] Epoch: 2 [317760/620022]    Loss: 0.008622   Batch Acc: 76.56
[Train] Epoch: 2 [317824/620022]    Loss: 0.008473   Batch Acc: 75.00
[Train] Epoch: 2 [317888/620022]    Loss: 0.010800   Batch Acc: 65.62
[Train] Epoch: 2 [317952/620022]    Loss: 0.008805   Batch Acc: 82.81
[Train] Epoch: 2 [318016/620022]    Loss: 0.008942   Batch Acc: 76.56
[Train] Epoch: 2 [318080/620022]    Loss: 0.010932   Batch Acc: 64.06
[Train] Epoch: 2 [318144/620022]    Loss: 0.007482   Batch Acc: 84.38
[Train] Epoch: 2 [318208/620022]    Loss: 0.008723   Batch Acc: 73.44
[Train] Epoch: 2 [318272/620022]    Loss: 0.007122   Batch Acc: 82.81
[Train] Epoch: 2 [318336/620022]    Loss: 0.008299   Batch Acc: 78.12
[Train] Epoch: 2 [318400/620022]    Loss: 0.007024   Batch Acc: 84.38
[Train] Epoch: 2 [318464/620022]    Loss: 0.008725   Batch Acc: 75.00
[Train] Epoch: 2 [318528/620022]    Loss: 0.010700   Batch Acc: 75.00
[Train] Epoch: 2 [318592/620022]    Loss: 0.010694   Batch Acc: 71.88
[Train] Epoch: 2 [318656/620022]    Loss: 0.009898   Batch Acc: 75.00
[Train] Epoch: 2 [318720/620022]    Loss: 0.007972   Batch Acc: 76.56
[Train] Epoch: 2 [318784/620022]    Loss: 0.007689   Batch Acc: 79.69
[Train] Epoch: 2 [318848/620022]    Loss: 0.007138   Batch Acc: 81.25
[Train] Epoch: 2 [318912/620022]    Loss: 0.008483   Batch Acc: 78.12
[Train] Epoch: 2 [318976/620022]    Loss: 0.009158   Batch Acc: 78.12
[Train] Epoch: 2 [319040/620022]    Loss: 0.009801   Batch Acc: 75.00
[Train] Epoch: 2 [319104/620022]    Loss: 0.009574   Batch Acc: 73.44
[Train] Epoch: 2 [319168/620022]    Loss: 0.009907   Batch Acc: 75.00
[Train] Epoch: 2 [319232/620022]    Loss: 0.007284   Batch Acc: 81.25
[Train] Epoch: 2 [319296/620022]    Loss: 0.009590   Batch Acc: 79.69
[Train] Epoch: 2 [319360/620022]    Loss: 0.010380   Batch Acc: 70.31
[Train] Epoch: 2 [319424/620022]    Loss: 0.008430   Batch Acc: 79.69
[Train] Epoch: 2 [319488/620022]    Loss: 0.008449   Batch Acc: 81.25
[Train] Epoch: 2 [319552/620022]    Loss: 0.008236   Batch Acc: 81.25
[Train] Epoch: 2 [319616/620022]    Loss: 0.008126   Batch Acc: 81.25
[Train] Epoch: 2 [319680/620022]    Loss: 0.007352   Batch Acc: 84.38
[Train] Epoch: 2 [319744/620022]    Loss: 0.008827   Batch Acc: 81.25
[Train] Epoch: 2 [319808/620022]    Loss: 0.009411   Batch Acc: 79.69
[Train] Epoch: 2 [319872/620022]    Loss: 0.008752   Batch Acc: 79.69
[Train] Epoch: 2 [319936/620022]    Loss: 0.009163   Batch Acc: 68.75
[Train] Epoch: 2 [320000/620022]    Loss: 0.009041   Batch Acc: 75.00
[Train] Epoch: 2 [320064/620022]    Loss: 0.009262   Batch Acc: 79.69
[Train] Epoch: 2 [320128/620022]    Loss: 0.008424   Batch Acc: 84.38
[Train] Epoch: 2 [320192/620022]    Loss: 0.008453   Batch Acc: 75.00
[Train] Epoch: 2 [320256/620022]    Loss: 0.009674   Batch Acc: 75.00
[Train] Epoch: 2 [320320/620022]    Loss: 0.010039   Batch Acc: 73.44
[Train] Epoch: 2 [320384/620022]    Loss: 0.006376   Batch Acc: 87.50
[Train] Epoch: 2 [320448/620022]    Loss: 0.008493   Batch Acc: 81.25
[Train] Epoch: 2 [320512/620022]    Loss: 0.007807   Batch Acc: 76.56
[Train] Epoch: 2 [320576/620022]    Loss: 0.009073   Batch Acc: 76.56
[Train] Epoch: 2 [320640/620022]    Loss: 0.008816   Batch Acc: 78.12
[Train] Epoch: 2 [320704/620022]    Loss: 0.009359   Batch Acc: 79.69
[Train] Epoch: 2 [320768/620022]    Loss: 0.007664   Batch Acc: 84.38
[Train] Epoch: 2 [320832/620022]    Loss: 0.006801   Batch Acc: 85.94
[Train] Epoch: 2 [320896/620022]    Loss: 0.006930   Batch Acc: 82.81
[Train] Epoch: 2 [320960/620022]    Loss: 0.010896   Batch Acc: 76.56
[Train] Epoch: 2 [321024/620022]    Loss: 0.009016   Batch Acc: 78.12
[Train] Epoch: 2 [321088/620022]    Loss: 0.008513   Batch Acc: 75.00
[Train] Epoch: 2 [321152/620022]    Loss: 0.008587   Batch Acc: 78.12
[Train] Epoch: 2 [321216/620022]    Loss: 0.008821   Batch Acc: 73.44
[Train] Epoch: 2 [321280/620022]    Loss: 0.006506   Batch Acc: 85.94
[Train] Epoch: 2 [321344/620022]    Loss: 0.008301   Batch Acc: 76.56
[Train] Epoch: 2 [321408/620022]    Loss: 0.010299   Batch Acc: 68.75
[Train] Epoch: 2 [321472/620022]    Loss: 0.009869   Batch Acc: 78.12
[Train] Epoch: 2 [321536/620022]    Loss: 0.011022   Batch Acc: 68.75
[Train] Epoch: 2 [321600/620022]    Loss: 0.009752   Batch Acc: 78.12
[Train] Epoch: 2 [321664/620022]    Loss: 0.007438   Batch Acc: 78.12
[Train] Epoch: 2 [321728/620022]    Loss: 0.010121   Batch Acc: 78.12
[Train] Epoch: 2 [321792/620022]    Loss: 0.006333   Batch Acc: 81.25
[Train] Epoch: 2 [321856/620022]    Loss: 0.011447   Batch Acc: 71.88
[Train] Epoch: 2 [321920/620022]    Loss: 0.008095   Batch Acc: 81.25
[Train] Epoch: 2 [321984/620022]    Loss: 0.008636   Batch Acc: 78.12
[Train] Epoch: 2 [322048/620022]    Loss: 0.008445   Batch Acc: 76.56
[Train] Epoch: 2 [322112/620022]    Loss: 0.006331   Batch Acc: 84.38
[Train] Epoch: 2 [322176/620022]    Loss: 0.009354   Batch Acc: 75.00
[Train] Epoch: 2 [322240/620022]    Loss: 0.008000   Batch Acc: 78.12
[Train] Epoch: 2 [322304/620022]    Loss: 0.007543   Batch Acc: 81.25
[Train] Epoch: 2 [322368/620022]    Loss: 0.008267   Batch Acc: 76.56
[Train] Epoch: 2 [322432/620022]    Loss: 0.011979   Batch Acc: 71.88
[Train] Epoch: 2 [322496/620022]    Loss: 0.006113   Batch Acc: 90.62
[Train] Epoch: 2 [322560/620022]    Loss: 0.011210   Batch Acc: 75.00
[Train] Epoch: 2 [322624/620022]    Loss: 0.007386   Batch Acc: 79.69
[Train] Epoch: 2 [322688/620022]    Loss: 0.009376   Batch Acc: 73.44
[Train] Epoch: 2 [322752/620022]    Loss: 0.010012   Batch Acc: 79.69
[Train] Epoch: 2 [322816/620022]    Loss: 0.008500   Batch Acc: 78.12
[Train] Epoch: 2 [322880/620022]    Loss: 0.007171   Batch Acc: 81.25
[Train] Epoch: 2 [322944/620022]    Loss: 0.008039   Batch Acc: 79.69
[Train] Epoch: 2 [323008/620022]    Loss: 0.008285   Batch Acc: 81.25
[Train] Epoch: 2 [323072/620022]    Loss: 0.009393   Batch Acc: 76.56
[Train] Epoch: 2 [323136/620022]    Loss: 0.009654   Batch Acc: 75.00
[Train] Epoch: 2 [323200/620022]    Loss: 0.008181   Batch Acc: 81.25
[Train] Epoch: 2 [323264/620022]    Loss: 0.010432   Batch Acc: 70.31
[Train] Epoch: 2 [323328/620022]    Loss: 0.009750   Batch Acc: 68.75
[Train] Epoch: 2 [323392/620022]    Loss: 0.010850   Batch Acc: 76.56
[Train] Epoch: 2 [323456/620022]    Loss: 0.007203   Batch Acc: 81.25
[Train] Epoch: 2 [323520/620022]    Loss: 0.008134   Batch Acc: 82.81
[Train] Epoch: 2 [323584/620022]    Loss: 0.008095   Batch Acc: 81.25
[Train] Epoch: 2 [323648/620022]    Loss: 0.006856   Batch Acc: 79.69
[Train] Epoch: 2 [323712/620022]    Loss: 0.007812   Batch Acc: 82.81
[Train] Epoch: 2 [323776/620022]    Loss: 0.009484   Batch Acc: 70.31
[Train] Epoch: 2 [323840/620022]    Loss: 0.010291   Batch Acc: 70.31
[Train] Epoch: 2 [323904/620022]    Loss: 0.010855   Batch Acc: 70.31
[Train] Epoch: 2 [323968/620022]    Loss: 0.009205   Batch Acc: 70.31
[Train] Epoch: 2 [324032/620022]    Loss: 0.008369   Batch Acc: 78.12
[Train] Epoch: 2 [324096/620022]    Loss: 0.008089   Batch Acc: 81.25
[Train] Epoch: 2 [324160/620022]    Loss: 0.008766   Batch Acc: 71.88
[Train] Epoch: 2 [324224/620022]    Loss: 0.008416   Batch Acc: 78.12
[Train] Epoch: 2 [324288/620022]    Loss: 0.009784   Batch Acc: 71.88
[Train] Epoch: 2 [324352/620022]    Loss: 0.008954   Batch Acc: 81.25
[Train] Epoch: 2 [324416/620022]    Loss: 0.009282   Batch Acc: 78.12
[Train] Epoch: 2 [324480/620022]    Loss: 0.007329   Batch Acc: 81.25
[Train] Epoch: 2 [324544/620022]    Loss: 0.008549   Batch Acc: 75.00
[Train] Epoch: 2 [324608/620022]    Loss: 0.006633   Batch Acc: 84.38
[Train] Epoch: 2 [324672/620022]    Loss: 0.008454   Batch Acc: 76.56
[Train] Epoch: 2 [324736/620022]    Loss: 0.007322   Batch Acc: 79.69
[Train] Epoch: 2 [324800/620022]    Loss: 0.007515   Batch Acc: 85.94
[Train] Epoch: 2 [324864/620022]    Loss: 0.007788   Batch Acc: 81.25
[Train] Epoch: 2 [324928/620022]    Loss: 0.008198   Batch Acc: 81.25
[Train] Epoch: 2 [324992/620022]    Loss: 0.011224   Batch Acc: 71.88
[Train] Epoch: 2 [325056/620022]    Loss: 0.008794   Batch Acc: 71.88
[Train] Epoch: 2 [325120/620022]    Loss: 0.008152   Batch Acc: 78.12
[Train] Epoch: 2 [325184/620022]    Loss: 0.010472   Batch Acc: 75.00
[Train] Epoch: 2 [325248/620022]    Loss: 0.008084   Batch Acc: 82.81
[Train] Epoch: 2 [325312/620022]    Loss: 0.009522   Batch Acc: 76.56
[Train] Epoch: 2 [325376/620022]    Loss: 0.006647   Batch Acc: 89.06
[Train] Epoch: 2 [325440/620022]    Loss: 0.006097   Batch Acc: 85.94
[Train] Epoch: 2 [325504/620022]    Loss: 0.009210   Batch Acc: 76.56
[Train] Epoch: 2 [325568/620022]    Loss: 0.008443   Batch Acc: 82.81
[Train] Epoch: 2 [325632/620022]    Loss: 0.005479   Batch Acc: 89.06
[Train] Epoch: 2 [325696/620022]    Loss: 0.010732   Batch Acc: 76.56
[Train] Epoch: 2 [325760/620022]    Loss: 0.008596   Batch Acc: 79.69
[Train] Epoch: 2 [325824/620022]    Loss: 0.009362   Batch Acc: 81.25
[Train] Epoch: 2 [325888/620022]    Loss: 0.008023   Batch Acc: 75.00
[Train] Epoch: 2 [325952/620022]    Loss: 0.009959   Batch Acc: 76.56
[Train] Epoch: 2 [326016/620022]    Loss: 0.007260   Batch Acc: 89.06
[Train] Epoch: 2 [326080/620022]    Loss: 0.006987   Batch Acc: 82.81
[Train] Epoch: 2 [326144/620022]    Loss: 0.008865   Batch Acc: 79.69
[Train] Epoch: 2 [326208/620022]    Loss: 0.009291   Batch Acc: 76.56
[Train] Epoch: 2 [326272/620022]    Loss: 0.008641   Batch Acc: 81.25
[Train] Epoch: 2 [326336/620022]    Loss: 0.007586   Batch Acc: 82.81
[Train] Epoch: 2 [326400/620022]    Loss: 0.006990   Batch Acc: 82.81
[Train] Epoch: 2 [326464/620022]    Loss: 0.007934   Batch Acc: 82.81
[Train] Epoch: 2 [326528/620022]    Loss: 0.006510   Batch Acc: 82.81
[Train] Epoch: 2 [326592/620022]    Loss: 0.010820   Batch Acc: 67.19
[Train] Epoch: 2 [326656/620022]    Loss: 0.008305   Batch Acc: 78.12
[Train] Epoch: 2 [326720/620022]    Loss: 0.008242   Batch Acc: 79.69
[Train] Epoch: 2 [326784/620022]    Loss: 0.011672   Batch Acc: 59.38
[Train] Epoch: 2 [326848/620022]    Loss: 0.008538   Batch Acc: 79.69
[Train] Epoch: 2 [326912/620022]    Loss: 0.011649   Batch Acc: 67.19
[Train] Epoch: 2 [326976/620022]    Loss: 0.005684   Batch Acc: 85.94
[Train] Epoch: 2 [327040/620022]    Loss: 0.007555   Batch Acc: 78.12
[Train] Epoch: 2 [327104/620022]    Loss: 0.009962   Batch Acc: 70.31
[Train] Epoch: 2 [327168/620022]    Loss: 0.008794   Batch Acc: 81.25
[Train] Epoch: 2 [327232/620022]    Loss: 0.009445   Batch Acc: 76.56
[Train] Epoch: 2 [327296/620022]    Loss: 0.010153   Batch Acc: 73.44
[Train] Epoch: 2 [327360/620022]    Loss: 0.008212   Batch Acc: 82.81
[Train] Epoch: 2 [327424/620022]    Loss: 0.008712   Batch Acc: 76.56
[Train] Epoch: 2 [327488/620022]    Loss: 0.010147   Batch Acc: 71.88
[Train] Epoch: 2 [327552/620022]    Loss: 0.007047   Batch Acc: 79.69
[Train] Epoch: 2 [327616/620022]    Loss: 0.008807   Batch Acc: 78.12
[Train] Epoch: 2 [327680/620022]    Loss: 0.008779   Batch Acc: 82.81
[Train] Epoch: 2 [327744/620022]    Loss: 0.008931   Batch Acc: 71.88
[Train] Epoch: 2 [327808/620022]    Loss: 0.009876   Batch Acc: 76.56
[Train] Epoch: 2 [327872/620022]    Loss: 0.006986   Batch Acc: 87.50
[Train] Epoch: 2 [327936/620022]    Loss: 0.009643   Batch Acc: 82.81
[Train] Epoch: 2 [328000/620022]    Loss: 0.008353   Batch Acc: 78.12
[Train] Epoch: 2 [328064/620022]    Loss: 0.008377   Batch Acc: 81.25
[Train] Epoch: 2 [328128/620022]    Loss: 0.009059   Batch Acc: 79.69
[Train] Epoch: 2 [328192/620022]    Loss: 0.008579   Batch Acc: 76.56
[Train] Epoch: 2 [328256/620022]    Loss: 0.009230   Batch Acc: 71.88
[Train] Epoch: 2 [328320/620022]    Loss: 0.010876   Batch Acc: 65.62
[Train] Epoch: 2 [328384/620022]    Loss: 0.010323   Batch Acc: 75.00
[Train] Epoch: 2 [328448/620022]    Loss: 0.008768   Batch Acc: 81.25
[Train] Epoch: 2 [328512/620022]    Loss: 0.009051   Batch Acc: 82.81
[Train] Epoch: 2 [328576/620022]    Loss: 0.006176   Batch Acc: 85.94
[Train] Epoch: 2 [328640/620022]    Loss: 0.008138   Batch Acc: 81.25
[Train] Epoch: 2 [328704/620022]    Loss: 0.007034   Batch Acc: 85.94
[Train] Epoch: 2 [328768/620022]    Loss: 0.010525   Batch Acc: 68.75
[Train] Epoch: 2 [328832/620022]    Loss: 0.008108   Batch Acc: 79.69
[Train] Epoch: 2 [328896/620022]    Loss: 0.009210   Batch Acc: 79.69
[Train] Epoch: 2 [328960/620022]    Loss: 0.006399   Batch Acc: 90.62
[Train] Epoch: 2 [329024/620022]    Loss: 0.008872   Batch Acc: 78.12
[Train] Epoch: 2 [329088/620022]    Loss: 0.009630   Batch Acc: 73.44
[Train] Epoch: 2 [329152/620022]    Loss: 0.007348   Batch Acc: 85.94
[Train] Epoch: 2 [329216/620022]    Loss: 0.008565   Batch Acc: 75.00
[Train] Epoch: 2 [329280/620022]    Loss: 0.007809   Batch Acc: 81.25
[Train] Epoch: 2 [329344/620022]    Loss: 0.009966   Batch Acc: 73.44
[Train] Epoch: 2 [329408/620022]    Loss: 0.009867   Batch Acc: 75.00
[Train] Epoch: 2 [329472/620022]    Loss: 0.007948   Batch Acc: 82.81
[Train] Epoch: 2 [329536/620022]    Loss: 0.010241   Batch Acc: 75.00
[Train] Epoch: 2 [329600/620022]    Loss: 0.011162   Batch Acc: 70.31
[Train] Epoch: 2 [329664/620022]    Loss: 0.009864   Batch Acc: 71.88
[Train] Epoch: 2 [329728/620022]    Loss: 0.009819   Batch Acc: 75.00
[Train] Epoch: 2 [329792/620022]    Loss: 0.007756   Batch Acc: 84.38
[Train] Epoch: 2 [329856/620022]    Loss: 0.011593   Batch Acc: 75.00
[Train] Epoch: 2 [329920/620022]    Loss: 0.008616   Batch Acc: 81.25
[Train] Epoch: 2 [329984/620022]    Loss: 0.008375   Batch Acc: 79.69
[Train] Epoch: 2 [330048/620022]    Loss: 0.009010   Batch Acc: 73.44
[Train] Epoch: 2 [330112/620022]    Loss: 0.008405   Batch Acc: 78.12
[Train] Epoch: 2 [330176/620022]    Loss: 0.008643   Batch Acc: 75.00
[Train] Epoch: 2 [330240/620022]    Loss: 0.008118   Batch Acc: 82.81
[Train] Epoch: 2 [330304/620022]    Loss: 0.009180   Batch Acc: 70.31
[Train] Epoch: 2 [330368/620022]    Loss: 0.009113   Batch Acc: 79.69
[Train] Epoch: 2 [330432/620022]    Loss: 0.009467   Batch Acc: 79.69
[Train] Epoch: 2 [330496/620022]    Loss: 0.008779   Batch Acc: 75.00
[Train] Epoch: 2 [330560/620022]    Loss: 0.009190   Batch Acc: 75.00
[Train] Epoch: 2 [330624/620022]    Loss: 0.008072   Batch Acc: 81.25
[Train] Epoch: 2 [330688/620022]    Loss: 0.009739   Batch Acc: 71.88
[Train] Epoch: 2 [330752/620022]    Loss: 0.009876   Batch Acc: 75.00
[Train] Epoch: 2 [330816/620022]    Loss: 0.007820   Batch Acc: 82.81
[Train] Epoch: 2 [330880/620022]    Loss: 0.007502   Batch Acc: 84.38
[Train] Epoch: 2 [330944/620022]    Loss: 0.008703   Batch Acc: 81.25
[Train] Epoch: 2 [331008/620022]    Loss: 0.009513   Batch Acc: 76.56
[Train] Epoch: 2 [331072/620022]    Loss: 0.007503   Batch Acc: 84.38
[Train] Epoch: 2 [331136/620022]    Loss: 0.008685   Batch Acc: 82.81
[Train] Epoch: 2 [331200/620022]    Loss: 0.008867   Batch Acc: 76.56
[Train] Epoch: 2 [331264/620022]    Loss: 0.009466   Batch Acc: 79.69
[Train] Epoch: 2 [331328/620022]    Loss: 0.007729   Batch Acc: 82.81
[Train] Epoch: 2 [331392/620022]    Loss: 0.009526   Batch Acc: 76.56
[Train] Epoch: 2 [331456/620022]    Loss: 0.007870   Batch Acc: 82.81
[Train] Epoch: 2 [331520/620022]    Loss: 0.007514   Batch Acc: 82.81
[Train] Epoch: 2 [331584/620022]    Loss: 0.008700   Batch Acc: 70.31
[Train] Epoch: 2 [331648/620022]    Loss: 0.007959   Batch Acc: 78.12
[Train] Epoch: 2 [331712/620022]    Loss: 0.008220   Batch Acc: 76.56
[Train] Epoch: 2 [331776/620022]    Loss: 0.008926   Batch Acc: 75.00
[Train] Epoch: 2 [331840/620022]    Loss: 0.009731   Batch Acc: 73.44
[Train] Epoch: 2 [331904/620022]    Loss: 0.006769   Batch Acc: 82.81
[Train] Epoch: 2 [331968/620022]    Loss: 0.008455   Batch Acc: 75.00
[Train] Epoch: 2 [332032/620022]    Loss: 0.009385   Batch Acc: 73.44
[Train] Epoch: 2 [332096/620022]    Loss: 0.010330   Batch Acc: 68.75
[Train] Epoch: 2 [332160/620022]    Loss: 0.009389   Batch Acc: 68.75
[Train] Epoch: 2 [332224/620022]    Loss: 0.006542   Batch Acc: 85.94
[Train] Epoch: 2 [332288/620022]    Loss: 0.008833   Batch Acc: 76.56
[Train] Epoch: 2 [332352/620022]    Loss: 0.009507   Batch Acc: 75.00
[Train] Epoch: 2 [332416/620022]    Loss: 0.008710   Batch Acc: 71.88
[Train] Epoch: 2 [332480/620022]    Loss: 0.010493   Batch Acc: 75.00
[Train] Epoch: 2 [332544/620022]    Loss: 0.008986   Batch Acc: 76.56
[Train] Epoch: 2 [332608/620022]    Loss: 0.009509   Batch Acc: 68.75
[Train] Epoch: 2 [332672/620022]    Loss: 0.007814   Batch Acc: 87.50
[Train] Epoch: 2 [332736/620022]    Loss: 0.008710   Batch Acc: 79.69
[Train] Epoch: 2 [332800/620022]    Loss: 0.009034   Batch Acc: 79.69
[Train] Epoch: 2 [332864/620022]    Loss: 0.008509   Batch Acc: 76.56
[Train] Epoch: 2 [332928/620022]    Loss: 0.009527   Batch Acc: 73.44
[Train] Epoch: 2 [332992/620022]    Loss: 0.007571   Batch Acc: 79.69
[Train] Epoch: 2 [333056/620022]    Loss: 0.006996   Batch Acc: 79.69
[Train] Epoch: 2 [333120/620022]    Loss: 0.009819   Batch Acc: 73.44
[Train] Epoch: 2 [333184/620022]    Loss: 0.006937   Batch Acc: 84.38
[Train] Epoch: 2 [333248/620022]    Loss: 0.009001   Batch Acc: 73.44
[Train] Epoch: 2 [333312/620022]    Loss: 0.007971   Batch Acc: 78.12
[Train] Epoch: 2 [333376/620022]    Loss: 0.009110   Batch Acc: 78.12
[Train] Epoch: 2 [333440/620022]    Loss: 0.006926   Batch Acc: 82.81
[Train] Epoch: 2 [333504/620022]    Loss: 0.010506   Batch Acc: 78.12
[Train] Epoch: 2 [333568/620022]    Loss: 0.007684   Batch Acc: 81.25
[Train] Epoch: 2 [333632/620022]    Loss: 0.009460   Batch Acc: 81.25
[Train] Epoch: 2 [333696/620022]    Loss: 0.009639   Batch Acc: 73.44
[Train] Epoch: 2 [333760/620022]    Loss: 0.009310   Batch Acc: 73.44
[Train] Epoch: 2 [333824/620022]    Loss: 0.010026   Batch Acc: 73.44
[Train] Epoch: 2 [333888/620022]    Loss: 0.010062   Batch Acc: 70.31
[Train] Epoch: 2 [333952/620022]    Loss: 0.007778   Batch Acc: 75.00
[Train] Epoch: 2 [334016/620022]    Loss: 0.007666   Batch Acc: 81.25
[Train] Epoch: 2 [334080/620022]    Loss: 0.007876   Batch Acc: 76.56
[Train] Epoch: 2 [334144/620022]    Loss: 0.006856   Batch Acc: 89.06
[Train] Epoch: 2 [334208/620022]    Loss: 0.007686   Batch Acc: 84.38
[Train] Epoch: 2 [334272/620022]    Loss: 0.006508   Batch Acc: 84.38
[Train] Epoch: 2 [334336/620022]    Loss: 0.010024   Batch Acc: 71.88
[Train] Epoch: 2 [334400/620022]    Loss: 0.008987   Batch Acc: 76.56
[Train] Epoch: 2 [334464/620022]    Loss: 0.012965   Batch Acc: 65.62
[Train] Epoch: 2 [334528/620022]    Loss: 0.009727   Batch Acc: 71.88
[Train] Epoch: 2 [334592/620022]    Loss: 0.006856   Batch Acc: 84.38
[Train] Epoch: 2 [334656/620022]    Loss: 0.007848   Batch Acc: 76.56
[Train] Epoch: 2 [334720/620022]    Loss: 0.010301   Batch Acc: 76.56
[Train] Epoch: 2 [334784/620022]    Loss: 0.009791   Batch Acc: 73.44
[Train] Epoch: 2 [334848/620022]    Loss: 0.008119   Batch Acc: 85.94
[Train] Epoch: 2 [334912/620022]    Loss: 0.009212   Batch Acc: 71.88
[Train] Epoch: 2 [334976/620022]    Loss: 0.010007   Batch Acc: 75.00
[Train] Epoch: 2 [335040/620022]    Loss: 0.008849   Batch Acc: 73.44
[Train] Epoch: 2 [335104/620022]    Loss: 0.008396   Batch Acc: 82.81
[Train] Epoch: 2 [335168/620022]    Loss: 0.008188   Batch Acc: 78.12
[Train] Epoch: 2 [335232/620022]    Loss: 0.007676   Batch Acc: 84.38
[Train] Epoch: 2 [335296/620022]    Loss: 0.010187   Batch Acc: 78.12
[Train] Epoch: 2 [335360/620022]    Loss: 0.010415   Batch Acc: 73.44
[Train] Epoch: 2 [335424/620022]    Loss: 0.008360   Batch Acc: 79.69
[Train] Epoch: 2 [335488/620022]    Loss: 0.007674   Batch Acc: 84.38
[Train] Epoch: 2 [335552/620022]    Loss: 0.009261   Batch Acc: 68.75
[Train] Epoch: 2 [335616/620022]    Loss: 0.007779   Batch Acc: 79.69
[Train] Epoch: 2 [335680/620022]    Loss: 0.009542   Batch Acc: 71.88
[Train] Epoch: 2 [335744/620022]    Loss: 0.007859   Batch Acc: 79.69
[Train] Epoch: 2 [335808/620022]    Loss: 0.007182   Batch Acc: 81.25
[Train] Epoch: 2 [335872/620022]    Loss: 0.006009   Batch Acc: 87.50
[Train] Epoch: 2 [335936/620022]    Loss: 0.010010   Batch Acc: 73.44
[Train] Epoch: 2 [336000/620022]    Loss: 0.007001   Batch Acc: 89.06
[Train] Epoch: 2 [336064/620022]    Loss: 0.010020   Batch Acc: 70.31
[Train] Epoch: 2 [336128/620022]    Loss: 0.008797   Batch Acc: 84.38
[Train] Epoch: 2 [336192/620022]    Loss: 0.008272   Batch Acc: 75.00
[Train] Epoch: 2 [336256/620022]    Loss: 0.008413   Batch Acc: 76.56
[Train] Epoch: 2 [336320/620022]    Loss: 0.009087   Batch Acc: 73.44
[Train] Epoch: 2 [336384/620022]    Loss: 0.008254   Batch Acc: 79.69
[Train] Epoch: 2 [336448/620022]    Loss: 0.008525   Batch Acc: 79.69
[Train] Epoch: 2 [336512/620022]    Loss: 0.009701   Batch Acc: 73.44
[Train] Epoch: 2 [336576/620022]    Loss: 0.009593   Batch Acc: 75.00
[Train] Epoch: 2 [336640/620022]    Loss: 0.009017   Batch Acc: 82.81
[Train] Epoch: 2 [336704/620022]    Loss: 0.008171   Batch Acc: 79.69
[Train] Epoch: 2 [336768/620022]    Loss: 0.009494   Batch Acc: 71.88
[Train] Epoch: 2 [336832/620022]    Loss: 0.007609   Batch Acc: 76.56
[Train] Epoch: 2 [336896/620022]    Loss: 0.007369   Batch Acc: 76.56
[Train] Epoch: 2 [336960/620022]    Loss: 0.008098   Batch Acc: 84.38
[Train] Epoch: 2 [337024/620022]    Loss: 0.008207   Batch Acc: 79.69
[Train] Epoch: 2 [337088/620022]    Loss: 0.009654   Batch Acc: 75.00
[Train] Epoch: 2 [337152/620022]    Loss: 0.006172   Batch Acc: 85.94
[Train] Epoch: 2 [337216/620022]    Loss: 0.007602   Batch Acc: 82.81
[Train] Epoch: 2 [337280/620022]    Loss: 0.007852   Batch Acc: 82.81
[Train] Epoch: 2 [337344/620022]    Loss: 0.009440   Batch Acc: 73.44
[Train] Epoch: 2 [337408/620022]    Loss: 0.010038   Batch Acc: 76.56
[Train] Epoch: 2 [337472/620022]    Loss: 0.009742   Batch Acc: 64.06
[Train] Epoch: 2 [337536/620022]    Loss: 0.007274   Batch Acc: 81.25
[Train] Epoch: 2 [337600/620022]    Loss: 0.006732   Batch Acc: 85.94
[Train] Epoch: 2 [337664/620022]    Loss: 0.009010   Batch Acc: 79.69
[Train] Epoch: 2 [337728/620022]    Loss: 0.009045   Batch Acc: 76.56
[Train] Epoch: 2 [337792/620022]    Loss: 0.009210   Batch Acc: 73.44
[Train] Epoch: 2 [337856/620022]    Loss: 0.008737   Batch Acc: 78.12
[Train] Epoch: 2 [337920/620022]    Loss: 0.008256   Batch Acc: 79.69
[Train] Epoch: 2 [337984/620022]    Loss: 0.010813   Batch Acc: 70.31
[Train] Epoch: 2 [338048/620022]    Loss: 0.008333   Batch Acc: 76.56
[Train] Epoch: 2 [338112/620022]    Loss: 0.006278   Batch Acc: 87.50
[Train] Epoch: 2 [338176/620022]    Loss: 0.007626   Batch Acc: 79.69
[Train] Epoch: 2 [338240/620022]    Loss: 0.009887   Batch Acc: 76.56
[Train] Epoch: 2 [338304/620022]    Loss: 0.010098   Batch Acc: 78.12
[Train] Epoch: 2 [338368/620022]    Loss: 0.008596   Batch Acc: 67.19
[Train] Epoch: 2 [338432/620022]    Loss: 0.007257   Batch Acc: 82.81
[Train] Epoch: 2 [338496/620022]    Loss: 0.005667   Batch Acc: 84.38
[Train] Epoch: 2 [338560/620022]    Loss: 0.008666   Batch Acc: 79.69
[Train] Epoch: 2 [338624/620022]    Loss: 0.008020   Batch Acc: 82.81
[Train] Epoch: 2 [338688/620022]    Loss: 0.007485   Batch Acc: 84.38
[Train] Epoch: 2 [338752/620022]    Loss: 0.006344   Batch Acc: 81.25
[Train] Epoch: 2 [338816/620022]    Loss: 0.007418   Batch Acc: 89.06
[Train] Epoch: 2 [338880/620022]    Loss: 0.008812   Batch Acc: 76.56
[Train] Epoch: 2 [338944/620022]    Loss: 0.010175   Batch Acc: 68.75
[Train] Epoch: 2 [339008/620022]    Loss: 0.008592   Batch Acc: 78.12
[Train] Epoch: 2 [339072/620022]    Loss: 0.010424   Batch Acc: 73.44
[Train] Epoch: 2 [339136/620022]    Loss: 0.008990   Batch Acc: 75.00
[Train] Epoch: 2 [339200/620022]    Loss: 0.010836   Batch Acc: 70.31
[Train] Epoch: 2 [339264/620022]    Loss: 0.007348   Batch Acc: 82.81
[Train] Epoch: 2 [339328/620022]    Loss: 0.007400   Batch Acc: 81.25
[Train] Epoch: 2 [339392/620022]    Loss: 0.007207   Batch Acc: 84.38
[Train] Epoch: 2 [339456/620022]    Loss: 0.011715   Batch Acc: 68.75
[Train] Epoch: 2 [339520/620022]    Loss: 0.010748   Batch Acc: 68.75
[Train] Epoch: 2 [339584/620022]    Loss: 0.008564   Batch Acc: 79.69
[Train] Epoch: 2 [339648/620022]    Loss: 0.010194   Batch Acc: 75.00
[Train] Epoch: 2 [339712/620022]    Loss: 0.010678   Batch Acc: 75.00
[Train] Epoch: 2 [339776/620022]    Loss: 0.008026   Batch Acc: 82.81
[Train] Epoch: 2 [339840/620022]    Loss: 0.008347   Batch Acc: 79.69
[Train] Epoch: 2 [339904/620022]    Loss: 0.008006   Batch Acc: 75.00
[Train] Epoch: 2 [339968/620022]    Loss: 0.007168   Batch Acc: 84.38
[Train] Epoch: 2 [340032/620022]    Loss: 0.008992   Batch Acc: 76.56
[Train] Epoch: 2 [340096/620022]    Loss: 0.009866   Batch Acc: 76.56
[Train] Epoch: 2 [340160/620022]    Loss: 0.007812   Batch Acc: 81.25
[Train] Epoch: 2 [340224/620022]    Loss: 0.008998   Batch Acc: 78.12
[Train] Epoch: 2 [340288/620022]    Loss: 0.010461   Batch Acc: 76.56
[Train] Epoch: 2 [340352/620022]    Loss: 0.010480   Batch Acc: 75.00
[Train] Epoch: 2 [340416/620022]    Loss: 0.006675   Batch Acc: 84.38
[Train] Epoch: 2 [340480/620022]    Loss: 0.008767   Batch Acc: 75.00
[Train] Epoch: 2 [340544/620022]    Loss: 0.006627   Batch Acc: 89.06
[Train] Epoch: 2 [340608/620022]    Loss: 0.009409   Batch Acc: 81.25
[Train] Epoch: 2 [340672/620022]    Loss: 0.007211   Batch Acc: 84.38
[Train] Epoch: 2 [340736/620022]    Loss: 0.010156   Batch Acc: 73.44
[Train] Epoch: 2 [340800/620022]    Loss: 0.008332   Batch Acc: 79.69
[Train] Epoch: 2 [340864/620022]    Loss: 0.009877   Batch Acc: 78.12
[Train] Epoch: 2 [340928/620022]    Loss: 0.007578   Batch Acc: 84.38
[Train] Epoch: 2 [340992/620022]    Loss: 0.008904   Batch Acc: 78.12
[Train] Epoch: 2 [341056/620022]    Loss: 0.010399   Batch Acc: 76.56
[Train] Epoch: 2 [341120/620022]    Loss: 0.006407   Batch Acc: 85.94
[Train] Epoch: 2 [341184/620022]    Loss: 0.007975   Batch Acc: 79.69
[Train] Epoch: 2 [341248/620022]    Loss: 0.009404   Batch Acc: 76.56
[Train] Epoch: 2 [341312/620022]    Loss: 0.009434   Batch Acc: 70.31
[Train] Epoch: 2 [341376/620022]    Loss: 0.007914   Batch Acc: 78.12
[Train] Epoch: 2 [341440/620022]    Loss: 0.010829   Batch Acc: 70.31
[Train] Epoch: 2 [341504/620022]    Loss: 0.009515   Batch Acc: 76.56
[Train] Epoch: 2 [341568/620022]    Loss: 0.008482   Batch Acc: 82.81
[Train] Epoch: 2 [341632/620022]    Loss: 0.008325   Batch Acc: 81.25
[Train] Epoch: 2 [341696/620022]    Loss: 0.008188   Batch Acc: 82.81
[Train] Epoch: 2 [341760/620022]    Loss: 0.007094   Batch Acc: 81.25
[Train] Epoch: 2 [341824/620022]    Loss: 0.007540   Batch Acc: 81.25
[Train] Epoch: 2 [341888/620022]    Loss: 0.007952   Batch Acc: 84.38
[Train] Epoch: 2 [341952/620022]    Loss: 0.006969   Batch Acc: 85.94
[Train] Epoch: 2 [342016/620022]    Loss: 0.009268   Batch Acc: 76.56
[Train] Epoch: 2 [342080/620022]    Loss: 0.011405   Batch Acc: 71.88
[Train] Epoch: 2 [342144/620022]    Loss: 0.009667   Batch Acc: 82.81
[Train] Epoch: 2 [342208/620022]    Loss: 0.007159   Batch Acc: 81.25
[Train] Epoch: 2 [342272/620022]    Loss: 0.007953   Batch Acc: 82.81
[Train] Epoch: 2 [342336/620022]    Loss: 0.010016   Batch Acc: 73.44
[Train] Epoch: 2 [342400/620022]    Loss: 0.010823   Batch Acc: 71.88
[Train] Epoch: 2 [342464/620022]    Loss: 0.010911   Batch Acc: 67.19
[Train] Epoch: 2 [342528/620022]    Loss: 0.012024   Batch Acc: 64.06
[Train] Epoch: 2 [342592/620022]    Loss: 0.008172   Batch Acc: 79.69
[Train] Epoch: 2 [342656/620022]    Loss: 0.007886   Batch Acc: 81.25
[Train] Epoch: 2 [342720/620022]    Loss: 0.008995   Batch Acc: 79.69
[Train] Epoch: 2 [342784/620022]    Loss: 0.007819   Batch Acc: 79.69
[Train] Epoch: 2 [342848/620022]    Loss: 0.005678   Batch Acc: 87.50
[Train] Epoch: 2 [342912/620022]    Loss: 0.007080   Batch Acc: 85.94
[Train] Epoch: 2 [342976/620022]    Loss: 0.008092   Batch Acc: 78.12
[Train] Epoch: 2 [343040/620022]    Loss: 0.008648   Batch Acc: 82.81
[Train] Epoch: 2 [343104/620022]    Loss: 0.008588   Batch Acc: 76.56
[Train] Epoch: 2 [343168/620022]    Loss: 0.007675   Batch Acc: 82.81
[Train] Epoch: 2 [343232/620022]    Loss: 0.007929   Batch Acc: 79.69
[Train] Epoch: 2 [343296/620022]    Loss: 0.007797   Batch Acc: 76.56
[Train] Epoch: 2 [343360/620022]    Loss: 0.007286   Batch Acc: 84.38
[Train] Epoch: 2 [343424/620022]    Loss: 0.009116   Batch Acc: 79.69
[Train] Epoch: 2 [343488/620022]    Loss: 0.008081   Batch Acc: 82.81
[Train] Epoch: 2 [343552/620022]    Loss: 0.006904   Batch Acc: 82.81
[Train] Epoch: 2 [343616/620022]    Loss: 0.007700   Batch Acc: 81.25
[Train] Epoch: 2 [343680/620022]    Loss: 0.006943   Batch Acc: 82.81
[Train] Epoch: 2 [343744/620022]    Loss: 0.009465   Batch Acc: 71.88
[Train] Epoch: 2 [343808/620022]    Loss: 0.010576   Batch Acc: 78.12
[Train] Epoch: 2 [343872/620022]    Loss: 0.010122   Batch Acc: 68.75
[Train] Epoch: 2 [343936/620022]    Loss: 0.008512   Batch Acc: 78.12
[Train] Epoch: 2 [344000/620022]    Loss: 0.008875   Batch Acc: 84.38
[Train] Epoch: 2 [344064/620022]    Loss: 0.008662   Batch Acc: 75.00
[Train] Epoch: 2 [344128/620022]    Loss: 0.010171   Batch Acc: 75.00
[Train] Epoch: 2 [344192/620022]    Loss: 0.008880   Batch Acc: 73.44
[Train] Epoch: 2 [344256/620022]    Loss: 0.009326   Batch Acc: 76.56
[Train] Epoch: 2 [344320/620022]    Loss: 0.007843   Batch Acc: 81.25
[Train] Epoch: 2 [344384/620022]    Loss: 0.007427   Batch Acc: 81.25
[Train] Epoch: 2 [344448/620022]    Loss: 0.007921   Batch Acc: 82.81
[Train] Epoch: 2 [344512/620022]    Loss: 0.006696   Batch Acc: 82.81
[Train] Epoch: 2 [344576/620022]    Loss: 0.010774   Batch Acc: 71.88
[Train] Epoch: 2 [344640/620022]    Loss: 0.008249   Batch Acc: 84.38
[Train] Epoch: 2 [344704/620022]    Loss: 0.009390   Batch Acc: 75.00
[Train] Epoch: 2 [344768/620022]    Loss: 0.009369   Batch Acc: 76.56
[Train] Epoch: 2 [344832/620022]    Loss: 0.007397   Batch Acc: 79.69
[Train] Epoch: 2 [344896/620022]    Loss: 0.011023   Batch Acc: 73.44
[Train] Epoch: 2 [344960/620022]    Loss: 0.008518   Batch Acc: 79.69
[Train] Epoch: 2 [345024/620022]    Loss: 0.008914   Batch Acc: 81.25
[Train] Epoch: 2 [345088/620022]    Loss: 0.012030   Batch Acc: 67.19
[Train] Epoch: 2 [345152/620022]    Loss: 0.009296   Batch Acc: 78.12
[Train] Epoch: 2 [345216/620022]    Loss: 0.007410   Batch Acc: 79.69
[Train] Epoch: 2 [345280/620022]    Loss: 0.009307   Batch Acc: 76.56
[Train] Epoch: 2 [345344/620022]    Loss: 0.007276   Batch Acc: 81.25
[Train] Epoch: 2 [345408/620022]    Loss: 0.010151   Batch Acc: 75.00
[Train] Epoch: 2 [345472/620022]    Loss: 0.006055   Batch Acc: 84.38
[Train] Epoch: 2 [345536/620022]    Loss: 0.008733   Batch Acc: 82.81
[Train] Epoch: 2 [345600/620022]    Loss: 0.006830   Batch Acc: 82.81
[Train] Epoch: 2 [345664/620022]    Loss: 0.010578   Batch Acc: 71.88
[Train] Epoch: 2 [345728/620022]    Loss: 0.011108   Batch Acc: 68.75
[Train] Epoch: 2 [345792/620022]    Loss: 0.007357   Batch Acc: 82.81
[Train] Epoch: 2 [345856/620022]    Loss: 0.009310   Batch Acc: 79.69
[Train] Epoch: 2 [345920/620022]    Loss: 0.008993   Batch Acc: 78.12
[Train] Epoch: 2 [345984/620022]    Loss: 0.010903   Batch Acc: 71.88
[Train] Epoch: 2 [346048/620022]    Loss: 0.008802   Batch Acc: 75.00
[Train] Epoch: 2 [346112/620022]    Loss: 0.008988   Batch Acc: 78.12
[Train] Epoch: 2 [346176/620022]    Loss: 0.010322   Batch Acc: 75.00
[Train] Epoch: 2 [346240/620022]    Loss: 0.009198   Batch Acc: 78.12
[Train] Epoch: 2 [346304/620022]    Loss: 0.008033   Batch Acc: 76.56
[Train] Epoch: 2 [346368/620022]    Loss: 0.009319   Batch Acc: 70.31
[Train] Epoch: 2 [346432/620022]    Loss: 0.006070   Batch Acc: 89.06
[Train] Epoch: 2 [346496/620022]    Loss: 0.009092   Batch Acc: 79.69
[Train] Epoch: 2 [346560/620022]    Loss: 0.012732   Batch Acc: 67.19
[Train] Epoch: 2 [346624/620022]    Loss: 0.009577   Batch Acc: 79.69
[Train] Epoch: 2 [346688/620022]    Loss: 0.010272   Batch Acc: 64.06
[Train] Epoch: 2 [346752/620022]    Loss: 0.006436   Batch Acc: 85.94
[Train] Epoch: 2 [346816/620022]    Loss: 0.010347   Batch Acc: 73.44
[Train] Epoch: 2 [346880/620022]    Loss: 0.008377   Batch Acc: 78.12
[Train] Epoch: 2 [346944/620022]    Loss: 0.010251   Batch Acc: 70.31
[Train] Epoch: 2 [347008/620022]    Loss: 0.010135   Batch Acc: 73.44
[Train] Epoch: 2 [347072/620022]    Loss: 0.006329   Batch Acc: 85.94
[Train] Epoch: 2 [347136/620022]    Loss: 0.006884   Batch Acc: 84.38
[Train] Epoch: 2 [347200/620022]    Loss: 0.010366   Batch Acc: 68.75
[Train] Epoch: 2 [347264/620022]    Loss: 0.006344   Batch Acc: 89.06
[Train] Epoch: 2 [347328/620022]    Loss: 0.007022   Batch Acc: 85.94
[Train] Epoch: 2 [347392/620022]    Loss: 0.007518   Batch Acc: 81.25
[Train] Epoch: 2 [347456/620022]    Loss: 0.009017   Batch Acc: 75.00
[Train] Epoch: 2 [347520/620022]    Loss: 0.008057   Batch Acc: 79.69
[Train] Epoch: 2 [347584/620022]    Loss: 0.007189   Batch Acc: 81.25
[Train] Epoch: 2 [347648/620022]    Loss: 0.008011   Batch Acc: 79.69
[Train] Epoch: 2 [347712/620022]    Loss: 0.010346   Batch Acc: 73.44
[Train] Epoch: 2 [347776/620022]    Loss: 0.009926   Batch Acc: 67.19
[Train] Epoch: 2 [347840/620022]    Loss: 0.006172   Batch Acc: 90.62
[Train] Epoch: 2 [347904/620022]    Loss: 0.007829   Batch Acc: 79.69
[Train] Epoch: 2 [347968/620022]    Loss: 0.007199   Batch Acc: 82.81
[Train] Epoch: 2 [348032/620022]    Loss: 0.006965   Batch Acc: 82.81
[Train] Epoch: 2 [348096/620022]    Loss: 0.007928   Batch Acc: 76.56
[Train] Epoch: 2 [348160/620022]    Loss: 0.007860   Batch Acc: 76.56
[Train] Epoch: 2 [348224/620022]    Loss: 0.009375   Batch Acc: 75.00
[Train] Epoch: 2 [348288/620022]    Loss: 0.008169   Batch Acc: 76.56
[Train] Epoch: 2 [348352/620022]    Loss: 0.008972   Batch Acc: 75.00
[Train] Epoch: 2 [348416/620022]    Loss: 0.008980   Batch Acc: 73.44
[Train] Epoch: 2 [348480/620022]    Loss: 0.009541   Batch Acc: 81.25
[Train] Epoch: 2 [348544/620022]    Loss: 0.007231   Batch Acc: 84.38
[Train] Epoch: 2 [348608/620022]    Loss: 0.007904   Batch Acc: 75.00
[Train] Epoch: 2 [348672/620022]    Loss: 0.008754   Batch Acc: 76.56
[Train] Epoch: 2 [348736/620022]    Loss: 0.010940   Batch Acc: 67.19
[Train] Epoch: 2 [348800/620022]    Loss: 0.008909   Batch Acc: 75.00
[Train] Epoch: 2 [348864/620022]    Loss: 0.008170   Batch Acc: 81.25
[Train] Epoch: 2 [348928/620022]    Loss: 0.009262   Batch Acc: 75.00
[Train] Epoch: 2 [348992/620022]    Loss: 0.007456   Batch Acc: 82.81
[Train] Epoch: 2 [349056/620022]    Loss: 0.007845   Batch Acc: 76.56
[Train] Epoch: 2 [349120/620022]    Loss: 0.010705   Batch Acc: 73.44
[Train] Epoch: 2 [349184/620022]    Loss: 0.006589   Batch Acc: 81.25
[Train] Epoch: 2 [349248/620022]    Loss: 0.009696   Batch Acc: 70.31
[Train] Epoch: 2 [349312/620022]    Loss: 0.008754   Batch Acc: 79.69
[Train] Epoch: 2 [349376/620022]    Loss: 0.007336   Batch Acc: 82.81
[Train] Epoch: 2 [349440/620022]    Loss: 0.009741   Batch Acc: 75.00
[Train] Epoch: 2 [349504/620022]    Loss: 0.010026   Batch Acc: 75.00
[Train] Epoch: 2 [349568/620022]    Loss: 0.009244   Batch Acc: 73.44
[Train] Epoch: 2 [349632/620022]    Loss: 0.008336   Batch Acc: 78.12
[Train] Epoch: 2 [349696/620022]    Loss: 0.008104   Batch Acc: 76.56
[Train] Epoch: 2 [349760/620022]    Loss: 0.008457   Batch Acc: 79.69
[Train] Epoch: 2 [349824/620022]    Loss: 0.007824   Batch Acc: 85.94
[Train] Epoch: 2 [349888/620022]    Loss: 0.009339   Batch Acc: 75.00
[Train] Epoch: 2 [349952/620022]    Loss: 0.007869   Batch Acc: 78.12
[Train] Epoch: 2 [350016/620022]    Loss: 0.007262   Batch Acc: 82.81
[Train] Epoch: 2 [350080/620022]    Loss: 0.009601   Batch Acc: 73.44
[Train] Epoch: 2 [350144/620022]    Loss: 0.007761   Batch Acc: 76.56
[Train] Epoch: 2 [350208/620022]    Loss: 0.009527   Batch Acc: 78.12
[Train] Epoch: 2 [350272/620022]    Loss: 0.007449   Batch Acc: 84.38
[Train] Epoch: 2 [350336/620022]    Loss: 0.012427   Batch Acc: 68.75
[Train] Epoch: 2 [350400/620022]    Loss: 0.009016   Batch Acc: 76.56
[Train] Epoch: 2 [350464/620022]    Loss: 0.008587   Batch Acc: 76.56
[Train] Epoch: 2 [350528/620022]    Loss: 0.007145   Batch Acc: 84.38
[Train] Epoch: 2 [350592/620022]    Loss: 0.007161   Batch Acc: 82.81
[Train] Epoch: 2 [350656/620022]    Loss: 0.007432   Batch Acc: 84.38
[Train] Epoch: 2 [350720/620022]    Loss: 0.007972   Batch Acc: 79.69
[Train] Epoch: 2 [350784/620022]    Loss: 0.011297   Batch Acc: 73.44
[Train] Epoch: 2 [350848/620022]    Loss: 0.008364   Batch Acc: 75.00
[Train] Epoch: 2 [350912/620022]    Loss: 0.009762   Batch Acc: 76.56
[Train] Epoch: 2 [350976/620022]    Loss: 0.009740   Batch Acc: 70.31
[Train] Epoch: 2 [351040/620022]    Loss: 0.008109   Batch Acc: 79.69
[Train] Epoch: 2 [351104/620022]    Loss: 0.007905   Batch Acc: 81.25
[Train] Epoch: 2 [351168/620022]    Loss: 0.010714   Batch Acc: 67.19
[Train] Epoch: 2 [351232/620022]    Loss: 0.006122   Batch Acc: 89.06
[Train] Epoch: 2 [351296/620022]    Loss: 0.007462   Batch Acc: 76.56
[Train] Epoch: 2 [351360/620022]    Loss: 0.007934   Batch Acc: 82.81
[Train] Epoch: 2 [351424/620022]    Loss: 0.007148   Batch Acc: 84.38
[Train] Epoch: 2 [351488/620022]    Loss: 0.006994   Batch Acc: 85.94
[Train] Epoch: 2 [351552/620022]    Loss: 0.008401   Batch Acc: 76.56
[Train] Epoch: 2 [351616/620022]    Loss: 0.009084   Batch Acc: 73.44
[Train] Epoch: 2 [351680/620022]    Loss: 0.009370   Batch Acc: 76.56
[Train] Epoch: 2 [351744/620022]    Loss: 0.006787   Batch Acc: 81.25
[Train] Epoch: 2 [351808/620022]    Loss: 0.011293   Batch Acc: 68.75
[Train] Epoch: 2 [351872/620022]    Loss: 0.009883   Batch Acc: 73.44
[Train] Epoch: 2 [351936/620022]    Loss: 0.008948   Batch Acc: 76.56
[Train] Epoch: 2 [352000/620022]    Loss: 0.006802   Batch Acc: 87.50
[Train] Epoch: 2 [352064/620022]    Loss: 0.010441   Batch Acc: 67.19
[Train] Epoch: 2 [352128/620022]    Loss: 0.009083   Batch Acc: 75.00
[Train] Epoch: 2 [352192/620022]    Loss: 0.011073   Batch Acc: 68.75
[Train] Epoch: 2 [352256/620022]    Loss: 0.008735   Batch Acc: 82.81
[Train] Epoch: 2 [352320/620022]    Loss: 0.005720   Batch Acc: 85.94
[Train] Epoch: 2 [352384/620022]    Loss: 0.009009   Batch Acc: 78.12
[Train] Epoch: 2 [352448/620022]    Loss: 0.007719   Batch Acc: 79.69
[Train] Epoch: 2 [352512/620022]    Loss: 0.008287   Batch Acc: 79.69
[Train] Epoch: 2 [352576/620022]    Loss: 0.010703   Batch Acc: 76.56
[Train] Epoch: 2 [352640/620022]    Loss: 0.007102   Batch Acc: 84.38
[Train] Epoch: 2 [352704/620022]    Loss: 0.007944   Batch Acc: 78.12
[Train] Epoch: 2 [352768/620022]    Loss: 0.010391   Batch Acc: 73.44
[Train] Epoch: 2 [352832/620022]    Loss: 0.008307   Batch Acc: 82.81
[Train] Epoch: 2 [352896/620022]    Loss: 0.006459   Batch Acc: 81.25
[Train] Epoch: 2 [352960/620022]    Loss: 0.009225   Batch Acc: 78.12
[Train] Epoch: 2 [353024/620022]    Loss: 0.009137   Batch Acc: 75.00
[Train] Epoch: 2 [353088/620022]    Loss: 0.008548   Batch Acc: 76.56
[Train] Epoch: 2 [353152/620022]    Loss: 0.008896   Batch Acc: 78.12
[Train] Epoch: 2 [353216/620022]    Loss: 0.008392   Batch Acc: 75.00
[Train] Epoch: 2 [353280/620022]    Loss: 0.008273   Batch Acc: 81.25
[Train] Epoch: 2 [353344/620022]    Loss: 0.008465   Batch Acc: 78.12
[Train] Epoch: 2 [353408/620022]    Loss: 0.009548   Batch Acc: 73.44
[Train] Epoch: 2 [353472/620022]    Loss: 0.008808   Batch Acc: 81.25
[Train] Epoch: 2 [353536/620022]    Loss: 0.009193   Batch Acc: 71.88
[Train] Epoch: 2 [353600/620022]    Loss: 0.009981   Batch Acc: 75.00
[Train] Epoch: 2 [353664/620022]    Loss: 0.008062   Batch Acc: 78.12
[Train] Epoch: 2 [353728/620022]    Loss: 0.011140   Batch Acc: 67.19
[Train] Epoch: 2 [353792/620022]    Loss: 0.008990   Batch Acc: 81.25
[Train] Epoch: 2 [353856/620022]    Loss: 0.009719   Batch Acc: 78.12
[Train] Epoch: 2 [353920/620022]    Loss: 0.010318   Batch Acc: 70.31
[Train] Epoch: 2 [353984/620022]    Loss: 0.011394   Batch Acc: 68.75
[Train] Epoch: 2 [354048/620022]    Loss: 0.008721   Batch Acc: 76.56
[Train] Epoch: 2 [354112/620022]    Loss: 0.008248   Batch Acc: 78.12
[Train] Epoch: 2 [354176/620022]    Loss: 0.007266   Batch Acc: 76.56
[Train] Epoch: 2 [354240/620022]    Loss: 0.008973   Batch Acc: 78.12
[Train] Epoch: 2 [354304/620022]    Loss: 0.007415   Batch Acc: 79.69
[Train] Epoch: 2 [354368/620022]    Loss: 0.010405   Batch Acc: 70.31
[Train] Epoch: 2 [354432/620022]    Loss: 0.010093   Batch Acc: 70.31
[Train] Epoch: 2 [354496/620022]    Loss: 0.009042   Batch Acc: 73.44
[Train] Epoch: 2 [354560/620022]    Loss: 0.008865   Batch Acc: 76.56
[Train] Epoch: 2 [354624/620022]    Loss: 0.009181   Batch Acc: 79.69
[Train] Epoch: 2 [354688/620022]    Loss: 0.006712   Batch Acc: 85.94
[Train] Epoch: 2 [354752/620022]    Loss: 0.010802   Batch Acc: 75.00
[Train] Epoch: 2 [354816/620022]    Loss: 0.009196   Batch Acc: 68.75
[Train] Epoch: 2 [354880/620022]    Loss: 0.008186   Batch Acc: 81.25
[Train] Epoch: 2 [354944/620022]    Loss: 0.006982   Batch Acc: 81.25
[Train] Epoch: 2 [355008/620022]    Loss: 0.009096   Batch Acc: 76.56
[Train] Epoch: 2 [355072/620022]    Loss: 0.009120   Batch Acc: 81.25
[Train] Epoch: 2 [355136/620022]    Loss: 0.009013   Batch Acc: 78.12
[Train] Epoch: 2 [355200/620022]    Loss: 0.007197   Batch Acc: 82.81
[Train] Epoch: 2 [355264/620022]    Loss: 0.008688   Batch Acc: 81.25
[Train] Epoch: 2 [355328/620022]    Loss: 0.010325   Batch Acc: 78.12
[Train] Epoch: 2 [355392/620022]    Loss: 0.010574   Batch Acc: 71.88
[Train] Epoch: 2 [355456/620022]    Loss: 0.008085   Batch Acc: 79.69
[Train] Epoch: 2 [355520/620022]    Loss: 0.007958   Batch Acc: 82.81
[Train] Epoch: 2 [355584/620022]    Loss: 0.008023   Batch Acc: 79.69
[Train] Epoch: 2 [355648/620022]    Loss: 0.007537   Batch Acc: 82.81
[Train] Epoch: 2 [355712/620022]    Loss: 0.008760   Batch Acc: 76.56
[Train] Epoch: 2 [355776/620022]    Loss: 0.009683   Batch Acc: 71.88
[Train] Epoch: 2 [355840/620022]    Loss: 0.006708   Batch Acc: 81.25
[Train] Epoch: 2 [355904/620022]    Loss: 0.007950   Batch Acc: 73.44
[Train] Epoch: 2 [355968/620022]    Loss: 0.010381   Batch Acc: 68.75
[Train] Epoch: 2 [356032/620022]    Loss: 0.009271   Batch Acc: 75.00
[Train] Epoch: 2 [356096/620022]    Loss: 0.010849   Batch Acc: 65.62
[Train] Epoch: 2 [356160/620022]    Loss: 0.007500   Batch Acc: 84.38
[Train] Epoch: 2 [356224/620022]    Loss: 0.011335   Batch Acc: 68.75
[Train] Epoch: 2 [356288/620022]    Loss: 0.010750   Batch Acc: 79.69
[Train] Epoch: 2 [356352/620022]    Loss: 0.008235   Batch Acc: 79.69
[Train] Epoch: 2 [356416/620022]    Loss: 0.008668   Batch Acc: 79.69
[Train] Epoch: 2 [356480/620022]    Loss: 0.008526   Batch Acc: 79.69
[Train] Epoch: 2 [356544/620022]    Loss: 0.007235   Batch Acc: 81.25
[Train] Epoch: 2 [356608/620022]    Loss: 0.008326   Batch Acc: 79.69
[Train] Epoch: 2 [356672/620022]    Loss: 0.008156   Batch Acc: 79.69
[Train] Epoch: 2 [356736/620022]    Loss: 0.007677   Batch Acc: 78.12
[Train] Epoch: 2 [356800/620022]    Loss: 0.008112   Batch Acc: 76.56
[Train] Epoch: 2 [356864/620022]    Loss: 0.009350   Batch Acc: 70.31
[Train] Epoch: 2 [356928/620022]    Loss: 0.009825   Batch Acc: 76.56
[Train] Epoch: 2 [356992/620022]    Loss: 0.009895   Batch Acc: 76.56
[Train] Epoch: 2 [357056/620022]    Loss: 0.010312   Batch Acc: 75.00
[Train] Epoch: 2 [357120/620022]    Loss: 0.009275   Batch Acc: 76.56
[Train] Epoch: 2 [357184/620022]    Loss: 0.008417   Batch Acc: 75.00
[Train] Epoch: 2 [357248/620022]    Loss: 0.009787   Batch Acc: 75.00
[Train] Epoch: 2 [357312/620022]    Loss: 0.010603   Batch Acc: 73.44
[Train] Epoch: 2 [357376/620022]    Loss: 0.008532   Batch Acc: 79.69
[Train] Epoch: 2 [357440/620022]    Loss: 0.008818   Batch Acc: 76.56
[Train] Epoch: 2 [357504/620022]    Loss: 0.008314   Batch Acc: 73.44
[Train] Epoch: 2 [357568/620022]    Loss: 0.009047   Batch Acc: 75.00
[Train] Epoch: 2 [357632/620022]    Loss: 0.009168   Batch Acc: 75.00
[Train] Epoch: 2 [357696/620022]    Loss: 0.008266   Batch Acc: 78.12
[Train] Epoch: 2 [357760/620022]    Loss: 0.013187   Batch Acc: 67.19
[Train] Epoch: 2 [357824/620022]    Loss: 0.010580   Batch Acc: 76.56
[Train] Epoch: 2 [357888/620022]    Loss: 0.006042   Batch Acc: 82.81
[Train] Epoch: 2 [357952/620022]    Loss: 0.010180   Batch Acc: 73.44
[Train] Epoch: 2 [358016/620022]    Loss: 0.009123   Batch Acc: 75.00
[Train] Epoch: 2 [358080/620022]    Loss: 0.007992   Batch Acc: 79.69
[Train] Epoch: 2 [358144/620022]    Loss: 0.008155   Batch Acc: 76.56
[Train] Epoch: 2 [358208/620022]    Loss: 0.008641   Batch Acc: 78.12
[Train] Epoch: 2 [358272/620022]    Loss: 0.005933   Batch Acc: 87.50
[Train] Epoch: 2 [358336/620022]    Loss: 0.006344   Batch Acc: 87.50
[Train] Epoch: 2 [358400/620022]    Loss: 0.010624   Batch Acc: 75.00
[Train] Epoch: 2 [358464/620022]    Loss: 0.006862   Batch Acc: 84.38
[Train] Epoch: 2 [358528/620022]    Loss: 0.008556   Batch Acc: 76.56
[Train] Epoch: 2 [358592/620022]    Loss: 0.010132   Batch Acc: 76.56
[Train] Epoch: 2 [358656/620022]    Loss: 0.006671   Batch Acc: 79.69
[Train] Epoch: 2 [358720/620022]    Loss: 0.007819   Batch Acc: 79.69
[Train] Epoch: 2 [358784/620022]    Loss: 0.007047   Batch Acc: 85.94
[Train] Epoch: 2 [358848/620022]    Loss: 0.008842   Batch Acc: 81.25
[Train] Epoch: 2 [358912/620022]    Loss: 0.009835   Batch Acc: 71.88
[Train] Epoch: 2 [358976/620022]    Loss: 0.007276   Batch Acc: 84.38
[Train] Epoch: 2 [359040/620022]    Loss: 0.007777   Batch Acc: 82.81
[Train] Epoch: 2 [359104/620022]    Loss: 0.009360   Batch Acc: 76.56
[Train] Epoch: 2 [359168/620022]    Loss: 0.007456   Batch Acc: 79.69
[Train] Epoch: 2 [359232/620022]    Loss: 0.007938   Batch Acc: 79.69
[Train] Epoch: 2 [359296/620022]    Loss: 0.011113   Batch Acc: 68.75
[Train] Epoch: 2 [359360/620022]    Loss: 0.011384   Batch Acc: 65.62
[Train] Epoch: 2 [359424/620022]    Loss: 0.008487   Batch Acc: 75.00
[Train] Epoch: 2 [359488/620022]    Loss: 0.009793   Batch Acc: 76.56
[Train] Epoch: 2 [359552/620022]    Loss: 0.011712   Batch Acc: 65.62
[Train] Epoch: 2 [359616/620022]    Loss: 0.007396   Batch Acc: 87.50
[Train] Epoch: 2 [359680/620022]    Loss: 0.008938   Batch Acc: 76.56
[Train] Epoch: 2 [359744/620022]    Loss: 0.009252   Batch Acc: 78.12
[Train] Epoch: 2 [359808/620022]    Loss: 0.008946   Batch Acc: 84.38
[Train] Epoch: 2 [359872/620022]    Loss: 0.007724   Batch Acc: 76.56
[Train] Epoch: 2 [359936/620022]    Loss: 0.010830   Batch Acc: 73.44
[Train] Epoch: 2 [360000/620022]    Loss: 0.011271   Batch Acc: 67.19
[Train] Epoch: 2 [360064/620022]    Loss: 0.007632   Batch Acc: 78.12
[Train] Epoch: 2 [360128/620022]    Loss: 0.008689   Batch Acc: 78.12
[Train] Epoch: 2 [360192/620022]    Loss: 0.010559   Batch Acc: 71.88
[Train] Epoch: 2 [360256/620022]    Loss: 0.010469   Batch Acc: 73.44
[Train] Epoch: 2 [360320/620022]    Loss: 0.007301   Batch Acc: 82.81
[Train] Epoch: 2 [360384/620022]    Loss: 0.005345   Batch Acc: 90.62
[Train] Epoch: 2 [360448/620022]    Loss: 0.008279   Batch Acc: 75.00
[Train] Epoch: 2 [360512/620022]    Loss: 0.008801   Batch Acc: 76.56
[Train] Epoch: 2 [360576/620022]    Loss: 0.009698   Batch Acc: 78.12
[Train] Epoch: 2 [360640/620022]    Loss: 0.010764   Batch Acc: 64.06
[Train] Epoch: 2 [360704/620022]    Loss: 0.008187   Batch Acc: 78.12
[Train] Epoch: 2 [360768/620022]    Loss: 0.006700   Batch Acc: 85.94
[Train] Epoch: 2 [360832/620022]    Loss: 0.007633   Batch Acc: 84.38
[Train] Epoch: 2 [360896/620022]    Loss: 0.008501   Batch Acc: 78.12
[Train] Epoch: 2 [360960/620022]    Loss: 0.008246   Batch Acc: 82.81
[Train] Epoch: 2 [361024/620022]    Loss: 0.007804   Batch Acc: 78.12
[Train] Epoch: 2 [361088/620022]    Loss: 0.006205   Batch Acc: 84.38
[Train] Epoch: 2 [361152/620022]    Loss: 0.008798   Batch Acc: 78.12
[Train] Epoch: 2 [361216/620022]    Loss: 0.009365   Batch Acc: 76.56
[Train] Epoch: 2 [361280/620022]    Loss: 0.010249   Batch Acc: 76.56
[Train] Epoch: 2 [361344/620022]    Loss: 0.010265   Batch Acc: 70.31
[Train] Epoch: 2 [361408/620022]    Loss: 0.008200   Batch Acc: 81.25
[Train] Epoch: 2 [361472/620022]    Loss: 0.011603   Batch Acc: 70.31
[Train] Epoch: 2 [361536/620022]    Loss: 0.009530   Batch Acc: 76.56
[Train] Epoch: 2 [361600/620022]    Loss: 0.007986   Batch Acc: 81.25
[Train] Epoch: 2 [361664/620022]    Loss: 0.008113   Batch Acc: 81.25
[Train] Epoch: 2 [361728/620022]    Loss: 0.010259   Batch Acc: 68.75
[Train] Epoch: 2 [361792/620022]    Loss: 0.007572   Batch Acc: 78.12
[Train] Epoch: 2 [361856/620022]    Loss: 0.008292   Batch Acc: 75.00
[Train] Epoch: 2 [361920/620022]    Loss: 0.008843   Batch Acc: 76.56
[Train] Epoch: 2 [361984/620022]    Loss: 0.009061   Batch Acc: 73.44
[Train] Epoch: 2 [362048/620022]    Loss: 0.007775   Batch Acc: 81.25
[Train] Epoch: 2 [362112/620022]    Loss: 0.007982   Batch Acc: 78.12
[Train] Epoch: 2 [362176/620022]    Loss: 0.009061   Batch Acc: 76.56
[Train] Epoch: 2 [362240/620022]    Loss: 0.009877   Batch Acc: 70.31
[Train] Epoch: 2 [362304/620022]    Loss: 0.008659   Batch Acc: 76.56
[Train] Epoch: 2 [362368/620022]    Loss: 0.011098   Batch Acc: 71.88
[Train] Epoch: 2 [362432/620022]    Loss: 0.010767   Batch Acc: 68.75
[Train] Epoch: 2 [362496/620022]    Loss: 0.010041   Batch Acc: 75.00
[Train] Epoch: 2 [362560/620022]    Loss: 0.007578   Batch Acc: 76.56
[Train] Epoch: 2 [362624/620022]    Loss: 0.006200   Batch Acc: 84.38
[Train] Epoch: 2 [362688/620022]    Loss: 0.009542   Batch Acc: 73.44
[Train] Epoch: 2 [362752/620022]    Loss: 0.008897   Batch Acc: 79.69
[Train] Epoch: 2 [362816/620022]    Loss: 0.007939   Batch Acc: 82.81
[Train] Epoch: 2 [362880/620022]    Loss: 0.011780   Batch Acc: 64.06
[Train] Epoch: 2 [362944/620022]    Loss: 0.008660   Batch Acc: 76.56
[Train] Epoch: 2 [363008/620022]    Loss: 0.007389   Batch Acc: 81.25
[Train] Epoch: 2 [363072/620022]    Loss: 0.010384   Batch Acc: 71.88
[Train] Epoch: 2 [363136/620022]    Loss: 0.008141   Batch Acc: 76.56
[Train] Epoch: 2 [363200/620022]    Loss: 0.008276   Batch Acc: 78.12
[Train] Epoch: 2 [363264/620022]    Loss: 0.008970   Batch Acc: 76.56
[Train] Epoch: 2 [363328/620022]    Loss: 0.009103   Batch Acc: 79.69
[Train] Epoch: 2 [363392/620022]    Loss: 0.009499   Batch Acc: 73.44
[Train] Epoch: 2 [363456/620022]    Loss: 0.010053   Batch Acc: 76.56
[Train] Epoch: 2 [363520/620022]    Loss: 0.008817   Batch Acc: 79.69
[Train] Epoch: 2 [363584/620022]    Loss: 0.008470   Batch Acc: 81.25
[Train] Epoch: 2 [363648/620022]    Loss: 0.006342   Batch Acc: 87.50
[Train] Epoch: 2 [363712/620022]    Loss: 0.008352   Batch Acc: 82.81
[Train] Epoch: 2 [363776/620022]    Loss: 0.008661   Batch Acc: 81.25
[Train] Epoch: 2 [363840/620022]    Loss: 0.008982   Batch Acc: 73.44
[Train] Epoch: 2 [363904/620022]    Loss: 0.011063   Batch Acc: 75.00
[Train] Epoch: 2 [363968/620022]    Loss: 0.007570   Batch Acc: 82.81
[Train] Epoch: 2 [364032/620022]    Loss: 0.007943   Batch Acc: 82.81
[Train] Epoch: 2 [364096/620022]    Loss: 0.008432   Batch Acc: 76.56
[Train] Epoch: 2 [364160/620022]    Loss: 0.007155   Batch Acc: 85.94
[Train] Epoch: 2 [364224/620022]    Loss: 0.008630   Batch Acc: 76.56
[Train] Epoch: 2 [364288/620022]    Loss: 0.007178   Batch Acc: 75.00
[Train] Epoch: 2 [364352/620022]    Loss: 0.008900   Batch Acc: 79.69
[Train] Epoch: 2 [364416/620022]    Loss: 0.007747   Batch Acc: 84.38
[Train] Epoch: 2 [364480/620022]    Loss: 0.010200   Batch Acc: 70.31
[Train] Epoch: 2 [364544/620022]    Loss: 0.009440   Batch Acc: 73.44
[Train] Epoch: 2 [364608/620022]    Loss: 0.008018   Batch Acc: 84.38
[Train] Epoch: 2 [364672/620022]    Loss: 0.009526   Batch Acc: 71.88
[Train] Epoch: 2 [364736/620022]    Loss: 0.008195   Batch Acc: 78.12
[Train] Epoch: 2 [364800/620022]    Loss: 0.008371   Batch Acc: 78.12
[Train] Epoch: 2 [364864/620022]    Loss: 0.007082   Batch Acc: 79.69
[Train] Epoch: 2 [364928/620022]    Loss: 0.009106   Batch Acc: 73.44
[Train] Epoch: 2 [364992/620022]    Loss: 0.008907   Batch Acc: 76.56
[Train] Epoch: 2 [365056/620022]    Loss: 0.008700   Batch Acc: 76.56
[Train] Epoch: 2 [365120/620022]    Loss: 0.010466   Batch Acc: 76.56
[Train] Epoch: 2 [365184/620022]    Loss: 0.008862   Batch Acc: 79.69
[Train] Epoch: 2 [365248/620022]    Loss: 0.009874   Batch Acc: 78.12
[Train] Epoch: 2 [365312/620022]    Loss: 0.008825   Batch Acc: 85.94
[Train] Epoch: 2 [365376/620022]    Loss: 0.010352   Batch Acc: 71.88
[Train] Epoch: 2 [365440/620022]    Loss: 0.009487   Batch Acc: 65.62
[Train] Epoch: 2 [365504/620022]    Loss: 0.009412   Batch Acc: 73.44
[Train] Epoch: 2 [365568/620022]    Loss: 0.009456   Batch Acc: 70.31
[Train] Epoch: 2 [365632/620022]    Loss: 0.008420   Batch Acc: 84.38
[Train] Epoch: 2 [365696/620022]    Loss: 0.006752   Batch Acc: 85.94
[Train] Epoch: 2 [365760/620022]    Loss: 0.007368   Batch Acc: 79.69
[Train] Epoch: 2 [365824/620022]    Loss: 0.007412   Batch Acc: 79.69
[Train] Epoch: 2 [365888/620022]    Loss: 0.007359   Batch Acc: 85.94
[Train] Epoch: 2 [365952/620022]    Loss: 0.009952   Batch Acc: 68.75
[Train] Epoch: 2 [366016/620022]    Loss: 0.007685   Batch Acc: 82.81
[Train] Epoch: 2 [366080/620022]    Loss: 0.009713   Batch Acc: 76.56
[Train] Epoch: 2 [366144/620022]    Loss: 0.009771   Batch Acc: 75.00
[Train] Epoch: 2 [366208/620022]    Loss: 0.010028   Batch Acc: 75.00
[Train] Epoch: 2 [366272/620022]    Loss: 0.005008   Batch Acc: 92.19
[Train] Epoch: 2 [366336/620022]    Loss: 0.008998   Batch Acc: 76.56
[Train] Epoch: 2 [366400/620022]    Loss: 0.009334   Batch Acc: 76.56
[Train] Epoch: 2 [366464/620022]    Loss: 0.006358   Batch Acc: 84.38
[Train] Epoch: 2 [366528/620022]    Loss: 0.008123   Batch Acc: 76.56
[Train] Epoch: 2 [366592/620022]    Loss: 0.008025   Batch Acc: 81.25
[Train] Epoch: 2 [366656/620022]    Loss: 0.010525   Batch Acc: 78.12
[Train] Epoch: 2 [366720/620022]    Loss: 0.009529   Batch Acc: 71.88
[Train] Epoch: 2 [366784/620022]    Loss: 0.011117   Batch Acc: 65.62
[Train] Epoch: 2 [366848/620022]    Loss: 0.011137   Batch Acc: 71.88
[Train] Epoch: 2 [366912/620022]    Loss: 0.010425   Batch Acc: 71.88
[Train] Epoch: 2 [366976/620022]    Loss: 0.007638   Batch Acc: 84.38
[Train] Epoch: 2 [367040/620022]    Loss: 0.007355   Batch Acc: 78.12
[Train] Epoch: 2 [367104/620022]    Loss: 0.009886   Batch Acc: 79.69
[Train] Epoch: 2 [367168/620022]    Loss: 0.009361   Batch Acc: 79.69
[Train] Epoch: 2 [367232/620022]    Loss: 0.007361   Batch Acc: 82.81
[Train] Epoch: 2 [367296/620022]    Loss: 0.008829   Batch Acc: 75.00
[Train] Epoch: 2 [367360/620022]    Loss: 0.008583   Batch Acc: 79.69
[Train] Epoch: 2 [367424/620022]    Loss: 0.009907   Batch Acc: 71.88
[Train] Epoch: 2 [367488/620022]    Loss: 0.008704   Batch Acc: 78.12
[Train] Epoch: 2 [367552/620022]    Loss: 0.008350   Batch Acc: 78.12
[Train] Epoch: 2 [367616/620022]    Loss: 0.008581   Batch Acc: 78.12
[Train] Epoch: 2 [367680/620022]    Loss: 0.007925   Batch Acc: 79.69
[Train] Epoch: 2 [367744/620022]    Loss: 0.009178   Batch Acc: 78.12
[Train] Epoch: 2 [367808/620022]    Loss: 0.006529   Batch Acc: 82.81
[Train] Epoch: 2 [367872/620022]    Loss: 0.010115   Batch Acc: 73.44
[Train] Epoch: 2 [367936/620022]    Loss: 0.008038   Batch Acc: 78.12
[Train] Epoch: 2 [368000/620022]    Loss: 0.006772   Batch Acc: 82.81
[Train] Epoch: 2 [368064/620022]    Loss: 0.005907   Batch Acc: 89.06
[Train] Epoch: 2 [368128/620022]    Loss: 0.007897   Batch Acc: 78.12
[Train] Epoch: 2 [368192/620022]    Loss: 0.007653   Batch Acc: 84.38
[Train] Epoch: 2 [368256/620022]    Loss: 0.009439   Batch Acc: 75.00
[Train] Epoch: 2 [368320/620022]    Loss: 0.007848   Batch Acc: 82.81
[Train] Epoch: 2 [368384/620022]    Loss: 0.007281   Batch Acc: 81.25
[Train] Epoch: 2 [368448/620022]    Loss: 0.008661   Batch Acc: 79.69
[Train] Epoch: 2 [368512/620022]    Loss: 0.008748   Batch Acc: 78.12
[Train] Epoch: 2 [368576/620022]    Loss: 0.009831   Batch Acc: 71.88
[Train] Epoch: 2 [368640/620022]    Loss: 0.010575   Batch Acc: 70.31
[Train] Epoch: 2 [368704/620022]    Loss: 0.007305   Batch Acc: 82.81
[Train] Epoch: 2 [368768/620022]    Loss: 0.010031   Batch Acc: 75.00
[Train] Epoch: 2 [368832/620022]    Loss: 0.008822   Batch Acc: 75.00
[Train] Epoch: 2 [368896/620022]    Loss: 0.009269   Batch Acc: 75.00
[Train] Epoch: 2 [368960/620022]    Loss: 0.007936   Batch Acc: 84.38
[Train] Epoch: 2 [369024/620022]    Loss: 0.009405   Batch Acc: 71.88
[Train] Epoch: 2 [369088/620022]    Loss: 0.010711   Batch Acc: 67.19
[Train] Epoch: 2 [369152/620022]    Loss: 0.010826   Batch Acc: 75.00
[Train] Epoch: 2 [369216/620022]    Loss: 0.011035   Batch Acc: 71.88
[Train] Epoch: 2 [369280/620022]    Loss: 0.007675   Batch Acc: 81.25
[Train] Epoch: 2 [369344/620022]    Loss: 0.008047   Batch Acc: 89.06
[Train] Epoch: 2 [369408/620022]    Loss: 0.007663   Batch Acc: 84.38
[Train] Epoch: 2 [369472/620022]    Loss: 0.009349   Batch Acc: 70.31
[Train] Epoch: 2 [369536/620022]    Loss: 0.005892   Batch Acc: 90.62
[Train] Epoch: 2 [369600/620022]    Loss: 0.007538   Batch Acc: 84.38
[Train] Epoch: 2 [369664/620022]    Loss: 0.008290   Batch Acc: 78.12
[Train] Epoch: 2 [369728/620022]    Loss: 0.009892   Batch Acc: 68.75
[Train] Epoch: 2 [369792/620022]    Loss: 0.007429   Batch Acc: 79.69
[Train] Epoch: 2 [369856/620022]    Loss: 0.010022   Batch Acc: 70.31
[Train] Epoch: 2 [369920/620022]    Loss: 0.008815   Batch Acc: 75.00
[Train] Epoch: 2 [369984/620022]    Loss: 0.008648   Batch Acc: 73.44
[Train] Epoch: 2 [370048/620022]    Loss: 0.009077   Batch Acc: 71.88
[Train] Epoch: 2 [370112/620022]    Loss: 0.007872   Batch Acc: 82.81
[Train] Epoch: 2 [370176/620022]    Loss: 0.007695   Batch Acc: 78.12
[Train] Epoch: 2 [370240/620022]    Loss: 0.006782   Batch Acc: 81.25
[Train] Epoch: 2 [370304/620022]    Loss: 0.008297   Batch Acc: 73.44
[Train] Epoch: 2 [370368/620022]    Loss: 0.009042   Batch Acc: 75.00
[Train] Epoch: 2 [370432/620022]    Loss: 0.011477   Batch Acc: 76.56
[Train] Epoch: 2 [370496/620022]    Loss: 0.008643   Batch Acc: 76.56
[Train] Epoch: 2 [370560/620022]    Loss: 0.008377   Batch Acc: 81.25
[Train] Epoch: 2 [370624/620022]    Loss: 0.007188   Batch Acc: 82.81
[Train] Epoch: 2 [370688/620022]    Loss: 0.008648   Batch Acc: 75.00
[Train] Epoch: 2 [370752/620022]    Loss: 0.009788   Batch Acc: 75.00
[Train] Epoch: 2 [370816/620022]    Loss: 0.009076   Batch Acc: 76.56
[Train] Epoch: 2 [370880/620022]    Loss: 0.005854   Batch Acc: 85.94
[Train] Epoch: 2 [370944/620022]    Loss: 0.007961   Batch Acc: 79.69
[Train] Epoch: 2 [371008/620022]    Loss: 0.009536   Batch Acc: 78.12
[Train] Epoch: 2 [371072/620022]    Loss: 0.007034   Batch Acc: 85.94
[Train] Epoch: 2 [371136/620022]    Loss: 0.010396   Batch Acc: 75.00
[Train] Epoch: 2 [371200/620022]    Loss: 0.008466   Batch Acc: 73.44
[Train] Epoch: 2 [371264/620022]    Loss: 0.008963   Batch Acc: 75.00
[Train] Epoch: 2 [371328/620022]    Loss: 0.008149   Batch Acc: 81.25
[Train] Epoch: 2 [371392/620022]    Loss: 0.009505   Batch Acc: 79.69
[Train] Epoch: 2 [371456/620022]    Loss: 0.008902   Batch Acc: 73.44
[Train] Epoch: 2 [371520/620022]    Loss: 0.008404   Batch Acc: 79.69
[Train] Epoch: 2 [371584/620022]    Loss: 0.006938   Batch Acc: 82.81
[Train] Epoch: 2 [371648/620022]    Loss: 0.009089   Batch Acc: 70.31
[Train] Epoch: 2 [371712/620022]    Loss: 0.008049   Batch Acc: 82.81
[Train] Epoch: 2 [371776/620022]    Loss: 0.008504   Batch Acc: 78.12
[Train] Epoch: 2 [371840/620022]    Loss: 0.010182   Batch Acc: 67.19
[Train] Epoch: 2 [371904/620022]    Loss: 0.008889   Batch Acc: 81.25
[Train] Epoch: 2 [371968/620022]    Loss: 0.009007   Batch Acc: 73.44
[Train] Epoch: 2 [372032/620022]    Loss: 0.007851   Batch Acc: 76.56
[Train] Epoch: 2 [372096/620022]    Loss: 0.008880   Batch Acc: 79.69
[Train] Epoch: 2 [372160/620022]    Loss: 0.008364   Batch Acc: 75.00
[Train] Epoch: 2 [372224/620022]    Loss: 0.007191   Batch Acc: 79.69
[Train] Epoch: 2 [372288/620022]    Loss: 0.007645   Batch Acc: 79.69
[Train] Epoch: 2 [372352/620022]    Loss: 0.008689   Batch Acc: 82.81
[Train] Epoch: 2 [372416/620022]    Loss: 0.008687   Batch Acc: 79.69
[Train] Epoch: 2 [372480/620022]    Loss: 0.009137   Batch Acc: 78.12
[Train] Epoch: 2 [372544/620022]    Loss: 0.006532   Batch Acc: 82.81
[Train] Epoch: 2 [372608/620022]    Loss: 0.010557   Batch Acc: 81.25
[Train] Epoch: 2 [372672/620022]    Loss: 0.006191   Batch Acc: 85.94
[Train] Epoch: 2 [372736/620022]    Loss: 0.007156   Batch Acc: 81.25
[Train] Epoch: 2 [372800/620022]    Loss: 0.009727   Batch Acc: 79.69
[Train] Epoch: 2 [372864/620022]    Loss: 0.010005   Batch Acc: 73.44
[Train] Epoch: 2 [372928/620022]    Loss: 0.008596   Batch Acc: 76.56
[Train] Epoch: 2 [372992/620022]    Loss: 0.008516   Batch Acc: 75.00
[Train] Epoch: 2 [373056/620022]    Loss: 0.010281   Batch Acc: 70.31
[Train] Epoch: 2 [373120/620022]    Loss: 0.008520   Batch Acc: 78.12
[Train] Epoch: 2 [373184/620022]    Loss: 0.010511   Batch Acc: 73.44
[Train] Epoch: 2 [373248/620022]    Loss: 0.008953   Batch Acc: 73.44
[Train] Epoch: 2 [373312/620022]    Loss: 0.009446   Batch Acc: 71.88
[Train] Epoch: 2 [373376/620022]    Loss: 0.008455   Batch Acc: 75.00
[Train] Epoch: 2 [373440/620022]    Loss: 0.006694   Batch Acc: 82.81
[Train] Epoch: 2 [373504/620022]    Loss: 0.008313   Batch Acc: 76.56
[Train] Epoch: 2 [373568/620022]    Loss: 0.007759   Batch Acc: 81.25
[Train] Epoch: 2 [373632/620022]    Loss: 0.007194   Batch Acc: 87.50
[Train] Epoch: 2 [373696/620022]    Loss: 0.008996   Batch Acc: 73.44
[Train] Epoch: 2 [373760/620022]    Loss: 0.010152   Batch Acc: 71.88
[Train] Epoch: 2 [373824/620022]    Loss: 0.008885   Batch Acc: 75.00
[Train] Epoch: 2 [373888/620022]    Loss: 0.008717   Batch Acc: 73.44
[Train] Epoch: 2 [373952/620022]    Loss: 0.008489   Batch Acc: 75.00
[Train] Epoch: 2 [374016/620022]    Loss: 0.010098   Batch Acc: 70.31
[Train] Epoch: 2 [374080/620022]    Loss: 0.009874   Batch Acc: 71.88
[Train] Epoch: 2 [374144/620022]    Loss: 0.007923   Batch Acc: 82.81
[Train] Epoch: 2 [374208/620022]    Loss: 0.007624   Batch Acc: 82.81
[Train] Epoch: 2 [374272/620022]    Loss: 0.009258   Batch Acc: 76.56
[Train] Epoch: 2 [374336/620022]    Loss: 0.007366   Batch Acc: 79.69
[Train] Epoch: 2 [374400/620022]    Loss: 0.008113   Batch Acc: 79.69
[Train] Epoch: 2 [374464/620022]    Loss: 0.010311   Batch Acc: 71.88
[Train] Epoch: 2 [374528/620022]    Loss: 0.007606   Batch Acc: 81.25
[Train] Epoch: 2 [374592/620022]    Loss: 0.008633   Batch Acc: 73.44
[Train] Epoch: 2 [374656/620022]    Loss: 0.007872   Batch Acc: 81.25
[Train] Epoch: 2 [374720/620022]    Loss: 0.007401   Batch Acc: 81.25
[Train] Epoch: 2 [374784/620022]    Loss: 0.009575   Batch Acc: 71.88
[Train] Epoch: 2 [374848/620022]    Loss: 0.010066   Batch Acc: 71.88
[Train] Epoch: 2 [374912/620022]    Loss: 0.007374   Batch Acc: 84.38
[Train] Epoch: 2 [374976/620022]    Loss: 0.005685   Batch Acc: 85.94
[Train] Epoch: 2 [375040/620022]    Loss: 0.009478   Batch Acc: 76.56
[Train] Epoch: 2 [375104/620022]    Loss: 0.010537   Batch Acc: 65.62
[Train] Epoch: 2 [375168/620022]    Loss: 0.007905   Batch Acc: 79.69
[Train] Epoch: 2 [375232/620022]    Loss: 0.007632   Batch Acc: 82.81
[Train] Epoch: 2 [375296/620022]    Loss: 0.009683   Batch Acc: 68.75
[Train] Epoch: 2 [375360/620022]    Loss: 0.008139   Batch Acc: 75.00
[Train] Epoch: 2 [375424/620022]    Loss: 0.008549   Batch Acc: 81.25
[Train] Epoch: 2 [375488/620022]    Loss: 0.009561   Batch Acc: 78.12
[Train] Epoch: 2 [375552/620022]    Loss: 0.008945   Batch Acc: 78.12
[Train] Epoch: 2 [375616/620022]    Loss: 0.009590   Batch Acc: 75.00
[Train] Epoch: 2 [375680/620022]    Loss: 0.007554   Batch Acc: 84.38
[Train] Epoch: 2 [375744/620022]    Loss: 0.007525   Batch Acc: 84.38
[Train] Epoch: 2 [375808/620022]    Loss: 0.009155   Batch Acc: 75.00
[Train] Epoch: 2 [375872/620022]    Loss: 0.010531   Batch Acc: 76.56
[Train] Epoch: 2 [375936/620022]    Loss: 0.009465   Batch Acc: 71.88
[Train] Epoch: 2 [376000/620022]    Loss: 0.010846   Batch Acc: 75.00
[Train] Epoch: 2 [376064/620022]    Loss: 0.007411   Batch Acc: 85.94
[Train] Epoch: 2 [376128/620022]    Loss: 0.010313   Batch Acc: 75.00
[Train] Epoch: 2 [376192/620022]    Loss: 0.007903   Batch Acc: 85.94
[Train] Epoch: 2 [376256/620022]    Loss: 0.010570   Batch Acc: 71.88
[Train] Epoch: 2 [376320/620022]    Loss: 0.010431   Batch Acc: 70.31
[Train] Epoch: 2 [376384/620022]    Loss: 0.007369   Batch Acc: 82.81
[Train] Epoch: 2 [376448/620022]    Loss: 0.009328   Batch Acc: 81.25
[Train] Epoch: 2 [376512/620022]    Loss: 0.006399   Batch Acc: 81.25
[Train] Epoch: 2 [376576/620022]    Loss: 0.008522   Batch Acc: 81.25
[Train] Epoch: 2 [376640/620022]    Loss: 0.008729   Batch Acc: 81.25
[Train] Epoch: 2 [376704/620022]    Loss: 0.007973   Batch Acc: 85.94
[Train] Epoch: 2 [376768/620022]    Loss: 0.010291   Batch Acc: 76.56
[Train] Epoch: 2 [376832/620022]    Loss: 0.007885   Batch Acc: 84.38
[Train] Epoch: 2 [376896/620022]    Loss: 0.010778   Batch Acc: 73.44
[Train] Epoch: 2 [376960/620022]    Loss: 0.008603   Batch Acc: 78.12
[Train] Epoch: 2 [377024/620022]    Loss: 0.008151   Batch Acc: 75.00
[Train] Epoch: 2 [377088/620022]    Loss: 0.010707   Batch Acc: 75.00
[Train] Epoch: 2 [377152/620022]    Loss: 0.007958   Batch Acc: 75.00
[Train] Epoch: 2 [377216/620022]    Loss: 0.007069   Batch Acc: 82.81
[Train] Epoch: 2 [377280/620022]    Loss: 0.009709   Batch Acc: 73.44
[Train] Epoch: 2 [377344/620022]    Loss: 0.007601   Batch Acc: 84.38
[Train] Epoch: 2 [377408/620022]    Loss: 0.005842   Batch Acc: 84.38
[Train] Epoch: 2 [377472/620022]    Loss: 0.006932   Batch Acc: 82.81
[Train] Epoch: 2 [377536/620022]    Loss: 0.009992   Batch Acc: 79.69
[Train] Epoch: 2 [377600/620022]    Loss: 0.008464   Batch Acc: 76.56
[Train] Epoch: 2 [377664/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 2 [377728/620022]    Loss: 0.010846   Batch Acc: 71.88
[Train] Epoch: 2 [377792/620022]    Loss: 0.006187   Batch Acc: 85.94
[Train] Epoch: 2 [377856/620022]    Loss: 0.008845   Batch Acc: 84.38
[Train] Epoch: 2 [377920/620022]    Loss: 0.007633   Batch Acc: 81.25
[Train] Epoch: 2 [377984/620022]    Loss: 0.008071   Batch Acc: 81.25
[Train] Epoch: 2 [378048/620022]    Loss: 0.007969   Batch Acc: 81.25
[Train] Epoch: 2 [378112/620022]    Loss: 0.010096   Batch Acc: 71.88
[Train] Epoch: 2 [378176/620022]    Loss: 0.009035   Batch Acc: 76.56
[Train] Epoch: 2 [378240/620022]    Loss: 0.008994   Batch Acc: 75.00
[Train] Epoch: 2 [378304/620022]    Loss: 0.008849   Batch Acc: 75.00
[Train] Epoch: 2 [378368/620022]    Loss: 0.007498   Batch Acc: 81.25
[Train] Epoch: 2 [378432/620022]    Loss: 0.009518   Batch Acc: 75.00
[Train] Epoch: 2 [378496/620022]    Loss: 0.008838   Batch Acc: 75.00
[Train] Epoch: 2 [378560/620022]    Loss: 0.008031   Batch Acc: 79.69
[Train] Epoch: 2 [378624/620022]    Loss: 0.008635   Batch Acc: 87.50
[Train] Epoch: 2 [378688/620022]    Loss: 0.009609   Batch Acc: 78.12
[Train] Epoch: 2 [378752/620022]    Loss: 0.008320   Batch Acc: 79.69
[Train] Epoch: 2 [378816/620022]    Loss: 0.006290   Batch Acc: 82.81
[Train] Epoch: 2 [378880/620022]    Loss: 0.007765   Batch Acc: 85.94
[Train] Epoch: 2 [378944/620022]    Loss: 0.009324   Batch Acc: 75.00
[Train] Epoch: 2 [379008/620022]    Loss: 0.009757   Batch Acc: 78.12
[Train] Epoch: 2 [379072/620022]    Loss: 0.007401   Batch Acc: 84.38
[Train] Epoch: 2 [379136/620022]    Loss: 0.009727   Batch Acc: 75.00
[Train] Epoch: 2 [379200/620022]    Loss: 0.007547   Batch Acc: 81.25
[Train] Epoch: 2 [379264/620022]    Loss: 0.010643   Batch Acc: 73.44
[Train] Epoch: 2 [379328/620022]    Loss: 0.009540   Batch Acc: 71.88
[Train] Epoch: 2 [379392/620022]    Loss: 0.007971   Batch Acc: 79.69
[Train] Epoch: 2 [379456/620022]    Loss: 0.009660   Batch Acc: 79.69
[Train] Epoch: 2 [379520/620022]    Loss: 0.009632   Batch Acc: 76.56
[Train] Epoch: 2 [379584/620022]    Loss: 0.010491   Batch Acc: 75.00
[Train] Epoch: 2 [379648/620022]    Loss: 0.006908   Batch Acc: 82.81
[Train] Epoch: 2 [379712/620022]    Loss: 0.007577   Batch Acc: 78.12
[Train] Epoch: 2 [379776/620022]    Loss: 0.009561   Batch Acc: 76.56
[Train] Epoch: 2 [379840/620022]    Loss: 0.009205   Batch Acc: 76.56
[Train] Epoch: 2 [379904/620022]    Loss: 0.009620   Batch Acc: 76.56
[Train] Epoch: 2 [379968/620022]    Loss: 0.009210   Batch Acc: 78.12
[Train] Epoch: 2 [380032/620022]    Loss: 0.009462   Batch Acc: 73.44
[Train] Epoch: 2 [380096/620022]    Loss: 0.009388   Batch Acc: 79.69
[Train] Epoch: 2 [380160/620022]    Loss: 0.008819   Batch Acc: 82.81
[Train] Epoch: 2 [380224/620022]    Loss: 0.008572   Batch Acc: 78.12
[Train] Epoch: 2 [380288/620022]    Loss: 0.008535   Batch Acc: 78.12
[Train] Epoch: 2 [380352/620022]    Loss: 0.007938   Batch Acc: 81.25
[Train] Epoch: 2 [380416/620022]    Loss: 0.009691   Batch Acc: 76.56
[Train] Epoch: 2 [380480/620022]    Loss: 0.007105   Batch Acc: 81.25
[Train] Epoch: 2 [380544/620022]    Loss: 0.006275   Batch Acc: 84.38
[Train] Epoch: 2 [380608/620022]    Loss: 0.008177   Batch Acc: 81.25
[Train] Epoch: 2 [380672/620022]    Loss: 0.008234   Batch Acc: 73.44
[Train] Epoch: 2 [380736/620022]    Loss: 0.007955   Batch Acc: 79.69
[Train] Epoch: 2 [380800/620022]    Loss: 0.006331   Batch Acc: 87.50
[Train] Epoch: 2 [380864/620022]    Loss: 0.007828   Batch Acc: 79.69
[Train] Epoch: 2 [380928/620022]    Loss: 0.008246   Batch Acc: 79.69
[Train] Epoch: 2 [380992/620022]    Loss: 0.007105   Batch Acc: 87.50
[Train] Epoch: 2 [381056/620022]    Loss: 0.010054   Batch Acc: 78.12
[Train] Epoch: 2 [381120/620022]    Loss: 0.007271   Batch Acc: 82.81
[Train] Epoch: 2 [381184/620022]    Loss: 0.007621   Batch Acc: 81.25
[Train] Epoch: 2 [381248/620022]    Loss: 0.008138   Batch Acc: 79.69
[Train] Epoch: 2 [381312/620022]    Loss: 0.007021   Batch Acc: 84.38
[Train] Epoch: 2 [381376/620022]    Loss: 0.009741   Batch Acc: 78.12
[Train] Epoch: 2 [381440/620022]    Loss: 0.008727   Batch Acc: 81.25
[Train] Epoch: 2 [381504/620022]    Loss: 0.009157   Batch Acc: 73.44
[Train] Epoch: 2 [381568/620022]    Loss: 0.008659   Batch Acc: 75.00
[Train] Epoch: 2 [381632/620022]    Loss: 0.008052   Batch Acc: 79.69
[Train] Epoch: 2 [381696/620022]    Loss: 0.006661   Batch Acc: 79.69
[Train] Epoch: 2 [381760/620022]    Loss: 0.008723   Batch Acc: 78.12
[Train] Epoch: 2 [381824/620022]    Loss: 0.008860   Batch Acc: 76.56
[Train] Epoch: 2 [381888/620022]    Loss: 0.008178   Batch Acc: 78.12
[Train] Epoch: 2 [381952/620022]    Loss: 0.009241   Batch Acc: 79.69
[Train] Epoch: 2 [382016/620022]    Loss: 0.009573   Batch Acc: 67.19
[Train] Epoch: 2 [382080/620022]    Loss: 0.007184   Batch Acc: 84.38
[Train] Epoch: 2 [382144/620022]    Loss: 0.007283   Batch Acc: 79.69
[Train] Epoch: 2 [382208/620022]    Loss: 0.007449   Batch Acc: 79.69
[Train] Epoch: 2 [382272/620022]    Loss: 0.010913   Batch Acc: 70.31
[Train] Epoch: 2 [382336/620022]    Loss: 0.008079   Batch Acc: 79.69
[Train] Epoch: 2 [382400/620022]    Loss: 0.010073   Batch Acc: 73.44
[Train] Epoch: 2 [382464/620022]    Loss: 0.008976   Batch Acc: 73.44
[Train] Epoch: 2 [382528/620022]    Loss: 0.008479   Batch Acc: 81.25
[Train] Epoch: 2 [382592/620022]    Loss: 0.008551   Batch Acc: 81.25
[Train] Epoch: 2 [382656/620022]    Loss: 0.007064   Batch Acc: 82.81
[Train] Epoch: 2 [382720/620022]    Loss: 0.007730   Batch Acc: 84.38
[Train] Epoch: 2 [382784/620022]    Loss: 0.008289   Batch Acc: 78.12
[Train] Epoch: 2 [382848/620022]    Loss: 0.007760   Batch Acc: 79.69
[Train] Epoch: 2 [382912/620022]    Loss: 0.009290   Batch Acc: 68.75
[Train] Epoch: 2 [382976/620022]    Loss: 0.010885   Batch Acc: 73.44
[Train] Epoch: 2 [383040/620022]    Loss: 0.010574   Batch Acc: 70.31
[Train] Epoch: 2 [383104/620022]    Loss: 0.006681   Batch Acc: 81.25
[Train] Epoch: 2 [383168/620022]    Loss: 0.009266   Batch Acc: 75.00
[Train] Epoch: 2 [383232/620022]    Loss: 0.006951   Batch Acc: 82.81
[Train] Epoch: 2 [383296/620022]    Loss: 0.009195   Batch Acc: 76.56
[Train] Epoch: 2 [383360/620022]    Loss: 0.012052   Batch Acc: 73.44
[Train] Epoch: 2 [383424/620022]    Loss: 0.010114   Batch Acc: 70.31
[Train] Epoch: 2 [383488/620022]    Loss: 0.008811   Batch Acc: 73.44
[Train] Epoch: 2 [383552/620022]    Loss: 0.009559   Batch Acc: 68.75
[Train] Epoch: 2 [383616/620022]    Loss: 0.007163   Batch Acc: 82.81
[Train] Epoch: 2 [383680/620022]    Loss: 0.007917   Batch Acc: 84.38
[Train] Epoch: 2 [383744/620022]    Loss: 0.007936   Batch Acc: 81.25
[Train] Epoch: 2 [383808/620022]    Loss: 0.008501   Batch Acc: 78.12
[Train] Epoch: 2 [383872/620022]    Loss: 0.009186   Batch Acc: 70.31
[Train] Epoch: 2 [383936/620022]    Loss: 0.010763   Batch Acc: 68.75
[Train] Epoch: 2 [384000/620022]    Loss: 0.007823   Batch Acc: 78.12
[Train] Epoch: 2 [384064/620022]    Loss: 0.007773   Batch Acc: 76.56
[Train] Epoch: 2 [384128/620022]    Loss: 0.008963   Batch Acc: 79.69
[Train] Epoch: 2 [384192/620022]    Loss: 0.006965   Batch Acc: 84.38
[Train] Epoch: 2 [384256/620022]    Loss: 0.007610   Batch Acc: 78.12
[Train] Epoch: 2 [384320/620022]    Loss: 0.008896   Batch Acc: 79.69
[Train] Epoch: 2 [384384/620022]    Loss: 0.009334   Batch Acc: 79.69
[Train] Epoch: 2 [384448/620022]    Loss: 0.008044   Batch Acc: 75.00
[Train] Epoch: 2 [384512/620022]    Loss: 0.009650   Batch Acc: 70.31
[Train] Epoch: 2 [384576/620022]    Loss: 0.008740   Batch Acc: 79.69
[Train] Epoch: 2 [384640/620022]    Loss: 0.011130   Batch Acc: 75.00
[Train] Epoch: 2 [384704/620022]    Loss: 0.009058   Batch Acc: 76.56
[Train] Epoch: 2 [384768/620022]    Loss: 0.008508   Batch Acc: 76.56
[Train] Epoch: 2 [384832/620022]    Loss: 0.008814   Batch Acc: 75.00
[Train] Epoch: 2 [384896/620022]    Loss: 0.006485   Batch Acc: 89.06
[Train] Epoch: 2 [384960/620022]    Loss: 0.006933   Batch Acc: 85.94
[Train] Epoch: 2 [385024/620022]    Loss: 0.009628   Batch Acc: 75.00
[Train] Epoch: 2 [385088/620022]    Loss: 0.008931   Batch Acc: 73.44
[Train] Epoch: 2 [385152/620022]    Loss: 0.010416   Batch Acc: 73.44
[Train] Epoch: 2 [385216/620022]    Loss: 0.008237   Batch Acc: 78.12
[Train] Epoch: 2 [385280/620022]    Loss: 0.009159   Batch Acc: 70.31
[Train] Epoch: 2 [385344/620022]    Loss: 0.007565   Batch Acc: 81.25
[Train] Epoch: 2 [385408/620022]    Loss: 0.006814   Batch Acc: 82.81
[Train] Epoch: 2 [385472/620022]    Loss: 0.007960   Batch Acc: 75.00
[Train] Epoch: 2 [385536/620022]    Loss: 0.008537   Batch Acc: 82.81
[Train] Epoch: 2 [385600/620022]    Loss: 0.008879   Batch Acc: 75.00
[Train] Epoch: 2 [385664/620022]    Loss: 0.007680   Batch Acc: 82.81
[Train] Epoch: 2 [385728/620022]    Loss: 0.010251   Batch Acc: 75.00
[Train] Epoch: 2 [385792/620022]    Loss: 0.005267   Batch Acc: 89.06
[Train] Epoch: 2 [385856/620022]    Loss: 0.007437   Batch Acc: 82.81
[Train] Epoch: 2 [385920/620022]    Loss: 0.009857   Batch Acc: 70.31
[Train] Epoch: 2 [385984/620022]    Loss: 0.009965   Batch Acc: 73.44
[Train] Epoch: 2 [386048/620022]    Loss: 0.009732   Batch Acc: 67.19
[Train] Epoch: 2 [386112/620022]    Loss: 0.006842   Batch Acc: 82.81
[Train] Epoch: 2 [386176/620022]    Loss: 0.007226   Batch Acc: 79.69
[Train] Epoch: 2 [386240/620022]    Loss: 0.006912   Batch Acc: 79.69
[Train] Epoch: 2 [386304/620022]    Loss: 0.009523   Batch Acc: 76.56
[Train] Epoch: 2 [386368/620022]    Loss: 0.009774   Batch Acc: 71.88
[Train] Epoch: 2 [386432/620022]    Loss: 0.008430   Batch Acc: 79.69
[Train] Epoch: 2 [386496/620022]    Loss: 0.009504   Batch Acc: 76.56
[Train] Epoch: 2 [386560/620022]    Loss: 0.010466   Batch Acc: 70.31
[Train] Epoch: 2 [386624/620022]    Loss: 0.006787   Batch Acc: 84.38
[Train] Epoch: 2 [386688/620022]    Loss: 0.007529   Batch Acc: 79.69
[Train] Epoch: 2 [386752/620022]    Loss: 0.008559   Batch Acc: 79.69
[Train] Epoch: 2 [386816/620022]    Loss: 0.007212   Batch Acc: 75.00
[Train] Epoch: 2 [386880/620022]    Loss: 0.007983   Batch Acc: 75.00
[Train] Epoch: 2 [386944/620022]    Loss: 0.007807   Batch Acc: 81.25
[Train] Epoch: 2 [387008/620022]    Loss: 0.009767   Batch Acc: 78.12
[Train] Epoch: 2 [387072/620022]    Loss: 0.009085   Batch Acc: 76.56
[Train] Epoch: 2 [387136/620022]    Loss: 0.009320   Batch Acc: 78.12
[Train] Epoch: 2 [387200/620022]    Loss: 0.007370   Batch Acc: 79.69
[Train] Epoch: 2 [387264/620022]    Loss: 0.008304   Batch Acc: 78.12
[Train] Epoch: 2 [387328/620022]    Loss: 0.009832   Batch Acc: 70.31
[Train] Epoch: 2 [387392/620022]    Loss: 0.011235   Batch Acc: 67.19
[Train] Epoch: 2 [387456/620022]    Loss: 0.008178   Batch Acc: 73.44
[Train] Epoch: 2 [387520/620022]    Loss: 0.007434   Batch Acc: 82.81
[Train] Epoch: 2 [387584/620022]    Loss: 0.009138   Batch Acc: 73.44
[Train] Epoch: 2 [387648/620022]    Loss: 0.007121   Batch Acc: 76.56
[Train] Epoch: 2 [387712/620022]    Loss: 0.007152   Batch Acc: 79.69
[Train] Epoch: 2 [387776/620022]    Loss: 0.008648   Batch Acc: 81.25
[Train] Epoch: 2 [387840/620022]    Loss: 0.006918   Batch Acc: 87.50
[Train] Epoch: 2 [387904/620022]    Loss: 0.006548   Batch Acc: 84.38
[Train] Epoch: 2 [387968/620022]    Loss: 0.008186   Batch Acc: 79.69
[Train] Epoch: 2 [388032/620022]    Loss: 0.009769   Batch Acc: 78.12
[Train] Epoch: 2 [388096/620022]    Loss: 0.011826   Batch Acc: 67.19
[Train] Epoch: 2 [388160/620022]    Loss: 0.011639   Batch Acc: 70.31
[Train] Epoch: 2 [388224/620022]    Loss: 0.008917   Batch Acc: 76.56
[Train] Epoch: 2 [388288/620022]    Loss: 0.009699   Batch Acc: 70.31
[Train] Epoch: 2 [388352/620022]    Loss: 0.008682   Batch Acc: 75.00
[Train] Epoch: 2 [388416/620022]    Loss: 0.007277   Batch Acc: 84.38
[Train] Epoch: 2 [388480/620022]    Loss: 0.010003   Batch Acc: 73.44
[Train] Epoch: 2 [388544/620022]    Loss: 0.009243   Batch Acc: 75.00
[Train] Epoch: 2 [388608/620022]    Loss: 0.005033   Batch Acc: 84.38
[Train] Epoch: 2 [388672/620022]    Loss: 0.007535   Batch Acc: 84.38
[Train] Epoch: 2 [388736/620022]    Loss: 0.008403   Batch Acc: 73.44
[Train] Epoch: 2 [388800/620022]    Loss: 0.007311   Batch Acc: 87.50
[Train] Epoch: 2 [388864/620022]    Loss: 0.009050   Batch Acc: 79.69
[Train] Epoch: 2 [388928/620022]    Loss: 0.007287   Batch Acc: 81.25
[Train] Epoch: 2 [388992/620022]    Loss: 0.010188   Batch Acc: 70.31
[Train] Epoch: 2 [389056/620022]    Loss: 0.008692   Batch Acc: 78.12
[Train] Epoch: 2 [389120/620022]    Loss: 0.007291   Batch Acc: 85.94
[Train] Epoch: 2 [389184/620022]    Loss: 0.007316   Batch Acc: 84.38
[Train] Epoch: 2 [389248/620022]    Loss: 0.009817   Batch Acc: 75.00
[Train] Epoch: 2 [389312/620022]    Loss: 0.007953   Batch Acc: 81.25
[Train] Epoch: 2 [389376/620022]    Loss: 0.008029   Batch Acc: 81.25
[Train] Epoch: 2 [389440/620022]    Loss: 0.009282   Batch Acc: 76.56
[Train] Epoch: 2 [389504/620022]    Loss: 0.008225   Batch Acc: 81.25
[Train] Epoch: 2 [389568/620022]    Loss: 0.007989   Batch Acc: 76.56
[Train] Epoch: 2 [389632/620022]    Loss: 0.009352   Batch Acc: 71.88
[Train] Epoch: 2 [389696/620022]    Loss: 0.009610   Batch Acc: 78.12
[Train] Epoch: 2 [389760/620022]    Loss: 0.006797   Batch Acc: 82.81
[Train] Epoch: 2 [389824/620022]    Loss: 0.007857   Batch Acc: 82.81
[Train] Epoch: 2 [389888/620022]    Loss: 0.007696   Batch Acc: 79.69
[Train] Epoch: 2 [389952/620022]    Loss: 0.010223   Batch Acc: 71.88
[Train] Epoch: 2 [390016/620022]    Loss: 0.007434   Batch Acc: 79.69
[Train] Epoch: 2 [390080/620022]    Loss: 0.009723   Batch Acc: 75.00
[Train] Epoch: 2 [390144/620022]    Loss: 0.010103   Batch Acc: 76.56
[Train] Epoch: 2 [390208/620022]    Loss: 0.009096   Batch Acc: 79.69
[Train] Epoch: 2 [390272/620022]    Loss: 0.009029   Batch Acc: 78.12
[Train] Epoch: 2 [390336/620022]    Loss: 0.009087   Batch Acc: 78.12
[Train] Epoch: 2 [390400/620022]    Loss: 0.009245   Batch Acc: 76.56
[Train] Epoch: 2 [390464/620022]    Loss: 0.008980   Batch Acc: 76.56
[Train] Epoch: 2 [390528/620022]    Loss: 0.008574   Batch Acc: 78.12
[Train] Epoch: 2 [390592/620022]    Loss: 0.007572   Batch Acc: 81.25
[Train] Epoch: 2 [390656/620022]    Loss: 0.009513   Batch Acc: 78.12
[Train] Epoch: 2 [390720/620022]    Loss: 0.009804   Batch Acc: 78.12
[Train] Epoch: 2 [390784/620022]    Loss: 0.007308   Batch Acc: 87.50
[Train] Epoch: 2 [390848/620022]    Loss: 0.006737   Batch Acc: 82.81
[Train] Epoch: 2 [390912/620022]    Loss: 0.007566   Batch Acc: 82.81
[Train] Epoch: 2 [390976/620022]    Loss: 0.007612   Batch Acc: 76.56
[Train] Epoch: 2 [391040/620022]    Loss: 0.011764   Batch Acc: 67.19
[Train] Epoch: 2 [391104/620022]    Loss: 0.008259   Batch Acc: 82.81
[Train] Epoch: 2 [391168/620022]    Loss: 0.008542   Batch Acc: 79.69
[Train] Epoch: 2 [391232/620022]    Loss: 0.008553   Batch Acc: 85.94
[Train] Epoch: 2 [391296/620022]    Loss: 0.009849   Batch Acc: 71.88
[Train] Epoch: 2 [391360/620022]    Loss: 0.009555   Batch Acc: 70.31
[Train] Epoch: 2 [391424/620022]    Loss: 0.009348   Batch Acc: 71.88
[Train] Epoch: 2 [391488/620022]    Loss: 0.009483   Batch Acc: 78.12
[Train] Epoch: 2 [391552/620022]    Loss: 0.008309   Batch Acc: 78.12
[Train] Epoch: 2 [391616/620022]    Loss: 0.007463   Batch Acc: 89.06
[Train] Epoch: 2 [391680/620022]    Loss: 0.008478   Batch Acc: 78.12
[Train] Epoch: 2 [391744/620022]    Loss: 0.011002   Batch Acc: 68.75
[Train] Epoch: 2 [391808/620022]    Loss: 0.009037   Batch Acc: 78.12
[Train] Epoch: 2 [391872/620022]    Loss: 0.007563   Batch Acc: 82.81
[Train] Epoch: 2 [391936/620022]    Loss: 0.009889   Batch Acc: 76.56
[Train] Epoch: 2 [392000/620022]    Loss: 0.008846   Batch Acc: 79.69
[Train] Epoch: 2 [392064/620022]    Loss: 0.008640   Batch Acc: 76.56
[Train] Epoch: 2 [392128/620022]    Loss: 0.009152   Batch Acc: 76.56
[Train] Epoch: 2 [392192/620022]    Loss: 0.007663   Batch Acc: 79.69
[Train] Epoch: 2 [392256/620022]    Loss: 0.009382   Batch Acc: 79.69
[Train] Epoch: 2 [392320/620022]    Loss: 0.009908   Batch Acc: 73.44
[Train] Epoch: 2 [392384/620022]    Loss: 0.008495   Batch Acc: 81.25
[Train] Epoch: 2 [392448/620022]    Loss: 0.008041   Batch Acc: 79.69
[Train] Epoch: 2 [392512/620022]    Loss: 0.008368   Batch Acc: 81.25
[Train] Epoch: 2 [392576/620022]    Loss: 0.007597   Batch Acc: 79.69
[Train] Epoch: 2 [392640/620022]    Loss: 0.008137   Batch Acc: 79.69
[Train] Epoch: 2 [392704/620022]    Loss: 0.007164   Batch Acc: 85.94
[Train] Epoch: 2 [392768/620022]    Loss: 0.008935   Batch Acc: 76.56
[Train] Epoch: 2 [392832/620022]    Loss: 0.008613   Batch Acc: 75.00
[Train] Epoch: 2 [392896/620022]    Loss: 0.009331   Batch Acc: 73.44
[Train] Epoch: 2 [392960/620022]    Loss: 0.008518   Batch Acc: 78.12
[Train] Epoch: 2 [393024/620022]    Loss: 0.007727   Batch Acc: 82.81
[Train] Epoch: 2 [393088/620022]    Loss: 0.009325   Batch Acc: 78.12
[Train] Epoch: 2 [393152/620022]    Loss: 0.007183   Batch Acc: 79.69
[Train] Epoch: 2 [393216/620022]    Loss: 0.009573   Batch Acc: 76.56
[Train] Epoch: 2 [393280/620022]    Loss: 0.009988   Batch Acc: 71.88
[Train] Epoch: 2 [393344/620022]    Loss: 0.005810   Batch Acc: 89.06
[Train] Epoch: 2 [393408/620022]    Loss: 0.008462   Batch Acc: 76.56
[Train] Epoch: 2 [393472/620022]    Loss: 0.009459   Batch Acc: 70.31
[Train] Epoch: 2 [393536/620022]    Loss: 0.008004   Batch Acc: 79.69
[Train] Epoch: 2 [393600/620022]    Loss: 0.009568   Batch Acc: 71.88
[Train] Epoch: 2 [393664/620022]    Loss: 0.008666   Batch Acc: 76.56
[Train] Epoch: 2 [393728/620022]    Loss: 0.009513   Batch Acc: 73.44
[Train] Epoch: 2 [393792/620022]    Loss: 0.009921   Batch Acc: 73.44
[Train] Epoch: 2 [393856/620022]    Loss: 0.009075   Batch Acc: 76.56
[Train] Epoch: 2 [393920/620022]    Loss: 0.007265   Batch Acc: 84.38
[Train] Epoch: 2 [393984/620022]    Loss: 0.009714   Batch Acc: 73.44
[Train] Epoch: 2 [394048/620022]    Loss: 0.009856   Batch Acc: 71.88
[Train] Epoch: 2 [394112/620022]    Loss: 0.009948   Batch Acc: 78.12
[Train] Epoch: 2 [394176/620022]    Loss: 0.008456   Batch Acc: 76.56
[Train] Epoch: 2 [394240/620022]    Loss: 0.007393   Batch Acc: 84.38
[Train] Epoch: 2 [394304/620022]    Loss: 0.007293   Batch Acc: 87.50
[Train] Epoch: 2 [394368/620022]    Loss: 0.009643   Batch Acc: 73.44
[Train] Epoch: 2 [394432/620022]    Loss: 0.007509   Batch Acc: 76.56
[Train] Epoch: 2 [394496/620022]    Loss: 0.010246   Batch Acc: 68.75
[Train] Epoch: 2 [394560/620022]    Loss: 0.011280   Batch Acc: 67.19
[Train] Epoch: 2 [394624/620022]    Loss: 0.009577   Batch Acc: 73.44
[Train] Epoch: 2 [394688/620022]    Loss: 0.007295   Batch Acc: 84.38
[Train] Epoch: 2 [394752/620022]    Loss: 0.010116   Batch Acc: 73.44
[Train] Epoch: 2 [394816/620022]    Loss: 0.011666   Batch Acc: 64.06
[Train] Epoch: 2 [394880/620022]    Loss: 0.009976   Batch Acc: 75.00
[Train] Epoch: 2 [394944/620022]    Loss: 0.013008   Batch Acc: 65.62
[Train] Epoch: 2 [395008/620022]    Loss: 0.007376   Batch Acc: 81.25
[Train] Epoch: 2 [395072/620022]    Loss: 0.008982   Batch Acc: 73.44
[Train] Epoch: 2 [395136/620022]    Loss: 0.008595   Batch Acc: 82.81
[Train] Epoch: 2 [395200/620022]    Loss: 0.005510   Batch Acc: 93.75
[Train] Epoch: 2 [395264/620022]    Loss: 0.011215   Batch Acc: 73.44
[Train] Epoch: 2 [395328/620022]    Loss: 0.008320   Batch Acc: 78.12
[Train] Epoch: 2 [395392/620022]    Loss: 0.007904   Batch Acc: 76.56
[Train] Epoch: 2 [395456/620022]    Loss: 0.008498   Batch Acc: 79.69
[Train] Epoch: 2 [395520/620022]    Loss: 0.008761   Batch Acc: 76.56
[Train] Epoch: 2 [395584/620022]    Loss: 0.010203   Batch Acc: 71.88
[Train] Epoch: 2 [395648/620022]    Loss: 0.008933   Batch Acc: 78.12
[Train] Epoch: 2 [395712/620022]    Loss: 0.010267   Batch Acc: 73.44
[Train] Epoch: 2 [395776/620022]    Loss: 0.008523   Batch Acc: 76.56
[Train] Epoch: 2 [395840/620022]    Loss: 0.009575   Batch Acc: 68.75
[Train] Epoch: 2 [395904/620022]    Loss: 0.010707   Batch Acc: 71.88
[Train] Epoch: 2 [395968/620022]    Loss: 0.010430   Batch Acc: 73.44
[Train] Epoch: 2 [396032/620022]    Loss: 0.008008   Batch Acc: 78.12
[Train] Epoch: 2 [396096/620022]    Loss: 0.009297   Batch Acc: 71.88
[Train] Epoch: 2 [396160/620022]    Loss: 0.009618   Batch Acc: 76.56
[Train] Epoch: 2 [396224/620022]    Loss: 0.011919   Batch Acc: 73.44
[Train] Epoch: 2 [396288/620022]    Loss: 0.006696   Batch Acc: 82.81
[Train] Epoch: 2 [396352/620022]    Loss: 0.009787   Batch Acc: 76.56
[Train] Epoch: 2 [396416/620022]    Loss: 0.008259   Batch Acc: 75.00
[Train] Epoch: 2 [396480/620022]    Loss: 0.010689   Batch Acc: 76.56
[Train] Epoch: 2 [396544/620022]    Loss: 0.008583   Batch Acc: 81.25
[Train] Epoch: 2 [396608/620022]    Loss: 0.010944   Batch Acc: 59.38
[Train] Epoch: 2 [396672/620022]    Loss: 0.011264   Batch Acc: 67.19
[Train] Epoch: 2 [396736/620022]    Loss: 0.008328   Batch Acc: 82.81
[Train] Epoch: 2 [396800/620022]    Loss: 0.008788   Batch Acc: 79.69
[Train] Epoch: 2 [396864/620022]    Loss: 0.005825   Batch Acc: 87.50
[Train] Epoch: 2 [396928/620022]    Loss: 0.008724   Batch Acc: 76.56
[Train] Epoch: 2 [396992/620022]    Loss: 0.008989   Batch Acc: 79.69
[Train] Epoch: 2 [397056/620022]    Loss: 0.008874   Batch Acc: 75.00
[Train] Epoch: 2 [397120/620022]    Loss: 0.007764   Batch Acc: 81.25
[Train] Epoch: 2 [397184/620022]    Loss: 0.007234   Batch Acc: 84.38
[Train] Epoch: 2 [397248/620022]    Loss: 0.010123   Batch Acc: 71.88
[Train] Epoch: 2 [397312/620022]    Loss: 0.008542   Batch Acc: 84.38
[Train] Epoch: 2 [397376/620022]    Loss: 0.008447   Batch Acc: 76.56
[Train] Epoch: 2 [397440/620022]    Loss: 0.008433   Batch Acc: 82.81
[Train] Epoch: 2 [397504/620022]    Loss: 0.009943   Batch Acc: 75.00
[Train] Epoch: 2 [397568/620022]    Loss: 0.008105   Batch Acc: 81.25
[Train] Epoch: 2 [397632/620022]    Loss: 0.010065   Batch Acc: 75.00
[Train] Epoch: 2 [397696/620022]    Loss: 0.008535   Batch Acc: 76.56
[Train] Epoch: 2 [397760/620022]    Loss: 0.008383   Batch Acc: 73.44
[Train] Epoch: 2 [397824/620022]    Loss: 0.006231   Batch Acc: 90.62
[Train] Epoch: 2 [397888/620022]    Loss: 0.008159   Batch Acc: 78.12
[Train] Epoch: 2 [397952/620022]    Loss: 0.008934   Batch Acc: 78.12
[Train] Epoch: 2 [398016/620022]    Loss: 0.009985   Batch Acc: 76.56
[Train] Epoch: 2 [398080/620022]    Loss: 0.009173   Batch Acc: 75.00
[Train] Epoch: 2 [398144/620022]    Loss: 0.007408   Batch Acc: 79.69
[Train] Epoch: 2 [398208/620022]    Loss: 0.008129   Batch Acc: 82.81
[Train] Epoch: 2 [398272/620022]    Loss: 0.010917   Batch Acc: 70.31
[Train] Epoch: 2 [398336/620022]    Loss: 0.011198   Batch Acc: 70.31
[Train] Epoch: 2 [398400/620022]    Loss: 0.008678   Batch Acc: 73.44
[Train] Epoch: 2 [398464/620022]    Loss: 0.009677   Batch Acc: 76.56
[Train] Epoch: 2 [398528/620022]    Loss: 0.011100   Batch Acc: 68.75
[Train] Epoch: 2 [398592/620022]    Loss: 0.008349   Batch Acc: 73.44
[Train] Epoch: 2 [398656/620022]    Loss: 0.011005   Batch Acc: 73.44
[Train] Epoch: 2 [398720/620022]    Loss: 0.007076   Batch Acc: 82.81
[Train] Epoch: 2 [398784/620022]    Loss: 0.008968   Batch Acc: 78.12
[Train] Epoch: 2 [398848/620022]    Loss: 0.009774   Batch Acc: 73.44
[Train] Epoch: 2 [398912/620022]    Loss: 0.004654   Batch Acc: 89.06
[Train] Epoch: 2 [398976/620022]    Loss: 0.009778   Batch Acc: 70.31
[Train] Epoch: 2 [399040/620022]    Loss: 0.006919   Batch Acc: 85.94
[Train] Epoch: 2 [399104/620022]    Loss: 0.009691   Batch Acc: 73.44
[Train] Epoch: 2 [399168/620022]    Loss: 0.009205   Batch Acc: 78.12
[Train] Epoch: 2 [399232/620022]    Loss: 0.007287   Batch Acc: 81.25
[Train] Epoch: 2 [399296/620022]    Loss: 0.008603   Batch Acc: 82.81
[Train] Epoch: 2 [399360/620022]    Loss: 0.008633   Batch Acc: 79.69
[Train] Epoch: 2 [399424/620022]    Loss: 0.009021   Batch Acc: 71.88
[Train] Epoch: 2 [399488/620022]    Loss: 0.007084   Batch Acc: 82.81
[Train] Epoch: 2 [399552/620022]    Loss: 0.007925   Batch Acc: 76.56
[Train] Epoch: 2 [399616/620022]    Loss: 0.008166   Batch Acc: 85.94
[Train] Epoch: 2 [399680/620022]    Loss: 0.007271   Batch Acc: 85.94
[Train] Epoch: 2 [399744/620022]    Loss: 0.008047   Batch Acc: 82.81
[Train] Epoch: 2 [399808/620022]    Loss: 0.010214   Batch Acc: 68.75
[Train] Epoch: 2 [399872/620022]    Loss: 0.007934   Batch Acc: 78.12
[Train] Epoch: 2 [399936/620022]    Loss: 0.008420   Batch Acc: 79.69
[Train] Epoch: 2 [400000/620022]    Loss: 0.007702   Batch Acc: 81.25
[Train] Epoch: 2 [400064/620022]    Loss: 0.008351   Batch Acc: 78.12
[Train] Epoch: 2 [400128/620022]    Loss: 0.008974   Batch Acc: 76.56
[Train] Epoch: 2 [400192/620022]    Loss: 0.007785   Batch Acc: 78.12
[Train] Epoch: 2 [400256/620022]    Loss: 0.006963   Batch Acc: 84.38
[Train] Epoch: 2 [400320/620022]    Loss: 0.009102   Batch Acc: 82.81
[Train] Epoch: 2 [400384/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 2 [400448/620022]    Loss: 0.009291   Batch Acc: 76.56
[Train] Epoch: 2 [400512/620022]    Loss: 0.007981   Batch Acc: 82.81
[Train] Epoch: 2 [400576/620022]    Loss: 0.006233   Batch Acc: 82.81
[Train] Epoch: 2 [400640/620022]    Loss: 0.008807   Batch Acc: 71.88
[Train] Epoch: 2 [400704/620022]    Loss: 0.006807   Batch Acc: 81.25
[Train] Epoch: 2 [400768/620022]    Loss: 0.008132   Batch Acc: 76.56
[Train] Epoch: 2 [400832/620022]    Loss: 0.009405   Batch Acc: 73.44
[Train] Epoch: 2 [400896/620022]    Loss: 0.006395   Batch Acc: 84.38
[Train] Epoch: 2 [400960/620022]    Loss: 0.009738   Batch Acc: 75.00
[Train] Epoch: 2 [401024/620022]    Loss: 0.011497   Batch Acc: 70.31
[Train] Epoch: 2 [401088/620022]    Loss: 0.011627   Batch Acc: 64.06
[Train] Epoch: 2 [401152/620022]    Loss: 0.011228   Batch Acc: 67.19
[Train] Epoch: 2 [401216/620022]    Loss: 0.010468   Batch Acc: 70.31
[Train] Epoch: 2 [401280/620022]    Loss: 0.008938   Batch Acc: 78.12
[Train] Epoch: 2 [401344/620022]    Loss: 0.009222   Batch Acc: 82.81
[Train] Epoch: 2 [401408/620022]    Loss: 0.010458   Batch Acc: 76.56
[Train] Epoch: 2 [401472/620022]    Loss: 0.009280   Batch Acc: 70.31
[Train] Epoch: 2 [401536/620022]    Loss: 0.011087   Batch Acc: 70.31
[Train] Epoch: 2 [401600/620022]    Loss: 0.007772   Batch Acc: 79.69
[Train] Epoch: 2 [401664/620022]    Loss: 0.007877   Batch Acc: 82.81
[Train] Epoch: 2 [401728/620022]    Loss: 0.007478   Batch Acc: 81.25
[Train] Epoch: 2 [401792/620022]    Loss: 0.009656   Batch Acc: 76.56
[Train] Epoch: 2 [401856/620022]    Loss: 0.008186   Batch Acc: 84.38
[Train] Epoch: 2 [401920/620022]    Loss: 0.009092   Batch Acc: 79.69
[Train] Epoch: 2 [401984/620022]    Loss: 0.008107   Batch Acc: 78.12
[Train] Epoch: 2 [402048/620022]    Loss: 0.007857   Batch Acc: 82.81
[Train] Epoch: 2 [402112/620022]    Loss: 0.007694   Batch Acc: 82.81
[Train] Epoch: 2 [402176/620022]    Loss: 0.007262   Batch Acc: 84.38
[Train] Epoch: 2 [402240/620022]    Loss: 0.007833   Batch Acc: 78.12
[Train] Epoch: 2 [402304/620022]    Loss: 0.011429   Batch Acc: 70.31
[Train] Epoch: 2 [402368/620022]    Loss: 0.009223   Batch Acc: 81.25
[Train] Epoch: 2 [402432/620022]    Loss: 0.010812   Batch Acc: 76.56
[Train] Epoch: 2 [402496/620022]    Loss: 0.007148   Batch Acc: 79.69
[Train] Epoch: 2 [402560/620022]    Loss: 0.010355   Batch Acc: 75.00
[Train] Epoch: 2 [402624/620022]    Loss: 0.010757   Batch Acc: 71.88
[Train] Epoch: 2 [402688/620022]    Loss: 0.008931   Batch Acc: 76.56
[Train] Epoch: 2 [402752/620022]    Loss: 0.008239   Batch Acc: 78.12
[Train] Epoch: 2 [402816/620022]    Loss: 0.011539   Batch Acc: 71.88
[Train] Epoch: 2 [402880/620022]    Loss: 0.010299   Batch Acc: 65.62
[Train] Epoch: 2 [402944/620022]    Loss: 0.007994   Batch Acc: 78.12
[Train] Epoch: 2 [403008/620022]    Loss: 0.007178   Batch Acc: 79.69
[Train] Epoch: 2 [403072/620022]    Loss: 0.009298   Batch Acc: 76.56
[Train] Epoch: 2 [403136/620022]    Loss: 0.010168   Batch Acc: 78.12
[Train] Epoch: 2 [403200/620022]    Loss: 0.008717   Batch Acc: 81.25
[Train] Epoch: 2 [403264/620022]    Loss: 0.010375   Batch Acc: 78.12
[Train] Epoch: 2 [403328/620022]    Loss: 0.006963   Batch Acc: 84.38
[Train] Epoch: 2 [403392/620022]    Loss: 0.008327   Batch Acc: 87.50
[Train] Epoch: 2 [403456/620022]    Loss: 0.010846   Batch Acc: 70.31
[Train] Epoch: 2 [403520/620022]    Loss: 0.007493   Batch Acc: 81.25
[Train] Epoch: 2 [403584/620022]    Loss: 0.009710   Batch Acc: 82.81
[Train] Epoch: 2 [403648/620022]    Loss: 0.009136   Batch Acc: 78.12
[Train] Epoch: 2 [403712/620022]    Loss: 0.009542   Batch Acc: 73.44
[Train] Epoch: 2 [403776/620022]    Loss: 0.008284   Batch Acc: 78.12
[Train] Epoch: 2 [403840/620022]    Loss: 0.008823   Batch Acc: 73.44
[Train] Epoch: 2 [403904/620022]    Loss: 0.009801   Batch Acc: 76.56
[Train] Epoch: 2 [403968/620022]    Loss: 0.007522   Batch Acc: 84.38
[Train] Epoch: 2 [404032/620022]    Loss: 0.006394   Batch Acc: 85.94
[Train] Epoch: 2 [404096/620022]    Loss: 0.008679   Batch Acc: 75.00
[Train] Epoch: 2 [404160/620022]    Loss: 0.008412   Batch Acc: 76.56
[Train] Epoch: 2 [404224/620022]    Loss: 0.007507   Batch Acc: 84.38
[Train] Epoch: 2 [404288/620022]    Loss: 0.008502   Batch Acc: 76.56
[Train] Epoch: 2 [404352/620022]    Loss: 0.009739   Batch Acc: 75.00
[Train] Epoch: 2 [404416/620022]    Loss: 0.008809   Batch Acc: 76.56
[Train] Epoch: 2 [404480/620022]    Loss: 0.008522   Batch Acc: 78.12
[Train] Epoch: 2 [404544/620022]    Loss: 0.008347   Batch Acc: 79.69
[Train] Epoch: 2 [404608/620022]    Loss: 0.009001   Batch Acc: 75.00
[Train] Epoch: 2 [404672/620022]    Loss: 0.006962   Batch Acc: 82.81
[Train] Epoch: 2 [404736/620022]    Loss: 0.009199   Batch Acc: 76.56
[Train] Epoch: 2 [404800/620022]    Loss: 0.006745   Batch Acc: 85.94
[Train] Epoch: 2 [404864/620022]    Loss: 0.009877   Batch Acc: 75.00
[Train] Epoch: 2 [404928/620022]    Loss: 0.006918   Batch Acc: 79.69
[Train] Epoch: 2 [404992/620022]    Loss: 0.007357   Batch Acc: 79.69
[Train] Epoch: 2 [405056/620022]    Loss: 0.009993   Batch Acc: 73.44
[Train] Epoch: 2 [405120/620022]    Loss: 0.006029   Batch Acc: 84.38
[Train] Epoch: 2 [405184/620022]    Loss: 0.007754   Batch Acc: 79.69
[Train] Epoch: 2 [405248/620022]    Loss: 0.007382   Batch Acc: 84.38
[Train] Epoch: 2 [405312/620022]    Loss: 0.008454   Batch Acc: 82.81
[Train] Epoch: 2 [405376/620022]    Loss: 0.009563   Batch Acc: 76.56
[Train] Epoch: 2 [405440/620022]    Loss: 0.009529   Batch Acc: 78.12
[Train] Epoch: 2 [405504/620022]    Loss: 0.008606   Batch Acc: 71.88
[Train] Epoch: 2 [405568/620022]    Loss: 0.008842   Batch Acc: 78.12
[Train] Epoch: 2 [405632/620022]    Loss: 0.007653   Batch Acc: 84.38
[Train] Epoch: 2 [405696/620022]    Loss: 0.007382   Batch Acc: 81.25
[Train] Epoch: 2 [405760/620022]    Loss: 0.006509   Batch Acc: 82.81
[Train] Epoch: 2 [405824/620022]    Loss: 0.008560   Batch Acc: 81.25
[Train] Epoch: 2 [405888/620022]    Loss: 0.007315   Batch Acc: 82.81
[Train] Epoch: 2 [405952/620022]    Loss: 0.007661   Batch Acc: 79.69
[Train] Epoch: 2 [406016/620022]    Loss: 0.008907   Batch Acc: 78.12
[Train] Epoch: 2 [406080/620022]    Loss: 0.009393   Batch Acc: 73.44
[Train] Epoch: 2 [406144/620022]    Loss: 0.009532   Batch Acc: 76.56
[Train] Epoch: 2 [406208/620022]    Loss: 0.011944   Batch Acc: 64.06
[Train] Epoch: 2 [406272/620022]    Loss: 0.010630   Batch Acc: 71.88
[Train] Epoch: 2 [406336/620022]    Loss: 0.007025   Batch Acc: 84.38
[Train] Epoch: 2 [406400/620022]    Loss: 0.009630   Batch Acc: 71.88
[Train] Epoch: 2 [406464/620022]    Loss: 0.008555   Batch Acc: 75.00
[Train] Epoch: 2 [406528/620022]    Loss: 0.007115   Batch Acc: 82.81
[Train] Epoch: 2 [406592/620022]    Loss: 0.006897   Batch Acc: 81.25
[Train] Epoch: 2 [406656/620022]    Loss: 0.008740   Batch Acc: 79.69
[Train] Epoch: 2 [406720/620022]    Loss: 0.008229   Batch Acc: 75.00
[Train] Epoch: 2 [406784/620022]    Loss: 0.007491   Batch Acc: 85.94
[Train] Epoch: 2 [406848/620022]    Loss: 0.007848   Batch Acc: 78.12
[Train] Epoch: 2 [406912/620022]    Loss: 0.006930   Batch Acc: 84.38
[Train] Epoch: 2 [406976/620022]    Loss: 0.011968   Batch Acc: 67.19
[Train] Epoch: 2 [407040/620022]    Loss: 0.007335   Batch Acc: 84.38
[Train] Epoch: 2 [407104/620022]    Loss: 0.009682   Batch Acc: 70.31
[Train] Epoch: 2 [407168/620022]    Loss: 0.007842   Batch Acc: 81.25
[Train] Epoch: 2 [407232/620022]    Loss: 0.008141   Batch Acc: 78.12
[Train] Epoch: 2 [407296/620022]    Loss: 0.008486   Batch Acc: 78.12
[Train] Epoch: 2 [407360/620022]    Loss: 0.009392   Batch Acc: 75.00
[Train] Epoch: 2 [407424/620022]    Loss: 0.008131   Batch Acc: 76.56
[Train] Epoch: 2 [407488/620022]    Loss: 0.009062   Batch Acc: 76.56
[Train] Epoch: 2 [407552/620022]    Loss: 0.007736   Batch Acc: 78.12
[Train] Epoch: 2 [407616/620022]    Loss: 0.007589   Batch Acc: 76.56
[Train] Epoch: 2 [407680/620022]    Loss: 0.008228   Batch Acc: 78.12
[Train] Epoch: 2 [407744/620022]    Loss: 0.008293   Batch Acc: 82.81
[Train] Epoch: 2 [407808/620022]    Loss: 0.008999   Batch Acc: 75.00
[Train] Epoch: 2 [407872/620022]    Loss: 0.010098   Batch Acc: 73.44
[Train] Epoch: 2 [407936/620022]    Loss: 0.006664   Batch Acc: 85.94
[Train] Epoch: 2 [408000/620022]    Loss: 0.010058   Batch Acc: 73.44
[Train] Epoch: 2 [408064/620022]    Loss: 0.009602   Batch Acc: 78.12
[Train] Epoch: 2 [408128/620022]    Loss: 0.009289   Batch Acc: 81.25
[Train] Epoch: 2 [408192/620022]    Loss: 0.010966   Batch Acc: 73.44
[Train] Epoch: 2 [408256/620022]    Loss: 0.010518   Batch Acc: 68.75
[Train] Epoch: 2 [408320/620022]    Loss: 0.008139   Batch Acc: 79.69
[Train] Epoch: 2 [408384/620022]    Loss: 0.008806   Batch Acc: 78.12
[Train] Epoch: 2 [408448/620022]    Loss: 0.009489   Batch Acc: 81.25
[Train] Epoch: 2 [408512/620022]    Loss: 0.009796   Batch Acc: 75.00
[Train] Epoch: 2 [408576/620022]    Loss: 0.007533   Batch Acc: 84.38
[Train] Epoch: 2 [408640/620022]    Loss: 0.006420   Batch Acc: 87.50
[Train] Epoch: 2 [408704/620022]    Loss: 0.008716   Batch Acc: 79.69
[Train] Epoch: 2 [408768/620022]    Loss: 0.012614   Batch Acc: 70.31
[Train] Epoch: 2 [408832/620022]    Loss: 0.008263   Batch Acc: 75.00
[Train] Epoch: 2 [408896/620022]    Loss: 0.009994   Batch Acc: 73.44
[Train] Epoch: 2 [408960/620022]    Loss: 0.009891   Batch Acc: 67.19
[Train] Epoch: 2 [409024/620022]    Loss: 0.009810   Batch Acc: 71.88
[Train] Epoch: 2 [409088/620022]    Loss: 0.007464   Batch Acc: 82.81
[Train] Epoch: 2 [409152/620022]    Loss: 0.006239   Batch Acc: 85.94
[Train] Epoch: 2 [409216/620022]    Loss: 0.009870   Batch Acc: 76.56
[Train] Epoch: 2 [409280/620022]    Loss: 0.007218   Batch Acc: 76.56
[Train] Epoch: 2 [409344/620022]    Loss: 0.006664   Batch Acc: 81.25
[Train] Epoch: 2 [409408/620022]    Loss: 0.006096   Batch Acc: 85.94
[Train] Epoch: 2 [409472/620022]    Loss: 0.009011   Batch Acc: 76.56
[Train] Epoch: 2 [409536/620022]    Loss: 0.009279   Batch Acc: 75.00
[Train] Epoch: 2 [409600/620022]    Loss: 0.008584   Batch Acc: 78.12
[Train] Epoch: 2 [409664/620022]    Loss: 0.011892   Batch Acc: 68.75
[Train] Epoch: 2 [409728/620022]    Loss: 0.006742   Batch Acc: 84.38
[Train] Epoch: 2 [409792/620022]    Loss: 0.007446   Batch Acc: 76.56
[Train] Epoch: 2 [409856/620022]    Loss: 0.010107   Batch Acc: 70.31
[Train] Epoch: 2 [409920/620022]    Loss: 0.010397   Batch Acc: 67.19
[Train] Epoch: 2 [409984/620022]    Loss: 0.013116   Batch Acc: 59.38
[Train] Epoch: 2 [410048/620022]    Loss: 0.008338   Batch Acc: 73.44
[Train] Epoch: 2 [410112/620022]    Loss: 0.007699   Batch Acc: 82.81
[Train] Epoch: 2 [410176/620022]    Loss: 0.009300   Batch Acc: 78.12
[Train] Epoch: 2 [410240/620022]    Loss: 0.007479   Batch Acc: 87.50
[Train] Epoch: 2 [410304/620022]    Loss: 0.007570   Batch Acc: 81.25
[Train] Epoch: 2 [410368/620022]    Loss: 0.008649   Batch Acc: 81.25
[Train] Epoch: 2 [410432/620022]    Loss: 0.011552   Batch Acc: 67.19
[Train] Epoch: 2 [410496/620022]    Loss: 0.009066   Batch Acc: 79.69
[Train] Epoch: 2 [410560/620022]    Loss: 0.007946   Batch Acc: 82.81
[Train] Epoch: 2 [410624/620022]    Loss: 0.009152   Batch Acc: 71.88
[Train] Epoch: 2 [410688/620022]    Loss: 0.007540   Batch Acc: 84.38
[Train] Epoch: 2 [410752/620022]    Loss: 0.008962   Batch Acc: 76.56
[Train] Epoch: 2 [410816/620022]    Loss: 0.008961   Batch Acc: 75.00
[Train] Epoch: 2 [410880/620022]    Loss: 0.012870   Batch Acc: 59.38
[Train] Epoch: 2 [410944/620022]    Loss: 0.009422   Batch Acc: 71.88
[Train] Epoch: 2 [411008/620022]    Loss: 0.007018   Batch Acc: 82.81
[Train] Epoch: 2 [411072/620022]    Loss: 0.008113   Batch Acc: 79.69
[Train] Epoch: 2 [411136/620022]    Loss: 0.007490   Batch Acc: 85.94
[Train] Epoch: 2 [411200/620022]    Loss: 0.007913   Batch Acc: 84.38
[Train] Epoch: 2 [411264/620022]    Loss: 0.007707   Batch Acc: 81.25
[Train] Epoch: 2 [411328/620022]    Loss: 0.008984   Batch Acc: 82.81
[Train] Epoch: 2 [411392/620022]    Loss: 0.008828   Batch Acc: 73.44
[Train] Epoch: 2 [411456/620022]    Loss: 0.010615   Batch Acc: 70.31
[Train] Epoch: 2 [411520/620022]    Loss: 0.006999   Batch Acc: 79.69
[Train] Epoch: 2 [411584/620022]    Loss: 0.010030   Batch Acc: 75.00
[Train] Epoch: 2 [411648/620022]    Loss: 0.007809   Batch Acc: 78.12
[Train] Epoch: 2 [411712/620022]    Loss: 0.007301   Batch Acc: 79.69
[Train] Epoch: 2 [411776/620022]    Loss: 0.013193   Batch Acc: 70.31
[Train] Epoch: 2 [411840/620022]    Loss: 0.008554   Batch Acc: 75.00
[Train] Epoch: 2 [411904/620022]    Loss: 0.008305   Batch Acc: 78.12
[Train] Epoch: 2 [411968/620022]    Loss: 0.008318   Batch Acc: 81.25
[Train] Epoch: 2 [412032/620022]    Loss: 0.005813   Batch Acc: 89.06
[Train] Epoch: 2 [412096/620022]    Loss: 0.010957   Batch Acc: 75.00
[Train] Epoch: 2 [412160/620022]    Loss: 0.008272   Batch Acc: 81.25
[Train] Epoch: 2 [412224/620022]    Loss: 0.011223   Batch Acc: 73.44
[Train] Epoch: 2 [412288/620022]    Loss: 0.008647   Batch Acc: 76.56
[Train] Epoch: 2 [412352/620022]    Loss: 0.008675   Batch Acc: 78.12
[Train] Epoch: 2 [412416/620022]    Loss: 0.006794   Batch Acc: 87.50
[Train] Epoch: 2 [412480/620022]    Loss: 0.008364   Batch Acc: 78.12
[Train] Epoch: 2 [412544/620022]    Loss: 0.009252   Batch Acc: 71.88
[Train] Epoch: 2 [412608/620022]    Loss: 0.007326   Batch Acc: 81.25
[Train] Epoch: 2 [412672/620022]    Loss: 0.009664   Batch Acc: 76.56
[Train] Epoch: 2 [412736/620022]    Loss: 0.008053   Batch Acc: 79.69
[Train] Epoch: 2 [412800/620022]    Loss: 0.011042   Batch Acc: 73.44
[Train] Epoch: 2 [412864/620022]    Loss: 0.006697   Batch Acc: 85.94
[Train] Epoch: 2 [412928/620022]    Loss: 0.009573   Batch Acc: 78.12
[Train] Epoch: 2 [412992/620022]    Loss: 0.011121   Batch Acc: 62.50
[Train] Epoch: 2 [413056/620022]    Loss: 0.008647   Batch Acc: 79.69
[Train] Epoch: 2 [413120/620022]    Loss: 0.007759   Batch Acc: 76.56
[Train] Epoch: 2 [413184/620022]    Loss: 0.007578   Batch Acc: 82.81
[Train] Epoch: 2 [413248/620022]    Loss: 0.009689   Batch Acc: 73.44
[Train] Epoch: 2 [413312/620022]    Loss: 0.007231   Batch Acc: 78.12
[Train] Epoch: 2 [413376/620022]    Loss: 0.008609   Batch Acc: 81.25
[Train] Epoch: 2 [413440/620022]    Loss: 0.009380   Batch Acc: 71.88
[Train] Epoch: 2 [413504/620022]    Loss: 0.010013   Batch Acc: 78.12
[Train] Epoch: 2 [413568/620022]    Loss: 0.009062   Batch Acc: 76.56
[Train] Epoch: 2 [413632/620022]    Loss: 0.010309   Batch Acc: 71.88
[Train] Epoch: 2 [413696/620022]    Loss: 0.009959   Batch Acc: 76.56
[Train] Epoch: 2 [413760/620022]    Loss: 0.009843   Batch Acc: 68.75
[Train] Epoch: 2 [413824/620022]    Loss: 0.008268   Batch Acc: 79.69
[Train] Epoch: 2 [413888/620022]    Loss: 0.009347   Batch Acc: 76.56
[Train] Epoch: 2 [413952/620022]    Loss: 0.008525   Batch Acc: 71.88
[Train] Epoch: 2 [414016/620022]    Loss: 0.006977   Batch Acc: 87.50
[Train] Epoch: 2 [414080/620022]    Loss: 0.008427   Batch Acc: 84.38
[Train] Epoch: 2 [414144/620022]    Loss: 0.008491   Batch Acc: 75.00
[Train] Epoch: 2 [414208/620022]    Loss: 0.008469   Batch Acc: 79.69
[Train] Epoch: 2 [414272/620022]    Loss: 0.006351   Batch Acc: 84.38
[Train] Epoch: 2 [414336/620022]    Loss: 0.007292   Batch Acc: 82.81
[Train] Epoch: 2 [414400/620022]    Loss: 0.007245   Batch Acc: 85.94
[Train] Epoch: 2 [414464/620022]    Loss: 0.007741   Batch Acc: 82.81
[Train] Epoch: 2 [414528/620022]    Loss: 0.007080   Batch Acc: 81.25
[Train] Epoch: 2 [414592/620022]    Loss: 0.009998   Batch Acc: 75.00
[Train] Epoch: 2 [414656/620022]    Loss: 0.008834   Batch Acc: 79.69
[Train] Epoch: 2 [414720/620022]    Loss: 0.008492   Batch Acc: 76.56
[Train] Epoch: 2 [414784/620022]    Loss: 0.007889   Batch Acc: 81.25
[Train] Epoch: 2 [414848/620022]    Loss: 0.011516   Batch Acc: 68.75
[Train] Epoch: 2 [414912/620022]    Loss: 0.011570   Batch Acc: 70.31
[Train] Epoch: 2 [414976/620022]    Loss: 0.008071   Batch Acc: 82.81
[Train] Epoch: 2 [415040/620022]    Loss: 0.007885   Batch Acc: 81.25
[Train] Epoch: 2 [415104/620022]    Loss: 0.009174   Batch Acc: 76.56
[Train] Epoch: 2 [415168/620022]    Loss: 0.008437   Batch Acc: 75.00
[Train] Epoch: 2 [415232/620022]    Loss: 0.008516   Batch Acc: 76.56
[Train] Epoch: 2 [415296/620022]    Loss: 0.008713   Batch Acc: 85.94
[Train] Epoch: 2 [415360/620022]    Loss: 0.008611   Batch Acc: 76.56
[Train] Epoch: 2 [415424/620022]    Loss: 0.008798   Batch Acc: 79.69
[Train] Epoch: 2 [415488/620022]    Loss: 0.008641   Batch Acc: 75.00
[Train] Epoch: 2 [415552/620022]    Loss: 0.009563   Batch Acc: 81.25
[Train] Epoch: 2 [415616/620022]    Loss: 0.006385   Batch Acc: 81.25
[Train] Epoch: 2 [415680/620022]    Loss: 0.009455   Batch Acc: 75.00
[Train] Epoch: 2 [415744/620022]    Loss: 0.009705   Batch Acc: 70.31
[Train] Epoch: 2 [415808/620022]    Loss: 0.009157   Batch Acc: 76.56
[Train] Epoch: 2 [415872/620022]    Loss: 0.008108   Batch Acc: 81.25
[Train] Epoch: 2 [415936/620022]    Loss: 0.006778   Batch Acc: 84.38
[Train] Epoch: 2 [416000/620022]    Loss: 0.009786   Batch Acc: 76.56
[Train] Epoch: 2 [416064/620022]    Loss: 0.007459   Batch Acc: 85.94
[Train] Epoch: 2 [416128/620022]    Loss: 0.009479   Batch Acc: 75.00
[Train] Epoch: 2 [416192/620022]    Loss: 0.008401   Batch Acc: 79.69
[Train] Epoch: 2 [416256/620022]    Loss: 0.009167   Batch Acc: 71.88
[Train] Epoch: 2 [416320/620022]    Loss: 0.009723   Batch Acc: 68.75
[Train] Epoch: 2 [416384/620022]    Loss: 0.007909   Batch Acc: 78.12
[Train] Epoch: 2 [416448/620022]    Loss: 0.008309   Batch Acc: 76.56
[Train] Epoch: 2 [416512/620022]    Loss: 0.009088   Batch Acc: 76.56
[Train] Epoch: 2 [416576/620022]    Loss: 0.007740   Batch Acc: 78.12
[Train] Epoch: 2 [416640/620022]    Loss: 0.007030   Batch Acc: 87.50
[Train] Epoch: 2 [416704/620022]    Loss: 0.008775   Batch Acc: 78.12
[Train] Epoch: 2 [416768/620022]    Loss: 0.008817   Batch Acc: 78.12
[Train] Epoch: 2 [416832/620022]    Loss: 0.007168   Batch Acc: 85.94
[Train] Epoch: 2 [416896/620022]    Loss: 0.006974   Batch Acc: 85.94
[Train] Epoch: 2 [416960/620022]    Loss: 0.009664   Batch Acc: 67.19
[Train] Epoch: 2 [417024/620022]    Loss: 0.008784   Batch Acc: 78.12
[Train] Epoch: 2 [417088/620022]    Loss: 0.007996   Batch Acc: 78.12
[Train] Epoch: 2 [417152/620022]    Loss: 0.007973   Batch Acc: 84.38
[Train] Epoch: 2 [417216/620022]    Loss: 0.006978   Batch Acc: 79.69
[Train] Epoch: 2 [417280/620022]    Loss: 0.008225   Batch Acc: 75.00
[Train] Epoch: 2 [417344/620022]    Loss: 0.008966   Batch Acc: 78.12
[Train] Epoch: 2 [417408/620022]    Loss: 0.009213   Batch Acc: 79.69
[Train] Epoch: 2 [417472/620022]    Loss: 0.007622   Batch Acc: 78.12
[Train] Epoch: 2 [417536/620022]    Loss: 0.006805   Batch Acc: 89.06
[Train] Epoch: 2 [417600/620022]    Loss: 0.008516   Batch Acc: 78.12
[Train] Epoch: 2 [417664/620022]    Loss: 0.006318   Batch Acc: 84.38
[Train] Epoch: 2 [417728/620022]    Loss: 0.008005   Batch Acc: 78.12
[Train] Epoch: 2 [417792/620022]    Loss: 0.008411   Batch Acc: 78.12
[Train] Epoch: 2 [417856/620022]    Loss: 0.008395   Batch Acc: 75.00
[Train] Epoch: 2 [417920/620022]    Loss: 0.007610   Batch Acc: 78.12
[Train] Epoch: 2 [417984/620022]    Loss: 0.008886   Batch Acc: 76.56
[Train] Epoch: 2 [418048/620022]    Loss: 0.011689   Batch Acc: 70.31
[Train] Epoch: 2 [418112/620022]    Loss: 0.007349   Batch Acc: 78.12
[Train] Epoch: 2 [418176/620022]    Loss: 0.008509   Batch Acc: 82.81
[Train] Epoch: 2 [418240/620022]    Loss: 0.006754   Batch Acc: 84.38
[Train] Epoch: 2 [418304/620022]    Loss: 0.007709   Batch Acc: 84.38
[Train] Epoch: 2 [418368/620022]    Loss: 0.007337   Batch Acc: 84.38
[Train] Epoch: 2 [418432/620022]    Loss: 0.008290   Batch Acc: 81.25
[Train] Epoch: 2 [418496/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 2 [418560/620022]    Loss: 0.009385   Batch Acc: 76.56
[Train] Epoch: 2 [418624/620022]    Loss: 0.010661   Batch Acc: 70.31
[Train] Epoch: 2 [418688/620022]    Loss: 0.009031   Batch Acc: 79.69
[Train] Epoch: 2 [418752/620022]    Loss: 0.008537   Batch Acc: 71.88
[Train] Epoch: 2 [418816/620022]    Loss: 0.008129   Batch Acc: 81.25
[Train] Epoch: 2 [418880/620022]    Loss: 0.007654   Batch Acc: 78.12
[Train] Epoch: 2 [418944/620022]    Loss: 0.005833   Batch Acc: 90.62
[Train] Epoch: 2 [419008/620022]    Loss: 0.010012   Batch Acc: 79.69
[Train] Epoch: 2 [419072/620022]    Loss: 0.010689   Batch Acc: 73.44
[Train] Epoch: 2 [419136/620022]    Loss: 0.009861   Batch Acc: 73.44
[Train] Epoch: 2 [419200/620022]    Loss: 0.009744   Batch Acc: 70.31
[Train] Epoch: 2 [419264/620022]    Loss: 0.010232   Batch Acc: 68.75
[Train] Epoch: 2 [419328/620022]    Loss: 0.009122   Batch Acc: 70.31
[Train] Epoch: 2 [419392/620022]    Loss: 0.008027   Batch Acc: 81.25
[Train] Epoch: 2 [419456/620022]    Loss: 0.007205   Batch Acc: 82.81
[Train] Epoch: 2 [419520/620022]    Loss: 0.007206   Batch Acc: 81.25
[Train] Epoch: 2 [419584/620022]    Loss: 0.009249   Batch Acc: 71.88
[Train] Epoch: 2 [419648/620022]    Loss: 0.009897   Batch Acc: 67.19
[Train] Epoch: 2 [419712/620022]    Loss: 0.012425   Batch Acc: 62.50
[Train] Epoch: 2 [419776/620022]    Loss: 0.009620   Batch Acc: 76.56
[Train] Epoch: 2 [419840/620022]    Loss: 0.007676   Batch Acc: 85.94
[Train] Epoch: 2 [419904/620022]    Loss: 0.007047   Batch Acc: 85.94
[Train] Epoch: 2 [419968/620022]    Loss: 0.007856   Batch Acc: 78.12
[Train] Epoch: 2 [420032/620022]    Loss: 0.010255   Batch Acc: 71.88
[Train] Epoch: 2 [420096/620022]    Loss: 0.011218   Batch Acc: 73.44
[Train] Epoch: 2 [420160/620022]    Loss: 0.007302   Batch Acc: 79.69
[Train] Epoch: 2 [420224/620022]    Loss: 0.010054   Batch Acc: 75.00
[Train] Epoch: 2 [420288/620022]    Loss: 0.007851   Batch Acc: 79.69
[Train] Epoch: 2 [420352/620022]    Loss: 0.008311   Batch Acc: 79.69
[Train] Epoch: 2 [420416/620022]    Loss: 0.007091   Batch Acc: 79.69
[Train] Epoch: 2 [420480/620022]    Loss: 0.010521   Batch Acc: 76.56
[Train] Epoch: 2 [420544/620022]    Loss: 0.006589   Batch Acc: 85.94
[Train] Epoch: 2 [420608/620022]    Loss: 0.005722   Batch Acc: 89.06
[Train] Epoch: 2 [420672/620022]    Loss: 0.008408   Batch Acc: 79.69
[Train] Epoch: 2 [420736/620022]    Loss: 0.009042   Batch Acc: 73.44
[Train] Epoch: 2 [420800/620022]    Loss: 0.006912   Batch Acc: 82.81
[Train] Epoch: 2 [420864/620022]    Loss: 0.007780   Batch Acc: 84.38
[Train] Epoch: 2 [420928/620022]    Loss: 0.008559   Batch Acc: 79.69
[Train] Epoch: 2 [420992/620022]    Loss: 0.010331   Batch Acc: 76.56
[Train] Epoch: 2 [421056/620022]    Loss: 0.009878   Batch Acc: 68.75
[Train] Epoch: 2 [421120/620022]    Loss: 0.007207   Batch Acc: 81.25
[Train] Epoch: 2 [421184/620022]    Loss: 0.008673   Batch Acc: 76.56
[Train] Epoch: 2 [421248/620022]    Loss: 0.009698   Batch Acc: 71.88
[Train] Epoch: 2 [421312/620022]    Loss: 0.009837   Batch Acc: 75.00
[Train] Epoch: 2 [421376/620022]    Loss: 0.007289   Batch Acc: 82.81
[Train] Epoch: 2 [421440/620022]    Loss: 0.009733   Batch Acc: 75.00
[Train] Epoch: 2 [421504/620022]    Loss: 0.007283   Batch Acc: 82.81
[Train] Epoch: 2 [421568/620022]    Loss: 0.008708   Batch Acc: 76.56
[Train] Epoch: 2 [421632/620022]    Loss: 0.006445   Batch Acc: 85.94
[Train] Epoch: 2 [421696/620022]    Loss: 0.008444   Batch Acc: 73.44
[Train] Epoch: 2 [421760/620022]    Loss: 0.009666   Batch Acc: 76.56
[Train] Epoch: 2 [421824/620022]    Loss: 0.009123   Batch Acc: 79.69
[Train] Epoch: 2 [421888/620022]    Loss: 0.009192   Batch Acc: 78.12
[Train] Epoch: 2 [421952/620022]    Loss: 0.009943   Batch Acc: 76.56
[Train] Epoch: 2 [422016/620022]    Loss: 0.007845   Batch Acc: 81.25
[Train] Epoch: 2 [422080/620022]    Loss: 0.009365   Batch Acc: 68.75
[Train] Epoch: 2 [422144/620022]    Loss: 0.009648   Batch Acc: 73.44
[Train] Epoch: 2 [422208/620022]    Loss: 0.008368   Batch Acc: 78.12
[Train] Epoch: 2 [422272/620022]    Loss: 0.006064   Batch Acc: 84.38
[Train] Epoch: 2 [422336/620022]    Loss: 0.009406   Batch Acc: 75.00
[Train] Epoch: 2 [422400/620022]    Loss: 0.011838   Batch Acc: 68.75
[Train] Epoch: 2 [422464/620022]    Loss: 0.008227   Batch Acc: 79.69
[Train] Epoch: 2 [422528/620022]    Loss: 0.008311   Batch Acc: 81.25
[Train] Epoch: 2 [422592/620022]    Loss: 0.007926   Batch Acc: 84.38
[Train] Epoch: 2 [422656/620022]    Loss: 0.008830   Batch Acc: 81.25
[Train] Epoch: 2 [422720/620022]    Loss: 0.007331   Batch Acc: 78.12
[Train] Epoch: 2 [422784/620022]    Loss: 0.008781   Batch Acc: 81.25
[Train] Epoch: 2 [422848/620022]    Loss: 0.009486   Batch Acc: 81.25
[Train] Epoch: 2 [422912/620022]    Loss: 0.009197   Batch Acc: 75.00
[Train] Epoch: 2 [422976/620022]    Loss: 0.009634   Batch Acc: 75.00
[Train] Epoch: 2 [423040/620022]    Loss: 0.010669   Batch Acc: 70.31
[Train] Epoch: 2 [423104/620022]    Loss: 0.008335   Batch Acc: 81.25
[Train] Epoch: 2 [423168/620022]    Loss: 0.006361   Batch Acc: 87.50
[Train] Epoch: 2 [423232/620022]    Loss: 0.008779   Batch Acc: 79.69
[Train] Epoch: 2 [423296/620022]    Loss: 0.008756   Batch Acc: 76.56
[Train] Epoch: 2 [423360/620022]    Loss: 0.008725   Batch Acc: 70.31
[Train] Epoch: 2 [423424/620022]    Loss: 0.008212   Batch Acc: 79.69
[Train] Epoch: 2 [423488/620022]    Loss: 0.008301   Batch Acc: 78.12
[Train] Epoch: 2 [423552/620022]    Loss: 0.005210   Batch Acc: 92.19
[Train] Epoch: 2 [423616/620022]    Loss: 0.008495   Batch Acc: 76.56
[Train] Epoch: 2 [423680/620022]    Loss: 0.007352   Batch Acc: 78.12
[Train] Epoch: 2 [423744/620022]    Loss: 0.009347   Batch Acc: 71.88
[Train] Epoch: 2 [423808/620022]    Loss: 0.011202   Batch Acc: 75.00
[Train] Epoch: 2 [423872/620022]    Loss: 0.007867   Batch Acc: 78.12
[Train] Epoch: 2 [423936/620022]    Loss: 0.007718   Batch Acc: 78.12
[Train] Epoch: 2 [424000/620022]    Loss: 0.009136   Batch Acc: 81.25
[Train] Epoch: 2 [424064/620022]    Loss: 0.007660   Batch Acc: 75.00
[Train] Epoch: 2 [424128/620022]    Loss: 0.006417   Batch Acc: 85.94
[Train] Epoch: 2 [424192/620022]    Loss: 0.008227   Batch Acc: 76.56
[Train] Epoch: 2 [424256/620022]    Loss: 0.010730   Batch Acc: 70.31
[Train] Epoch: 2 [424320/620022]    Loss: 0.006343   Batch Acc: 84.38
[Train] Epoch: 2 [424384/620022]    Loss: 0.007312   Batch Acc: 81.25
[Train] Epoch: 2 [424448/620022]    Loss: 0.010756   Batch Acc: 71.88
[Train] Epoch: 2 [424512/620022]    Loss: 0.010571   Batch Acc: 70.31
[Train] Epoch: 2 [424576/620022]    Loss: 0.006533   Batch Acc: 85.94
[Train] Epoch: 2 [424640/620022]    Loss: 0.009741   Batch Acc: 71.88
[Train] Epoch: 2 [424704/620022]    Loss: 0.009279   Batch Acc: 75.00
[Train] Epoch: 2 [424768/620022]    Loss: 0.009688   Batch Acc: 76.56
[Train] Epoch: 2 [424832/620022]    Loss: 0.011274   Batch Acc: 79.69
[Train] Epoch: 2 [424896/620022]    Loss: 0.008886   Batch Acc: 82.81
[Train] Epoch: 2 [424960/620022]    Loss: 0.009113   Batch Acc: 81.25
[Train] Epoch: 2 [425024/620022]    Loss: 0.009403   Batch Acc: 76.56
[Train] Epoch: 2 [425088/620022]    Loss: 0.009180   Batch Acc: 71.88
[Train] Epoch: 2 [425152/620022]    Loss: 0.009385   Batch Acc: 73.44
[Train] Epoch: 2 [425216/620022]    Loss: 0.009196   Batch Acc: 82.81
[Train] Epoch: 2 [425280/620022]    Loss: 0.008014   Batch Acc: 79.69
[Train] Epoch: 2 [425344/620022]    Loss: 0.007036   Batch Acc: 84.38
[Train] Epoch: 2 [425408/620022]    Loss: 0.009421   Batch Acc: 76.56
[Train] Epoch: 2 [425472/620022]    Loss: 0.007493   Batch Acc: 79.69
[Train] Epoch: 2 [425536/620022]    Loss: 0.009843   Batch Acc: 71.88
[Train] Epoch: 2 [425600/620022]    Loss: 0.007328   Batch Acc: 85.94
[Train] Epoch: 2 [425664/620022]    Loss: 0.008579   Batch Acc: 81.25
[Train] Epoch: 2 [425728/620022]    Loss: 0.007067   Batch Acc: 82.81
[Train] Epoch: 2 [425792/620022]    Loss: 0.010698   Batch Acc: 67.19
[Train] Epoch: 2 [425856/620022]    Loss: 0.008041   Batch Acc: 78.12
[Train] Epoch: 2 [425920/620022]    Loss: 0.008260   Batch Acc: 85.94
[Train] Epoch: 2 [425984/620022]    Loss: 0.010154   Batch Acc: 68.75
[Train] Epoch: 2 [426048/620022]    Loss: 0.007562   Batch Acc: 78.12
[Train] Epoch: 2 [426112/620022]    Loss: 0.007450   Batch Acc: 82.81
[Train] Epoch: 2 [426176/620022]    Loss: 0.009280   Batch Acc: 73.44
[Train] Epoch: 2 [426240/620022]    Loss: 0.007482   Batch Acc: 87.50
[Train] Epoch: 2 [426304/620022]    Loss: 0.008047   Batch Acc: 81.25
[Train] Epoch: 2 [426368/620022]    Loss: 0.008574   Batch Acc: 82.81
[Train] Epoch: 2 [426432/620022]    Loss: 0.006992   Batch Acc: 82.81
[Train] Epoch: 2 [426496/620022]    Loss: 0.008904   Batch Acc: 79.69
[Train] Epoch: 2 [426560/620022]    Loss: 0.010350   Batch Acc: 71.88
[Train] Epoch: 2 [426624/620022]    Loss: 0.009091   Batch Acc: 73.44
[Train] Epoch: 2 [426688/620022]    Loss: 0.009021   Batch Acc: 78.12
[Train] Epoch: 2 [426752/620022]    Loss: 0.008640   Batch Acc: 76.56
[Train] Epoch: 2 [426816/620022]    Loss: 0.011188   Batch Acc: 67.19
[Train] Epoch: 2 [426880/620022]    Loss: 0.010075   Batch Acc: 78.12
[Train] Epoch: 2 [426944/620022]    Loss: 0.009271   Batch Acc: 82.81
[Train] Epoch: 2 [427008/620022]    Loss: 0.007057   Batch Acc: 85.94
[Train] Epoch: 2 [427072/620022]    Loss: 0.008741   Batch Acc: 78.12
[Train] Epoch: 2 [427136/620022]    Loss: 0.007360   Batch Acc: 81.25
[Train] Epoch: 2 [427200/620022]    Loss: 0.008110   Batch Acc: 81.25
[Train] Epoch: 2 [427264/620022]    Loss: 0.006291   Batch Acc: 84.38
[Train] Epoch: 2 [427328/620022]    Loss: 0.008291   Batch Acc: 79.69
[Train] Epoch: 2 [427392/620022]    Loss: 0.008868   Batch Acc: 79.69
[Train] Epoch: 2 [427456/620022]    Loss: 0.009420   Batch Acc: 73.44
[Train] Epoch: 2 [427520/620022]    Loss: 0.007800   Batch Acc: 73.44
[Train] Epoch: 2 [427584/620022]    Loss: 0.010104   Batch Acc: 76.56
[Train] Epoch: 2 [427648/620022]    Loss: 0.009417   Batch Acc: 71.88
[Train] Epoch: 2 [427712/620022]    Loss: 0.007421   Batch Acc: 81.25
[Train] Epoch: 2 [427776/620022]    Loss: 0.009054   Batch Acc: 79.69
[Train] Epoch: 2 [427840/620022]    Loss: 0.008403   Batch Acc: 76.56
[Train] Epoch: 2 [427904/620022]    Loss: 0.010005   Batch Acc: 73.44
[Train] Epoch: 2 [427968/620022]    Loss: 0.009434   Batch Acc: 75.00
[Train] Epoch: 2 [428032/620022]    Loss: 0.009784   Batch Acc: 73.44
[Train] Epoch: 2 [428096/620022]    Loss: 0.008131   Batch Acc: 82.81
[Train] Epoch: 2 [428160/620022]    Loss: 0.011784   Batch Acc: 62.50
[Train] Epoch: 2 [428224/620022]    Loss: 0.009491   Batch Acc: 71.88
[Train] Epoch: 2 [428288/620022]    Loss: 0.007620   Batch Acc: 81.25
[Train] Epoch: 2 [428352/620022]    Loss: 0.008688   Batch Acc: 76.56
[Train] Epoch: 2 [428416/620022]    Loss: 0.011607   Batch Acc: 65.62
[Train] Epoch: 2 [428480/620022]    Loss: 0.007428   Batch Acc: 82.81
[Train] Epoch: 2 [428544/620022]    Loss: 0.010121   Batch Acc: 70.31
[Train] Epoch: 2 [428608/620022]    Loss: 0.010117   Batch Acc: 73.44
[Train] Epoch: 2 [428672/620022]    Loss: 0.007308   Batch Acc: 82.81
[Train] Epoch: 2 [428736/620022]    Loss: 0.008235   Batch Acc: 79.69
[Train] Epoch: 2 [428800/620022]    Loss: 0.010292   Batch Acc: 76.56
[Train] Epoch: 2 [428864/620022]    Loss: 0.008351   Batch Acc: 71.88
[Train] Epoch: 2 [428928/620022]    Loss: 0.009312   Batch Acc: 78.12
[Train] Epoch: 2 [428992/620022]    Loss: 0.009751   Batch Acc: 71.88
[Train] Epoch: 2 [429056/620022]    Loss: 0.008607   Batch Acc: 81.25
[Train] Epoch: 2 [429120/620022]    Loss: 0.008405   Batch Acc: 81.25
[Train] Epoch: 2 [429184/620022]    Loss: 0.008368   Batch Acc: 75.00
[Train] Epoch: 2 [429248/620022]    Loss: 0.009752   Batch Acc: 76.56
[Train] Epoch: 2 [429312/620022]    Loss: 0.007507   Batch Acc: 82.81
[Train] Epoch: 2 [429376/620022]    Loss: 0.008619   Batch Acc: 76.56
[Train] Epoch: 2 [429440/620022]    Loss: 0.011041   Batch Acc: 71.88
[Train] Epoch: 2 [429504/620022]    Loss: 0.009612   Batch Acc: 78.12
[Train] Epoch: 2 [429568/620022]    Loss: 0.009500   Batch Acc: 75.00
[Train] Epoch: 2 [429632/620022]    Loss: 0.008173   Batch Acc: 81.25
[Train] Epoch: 2 [429696/620022]    Loss: 0.009096   Batch Acc: 73.44
[Train] Epoch: 2 [429760/620022]    Loss: 0.007817   Batch Acc: 82.81
[Train] Epoch: 2 [429824/620022]    Loss: 0.007794   Batch Acc: 81.25
[Train] Epoch: 2 [429888/620022]    Loss: 0.008076   Batch Acc: 81.25
[Train] Epoch: 2 [429952/620022]    Loss: 0.010218   Batch Acc: 73.44
[Train] Epoch: 2 [430016/620022]    Loss: 0.007946   Batch Acc: 81.25
[Train] Epoch: 2 [430080/620022]    Loss: 0.007910   Batch Acc: 79.69
[Train] Epoch: 2 [430144/620022]    Loss: 0.008658   Batch Acc: 78.12
[Train] Epoch: 2 [430208/620022]    Loss: 0.007743   Batch Acc: 76.56
[Train] Epoch: 2 [430272/620022]    Loss: 0.008831   Batch Acc: 78.12
[Train] Epoch: 2 [430336/620022]    Loss: 0.007752   Batch Acc: 76.56
[Train] Epoch: 2 [430400/620022]    Loss: 0.008157   Batch Acc: 81.25
[Train] Epoch: 2 [430464/620022]    Loss: 0.007592   Batch Acc: 84.38
[Train] Epoch: 2 [430528/620022]    Loss: 0.007376   Batch Acc: 84.38
[Train] Epoch: 2 [430592/620022]    Loss: 0.009150   Batch Acc: 78.12
[Train] Epoch: 2 [430656/620022]    Loss: 0.009764   Batch Acc: 70.31
[Train] Epoch: 2 [430720/620022]    Loss: 0.006293   Batch Acc: 82.81
[Train] Epoch: 2 [430784/620022]    Loss: 0.008748   Batch Acc: 76.56
[Train] Epoch: 2 [430848/620022]    Loss: 0.008437   Batch Acc: 78.12
[Train] Epoch: 2 [430912/620022]    Loss: 0.010314   Batch Acc: 75.00
[Train] Epoch: 2 [430976/620022]    Loss: 0.009090   Batch Acc: 76.56
[Train] Epoch: 2 [431040/620022]    Loss: 0.006773   Batch Acc: 81.25
[Train] Epoch: 2 [431104/620022]    Loss: 0.006751   Batch Acc: 79.69
[Train] Epoch: 2 [431168/620022]    Loss: 0.007321   Batch Acc: 82.81
[Train] Epoch: 2 [431232/620022]    Loss: 0.007834   Batch Acc: 82.81
[Train] Epoch: 2 [431296/620022]    Loss: 0.008943   Batch Acc: 71.88
[Train] Epoch: 2 [431360/620022]    Loss: 0.011550   Batch Acc: 71.88
[Train] Epoch: 2 [431424/620022]    Loss: 0.009531   Batch Acc: 70.31
[Train] Epoch: 2 [431488/620022]    Loss: 0.007897   Batch Acc: 82.81
[Train] Epoch: 2 [431552/620022]    Loss: 0.009872   Batch Acc: 75.00
[Train] Epoch: 2 [431616/620022]    Loss: 0.009239   Batch Acc: 81.25
[Train] Epoch: 2 [431680/620022]    Loss: 0.008597   Batch Acc: 78.12
[Train] Epoch: 2 [431744/620022]    Loss: 0.011239   Batch Acc: 73.44
[Train] Epoch: 2 [431808/620022]    Loss: 0.006595   Batch Acc: 84.38
[Train] Epoch: 2 [431872/620022]    Loss: 0.006610   Batch Acc: 87.50
[Train] Epoch: 2 [431936/620022]    Loss: 0.007930   Batch Acc: 81.25
[Train] Epoch: 2 [432000/620022]    Loss: 0.008701   Batch Acc: 76.56
[Train] Epoch: 2 [432064/620022]    Loss: 0.008535   Batch Acc: 79.69
[Train] Epoch: 2 [432128/620022]    Loss: 0.008267   Batch Acc: 76.56
[Train] Epoch: 2 [432192/620022]    Loss: 0.011317   Batch Acc: 71.88
[Train] Epoch: 2 [432256/620022]    Loss: 0.009289   Batch Acc: 71.88
[Train] Epoch: 2 [432320/620022]    Loss: 0.009834   Batch Acc: 73.44
[Train] Epoch: 2 [432384/620022]    Loss: 0.006921   Batch Acc: 84.38
[Train] Epoch: 2 [432448/620022]    Loss: 0.007984   Batch Acc: 78.12
[Train] Epoch: 2 [432512/620022]    Loss: 0.008924   Batch Acc: 78.12
[Train] Epoch: 2 [432576/620022]    Loss: 0.006682   Batch Acc: 84.38
[Train] Epoch: 2 [432640/620022]    Loss: 0.008679   Batch Acc: 78.12
[Train] Epoch: 2 [432704/620022]    Loss: 0.007890   Batch Acc: 78.12
[Train] Epoch: 2 [432768/620022]    Loss: 0.011171   Batch Acc: 70.31
[Train] Epoch: 2 [432832/620022]    Loss: 0.009489   Batch Acc: 78.12
[Train] Epoch: 2 [432896/620022]    Loss: 0.007849   Batch Acc: 82.81
[Train] Epoch: 2 [432960/620022]    Loss: 0.008670   Batch Acc: 81.25
[Train] Epoch: 2 [433024/620022]    Loss: 0.008818   Batch Acc: 82.81
[Train] Epoch: 2 [433088/620022]    Loss: 0.011428   Batch Acc: 73.44
[Train] Epoch: 2 [433152/620022]    Loss: 0.010091   Batch Acc: 73.44
[Train] Epoch: 2 [433216/620022]    Loss: 0.007492   Batch Acc: 81.25
[Train] Epoch: 2 [433280/620022]    Loss: 0.007853   Batch Acc: 76.56
[Train] Epoch: 2 [433344/620022]    Loss: 0.006782   Batch Acc: 85.94
[Train] Epoch: 2 [433408/620022]    Loss: 0.008872   Batch Acc: 76.56
[Train] Epoch: 2 [433472/620022]    Loss: 0.009713   Batch Acc: 81.25
[Train] Epoch: 2 [433536/620022]    Loss: 0.007607   Batch Acc: 79.69
[Train] Epoch: 2 [433600/620022]    Loss: 0.009127   Batch Acc: 70.31
[Train] Epoch: 2 [433664/620022]    Loss: 0.009325   Batch Acc: 71.88
[Train] Epoch: 2 [433728/620022]    Loss: 0.005795   Batch Acc: 87.50
[Train] Epoch: 2 [433792/620022]    Loss: 0.009293   Batch Acc: 70.31
[Train] Epoch: 2 [433856/620022]    Loss: 0.008330   Batch Acc: 82.81
[Train] Epoch: 2 [433920/620022]    Loss: 0.007614   Batch Acc: 84.38
[Train] Epoch: 2 [433984/620022]    Loss: 0.006779   Batch Acc: 85.94
[Train] Epoch: 2 [434048/620022]    Loss: 0.008811   Batch Acc: 73.44
[Train] Epoch: 2 [434112/620022]    Loss: 0.009095   Batch Acc: 79.69
[Train] Epoch: 2 [434176/620022]    Loss: 0.006766   Batch Acc: 76.56
[Train] Epoch: 2 [434240/620022]    Loss: 0.007795   Batch Acc: 78.12
[Train] Epoch: 2 [434304/620022]    Loss: 0.006710   Batch Acc: 81.25
[Train] Epoch: 2 [434368/620022]    Loss: 0.009145   Batch Acc: 75.00
[Train] Epoch: 2 [434432/620022]    Loss: 0.010460   Batch Acc: 67.19
[Train] Epoch: 2 [434496/620022]    Loss: 0.010896   Batch Acc: 71.88
[Train] Epoch: 2 [434560/620022]    Loss: 0.006764   Batch Acc: 79.69
[Train] Epoch: 2 [434624/620022]    Loss: 0.008732   Batch Acc: 76.56
[Train] Epoch: 2 [434688/620022]    Loss: 0.009284   Batch Acc: 76.56
[Train] Epoch: 2 [434752/620022]    Loss: 0.007726   Batch Acc: 81.25
[Train] Epoch: 2 [434816/620022]    Loss: 0.008407   Batch Acc: 75.00
[Train] Epoch: 2 [434880/620022]    Loss: 0.008999   Batch Acc: 82.81
[Train] Epoch: 2 [434944/620022]    Loss: 0.010769   Batch Acc: 76.56
[Train] Epoch: 2 [435008/620022]    Loss: 0.008610   Batch Acc: 81.25
[Train] Epoch: 2 [435072/620022]    Loss: 0.009828   Batch Acc: 76.56
[Train] Epoch: 2 [435136/620022]    Loss: 0.009749   Batch Acc: 75.00
[Train] Epoch: 2 [435200/620022]    Loss: 0.008806   Batch Acc: 78.12
[Train] Epoch: 2 [435264/620022]    Loss: 0.007247   Batch Acc: 85.94
[Train] Epoch: 2 [435328/620022]    Loss: 0.008547   Batch Acc: 82.81
[Train] Epoch: 2 [435392/620022]    Loss: 0.010669   Batch Acc: 73.44
[Train] Epoch: 2 [435456/620022]    Loss: 0.006787   Batch Acc: 81.25
[Train] Epoch: 2 [435520/620022]    Loss: 0.009739   Batch Acc: 76.56
[Train] Epoch: 2 [435584/620022]    Loss: 0.010591   Batch Acc: 68.75
[Train] Epoch: 2 [435648/620022]    Loss: 0.007389   Batch Acc: 76.56
[Train] Epoch: 2 [435712/620022]    Loss: 0.010102   Batch Acc: 76.56
[Train] Epoch: 2 [435776/620022]    Loss: 0.006987   Batch Acc: 85.94
[Train] Epoch: 2 [435840/620022]    Loss: 0.007348   Batch Acc: 85.94
[Train] Epoch: 2 [435904/620022]    Loss: 0.010569   Batch Acc: 76.56
[Train] Epoch: 2 [435968/620022]    Loss: 0.009210   Batch Acc: 76.56
[Train] Epoch: 2 [436032/620022]    Loss: 0.010964   Batch Acc: 71.88
[Train] Epoch: 2 [436096/620022]    Loss: 0.006679   Batch Acc: 89.06
[Train] Epoch: 2 [436160/620022]    Loss: 0.009917   Batch Acc: 73.44
[Train] Epoch: 2 [436224/620022]    Loss: 0.009701   Batch Acc: 75.00
[Train] Epoch: 2 [436288/620022]    Loss: 0.006559   Batch Acc: 85.94
[Train] Epoch: 2 [436352/620022]    Loss: 0.011173   Batch Acc: 67.19
[Train] Epoch: 2 [436416/620022]    Loss: 0.009765   Batch Acc: 73.44
[Train] Epoch: 2 [436480/620022]    Loss: 0.008905   Batch Acc: 76.56
[Train] Epoch: 2 [436544/620022]    Loss: 0.009641   Batch Acc: 75.00
[Train] Epoch: 2 [436608/620022]    Loss: 0.008106   Batch Acc: 71.88
[Train] Epoch: 2 [436672/620022]    Loss: 0.007735   Batch Acc: 79.69
[Train] Epoch: 2 [436736/620022]    Loss: 0.009359   Batch Acc: 81.25
[Train] Epoch: 2 [436800/620022]    Loss: 0.010135   Batch Acc: 67.19
[Train] Epoch: 2 [436864/620022]    Loss: 0.008881   Batch Acc: 75.00
[Train] Epoch: 2 [436928/620022]    Loss: 0.007565   Batch Acc: 79.69
[Train] Epoch: 2 [436992/620022]    Loss: 0.009572   Batch Acc: 68.75
[Train] Epoch: 2 [437056/620022]    Loss: 0.007954   Batch Acc: 73.44
[Train] Epoch: 2 [437120/620022]    Loss: 0.008212   Batch Acc: 75.00
[Train] Epoch: 2 [437184/620022]    Loss: 0.012212   Batch Acc: 64.06
[Train] Epoch: 2 [437248/620022]    Loss: 0.007701   Batch Acc: 79.69
[Train] Epoch: 2 [437312/620022]    Loss: 0.009022   Batch Acc: 73.44
[Train] Epoch: 2 [437376/620022]    Loss: 0.009131   Batch Acc: 76.56
[Train] Epoch: 2 [437440/620022]    Loss: 0.008857   Batch Acc: 76.56
[Train] Epoch: 2 [437504/620022]    Loss: 0.007935   Batch Acc: 76.56
[Train] Epoch: 2 [437568/620022]    Loss: 0.008991   Batch Acc: 76.56
[Train] Epoch: 2 [437632/620022]    Loss: 0.007259   Batch Acc: 78.12
[Train] Epoch: 2 [437696/620022]    Loss: 0.009177   Batch Acc: 75.00
[Train] Epoch: 2 [437760/620022]    Loss: 0.009234   Batch Acc: 71.88
[Train] Epoch: 2 [437824/620022]    Loss: 0.007113   Batch Acc: 84.38
[Train] Epoch: 2 [437888/620022]    Loss: 0.008822   Batch Acc: 82.81
[Train] Epoch: 2 [437952/620022]    Loss: 0.009394   Batch Acc: 79.69
[Train] Epoch: 2 [438016/620022]    Loss: 0.007214   Batch Acc: 84.38
[Train] Epoch: 2 [438080/620022]    Loss: 0.008385   Batch Acc: 84.38
[Train] Epoch: 2 [438144/620022]    Loss: 0.009571   Batch Acc: 71.88
[Train] Epoch: 2 [438208/620022]    Loss: 0.009523   Batch Acc: 75.00
[Train] Epoch: 2 [438272/620022]    Loss: 0.009038   Batch Acc: 76.56
[Train] Epoch: 2 [438336/620022]    Loss: 0.007825   Batch Acc: 81.25
[Train] Epoch: 2 [438400/620022]    Loss: 0.009282   Batch Acc: 78.12
[Train] Epoch: 2 [438464/620022]    Loss: 0.009445   Batch Acc: 70.31
[Train] Epoch: 2 [438528/620022]    Loss: 0.008496   Batch Acc: 76.56
[Train] Epoch: 2 [438592/620022]    Loss: 0.007590   Batch Acc: 84.38
[Train] Epoch: 2 [438656/620022]    Loss: 0.009100   Batch Acc: 76.56
[Train] Epoch: 2 [438720/620022]    Loss: 0.009409   Batch Acc: 76.56
[Train] Epoch: 2 [438784/620022]    Loss: 0.010586   Batch Acc: 73.44
[Train] Epoch: 2 [438848/620022]    Loss: 0.009564   Batch Acc: 70.31
[Train] Epoch: 2 [438912/620022]    Loss: 0.006835   Batch Acc: 82.81
[Train] Epoch: 2 [438976/620022]    Loss: 0.008626   Batch Acc: 76.56
[Train] Epoch: 2 [439040/620022]    Loss: 0.008670   Batch Acc: 75.00
[Train] Epoch: 2 [439104/620022]    Loss: 0.007847   Batch Acc: 84.38
[Train] Epoch: 2 [439168/620022]    Loss: 0.006491   Batch Acc: 85.94
[Train] Epoch: 2 [439232/620022]    Loss: 0.009085   Batch Acc: 79.69
[Train] Epoch: 2 [439296/620022]    Loss: 0.007796   Batch Acc: 85.94
[Train] Epoch: 2 [439360/620022]    Loss: 0.005175   Batch Acc: 92.19
[Train] Epoch: 2 [439424/620022]    Loss: 0.009652   Batch Acc: 73.44
[Train] Epoch: 2 [439488/620022]    Loss: 0.007530   Batch Acc: 82.81
[Train] Epoch: 2 [439552/620022]    Loss: 0.008099   Batch Acc: 76.56
[Train] Epoch: 2 [439616/620022]    Loss: 0.008614   Batch Acc: 79.69
[Train] Epoch: 2 [439680/620022]    Loss: 0.007482   Batch Acc: 81.25
[Train] Epoch: 2 [439744/620022]    Loss: 0.009160   Batch Acc: 81.25
[Train] Epoch: 2 [439808/620022]    Loss: 0.007445   Batch Acc: 82.81
[Train] Epoch: 2 [439872/620022]    Loss: 0.009280   Batch Acc: 71.88
[Train] Epoch: 2 [439936/620022]    Loss: 0.007267   Batch Acc: 79.69
[Train] Epoch: 2 [440000/620022]    Loss: 0.008673   Batch Acc: 79.69
[Train] Epoch: 2 [440064/620022]    Loss: 0.009570   Batch Acc: 76.56
[Train] Epoch: 2 [440128/620022]    Loss: 0.006298   Batch Acc: 84.38
[Train] Epoch: 2 [440192/620022]    Loss: 0.009836   Batch Acc: 78.12
[Train] Epoch: 2 [440256/620022]    Loss: 0.008374   Batch Acc: 81.25
[Train] Epoch: 2 [440320/620022]    Loss: 0.007238   Batch Acc: 85.94
[Train] Epoch: 2 [440384/620022]    Loss: 0.008637   Batch Acc: 76.56
[Train] Epoch: 2 [440448/620022]    Loss: 0.007587   Batch Acc: 78.12
[Train] Epoch: 2 [440512/620022]    Loss: 0.009511   Batch Acc: 76.56
[Train] Epoch: 2 [440576/620022]    Loss: 0.007854   Batch Acc: 81.25
[Train] Epoch: 2 [440640/620022]    Loss: 0.009975   Batch Acc: 78.12
[Train] Epoch: 2 [440704/620022]    Loss: 0.010799   Batch Acc: 71.88
[Train] Epoch: 2 [440768/620022]    Loss: 0.009424   Batch Acc: 75.00
[Train] Epoch: 2 [440832/620022]    Loss: 0.006944   Batch Acc: 84.38
[Train] Epoch: 2 [440896/620022]    Loss: 0.011304   Batch Acc: 64.06
[Train] Epoch: 2 [440960/620022]    Loss: 0.008012   Batch Acc: 76.56
[Train] Epoch: 2 [441024/620022]    Loss: 0.007219   Batch Acc: 81.25
[Train] Epoch: 2 [441088/620022]    Loss: 0.009606   Batch Acc: 71.88
[Train] Epoch: 2 [441152/620022]    Loss: 0.007504   Batch Acc: 81.25
[Train] Epoch: 2 [441216/620022]    Loss: 0.010301   Batch Acc: 78.12
[Train] Epoch: 2 [441280/620022]    Loss: 0.008281   Batch Acc: 76.56
[Train] Epoch: 2 [441344/620022]    Loss: 0.008342   Batch Acc: 82.81
[Train] Epoch: 2 [441408/620022]    Loss: 0.009935   Batch Acc: 73.44
[Train] Epoch: 2 [441472/620022]    Loss: 0.007705   Batch Acc: 82.81
[Train] Epoch: 2 [441536/620022]    Loss: 0.007672   Batch Acc: 85.94
[Train] Epoch: 2 [441600/620022]    Loss: 0.006023   Batch Acc: 85.94
[Train] Epoch: 2 [441664/620022]    Loss: 0.009668   Batch Acc: 78.12
[Train] Epoch: 2 [441728/620022]    Loss: 0.009158   Batch Acc: 75.00
[Train] Epoch: 2 [441792/620022]    Loss: 0.008691   Batch Acc: 75.00
[Train] Epoch: 2 [441856/620022]    Loss: 0.008150   Batch Acc: 73.44
[Train] Epoch: 2 [441920/620022]    Loss: 0.008952   Batch Acc: 76.56
[Train] Epoch: 2 [441984/620022]    Loss: 0.009883   Batch Acc: 73.44
[Train] Epoch: 2 [442048/620022]    Loss: 0.008809   Batch Acc: 70.31
[Train] Epoch: 2 [442112/620022]    Loss: 0.006984   Batch Acc: 87.50
[Train] Epoch: 2 [442176/620022]    Loss: 0.008870   Batch Acc: 81.25
[Train] Epoch: 2 [442240/620022]    Loss: 0.008667   Batch Acc: 78.12
[Train] Epoch: 2 [442304/620022]    Loss: 0.008664   Batch Acc: 79.69
[Train] Epoch: 2 [442368/620022]    Loss: 0.007881   Batch Acc: 79.69
[Train] Epoch: 2 [442432/620022]    Loss: 0.007453   Batch Acc: 78.12
[Train] Epoch: 2 [442496/620022]    Loss: 0.009520   Batch Acc: 78.12
[Train] Epoch: 2 [442560/620022]    Loss: 0.008490   Batch Acc: 81.25
[Train] Epoch: 2 [442624/620022]    Loss: 0.008267   Batch Acc: 75.00
[Train] Epoch: 2 [442688/620022]    Loss: 0.010515   Batch Acc: 75.00
[Train] Epoch: 2 [442752/620022]    Loss: 0.009740   Batch Acc: 76.56
[Train] Epoch: 2 [442816/620022]    Loss: 0.007873   Batch Acc: 78.12
[Train] Epoch: 2 [442880/620022]    Loss: 0.007638   Batch Acc: 81.25
[Train] Epoch: 2 [442944/620022]    Loss: 0.008846   Batch Acc: 76.56
[Train] Epoch: 2 [443008/620022]    Loss: 0.011641   Batch Acc: 71.88
[Train] Epoch: 2 [443072/620022]    Loss: 0.007747   Batch Acc: 82.81
[Train] Epoch: 2 [443136/620022]    Loss: 0.009734   Batch Acc: 76.56
[Train] Epoch: 2 [443200/620022]    Loss: 0.009166   Batch Acc: 79.69
[Train] Epoch: 2 [443264/620022]    Loss: 0.009490   Batch Acc: 79.69
[Train] Epoch: 2 [443328/620022]    Loss: 0.009015   Batch Acc: 79.69
[Train] Epoch: 2 [443392/620022]    Loss: 0.006898   Batch Acc: 81.25
[Train] Epoch: 2 [443456/620022]    Loss: 0.009001   Batch Acc: 79.69
[Train] Epoch: 2 [443520/620022]    Loss: 0.008616   Batch Acc: 75.00
[Train] Epoch: 2 [443584/620022]    Loss: 0.011251   Batch Acc: 68.75
[Train] Epoch: 2 [443648/620022]    Loss: 0.006688   Batch Acc: 84.38
[Train] Epoch: 2 [443712/620022]    Loss: 0.010142   Batch Acc: 78.12
[Train] Epoch: 2 [443776/620022]    Loss: 0.007972   Batch Acc: 75.00
[Train] Epoch: 2 [443840/620022]    Loss: 0.008759   Batch Acc: 79.69
[Train] Epoch: 2 [443904/620022]    Loss: 0.009884   Batch Acc: 76.56
[Train] Epoch: 2 [443968/620022]    Loss: 0.008980   Batch Acc: 81.25
[Train] Epoch: 2 [444032/620022]    Loss: 0.009038   Batch Acc: 75.00
[Train] Epoch: 2 [444096/620022]    Loss: 0.010137   Batch Acc: 76.56
[Train] Epoch: 2 [444160/620022]    Loss: 0.010106   Batch Acc: 71.88
[Train] Epoch: 2 [444224/620022]    Loss: 0.007029   Batch Acc: 82.81
[Train] Epoch: 2 [444288/620022]    Loss: 0.007774   Batch Acc: 81.25
[Train] Epoch: 2 [444352/620022]    Loss: 0.008397   Batch Acc: 81.25
[Train] Epoch: 2 [444416/620022]    Loss: 0.009808   Batch Acc: 70.31
[Train] Epoch: 2 [444480/620022]    Loss: 0.006422   Batch Acc: 84.38
[Train] Epoch: 2 [444544/620022]    Loss: 0.007857   Batch Acc: 84.38
[Train] Epoch: 2 [444608/620022]    Loss: 0.011321   Batch Acc: 75.00
[Train] Epoch: 2 [444672/620022]    Loss: 0.006845   Batch Acc: 85.94
[Train] Epoch: 2 [444736/620022]    Loss: 0.008115   Batch Acc: 75.00
[Train] Epoch: 2 [444800/620022]    Loss: 0.010261   Batch Acc: 67.19
[Train] Epoch: 2 [444864/620022]    Loss: 0.007633   Batch Acc: 84.38
[Train] Epoch: 2 [444928/620022]    Loss: 0.007618   Batch Acc: 79.69
[Train] Epoch: 2 [444992/620022]    Loss: 0.011505   Batch Acc: 70.31
[Train] Epoch: 2 [445056/620022]    Loss: 0.006605   Batch Acc: 85.94
[Train] Epoch: 2 [445120/620022]    Loss: 0.010508   Batch Acc: 78.12
[Train] Epoch: 2 [445184/620022]    Loss: 0.007079   Batch Acc: 81.25
[Train] Epoch: 2 [445248/620022]    Loss: 0.010400   Batch Acc: 70.31
[Train] Epoch: 2 [445312/620022]    Loss: 0.008351   Batch Acc: 71.88
[Train] Epoch: 2 [445376/620022]    Loss: 0.010703   Batch Acc: 76.56
[Train] Epoch: 2 [445440/620022]    Loss: 0.008823   Batch Acc: 78.12
[Train] Epoch: 2 [445504/620022]    Loss: 0.011975   Batch Acc: 65.62
[Train] Epoch: 2 [445568/620022]    Loss: 0.008854   Batch Acc: 79.69
[Train] Epoch: 2 [445632/620022]    Loss: 0.007519   Batch Acc: 81.25
[Train] Epoch: 2 [445696/620022]    Loss: 0.005623   Batch Acc: 85.94
[Train] Epoch: 2 [445760/620022]    Loss: 0.011470   Batch Acc: 68.75
[Train] Epoch: 2 [445824/620022]    Loss: 0.009636   Batch Acc: 71.88
[Train] Epoch: 2 [445888/620022]    Loss: 0.010708   Batch Acc: 60.94
[Train] Epoch: 2 [445952/620022]    Loss: 0.009761   Batch Acc: 78.12
[Train] Epoch: 2 [446016/620022]    Loss: 0.011018   Batch Acc: 70.31
[Train] Epoch: 2 [446080/620022]    Loss: 0.008561   Batch Acc: 81.25
[Train] Epoch: 2 [446144/620022]    Loss: 0.008965   Batch Acc: 76.56
[Train] Epoch: 2 [446208/620022]    Loss: 0.006088   Batch Acc: 84.38
[Train] Epoch: 2 [446272/620022]    Loss: 0.009513   Batch Acc: 73.44
[Train] Epoch: 2 [446336/620022]    Loss: 0.009322   Batch Acc: 73.44
[Train] Epoch: 2 [446400/620022]    Loss: 0.010147   Batch Acc: 75.00
[Train] Epoch: 2 [446464/620022]    Loss: 0.009030   Batch Acc: 76.56
[Train] Epoch: 2 [446528/620022]    Loss: 0.009866   Batch Acc: 71.88
[Train] Epoch: 2 [446592/620022]    Loss: 0.008983   Batch Acc: 76.56
[Train] Epoch: 2 [446656/620022]    Loss: 0.010506   Batch Acc: 71.88
[Train] Epoch: 2 [446720/620022]    Loss: 0.010154   Batch Acc: 73.44
[Train] Epoch: 2 [446784/620022]    Loss: 0.006440   Batch Acc: 82.81
[Train] Epoch: 2 [446848/620022]    Loss: 0.010013   Batch Acc: 73.44
[Train] Epoch: 2 [446912/620022]    Loss: 0.009583   Batch Acc: 78.12
[Train] Epoch: 2 [446976/620022]    Loss: 0.009994   Batch Acc: 79.69
[Train] Epoch: 2 [447040/620022]    Loss: 0.008407   Batch Acc: 76.56
[Train] Epoch: 2 [447104/620022]    Loss: 0.008284   Batch Acc: 78.12
[Train] Epoch: 2 [447168/620022]    Loss: 0.007650   Batch Acc: 82.81
[Train] Epoch: 2 [447232/620022]    Loss: 0.008284   Batch Acc: 78.12
[Train] Epoch: 2 [447296/620022]    Loss: 0.007987   Batch Acc: 79.69
[Train] Epoch: 2 [447360/620022]    Loss: 0.008567   Batch Acc: 76.56
[Train] Epoch: 2 [447424/620022]    Loss: 0.010373   Batch Acc: 67.19
[Train] Epoch: 2 [447488/620022]    Loss: 0.007160   Batch Acc: 82.81
[Train] Epoch: 2 [447552/620022]    Loss: 0.009142   Batch Acc: 73.44
[Train] Epoch: 2 [447616/620022]    Loss: 0.008705   Batch Acc: 79.69
[Train] Epoch: 2 [447680/620022]    Loss: 0.008010   Batch Acc: 79.69
[Train] Epoch: 2 [447744/620022]    Loss: 0.008629   Batch Acc: 81.25
[Train] Epoch: 2 [447808/620022]    Loss: 0.007292   Batch Acc: 82.81
[Train] Epoch: 2 [447872/620022]    Loss: 0.010983   Batch Acc: 67.19
[Train] Epoch: 2 [447936/620022]    Loss: 0.010285   Batch Acc: 71.88
[Train] Epoch: 2 [448000/620022]    Loss: 0.009619   Batch Acc: 71.88
[Train] Epoch: 2 [448064/620022]    Loss: 0.009782   Batch Acc: 73.44
[Train] Epoch: 2 [448128/620022]    Loss: 0.009045   Batch Acc: 78.12
[Train] Epoch: 2 [448192/620022]    Loss: 0.010352   Batch Acc: 75.00
[Train] Epoch: 2 [448256/620022]    Loss: 0.009164   Batch Acc: 78.12
[Train] Epoch: 2 [448320/620022]    Loss: 0.010041   Batch Acc: 78.12
[Train] Epoch: 2 [448384/620022]    Loss: 0.008233   Batch Acc: 75.00
[Train] Epoch: 2 [448448/620022]    Loss: 0.010138   Batch Acc: 67.19
[Train] Epoch: 2 [448512/620022]    Loss: 0.006559   Batch Acc: 84.38
[Train] Epoch: 2 [448576/620022]    Loss: 0.008428   Batch Acc: 79.69
[Train] Epoch: 2 [448640/620022]    Loss: 0.009436   Batch Acc: 70.31
[Train] Epoch: 2 [448704/620022]    Loss: 0.008107   Batch Acc: 78.12
[Train] Epoch: 2 [448768/620022]    Loss: 0.007531   Batch Acc: 82.81
[Train] Epoch: 2 [448832/620022]    Loss: 0.009281   Batch Acc: 78.12
[Train] Epoch: 2 [448896/620022]    Loss: 0.008094   Batch Acc: 75.00
[Train] Epoch: 2 [448960/620022]    Loss: 0.008504   Batch Acc: 79.69
[Train] Epoch: 2 [449024/620022]    Loss: 0.007533   Batch Acc: 81.25
[Train] Epoch: 2 [449088/620022]    Loss: 0.005943   Batch Acc: 87.50
[Train] Epoch: 2 [449152/620022]    Loss: 0.010135   Batch Acc: 71.88
[Train] Epoch: 2 [449216/620022]    Loss: 0.008939   Batch Acc: 70.31
[Train] Epoch: 2 [449280/620022]    Loss: 0.009039   Batch Acc: 76.56
[Train] Epoch: 2 [449344/620022]    Loss: 0.007943   Batch Acc: 78.12
[Train] Epoch: 2 [449408/620022]    Loss: 0.009850   Batch Acc: 76.56
[Train] Epoch: 2 [449472/620022]    Loss: 0.007789   Batch Acc: 79.69
[Train] Epoch: 2 [449536/620022]    Loss: 0.009927   Batch Acc: 79.69
[Train] Epoch: 2 [449600/620022]    Loss: 0.009006   Batch Acc: 81.25
[Train] Epoch: 2 [449664/620022]    Loss: 0.010173   Batch Acc: 76.56
[Train] Epoch: 2 [449728/620022]    Loss: 0.011730   Batch Acc: 75.00
[Train] Epoch: 2 [449792/620022]    Loss: 0.009580   Batch Acc: 78.12
[Train] Epoch: 2 [449856/620022]    Loss: 0.010238   Batch Acc: 73.44
[Train] Epoch: 2 [449920/620022]    Loss: 0.007940   Batch Acc: 82.81
[Train] Epoch: 2 [449984/620022]    Loss: 0.008936   Batch Acc: 79.69
[Train] Epoch: 2 [450048/620022]    Loss: 0.006967   Batch Acc: 82.81
[Train] Epoch: 2 [450112/620022]    Loss: 0.007994   Batch Acc: 84.38
[Train] Epoch: 2 [450176/620022]    Loss: 0.007835   Batch Acc: 81.25
[Train] Epoch: 2 [450240/620022]    Loss: 0.008293   Batch Acc: 79.69
[Train] Epoch: 2 [450304/620022]    Loss: 0.008687   Batch Acc: 79.69
[Train] Epoch: 2 [450368/620022]    Loss: 0.007669   Batch Acc: 81.25
[Train] Epoch: 2 [450432/620022]    Loss: 0.009929   Batch Acc: 75.00
[Train] Epoch: 2 [450496/620022]    Loss: 0.007594   Batch Acc: 79.69
[Train] Epoch: 2 [450560/620022]    Loss: 0.008629   Batch Acc: 81.25
[Train] Epoch: 2 [450624/620022]    Loss: 0.007850   Batch Acc: 81.25
[Train] Epoch: 2 [450688/620022]    Loss: 0.009047   Batch Acc: 70.31
[Train] Epoch: 2 [450752/620022]    Loss: 0.005906   Batch Acc: 90.62
[Train] Epoch: 2 [450816/620022]    Loss: 0.009052   Batch Acc: 75.00
[Train] Epoch: 2 [450880/620022]    Loss: 0.006665   Batch Acc: 82.81
[Train] Epoch: 2 [450944/620022]    Loss: 0.009866   Batch Acc: 76.56
[Train] Epoch: 2 [451008/620022]    Loss: 0.009443   Batch Acc: 79.69
[Train] Epoch: 2 [451072/620022]    Loss: 0.008542   Batch Acc: 78.12
[Train] Epoch: 2 [451136/620022]    Loss: 0.008541   Batch Acc: 84.38
[Train] Epoch: 2 [451200/620022]    Loss: 0.008456   Batch Acc: 70.31
[Train] Epoch: 2 [451264/620022]    Loss: 0.008364   Batch Acc: 76.56
[Train] Epoch: 2 [451328/620022]    Loss: 0.007432   Batch Acc: 79.69
[Train] Epoch: 2 [451392/620022]    Loss: 0.007579   Batch Acc: 82.81
[Train] Epoch: 2 [451456/620022]    Loss: 0.007457   Batch Acc: 85.94
[Train] Epoch: 2 [451520/620022]    Loss: 0.009321   Batch Acc: 79.69
[Train] Epoch: 2 [451584/620022]    Loss: 0.007257   Batch Acc: 84.38
[Train] Epoch: 2 [451648/620022]    Loss: 0.008959   Batch Acc: 73.44
[Train] Epoch: 2 [451712/620022]    Loss: 0.007417   Batch Acc: 84.38
[Train] Epoch: 2 [451776/620022]    Loss: 0.006056   Batch Acc: 87.50
[Train] Epoch: 2 [451840/620022]    Loss: 0.012092   Batch Acc: 60.94
[Train] Epoch: 2 [451904/620022]    Loss: 0.007980   Batch Acc: 78.12
[Train] Epoch: 2 [451968/620022]    Loss: 0.007152   Batch Acc: 78.12
[Train] Epoch: 2 [452032/620022]    Loss: 0.007802   Batch Acc: 79.69
[Train] Epoch: 2 [452096/620022]    Loss: 0.007872   Batch Acc: 81.25
[Train] Epoch: 2 [452160/620022]    Loss: 0.008411   Batch Acc: 75.00
[Train] Epoch: 2 [452224/620022]    Loss: 0.008222   Batch Acc: 76.56
[Train] Epoch: 2 [452288/620022]    Loss: 0.008264   Batch Acc: 75.00
[Train] Epoch: 2 [452352/620022]    Loss: 0.008733   Batch Acc: 76.56
[Train] Epoch: 2 [452416/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 2 [452480/620022]    Loss: 0.007825   Batch Acc: 78.12
[Train] Epoch: 2 [452544/620022]    Loss: 0.010744   Batch Acc: 71.88
[Train] Epoch: 2 [452608/620022]    Loss: 0.007067   Batch Acc: 82.81
[Train] Epoch: 2 [452672/620022]    Loss: 0.005855   Batch Acc: 89.06
[Train] Epoch: 2 [452736/620022]    Loss: 0.009622   Batch Acc: 73.44
[Train] Epoch: 2 [452800/620022]    Loss: 0.008847   Batch Acc: 76.56
[Train] Epoch: 2 [452864/620022]    Loss: 0.008700   Batch Acc: 81.25
[Train] Epoch: 2 [452928/620022]    Loss: 0.008213   Batch Acc: 79.69
[Train] Epoch: 2 [452992/620022]    Loss: 0.007112   Batch Acc: 81.25
[Train] Epoch: 2 [453056/620022]    Loss: 0.008783   Batch Acc: 73.44
[Train] Epoch: 2 [453120/620022]    Loss: 0.010974   Batch Acc: 70.31
[Train] Epoch: 2 [453184/620022]    Loss: 0.008726   Batch Acc: 81.25
[Train] Epoch: 2 [453248/620022]    Loss: 0.008083   Batch Acc: 85.94
[Train] Epoch: 2 [453312/620022]    Loss: 0.006438   Batch Acc: 84.38
[Train] Epoch: 2 [453376/620022]    Loss: 0.009019   Batch Acc: 76.56
[Train] Epoch: 2 [453440/620022]    Loss: 0.009721   Batch Acc: 70.31
[Train] Epoch: 2 [453504/620022]    Loss: 0.008370   Batch Acc: 81.25
[Train] Epoch: 2 [453568/620022]    Loss: 0.008652   Batch Acc: 81.25
[Train] Epoch: 2 [453632/620022]    Loss: 0.007893   Batch Acc: 79.69
[Train] Epoch: 2 [453696/620022]    Loss: 0.008076   Batch Acc: 79.69
[Train] Epoch: 2 [453760/620022]    Loss: 0.007487   Batch Acc: 84.38
[Train] Epoch: 2 [453824/620022]    Loss: 0.008430   Batch Acc: 79.69
[Train] Epoch: 2 [453888/620022]    Loss: 0.006837   Batch Acc: 85.94
[Train] Epoch: 2 [453952/620022]    Loss: 0.008557   Batch Acc: 81.25
[Train] Epoch: 2 [454016/620022]    Loss: 0.007123   Batch Acc: 78.12
[Train] Epoch: 2 [454080/620022]    Loss: 0.007869   Batch Acc: 81.25
[Train] Epoch: 2 [454144/620022]    Loss: 0.009547   Batch Acc: 76.56
[Train] Epoch: 2 [454208/620022]    Loss: 0.010207   Batch Acc: 70.31
[Train] Epoch: 2 [454272/620022]    Loss: 0.011738   Batch Acc: 65.62
[Train] Epoch: 2 [454336/620022]    Loss: 0.008507   Batch Acc: 78.12
[Train] Epoch: 2 [454400/620022]    Loss: 0.010889   Batch Acc: 62.50
[Train] Epoch: 2 [454464/620022]    Loss: 0.009470   Batch Acc: 76.56
[Train] Epoch: 2 [454528/620022]    Loss: 0.008375   Batch Acc: 76.56
[Train] Epoch: 2 [454592/620022]    Loss: 0.006831   Batch Acc: 81.25
[Train] Epoch: 2 [454656/620022]    Loss: 0.008506   Batch Acc: 73.44
[Train] Epoch: 2 [454720/620022]    Loss: 0.007146   Batch Acc: 81.25
[Train] Epoch: 2 [454784/620022]    Loss: 0.007103   Batch Acc: 85.94
[Train] Epoch: 2 [454848/620022]    Loss: 0.008002   Batch Acc: 84.38
[Train] Epoch: 2 [454912/620022]    Loss: 0.007370   Batch Acc: 78.12
[Train] Epoch: 2 [454976/620022]    Loss: 0.008261   Batch Acc: 82.81
[Train] Epoch: 2 [455040/620022]    Loss: 0.007911   Batch Acc: 75.00
[Train] Epoch: 2 [455104/620022]    Loss: 0.008176   Batch Acc: 79.69
[Train] Epoch: 2 [455168/620022]    Loss: 0.008331   Batch Acc: 79.69
[Train] Epoch: 2 [455232/620022]    Loss: 0.007681   Batch Acc: 76.56
[Train] Epoch: 2 [455296/620022]    Loss: 0.009105   Batch Acc: 76.56
[Train] Epoch: 2 [455360/620022]    Loss: 0.010785   Batch Acc: 70.31
[Train] Epoch: 2 [455424/620022]    Loss: 0.009287   Batch Acc: 78.12
[Train] Epoch: 2 [455488/620022]    Loss: 0.008727   Batch Acc: 78.12
[Train] Epoch: 2 [455552/620022]    Loss: 0.009348   Batch Acc: 75.00
[Train] Epoch: 2 [455616/620022]    Loss: 0.010050   Batch Acc: 79.69
[Train] Epoch: 2 [455680/620022]    Loss: 0.009087   Batch Acc: 76.56
[Train] Epoch: 2 [455744/620022]    Loss: 0.008237   Batch Acc: 82.81
[Train] Epoch: 2 [455808/620022]    Loss: 0.007749   Batch Acc: 79.69
[Train] Epoch: 2 [455872/620022]    Loss: 0.007185   Batch Acc: 85.94
[Train] Epoch: 2 [455936/620022]    Loss: 0.009992   Batch Acc: 73.44
[Train] Epoch: 2 [456000/620022]    Loss: 0.008391   Batch Acc: 79.69
[Train] Epoch: 2 [456064/620022]    Loss: 0.007445   Batch Acc: 81.25
[Train] Epoch: 2 [456128/620022]    Loss: 0.006936   Batch Acc: 82.81
[Train] Epoch: 2 [456192/620022]    Loss: 0.006675   Batch Acc: 87.50
[Train] Epoch: 2 [456256/620022]    Loss: 0.009831   Batch Acc: 70.31
[Train] Epoch: 2 [456320/620022]    Loss: 0.008362   Batch Acc: 78.12
[Train] Epoch: 2 [456384/620022]    Loss: 0.008593   Batch Acc: 81.25
[Train] Epoch: 2 [456448/620022]    Loss: 0.009180   Batch Acc: 71.88
[Train] Epoch: 2 [456512/620022]    Loss: 0.008527   Batch Acc: 79.69
[Train] Epoch: 2 [456576/620022]    Loss: 0.007154   Batch Acc: 82.81
[Train] Epoch: 2 [456640/620022]    Loss: 0.012096   Batch Acc: 71.88
[Train] Epoch: 2 [456704/620022]    Loss: 0.006997   Batch Acc: 82.81
[Train] Epoch: 2 [456768/620022]    Loss: 0.007923   Batch Acc: 81.25
[Train] Epoch: 2 [456832/620022]    Loss: 0.009465   Batch Acc: 78.12
[Train] Epoch: 2 [456896/620022]    Loss: 0.012307   Batch Acc: 65.62
[Train] Epoch: 2 [456960/620022]    Loss: 0.007387   Batch Acc: 81.25
[Train] Epoch: 2 [457024/620022]    Loss: 0.009681   Batch Acc: 73.44
[Train] Epoch: 2 [457088/620022]    Loss: 0.011086   Batch Acc: 73.44
[Train] Epoch: 2 [457152/620022]    Loss: 0.010333   Batch Acc: 71.88
[Train] Epoch: 2 [457216/620022]    Loss: 0.008873   Batch Acc: 73.44
[Train] Epoch: 2 [457280/620022]    Loss: 0.008594   Batch Acc: 79.69
[Train] Epoch: 2 [457344/620022]    Loss: 0.008211   Batch Acc: 81.25
[Train] Epoch: 2 [457408/620022]    Loss: 0.012379   Batch Acc: 64.06
[Train] Epoch: 2 [457472/620022]    Loss: 0.006144   Batch Acc: 82.81
[Train] Epoch: 2 [457536/620022]    Loss: 0.006759   Batch Acc: 87.50
[Train] Epoch: 2 [457600/620022]    Loss: 0.008212   Batch Acc: 76.56
[Train] Epoch: 2 [457664/620022]    Loss: 0.008570   Batch Acc: 81.25
[Train] Epoch: 2 [457728/620022]    Loss: 0.006624   Batch Acc: 85.94
[Train] Epoch: 2 [457792/620022]    Loss: 0.009001   Batch Acc: 79.69
[Train] Epoch: 2 [457856/620022]    Loss: 0.007917   Batch Acc: 78.12
[Train] Epoch: 2 [457920/620022]    Loss: 0.008853   Batch Acc: 76.56
[Train] Epoch: 2 [457984/620022]    Loss: 0.007605   Batch Acc: 81.25
[Train] Epoch: 2 [458048/620022]    Loss: 0.007112   Batch Acc: 84.38
[Train] Epoch: 2 [458112/620022]    Loss: 0.009917   Batch Acc: 75.00
[Train] Epoch: 2 [458176/620022]    Loss: 0.010757   Batch Acc: 68.75
[Train] Epoch: 2 [458240/620022]    Loss: 0.009157   Batch Acc: 76.56
[Train] Epoch: 2 [458304/620022]    Loss: 0.008276   Batch Acc: 79.69
[Train] Epoch: 2 [458368/620022]    Loss: 0.008710   Batch Acc: 79.69
[Train] Epoch: 2 [458432/620022]    Loss: 0.008705   Batch Acc: 79.69
[Train] Epoch: 2 [458496/620022]    Loss: 0.011040   Batch Acc: 65.62
[Train] Epoch: 2 [458560/620022]    Loss: 0.007561   Batch Acc: 84.38
[Train] Epoch: 2 [458624/620022]    Loss: 0.009282   Batch Acc: 71.88
[Train] Epoch: 2 [458688/620022]    Loss: 0.010537   Batch Acc: 73.44
[Train] Epoch: 2 [458752/620022]    Loss: 0.007938   Batch Acc: 81.25
[Train] Epoch: 2 [458816/620022]    Loss: 0.008491   Batch Acc: 84.38
[Train] Epoch: 2 [458880/620022]    Loss: 0.010721   Batch Acc: 71.88
[Train] Epoch: 2 [458944/620022]    Loss: 0.006955   Batch Acc: 79.69
[Train] Epoch: 2 [459008/620022]    Loss: 0.008180   Batch Acc: 76.56
[Train] Epoch: 2 [459072/620022]    Loss: 0.010218   Batch Acc: 71.88
[Train] Epoch: 2 [459136/620022]    Loss: 0.008046   Batch Acc: 75.00
[Train] Epoch: 2 [459200/620022]    Loss: 0.006908   Batch Acc: 84.38
[Train] Epoch: 2 [459264/620022]    Loss: 0.009228   Batch Acc: 73.44
[Train] Epoch: 2 [459328/620022]    Loss: 0.007076   Batch Acc: 84.38
[Train] Epoch: 2 [459392/620022]    Loss: 0.010845   Batch Acc: 67.19
[Train] Epoch: 2 [459456/620022]    Loss: 0.008992   Batch Acc: 79.69
[Train] Epoch: 2 [459520/620022]    Loss: 0.008975   Batch Acc: 82.81
[Train] Epoch: 2 [459584/620022]    Loss: 0.010274   Batch Acc: 70.31
[Train] Epoch: 2 [459648/620022]    Loss: 0.008774   Batch Acc: 78.12
[Train] Epoch: 2 [459712/620022]    Loss: 0.006970   Batch Acc: 89.06
[Train] Epoch: 2 [459776/620022]    Loss: 0.007085   Batch Acc: 78.12
[Train] Epoch: 2 [459840/620022]    Loss: 0.009438   Batch Acc: 71.88
[Train] Epoch: 2 [459904/620022]    Loss: 0.008901   Batch Acc: 82.81
[Train] Epoch: 2 [459968/620022]    Loss: 0.008300   Batch Acc: 78.12
[Train] Epoch: 2 [460032/620022]    Loss: 0.010935   Batch Acc: 71.88
[Train] Epoch: 2 [460096/620022]    Loss: 0.009921   Batch Acc: 75.00
[Train] Epoch: 2 [460160/620022]    Loss: 0.009619   Batch Acc: 73.44
[Train] Epoch: 2 [460224/620022]    Loss: 0.009258   Batch Acc: 75.00
[Train] Epoch: 2 [460288/620022]    Loss: 0.013181   Batch Acc: 64.06
[Train] Epoch: 2 [460352/620022]    Loss: 0.007342   Batch Acc: 79.69
[Train] Epoch: 2 [460416/620022]    Loss: 0.009835   Batch Acc: 79.69
[Train] Epoch: 2 [460480/620022]    Loss: 0.008189   Batch Acc: 82.81
[Train] Epoch: 2 [460544/620022]    Loss: 0.008333   Batch Acc: 79.69
[Train] Epoch: 2 [460608/620022]    Loss: 0.008151   Batch Acc: 78.12
[Train] Epoch: 2 [460672/620022]    Loss: 0.009076   Batch Acc: 75.00
[Train] Epoch: 2 [460736/620022]    Loss: 0.008152   Batch Acc: 75.00
[Train] Epoch: 2 [460800/620022]    Loss: 0.007073   Batch Acc: 87.50
[Train] Epoch: 2 [460864/620022]    Loss: 0.008217   Batch Acc: 75.00
[Train] Epoch: 2 [460928/620022]    Loss: 0.008295   Batch Acc: 81.25
[Train] Epoch: 2 [460992/620022]    Loss: 0.007835   Batch Acc: 79.69
[Train] Epoch: 2 [461056/620022]    Loss: 0.010555   Batch Acc: 73.44
[Train] Epoch: 2 [461120/620022]    Loss: 0.010555   Batch Acc: 71.88
[Train] Epoch: 2 [461184/620022]    Loss: 0.007479   Batch Acc: 82.81
[Train] Epoch: 2 [461248/620022]    Loss: 0.010667   Batch Acc: 70.31
[Train] Epoch: 2 [461312/620022]    Loss: 0.006941   Batch Acc: 85.94
[Train] Epoch: 2 [461376/620022]    Loss: 0.008206   Batch Acc: 79.69
[Train] Epoch: 2 [461440/620022]    Loss: 0.006173   Batch Acc: 85.94
[Train] Epoch: 2 [461504/620022]    Loss: 0.010364   Batch Acc: 75.00
[Train] Epoch: 2 [461568/620022]    Loss: 0.010730   Batch Acc: 68.75
[Train] Epoch: 2 [461632/620022]    Loss: 0.009381   Batch Acc: 78.12
[Train] Epoch: 2 [461696/620022]    Loss: 0.010373   Batch Acc: 70.31
[Train] Epoch: 2 [461760/620022]    Loss: 0.008582   Batch Acc: 78.12
[Train] Epoch: 2 [461824/620022]    Loss: 0.009292   Batch Acc: 75.00
[Train] Epoch: 2 [461888/620022]    Loss: 0.007721   Batch Acc: 82.81
[Train] Epoch: 2 [461952/620022]    Loss: 0.010235   Batch Acc: 79.69
[Train] Epoch: 2 [462016/620022]    Loss: 0.008123   Batch Acc: 81.25
[Train] Epoch: 2 [462080/620022]    Loss: 0.008487   Batch Acc: 82.81
[Train] Epoch: 2 [462144/620022]    Loss: 0.010727   Batch Acc: 75.00
[Train] Epoch: 2 [462208/620022]    Loss: 0.007589   Batch Acc: 84.38
[Train] Epoch: 2 [462272/620022]    Loss: 0.008609   Batch Acc: 79.69
[Train] Epoch: 2 [462336/620022]    Loss: 0.010359   Batch Acc: 81.25
[Train] Epoch: 2 [462400/620022]    Loss: 0.008740   Batch Acc: 76.56
[Train] Epoch: 2 [462464/620022]    Loss: 0.009849   Batch Acc: 71.88
[Train] Epoch: 2 [462528/620022]    Loss: 0.007791   Batch Acc: 79.69
[Train] Epoch: 2 [462592/620022]    Loss: 0.011441   Batch Acc: 68.75
[Train] Epoch: 2 [462656/620022]    Loss: 0.009631   Batch Acc: 79.69
[Train] Epoch: 2 [462720/620022]    Loss: 0.007205   Batch Acc: 87.50
[Train] Epoch: 2 [462784/620022]    Loss: 0.010392   Batch Acc: 70.31
[Train] Epoch: 2 [462848/620022]    Loss: 0.008983   Batch Acc: 81.25
[Train] Epoch: 2 [462912/620022]    Loss: 0.010177   Batch Acc: 68.75
[Train] Epoch: 2 [462976/620022]    Loss: 0.010806   Batch Acc: 68.75
[Train] Epoch: 2 [463040/620022]    Loss: 0.010229   Batch Acc: 73.44
[Train] Epoch: 2 [463104/620022]    Loss: 0.007176   Batch Acc: 81.25
[Train] Epoch: 2 [463168/620022]    Loss: 0.010043   Batch Acc: 76.56
[Train] Epoch: 2 [463232/620022]    Loss: 0.010551   Batch Acc: 73.44
[Train] Epoch: 2 [463296/620022]    Loss: 0.009521   Batch Acc: 76.56
[Train] Epoch: 2 [463360/620022]    Loss: 0.007313   Batch Acc: 79.69
[Train] Epoch: 2 [463424/620022]    Loss: 0.010200   Batch Acc: 70.31
[Train] Epoch: 2 [463488/620022]    Loss: 0.009565   Batch Acc: 71.88
[Train] Epoch: 2 [463552/620022]    Loss: 0.007781   Batch Acc: 79.69
[Train] Epoch: 2 [463616/620022]    Loss: 0.009234   Batch Acc: 79.69
[Train] Epoch: 2 [463680/620022]    Loss: 0.011583   Batch Acc: 67.19
[Train] Epoch: 2 [463744/620022]    Loss: 0.008563   Batch Acc: 81.25
[Train] Epoch: 2 [463808/620022]    Loss: 0.009413   Batch Acc: 73.44
[Train] Epoch: 2 [463872/620022]    Loss: 0.008006   Batch Acc: 82.81
[Train] Epoch: 2 [463936/620022]    Loss: 0.010765   Batch Acc: 71.88
[Train] Epoch: 2 [464000/620022]    Loss: 0.007423   Batch Acc: 79.69
[Train] Epoch: 2 [464064/620022]    Loss: 0.009862   Batch Acc: 75.00
[Train] Epoch: 2 [464128/620022]    Loss: 0.008762   Batch Acc: 71.88
[Train] Epoch: 2 [464192/620022]    Loss: 0.008720   Batch Acc: 79.69
[Train] Epoch: 2 [464256/620022]    Loss: 0.009904   Batch Acc: 70.31
[Train] Epoch: 2 [464320/620022]    Loss: 0.010140   Batch Acc: 73.44
[Train] Epoch: 2 [464384/620022]    Loss: 0.007555   Batch Acc: 84.38
[Train] Epoch: 2 [464448/620022]    Loss: 0.009872   Batch Acc: 73.44
[Train] Epoch: 2 [464512/620022]    Loss: 0.008487   Batch Acc: 78.12
[Train] Epoch: 2 [464576/620022]    Loss: 0.008740   Batch Acc: 76.56
[Train] Epoch: 2 [464640/620022]    Loss: 0.009912   Batch Acc: 67.19
[Train] Epoch: 2 [464704/620022]    Loss: 0.006718   Batch Acc: 76.56
[Train] Epoch: 2 [464768/620022]    Loss: 0.008504   Batch Acc: 79.69
[Train] Epoch: 2 [464832/620022]    Loss: 0.008153   Batch Acc: 79.69
[Train] Epoch: 2 [464896/620022]    Loss: 0.008189   Batch Acc: 81.25
[Train] Epoch: 2 [464960/620022]    Loss: 0.008623   Batch Acc: 79.69
[Train] Epoch: 2 [465024/620022]    Loss: 0.007782   Batch Acc: 78.12
[Train] Epoch: 2 [465088/620022]    Loss: 0.009221   Batch Acc: 75.00
[Train] Epoch: 2 [465152/620022]    Loss: 0.006990   Batch Acc: 85.94
[Train] Epoch: 2 [465216/620022]    Loss: 0.007490   Batch Acc: 81.25
[Train] Epoch: 2 [465280/620022]    Loss: 0.007486   Batch Acc: 78.12
[Train] Epoch: 2 [465344/620022]    Loss: 0.011761   Batch Acc: 65.62
[Train] Epoch: 2 [465408/620022]    Loss: 0.008083   Batch Acc: 82.81
[Train] Epoch: 2 [465472/620022]    Loss: 0.010094   Batch Acc: 75.00
[Train] Epoch: 2 [465536/620022]    Loss: 0.008459   Batch Acc: 75.00
[Train] Epoch: 2 [465600/620022]    Loss: 0.006762   Batch Acc: 82.81
[Train] Epoch: 2 [465664/620022]    Loss: 0.007845   Batch Acc: 84.38
[Train] Epoch: 2 [465728/620022]    Loss: 0.009879   Batch Acc: 68.75
[Train] Epoch: 2 [465792/620022]    Loss: 0.010216   Batch Acc: 68.75
[Train] Epoch: 2 [465856/620022]    Loss: 0.007233   Batch Acc: 84.38
[Train] Epoch: 2 [465920/620022]    Loss: 0.008722   Batch Acc: 79.69
[Train] Epoch: 2 [465984/620022]    Loss: 0.009469   Batch Acc: 75.00
[Train] Epoch: 2 [466048/620022]    Loss: 0.007973   Batch Acc: 85.94
[Train] Epoch: 2 [466112/620022]    Loss: 0.008595   Batch Acc: 78.12
[Train] Epoch: 2 [466176/620022]    Loss: 0.008341   Batch Acc: 76.56
[Train] Epoch: 2 [466240/620022]    Loss: 0.007109   Batch Acc: 81.25
[Train] Epoch: 2 [466304/620022]    Loss: 0.008056   Batch Acc: 79.69
[Train] Epoch: 2 [466368/620022]    Loss: 0.009698   Batch Acc: 71.88
[Train] Epoch: 2 [466432/620022]    Loss: 0.011893   Batch Acc: 68.75
[Train] Epoch: 2 [466496/620022]    Loss: 0.008023   Batch Acc: 79.69
[Train] Epoch: 2 [466560/620022]    Loss: 0.008422   Batch Acc: 71.88
[Train] Epoch: 2 [466624/620022]    Loss: 0.006669   Batch Acc: 87.50
[Train] Epoch: 2 [466688/620022]    Loss: 0.008306   Batch Acc: 76.56
[Train] Epoch: 2 [466752/620022]    Loss: 0.007999   Batch Acc: 73.44
[Train] Epoch: 2 [466816/620022]    Loss: 0.008467   Batch Acc: 81.25
[Train] Epoch: 2 [466880/620022]    Loss: 0.009518   Batch Acc: 73.44
[Train] Epoch: 2 [466944/620022]    Loss: 0.006258   Batch Acc: 87.50
[Train] Epoch: 2 [467008/620022]    Loss: 0.009274   Batch Acc: 75.00
[Train] Epoch: 2 [467072/620022]    Loss: 0.008803   Batch Acc: 68.75
[Train] Epoch: 2 [467136/620022]    Loss: 0.008318   Batch Acc: 75.00
[Train] Epoch: 2 [467200/620022]    Loss: 0.006482   Batch Acc: 84.38
[Train] Epoch: 2 [467264/620022]    Loss: 0.007521   Batch Acc: 85.94
[Train] Epoch: 2 [467328/620022]    Loss: 0.008592   Batch Acc: 75.00
[Train] Epoch: 2 [467392/620022]    Loss: 0.011328   Batch Acc: 73.44
[Train] Epoch: 2 [467456/620022]    Loss: 0.009314   Batch Acc: 76.56
[Train] Epoch: 2 [467520/620022]    Loss: 0.007320   Batch Acc: 82.81
[Train] Epoch: 2 [467584/620022]    Loss: 0.009490   Batch Acc: 78.12
[Train] Epoch: 2 [467648/620022]    Loss: 0.009386   Batch Acc: 78.12
[Train] Epoch: 2 [467712/620022]    Loss: 0.008642   Batch Acc: 81.25
[Train] Epoch: 2 [467776/620022]    Loss: 0.008002   Batch Acc: 81.25
[Train] Epoch: 2 [467840/620022]    Loss: 0.008523   Batch Acc: 78.12
[Train] Epoch: 2 [467904/620022]    Loss: 0.009838   Batch Acc: 73.44
[Train] Epoch: 2 [467968/620022]    Loss: 0.006980   Batch Acc: 87.50
[Train] Epoch: 2 [468032/620022]    Loss: 0.010697   Batch Acc: 67.19
[Train] Epoch: 2 [468096/620022]    Loss: 0.007960   Batch Acc: 73.44
[Train] Epoch: 2 [468160/620022]    Loss: 0.007030   Batch Acc: 89.06
[Train] Epoch: 2 [468224/620022]    Loss: 0.008641   Batch Acc: 78.12
[Train] Epoch: 2 [468288/620022]    Loss: 0.008158   Batch Acc: 78.12
[Train] Epoch: 2 [468352/620022]    Loss: 0.008629   Batch Acc: 79.69
[Train] Epoch: 2 [468416/620022]    Loss: 0.007497   Batch Acc: 82.81
[Train] Epoch: 2 [468480/620022]    Loss: 0.010351   Batch Acc: 73.44
[Train] Epoch: 2 [468544/620022]    Loss: 0.008440   Batch Acc: 81.25
[Train] Epoch: 2 [468608/620022]    Loss: 0.006465   Batch Acc: 87.50
[Train] Epoch: 2 [468672/620022]    Loss: 0.007749   Batch Acc: 75.00
[Train] Epoch: 2 [468736/620022]    Loss: 0.007681   Batch Acc: 81.25
[Train] Epoch: 2 [468800/620022]    Loss: 0.010247   Batch Acc: 76.56
[Train] Epoch: 2 [468864/620022]    Loss: 0.008303   Batch Acc: 78.12
[Train] Epoch: 2 [468928/620022]    Loss: 0.009355   Batch Acc: 76.56
[Train] Epoch: 2 [468992/620022]    Loss: 0.011638   Batch Acc: 67.19
[Train] Epoch: 2 [469056/620022]    Loss: 0.008918   Batch Acc: 71.88
[Train] Epoch: 2 [469120/620022]    Loss: 0.005528   Batch Acc: 87.50
[Train] Epoch: 2 [469184/620022]    Loss: 0.008582   Batch Acc: 81.25
[Train] Epoch: 2 [469248/620022]    Loss: 0.008080   Batch Acc: 75.00
[Train] Epoch: 2 [469312/620022]    Loss: 0.007983   Batch Acc: 85.94
[Train] Epoch: 2 [469376/620022]    Loss: 0.009097   Batch Acc: 78.12
[Train] Epoch: 2 [469440/620022]    Loss: 0.007477   Batch Acc: 81.25
[Train] Epoch: 2 [469504/620022]    Loss: 0.009307   Batch Acc: 78.12
[Train] Epoch: 2 [469568/620022]    Loss: 0.010654   Batch Acc: 71.88
[Train] Epoch: 2 [469632/620022]    Loss: 0.009536   Batch Acc: 71.88
[Train] Epoch: 2 [469696/620022]    Loss: 0.005275   Batch Acc: 85.94
[Train] Epoch: 2 [469760/620022]    Loss: 0.007512   Batch Acc: 89.06
[Train] Epoch: 2 [469824/620022]    Loss: 0.005518   Batch Acc: 93.75
[Train] Epoch: 2 [469888/620022]    Loss: 0.010750   Batch Acc: 70.31
[Train] Epoch: 2 [469952/620022]    Loss: 0.009064   Batch Acc: 75.00
[Train] Epoch: 2 [470016/620022]    Loss: 0.006491   Batch Acc: 82.81
[Train] Epoch: 2 [470080/620022]    Loss: 0.009773   Batch Acc: 73.44
[Train] Epoch: 2 [470144/620022]    Loss: 0.009338   Batch Acc: 71.88
[Train] Epoch: 2 [470208/620022]    Loss: 0.011491   Batch Acc: 73.44
[Train] Epoch: 2 [470272/620022]    Loss: 0.010496   Batch Acc: 71.88
[Train] Epoch: 2 [470336/620022]    Loss: 0.007863   Batch Acc: 82.81
[Train] Epoch: 2 [470400/620022]    Loss: 0.008200   Batch Acc: 84.38
[Train] Epoch: 2 [470464/620022]    Loss: 0.009498   Batch Acc: 76.56
[Train] Epoch: 2 [470528/620022]    Loss: 0.009420   Batch Acc: 78.12
[Train] Epoch: 2 [470592/620022]    Loss: 0.010434   Batch Acc: 71.88
[Train] Epoch: 2 [470656/620022]    Loss: 0.007866   Batch Acc: 76.56
[Train] Epoch: 2 [470720/620022]    Loss: 0.007155   Batch Acc: 87.50
[Train] Epoch: 2 [470784/620022]    Loss: 0.008640   Batch Acc: 79.69
[Train] Epoch: 2 [470848/620022]    Loss: 0.007999   Batch Acc: 81.25
[Train] Epoch: 2 [470912/620022]    Loss: 0.008058   Batch Acc: 75.00
[Train] Epoch: 2 [470976/620022]    Loss: 0.007400   Batch Acc: 79.69
[Train] Epoch: 2 [471040/620022]    Loss: 0.010174   Batch Acc: 73.44
[Train] Epoch: 2 [471104/620022]    Loss: 0.009252   Batch Acc: 70.31
[Train] Epoch: 2 [471168/620022]    Loss: 0.008908   Batch Acc: 75.00
[Train] Epoch: 2 [471232/620022]    Loss: 0.009062   Batch Acc: 70.31
[Train] Epoch: 2 [471296/620022]    Loss: 0.009851   Batch Acc: 79.69
[Train] Epoch: 2 [471360/620022]    Loss: 0.008958   Batch Acc: 78.12
[Train] Epoch: 2 [471424/620022]    Loss: 0.007300   Batch Acc: 82.81
[Train] Epoch: 2 [471488/620022]    Loss: 0.007507   Batch Acc: 78.12
[Train] Epoch: 2 [471552/620022]    Loss: 0.010103   Batch Acc: 73.44
[Train] Epoch: 2 [471616/620022]    Loss: 0.010998   Batch Acc: 70.31
[Train] Epoch: 2 [471680/620022]    Loss: 0.009126   Batch Acc: 70.31
[Train] Epoch: 2 [471744/620022]    Loss: 0.009268   Batch Acc: 75.00
[Train] Epoch: 2 [471808/620022]    Loss: 0.007562   Batch Acc: 81.25
[Train] Epoch: 2 [471872/620022]    Loss: 0.007742   Batch Acc: 79.69
[Train] Epoch: 2 [471936/620022]    Loss: 0.009440   Batch Acc: 75.00
[Train] Epoch: 2 [472000/620022]    Loss: 0.009743   Batch Acc: 70.31
[Train] Epoch: 2 [472064/620022]    Loss: 0.008641   Batch Acc: 81.25
[Train] Epoch: 2 [472128/620022]    Loss: 0.010064   Batch Acc: 78.12
[Train] Epoch: 2 [472192/620022]    Loss: 0.009378   Batch Acc: 71.88
[Train] Epoch: 2 [472256/620022]    Loss: 0.008684   Batch Acc: 81.25
[Train] Epoch: 2 [472320/620022]    Loss: 0.009657   Batch Acc: 75.00
[Train] Epoch: 2 [472384/620022]    Loss: 0.009133   Batch Acc: 73.44
[Train] Epoch: 2 [472448/620022]    Loss: 0.009109   Batch Acc: 78.12
[Train] Epoch: 2 [472512/620022]    Loss: 0.009127   Batch Acc: 76.56
[Train] Epoch: 2 [472576/620022]    Loss: 0.010718   Batch Acc: 73.44
[Train] Epoch: 2 [472640/620022]    Loss: 0.007657   Batch Acc: 81.25
[Train] Epoch: 2 [472704/620022]    Loss: 0.007537   Batch Acc: 81.25
[Train] Epoch: 2 [472768/620022]    Loss: 0.007680   Batch Acc: 82.81
[Train] Epoch: 2 [472832/620022]    Loss: 0.008898   Batch Acc: 75.00
[Train] Epoch: 2 [472896/620022]    Loss: 0.010763   Batch Acc: 71.88
[Train] Epoch: 2 [472960/620022]    Loss: 0.008927   Batch Acc: 82.81
[Train] Epoch: 2 [473024/620022]    Loss: 0.007310   Batch Acc: 79.69
[Train] Epoch: 2 [473088/620022]    Loss: 0.010053   Batch Acc: 71.88
[Train] Epoch: 2 [473152/620022]    Loss: 0.009755   Batch Acc: 68.75
[Train] Epoch: 2 [473216/620022]    Loss: 0.006885   Batch Acc: 79.69
[Train] Epoch: 2 [473280/620022]    Loss: 0.010170   Batch Acc: 75.00
[Train] Epoch: 2 [473344/620022]    Loss: 0.008809   Batch Acc: 82.81
[Train] Epoch: 2 [473408/620022]    Loss: 0.012880   Batch Acc: 70.31
[Train] Epoch: 2 [473472/620022]    Loss: 0.009329   Batch Acc: 75.00
[Train] Epoch: 2 [473536/620022]    Loss: 0.008312   Batch Acc: 76.56
[Train] Epoch: 2 [473600/620022]    Loss: 0.009172   Batch Acc: 79.69
[Train] Epoch: 2 [473664/620022]    Loss: 0.012331   Batch Acc: 71.88
[Train] Epoch: 2 [473728/620022]    Loss: 0.009400   Batch Acc: 73.44
[Train] Epoch: 2 [473792/620022]    Loss: 0.006952   Batch Acc: 84.38
[Train] Epoch: 2 [473856/620022]    Loss: 0.006990   Batch Acc: 78.12
[Train] Epoch: 2 [473920/620022]    Loss: 0.008023   Batch Acc: 82.81
[Train] Epoch: 2 [473984/620022]    Loss: 0.011368   Batch Acc: 64.06
[Train] Epoch: 2 [474048/620022]    Loss: 0.010793   Batch Acc: 73.44
[Train] Epoch: 2 [474112/620022]    Loss: 0.009918   Batch Acc: 71.88
[Train] Epoch: 2 [474176/620022]    Loss: 0.006817   Batch Acc: 82.81
[Train] Epoch: 2 [474240/620022]    Loss: 0.009381   Batch Acc: 75.00
[Train] Epoch: 2 [474304/620022]    Loss: 0.004471   Batch Acc: 93.75
[Train] Epoch: 2 [474368/620022]    Loss: 0.009222   Batch Acc: 73.44
[Train] Epoch: 2 [474432/620022]    Loss: 0.006495   Batch Acc: 84.38
[Train] Epoch: 2 [474496/620022]    Loss: 0.008300   Batch Acc: 78.12
[Train] Epoch: 2 [474560/620022]    Loss: 0.007242   Batch Acc: 81.25
[Train] Epoch: 2 [474624/620022]    Loss: 0.008083   Batch Acc: 82.81
[Train] Epoch: 2 [474688/620022]    Loss: 0.008417   Batch Acc: 82.81
[Train] Epoch: 2 [474752/620022]    Loss: 0.007709   Batch Acc: 79.69
[Train] Epoch: 2 [474816/620022]    Loss: 0.008383   Batch Acc: 82.81
[Train] Epoch: 2 [474880/620022]    Loss: 0.011645   Batch Acc: 73.44
[Train] Epoch: 2 [474944/620022]    Loss: 0.009756   Batch Acc: 73.44
[Train] Epoch: 2 [475008/620022]    Loss: 0.008789   Batch Acc: 71.88
[Train] Epoch: 2 [475072/620022]    Loss: 0.009919   Batch Acc: 71.88
[Train] Epoch: 2 [475136/620022]    Loss: 0.009515   Batch Acc: 79.69
[Train] Epoch: 2 [475200/620022]    Loss: 0.007337   Batch Acc: 81.25
[Train] Epoch: 2 [475264/620022]    Loss: 0.006935   Batch Acc: 82.81
[Train] Epoch: 2 [475328/620022]    Loss: 0.010036   Batch Acc: 75.00
[Train] Epoch: 2 [475392/620022]    Loss: 0.009949   Batch Acc: 73.44
[Train] Epoch: 2 [475456/620022]    Loss: 0.010306   Batch Acc: 73.44
[Train] Epoch: 2 [475520/620022]    Loss: 0.007636   Batch Acc: 82.81
[Train] Epoch: 2 [475584/620022]    Loss: 0.008743   Batch Acc: 79.69
[Train] Epoch: 2 [475648/620022]    Loss: 0.008248   Batch Acc: 79.69
[Train] Epoch: 2 [475712/620022]    Loss: 0.010905   Batch Acc: 71.88
[Train] Epoch: 2 [475776/620022]    Loss: 0.011123   Batch Acc: 68.75
[Train] Epoch: 2 [475840/620022]    Loss: 0.007621   Batch Acc: 78.12
[Train] Epoch: 2 [475904/620022]    Loss: 0.008678   Batch Acc: 71.88
[Train] Epoch: 2 [475968/620022]    Loss: 0.007653   Batch Acc: 79.69
[Train] Epoch: 2 [476032/620022]    Loss: 0.009202   Batch Acc: 75.00
[Train] Epoch: 2 [476096/620022]    Loss: 0.007569   Batch Acc: 76.56
[Train] Epoch: 2 [476160/620022]    Loss: 0.009785   Batch Acc: 73.44
[Train] Epoch: 2 [476224/620022]    Loss: 0.007076   Batch Acc: 82.81
[Train] Epoch: 2 [476288/620022]    Loss: 0.007511   Batch Acc: 78.12
[Train] Epoch: 2 [476352/620022]    Loss: 0.008925   Batch Acc: 79.69
[Train] Epoch: 2 [476416/620022]    Loss: 0.008924   Batch Acc: 78.12
[Train] Epoch: 2 [476480/620022]    Loss: 0.006674   Batch Acc: 89.06
[Train] Epoch: 2 [476544/620022]    Loss: 0.008291   Batch Acc: 79.69
[Train] Epoch: 2 [476608/620022]    Loss: 0.007925   Batch Acc: 79.69
[Train] Epoch: 2 [476672/620022]    Loss: 0.006337   Batch Acc: 87.50
[Train] Epoch: 2 [476736/620022]    Loss: 0.010395   Batch Acc: 73.44
[Train] Epoch: 2 [476800/620022]    Loss: 0.008316   Batch Acc: 81.25
[Train] Epoch: 2 [476864/620022]    Loss: 0.008399   Batch Acc: 76.56
[Train] Epoch: 2 [476928/620022]    Loss: 0.010778   Batch Acc: 70.31
[Train] Epoch: 2 [476992/620022]    Loss: 0.009816   Batch Acc: 71.88
[Train] Epoch: 2 [477056/620022]    Loss: 0.009541   Batch Acc: 73.44
[Train] Epoch: 2 [477120/620022]    Loss: 0.010334   Batch Acc: 75.00
[Train] Epoch: 2 [477184/620022]    Loss: 0.007539   Batch Acc: 82.81
[Train] Epoch: 2 [477248/620022]    Loss: 0.009005   Batch Acc: 71.88
[Train] Epoch: 2 [477312/620022]    Loss: 0.008786   Batch Acc: 73.44
[Train] Epoch: 2 [477376/620022]    Loss: 0.008469   Batch Acc: 70.31
[Train] Epoch: 2 [477440/620022]    Loss: 0.006048   Batch Acc: 87.50
[Train] Epoch: 2 [477504/620022]    Loss: 0.008215   Batch Acc: 85.94
[Train] Epoch: 2 [477568/620022]    Loss: 0.008591   Batch Acc: 76.56
[Train] Epoch: 2 [477632/620022]    Loss: 0.007620   Batch Acc: 82.81
[Train] Epoch: 2 [477696/620022]    Loss: 0.006914   Batch Acc: 81.25
[Train] Epoch: 2 [477760/620022]    Loss: 0.007927   Batch Acc: 84.38
[Train] Epoch: 2 [477824/620022]    Loss: 0.008320   Batch Acc: 81.25
[Train] Epoch: 2 [477888/620022]    Loss: 0.008326   Batch Acc: 79.69
[Train] Epoch: 2 [477952/620022]    Loss: 0.007561   Batch Acc: 89.06
[Train] Epoch: 2 [478016/620022]    Loss: 0.011126   Batch Acc: 76.56
[Train] Epoch: 2 [478080/620022]    Loss: 0.009400   Batch Acc: 71.88
[Train] Epoch: 2 [478144/620022]    Loss: 0.007972   Batch Acc: 81.25
[Train] Epoch: 2 [478208/620022]    Loss: 0.009164   Batch Acc: 76.56
[Train] Epoch: 2 [478272/620022]    Loss: 0.006767   Batch Acc: 85.94
[Train] Epoch: 2 [478336/620022]    Loss: 0.009015   Batch Acc: 75.00
[Train] Epoch: 2 [478400/620022]    Loss: 0.008038   Batch Acc: 79.69
[Train] Epoch: 2 [478464/620022]    Loss: 0.007394   Batch Acc: 76.56
[Train] Epoch: 2 [478528/620022]    Loss: 0.007047   Batch Acc: 85.94
[Train] Epoch: 2 [478592/620022]    Loss: 0.009358   Batch Acc: 70.31
[Train] Epoch: 2 [478656/620022]    Loss: 0.007811   Batch Acc: 75.00
[Train] Epoch: 2 [478720/620022]    Loss: 0.009057   Batch Acc: 76.56
[Train] Epoch: 2 [478784/620022]    Loss: 0.009666   Batch Acc: 79.69
[Train] Epoch: 2 [478848/620022]    Loss: 0.009646   Batch Acc: 75.00
[Train] Epoch: 2 [478912/620022]    Loss: 0.007736   Batch Acc: 73.44
[Train] Epoch: 2 [478976/620022]    Loss: 0.008766   Batch Acc: 75.00
[Train] Epoch: 2 [479040/620022]    Loss: 0.006735   Batch Acc: 79.69
[Train] Epoch: 2 [479104/620022]    Loss: 0.008260   Batch Acc: 79.69
[Train] Epoch: 2 [479168/620022]    Loss: 0.008658   Batch Acc: 82.81
[Train] Epoch: 2 [479232/620022]    Loss: 0.006867   Batch Acc: 82.81
[Train] Epoch: 2 [479296/620022]    Loss: 0.010774   Batch Acc: 70.31
[Train] Epoch: 2 [479360/620022]    Loss: 0.009078   Batch Acc: 78.12
[Train] Epoch: 2 [479424/620022]    Loss: 0.005917   Batch Acc: 85.94
[Train] Epoch: 2 [479488/620022]    Loss: 0.008364   Batch Acc: 76.56
[Train] Epoch: 2 [479552/620022]    Loss: 0.006846   Batch Acc: 82.81
[Train] Epoch: 2 [479616/620022]    Loss: 0.009540   Batch Acc: 71.88
[Train] Epoch: 2 [479680/620022]    Loss: 0.008329   Batch Acc: 81.25
[Train] Epoch: 2 [479744/620022]    Loss: 0.009166   Batch Acc: 75.00
[Train] Epoch: 2 [479808/620022]    Loss: 0.007683   Batch Acc: 84.38
[Train] Epoch: 2 [479872/620022]    Loss: 0.007816   Batch Acc: 81.25
[Train] Epoch: 2 [479936/620022]    Loss: 0.008805   Batch Acc: 75.00
[Train] Epoch: 2 [480000/620022]    Loss: 0.009074   Batch Acc: 75.00
[Train] Epoch: 2 [480064/620022]    Loss: 0.009227   Batch Acc: 71.88
[Train] Epoch: 2 [480128/620022]    Loss: 0.008868   Batch Acc: 82.81
[Train] Epoch: 2 [480192/620022]    Loss: 0.008954   Batch Acc: 79.69
[Train] Epoch: 2 [480256/620022]    Loss: 0.008203   Batch Acc: 75.00
[Train] Epoch: 2 [480320/620022]    Loss: 0.007615   Batch Acc: 81.25
[Train] Epoch: 2 [480384/620022]    Loss: 0.008671   Batch Acc: 79.69
[Train] Epoch: 2 [480448/620022]    Loss: 0.009389   Batch Acc: 75.00
[Train] Epoch: 2 [480512/620022]    Loss: 0.010166   Batch Acc: 70.31
[Train] Epoch: 2 [480576/620022]    Loss: 0.007499   Batch Acc: 87.50
[Train] Epoch: 2 [480640/620022]    Loss: 0.010236   Batch Acc: 75.00
[Train] Epoch: 2 [480704/620022]    Loss: 0.009007   Batch Acc: 75.00
[Train] Epoch: 2 [480768/620022]    Loss: 0.008970   Batch Acc: 81.25
[Train] Epoch: 2 [480832/620022]    Loss: 0.007517   Batch Acc: 81.25
[Train] Epoch: 2 [480896/620022]    Loss: 0.008178   Batch Acc: 84.38
[Train] Epoch: 2 [480960/620022]    Loss: 0.011092   Batch Acc: 67.19
[Train] Epoch: 2 [481024/620022]    Loss: 0.007972   Batch Acc: 81.25
[Train] Epoch: 2 [481088/620022]    Loss: 0.008613   Batch Acc: 81.25
[Train] Epoch: 2 [481152/620022]    Loss: 0.009453   Batch Acc: 78.12
[Train] Epoch: 2 [481216/620022]    Loss: 0.006956   Batch Acc: 84.38
[Train] Epoch: 2 [481280/620022]    Loss: 0.007899   Batch Acc: 78.12
[Train] Epoch: 2 [481344/620022]    Loss: 0.008342   Batch Acc: 78.12
[Train] Epoch: 2 [481408/620022]    Loss: 0.007184   Batch Acc: 79.69
[Train] Epoch: 2 [481472/620022]    Loss: 0.009258   Batch Acc: 78.12
[Train] Epoch: 2 [481536/620022]    Loss: 0.009790   Batch Acc: 79.69
[Train] Epoch: 2 [481600/620022]    Loss: 0.011680   Batch Acc: 73.44
[Train] Epoch: 2 [481664/620022]    Loss: 0.009435   Batch Acc: 73.44
[Train] Epoch: 2 [481728/620022]    Loss: 0.006959   Batch Acc: 79.69
[Train] Epoch: 2 [481792/620022]    Loss: 0.008894   Batch Acc: 76.56
[Train] Epoch: 2 [481856/620022]    Loss: 0.006873   Batch Acc: 81.25
[Train] Epoch: 2 [481920/620022]    Loss: 0.005923   Batch Acc: 89.06
[Train] Epoch: 2 [481984/620022]    Loss: 0.007263   Batch Acc: 84.38
[Train] Epoch: 2 [482048/620022]    Loss: 0.009054   Batch Acc: 76.56
[Train] Epoch: 2 [482112/620022]    Loss: 0.008795   Batch Acc: 67.19
[Train] Epoch: 2 [482176/620022]    Loss: 0.008084   Batch Acc: 82.81
[Train] Epoch: 2 [482240/620022]    Loss: 0.008365   Batch Acc: 76.56
[Train] Epoch: 2 [482304/620022]    Loss: 0.011879   Batch Acc: 70.31
[Train] Epoch: 2 [482368/620022]    Loss: 0.007104   Batch Acc: 87.50
[Train] Epoch: 2 [482432/620022]    Loss: 0.009841   Batch Acc: 73.44
[Train] Epoch: 2 [482496/620022]    Loss: 0.007531   Batch Acc: 75.00
[Train] Epoch: 2 [482560/620022]    Loss: 0.010191   Batch Acc: 73.44
[Train] Epoch: 2 [482624/620022]    Loss: 0.006605   Batch Acc: 82.81
[Train] Epoch: 2 [482688/620022]    Loss: 0.009030   Batch Acc: 76.56
[Train] Epoch: 2 [482752/620022]    Loss: 0.006914   Batch Acc: 87.50
[Train] Epoch: 2 [482816/620022]    Loss: 0.009686   Batch Acc: 75.00
[Train] Epoch: 2 [482880/620022]    Loss: 0.008128   Batch Acc: 85.94
[Train] Epoch: 2 [482944/620022]    Loss: 0.010460   Batch Acc: 76.56
[Train] Epoch: 2 [483008/620022]    Loss: 0.010775   Batch Acc: 65.62
[Train] Epoch: 2 [483072/620022]    Loss: 0.008858   Batch Acc: 78.12
[Train] Epoch: 2 [483136/620022]    Loss: 0.007219   Batch Acc: 85.94
[Train] Epoch: 2 [483200/620022]    Loss: 0.009858   Batch Acc: 70.31
[Train] Epoch: 2 [483264/620022]    Loss: 0.009667   Batch Acc: 75.00
[Train] Epoch: 2 [483328/620022]    Loss: 0.008671   Batch Acc: 84.38
[Train] Epoch: 2 [483392/620022]    Loss: 0.006503   Batch Acc: 82.81
[Train] Epoch: 2 [483456/620022]    Loss: 0.008302   Batch Acc: 85.94
[Train] Epoch: 2 [483520/620022]    Loss: 0.008238   Batch Acc: 78.12
[Train] Epoch: 2 [483584/620022]    Loss: 0.009135   Batch Acc: 76.56
[Train] Epoch: 2 [483648/620022]    Loss: 0.009261   Batch Acc: 70.31
[Train] Epoch: 2 [483712/620022]    Loss: 0.007133   Batch Acc: 81.25
[Train] Epoch: 2 [483776/620022]    Loss: 0.009004   Batch Acc: 76.56
[Train] Epoch: 2 [483840/620022]    Loss: 0.008375   Batch Acc: 79.69
[Train] Epoch: 2 [483904/620022]    Loss: 0.009702   Batch Acc: 70.31
[Train] Epoch: 2 [483968/620022]    Loss: 0.008455   Batch Acc: 78.12
[Train] Epoch: 2 [484032/620022]    Loss: 0.007808   Batch Acc: 82.81
[Train] Epoch: 2 [484096/620022]    Loss: 0.009056   Batch Acc: 76.56
[Train] Epoch: 2 [484160/620022]    Loss: 0.009214   Batch Acc: 70.31
[Train] Epoch: 2 [484224/620022]    Loss: 0.008699   Batch Acc: 79.69
[Train] Epoch: 2 [484288/620022]    Loss: 0.011205   Batch Acc: 68.75
[Train] Epoch: 2 [484352/620022]    Loss: 0.008318   Batch Acc: 84.38
[Train] Epoch: 2 [484416/620022]    Loss: 0.009495   Batch Acc: 78.12
[Train] Epoch: 2 [484480/620022]    Loss: 0.009000   Batch Acc: 75.00
[Train] Epoch: 2 [484544/620022]    Loss: 0.007682   Batch Acc: 82.81
[Train] Epoch: 2 [484608/620022]    Loss: 0.008437   Batch Acc: 76.56
[Train] Epoch: 2 [484672/620022]    Loss: 0.013836   Batch Acc: 67.19
[Train] Epoch: 2 [484736/620022]    Loss: 0.008508   Batch Acc: 78.12
[Train] Epoch: 2 [484800/620022]    Loss: 0.009308   Batch Acc: 76.56
[Train] Epoch: 2 [484864/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 2 [484928/620022]    Loss: 0.007399   Batch Acc: 79.69
[Train] Epoch: 2 [484992/620022]    Loss: 0.007383   Batch Acc: 78.12
[Train] Epoch: 2 [485056/620022]    Loss: 0.009108   Batch Acc: 71.88
[Train] Epoch: 2 [485120/620022]    Loss: 0.007337   Batch Acc: 75.00
[Train] Epoch: 2 [485184/620022]    Loss: 0.008170   Batch Acc: 78.12
[Train] Epoch: 2 [485248/620022]    Loss: 0.007314   Batch Acc: 82.81
[Train] Epoch: 2 [485312/620022]    Loss: 0.008287   Batch Acc: 75.00
[Train] Epoch: 2 [485376/620022]    Loss: 0.009707   Batch Acc: 75.00
[Train] Epoch: 2 [485440/620022]    Loss: 0.008711   Batch Acc: 81.25
[Train] Epoch: 2 [485504/620022]    Loss: 0.011121   Batch Acc: 64.06
[Train] Epoch: 2 [485568/620022]    Loss: 0.009451   Batch Acc: 75.00
[Train] Epoch: 2 [485632/620022]    Loss: 0.009556   Batch Acc: 78.12
[Train] Epoch: 2 [485696/620022]    Loss: 0.009620   Batch Acc: 78.12
[Train] Epoch: 2 [485760/620022]    Loss: 0.009292   Batch Acc: 73.44
[Train] Epoch: 2 [485824/620022]    Loss: 0.009692   Batch Acc: 76.56
[Train] Epoch: 2 [485888/620022]    Loss: 0.008422   Batch Acc: 81.25
[Train] Epoch: 2 [485952/620022]    Loss: 0.006725   Batch Acc: 89.06
[Train] Epoch: 2 [486016/620022]    Loss: 0.008297   Batch Acc: 78.12
[Train] Epoch: 2 [486080/620022]    Loss: 0.009113   Batch Acc: 75.00
[Train] Epoch: 2 [486144/620022]    Loss: 0.009926   Batch Acc: 67.19
[Train] Epoch: 2 [486208/620022]    Loss: 0.006944   Batch Acc: 85.94
[Train] Epoch: 2 [486272/620022]    Loss: 0.006490   Batch Acc: 85.94
[Train] Epoch: 2 [486336/620022]    Loss: 0.006674   Batch Acc: 79.69
[Train] Epoch: 2 [486400/620022]    Loss: 0.006520   Batch Acc: 82.81
[Train] Epoch: 2 [486464/620022]    Loss: 0.007099   Batch Acc: 85.94
[Train] Epoch: 2 [486528/620022]    Loss: 0.009019   Batch Acc: 85.94
[Train] Epoch: 2 [486592/620022]    Loss: 0.007390   Batch Acc: 81.25
[Train] Epoch: 2 [486656/620022]    Loss: 0.006905   Batch Acc: 82.81
[Train] Epoch: 2 [486720/620022]    Loss: 0.008062   Batch Acc: 87.50
[Train] Epoch: 2 [486784/620022]    Loss: 0.008629   Batch Acc: 78.12
[Train] Epoch: 2 [486848/620022]    Loss: 0.008493   Batch Acc: 81.25
[Train] Epoch: 2 [486912/620022]    Loss: 0.008802   Batch Acc: 76.56
[Train] Epoch: 2 [486976/620022]    Loss: 0.007197   Batch Acc: 82.81
[Train] Epoch: 2 [487040/620022]    Loss: 0.008066   Batch Acc: 81.25
[Train] Epoch: 2 [487104/620022]    Loss: 0.008932   Batch Acc: 78.12
[Train] Epoch: 2 [487168/620022]    Loss: 0.008513   Batch Acc: 79.69
[Train] Epoch: 2 [487232/620022]    Loss: 0.008497   Batch Acc: 76.56
[Train] Epoch: 2 [487296/620022]    Loss: 0.009169   Batch Acc: 67.19
[Train] Epoch: 2 [487360/620022]    Loss: 0.010560   Batch Acc: 62.50
[Train] Epoch: 2 [487424/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 2 [487488/620022]    Loss: 0.008501   Batch Acc: 76.56
[Train] Epoch: 2 [487552/620022]    Loss: 0.008021   Batch Acc: 79.69
[Train] Epoch: 2 [487616/620022]    Loss: 0.007453   Batch Acc: 82.81
[Train] Epoch: 2 [487680/620022]    Loss: 0.008855   Batch Acc: 79.69
[Train] Epoch: 2 [487744/620022]    Loss: 0.008606   Batch Acc: 84.38
[Train] Epoch: 2 [487808/620022]    Loss: 0.008959   Batch Acc: 71.88
[Train] Epoch: 2 [487872/620022]    Loss: 0.009607   Batch Acc: 78.12
[Train] Epoch: 2 [487936/620022]    Loss: 0.009448   Batch Acc: 75.00
[Train] Epoch: 2 [488000/620022]    Loss: 0.007558   Batch Acc: 84.38
[Train] Epoch: 2 [488064/620022]    Loss: 0.008357   Batch Acc: 82.81
[Train] Epoch: 2 [488128/620022]    Loss: 0.008929   Batch Acc: 73.44
[Train] Epoch: 2 [488192/620022]    Loss: 0.009574   Batch Acc: 71.88
[Train] Epoch: 2 [488256/620022]    Loss: 0.007357   Batch Acc: 84.38
[Train] Epoch: 2 [488320/620022]    Loss: 0.008698   Batch Acc: 76.56
[Train] Epoch: 2 [488384/620022]    Loss: 0.011205   Batch Acc: 64.06
[Train] Epoch: 2 [488448/620022]    Loss: 0.008456   Batch Acc: 73.44
[Train] Epoch: 2 [488512/620022]    Loss: 0.006169   Batch Acc: 89.06
[Train] Epoch: 2 [488576/620022]    Loss: 0.008105   Batch Acc: 79.69
[Train] Epoch: 2 [488640/620022]    Loss: 0.008055   Batch Acc: 85.94
[Train] Epoch: 2 [488704/620022]    Loss: 0.009115   Batch Acc: 76.56
[Train] Epoch: 2 [488768/620022]    Loss: 0.007142   Batch Acc: 82.81
[Train] Epoch: 2 [488832/620022]    Loss: 0.009264   Batch Acc: 67.19
[Train] Epoch: 2 [488896/620022]    Loss: 0.008867   Batch Acc: 75.00
[Train] Epoch: 2 [488960/620022]    Loss: 0.011101   Batch Acc: 67.19
[Train] Epoch: 2 [489024/620022]    Loss: 0.007268   Batch Acc: 76.56
[Train] Epoch: 2 [489088/620022]    Loss: 0.007099   Batch Acc: 89.06
[Train] Epoch: 2 [489152/620022]    Loss: 0.006297   Batch Acc: 87.50
[Train] Epoch: 2 [489216/620022]    Loss: 0.009573   Batch Acc: 76.56
[Train] Epoch: 2 [489280/620022]    Loss: 0.006438   Batch Acc: 82.81
[Train] Epoch: 2 [489344/620022]    Loss: 0.007277   Batch Acc: 87.50
[Train] Epoch: 2 [489408/620022]    Loss: 0.010001   Batch Acc: 70.31
[Train] Epoch: 2 [489472/620022]    Loss: 0.010235   Batch Acc: 76.56
[Train] Epoch: 2 [489536/620022]    Loss: 0.010146   Batch Acc: 68.75
[Train] Epoch: 2 [489600/620022]    Loss: 0.006571   Batch Acc: 87.50
[Train] Epoch: 2 [489664/620022]    Loss: 0.006316   Batch Acc: 84.38
[Train] Epoch: 2 [489728/620022]    Loss: 0.009859   Batch Acc: 75.00
[Train] Epoch: 2 [489792/620022]    Loss: 0.008502   Batch Acc: 81.25
[Train] Epoch: 2 [489856/620022]    Loss: 0.009502   Batch Acc: 73.44
[Train] Epoch: 2 [489920/620022]    Loss: 0.008897   Batch Acc: 75.00
[Train] Epoch: 2 [489984/620022]    Loss: 0.009311   Batch Acc: 71.88
[Train] Epoch: 2 [490048/620022]    Loss: 0.007525   Batch Acc: 82.81
[Train] Epoch: 2 [490112/620022]    Loss: 0.007138   Batch Acc: 81.25
[Train] Epoch: 2 [490176/620022]    Loss: 0.006818   Batch Acc: 84.38
[Train] Epoch: 2 [490240/620022]    Loss: 0.009419   Batch Acc: 75.00
[Train] Epoch: 2 [490304/620022]    Loss: 0.007796   Batch Acc: 71.88
[Train] Epoch: 2 [490368/620022]    Loss: 0.007711   Batch Acc: 82.81
[Train] Epoch: 2 [490432/620022]    Loss: 0.010606   Batch Acc: 70.31
[Train] Epoch: 2 [490496/620022]    Loss: 0.007611   Batch Acc: 81.25
[Train] Epoch: 2 [490560/620022]    Loss: 0.008940   Batch Acc: 76.56
[Train] Epoch: 2 [490624/620022]    Loss: 0.008433   Batch Acc: 76.56
[Train] Epoch: 2 [490688/620022]    Loss: 0.006598   Batch Acc: 85.94
[Train] Epoch: 2 [490752/620022]    Loss: 0.009669   Batch Acc: 68.75
[Train] Epoch: 2 [490816/620022]    Loss: 0.007006   Batch Acc: 87.50
[Train] Epoch: 2 [490880/620022]    Loss: 0.007461   Batch Acc: 82.81
[Train] Epoch: 2 [490944/620022]    Loss: 0.007200   Batch Acc: 82.81
[Train] Epoch: 2 [491008/620022]    Loss: 0.007768   Batch Acc: 79.69
[Train] Epoch: 2 [491072/620022]    Loss: 0.009503   Batch Acc: 71.88
[Train] Epoch: 2 [491136/620022]    Loss: 0.008579   Batch Acc: 79.69
[Train] Epoch: 2 [491200/620022]    Loss: 0.009901   Batch Acc: 71.88
[Train] Epoch: 2 [491264/620022]    Loss: 0.008901   Batch Acc: 79.69
[Train] Epoch: 2 [491328/620022]    Loss: 0.009107   Batch Acc: 76.56
[Train] Epoch: 2 [491392/620022]    Loss: 0.008359   Batch Acc: 81.25
[Train] Epoch: 2 [491456/620022]    Loss: 0.008665   Batch Acc: 79.69
[Train] Epoch: 2 [491520/620022]    Loss: 0.008267   Batch Acc: 76.56
[Train] Epoch: 2 [491584/620022]    Loss: 0.007381   Batch Acc: 81.25
[Train] Epoch: 2 [491648/620022]    Loss: 0.009835   Batch Acc: 76.56
[Train] Epoch: 2 [491712/620022]    Loss: 0.006846   Batch Acc: 76.56
[Train] Epoch: 2 [491776/620022]    Loss: 0.007895   Batch Acc: 81.25
[Train] Epoch: 2 [491840/620022]    Loss: 0.009848   Batch Acc: 76.56
[Train] Epoch: 2 [491904/620022]    Loss: 0.007072   Batch Acc: 81.25
[Train] Epoch: 2 [491968/620022]    Loss: 0.009320   Batch Acc: 78.12
[Train] Epoch: 2 [492032/620022]    Loss: 0.011427   Batch Acc: 71.88
[Train] Epoch: 2 [492096/620022]    Loss: 0.007424   Batch Acc: 79.69
[Train] Epoch: 2 [492160/620022]    Loss: 0.006109   Batch Acc: 87.50
[Train] Epoch: 2 [492224/620022]    Loss: 0.006435   Batch Acc: 87.50
[Train] Epoch: 2 [492288/620022]    Loss: 0.007285   Batch Acc: 84.38
[Train] Epoch: 2 [492352/620022]    Loss: 0.006925   Batch Acc: 81.25
[Train] Epoch: 2 [492416/620022]    Loss: 0.010282   Batch Acc: 68.75
[Train] Epoch: 2 [492480/620022]    Loss: 0.011351   Batch Acc: 68.75
[Train] Epoch: 2 [492544/620022]    Loss: 0.008479   Batch Acc: 75.00
[Train] Epoch: 2 [492608/620022]    Loss: 0.009416   Batch Acc: 76.56
[Train] Epoch: 2 [492672/620022]    Loss: 0.010532   Batch Acc: 68.75
[Train] Epoch: 2 [492736/620022]    Loss: 0.010266   Batch Acc: 73.44
[Train] Epoch: 2 [492800/620022]    Loss: 0.010751   Batch Acc: 70.31
[Train] Epoch: 2 [492864/620022]    Loss: 0.009351   Batch Acc: 76.56
[Train] Epoch: 2 [492928/620022]    Loss: 0.011377   Batch Acc: 71.88
[Train] Epoch: 2 [492992/620022]    Loss: 0.009920   Batch Acc: 76.56
[Train] Epoch: 2 [493056/620022]    Loss: 0.010948   Batch Acc: 71.88
[Train] Epoch: 2 [493120/620022]    Loss: 0.011732   Batch Acc: 68.75
[Train] Epoch: 2 [493184/620022]    Loss: 0.008389   Batch Acc: 81.25
[Train] Epoch: 2 [493248/620022]    Loss: 0.007788   Batch Acc: 79.69
[Train] Epoch: 2 [493312/620022]    Loss: 0.007520   Batch Acc: 78.12
[Train] Epoch: 2 [493376/620022]    Loss: 0.008031   Batch Acc: 85.94
[Train] Epoch: 2 [493440/620022]    Loss: 0.010364   Batch Acc: 60.94
[Train] Epoch: 2 [493504/620022]    Loss: 0.010100   Batch Acc: 71.88
[Train] Epoch: 2 [493568/620022]    Loss: 0.008044   Batch Acc: 79.69
[Train] Epoch: 2 [493632/620022]    Loss: 0.010802   Batch Acc: 75.00
[Train] Epoch: 2 [493696/620022]    Loss: 0.006978   Batch Acc: 82.81
[Train] Epoch: 2 [493760/620022]    Loss: 0.007569   Batch Acc: 82.81
[Train] Epoch: 2 [493824/620022]    Loss: 0.008530   Batch Acc: 73.44
[Train] Epoch: 2 [493888/620022]    Loss: 0.009858   Batch Acc: 76.56
[Train] Epoch: 2 [493952/620022]    Loss: 0.009179   Batch Acc: 76.56
[Train] Epoch: 2 [494016/620022]    Loss: 0.007832   Batch Acc: 79.69
[Train] Epoch: 2 [494080/620022]    Loss: 0.006411   Batch Acc: 87.50
[Train] Epoch: 2 [494144/620022]    Loss: 0.009373   Batch Acc: 76.56
[Train] Epoch: 2 [494208/620022]    Loss: 0.008589   Batch Acc: 76.56
[Train] Epoch: 2 [494272/620022]    Loss: 0.010971   Batch Acc: 68.75
[Train] Epoch: 2 [494336/620022]    Loss: 0.009098   Batch Acc: 73.44
[Train] Epoch: 2 [494400/620022]    Loss: 0.008591   Batch Acc: 73.44
[Train] Epoch: 2 [494464/620022]    Loss: 0.008712   Batch Acc: 75.00
[Train] Epoch: 2 [494528/620022]    Loss: 0.009026   Batch Acc: 76.56
[Train] Epoch: 2 [494592/620022]    Loss: 0.008790   Batch Acc: 75.00
[Train] Epoch: 2 [494656/620022]    Loss: 0.007347   Batch Acc: 82.81
[Train] Epoch: 2 [494720/620022]    Loss: 0.009409   Batch Acc: 78.12
[Train] Epoch: 2 [494784/620022]    Loss: 0.009275   Batch Acc: 78.12
[Train] Epoch: 2 [494848/620022]    Loss: 0.009134   Batch Acc: 76.56
[Train] Epoch: 2 [494912/620022]    Loss: 0.007935   Batch Acc: 82.81
[Train] Epoch: 2 [494976/620022]    Loss: 0.006887   Batch Acc: 79.69
[Train] Epoch: 2 [495040/620022]    Loss: 0.005819   Batch Acc: 85.94
[Train] Epoch: 2 [495104/620022]    Loss: 0.008585   Batch Acc: 75.00
[Train] Epoch: 2 [495168/620022]    Loss: 0.008634   Batch Acc: 76.56
[Train] Epoch: 2 [495232/620022]    Loss: 0.008656   Batch Acc: 76.56
[Train] Epoch: 2 [495296/620022]    Loss: 0.008833   Batch Acc: 78.12
[Train] Epoch: 2 [495360/620022]    Loss: 0.008496   Batch Acc: 79.69
[Train] Epoch: 2 [495424/620022]    Loss: 0.009580   Batch Acc: 76.56
[Train] Epoch: 2 [495488/620022]    Loss: 0.006506   Batch Acc: 84.38
[Train] Epoch: 2 [495552/620022]    Loss: 0.008787   Batch Acc: 84.38
[Train] Epoch: 2 [495616/620022]    Loss: 0.008159   Batch Acc: 71.88
[Train] Epoch: 2 [495680/620022]    Loss: 0.009500   Batch Acc: 71.88
[Train] Epoch: 2 [495744/620022]    Loss: 0.008199   Batch Acc: 81.25
[Train] Epoch: 2 [495808/620022]    Loss: 0.010268   Batch Acc: 68.75
[Train] Epoch: 2 [495872/620022]    Loss: 0.011170   Batch Acc: 64.06
[Train] Epoch: 2 [495936/620022]    Loss: 0.009097   Batch Acc: 78.12
[Train] Epoch: 2 [496000/620022]    Loss: 0.010170   Batch Acc: 70.31
[Train] Epoch: 2 [496064/620022]    Loss: 0.008447   Batch Acc: 75.00
[Train] Epoch: 2 [496128/620022]    Loss: 0.008893   Batch Acc: 76.56
[Train] Epoch: 2 [496192/620022]    Loss: 0.006581   Batch Acc: 92.19
[Train] Epoch: 2 [496256/620022]    Loss: 0.006878   Batch Acc: 81.25
[Train] Epoch: 2 [496320/620022]    Loss: 0.007197   Batch Acc: 89.06
[Train] Epoch: 2 [496384/620022]    Loss: 0.007882   Batch Acc: 76.56
[Train] Epoch: 2 [496448/620022]    Loss: 0.008977   Batch Acc: 75.00
[Train] Epoch: 2 [496512/620022]    Loss: 0.008946   Batch Acc: 71.88
[Train] Epoch: 2 [496576/620022]    Loss: 0.007450   Batch Acc: 78.12
[Train] Epoch: 2 [496640/620022]    Loss: 0.008412   Batch Acc: 81.25
[Train] Epoch: 2 [496704/620022]    Loss: 0.011150   Batch Acc: 67.19
[Train] Epoch: 2 [496768/620022]    Loss: 0.008432   Batch Acc: 79.69
[Train] Epoch: 2 [496832/620022]    Loss: 0.008479   Batch Acc: 79.69
[Train] Epoch: 2 [496896/620022]    Loss: 0.010566   Batch Acc: 68.75
[Train] Epoch: 2 [496960/620022]    Loss: 0.007336   Batch Acc: 82.81
[Train] Epoch: 2 [497024/620022]    Loss: 0.007431   Batch Acc: 81.25
[Train] Epoch: 2 [497088/620022]    Loss: 0.007525   Batch Acc: 82.81
[Train] Epoch: 2 [497152/620022]    Loss: 0.009842   Batch Acc: 78.12
[Train] Epoch: 2 [497216/620022]    Loss: 0.007572   Batch Acc: 81.25
[Train] Epoch: 2 [497280/620022]    Loss: 0.008013   Batch Acc: 79.69
[Train] Epoch: 2 [497344/620022]    Loss: 0.008100   Batch Acc: 78.12
[Train] Epoch: 2 [497408/620022]    Loss: 0.007944   Batch Acc: 85.94
[Train] Epoch: 2 [497472/620022]    Loss: 0.010033   Batch Acc: 78.12
[Train] Epoch: 2 [497536/620022]    Loss: 0.008596   Batch Acc: 85.94
[Train] Epoch: 2 [497600/620022]    Loss: 0.008774   Batch Acc: 75.00
[Train] Epoch: 2 [497664/620022]    Loss: 0.007760   Batch Acc: 84.38
[Train] Epoch: 2 [497728/620022]    Loss: 0.007575   Batch Acc: 78.12
[Train] Epoch: 2 [497792/620022]    Loss: 0.010099   Batch Acc: 78.12
[Train] Epoch: 2 [497856/620022]    Loss: 0.009632   Batch Acc: 67.19
[Train] Epoch: 2 [497920/620022]    Loss: 0.009724   Batch Acc: 71.88
[Train] Epoch: 2 [497984/620022]    Loss: 0.008718   Batch Acc: 81.25
[Train] Epoch: 2 [498048/620022]    Loss: 0.008252   Batch Acc: 79.69
[Train] Epoch: 2 [498112/620022]    Loss: 0.011268   Batch Acc: 70.31
[Train] Epoch: 2 [498176/620022]    Loss: 0.007345   Batch Acc: 85.94
[Train] Epoch: 2 [498240/620022]    Loss: 0.008257   Batch Acc: 76.56
[Train] Epoch: 2 [498304/620022]    Loss: 0.008267   Batch Acc: 81.25
[Train] Epoch: 2 [498368/620022]    Loss: 0.006565   Batch Acc: 84.38
[Train] Epoch: 2 [498432/620022]    Loss: 0.008513   Batch Acc: 78.12
[Train] Epoch: 2 [498496/620022]    Loss: 0.009945   Batch Acc: 73.44
[Train] Epoch: 2 [498560/620022]    Loss: 0.007816   Batch Acc: 82.81
[Train] Epoch: 2 [498624/620022]    Loss: 0.009769   Batch Acc: 81.25
[Train] Epoch: 2 [498688/620022]    Loss: 0.009164   Batch Acc: 71.88
[Train] Epoch: 2 [498752/620022]    Loss: 0.012469   Batch Acc: 65.62
[Train] Epoch: 2 [498816/620022]    Loss: 0.010234   Batch Acc: 70.31
[Train] Epoch: 2 [498880/620022]    Loss: 0.008268   Batch Acc: 75.00
[Train] Epoch: 2 [498944/620022]    Loss: 0.008923   Batch Acc: 81.25
[Train] Epoch: 2 [499008/620022]    Loss: 0.008479   Batch Acc: 79.69
[Train] Epoch: 2 [499072/620022]    Loss: 0.009167   Batch Acc: 81.25
[Train] Epoch: 2 [499136/620022]    Loss: 0.009140   Batch Acc: 75.00
[Train] Epoch: 2 [499200/620022]    Loss: 0.007507   Batch Acc: 84.38
[Train] Epoch: 2 [499264/620022]    Loss: 0.009263   Batch Acc: 73.44
[Train] Epoch: 2 [499328/620022]    Loss: 0.009431   Batch Acc: 71.88
[Train] Epoch: 2 [499392/620022]    Loss: 0.008039   Batch Acc: 81.25
[Train] Epoch: 2 [499456/620022]    Loss: 0.010614   Batch Acc: 73.44
[Train] Epoch: 2 [499520/620022]    Loss: 0.008311   Batch Acc: 79.69
[Train] Epoch: 2 [499584/620022]    Loss: 0.006890   Batch Acc: 89.06
[Train] Epoch: 2 [499648/620022]    Loss: 0.010509   Batch Acc: 71.88
[Train] Epoch: 2 [499712/620022]    Loss: 0.010734   Batch Acc: 71.88
[Train] Epoch: 2 [499776/620022]    Loss: 0.005546   Batch Acc: 89.06
[Train] Epoch: 2 [499840/620022]    Loss: 0.009399   Batch Acc: 82.81
[Train] Epoch: 2 [499904/620022]    Loss: 0.008562   Batch Acc: 78.12
[Train] Epoch: 2 [499968/620022]    Loss: 0.006676   Batch Acc: 82.81
[Train] Epoch: 2 [500032/620022]    Loss: 0.008724   Batch Acc: 73.44
[Train] Epoch: 2 [500096/620022]    Loss: 0.006747   Batch Acc: 85.94
[Train] Epoch: 2 [500160/620022]    Loss: 0.010466   Batch Acc: 70.31
[Train] Epoch: 2 [500224/620022]    Loss: 0.008850   Batch Acc: 79.69
[Train] Epoch: 2 [500288/620022]    Loss: 0.011681   Batch Acc: 67.19
[Train] Epoch: 2 [500352/620022]    Loss: 0.007300   Batch Acc: 79.69
[Train] Epoch: 2 [500416/620022]    Loss: 0.009286   Batch Acc: 79.69
[Train] Epoch: 2 [500480/620022]    Loss: 0.009258   Batch Acc: 78.12
[Train] Epoch: 2 [500544/620022]    Loss: 0.009537   Batch Acc: 71.88
[Train] Epoch: 2 [500608/620022]    Loss: 0.008613   Batch Acc: 81.25
[Train] Epoch: 2 [500672/620022]    Loss: 0.009314   Batch Acc: 79.69
[Train] Epoch: 2 [500736/620022]    Loss: 0.008653   Batch Acc: 75.00
[Train] Epoch: 2 [500800/620022]    Loss: 0.010055   Batch Acc: 71.88
[Train] Epoch: 2 [500864/620022]    Loss: 0.010649   Batch Acc: 70.31
[Train] Epoch: 2 [500928/620022]    Loss: 0.008748   Batch Acc: 79.69
[Train] Epoch: 2 [500992/620022]    Loss: 0.010065   Batch Acc: 73.44
[Train] Epoch: 2 [501056/620022]    Loss: 0.010349   Batch Acc: 75.00
[Train] Epoch: 2 [501120/620022]    Loss: 0.009194   Batch Acc: 78.12
[Train] Epoch: 2 [501184/620022]    Loss: 0.009322   Batch Acc: 73.44
[Train] Epoch: 2 [501248/620022]    Loss: 0.008176   Batch Acc: 76.56
[Train] Epoch: 2 [501312/620022]    Loss: 0.007386   Batch Acc: 84.38
[Train] Epoch: 2 [501376/620022]    Loss: 0.009497   Batch Acc: 70.31
[Train] Epoch: 2 [501440/620022]    Loss: 0.010837   Batch Acc: 67.19
[Train] Epoch: 2 [501504/620022]    Loss: 0.009169   Batch Acc: 71.88
[Train] Epoch: 2 [501568/620022]    Loss: 0.007747   Batch Acc: 79.69
[Train] Epoch: 2 [501632/620022]    Loss: 0.006105   Batch Acc: 89.06
[Train] Epoch: 2 [501696/620022]    Loss: 0.009123   Batch Acc: 76.56
[Train] Epoch: 2 [501760/620022]    Loss: 0.008356   Batch Acc: 78.12
[Train] Epoch: 2 [501824/620022]    Loss: 0.008313   Batch Acc: 84.38
[Train] Epoch: 2 [501888/620022]    Loss: 0.007625   Batch Acc: 84.38
[Train] Epoch: 2 [501952/620022]    Loss: 0.008161   Batch Acc: 78.12
[Train] Epoch: 2 [502016/620022]    Loss: 0.008891   Batch Acc: 73.44
[Train] Epoch: 2 [502080/620022]    Loss: 0.007784   Batch Acc: 81.25
[Train] Epoch: 2 [502144/620022]    Loss: 0.010177   Batch Acc: 75.00
[Train] Epoch: 2 [502208/620022]    Loss: 0.007282   Batch Acc: 87.50
[Train] Epoch: 2 [502272/620022]    Loss: 0.009770   Batch Acc: 79.69
[Train] Epoch: 2 [502336/620022]    Loss: 0.011809   Batch Acc: 70.31
[Train] Epoch: 2 [502400/620022]    Loss: 0.009212   Batch Acc: 75.00
[Train] Epoch: 2 [502464/620022]    Loss: 0.006658   Batch Acc: 79.69
[Train] Epoch: 2 [502528/620022]    Loss: 0.008325   Batch Acc: 78.12
[Train] Epoch: 2 [502592/620022]    Loss: 0.009586   Batch Acc: 68.75
[Train] Epoch: 2 [502656/620022]    Loss: 0.008022   Batch Acc: 82.81
[Train] Epoch: 2 [502720/620022]    Loss: 0.008529   Batch Acc: 79.69
[Train] Epoch: 2 [502784/620022]    Loss: 0.007402   Batch Acc: 84.38
[Train] Epoch: 2 [502848/620022]    Loss: 0.007929   Batch Acc: 78.12
[Train] Epoch: 2 [502912/620022]    Loss: 0.009462   Batch Acc: 65.62
[Train] Epoch: 2 [502976/620022]    Loss: 0.008441   Batch Acc: 76.56
[Train] Epoch: 2 [503040/620022]    Loss: 0.007186   Batch Acc: 81.25
[Train] Epoch: 2 [503104/620022]    Loss: 0.007115   Batch Acc: 79.69
[Train] Epoch: 2 [503168/620022]    Loss: 0.010876   Batch Acc: 70.31
[Train] Epoch: 2 [503232/620022]    Loss: 0.008129   Batch Acc: 79.69
[Train] Epoch: 2 [503296/620022]    Loss: 0.009319   Batch Acc: 78.12
[Train] Epoch: 2 [503360/620022]    Loss: 0.008855   Batch Acc: 76.56
[Train] Epoch: 2 [503424/620022]    Loss: 0.008534   Batch Acc: 79.69
[Train] Epoch: 2 [503488/620022]    Loss: 0.010598   Batch Acc: 68.75
[Train] Epoch: 2 [503552/620022]    Loss: 0.007631   Batch Acc: 82.81
[Train] Epoch: 2 [503616/620022]    Loss: 0.009398   Batch Acc: 79.69
[Train] Epoch: 2 [503680/620022]    Loss: 0.008931   Batch Acc: 76.56
[Train] Epoch: 2 [503744/620022]    Loss: 0.008672   Batch Acc: 73.44
[Train] Epoch: 2 [503808/620022]    Loss: 0.008659   Batch Acc: 79.69
[Train] Epoch: 2 [503872/620022]    Loss: 0.008700   Batch Acc: 73.44
[Train] Epoch: 2 [503936/620022]    Loss: 0.007642   Batch Acc: 81.25
[Train] Epoch: 2 [504000/620022]    Loss: 0.007882   Batch Acc: 81.25
[Train] Epoch: 2 [504064/620022]    Loss: 0.009261   Batch Acc: 67.19
[Train] Epoch: 2 [504128/620022]    Loss: 0.008136   Batch Acc: 78.12
[Train] Epoch: 2 [504192/620022]    Loss: 0.008188   Batch Acc: 84.38
[Train] Epoch: 2 [504256/620022]    Loss: 0.006151   Batch Acc: 85.94
[Train] Epoch: 2 [504320/620022]    Loss: 0.007889   Batch Acc: 84.38
[Train] Epoch: 2 [504384/620022]    Loss: 0.010330   Batch Acc: 73.44
[Train] Epoch: 2 [504448/620022]    Loss: 0.009234   Batch Acc: 75.00
[Train] Epoch: 2 [504512/620022]    Loss: 0.009568   Batch Acc: 78.12
[Train] Epoch: 2 [504576/620022]    Loss: 0.010007   Batch Acc: 75.00
[Train] Epoch: 2 [504640/620022]    Loss: 0.007059   Batch Acc: 79.69
[Train] Epoch: 2 [504704/620022]    Loss: 0.009557   Batch Acc: 75.00
[Train] Epoch: 2 [504768/620022]    Loss: 0.008784   Batch Acc: 81.25
[Train] Epoch: 2 [504832/620022]    Loss: 0.008912   Batch Acc: 81.25
[Train] Epoch: 2 [504896/620022]    Loss: 0.009518   Batch Acc: 73.44
[Train] Epoch: 2 [504960/620022]    Loss: 0.006854   Batch Acc: 85.94
[Train] Epoch: 2 [505024/620022]    Loss: 0.007824   Batch Acc: 78.12
[Train] Epoch: 2 [505088/620022]    Loss: 0.008430   Batch Acc: 85.94
[Train] Epoch: 2 [505152/620022]    Loss: 0.009172   Batch Acc: 76.56
[Train] Epoch: 2 [505216/620022]    Loss: 0.009945   Batch Acc: 73.44
[Train] Epoch: 2 [505280/620022]    Loss: 0.007686   Batch Acc: 84.38
[Train] Epoch: 2 [505344/620022]    Loss: 0.009628   Batch Acc: 70.31
[Train] Epoch: 2 [505408/620022]    Loss: 0.009579   Batch Acc: 73.44
[Train] Epoch: 2 [505472/620022]    Loss: 0.008220   Batch Acc: 79.69
[Train] Epoch: 2 [505536/620022]    Loss: 0.009569   Batch Acc: 76.56
[Train] Epoch: 2 [505600/620022]    Loss: 0.006148   Batch Acc: 84.38
[Train] Epoch: 2 [505664/620022]    Loss: 0.008088   Batch Acc: 84.38
[Train] Epoch: 2 [505728/620022]    Loss: 0.008589   Batch Acc: 81.25
[Train] Epoch: 2 [505792/620022]    Loss: 0.009823   Batch Acc: 75.00
[Train] Epoch: 2 [505856/620022]    Loss: 0.010202   Batch Acc: 75.00
[Train] Epoch: 2 [505920/620022]    Loss: 0.011248   Batch Acc: 71.88
[Train] Epoch: 2 [505984/620022]    Loss: 0.008244   Batch Acc: 76.56
[Train] Epoch: 2 [506048/620022]    Loss: 0.007775   Batch Acc: 81.25
[Train] Epoch: 2 [506112/620022]    Loss: 0.008665   Batch Acc: 79.69
[Train] Epoch: 2 [506176/620022]    Loss: 0.007989   Batch Acc: 73.44
[Train] Epoch: 2 [506240/620022]    Loss: 0.009826   Batch Acc: 70.31
[Train] Epoch: 2 [506304/620022]    Loss: 0.010457   Batch Acc: 73.44
[Train] Epoch: 2 [506368/620022]    Loss: 0.009960   Batch Acc: 81.25
[Train] Epoch: 2 [506432/620022]    Loss: 0.009848   Batch Acc: 71.88
[Train] Epoch: 2 [506496/620022]    Loss: 0.010614   Batch Acc: 73.44
[Train] Epoch: 2 [506560/620022]    Loss: 0.006543   Batch Acc: 89.06
[Train] Epoch: 2 [506624/620022]    Loss: 0.007905   Batch Acc: 78.12
[Train] Epoch: 2 [506688/620022]    Loss: 0.009543   Batch Acc: 70.31
[Train] Epoch: 2 [506752/620022]    Loss: 0.008609   Batch Acc: 81.25
[Train] Epoch: 2 [506816/620022]    Loss: 0.008902   Batch Acc: 73.44
[Train] Epoch: 2 [506880/620022]    Loss: 0.007998   Batch Acc: 82.81
[Train] Epoch: 2 [506944/620022]    Loss: 0.009449   Batch Acc: 78.12
[Train] Epoch: 2 [507008/620022]    Loss: 0.006406   Batch Acc: 89.06
[Train] Epoch: 2 [507072/620022]    Loss: 0.011614   Batch Acc: 75.00
[Train] Epoch: 2 [507136/620022]    Loss: 0.008861   Batch Acc: 75.00
[Train] Epoch: 2 [507200/620022]    Loss: 0.008904   Batch Acc: 76.56
[Train] Epoch: 2 [507264/620022]    Loss: 0.010031   Batch Acc: 68.75
[Train] Epoch: 2 [507328/620022]    Loss: 0.008194   Batch Acc: 81.25
[Train] Epoch: 2 [507392/620022]    Loss: 0.008784   Batch Acc: 78.12
[Train] Epoch: 2 [507456/620022]    Loss: 0.010391   Batch Acc: 68.75
[Train] Epoch: 2 [507520/620022]    Loss: 0.007974   Batch Acc: 84.38
[Train] Epoch: 2 [507584/620022]    Loss: 0.007832   Batch Acc: 76.56
[Train] Epoch: 2 [507648/620022]    Loss: 0.008739   Batch Acc: 79.69
[Train] Epoch: 2 [507712/620022]    Loss: 0.008178   Batch Acc: 79.69
[Train] Epoch: 2 [507776/620022]    Loss: 0.008809   Batch Acc: 79.69
[Train] Epoch: 2 [507840/620022]    Loss: 0.010254   Batch Acc: 75.00
[Train] Epoch: 2 [507904/620022]    Loss: 0.009845   Batch Acc: 75.00
[Train] Epoch: 2 [507968/620022]    Loss: 0.009043   Batch Acc: 76.56
[Train] Epoch: 2 [508032/620022]    Loss: 0.007151   Batch Acc: 79.69
[Train] Epoch: 2 [508096/620022]    Loss: 0.007352   Batch Acc: 84.38
[Train] Epoch: 2 [508160/620022]    Loss: 0.007072   Batch Acc: 79.69
[Train] Epoch: 2 [508224/620022]    Loss: 0.007592   Batch Acc: 78.12
[Train] Epoch: 2 [508288/620022]    Loss: 0.009024   Batch Acc: 78.12
[Train] Epoch: 2 [508352/620022]    Loss: 0.008027   Batch Acc: 75.00
[Train] Epoch: 2 [508416/620022]    Loss: 0.008462   Batch Acc: 76.56
[Train] Epoch: 2 [508480/620022]    Loss: 0.008382   Batch Acc: 79.69
[Train] Epoch: 2 [508544/620022]    Loss: 0.008896   Batch Acc: 76.56
[Train] Epoch: 2 [508608/620022]    Loss: 0.007486   Batch Acc: 82.81
[Train] Epoch: 2 [508672/620022]    Loss: 0.009649   Batch Acc: 75.00
[Train] Epoch: 2 [508736/620022]    Loss: 0.009742   Batch Acc: 71.88
[Train] Epoch: 2 [508800/620022]    Loss: 0.009138   Batch Acc: 73.44
[Train] Epoch: 2 [508864/620022]    Loss: 0.009458   Batch Acc: 73.44
[Train] Epoch: 2 [508928/620022]    Loss: 0.010996   Batch Acc: 68.75
[Train] Epoch: 2 [508992/620022]    Loss: 0.005957   Batch Acc: 87.50
[Train] Epoch: 2 [509056/620022]    Loss: 0.007502   Batch Acc: 79.69
[Train] Epoch: 2 [509120/620022]    Loss: 0.010729   Batch Acc: 64.06
[Train] Epoch: 2 [509184/620022]    Loss: 0.006457   Batch Acc: 87.50
[Train] Epoch: 2 [509248/620022]    Loss: 0.008342   Batch Acc: 78.12
[Train] Epoch: 2 [509312/620022]    Loss: 0.010340   Batch Acc: 67.19
[Train] Epoch: 2 [509376/620022]    Loss: 0.008539   Batch Acc: 76.56
[Train] Epoch: 2 [509440/620022]    Loss: 0.007188   Batch Acc: 81.25
[Train] Epoch: 2 [509504/620022]    Loss: 0.011050   Batch Acc: 71.88
[Train] Epoch: 2 [509568/620022]    Loss: 0.006944   Batch Acc: 79.69
[Train] Epoch: 2 [509632/620022]    Loss: 0.008044   Batch Acc: 79.69
[Train] Epoch: 2 [509696/620022]    Loss: 0.007893   Batch Acc: 73.44
[Train] Epoch: 2 [509760/620022]    Loss: 0.009592   Batch Acc: 79.69
[Train] Epoch: 2 [509824/620022]    Loss: 0.008485   Batch Acc: 76.56
[Train] Epoch: 2 [509888/620022]    Loss: 0.011750   Batch Acc: 65.62
[Train] Epoch: 2 [509952/620022]    Loss: 0.008563   Batch Acc: 78.12
[Train] Epoch: 2 [510016/620022]    Loss: 0.008815   Batch Acc: 75.00
[Train] Epoch: 2 [510080/620022]    Loss: 0.007729   Batch Acc: 82.81
[Train] Epoch: 2 [510144/620022]    Loss: 0.009510   Batch Acc: 73.44
[Train] Epoch: 2 [510208/620022]    Loss: 0.007207   Batch Acc: 79.69
[Train] Epoch: 2 [510272/620022]    Loss: 0.009330   Batch Acc: 76.56
[Train] Epoch: 2 [510336/620022]    Loss: 0.008472   Batch Acc: 85.94
[Train] Epoch: 2 [510400/620022]    Loss: 0.006080   Batch Acc: 89.06
[Train] Epoch: 2 [510464/620022]    Loss: 0.010312   Batch Acc: 81.25
[Train] Epoch: 2 [510528/620022]    Loss: 0.007110   Batch Acc: 81.25
[Train] Epoch: 2 [510592/620022]    Loss: 0.007132   Batch Acc: 82.81
[Train] Epoch: 2 [510656/620022]    Loss: 0.008805   Batch Acc: 76.56
[Train] Epoch: 2 [510720/620022]    Loss: 0.007471   Batch Acc: 79.69
[Train] Epoch: 2 [510784/620022]    Loss: 0.006914   Batch Acc: 79.69
[Train] Epoch: 2 [510848/620022]    Loss: 0.009029   Batch Acc: 70.31
[Train] Epoch: 2 [510912/620022]    Loss: 0.006141   Batch Acc: 84.38
[Train] Epoch: 2 [510976/620022]    Loss: 0.008146   Batch Acc: 75.00
[Train] Epoch: 2 [511040/620022]    Loss: 0.007586   Batch Acc: 76.56
[Train] Epoch: 2 [511104/620022]    Loss: 0.010436   Batch Acc: 68.75
[Train] Epoch: 2 [511168/620022]    Loss: 0.009708   Batch Acc: 79.69
[Train] Epoch: 2 [511232/620022]    Loss: 0.007880   Batch Acc: 76.56
[Train] Epoch: 2 [511296/620022]    Loss: 0.008680   Batch Acc: 81.25
[Train] Epoch: 2 [511360/620022]    Loss: 0.006595   Batch Acc: 84.38
[Train] Epoch: 2 [511424/620022]    Loss: 0.008203   Batch Acc: 79.69
[Train] Epoch: 2 [511488/620022]    Loss: 0.008336   Batch Acc: 82.81
[Train] Epoch: 2 [511552/620022]    Loss: 0.009047   Batch Acc: 76.56
[Train] Epoch: 2 [511616/620022]    Loss: 0.011560   Batch Acc: 73.44
[Train] Epoch: 2 [511680/620022]    Loss: 0.008857   Batch Acc: 81.25
[Train] Epoch: 2 [511744/620022]    Loss: 0.011403   Batch Acc: 73.44
[Train] Epoch: 2 [511808/620022]    Loss: 0.008241   Batch Acc: 78.12
[Train] Epoch: 2 [511872/620022]    Loss: 0.008246   Batch Acc: 75.00
[Train] Epoch: 2 [511936/620022]    Loss: 0.009196   Batch Acc: 73.44
[Train] Epoch: 2 [512000/620022]    Loss: 0.007765   Batch Acc: 82.81
[Train] Epoch: 2 [512064/620022]    Loss: 0.007318   Batch Acc: 84.38
[Train] Epoch: 2 [512128/620022]    Loss: 0.007759   Batch Acc: 81.25
[Train] Epoch: 2 [512192/620022]    Loss: 0.008308   Batch Acc: 76.56
[Train] Epoch: 2 [512256/620022]    Loss: 0.007180   Batch Acc: 78.12
[Train] Epoch: 2 [512320/620022]    Loss: 0.007766   Batch Acc: 78.12
[Train] Epoch: 2 [512384/620022]    Loss: 0.008942   Batch Acc: 67.19
[Train] Epoch: 2 [512448/620022]    Loss: 0.009893   Batch Acc: 76.56
[Train] Epoch: 2 [512512/620022]    Loss: 0.009770   Batch Acc: 71.88
[Train] Epoch: 2 [512576/620022]    Loss: 0.008704   Batch Acc: 81.25
[Train] Epoch: 2 [512640/620022]    Loss: 0.008016   Batch Acc: 75.00
[Train] Epoch: 2 [512704/620022]    Loss: 0.009525   Batch Acc: 76.56
[Train] Epoch: 2 [512768/620022]    Loss: 0.011561   Batch Acc: 65.62
[Train] Epoch: 2 [512832/620022]    Loss: 0.008158   Batch Acc: 84.38
[Train] Epoch: 2 [512896/620022]    Loss: 0.006909   Batch Acc: 81.25
[Train] Epoch: 2 [512960/620022]    Loss: 0.010172   Batch Acc: 73.44
[Train] Epoch: 2 [513024/620022]    Loss: 0.008815   Batch Acc: 78.12
[Train] Epoch: 2 [513088/620022]    Loss: 0.010187   Batch Acc: 75.00
[Train] Epoch: 2 [513152/620022]    Loss: 0.007882   Batch Acc: 85.94
[Train] Epoch: 2 [513216/620022]    Loss: 0.008774   Batch Acc: 79.69
[Train] Epoch: 2 [513280/620022]    Loss: 0.008307   Batch Acc: 78.12
[Train] Epoch: 2 [513344/620022]    Loss: 0.008551   Batch Acc: 75.00
[Train] Epoch: 2 [513408/620022]    Loss: 0.008036   Batch Acc: 79.69
[Train] Epoch: 2 [513472/620022]    Loss: 0.006905   Batch Acc: 84.38
[Train] Epoch: 2 [513536/620022]    Loss: 0.007200   Batch Acc: 87.50
[Train] Epoch: 2 [513600/620022]    Loss: 0.007729   Batch Acc: 81.25
[Train] Epoch: 2 [513664/620022]    Loss: 0.009798   Batch Acc: 67.19
[Train] Epoch: 2 [513728/620022]    Loss: 0.008993   Batch Acc: 78.12
[Train] Epoch: 2 [513792/620022]    Loss: 0.008078   Batch Acc: 79.69
[Train] Epoch: 2 [513856/620022]    Loss: 0.011511   Batch Acc: 73.44
[Train] Epoch: 2 [513920/620022]    Loss: 0.006512   Batch Acc: 82.81
[Train] Epoch: 2 [513984/620022]    Loss: 0.006284   Batch Acc: 87.50
[Train] Epoch: 2 [514048/620022]    Loss: 0.007340   Batch Acc: 81.25
[Train] Epoch: 2 [514112/620022]    Loss: 0.007144   Batch Acc: 81.25
[Train] Epoch: 2 [514176/620022]    Loss: 0.009901   Batch Acc: 71.88
[Train] Epoch: 2 [514240/620022]    Loss: 0.008642   Batch Acc: 81.25
[Train] Epoch: 2 [514304/620022]    Loss: 0.009211   Batch Acc: 75.00
[Train] Epoch: 2 [514368/620022]    Loss: 0.007545   Batch Acc: 81.25
[Train] Epoch: 2 [514432/620022]    Loss: 0.008493   Batch Acc: 79.69
[Train] Epoch: 2 [514496/620022]    Loss: 0.009747   Batch Acc: 78.12
[Train] Epoch: 2 [514560/620022]    Loss: 0.009189   Batch Acc: 71.88
[Train] Epoch: 2 [514624/620022]    Loss: 0.007289   Batch Acc: 84.38
[Train] Epoch: 2 [514688/620022]    Loss: 0.012063   Batch Acc: 67.19
[Train] Epoch: 2 [514752/620022]    Loss: 0.007673   Batch Acc: 81.25
[Train] Epoch: 2 [514816/620022]    Loss: 0.009995   Batch Acc: 71.88
[Train] Epoch: 2 [514880/620022]    Loss: 0.008999   Batch Acc: 78.12
[Train] Epoch: 2 [514944/620022]    Loss: 0.010125   Batch Acc: 70.31
[Train] Epoch: 2 [515008/620022]    Loss: 0.011166   Batch Acc: 70.31
[Train] Epoch: 2 [515072/620022]    Loss: 0.008059   Batch Acc: 73.44
[Train] Epoch: 2 [515136/620022]    Loss: 0.007273   Batch Acc: 79.69
[Train] Epoch: 2 [515200/620022]    Loss: 0.009659   Batch Acc: 71.88
[Train] Epoch: 2 [515264/620022]    Loss: 0.009343   Batch Acc: 76.56
[Train] Epoch: 2 [515328/620022]    Loss: 0.009749   Batch Acc: 76.56
[Train] Epoch: 2 [515392/620022]    Loss: 0.008166   Batch Acc: 78.12
[Train] Epoch: 2 [515456/620022]    Loss: 0.009063   Batch Acc: 79.69
[Train] Epoch: 2 [515520/620022]    Loss: 0.008578   Batch Acc: 75.00
[Train] Epoch: 2 [515584/620022]    Loss: 0.007383   Batch Acc: 81.25
[Train] Epoch: 2 [515648/620022]    Loss: 0.006978   Batch Acc: 81.25
[Train] Epoch: 2 [515712/620022]    Loss: 0.009441   Batch Acc: 78.12
[Train] Epoch: 2 [515776/620022]    Loss: 0.005789   Batch Acc: 89.06
[Train] Epoch: 2 [515840/620022]    Loss: 0.009145   Batch Acc: 71.88
[Train] Epoch: 2 [515904/620022]    Loss: 0.008104   Batch Acc: 81.25
[Train] Epoch: 2 [515968/620022]    Loss: 0.007201   Batch Acc: 84.38
[Train] Epoch: 2 [516032/620022]    Loss: 0.007975   Batch Acc: 79.69
[Train] Epoch: 2 [516096/620022]    Loss: 0.007199   Batch Acc: 84.38
[Train] Epoch: 2 [516160/620022]    Loss: 0.008655   Batch Acc: 81.25
[Train] Epoch: 2 [516224/620022]    Loss: 0.008759   Batch Acc: 78.12
[Train] Epoch: 2 [516288/620022]    Loss: 0.008871   Batch Acc: 78.12
[Train] Epoch: 2 [516352/620022]    Loss: 0.007444   Batch Acc: 82.81
[Train] Epoch: 2 [516416/620022]    Loss: 0.009337   Batch Acc: 75.00
[Train] Epoch: 2 [516480/620022]    Loss: 0.009437   Batch Acc: 70.31
[Train] Epoch: 2 [516544/620022]    Loss: 0.007120   Batch Acc: 81.25
[Train] Epoch: 2 [516608/620022]    Loss: 0.008688   Batch Acc: 76.56
[Train] Epoch: 2 [516672/620022]    Loss: 0.006085   Batch Acc: 87.50
[Train] Epoch: 2 [516736/620022]    Loss: 0.007051   Batch Acc: 81.25
[Train] Epoch: 2 [516800/620022]    Loss: 0.008100   Batch Acc: 78.12
[Train] Epoch: 2 [516864/620022]    Loss: 0.009597   Batch Acc: 75.00
[Train] Epoch: 2 [516928/620022]    Loss: 0.007169   Batch Acc: 87.50
[Train] Epoch: 2 [516992/620022]    Loss: 0.008857   Batch Acc: 78.12
[Train] Epoch: 2 [517056/620022]    Loss: 0.009759   Batch Acc: 75.00
[Train] Epoch: 2 [517120/620022]    Loss: 0.008187   Batch Acc: 82.81
[Train] Epoch: 2 [517184/620022]    Loss: 0.009396   Batch Acc: 76.56
[Train] Epoch: 2 [517248/620022]    Loss: 0.008963   Batch Acc: 78.12
[Train] Epoch: 2 [517312/620022]    Loss: 0.007951   Batch Acc: 78.12
[Train] Epoch: 2 [517376/620022]    Loss: 0.008377   Batch Acc: 82.81
[Train] Epoch: 2 [517440/620022]    Loss: 0.008352   Batch Acc: 81.25
[Train] Epoch: 2 [517504/620022]    Loss: 0.009440   Batch Acc: 75.00
[Train] Epoch: 2 [517568/620022]    Loss: 0.007583   Batch Acc: 79.69
[Train] Epoch: 2 [517632/620022]    Loss: 0.012067   Batch Acc: 65.62
[Train] Epoch: 2 [517696/620022]    Loss: 0.010709   Batch Acc: 71.88
[Train] Epoch: 2 [517760/620022]    Loss: 0.009100   Batch Acc: 81.25
[Train] Epoch: 2 [517824/620022]    Loss: 0.010329   Batch Acc: 73.44
[Train] Epoch: 2 [517888/620022]    Loss: 0.010856   Batch Acc: 71.88
[Train] Epoch: 2 [517952/620022]    Loss: 0.008433   Batch Acc: 81.25
[Train] Epoch: 2 [518016/620022]    Loss: 0.008818   Batch Acc: 78.12
[Train] Epoch: 2 [518080/620022]    Loss: 0.008532   Batch Acc: 84.38
[Train] Epoch: 2 [518144/620022]    Loss: 0.010682   Batch Acc: 67.19
[Train] Epoch: 2 [518208/620022]    Loss: 0.006757   Batch Acc: 84.38
[Train] Epoch: 2 [518272/620022]    Loss: 0.009740   Batch Acc: 78.12
[Train] Epoch: 2 [518336/620022]    Loss: 0.009365   Batch Acc: 76.56
[Train] Epoch: 2 [518400/620022]    Loss: 0.008846   Batch Acc: 76.56
[Train] Epoch: 2 [518464/620022]    Loss: 0.010775   Batch Acc: 70.31
[Train] Epoch: 2 [518528/620022]    Loss: 0.007082   Batch Acc: 87.50
[Train] Epoch: 2 [518592/620022]    Loss: 0.009739   Batch Acc: 76.56
[Train] Epoch: 2 [518656/620022]    Loss: 0.008637   Batch Acc: 82.81
[Train] Epoch: 2 [518720/620022]    Loss: 0.009027   Batch Acc: 78.12
[Train] Epoch: 2 [518784/620022]    Loss: 0.009655   Batch Acc: 70.31
[Train] Epoch: 2 [518848/620022]    Loss: 0.008771   Batch Acc: 76.56
[Train] Epoch: 2 [518912/620022]    Loss: 0.009748   Batch Acc: 78.12
[Train] Epoch: 2 [518976/620022]    Loss: 0.009382   Batch Acc: 73.44
[Train] Epoch: 2 [519040/620022]    Loss: 0.008642   Batch Acc: 76.56
[Train] Epoch: 2 [519104/620022]    Loss: 0.008573   Batch Acc: 78.12
[Train] Epoch: 2 [519168/620022]    Loss: 0.007819   Batch Acc: 84.38
[Train] Epoch: 2 [519232/620022]    Loss: 0.009904   Batch Acc: 79.69
[Train] Epoch: 2 [519296/620022]    Loss: 0.007234   Batch Acc: 81.25
[Train] Epoch: 2 [519360/620022]    Loss: 0.010430   Batch Acc: 76.56
[Train] Epoch: 2 [519424/620022]    Loss: 0.008222   Batch Acc: 79.69
[Train] Epoch: 2 [519488/620022]    Loss: 0.008138   Batch Acc: 75.00
[Train] Epoch: 2 [519552/620022]    Loss: 0.007685   Batch Acc: 78.12
[Train] Epoch: 2 [519616/620022]    Loss: 0.008124   Batch Acc: 79.69
[Train] Epoch: 2 [519680/620022]    Loss: 0.009746   Batch Acc: 75.00
[Train] Epoch: 2 [519744/620022]    Loss: 0.008605   Batch Acc: 84.38
[Train] Epoch: 2 [519808/620022]    Loss: 0.011436   Batch Acc: 62.50
[Train] Epoch: 2 [519872/620022]    Loss: 0.009765   Batch Acc: 78.12
[Train] Epoch: 2 [519936/620022]    Loss: 0.007593   Batch Acc: 78.12
[Train] Epoch: 2 [520000/620022]    Loss: 0.008928   Batch Acc: 76.56
[Train] Epoch: 2 [520064/620022]    Loss: 0.008390   Batch Acc: 81.25
[Train] Epoch: 2 [520128/620022]    Loss: 0.008168   Batch Acc: 79.69
[Train] Epoch: 2 [520192/620022]    Loss: 0.006965   Batch Acc: 85.94
[Train] Epoch: 2 [520256/620022]    Loss: 0.008251   Batch Acc: 79.69
[Train] Epoch: 2 [520320/620022]    Loss: 0.008091   Batch Acc: 76.56
[Train] Epoch: 2 [520384/620022]    Loss: 0.008462   Batch Acc: 76.56
[Train] Epoch: 2 [520448/620022]    Loss: 0.008690   Batch Acc: 79.69
[Train] Epoch: 2 [520512/620022]    Loss: 0.008553   Batch Acc: 78.12
[Train] Epoch: 2 [520576/620022]    Loss: 0.008679   Batch Acc: 76.56
[Train] Epoch: 2 [520640/620022]    Loss: 0.007480   Batch Acc: 78.12
[Train] Epoch: 2 [520704/620022]    Loss: 0.010051   Batch Acc: 71.88
[Train] Epoch: 2 [520768/620022]    Loss: 0.008754   Batch Acc: 75.00
[Train] Epoch: 2 [520832/620022]    Loss: 0.007264   Batch Acc: 79.69
[Train] Epoch: 2 [520896/620022]    Loss: 0.008740   Batch Acc: 78.12
[Train] Epoch: 2 [520960/620022]    Loss: 0.006957   Batch Acc: 85.94
[Train] Epoch: 2 [521024/620022]    Loss: 0.007516   Batch Acc: 82.81
[Train] Epoch: 2 [521088/620022]    Loss: 0.008837   Batch Acc: 76.56
[Train] Epoch: 2 [521152/620022]    Loss: 0.008742   Batch Acc: 84.38
[Train] Epoch: 2 [521216/620022]    Loss: 0.009636   Batch Acc: 75.00
[Train] Epoch: 2 [521280/620022]    Loss: 0.010359   Batch Acc: 76.56
[Train] Epoch: 2 [521344/620022]    Loss: 0.009736   Batch Acc: 71.88
[Train] Epoch: 2 [521408/620022]    Loss: 0.007311   Batch Acc: 79.69
[Train] Epoch: 2 [521472/620022]    Loss: 0.008551   Batch Acc: 73.44
[Train] Epoch: 2 [521536/620022]    Loss: 0.008666   Batch Acc: 81.25
[Train] Epoch: 2 [521600/620022]    Loss: 0.007403   Batch Acc: 79.69
[Train] Epoch: 2 [521664/620022]    Loss: 0.009108   Batch Acc: 75.00
[Train] Epoch: 2 [521728/620022]    Loss: 0.007915   Batch Acc: 84.38
[Train] Epoch: 2 [521792/620022]    Loss: 0.008412   Batch Acc: 78.12
[Train] Epoch: 2 [521856/620022]    Loss: 0.006265   Batch Acc: 81.25
[Train] Epoch: 2 [521920/620022]    Loss: 0.010197   Batch Acc: 73.44
[Train] Epoch: 2 [521984/620022]    Loss: 0.009674   Batch Acc: 73.44
[Train] Epoch: 2 [522048/620022]    Loss: 0.008030   Batch Acc: 79.69
[Train] Epoch: 2 [522112/620022]    Loss: 0.007428   Batch Acc: 85.94
[Train] Epoch: 2 [522176/620022]    Loss: 0.009762   Batch Acc: 73.44
[Train] Epoch: 2 [522240/620022]    Loss: 0.008272   Batch Acc: 75.00
[Train] Epoch: 2 [522304/620022]    Loss: 0.009294   Batch Acc: 75.00
[Train] Epoch: 2 [522368/620022]    Loss: 0.009240   Batch Acc: 73.44
[Train] Epoch: 2 [522432/620022]    Loss: 0.012344   Batch Acc: 68.75
[Train] Epoch: 2 [522496/620022]    Loss: 0.009022   Batch Acc: 78.12
[Train] Epoch: 2 [522560/620022]    Loss: 0.011642   Batch Acc: 70.31
[Train] Epoch: 2 [522624/620022]    Loss: 0.007043   Batch Acc: 79.69
[Train] Epoch: 2 [522688/620022]    Loss: 0.009972   Batch Acc: 70.31
[Train] Epoch: 2 [522752/620022]    Loss: 0.009922   Batch Acc: 71.88
[Train] Epoch: 2 [522816/620022]    Loss: 0.007200   Batch Acc: 81.25
[Train] Epoch: 2 [522880/620022]    Loss: 0.008357   Batch Acc: 81.25
[Train] Epoch: 2 [522944/620022]    Loss: 0.010212   Batch Acc: 75.00
[Train] Epoch: 2 [523008/620022]    Loss: 0.007677   Batch Acc: 81.25
[Train] Epoch: 2 [523072/620022]    Loss: 0.009247   Batch Acc: 78.12
[Train] Epoch: 2 [523136/620022]    Loss: 0.007045   Batch Acc: 78.12
[Train] Epoch: 2 [523200/620022]    Loss: 0.009624   Batch Acc: 71.88
[Train] Epoch: 2 [523264/620022]    Loss: 0.007869   Batch Acc: 79.69
[Train] Epoch: 2 [523328/620022]    Loss: 0.008924   Batch Acc: 78.12
[Train] Epoch: 2 [523392/620022]    Loss: 0.007664   Batch Acc: 79.69
[Train] Epoch: 2 [523456/620022]    Loss: 0.013608   Batch Acc: 60.94
[Train] Epoch: 2 [523520/620022]    Loss: 0.008525   Batch Acc: 75.00
[Train] Epoch: 2 [523584/620022]    Loss: 0.008739   Batch Acc: 76.56
[Train] Epoch: 2 [523648/620022]    Loss: 0.009684   Batch Acc: 78.12
[Train] Epoch: 2 [523712/620022]    Loss: 0.007053   Batch Acc: 84.38
[Train] Epoch: 2 [523776/620022]    Loss: 0.007165   Batch Acc: 79.69
[Train] Epoch: 2 [523840/620022]    Loss: 0.010337   Batch Acc: 75.00
[Train] Epoch: 2 [523904/620022]    Loss: 0.007751   Batch Acc: 79.69
[Train] Epoch: 2 [523968/620022]    Loss: 0.007727   Batch Acc: 84.38
[Train] Epoch: 2 [524032/620022]    Loss: 0.010120   Batch Acc: 75.00
[Train] Epoch: 2 [524096/620022]    Loss: 0.008813   Batch Acc: 71.88
[Train] Epoch: 2 [524160/620022]    Loss: 0.009637   Batch Acc: 73.44
[Train] Epoch: 2 [524224/620022]    Loss: 0.008282   Batch Acc: 81.25
[Train] Epoch: 2 [524288/620022]    Loss: 0.008518   Batch Acc: 78.12
[Train] Epoch: 2 [524352/620022]    Loss: 0.007459   Batch Acc: 82.81
[Train] Epoch: 2 [524416/620022]    Loss: 0.008370   Batch Acc: 76.56
[Train] Epoch: 2 [524480/620022]    Loss: 0.007950   Batch Acc: 78.12
[Train] Epoch: 2 [524544/620022]    Loss: 0.007298   Batch Acc: 81.25
[Train] Epoch: 2 [524608/620022]    Loss: 0.007650   Batch Acc: 78.12
[Train] Epoch: 2 [524672/620022]    Loss: 0.007273   Batch Acc: 81.25
[Train] Epoch: 2 [524736/620022]    Loss: 0.009432   Batch Acc: 79.69
[Train] Epoch: 2 [524800/620022]    Loss: 0.010458   Batch Acc: 75.00
[Train] Epoch: 2 [524864/620022]    Loss: 0.007011   Batch Acc: 79.69
[Train] Epoch: 2 [524928/620022]    Loss: 0.007838   Batch Acc: 79.69
[Train] Epoch: 2 [524992/620022]    Loss: 0.008491   Batch Acc: 81.25
[Train] Epoch: 2 [525056/620022]    Loss: 0.010673   Batch Acc: 71.88
[Train] Epoch: 2 [525120/620022]    Loss: 0.007506   Batch Acc: 85.94
[Train] Epoch: 2 [525184/620022]    Loss: 0.006161   Batch Acc: 89.06
[Train] Epoch: 2 [525248/620022]    Loss: 0.010032   Batch Acc: 71.88
[Train] Epoch: 2 [525312/620022]    Loss: 0.008538   Batch Acc: 82.81
[Train] Epoch: 2 [525376/620022]    Loss: 0.008599   Batch Acc: 78.12
[Train] Epoch: 2 [525440/620022]    Loss: 0.007545   Batch Acc: 82.81
[Train] Epoch: 2 [525504/620022]    Loss: 0.006242   Batch Acc: 84.38
[Train] Epoch: 2 [525568/620022]    Loss: 0.009943   Batch Acc: 75.00
[Train] Epoch: 2 [525632/620022]    Loss: 0.007596   Batch Acc: 81.25
[Train] Epoch: 2 [525696/620022]    Loss: 0.008787   Batch Acc: 76.56
[Train] Epoch: 2 [525760/620022]    Loss: 0.008464   Batch Acc: 75.00
[Train] Epoch: 2 [525824/620022]    Loss: 0.005828   Batch Acc: 85.94
[Train] Epoch: 2 [525888/620022]    Loss: 0.007461   Batch Acc: 84.38
[Train] Epoch: 2 [525952/620022]    Loss: 0.008131   Batch Acc: 78.12
[Train] Epoch: 2 [526016/620022]    Loss: 0.008653   Batch Acc: 76.56
[Train] Epoch: 2 [526080/620022]    Loss: 0.007957   Batch Acc: 76.56
[Train] Epoch: 2 [526144/620022]    Loss: 0.007917   Batch Acc: 75.00
[Train] Epoch: 2 [526208/620022]    Loss: 0.009597   Batch Acc: 75.00
[Train] Epoch: 2 [526272/620022]    Loss: 0.009976   Batch Acc: 78.12
[Train] Epoch: 2 [526336/620022]    Loss: 0.006919   Batch Acc: 84.38
[Train] Epoch: 2 [526400/620022]    Loss: 0.007032   Batch Acc: 85.94
[Train] Epoch: 2 [526464/620022]    Loss: 0.007589   Batch Acc: 85.94
[Train] Epoch: 2 [526528/620022]    Loss: 0.007354   Batch Acc: 78.12
[Train] Epoch: 2 [526592/620022]    Loss: 0.007917   Batch Acc: 82.81
[Train] Epoch: 2 [526656/620022]    Loss: 0.007586   Batch Acc: 87.50
[Train] Epoch: 2 [526720/620022]    Loss: 0.010122   Batch Acc: 70.31
[Train] Epoch: 2 [526784/620022]    Loss: 0.005992   Batch Acc: 87.50
[Train] Epoch: 2 [526848/620022]    Loss: 0.009506   Batch Acc: 64.06
[Train] Epoch: 2 [526912/620022]    Loss: 0.007445   Batch Acc: 78.12
[Train] Epoch: 2 [526976/620022]    Loss: 0.010106   Batch Acc: 70.31
[Train] Epoch: 2 [527040/620022]    Loss: 0.009609   Batch Acc: 71.88
[Train] Epoch: 2 [527104/620022]    Loss: 0.010771   Batch Acc: 75.00
[Train] Epoch: 2 [527168/620022]    Loss: 0.008030   Batch Acc: 78.12
[Train] Epoch: 2 [527232/620022]    Loss: 0.008003   Batch Acc: 82.81
[Train] Epoch: 2 [527296/620022]    Loss: 0.009014   Batch Acc: 76.56
[Train] Epoch: 2 [527360/620022]    Loss: 0.008010   Batch Acc: 76.56
[Train] Epoch: 2 [527424/620022]    Loss: 0.005621   Batch Acc: 90.62
[Train] Epoch: 2 [527488/620022]    Loss: 0.008037   Batch Acc: 78.12
[Train] Epoch: 2 [527552/620022]    Loss: 0.010634   Batch Acc: 73.44
[Train] Epoch: 2 [527616/620022]    Loss: 0.010407   Batch Acc: 65.62
[Train] Epoch: 2 [527680/620022]    Loss: 0.008117   Batch Acc: 79.69
[Train] Epoch: 2 [527744/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 2 [527808/620022]    Loss: 0.007589   Batch Acc: 81.25
[Train] Epoch: 2 [527872/620022]    Loss: 0.009339   Batch Acc: 81.25
[Train] Epoch: 2 [527936/620022]    Loss: 0.009310   Batch Acc: 71.88
[Train] Epoch: 2 [528000/620022]    Loss: 0.010057   Batch Acc: 73.44
[Train] Epoch: 2 [528064/620022]    Loss: 0.010044   Batch Acc: 70.31
[Train] Epoch: 2 [528128/620022]    Loss: 0.006326   Batch Acc: 84.38
[Train] Epoch: 2 [528192/620022]    Loss: 0.008554   Batch Acc: 79.69
[Train] Epoch: 2 [528256/620022]    Loss: 0.011175   Batch Acc: 62.50
[Train] Epoch: 2 [528320/620022]    Loss: 0.008622   Batch Acc: 78.12
[Train] Epoch: 2 [528384/620022]    Loss: 0.007170   Batch Acc: 87.50
[Train] Epoch: 2 [528448/620022]    Loss: 0.008293   Batch Acc: 73.44
[Train] Epoch: 2 [528512/620022]    Loss: 0.009345   Batch Acc: 79.69
[Train] Epoch: 2 [528576/620022]    Loss: 0.010222   Batch Acc: 73.44
[Train] Epoch: 2 [528640/620022]    Loss: 0.006194   Batch Acc: 82.81
[Train] Epoch: 2 [528704/620022]    Loss: 0.008228   Batch Acc: 75.00
[Train] Epoch: 2 [528768/620022]    Loss: 0.010259   Batch Acc: 71.88
[Train] Epoch: 2 [528832/620022]    Loss: 0.008099   Batch Acc: 79.69
[Train] Epoch: 2 [528896/620022]    Loss: 0.010122   Batch Acc: 71.88
[Train] Epoch: 2 [528960/620022]    Loss: 0.007687   Batch Acc: 84.38
[Train] Epoch: 2 [529024/620022]    Loss: 0.009699   Batch Acc: 76.56
[Train] Epoch: 2 [529088/620022]    Loss: 0.007683   Batch Acc: 76.56
[Train] Epoch: 2 [529152/620022]    Loss: 0.009817   Batch Acc: 71.88
[Train] Epoch: 2 [529216/620022]    Loss: 0.007500   Batch Acc: 82.81
[Train] Epoch: 2 [529280/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 2 [529344/620022]    Loss: 0.007335   Batch Acc: 76.56
[Train] Epoch: 2 [529408/620022]    Loss: 0.011278   Batch Acc: 70.31
[Train] Epoch: 2 [529472/620022]    Loss: 0.008289   Batch Acc: 76.56
[Train] Epoch: 2 [529536/620022]    Loss: 0.008237   Batch Acc: 79.69
[Train] Epoch: 2 [529600/620022]    Loss: 0.008074   Batch Acc: 79.69
[Train] Epoch: 2 [529664/620022]    Loss: 0.007828   Batch Acc: 78.12
[Train] Epoch: 2 [529728/620022]    Loss: 0.007902   Batch Acc: 84.38
[Train] Epoch: 2 [529792/620022]    Loss: 0.007063   Batch Acc: 85.94
[Train] Epoch: 2 [529856/620022]    Loss: 0.008175   Batch Acc: 78.12
[Train] Epoch: 2 [529920/620022]    Loss: 0.006371   Batch Acc: 89.06
[Train] Epoch: 2 [529984/620022]    Loss: 0.009608   Batch Acc: 73.44
[Train] Epoch: 2 [530048/620022]    Loss: 0.005660   Batch Acc: 89.06
[Train] Epoch: 2 [530112/620022]    Loss: 0.008031   Batch Acc: 79.69
[Train] Epoch: 2 [530176/620022]    Loss: 0.008700   Batch Acc: 75.00
[Train] Epoch: 2 [530240/620022]    Loss: 0.007366   Batch Acc: 82.81
[Train] Epoch: 2 [530304/620022]    Loss: 0.008782   Batch Acc: 75.00
[Train] Epoch: 2 [530368/620022]    Loss: 0.007085   Batch Acc: 84.38
[Train] Epoch: 2 [530432/620022]    Loss: 0.009826   Batch Acc: 75.00
[Train] Epoch: 2 [530496/620022]    Loss: 0.009143   Batch Acc: 71.88
[Train] Epoch: 2 [530560/620022]    Loss: 0.008300   Batch Acc: 79.69
[Train] Epoch: 2 [530624/620022]    Loss: 0.007553   Batch Acc: 75.00
[Train] Epoch: 2 [530688/620022]    Loss: 0.010353   Batch Acc: 76.56
[Train] Epoch: 2 [530752/620022]    Loss: 0.009928   Batch Acc: 73.44
[Train] Epoch: 2 [530816/620022]    Loss: 0.008141   Batch Acc: 79.69
[Train] Epoch: 2 [530880/620022]    Loss: 0.010386   Batch Acc: 73.44
[Train] Epoch: 2 [530944/620022]    Loss: 0.009859   Batch Acc: 71.88
[Train] Epoch: 2 [531008/620022]    Loss: 0.007476   Batch Acc: 81.25
[Train] Epoch: 2 [531072/620022]    Loss: 0.008602   Batch Acc: 70.31
[Train] Epoch: 2 [531136/620022]    Loss: 0.011088   Batch Acc: 70.31
[Train] Epoch: 2 [531200/620022]    Loss: 0.007635   Batch Acc: 76.56
[Train] Epoch: 2 [531264/620022]    Loss: 0.006527   Batch Acc: 87.50
[Train] Epoch: 2 [531328/620022]    Loss: 0.010121   Batch Acc: 79.69
[Train] Epoch: 2 [531392/620022]    Loss: 0.009581   Batch Acc: 75.00
[Train] Epoch: 2 [531456/620022]    Loss: 0.008971   Batch Acc: 81.25
[Train] Epoch: 2 [531520/620022]    Loss: 0.007375   Batch Acc: 81.25
[Train] Epoch: 2 [531584/620022]    Loss: 0.008321   Batch Acc: 76.56
[Train] Epoch: 2 [531648/620022]    Loss: 0.008005   Batch Acc: 79.69
[Train] Epoch: 2 [531712/620022]    Loss: 0.010006   Batch Acc: 70.31
[Train] Epoch: 2 [531776/620022]    Loss: 0.008417   Batch Acc: 76.56
[Train] Epoch: 2 [531840/620022]    Loss: 0.007324   Batch Acc: 85.94
[Train] Epoch: 2 [531904/620022]    Loss: 0.007235   Batch Acc: 82.81
[Train] Epoch: 2 [531968/620022]    Loss: 0.008595   Batch Acc: 78.12
[Train] Epoch: 2 [532032/620022]    Loss: 0.010225   Batch Acc: 73.44
[Train] Epoch: 2 [532096/620022]    Loss: 0.007557   Batch Acc: 79.69
[Train] Epoch: 2 [532160/620022]    Loss: 0.008129   Batch Acc: 82.81
[Train] Epoch: 2 [532224/620022]    Loss: 0.008356   Batch Acc: 79.69
[Train] Epoch: 2 [532288/620022]    Loss: 0.007305   Batch Acc: 70.31
[Train] Epoch: 2 [532352/620022]    Loss: 0.007082   Batch Acc: 82.81
[Train] Epoch: 2 [532416/620022]    Loss: 0.010200   Batch Acc: 73.44
[Train] Epoch: 2 [532480/620022]    Loss: 0.009217   Batch Acc: 76.56
[Train] Epoch: 2 [532544/620022]    Loss: 0.009897   Batch Acc: 73.44
[Train] Epoch: 2 [532608/620022]    Loss: 0.009022   Batch Acc: 79.69
[Train] Epoch: 2 [532672/620022]    Loss: 0.009610   Batch Acc: 75.00
[Train] Epoch: 2 [532736/620022]    Loss: 0.007598   Batch Acc: 84.38
[Train] Epoch: 2 [532800/620022]    Loss: 0.009227   Batch Acc: 79.69
[Train] Epoch: 2 [532864/620022]    Loss: 0.008933   Batch Acc: 73.44
[Train] Epoch: 2 [532928/620022]    Loss: 0.007246   Batch Acc: 79.69
[Train] Epoch: 2 [532992/620022]    Loss: 0.008769   Batch Acc: 81.25
[Train] Epoch: 2 [533056/620022]    Loss: 0.007433   Batch Acc: 84.38
[Train] Epoch: 2 [533120/620022]    Loss: 0.009346   Batch Acc: 78.12
[Train] Epoch: 2 [533184/620022]    Loss: 0.006356   Batch Acc: 90.62
[Train] Epoch: 2 [533248/620022]    Loss: 0.008638   Batch Acc: 79.69
[Train] Epoch: 2 [533312/620022]    Loss: 0.008718   Batch Acc: 73.44
[Train] Epoch: 2 [533376/620022]    Loss: 0.009243   Batch Acc: 76.56
[Train] Epoch: 2 [533440/620022]    Loss: 0.007760   Batch Acc: 89.06
[Train] Epoch: 2 [533504/620022]    Loss: 0.009535   Batch Acc: 81.25
[Train] Epoch: 2 [533568/620022]    Loss: 0.011516   Batch Acc: 73.44
[Train] Epoch: 2 [533632/620022]    Loss: 0.011503   Batch Acc: 71.88
[Train] Epoch: 2 [533696/620022]    Loss: 0.006874   Batch Acc: 82.81
[Train] Epoch: 2 [533760/620022]    Loss: 0.008909   Batch Acc: 70.31
[Train] Epoch: 2 [533824/620022]    Loss: 0.009315   Batch Acc: 75.00
[Train] Epoch: 2 [533888/620022]    Loss: 0.007890   Batch Acc: 82.81
[Train] Epoch: 2 [533952/620022]    Loss: 0.007571   Batch Acc: 79.69
[Train] Epoch: 2 [534016/620022]    Loss: 0.009051   Batch Acc: 82.81
[Train] Epoch: 2 [534080/620022]    Loss: 0.007098   Batch Acc: 81.25
[Train] Epoch: 2 [534144/620022]    Loss: 0.007590   Batch Acc: 76.56
[Train] Epoch: 2 [534208/620022]    Loss: 0.007381   Batch Acc: 81.25
[Train] Epoch: 2 [534272/620022]    Loss: 0.008328   Batch Acc: 78.12
[Train] Epoch: 2 [534336/620022]    Loss: 0.007260   Batch Acc: 85.94
[Train] Epoch: 2 [534400/620022]    Loss: 0.008516   Batch Acc: 79.69
[Train] Epoch: 2 [534464/620022]    Loss: 0.010576   Batch Acc: 73.44
[Train] Epoch: 2 [534528/620022]    Loss: 0.010175   Batch Acc: 79.69
[Train] Epoch: 2 [534592/620022]    Loss: 0.009693   Batch Acc: 71.88
[Train] Epoch: 2 [534656/620022]    Loss: 0.008061   Batch Acc: 85.94
[Train] Epoch: 2 [534720/620022]    Loss: 0.009255   Batch Acc: 73.44
[Train] Epoch: 2 [534784/620022]    Loss: 0.008656   Batch Acc: 76.56
[Train] Epoch: 2 [534848/620022]    Loss: 0.008092   Batch Acc: 85.94
[Train] Epoch: 2 [534912/620022]    Loss: 0.006625   Batch Acc: 82.81
[Train] Epoch: 2 [534976/620022]    Loss: 0.009781   Batch Acc: 78.12
[Train] Epoch: 2 [535040/620022]    Loss: 0.009716   Batch Acc: 78.12
[Train] Epoch: 2 [535104/620022]    Loss: 0.010628   Batch Acc: 73.44
[Train] Epoch: 2 [535168/620022]    Loss: 0.009765   Batch Acc: 68.75
[Train] Epoch: 2 [535232/620022]    Loss: 0.009314   Batch Acc: 71.88
[Train] Epoch: 2 [535296/620022]    Loss: 0.010158   Batch Acc: 67.19
[Train] Epoch: 2 [535360/620022]    Loss: 0.009559   Batch Acc: 75.00
[Train] Epoch: 2 [535424/620022]    Loss: 0.006424   Batch Acc: 84.38
[Train] Epoch: 2 [535488/620022]    Loss: 0.007496   Batch Acc: 84.38
[Train] Epoch: 2 [535552/620022]    Loss: 0.006641   Batch Acc: 82.81
[Train] Epoch: 2 [535616/620022]    Loss: 0.009298   Batch Acc: 76.56
[Train] Epoch: 2 [535680/620022]    Loss: 0.008580   Batch Acc: 76.56
[Train] Epoch: 2 [535744/620022]    Loss: 0.008717   Batch Acc: 78.12
[Train] Epoch: 2 [535808/620022]    Loss: 0.008010   Batch Acc: 82.81
[Train] Epoch: 2 [535872/620022]    Loss: 0.010594   Batch Acc: 78.12
[Train] Epoch: 2 [535936/620022]    Loss: 0.006947   Batch Acc: 85.94
[Train] Epoch: 2 [536000/620022]    Loss: 0.007600   Batch Acc: 81.25
[Train] Epoch: 2 [536064/620022]    Loss: 0.008572   Batch Acc: 73.44
[Train] Epoch: 2 [536128/620022]    Loss: 0.008695   Batch Acc: 82.81
[Train] Epoch: 2 [536192/620022]    Loss: 0.008138   Batch Acc: 78.12
[Train] Epoch: 2 [536256/620022]    Loss: 0.011207   Batch Acc: 71.88
[Train] Epoch: 2 [536320/620022]    Loss: 0.009929   Batch Acc: 76.56
[Train] Epoch: 2 [536384/620022]    Loss: 0.009422   Batch Acc: 73.44
[Train] Epoch: 2 [536448/620022]    Loss: 0.007593   Batch Acc: 78.12
[Train] Epoch: 2 [536512/620022]    Loss: 0.008449   Batch Acc: 73.44
[Train] Epoch: 2 [536576/620022]    Loss: 0.007290   Batch Acc: 81.25
[Train] Epoch: 2 [536640/620022]    Loss: 0.008531   Batch Acc: 73.44
[Train] Epoch: 2 [536704/620022]    Loss: 0.006534   Batch Acc: 85.94
[Train] Epoch: 2 [536768/620022]    Loss: 0.007129   Batch Acc: 87.50
[Train] Epoch: 2 [536832/620022]    Loss: 0.007072   Batch Acc: 82.81
[Train] Epoch: 2 [536896/620022]    Loss: 0.007707   Batch Acc: 81.25
[Train] Epoch: 2 [536960/620022]    Loss: 0.008805   Batch Acc: 76.56
[Train] Epoch: 2 [537024/620022]    Loss: 0.008623   Batch Acc: 73.44
[Train] Epoch: 2 [537088/620022]    Loss: 0.007631   Batch Acc: 81.25
[Train] Epoch: 2 [537152/620022]    Loss: 0.008524   Batch Acc: 81.25
[Train] Epoch: 2 [537216/620022]    Loss: 0.006316   Batch Acc: 90.62
[Train] Epoch: 2 [537280/620022]    Loss: 0.009409   Batch Acc: 70.31
[Train] Epoch: 2 [537344/620022]    Loss: 0.009027   Batch Acc: 78.12
[Train] Epoch: 2 [537408/620022]    Loss: 0.006327   Batch Acc: 84.38
[Train] Epoch: 2 [537472/620022]    Loss: 0.008643   Batch Acc: 82.81
[Train] Epoch: 2 [537536/620022]    Loss: 0.009823   Batch Acc: 78.12
[Train] Epoch: 2 [537600/620022]    Loss: 0.006279   Batch Acc: 85.94
[Train] Epoch: 2 [537664/620022]    Loss: 0.009676   Batch Acc: 76.56
[Train] Epoch: 2 [537728/620022]    Loss: 0.010573   Batch Acc: 68.75
[Train] Epoch: 2 [537792/620022]    Loss: 0.007523   Batch Acc: 81.25
[Train] Epoch: 2 [537856/620022]    Loss: 0.008324   Batch Acc: 82.81
[Train] Epoch: 2 [537920/620022]    Loss: 0.007369   Batch Acc: 79.69
[Train] Epoch: 2 [537984/620022]    Loss: 0.008819   Batch Acc: 78.12
[Train] Epoch: 2 [538048/620022]    Loss: 0.007529   Batch Acc: 79.69
[Train] Epoch: 2 [538112/620022]    Loss: 0.006488   Batch Acc: 82.81
[Train] Epoch: 2 [538176/620022]    Loss: 0.008251   Batch Acc: 78.12
[Train] Epoch: 2 [538240/620022]    Loss: 0.009968   Batch Acc: 73.44
[Train] Epoch: 2 [538304/620022]    Loss: 0.010059   Batch Acc: 73.44
[Train] Epoch: 2 [538368/620022]    Loss: 0.009448   Batch Acc: 68.75
[Train] Epoch: 2 [538432/620022]    Loss: 0.011650   Batch Acc: 71.88
[Train] Epoch: 2 [538496/620022]    Loss: 0.007407   Batch Acc: 82.81
[Train] Epoch: 2 [538560/620022]    Loss: 0.009892   Batch Acc: 76.56
[Train] Epoch: 2 [538624/620022]    Loss: 0.010426   Batch Acc: 73.44
[Train] Epoch: 2 [538688/620022]    Loss: 0.007089   Batch Acc: 84.38
[Train] Epoch: 2 [538752/620022]    Loss: 0.009581   Batch Acc: 76.56
[Train] Epoch: 2 [538816/620022]    Loss: 0.007305   Batch Acc: 84.38
[Train] Epoch: 2 [538880/620022]    Loss: 0.007229   Batch Acc: 79.69
[Train] Epoch: 2 [538944/620022]    Loss: 0.010193   Batch Acc: 68.75
[Train] Epoch: 2 [539008/620022]    Loss: 0.007827   Batch Acc: 78.12
[Train] Epoch: 2 [539072/620022]    Loss: 0.010371   Batch Acc: 73.44
[Train] Epoch: 2 [539136/620022]    Loss: 0.007291   Batch Acc: 82.81
[Train] Epoch: 2 [539200/620022]    Loss: 0.008988   Batch Acc: 76.56
[Train] Epoch: 2 [539264/620022]    Loss: 0.007765   Batch Acc: 79.69
[Train] Epoch: 2 [539328/620022]    Loss: 0.007359   Batch Acc: 84.38
[Train] Epoch: 2 [539392/620022]    Loss: 0.008037   Batch Acc: 79.69
[Train] Epoch: 2 [539456/620022]    Loss: 0.010657   Batch Acc: 73.44
[Train] Epoch: 2 [539520/620022]    Loss: 0.009308   Batch Acc: 73.44
[Train] Epoch: 2 [539584/620022]    Loss: 0.008938   Batch Acc: 78.12
[Train] Epoch: 2 [539648/620022]    Loss: 0.008183   Batch Acc: 85.94
[Train] Epoch: 2 [539712/620022]    Loss: 0.008544   Batch Acc: 76.56
[Train] Epoch: 2 [539776/620022]    Loss: 0.008833   Batch Acc: 75.00
[Train] Epoch: 2 [539840/620022]    Loss: 0.007784   Batch Acc: 87.50
[Train] Epoch: 2 [539904/620022]    Loss: 0.007904   Batch Acc: 76.56
[Train] Epoch: 2 [539968/620022]    Loss: 0.010261   Batch Acc: 71.88
[Train] Epoch: 2 [540032/620022]    Loss: 0.008596   Batch Acc: 79.69
[Train] Epoch: 2 [540096/620022]    Loss: 0.009922   Batch Acc: 81.25
[Train] Epoch: 2 [540160/620022]    Loss: 0.009340   Batch Acc: 79.69
[Train] Epoch: 2 [540224/620022]    Loss: 0.008096   Batch Acc: 81.25
[Train] Epoch: 2 [540288/620022]    Loss: 0.006834   Batch Acc: 89.06
[Train] Epoch: 2 [540352/620022]    Loss: 0.008421   Batch Acc: 76.56
[Train] Epoch: 2 [540416/620022]    Loss: 0.007381   Batch Acc: 81.25
[Train] Epoch: 2 [540480/620022]    Loss: 0.007820   Batch Acc: 76.56
[Train] Epoch: 2 [540544/620022]    Loss: 0.010599   Batch Acc: 68.75
[Train] Epoch: 2 [540608/620022]    Loss: 0.010944   Batch Acc: 67.19
[Train] Epoch: 2 [540672/620022]    Loss: 0.007921   Batch Acc: 76.56
[Train] Epoch: 2 [540736/620022]    Loss: 0.010041   Batch Acc: 81.25
[Train] Epoch: 2 [540800/620022]    Loss: 0.009011   Batch Acc: 78.12
[Train] Epoch: 2 [540864/620022]    Loss: 0.009085   Batch Acc: 76.56
[Train] Epoch: 2 [540928/620022]    Loss: 0.006620   Batch Acc: 82.81
[Train] Epoch: 2 [540992/620022]    Loss: 0.008008   Batch Acc: 79.69
[Train] Epoch: 2 [541056/620022]    Loss: 0.008903   Batch Acc: 78.12
[Train] Epoch: 2 [541120/620022]    Loss: 0.010668   Batch Acc: 64.06
[Train] Epoch: 2 [541184/620022]    Loss: 0.009682   Batch Acc: 75.00
[Train] Epoch: 2 [541248/620022]    Loss: 0.009380   Batch Acc: 75.00
[Train] Epoch: 2 [541312/620022]    Loss: 0.010046   Batch Acc: 70.31
[Train] Epoch: 2 [541376/620022]    Loss: 0.008703   Batch Acc: 79.69
[Train] Epoch: 2 [541440/620022]    Loss: 0.009055   Batch Acc: 78.12
[Train] Epoch: 2 [541504/620022]    Loss: 0.010946   Batch Acc: 75.00
[Train] Epoch: 2 [541568/620022]    Loss: 0.009240   Batch Acc: 78.12
[Train] Epoch: 2 [541632/620022]    Loss: 0.009252   Batch Acc: 71.88
[Train] Epoch: 2 [541696/620022]    Loss: 0.010139   Batch Acc: 68.75
[Train] Epoch: 2 [541760/620022]    Loss: 0.008702   Batch Acc: 76.56
[Train] Epoch: 2 [541824/620022]    Loss: 0.007857   Batch Acc: 82.81
[Train] Epoch: 2 [541888/620022]    Loss: 0.010845   Batch Acc: 70.31
[Train] Epoch: 2 [541952/620022]    Loss: 0.007688   Batch Acc: 79.69
[Train] Epoch: 2 [542016/620022]    Loss: 0.010639   Batch Acc: 76.56
[Train] Epoch: 2 [542080/620022]    Loss: 0.008253   Batch Acc: 82.81
[Train] Epoch: 2 [542144/620022]    Loss: 0.011210   Batch Acc: 70.31
[Train] Epoch: 2 [542208/620022]    Loss: 0.009543   Batch Acc: 76.56
[Train] Epoch: 2 [542272/620022]    Loss: 0.010672   Batch Acc: 68.75
[Train] Epoch: 2 [542336/620022]    Loss: 0.008073   Batch Acc: 76.56
[Train] Epoch: 2 [542400/620022]    Loss: 0.005928   Batch Acc: 87.50
[Train] Epoch: 2 [542464/620022]    Loss: 0.008200   Batch Acc: 84.38
[Train] Epoch: 2 [542528/620022]    Loss: 0.008500   Batch Acc: 81.25
[Train] Epoch: 2 [542592/620022]    Loss: 0.009087   Batch Acc: 78.12
[Train] Epoch: 2 [542656/620022]    Loss: 0.007920   Batch Acc: 78.12
[Train] Epoch: 2 [542720/620022]    Loss: 0.008911   Batch Acc: 84.38
[Train] Epoch: 2 [542784/620022]    Loss: 0.009994   Batch Acc: 70.31
[Train] Epoch: 2 [542848/620022]    Loss: 0.010605   Batch Acc: 73.44
[Train] Epoch: 2 [542912/620022]    Loss: 0.008805   Batch Acc: 78.12
[Train] Epoch: 2 [542976/620022]    Loss: 0.005781   Batch Acc: 89.06
[Train] Epoch: 2 [543040/620022]    Loss: 0.010114   Batch Acc: 73.44
[Train] Epoch: 2 [543104/620022]    Loss: 0.008006   Batch Acc: 85.94
[Train] Epoch: 2 [543168/620022]    Loss: 0.006830   Batch Acc: 79.69
[Train] Epoch: 2 [543232/620022]    Loss: 0.008649   Batch Acc: 73.44
[Train] Epoch: 2 [543296/620022]    Loss: 0.007334   Batch Acc: 78.12
[Train] Epoch: 2 [543360/620022]    Loss: 0.010153   Batch Acc: 70.31
[Train] Epoch: 2 [543424/620022]    Loss: 0.008043   Batch Acc: 73.44
[Train] Epoch: 2 [543488/620022]    Loss: 0.009275   Batch Acc: 71.88
[Train] Epoch: 2 [543552/620022]    Loss: 0.008247   Batch Acc: 75.00
[Train] Epoch: 2 [543616/620022]    Loss: 0.010064   Batch Acc: 76.56
[Train] Epoch: 2 [543680/620022]    Loss: 0.007499   Batch Acc: 76.56
[Train] Epoch: 2 [543744/620022]    Loss: 0.008146   Batch Acc: 78.12
[Train] Epoch: 2 [543808/620022]    Loss: 0.008863   Batch Acc: 76.56
[Train] Epoch: 2 [543872/620022]    Loss: 0.009724   Batch Acc: 70.31
[Train] Epoch: 2 [543936/620022]    Loss: 0.008583   Batch Acc: 79.69
[Train] Epoch: 2 [544000/620022]    Loss: 0.007118   Batch Acc: 84.38
[Train] Epoch: 2 [544064/620022]    Loss: 0.007691   Batch Acc: 81.25
[Train] Epoch: 2 [544128/620022]    Loss: 0.008785   Batch Acc: 76.56
[Train] Epoch: 2 [544192/620022]    Loss: 0.010135   Batch Acc: 68.75
[Train] Epoch: 2 [544256/620022]    Loss: 0.008693   Batch Acc: 81.25
[Train] Epoch: 2 [544320/620022]    Loss: 0.010135   Batch Acc: 71.88
[Train] Epoch: 2 [544384/620022]    Loss: 0.008453   Batch Acc: 73.44
[Train] Epoch: 2 [544448/620022]    Loss: 0.008772   Batch Acc: 71.88
[Train] Epoch: 2 [544512/620022]    Loss: 0.007695   Batch Acc: 81.25
[Train] Epoch: 2 [544576/620022]    Loss: 0.008728   Batch Acc: 81.25
[Train] Epoch: 2 [544640/620022]    Loss: 0.008631   Batch Acc: 73.44
[Train] Epoch: 2 [544704/620022]    Loss: 0.007529   Batch Acc: 84.38
[Train] Epoch: 2 [544768/620022]    Loss: 0.009155   Batch Acc: 73.44
[Train] Epoch: 2 [544832/620022]    Loss: 0.007930   Batch Acc: 79.69
[Train] Epoch: 2 [544896/620022]    Loss: 0.008911   Batch Acc: 76.56
[Train] Epoch: 2 [544960/620022]    Loss: 0.009395   Batch Acc: 76.56
[Train] Epoch: 2 [545024/620022]    Loss: 0.007706   Batch Acc: 82.81
[Train] Epoch: 2 [545088/620022]    Loss: 0.007054   Batch Acc: 78.12
[Train] Epoch: 2 [545152/620022]    Loss: 0.009024   Batch Acc: 78.12
[Train] Epoch: 2 [545216/620022]    Loss: 0.008910   Batch Acc: 79.69
[Train] Epoch: 2 [545280/620022]    Loss: 0.008170   Batch Acc: 78.12
[Train] Epoch: 2 [545344/620022]    Loss: 0.008897   Batch Acc: 73.44
[Train] Epoch: 2 [545408/620022]    Loss: 0.008261   Batch Acc: 78.12
[Train] Epoch: 2 [545472/620022]    Loss: 0.007815   Batch Acc: 76.56
[Train] Epoch: 2 [545536/620022]    Loss: 0.009494   Batch Acc: 78.12
[Train] Epoch: 2 [545600/620022]    Loss: 0.011716   Batch Acc: 59.38
[Train] Epoch: 2 [545664/620022]    Loss: 0.008219   Batch Acc: 78.12
[Train] Epoch: 2 [545728/620022]    Loss: 0.010070   Batch Acc: 70.31
[Train] Epoch: 2 [545792/620022]    Loss: 0.011899   Batch Acc: 64.06
[Train] Epoch: 2 [545856/620022]    Loss: 0.009791   Batch Acc: 78.12
[Train] Epoch: 2 [545920/620022]    Loss: 0.009730   Batch Acc: 73.44
[Train] Epoch: 2 [545984/620022]    Loss: 0.011110   Batch Acc: 75.00
[Train] Epoch: 2 [546048/620022]    Loss: 0.007408   Batch Acc: 85.94
[Train] Epoch: 2 [546112/620022]    Loss: 0.009410   Batch Acc: 71.88
[Train] Epoch: 2 [546176/620022]    Loss: 0.007806   Batch Acc: 76.56
[Train] Epoch: 2 [546240/620022]    Loss: 0.008851   Batch Acc: 76.56
[Train] Epoch: 2 [546304/620022]    Loss: 0.007802   Batch Acc: 78.12
[Train] Epoch: 2 [546368/620022]    Loss: 0.008280   Batch Acc: 79.69
[Train] Epoch: 2 [546432/620022]    Loss: 0.007171   Batch Acc: 81.25
[Train] Epoch: 2 [546496/620022]    Loss: 0.006355   Batch Acc: 84.38
[Train] Epoch: 2 [546560/620022]    Loss: 0.009005   Batch Acc: 76.56
[Train] Epoch: 2 [546624/620022]    Loss: 0.011792   Batch Acc: 70.31
[Train] Epoch: 2 [546688/620022]    Loss: 0.007852   Batch Acc: 79.69
[Train] Epoch: 2 [546752/620022]    Loss: 0.006754   Batch Acc: 87.50
[Train] Epoch: 2 [546816/620022]    Loss: 0.008366   Batch Acc: 82.81
[Train] Epoch: 2 [546880/620022]    Loss: 0.006425   Batch Acc: 89.06
[Train] Epoch: 2 [546944/620022]    Loss: 0.009453   Batch Acc: 79.69
[Train] Epoch: 2 [547008/620022]    Loss: 0.008036   Batch Acc: 81.25
[Train] Epoch: 2 [547072/620022]    Loss: 0.008634   Batch Acc: 79.69
[Train] Epoch: 2 [547136/620022]    Loss: 0.008564   Batch Acc: 82.81
[Train] Epoch: 2 [547200/620022]    Loss: 0.006567   Batch Acc: 89.06
[Train] Epoch: 2 [547264/620022]    Loss: 0.007268   Batch Acc: 84.38
[Train] Epoch: 2 [547328/620022]    Loss: 0.009202   Batch Acc: 70.31
[Train] Epoch: 2 [547392/620022]    Loss: 0.008814   Batch Acc: 75.00
[Train] Epoch: 2 [547456/620022]    Loss: 0.009488   Batch Acc: 76.56
[Train] Epoch: 2 [547520/620022]    Loss: 0.007441   Batch Acc: 84.38
[Train] Epoch: 2 [547584/620022]    Loss: 0.006318   Batch Acc: 84.38
[Train] Epoch: 2 [547648/620022]    Loss: 0.009436   Batch Acc: 73.44
[Train] Epoch: 2 [547712/620022]    Loss: 0.011260   Batch Acc: 70.31
[Train] Epoch: 2 [547776/620022]    Loss: 0.007715   Batch Acc: 81.25
[Train] Epoch: 2 [547840/620022]    Loss: 0.011417   Batch Acc: 64.06
[Train] Epoch: 2 [547904/620022]    Loss: 0.009773   Batch Acc: 75.00
[Train] Epoch: 2 [547968/620022]    Loss: 0.007465   Batch Acc: 85.94
[Train] Epoch: 2 [548032/620022]    Loss: 0.010175   Batch Acc: 71.88
[Train] Epoch: 2 [548096/620022]    Loss: 0.008878   Batch Acc: 70.31
[Train] Epoch: 2 [548160/620022]    Loss: 0.009008   Batch Acc: 75.00
[Train] Epoch: 2 [548224/620022]    Loss: 0.009482   Batch Acc: 70.31
[Train] Epoch: 2 [548288/620022]    Loss: 0.009408   Batch Acc: 75.00
[Train] Epoch: 2 [548352/620022]    Loss: 0.007232   Batch Acc: 85.94
[Train] Epoch: 2 [548416/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 2 [548480/620022]    Loss: 0.012043   Batch Acc: 70.31
[Train] Epoch: 2 [548544/620022]    Loss: 0.007756   Batch Acc: 82.81
[Train] Epoch: 2 [548608/620022]    Loss: 0.008293   Batch Acc: 82.81
[Train] Epoch: 2 [548672/620022]    Loss: 0.007919   Batch Acc: 81.25
[Train] Epoch: 2 [548736/620022]    Loss: 0.009976   Batch Acc: 73.44
[Train] Epoch: 2 [548800/620022]    Loss: 0.007812   Batch Acc: 75.00
[Train] Epoch: 2 [548864/620022]    Loss: 0.008977   Batch Acc: 81.25
[Train] Epoch: 2 [548928/620022]    Loss: 0.012951   Batch Acc: 60.94
[Train] Epoch: 2 [548992/620022]    Loss: 0.011178   Batch Acc: 67.19
[Train] Epoch: 2 [549056/620022]    Loss: 0.008195   Batch Acc: 82.81
[Train] Epoch: 2 [549120/620022]    Loss: 0.009900   Batch Acc: 78.12
[Train] Epoch: 2 [549184/620022]    Loss: 0.006054   Batch Acc: 87.50
[Train] Epoch: 2 [549248/620022]    Loss: 0.008132   Batch Acc: 76.56
[Train] Epoch: 2 [549312/620022]    Loss: 0.006181   Batch Acc: 89.06
[Train] Epoch: 2 [549376/620022]    Loss: 0.009020   Batch Acc: 71.88
[Train] Epoch: 2 [549440/620022]    Loss: 0.006804   Batch Acc: 85.94
[Train] Epoch: 2 [549504/620022]    Loss: 0.008406   Batch Acc: 79.69
[Train] Epoch: 2 [549568/620022]    Loss: 0.007526   Batch Acc: 82.81
[Train] Epoch: 2 [549632/620022]    Loss: 0.007643   Batch Acc: 76.56
[Train] Epoch: 2 [549696/620022]    Loss: 0.009012   Batch Acc: 73.44
[Train] Epoch: 2 [549760/620022]    Loss: 0.011009   Batch Acc: 71.88
[Train] Epoch: 2 [549824/620022]    Loss: 0.008041   Batch Acc: 76.56
[Train] Epoch: 2 [549888/620022]    Loss: 0.011741   Batch Acc: 71.88
[Train] Epoch: 2 [549952/620022]    Loss: 0.010377   Batch Acc: 70.31
[Train] Epoch: 2 [550016/620022]    Loss: 0.007939   Batch Acc: 79.69
[Train] Epoch: 2 [550080/620022]    Loss: 0.009312   Batch Acc: 75.00
[Train] Epoch: 2 [550144/620022]    Loss: 0.007002   Batch Acc: 82.81
[Train] Epoch: 2 [550208/620022]    Loss: 0.008699   Batch Acc: 78.12
[Train] Epoch: 2 [550272/620022]    Loss: 0.006968   Batch Acc: 78.12
[Train] Epoch: 2 [550336/620022]    Loss: 0.008010   Batch Acc: 76.56
[Train] Epoch: 2 [550400/620022]    Loss: 0.010047   Batch Acc: 75.00
[Train] Epoch: 2 [550464/620022]    Loss: 0.008434   Batch Acc: 82.81
[Train] Epoch: 2 [550528/620022]    Loss: 0.008230   Batch Acc: 79.69
[Train] Epoch: 2 [550592/620022]    Loss: 0.010255   Batch Acc: 70.31
[Train] Epoch: 2 [550656/620022]    Loss: 0.007986   Batch Acc: 79.69
[Train] Epoch: 2 [550720/620022]    Loss: 0.009099   Batch Acc: 78.12
[Train] Epoch: 2 [550784/620022]    Loss: 0.011010   Batch Acc: 70.31
[Train] Epoch: 2 [550848/620022]    Loss: 0.011083   Batch Acc: 76.56
[Train] Epoch: 2 [550912/620022]    Loss: 0.007609   Batch Acc: 76.56
[Train] Epoch: 2 [550976/620022]    Loss: 0.011301   Batch Acc: 62.50
[Train] Epoch: 2 [551040/620022]    Loss: 0.008603   Batch Acc: 76.56
[Train] Epoch: 2 [551104/620022]    Loss: 0.009584   Batch Acc: 78.12
[Train] Epoch: 2 [551168/620022]    Loss: 0.008937   Batch Acc: 71.88
[Train] Epoch: 2 [551232/620022]    Loss: 0.007044   Batch Acc: 84.38
[Train] Epoch: 2 [551296/620022]    Loss: 0.009611   Batch Acc: 76.56
[Train] Epoch: 2 [551360/620022]    Loss: 0.010403   Batch Acc: 71.88
[Train] Epoch: 2 [551424/620022]    Loss: 0.008757   Batch Acc: 75.00
[Train] Epoch: 2 [551488/620022]    Loss: 0.006367   Batch Acc: 85.94
[Train] Epoch: 2 [551552/620022]    Loss: 0.008644   Batch Acc: 71.88
[Train] Epoch: 2 [551616/620022]    Loss: 0.009565   Batch Acc: 78.12
[Train] Epoch: 2 [551680/620022]    Loss: 0.006446   Batch Acc: 84.38
[Train] Epoch: 2 [551744/620022]    Loss: 0.009552   Batch Acc: 70.31
[Train] Epoch: 2 [551808/620022]    Loss: 0.007500   Batch Acc: 84.38
[Train] Epoch: 2 [551872/620022]    Loss: 0.007027   Batch Acc: 85.94
[Train] Epoch: 2 [551936/620022]    Loss: 0.007157   Batch Acc: 79.69
[Train] Epoch: 2 [552000/620022]    Loss: 0.008628   Batch Acc: 76.56
[Train] Epoch: 2 [552064/620022]    Loss: 0.006718   Batch Acc: 85.94
[Train] Epoch: 2 [552128/620022]    Loss: 0.007906   Batch Acc: 79.69
[Train] Epoch: 2 [552192/620022]    Loss: 0.010013   Batch Acc: 75.00
[Train] Epoch: 2 [552256/620022]    Loss: 0.010331   Batch Acc: 73.44
[Train] Epoch: 2 [552320/620022]    Loss: 0.007883   Batch Acc: 79.69
[Train] Epoch: 2 [552384/620022]    Loss: 0.007906   Batch Acc: 78.12
[Train] Epoch: 2 [552448/620022]    Loss: 0.007803   Batch Acc: 79.69
[Train] Epoch: 2 [552512/620022]    Loss: 0.008192   Batch Acc: 71.88
[Train] Epoch: 2 [552576/620022]    Loss: 0.008661   Batch Acc: 78.12
[Train] Epoch: 2 [552640/620022]    Loss: 0.010163   Batch Acc: 78.12
[Train] Epoch: 2 [552704/620022]    Loss: 0.007308   Batch Acc: 78.12
[Train] Epoch: 2 [552768/620022]    Loss: 0.009112   Batch Acc: 73.44
[Train] Epoch: 2 [552832/620022]    Loss: 0.009670   Batch Acc: 73.44
[Train] Epoch: 2 [552896/620022]    Loss: 0.006140   Batch Acc: 90.62
[Train] Epoch: 2 [552960/620022]    Loss: 0.009014   Batch Acc: 71.88
[Train] Epoch: 2 [553024/620022]    Loss: 0.007982   Batch Acc: 78.12
[Train] Epoch: 2 [553088/620022]    Loss: 0.009949   Batch Acc: 76.56
[Train] Epoch: 2 [553152/620022]    Loss: 0.009346   Batch Acc: 79.69
[Train] Epoch: 2 [553216/620022]    Loss: 0.009480   Batch Acc: 70.31
[Train] Epoch: 2 [553280/620022]    Loss: 0.009486   Batch Acc: 75.00
[Train] Epoch: 2 [553344/620022]    Loss: 0.007195   Batch Acc: 82.81
[Train] Epoch: 2 [553408/620022]    Loss: 0.006976   Batch Acc: 84.38
[Train] Epoch: 2 [553472/620022]    Loss: 0.011742   Batch Acc: 73.44
[Train] Epoch: 2 [553536/620022]    Loss: 0.009618   Batch Acc: 78.12
[Train] Epoch: 2 [553600/620022]    Loss: 0.006834   Batch Acc: 84.38
[Train] Epoch: 2 [553664/620022]    Loss: 0.006415   Batch Acc: 87.50
[Train] Epoch: 2 [553728/620022]    Loss: 0.007774   Batch Acc: 82.81
[Train] Epoch: 2 [553792/620022]    Loss: 0.007067   Batch Acc: 81.25
[Train] Epoch: 2 [553856/620022]    Loss: 0.008297   Batch Acc: 76.56
[Train] Epoch: 2 [553920/620022]    Loss: 0.007913   Batch Acc: 81.25
[Train] Epoch: 2 [553984/620022]    Loss: 0.007768   Batch Acc: 82.81
[Train] Epoch: 2 [554048/620022]    Loss: 0.011405   Batch Acc: 64.06
[Train] Epoch: 2 [554112/620022]    Loss: 0.005575   Batch Acc: 87.50
[Train] Epoch: 2 [554176/620022]    Loss: 0.009160   Batch Acc: 73.44
[Train] Epoch: 2 [554240/620022]    Loss: 0.010282   Batch Acc: 65.62
[Train] Epoch: 2 [554304/620022]    Loss: 0.006766   Batch Acc: 84.38
[Train] Epoch: 2 [554368/620022]    Loss: 0.009754   Batch Acc: 76.56
[Train] Epoch: 2 [554432/620022]    Loss: 0.008718   Batch Acc: 78.12
[Train] Epoch: 2 [554496/620022]    Loss: 0.009095   Batch Acc: 76.56
[Train] Epoch: 2 [554560/620022]    Loss: 0.011444   Batch Acc: 70.31
[Train] Epoch: 2 [554624/620022]    Loss: 0.007810   Batch Acc: 79.69
[Train] Epoch: 2 [554688/620022]    Loss: 0.008651   Batch Acc: 75.00
[Train] Epoch: 2 [554752/620022]    Loss: 0.008209   Batch Acc: 82.81
[Train] Epoch: 2 [554816/620022]    Loss: 0.008529   Batch Acc: 79.69
[Train] Epoch: 2 [554880/620022]    Loss: 0.005850   Batch Acc: 82.81
[Train] Epoch: 2 [554944/620022]    Loss: 0.009605   Batch Acc: 75.00
[Train] Epoch: 2 [555008/620022]    Loss: 0.009367   Batch Acc: 76.56
[Train] Epoch: 2 [555072/620022]    Loss: 0.007361   Batch Acc: 85.94
[Train] Epoch: 2 [555136/620022]    Loss: 0.010878   Batch Acc: 67.19
[Train] Epoch: 2 [555200/620022]    Loss: 0.008877   Batch Acc: 73.44
[Train] Epoch: 2 [555264/620022]    Loss: 0.007336   Batch Acc: 81.25
[Train] Epoch: 2 [555328/620022]    Loss: 0.006723   Batch Acc: 87.50
[Train] Epoch: 2 [555392/620022]    Loss: 0.009570   Batch Acc: 75.00
[Train] Epoch: 2 [555456/620022]    Loss: 0.011781   Batch Acc: 64.06
[Train] Epoch: 2 [555520/620022]    Loss: 0.008749   Batch Acc: 81.25
[Train] Epoch: 2 [555584/620022]    Loss: 0.008646   Batch Acc: 75.00
[Train] Epoch: 2 [555648/620022]    Loss: 0.010906   Batch Acc: 76.56
[Train] Epoch: 2 [555712/620022]    Loss: 0.008292   Batch Acc: 78.12
[Train] Epoch: 2 [555776/620022]    Loss: 0.008165   Batch Acc: 78.12
[Train] Epoch: 2 [555840/620022]    Loss: 0.008012   Batch Acc: 81.25
[Train] Epoch: 2 [555904/620022]    Loss: 0.007723   Batch Acc: 85.94
[Train] Epoch: 2 [555968/620022]    Loss: 0.011234   Batch Acc: 67.19
[Train] Epoch: 2 [556032/620022]    Loss: 0.008851   Batch Acc: 75.00
[Train] Epoch: 2 [556096/620022]    Loss: 0.008702   Batch Acc: 70.31
[Train] Epoch: 2 [556160/620022]    Loss: 0.006915   Batch Acc: 79.69
[Train] Epoch: 2 [556224/620022]    Loss: 0.007843   Batch Acc: 79.69
[Train] Epoch: 2 [556288/620022]    Loss: 0.007429   Batch Acc: 84.38
[Train] Epoch: 2 [556352/620022]    Loss: 0.006843   Batch Acc: 90.62
[Train] Epoch: 2 [556416/620022]    Loss: 0.007058   Batch Acc: 82.81
[Train] Epoch: 2 [556480/620022]    Loss: 0.010964   Batch Acc: 68.75
[Train] Epoch: 2 [556544/620022]    Loss: 0.007873   Batch Acc: 81.25
[Train] Epoch: 2 [556608/620022]    Loss: 0.007121   Batch Acc: 79.69
[Train] Epoch: 2 [556672/620022]    Loss: 0.009826   Batch Acc: 71.88
[Train] Epoch: 2 [556736/620022]    Loss: 0.007980   Batch Acc: 78.12
[Train] Epoch: 2 [556800/620022]    Loss: 0.006697   Batch Acc: 89.06
[Train] Epoch: 2 [556864/620022]    Loss: 0.008172   Batch Acc: 75.00
[Train] Epoch: 2 [556928/620022]    Loss: 0.009889   Batch Acc: 78.12
[Train] Epoch: 2 [556992/620022]    Loss: 0.009146   Batch Acc: 79.69
[Train] Epoch: 2 [557056/620022]    Loss: 0.009672   Batch Acc: 68.75
[Train] Epoch: 2 [557120/620022]    Loss: 0.010114   Batch Acc: 70.31
[Train] Epoch: 2 [557184/620022]    Loss: 0.006976   Batch Acc: 81.25
[Train] Epoch: 2 [557248/620022]    Loss: 0.010007   Batch Acc: 70.31
[Train] Epoch: 2 [557312/620022]    Loss: 0.007619   Batch Acc: 78.12
[Train] Epoch: 2 [557376/620022]    Loss: 0.006343   Batch Acc: 87.50
[Train] Epoch: 2 [557440/620022]    Loss: 0.007539   Batch Acc: 79.69
[Train] Epoch: 2 [557504/620022]    Loss: 0.009655   Batch Acc: 75.00
[Train] Epoch: 2 [557568/620022]    Loss: 0.008439   Batch Acc: 78.12
[Train] Epoch: 2 [557632/620022]    Loss: 0.009967   Batch Acc: 73.44
[Train] Epoch: 2 [557696/620022]    Loss: 0.010278   Batch Acc: 71.88
[Train] Epoch: 2 [557760/620022]    Loss: 0.007269   Batch Acc: 81.25
[Train] Epoch: 2 [557824/620022]    Loss: 0.008865   Batch Acc: 81.25
[Train] Epoch: 2 [557888/620022]    Loss: 0.009446   Batch Acc: 81.25
[Train] Epoch: 2 [557952/620022]    Loss: 0.011489   Batch Acc: 65.62
[Train] Epoch: 2 [558016/620022]    Loss: 0.008223   Batch Acc: 84.38
[Train] Epoch: 2 [558080/620022]    Loss: 0.012682   Batch Acc: 67.19
[Train] Epoch: 2 [558144/620022]    Loss: 0.011289   Batch Acc: 73.44
[Train] Epoch: 2 [558208/620022]    Loss: 0.008281   Batch Acc: 78.12
[Train] Epoch: 2 [558272/620022]    Loss: 0.011079   Batch Acc: 67.19
[Train] Epoch: 2 [558336/620022]    Loss: 0.008000   Batch Acc: 78.12
[Train] Epoch: 2 [558400/620022]    Loss: 0.006733   Batch Acc: 90.62
[Train] Epoch: 2 [558464/620022]    Loss: 0.013829   Batch Acc: 62.50
[Train] Epoch: 2 [558528/620022]    Loss: 0.006912   Batch Acc: 87.50
[Train] Epoch: 2 [558592/620022]    Loss: 0.008439   Batch Acc: 79.69
[Train] Epoch: 2 [558656/620022]    Loss: 0.009159   Batch Acc: 82.81
[Train] Epoch: 2 [558720/620022]    Loss: 0.010376   Batch Acc: 75.00
[Train] Epoch: 2 [558784/620022]    Loss: 0.008578   Batch Acc: 75.00
[Train] Epoch: 2 [558848/620022]    Loss: 0.008455   Batch Acc: 75.00
[Train] Epoch: 2 [558912/620022]    Loss: 0.007686   Batch Acc: 78.12
[Train] Epoch: 2 [558976/620022]    Loss: 0.007830   Batch Acc: 76.56
[Train] Epoch: 2 [559040/620022]    Loss: 0.008406   Batch Acc: 78.12
[Train] Epoch: 2 [559104/620022]    Loss: 0.008171   Batch Acc: 81.25
[Train] Epoch: 2 [559168/620022]    Loss: 0.007602   Batch Acc: 85.94
[Train] Epoch: 2 [559232/620022]    Loss: 0.006653   Batch Acc: 89.06
[Train] Epoch: 2 [559296/620022]    Loss: 0.008483   Batch Acc: 78.12
[Train] Epoch: 2 [559360/620022]    Loss: 0.010072   Batch Acc: 64.06
[Train] Epoch: 2 [559424/620022]    Loss: 0.008436   Batch Acc: 75.00
[Train] Epoch: 2 [559488/620022]    Loss: 0.010204   Batch Acc: 70.31
[Train] Epoch: 2 [559552/620022]    Loss: 0.009373   Batch Acc: 76.56
[Train] Epoch: 2 [559616/620022]    Loss: 0.009207   Batch Acc: 76.56
[Train] Epoch: 2 [559680/620022]    Loss: 0.009884   Batch Acc: 73.44
[Train] Epoch: 2 [559744/620022]    Loss: 0.007676   Batch Acc: 78.12
[Train] Epoch: 2 [559808/620022]    Loss: 0.008267   Batch Acc: 82.81
[Train] Epoch: 2 [559872/620022]    Loss: 0.006912   Batch Acc: 81.25
[Train] Epoch: 2 [559936/620022]    Loss: 0.008523   Batch Acc: 84.38
[Train] Epoch: 2 [560000/620022]    Loss: 0.007822   Batch Acc: 76.56
[Train] Epoch: 2 [560064/620022]    Loss: 0.012554   Batch Acc: 64.06
[Train] Epoch: 2 [560128/620022]    Loss: 0.010003   Batch Acc: 73.44
[Train] Epoch: 2 [560192/620022]    Loss: 0.007547   Batch Acc: 81.25
[Train] Epoch: 2 [560256/620022]    Loss: 0.008992   Batch Acc: 79.69
[Train] Epoch: 2 [560320/620022]    Loss: 0.007759   Batch Acc: 81.25
[Train] Epoch: 2 [560384/620022]    Loss: 0.007776   Batch Acc: 78.12
[Train] Epoch: 2 [560448/620022]    Loss: 0.007848   Batch Acc: 82.81
[Train] Epoch: 2 [560512/620022]    Loss: 0.011757   Batch Acc: 64.06
[Train] Epoch: 2 [560576/620022]    Loss: 0.007200   Batch Acc: 84.38
[Train] Epoch: 2 [560640/620022]    Loss: 0.007196   Batch Acc: 84.38
[Train] Epoch: 2 [560704/620022]    Loss: 0.006844   Batch Acc: 85.94
[Train] Epoch: 2 [560768/620022]    Loss: 0.010301   Batch Acc: 73.44
[Train] Epoch: 2 [560832/620022]    Loss: 0.008008   Batch Acc: 82.81
[Train] Epoch: 2 [560896/620022]    Loss: 0.007709   Batch Acc: 82.81
[Train] Epoch: 2 [560960/620022]    Loss: 0.007003   Batch Acc: 82.81
[Train] Epoch: 2 [561024/620022]    Loss: 0.008633   Batch Acc: 76.56
[Train] Epoch: 2 [561088/620022]    Loss: 0.008829   Batch Acc: 81.25
[Train] Epoch: 2 [561152/620022]    Loss: 0.007409   Batch Acc: 79.69
[Train] Epoch: 2 [561216/620022]    Loss: 0.007389   Batch Acc: 79.69
[Train] Epoch: 2 [561280/620022]    Loss: 0.008613   Batch Acc: 76.56
[Train] Epoch: 2 [561344/620022]    Loss: 0.007343   Batch Acc: 79.69
[Train] Epoch: 2 [561408/620022]    Loss: 0.008864   Batch Acc: 76.56
[Train] Epoch: 2 [561472/620022]    Loss: 0.008493   Batch Acc: 79.69
[Train] Epoch: 2 [561536/620022]    Loss: 0.008276   Batch Acc: 82.81
[Train] Epoch: 2 [561600/620022]    Loss: 0.008685   Batch Acc: 78.12
[Train] Epoch: 2 [561664/620022]    Loss: 0.008355   Batch Acc: 81.25
[Train] Epoch: 2 [561728/620022]    Loss: 0.010787   Batch Acc: 73.44
[Train] Epoch: 2 [561792/620022]    Loss: 0.007357   Batch Acc: 81.25
[Train] Epoch: 2 [561856/620022]    Loss: 0.007099   Batch Acc: 84.38
[Train] Epoch: 2 [561920/620022]    Loss: 0.010204   Batch Acc: 71.88
[Train] Epoch: 2 [561984/620022]    Loss: 0.007378   Batch Acc: 85.94
[Train] Epoch: 2 [562048/620022]    Loss: 0.011114   Batch Acc: 70.31
[Train] Epoch: 2 [562112/620022]    Loss: 0.009511   Batch Acc: 71.88
[Train] Epoch: 2 [562176/620022]    Loss: 0.009186   Batch Acc: 71.88
[Train] Epoch: 2 [562240/620022]    Loss: 0.008453   Batch Acc: 76.56
[Train] Epoch: 2 [562304/620022]    Loss: 0.008143   Batch Acc: 84.38
[Train] Epoch: 2 [562368/620022]    Loss: 0.009494   Batch Acc: 76.56
[Train] Epoch: 2 [562432/620022]    Loss: 0.010151   Batch Acc: 70.31
[Train] Epoch: 2 [562496/620022]    Loss: 0.008284   Batch Acc: 84.38
[Train] Epoch: 2 [562560/620022]    Loss: 0.007974   Batch Acc: 76.56
[Train] Epoch: 2 [562624/620022]    Loss: 0.006451   Batch Acc: 84.38
[Train] Epoch: 2 [562688/620022]    Loss: 0.010827   Batch Acc: 70.31
[Train] Epoch: 2 [562752/620022]    Loss: 0.008013   Batch Acc: 78.12
[Train] Epoch: 2 [562816/620022]    Loss: 0.007953   Batch Acc: 82.81
[Train] Epoch: 2 [562880/620022]    Loss: 0.007958   Batch Acc: 73.44
[Train] Epoch: 2 [562944/620022]    Loss: 0.009223   Batch Acc: 76.56
[Train] Epoch: 2 [563008/620022]    Loss: 0.008733   Batch Acc: 73.44
[Train] Epoch: 2 [563072/620022]    Loss: 0.008055   Batch Acc: 84.38
[Train] Epoch: 2 [563136/620022]    Loss: 0.009371   Batch Acc: 71.88
[Train] Epoch: 2 [563200/620022]    Loss: 0.006917   Batch Acc: 85.94
[Train] Epoch: 2 [563264/620022]    Loss: 0.007718   Batch Acc: 76.56
[Train] Epoch: 2 [563328/620022]    Loss: 0.007962   Batch Acc: 84.38
[Train] Epoch: 2 [563392/620022]    Loss: 0.007091   Batch Acc: 81.25
[Train] Epoch: 2 [563456/620022]    Loss: 0.010078   Batch Acc: 65.62
[Train] Epoch: 2 [563520/620022]    Loss: 0.006824   Batch Acc: 82.81
[Train] Epoch: 2 [563584/620022]    Loss: 0.009357   Batch Acc: 78.12
[Train] Epoch: 2 [563648/620022]    Loss: 0.009414   Batch Acc: 70.31
[Train] Epoch: 2 [563712/620022]    Loss: 0.008707   Batch Acc: 82.81
[Train] Epoch: 2 [563776/620022]    Loss: 0.009801   Batch Acc: 75.00
[Train] Epoch: 2 [563840/620022]    Loss: 0.008739   Batch Acc: 78.12
[Train] Epoch: 2 [563904/620022]    Loss: 0.009989   Batch Acc: 76.56
[Train] Epoch: 2 [563968/620022]    Loss: 0.007004   Batch Acc: 79.69
[Train] Epoch: 2 [564032/620022]    Loss: 0.008677   Batch Acc: 78.12
[Train] Epoch: 2 [564096/620022]    Loss: 0.009321   Batch Acc: 76.56
[Train] Epoch: 2 [564160/620022]    Loss: 0.009226   Batch Acc: 71.88
[Train] Epoch: 2 [564224/620022]    Loss: 0.009581   Batch Acc: 70.31
[Train] Epoch: 2 [564288/620022]    Loss: 0.011634   Batch Acc: 65.62
[Train] Epoch: 2 [564352/620022]    Loss: 0.009151   Batch Acc: 70.31
[Train] Epoch: 2 [564416/620022]    Loss: 0.008817   Batch Acc: 75.00
[Train] Epoch: 2 [564480/620022]    Loss: 0.006428   Batch Acc: 84.38
[Train] Epoch: 2 [564544/620022]    Loss: 0.007659   Batch Acc: 82.81
[Train] Epoch: 2 [564608/620022]    Loss: 0.010452   Batch Acc: 73.44
[Train] Epoch: 2 [564672/620022]    Loss: 0.007516   Batch Acc: 81.25
[Train] Epoch: 2 [564736/620022]    Loss: 0.007579   Batch Acc: 85.94
[Train] Epoch: 2 [564800/620022]    Loss: 0.009136   Batch Acc: 73.44
[Train] Epoch: 2 [564864/620022]    Loss: 0.009998   Batch Acc: 71.88
[Train] Epoch: 2 [564928/620022]    Loss: 0.010142   Batch Acc: 71.88
[Train] Epoch: 2 [564992/620022]    Loss: 0.009979   Batch Acc: 76.56
[Train] Epoch: 2 [565056/620022]    Loss: 0.010004   Batch Acc: 75.00
[Train] Epoch: 2 [565120/620022]    Loss: 0.010482   Batch Acc: 67.19
[Train] Epoch: 2 [565184/620022]    Loss: 0.008163   Batch Acc: 81.25
[Train] Epoch: 2 [565248/620022]    Loss: 0.006779   Batch Acc: 82.81
[Train] Epoch: 2 [565312/620022]    Loss: 0.009820   Batch Acc: 75.00
[Train] Epoch: 2 [565376/620022]    Loss: 0.008477   Batch Acc: 78.12
[Train] Epoch: 2 [565440/620022]    Loss: 0.006715   Batch Acc: 84.38
[Train] Epoch: 2 [565504/620022]    Loss: 0.007774   Batch Acc: 79.69
[Train] Epoch: 2 [565568/620022]    Loss: 0.009335   Batch Acc: 82.81
[Train] Epoch: 2 [565632/620022]    Loss: 0.008792   Batch Acc: 81.25
[Train] Epoch: 2 [565696/620022]    Loss: 0.010319   Batch Acc: 79.69
[Train] Epoch: 2 [565760/620022]    Loss: 0.009418   Batch Acc: 75.00
[Train] Epoch: 2 [565824/620022]    Loss: 0.010115   Batch Acc: 71.88
[Train] Epoch: 2 [565888/620022]    Loss: 0.008919   Batch Acc: 76.56
[Train] Epoch: 2 [565952/620022]    Loss: 0.010413   Batch Acc: 76.56
[Train] Epoch: 2 [566016/620022]    Loss: 0.008996   Batch Acc: 76.56
[Train] Epoch: 2 [566080/620022]    Loss: 0.008628   Batch Acc: 81.25
[Train] Epoch: 2 [566144/620022]    Loss: 0.010789   Batch Acc: 62.50
[Train] Epoch: 2 [566208/620022]    Loss: 0.008224   Batch Acc: 84.38
[Train] Epoch: 2 [566272/620022]    Loss: 0.009482   Batch Acc: 75.00
[Train] Epoch: 2 [566336/620022]    Loss: 0.010079   Batch Acc: 75.00
[Train] Epoch: 2 [566400/620022]    Loss: 0.008313   Batch Acc: 76.56
[Train] Epoch: 2 [566464/620022]    Loss: 0.007967   Batch Acc: 82.81
[Train] Epoch: 2 [566528/620022]    Loss: 0.007324   Batch Acc: 81.25
[Train] Epoch: 2 [566592/620022]    Loss: 0.007825   Batch Acc: 75.00
[Train] Epoch: 2 [566656/620022]    Loss: 0.007474   Batch Acc: 82.81
[Train] Epoch: 2 [566720/620022]    Loss: 0.011663   Batch Acc: 71.88
[Train] Epoch: 2 [566784/620022]    Loss: 0.006504   Batch Acc: 85.94
[Train] Epoch: 2 [566848/620022]    Loss: 0.007471   Batch Acc: 82.81
[Train] Epoch: 2 [566912/620022]    Loss: 0.007621   Batch Acc: 79.69
[Train] Epoch: 2 [566976/620022]    Loss: 0.011645   Batch Acc: 70.31
[Train] Epoch: 2 [567040/620022]    Loss: 0.007310   Batch Acc: 82.81
[Train] Epoch: 2 [567104/620022]    Loss: 0.010351   Batch Acc: 71.88
[Train] Epoch: 2 [567168/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 2 [567232/620022]    Loss: 0.007713   Batch Acc: 82.81
[Train] Epoch: 2 [567296/620022]    Loss: 0.008327   Batch Acc: 82.81
[Train] Epoch: 2 [567360/620022]    Loss: 0.007280   Batch Acc: 82.81
[Train] Epoch: 2 [567424/620022]    Loss: 0.005555   Batch Acc: 89.06
[Train] Epoch: 2 [567488/620022]    Loss: 0.009031   Batch Acc: 76.56
[Train] Epoch: 2 [567552/620022]    Loss: 0.011363   Batch Acc: 65.62
[Train] Epoch: 2 [567616/620022]    Loss: 0.006814   Batch Acc: 81.25
[Train] Epoch: 2 [567680/620022]    Loss: 0.007250   Batch Acc: 84.38
[Train] Epoch: 2 [567744/620022]    Loss: 0.012051   Batch Acc: 68.75
[Train] Epoch: 2 [567808/620022]    Loss: 0.007803   Batch Acc: 79.69
[Train] Epoch: 2 [567872/620022]    Loss: 0.009601   Batch Acc: 76.56
[Train] Epoch: 2 [567936/620022]    Loss: 0.009549   Batch Acc: 68.75
[Train] Epoch: 2 [568000/620022]    Loss: 0.009536   Batch Acc: 70.31
[Train] Epoch: 2 [568064/620022]    Loss: 0.005972   Batch Acc: 90.62
[Train] Epoch: 2 [568128/620022]    Loss: 0.009381   Batch Acc: 81.25
[Train] Epoch: 2 [568192/620022]    Loss: 0.010785   Batch Acc: 78.12
[Train] Epoch: 2 [568256/620022]    Loss: 0.008019   Batch Acc: 79.69
[Train] Epoch: 2 [568320/620022]    Loss: 0.007969   Batch Acc: 81.25
[Train] Epoch: 2 [568384/620022]    Loss: 0.005511   Batch Acc: 89.06
[Train] Epoch: 2 [568448/620022]    Loss: 0.008118   Batch Acc: 81.25
[Train] Epoch: 2 [568512/620022]    Loss: 0.007921   Batch Acc: 78.12
[Train] Epoch: 2 [568576/620022]    Loss: 0.008018   Batch Acc: 81.25
[Train] Epoch: 2 [568640/620022]    Loss: 0.011190   Batch Acc: 68.75
[Train] Epoch: 2 [568704/620022]    Loss: 0.008190   Batch Acc: 79.69
[Train] Epoch: 2 [568768/620022]    Loss: 0.010069   Batch Acc: 75.00
[Train] Epoch: 2 [568832/620022]    Loss: 0.008438   Batch Acc: 84.38
[Train] Epoch: 2 [568896/620022]    Loss: 0.007518   Batch Acc: 81.25
[Train] Epoch: 2 [568960/620022]    Loss: 0.008765   Batch Acc: 71.88
[Train] Epoch: 2 [569024/620022]    Loss: 0.008707   Batch Acc: 78.12
[Train] Epoch: 2 [569088/620022]    Loss: 0.007378   Batch Acc: 81.25
[Train] Epoch: 2 [569152/620022]    Loss: 0.008455   Batch Acc: 81.25
[Train] Epoch: 2 [569216/620022]    Loss: 0.008395   Batch Acc: 78.12
[Train] Epoch: 2 [569280/620022]    Loss: 0.010073   Batch Acc: 78.12
[Train] Epoch: 2 [569344/620022]    Loss: 0.005984   Batch Acc: 85.94
[Train] Epoch: 2 [569408/620022]    Loss: 0.010459   Batch Acc: 78.12
[Train] Epoch: 2 [569472/620022]    Loss: 0.007814   Batch Acc: 76.56
[Train] Epoch: 2 [569536/620022]    Loss: 0.010847   Batch Acc: 70.31
[Train] Epoch: 2 [569600/620022]    Loss: 0.012142   Batch Acc: 62.50
[Train] Epoch: 2 [569664/620022]    Loss: 0.009365   Batch Acc: 78.12
[Train] Epoch: 2 [569728/620022]    Loss: 0.007466   Batch Acc: 82.81
[Train] Epoch: 2 [569792/620022]    Loss: 0.008112   Batch Acc: 76.56
[Train] Epoch: 2 [569856/620022]    Loss: 0.008821   Batch Acc: 73.44
[Train] Epoch: 2 [569920/620022]    Loss: 0.008206   Batch Acc: 81.25
[Train] Epoch: 2 [569984/620022]    Loss: 0.007595   Batch Acc: 82.81
[Train] Epoch: 2 [570048/620022]    Loss: 0.008225   Batch Acc: 81.25
[Train] Epoch: 2 [570112/620022]    Loss: 0.010827   Batch Acc: 70.31
[Train] Epoch: 2 [570176/620022]    Loss: 0.007001   Batch Acc: 79.69
[Train] Epoch: 2 [570240/620022]    Loss: 0.007535   Batch Acc: 82.81
[Train] Epoch: 2 [570304/620022]    Loss: 0.010829   Batch Acc: 78.12
[Train] Epoch: 2 [570368/620022]    Loss: 0.011092   Batch Acc: 70.31
[Train] Epoch: 2 [570432/620022]    Loss: 0.008741   Batch Acc: 79.69
[Train] Epoch: 2 [570496/620022]    Loss: 0.007878   Batch Acc: 76.56
[Train] Epoch: 2 [570560/620022]    Loss: 0.010738   Batch Acc: 71.88
[Train] Epoch: 2 [570624/620022]    Loss: 0.008345   Batch Acc: 79.69
[Train] Epoch: 2 [570688/620022]    Loss: 0.009639   Batch Acc: 68.75
[Train] Epoch: 2 [570752/620022]    Loss: 0.008014   Batch Acc: 78.12
[Train] Epoch: 2 [570816/620022]    Loss: 0.009970   Batch Acc: 71.88
[Train] Epoch: 2 [570880/620022]    Loss: 0.008842   Batch Acc: 71.88
[Train] Epoch: 2 [570944/620022]    Loss: 0.009421   Batch Acc: 73.44
[Train] Epoch: 2 [571008/620022]    Loss: 0.007529   Batch Acc: 79.69
[Train] Epoch: 2 [571072/620022]    Loss: 0.008609   Batch Acc: 81.25
[Train] Epoch: 2 [571136/620022]    Loss: 0.008591   Batch Acc: 71.88
[Train] Epoch: 2 [571200/620022]    Loss: 0.009795   Batch Acc: 71.88
[Train] Epoch: 2 [571264/620022]    Loss: 0.010061   Batch Acc: 78.12
[Train] Epoch: 2 [571328/620022]    Loss: 0.008281   Batch Acc: 76.56
[Train] Epoch: 2 [571392/620022]    Loss: 0.009411   Batch Acc: 73.44
[Train] Epoch: 2 [571456/620022]    Loss: 0.008885   Batch Acc: 68.75
[Train] Epoch: 2 [571520/620022]    Loss: 0.008395   Batch Acc: 76.56
[Train] Epoch: 2 [571584/620022]    Loss: 0.007879   Batch Acc: 79.69
[Train] Epoch: 2 [571648/620022]    Loss: 0.008360   Batch Acc: 76.56
[Train] Epoch: 2 [571712/620022]    Loss: 0.010570   Batch Acc: 73.44
[Train] Epoch: 2 [571776/620022]    Loss: 0.009756   Batch Acc: 76.56
[Train] Epoch: 2 [571840/620022]    Loss: 0.009813   Batch Acc: 67.19
[Train] Epoch: 2 [571904/620022]    Loss: 0.008040   Batch Acc: 78.12
[Train] Epoch: 2 [571968/620022]    Loss: 0.008534   Batch Acc: 76.56
[Train] Epoch: 2 [572032/620022]    Loss: 0.012956   Batch Acc: 65.62
[Train] Epoch: 2 [572096/620022]    Loss: 0.007754   Batch Acc: 84.38
[Train] Epoch: 2 [572160/620022]    Loss: 0.009242   Batch Acc: 76.56
[Train] Epoch: 2 [572224/620022]    Loss: 0.006303   Batch Acc: 84.38
[Train] Epoch: 2 [572288/620022]    Loss: 0.008221   Batch Acc: 79.69
[Train] Epoch: 2 [572352/620022]    Loss: 0.011715   Batch Acc: 70.31
[Train] Epoch: 2 [572416/620022]    Loss: 0.010432   Batch Acc: 71.88
[Train] Epoch: 2 [572480/620022]    Loss: 0.009431   Batch Acc: 73.44
[Train] Epoch: 2 [572544/620022]    Loss: 0.008404   Batch Acc: 79.69
[Train] Epoch: 2 [572608/620022]    Loss: 0.009153   Batch Acc: 71.88
[Train] Epoch: 2 [572672/620022]    Loss: 0.008575   Batch Acc: 78.12
[Train] Epoch: 2 [572736/620022]    Loss: 0.011219   Batch Acc: 71.88
[Train] Epoch: 2 [572800/620022]    Loss: 0.009485   Batch Acc: 79.69
[Train] Epoch: 2 [572864/620022]    Loss: 0.007831   Batch Acc: 81.25
[Train] Epoch: 2 [572928/620022]    Loss: 0.010291   Batch Acc: 70.31
[Train] Epoch: 2 [572992/620022]    Loss: 0.006199   Batch Acc: 82.81
[Train] Epoch: 2 [573056/620022]    Loss: 0.008544   Batch Acc: 78.12
[Train] Epoch: 2 [573120/620022]    Loss: 0.008229   Batch Acc: 82.81
[Train] Epoch: 2 [573184/620022]    Loss: 0.007518   Batch Acc: 82.81
[Train] Epoch: 2 [573248/620022]    Loss: 0.010143   Batch Acc: 67.19
[Train] Epoch: 2 [573312/620022]    Loss: 0.007043   Batch Acc: 84.38
[Train] Epoch: 2 [573376/620022]    Loss: 0.007281   Batch Acc: 82.81
[Train] Epoch: 2 [573440/620022]    Loss: 0.008050   Batch Acc: 78.12
[Train] Epoch: 2 [573504/620022]    Loss: 0.008577   Batch Acc: 78.12
[Train] Epoch: 2 [573568/620022]    Loss: 0.009663   Batch Acc: 73.44
[Train] Epoch: 2 [573632/620022]    Loss: 0.008574   Batch Acc: 82.81
[Train] Epoch: 2 [573696/620022]    Loss: 0.007492   Batch Acc: 81.25
[Train] Epoch: 2 [573760/620022]    Loss: 0.010535   Batch Acc: 68.75
[Train] Epoch: 2 [573824/620022]    Loss: 0.008327   Batch Acc: 76.56
[Train] Epoch: 2 [573888/620022]    Loss: 0.009767   Batch Acc: 78.12
[Train] Epoch: 2 [573952/620022]    Loss: 0.011524   Batch Acc: 70.31
[Train] Epoch: 2 [574016/620022]    Loss: 0.010334   Batch Acc: 76.56
[Train] Epoch: 2 [574080/620022]    Loss: 0.009321   Batch Acc: 68.75
[Train] Epoch: 2 [574144/620022]    Loss: 0.006662   Batch Acc: 89.06
[Train] Epoch: 2 [574208/620022]    Loss: 0.009357   Batch Acc: 73.44
[Train] Epoch: 2 [574272/620022]    Loss: 0.011372   Batch Acc: 62.50
[Train] Epoch: 2 [574336/620022]    Loss: 0.009469   Batch Acc: 73.44
[Train] Epoch: 2 [574400/620022]    Loss: 0.011223   Batch Acc: 70.31
[Train] Epoch: 2 [574464/620022]    Loss: 0.008874   Batch Acc: 73.44
[Train] Epoch: 2 [574528/620022]    Loss: 0.007541   Batch Acc: 75.00
[Train] Epoch: 2 [574592/620022]    Loss: 0.008200   Batch Acc: 81.25
[Train] Epoch: 2 [574656/620022]    Loss: 0.011925   Batch Acc: 70.31
[Train] Epoch: 2 [574720/620022]    Loss: 0.009768   Batch Acc: 73.44
[Train] Epoch: 2 [574784/620022]    Loss: 0.009492   Batch Acc: 73.44
[Train] Epoch: 2 [574848/620022]    Loss: 0.007736   Batch Acc: 75.00
[Train] Epoch: 2 [574912/620022]    Loss: 0.007914   Batch Acc: 78.12
[Train] Epoch: 2 [574976/620022]    Loss: 0.008622   Batch Acc: 78.12
[Train] Epoch: 2 [575040/620022]    Loss: 0.009096   Batch Acc: 79.69
[Train] Epoch: 2 [575104/620022]    Loss: 0.009768   Batch Acc: 71.88
[Train] Epoch: 2 [575168/620022]    Loss: 0.007730   Batch Acc: 81.25
[Train] Epoch: 2 [575232/620022]    Loss: 0.008151   Batch Acc: 79.69
[Train] Epoch: 2 [575296/620022]    Loss: 0.008283   Batch Acc: 79.69
[Train] Epoch: 2 [575360/620022]    Loss: 0.008315   Batch Acc: 75.00
[Train] Epoch: 2 [575424/620022]    Loss: 0.007977   Batch Acc: 82.81
[Train] Epoch: 2 [575488/620022]    Loss: 0.010413   Batch Acc: 71.88
[Train] Epoch: 2 [575552/620022]    Loss: 0.009151   Batch Acc: 71.88
[Train] Epoch: 2 [575616/620022]    Loss: 0.009531   Batch Acc: 81.25
[Train] Epoch: 2 [575680/620022]    Loss: 0.009556   Batch Acc: 76.56
[Train] Epoch: 2 [575744/620022]    Loss: 0.008164   Batch Acc: 79.69
[Train] Epoch: 2 [575808/620022]    Loss: 0.010993   Batch Acc: 75.00
[Train] Epoch: 2 [575872/620022]    Loss: 0.007402   Batch Acc: 84.38
[Train] Epoch: 2 [575936/620022]    Loss: 0.008807   Batch Acc: 71.88
[Train] Epoch: 2 [576000/620022]    Loss: 0.008932   Batch Acc: 76.56
[Train] Epoch: 2 [576064/620022]    Loss: 0.009337   Batch Acc: 71.88
[Train] Epoch: 2 [576128/620022]    Loss: 0.007540   Batch Acc: 81.25
[Train] Epoch: 2 [576192/620022]    Loss: 0.006940   Batch Acc: 84.38
[Train] Epoch: 2 [576256/620022]    Loss: 0.007640   Batch Acc: 84.38
[Train] Epoch: 2 [576320/620022]    Loss: 0.007890   Batch Acc: 85.94
[Train] Epoch: 2 [576384/620022]    Loss: 0.007484   Batch Acc: 76.56
[Train] Epoch: 2 [576448/620022]    Loss: 0.009638   Batch Acc: 75.00
[Train] Epoch: 2 [576512/620022]    Loss: 0.008331   Batch Acc: 78.12
[Train] Epoch: 2 [576576/620022]    Loss: 0.007469   Batch Acc: 79.69
[Train] Epoch: 2 [576640/620022]    Loss: 0.010659   Batch Acc: 71.88
[Train] Epoch: 2 [576704/620022]    Loss: 0.006864   Batch Acc: 90.62
[Train] Epoch: 2 [576768/620022]    Loss: 0.008659   Batch Acc: 73.44
[Train] Epoch: 2 [576832/620022]    Loss: 0.008277   Batch Acc: 75.00
[Train] Epoch: 2 [576896/620022]    Loss: 0.008183   Batch Acc: 76.56
[Train] Epoch: 2 [576960/620022]    Loss: 0.007117   Batch Acc: 81.25
[Train] Epoch: 2 [577024/620022]    Loss: 0.009886   Batch Acc: 76.56
[Train] Epoch: 2 [577088/620022]    Loss: 0.009132   Batch Acc: 79.69
[Train] Epoch: 2 [577152/620022]    Loss: 0.010359   Batch Acc: 71.88
[Train] Epoch: 2 [577216/620022]    Loss: 0.010730   Batch Acc: 70.31
[Train] Epoch: 2 [577280/620022]    Loss: 0.008070   Batch Acc: 81.25
[Train] Epoch: 2 [577344/620022]    Loss: 0.011320   Batch Acc: 73.44
[Train] Epoch: 2 [577408/620022]    Loss: 0.009156   Batch Acc: 78.12
[Train] Epoch: 2 [577472/620022]    Loss: 0.011807   Batch Acc: 64.06
[Train] Epoch: 2 [577536/620022]    Loss: 0.008784   Batch Acc: 73.44
[Train] Epoch: 2 [577600/620022]    Loss: 0.008635   Batch Acc: 81.25
[Train] Epoch: 2 [577664/620022]    Loss: 0.008476   Batch Acc: 76.56
[Train] Epoch: 2 [577728/620022]    Loss: 0.008079   Batch Acc: 79.69
[Train] Epoch: 2 [577792/620022]    Loss: 0.007615   Batch Acc: 84.38
[Train] Epoch: 2 [577856/620022]    Loss: 0.008650   Batch Acc: 82.81
[Train] Epoch: 2 [577920/620022]    Loss: 0.009455   Batch Acc: 79.69
[Train] Epoch: 2 [577984/620022]    Loss: 0.008591   Batch Acc: 75.00
[Train] Epoch: 2 [578048/620022]    Loss: 0.008930   Batch Acc: 79.69
[Train] Epoch: 2 [578112/620022]    Loss: 0.007589   Batch Acc: 85.94
[Train] Epoch: 2 [578176/620022]    Loss: 0.008373   Batch Acc: 75.00
[Train] Epoch: 2 [578240/620022]    Loss: 0.008825   Batch Acc: 76.56
[Train] Epoch: 2 [578304/620022]    Loss: 0.008740   Batch Acc: 71.88
[Train] Epoch: 2 [578368/620022]    Loss: 0.011542   Batch Acc: 68.75
[Train] Epoch: 2 [578432/620022]    Loss: 0.011317   Batch Acc: 71.88
[Train] Epoch: 2 [578496/620022]    Loss: 0.008308   Batch Acc: 75.00
[Train] Epoch: 2 [578560/620022]    Loss: 0.009312   Batch Acc: 76.56
[Train] Epoch: 2 [578624/620022]    Loss: 0.008418   Batch Acc: 82.81
[Train] Epoch: 2 [578688/620022]    Loss: 0.007809   Batch Acc: 81.25
[Train] Epoch: 2 [578752/620022]    Loss: 0.008988   Batch Acc: 73.44
[Train] Epoch: 2 [578816/620022]    Loss: 0.008429   Batch Acc: 84.38
[Train] Epoch: 2 [578880/620022]    Loss: 0.008013   Batch Acc: 79.69
[Train] Epoch: 2 [578944/620022]    Loss: 0.007794   Batch Acc: 79.69
[Train] Epoch: 2 [579008/620022]    Loss: 0.011299   Batch Acc: 67.19
[Train] Epoch: 2 [579072/620022]    Loss: 0.007459   Batch Acc: 81.25
[Train] Epoch: 2 [579136/620022]    Loss: 0.008967   Batch Acc: 76.56
[Train] Epoch: 2 [579200/620022]    Loss: 0.008817   Batch Acc: 76.56
[Train] Epoch: 2 [579264/620022]    Loss: 0.008174   Batch Acc: 81.25
[Train] Epoch: 2 [579328/620022]    Loss: 0.009724   Batch Acc: 67.19
[Train] Epoch: 2 [579392/620022]    Loss: 0.009415   Batch Acc: 76.56
[Train] Epoch: 2 [579456/620022]    Loss: 0.008033   Batch Acc: 78.12
[Train] Epoch: 2 [579520/620022]    Loss: 0.010304   Batch Acc: 71.88
[Train] Epoch: 2 [579584/620022]    Loss: 0.009751   Batch Acc: 73.44
[Train] Epoch: 2 [579648/620022]    Loss: 0.007878   Batch Acc: 79.69
[Train] Epoch: 2 [579712/620022]    Loss: 0.008057   Batch Acc: 84.38
[Train] Epoch: 2 [579776/620022]    Loss: 0.009065   Batch Acc: 79.69
[Train] Epoch: 2 [579840/620022]    Loss: 0.009818   Batch Acc: 75.00
[Train] Epoch: 2 [579904/620022]    Loss: 0.009104   Batch Acc: 76.56
[Train] Epoch: 2 [579968/620022]    Loss: 0.009369   Batch Acc: 78.12
[Train] Epoch: 2 [580032/620022]    Loss: 0.008300   Batch Acc: 82.81
[Train] Epoch: 2 [580096/620022]    Loss: 0.005857   Batch Acc: 87.50
[Train] Epoch: 2 [580160/620022]    Loss: 0.010702   Batch Acc: 71.88
[Train] Epoch: 2 [580224/620022]    Loss: 0.008597   Batch Acc: 81.25
[Train] Epoch: 2 [580288/620022]    Loss: 0.010064   Batch Acc: 71.88
[Train] Epoch: 2 [580352/620022]    Loss: 0.008939   Batch Acc: 73.44
[Train] Epoch: 2 [580416/620022]    Loss: 0.008683   Batch Acc: 84.38
[Train] Epoch: 2 [580480/620022]    Loss: 0.009345   Batch Acc: 73.44
[Train] Epoch: 2 [580544/620022]    Loss: 0.008798   Batch Acc: 75.00
[Train] Epoch: 2 [580608/620022]    Loss: 0.008622   Batch Acc: 71.88
[Train] Epoch: 2 [580672/620022]    Loss: 0.009596   Batch Acc: 78.12
[Train] Epoch: 2 [580736/620022]    Loss: 0.009221   Batch Acc: 76.56
[Train] Epoch: 2 [580800/620022]    Loss: 0.011567   Batch Acc: 71.88
[Train] Epoch: 2 [580864/620022]    Loss: 0.008374   Batch Acc: 78.12
[Train] Epoch: 2 [580928/620022]    Loss: 0.006558   Batch Acc: 82.81
[Train] Epoch: 2 [580992/620022]    Loss: 0.009145   Batch Acc: 76.56
[Train] Epoch: 2 [581056/620022]    Loss: 0.008863   Batch Acc: 81.25
[Train] Epoch: 2 [581120/620022]    Loss: 0.010902   Batch Acc: 73.44
[Train] Epoch: 2 [581184/620022]    Loss: 0.009868   Batch Acc: 73.44
[Train] Epoch: 2 [581248/620022]    Loss: 0.007692   Batch Acc: 82.81
[Train] Epoch: 2 [581312/620022]    Loss: 0.009512   Batch Acc: 79.69
[Train] Epoch: 2 [581376/620022]    Loss: 0.007392   Batch Acc: 85.94
[Train] Epoch: 2 [581440/620022]    Loss: 0.007851   Batch Acc: 81.25
[Train] Epoch: 2 [581504/620022]    Loss: 0.006781   Batch Acc: 81.25
[Train] Epoch: 2 [581568/620022]    Loss: 0.007687   Batch Acc: 78.12
[Train] Epoch: 2 [581632/620022]    Loss: 0.008374   Batch Acc: 78.12
[Train] Epoch: 2 [581696/620022]    Loss: 0.009866   Batch Acc: 70.31
[Train] Epoch: 2 [581760/620022]    Loss: 0.006047   Batch Acc: 89.06
[Train] Epoch: 2 [581824/620022]    Loss: 0.010158   Batch Acc: 71.88
[Train] Epoch: 2 [581888/620022]    Loss: 0.007421   Batch Acc: 79.69
[Train] Epoch: 2 [581952/620022]    Loss: 0.008234   Batch Acc: 79.69
[Train] Epoch: 2 [582016/620022]    Loss: 0.007991   Batch Acc: 82.81
[Train] Epoch: 2 [582080/620022]    Loss: 0.008467   Batch Acc: 78.12
[Train] Epoch: 2 [582144/620022]    Loss: 0.009481   Batch Acc: 73.44
[Train] Epoch: 2 [582208/620022]    Loss: 0.008332   Batch Acc: 79.69
[Train] Epoch: 2 [582272/620022]    Loss: 0.007041   Batch Acc: 82.81
[Train] Epoch: 2 [582336/620022]    Loss: 0.009208   Batch Acc: 81.25
[Train] Epoch: 2 [582400/620022]    Loss: 0.008569   Batch Acc: 79.69
[Train] Epoch: 2 [582464/620022]    Loss: 0.007028   Batch Acc: 84.38
[Train] Epoch: 2 [582528/620022]    Loss: 0.006882   Batch Acc: 85.94
[Train] Epoch: 2 [582592/620022]    Loss: 0.010202   Batch Acc: 76.56
[Train] Epoch: 2 [582656/620022]    Loss: 0.007697   Batch Acc: 79.69
[Train] Epoch: 2 [582720/620022]    Loss: 0.009229   Batch Acc: 75.00
[Train] Epoch: 2 [582784/620022]    Loss: 0.008324   Batch Acc: 79.69
[Train] Epoch: 2 [582848/620022]    Loss: 0.007542   Batch Acc: 78.12
[Train] Epoch: 2 [582912/620022]    Loss: 0.008385   Batch Acc: 81.25
[Train] Epoch: 2 [582976/620022]    Loss: 0.008102   Batch Acc: 81.25
[Train] Epoch: 2 [583040/620022]    Loss: 0.008623   Batch Acc: 81.25
[Train] Epoch: 2 [583104/620022]    Loss: 0.010205   Batch Acc: 71.88
[Train] Epoch: 2 [583168/620022]    Loss: 0.008937   Batch Acc: 81.25
[Train] Epoch: 2 [583232/620022]    Loss: 0.009462   Batch Acc: 71.88
[Train] Epoch: 2 [583296/620022]    Loss: 0.008711   Batch Acc: 81.25
[Train] Epoch: 2 [583360/620022]    Loss: 0.008786   Batch Acc: 78.12
[Train] Epoch: 2 [583424/620022]    Loss: 0.010270   Batch Acc: 75.00
[Train] Epoch: 2 [583488/620022]    Loss: 0.007887   Batch Acc: 81.25
[Train] Epoch: 2 [583552/620022]    Loss: 0.006158   Batch Acc: 87.50
[Train] Epoch: 2 [583616/620022]    Loss: 0.010060   Batch Acc: 76.56
[Train] Epoch: 2 [583680/620022]    Loss: 0.009176   Batch Acc: 73.44
[Train] Epoch: 2 [583744/620022]    Loss: 0.010073   Batch Acc: 79.69
[Train] Epoch: 2 [583808/620022]    Loss: 0.007767   Batch Acc: 81.25
[Train] Epoch: 2 [583872/620022]    Loss: 0.009137   Batch Acc: 76.56
[Train] Epoch: 2 [583936/620022]    Loss: 0.008300   Batch Acc: 75.00
[Train] Epoch: 2 [584000/620022]    Loss: 0.008237   Batch Acc: 81.25
[Train] Epoch: 2 [584064/620022]    Loss: 0.007058   Batch Acc: 84.38
[Train] Epoch: 2 [584128/620022]    Loss: 0.009436   Batch Acc: 75.00
[Train] Epoch: 2 [584192/620022]    Loss: 0.008728   Batch Acc: 73.44
[Train] Epoch: 2 [584256/620022]    Loss: 0.007990   Batch Acc: 81.25
[Train] Epoch: 2 [584320/620022]    Loss: 0.009320   Batch Acc: 75.00
[Train] Epoch: 2 [584384/620022]    Loss: 0.007969   Batch Acc: 78.12
[Train] Epoch: 2 [584448/620022]    Loss: 0.008518   Batch Acc: 78.12
[Train] Epoch: 2 [584512/620022]    Loss: 0.008243   Batch Acc: 82.81
[Train] Epoch: 2 [584576/620022]    Loss: 0.008591   Batch Acc: 73.44
[Train] Epoch: 2 [584640/620022]    Loss: 0.009374   Batch Acc: 75.00
[Train] Epoch: 2 [584704/620022]    Loss: 0.008782   Batch Acc: 78.12
[Train] Epoch: 2 [584768/620022]    Loss: 0.010647   Batch Acc: 71.88
[Train] Epoch: 2 [584832/620022]    Loss: 0.010169   Batch Acc: 70.31
[Train] Epoch: 2 [584896/620022]    Loss: 0.010147   Batch Acc: 75.00
[Train] Epoch: 2 [584960/620022]    Loss: 0.009178   Batch Acc: 79.69
[Train] Epoch: 2 [585024/620022]    Loss: 0.009121   Batch Acc: 70.31
[Train] Epoch: 2 [585088/620022]    Loss: 0.009069   Batch Acc: 73.44
[Train] Epoch: 2 [585152/620022]    Loss: 0.011011   Batch Acc: 71.88
[Train] Epoch: 2 [585216/620022]    Loss: 0.007534   Batch Acc: 78.12
[Train] Epoch: 2 [585280/620022]    Loss: 0.008067   Batch Acc: 78.12
[Train] Epoch: 2 [585344/620022]    Loss: 0.008585   Batch Acc: 78.12
[Train] Epoch: 2 [585408/620022]    Loss: 0.008442   Batch Acc: 75.00
[Train] Epoch: 2 [585472/620022]    Loss: 0.009254   Batch Acc: 70.31
[Train] Epoch: 2 [585536/620022]    Loss: 0.009717   Batch Acc: 73.44
[Train] Epoch: 2 [585600/620022]    Loss: 0.009674   Batch Acc: 79.69
[Train] Epoch: 2 [585664/620022]    Loss: 0.007452   Batch Acc: 79.69
[Train] Epoch: 2 [585728/620022]    Loss: 0.010511   Batch Acc: 73.44
[Train] Epoch: 2 [585792/620022]    Loss: 0.009369   Batch Acc: 73.44
[Train] Epoch: 2 [585856/620022]    Loss: 0.007776   Batch Acc: 79.69
[Train] Epoch: 2 [585920/620022]    Loss: 0.008116   Batch Acc: 82.81
[Train] Epoch: 2 [585984/620022]    Loss: 0.011441   Batch Acc: 67.19
[Train] Epoch: 2 [586048/620022]    Loss: 0.011145   Batch Acc: 76.56
[Train] Epoch: 2 [586112/620022]    Loss: 0.008266   Batch Acc: 78.12
[Train] Epoch: 2 [586176/620022]    Loss: 0.007678   Batch Acc: 82.81
[Train] Epoch: 2 [586240/620022]    Loss: 0.010785   Batch Acc: 75.00
[Train] Epoch: 2 [586304/620022]    Loss: 0.009819   Batch Acc: 76.56
[Train] Epoch: 2 [586368/620022]    Loss: 0.008208   Batch Acc: 81.25
[Train] Epoch: 2 [586432/620022]    Loss: 0.011133   Batch Acc: 73.44
[Train] Epoch: 2 [586496/620022]    Loss: 0.009291   Batch Acc: 75.00
[Train] Epoch: 2 [586560/620022]    Loss: 0.008348   Batch Acc: 79.69
[Train] Epoch: 2 [586624/620022]    Loss: 0.008821   Batch Acc: 75.00
[Train] Epoch: 2 [586688/620022]    Loss: 0.009826   Batch Acc: 71.88
[Train] Epoch: 2 [586752/620022]    Loss: 0.011062   Batch Acc: 70.31
[Train] Epoch: 2 [586816/620022]    Loss: 0.007510   Batch Acc: 79.69
[Train] Epoch: 2 [586880/620022]    Loss: 0.010664   Batch Acc: 67.19
[Train] Epoch: 2 [586944/620022]    Loss: 0.006791   Batch Acc: 82.81
[Train] Epoch: 2 [587008/620022]    Loss: 0.009693   Batch Acc: 78.12
[Train] Epoch: 2 [587072/620022]    Loss: 0.007004   Batch Acc: 82.81
[Train] Epoch: 2 [587136/620022]    Loss: 0.008791   Batch Acc: 81.25
[Train] Epoch: 2 [587200/620022]    Loss: 0.007814   Batch Acc: 81.25
[Train] Epoch: 2 [587264/620022]    Loss: 0.009543   Batch Acc: 71.88
[Train] Epoch: 2 [587328/620022]    Loss: 0.010016   Batch Acc: 73.44
[Train] Epoch: 2 [587392/620022]    Loss: 0.010858   Batch Acc: 75.00
[Train] Epoch: 2 [587456/620022]    Loss: 0.009649   Batch Acc: 71.88
[Train] Epoch: 2 [587520/620022]    Loss: 0.008713   Batch Acc: 84.38
[Train] Epoch: 2 [587584/620022]    Loss: 0.008663   Batch Acc: 76.56
[Train] Epoch: 2 [587648/620022]    Loss: 0.009862   Batch Acc: 71.88
[Train] Epoch: 2 [587712/620022]    Loss: 0.007355   Batch Acc: 82.81
[Train] Epoch: 2 [587776/620022]    Loss: 0.007487   Batch Acc: 81.25
[Train] Epoch: 2 [587840/620022]    Loss: 0.008435   Batch Acc: 76.56
[Train] Epoch: 2 [587904/620022]    Loss: 0.006622   Batch Acc: 90.62
[Train] Epoch: 2 [587968/620022]    Loss: 0.007584   Batch Acc: 84.38
[Train] Epoch: 2 [588032/620022]    Loss: 0.009111   Batch Acc: 82.81
[Train] Epoch: 2 [588096/620022]    Loss: 0.009209   Batch Acc: 79.69
[Train] Epoch: 2 [588160/620022]    Loss: 0.008958   Batch Acc: 71.88
[Train] Epoch: 2 [588224/620022]    Loss: 0.009585   Batch Acc: 76.56
[Train] Epoch: 2 [588288/620022]    Loss: 0.007943   Batch Acc: 79.69
[Train] Epoch: 2 [588352/620022]    Loss: 0.009130   Batch Acc: 76.56
[Train] Epoch: 2 [588416/620022]    Loss: 0.009110   Batch Acc: 75.00
[Train] Epoch: 2 [588480/620022]    Loss: 0.008321   Batch Acc: 84.38
[Train] Epoch: 2 [588544/620022]    Loss: 0.008676   Batch Acc: 76.56
[Train] Epoch: 2 [588608/620022]    Loss: 0.007707   Batch Acc: 81.25
[Train] Epoch: 2 [588672/620022]    Loss: 0.007309   Batch Acc: 84.38
[Train] Epoch: 2 [588736/620022]    Loss: 0.011210   Batch Acc: 70.31
[Train] Epoch: 2 [588800/620022]    Loss: 0.009885   Batch Acc: 76.56
[Train] Epoch: 2 [588864/620022]    Loss: 0.010433   Batch Acc: 65.62
[Train] Epoch: 2 [588928/620022]    Loss: 0.009862   Batch Acc: 68.75
[Train] Epoch: 2 [588992/620022]    Loss: 0.008898   Batch Acc: 81.25
[Train] Epoch: 2 [589056/620022]    Loss: 0.008807   Batch Acc: 75.00
[Train] Epoch: 2 [589120/620022]    Loss: 0.008459   Batch Acc: 76.56
[Train] Epoch: 2 [589184/620022]    Loss: 0.009532   Batch Acc: 71.88
[Train] Epoch: 2 [589248/620022]    Loss: 0.006166   Batch Acc: 84.38
[Train] Epoch: 2 [589312/620022]    Loss: 0.008599   Batch Acc: 79.69
[Train] Epoch: 2 [589376/620022]    Loss: 0.010337   Batch Acc: 70.31
[Train] Epoch: 2 [589440/620022]    Loss: 0.010701   Batch Acc: 65.62
[Train] Epoch: 2 [589504/620022]    Loss: 0.006870   Batch Acc: 85.94
[Train] Epoch: 2 [589568/620022]    Loss: 0.010680   Batch Acc: 70.31
[Train] Epoch: 2 [589632/620022]    Loss: 0.009873   Batch Acc: 71.88
[Train] Epoch: 2 [589696/620022]    Loss: 0.007836   Batch Acc: 84.38
[Train] Epoch: 2 [589760/620022]    Loss: 0.007148   Batch Acc: 84.38
[Train] Epoch: 2 [589824/620022]    Loss: 0.009056   Batch Acc: 73.44
[Train] Epoch: 2 [589888/620022]    Loss: 0.010194   Batch Acc: 68.75
[Train] Epoch: 2 [589952/620022]    Loss: 0.010306   Batch Acc: 75.00
[Train] Epoch: 2 [590016/620022]    Loss: 0.009458   Batch Acc: 70.31
[Train] Epoch: 2 [590080/620022]    Loss: 0.007778   Batch Acc: 81.25
[Train] Epoch: 2 [590144/620022]    Loss: 0.006709   Batch Acc: 78.12
[Train] Epoch: 2 [590208/620022]    Loss: 0.009040   Batch Acc: 85.94
[Train] Epoch: 2 [590272/620022]    Loss: 0.007265   Batch Acc: 81.25
[Train] Epoch: 2 [590336/620022]    Loss: 0.009582   Batch Acc: 76.56
[Train] Epoch: 2 [590400/620022]    Loss: 0.008069   Batch Acc: 76.56
[Train] Epoch: 2 [590464/620022]    Loss: 0.008650   Batch Acc: 73.44
[Train] Epoch: 2 [590528/620022]    Loss: 0.009341   Batch Acc: 75.00
[Train] Epoch: 2 [590592/620022]    Loss: 0.008474   Batch Acc: 75.00
[Train] Epoch: 2 [590656/620022]    Loss: 0.006504   Batch Acc: 85.94
[Train] Epoch: 2 [590720/620022]    Loss: 0.007669   Batch Acc: 75.00
[Train] Epoch: 2 [590784/620022]    Loss: 0.006579   Batch Acc: 82.81
[Train] Epoch: 2 [590848/620022]    Loss: 0.009706   Batch Acc: 76.56
[Train] Epoch: 2 [590912/620022]    Loss: 0.011048   Batch Acc: 75.00
[Train] Epoch: 2 [590976/620022]    Loss: 0.007141   Batch Acc: 85.94
[Train] Epoch: 2 [591040/620022]    Loss: 0.008043   Batch Acc: 78.12
[Train] Epoch: 2 [591104/620022]    Loss: 0.008216   Batch Acc: 81.25
[Train] Epoch: 2 [591168/620022]    Loss: 0.008507   Batch Acc: 79.69
[Train] Epoch: 2 [591232/620022]    Loss: 0.006488   Batch Acc: 85.94
[Train] Epoch: 2 [591296/620022]    Loss: 0.011358   Batch Acc: 67.19
[Train] Epoch: 2 [591360/620022]    Loss: 0.008955   Batch Acc: 70.31
[Train] Epoch: 2 [591424/620022]    Loss: 0.010552   Batch Acc: 75.00
[Train] Epoch: 2 [591488/620022]    Loss: 0.008396   Batch Acc: 76.56
[Train] Epoch: 2 [591552/620022]    Loss: 0.009959   Batch Acc: 71.88
[Train] Epoch: 2 [591616/620022]    Loss: 0.009548   Batch Acc: 75.00
[Train] Epoch: 2 [591680/620022]    Loss: 0.006575   Batch Acc: 82.81
[Train] Epoch: 2 [591744/620022]    Loss: 0.008610   Batch Acc: 76.56
[Train] Epoch: 2 [591808/620022]    Loss: 0.008813   Batch Acc: 78.12
[Train] Epoch: 2 [591872/620022]    Loss: 0.008041   Batch Acc: 82.81
[Train] Epoch: 2 [591936/620022]    Loss: 0.007519   Batch Acc: 82.81
[Train] Epoch: 2 [592000/620022]    Loss: 0.006272   Batch Acc: 87.50
[Train] Epoch: 2 [592064/620022]    Loss: 0.009620   Batch Acc: 73.44
[Train] Epoch: 2 [592128/620022]    Loss: 0.007114   Batch Acc: 81.25
[Train] Epoch: 2 [592192/620022]    Loss: 0.006115   Batch Acc: 87.50
[Train] Epoch: 2 [592256/620022]    Loss: 0.008896   Batch Acc: 78.12
[Train] Epoch: 2 [592320/620022]    Loss: 0.008512   Batch Acc: 78.12
[Train] Epoch: 2 [592384/620022]    Loss: 0.006866   Batch Acc: 82.81
[Train] Epoch: 2 [592448/620022]    Loss: 0.008853   Batch Acc: 79.69
[Train] Epoch: 2 [592512/620022]    Loss: 0.009789   Batch Acc: 71.88
[Train] Epoch: 2 [592576/620022]    Loss: 0.008406   Batch Acc: 78.12
[Train] Epoch: 2 [592640/620022]    Loss: 0.007659   Batch Acc: 82.81
[Train] Epoch: 2 [592704/620022]    Loss: 0.010207   Batch Acc: 76.56
[Train] Epoch: 2 [592768/620022]    Loss: 0.009274   Batch Acc: 71.88
[Train] Epoch: 2 [592832/620022]    Loss: 0.007892   Batch Acc: 85.94
[Train] Epoch: 2 [592896/620022]    Loss: 0.008781   Batch Acc: 82.81
[Train] Epoch: 2 [592960/620022]    Loss: 0.006329   Batch Acc: 84.38
[Train] Epoch: 2 [593024/620022]    Loss: 0.009404   Batch Acc: 81.25
[Train] Epoch: 2 [593088/620022]    Loss: 0.008232   Batch Acc: 82.81
[Train] Epoch: 2 [593152/620022]    Loss: 0.009425   Batch Acc: 71.88
[Train] Epoch: 2 [593216/620022]    Loss: 0.007595   Batch Acc: 84.38
[Train] Epoch: 2 [593280/620022]    Loss: 0.007455   Batch Acc: 84.38
[Train] Epoch: 2 [593344/620022]    Loss: 0.008343   Batch Acc: 79.69
[Train] Epoch: 2 [593408/620022]    Loss: 0.007912   Batch Acc: 84.38
[Train] Epoch: 2 [593472/620022]    Loss: 0.008920   Batch Acc: 75.00
[Train] Epoch: 2 [593536/620022]    Loss: 0.008276   Batch Acc: 82.81
[Train] Epoch: 2 [593600/620022]    Loss: 0.010498   Batch Acc: 73.44
[Train] Epoch: 2 [593664/620022]    Loss: 0.008228   Batch Acc: 73.44
[Train] Epoch: 2 [593728/620022]    Loss: 0.007722   Batch Acc: 82.81
[Train] Epoch: 2 [593792/620022]    Loss: 0.008015   Batch Acc: 76.56
[Train] Epoch: 2 [593856/620022]    Loss: 0.008118   Batch Acc: 79.69
[Train] Epoch: 2 [593920/620022]    Loss: 0.007279   Batch Acc: 85.94
[Train] Epoch: 2 [593984/620022]    Loss: 0.008140   Batch Acc: 76.56
[Train] Epoch: 2 [594048/620022]    Loss: 0.008316   Batch Acc: 76.56
[Train] Epoch: 2 [594112/620022]    Loss: 0.008488   Batch Acc: 79.69
[Train] Epoch: 2 [594176/620022]    Loss: 0.009474   Batch Acc: 73.44
[Train] Epoch: 2 [594240/620022]    Loss: 0.008233   Batch Acc: 79.69
[Train] Epoch: 2 [594304/620022]    Loss: 0.007930   Batch Acc: 84.38
[Train] Epoch: 2 [594368/620022]    Loss: 0.008104   Batch Acc: 76.56
[Train] Epoch: 2 [594432/620022]    Loss: 0.009883   Batch Acc: 70.31
[Train] Epoch: 2 [594496/620022]    Loss: 0.008313   Batch Acc: 76.56
[Train] Epoch: 2 [594560/620022]    Loss: 0.009367   Batch Acc: 79.69
[Train] Epoch: 2 [594624/620022]    Loss: 0.008511   Batch Acc: 81.25
[Train] Epoch: 2 [594688/620022]    Loss: 0.008874   Batch Acc: 73.44
[Train] Epoch: 2 [594752/620022]    Loss: 0.007916   Batch Acc: 81.25
[Train] Epoch: 2 [594816/620022]    Loss: 0.009474   Batch Acc: 73.44
[Train] Epoch: 2 [594880/620022]    Loss: 0.007975   Batch Acc: 73.44
[Train] Epoch: 2 [594944/620022]    Loss: 0.008296   Batch Acc: 78.12
[Train] Epoch: 2 [595008/620022]    Loss: 0.008842   Batch Acc: 76.56
[Train] Epoch: 2 [595072/620022]    Loss: 0.007594   Batch Acc: 81.25
[Train] Epoch: 2 [595136/620022]    Loss: 0.010230   Batch Acc: 76.56
[Train] Epoch: 2 [595200/620022]    Loss: 0.009720   Batch Acc: 75.00
[Train] Epoch: 2 [595264/620022]    Loss: 0.010221   Batch Acc: 71.88
[Train] Epoch: 2 [595328/620022]    Loss: 0.011136   Batch Acc: 67.19
[Train] Epoch: 2 [595392/620022]    Loss: 0.010911   Batch Acc: 68.75
[Train] Epoch: 2 [595456/620022]    Loss: 0.009038   Batch Acc: 78.12
[Train] Epoch: 2 [595520/620022]    Loss: 0.011508   Batch Acc: 75.00
[Train] Epoch: 2 [595584/620022]    Loss: 0.006544   Batch Acc: 82.81
[Train] Epoch: 2 [595648/620022]    Loss: 0.006767   Batch Acc: 82.81
[Train] Epoch: 2 [595712/620022]    Loss: 0.008958   Batch Acc: 76.56
[Train] Epoch: 2 [595776/620022]    Loss: 0.007219   Batch Acc: 79.69
[Train] Epoch: 2 [595840/620022]    Loss: 0.009137   Batch Acc: 71.88
[Train] Epoch: 2 [595904/620022]    Loss: 0.008149   Batch Acc: 73.44
[Train] Epoch: 2 [595968/620022]    Loss: 0.008580   Batch Acc: 76.56
[Train] Epoch: 2 [596032/620022]    Loss: 0.008807   Batch Acc: 73.44
[Train] Epoch: 2 [596096/620022]    Loss: 0.010756   Batch Acc: 68.75
[Train] Epoch: 2 [596160/620022]    Loss: 0.009335   Batch Acc: 78.12
[Train] Epoch: 2 [596224/620022]    Loss: 0.007936   Batch Acc: 78.12
[Train] Epoch: 2 [596288/620022]    Loss: 0.009341   Batch Acc: 78.12
[Train] Epoch: 2 [596352/620022]    Loss: 0.008330   Batch Acc: 82.81
[Train] Epoch: 2 [596416/620022]    Loss: 0.009218   Batch Acc: 70.31
[Train] Epoch: 2 [596480/620022]    Loss: 0.007155   Batch Acc: 81.25
[Train] Epoch: 2 [596544/620022]    Loss: 0.007133   Batch Acc: 87.50
[Train] Epoch: 2 [596608/620022]    Loss: 0.007590   Batch Acc: 84.38
[Train] Epoch: 2 [596672/620022]    Loss: 0.009174   Batch Acc: 76.56
[Train] Epoch: 2 [596736/620022]    Loss: 0.012068   Batch Acc: 67.19
[Train] Epoch: 2 [596800/620022]    Loss: 0.008346   Batch Acc: 75.00
[Train] Epoch: 2 [596864/620022]    Loss: 0.007794   Batch Acc: 81.25
[Train] Epoch: 2 [596928/620022]    Loss: 0.010538   Batch Acc: 70.31
[Train] Epoch: 2 [596992/620022]    Loss: 0.009610   Batch Acc: 71.88
[Train] Epoch: 2 [597056/620022]    Loss: 0.009107   Batch Acc: 76.56
[Train] Epoch: 2 [597120/620022]    Loss: 0.008586   Batch Acc: 81.25
[Train] Epoch: 2 [597184/620022]    Loss: 0.008124   Batch Acc: 82.81
[Train] Epoch: 2 [597248/620022]    Loss: 0.010502   Batch Acc: 67.19
[Train] Epoch: 2 [597312/620022]    Loss: 0.009380   Batch Acc: 73.44
[Train] Epoch: 2 [597376/620022]    Loss: 0.008440   Batch Acc: 78.12
[Train] Epoch: 2 [597440/620022]    Loss: 0.008503   Batch Acc: 82.81
[Train] Epoch: 2 [597504/620022]    Loss: 0.008262   Batch Acc: 87.50
[Train] Epoch: 2 [597568/620022]    Loss: 0.010276   Batch Acc: 73.44
[Train] Epoch: 2 [597632/620022]    Loss: 0.009637   Batch Acc: 71.88
[Train] Epoch: 2 [597696/620022]    Loss: 0.009275   Batch Acc: 79.69
[Train] Epoch: 2 [597760/620022]    Loss: 0.009711   Batch Acc: 75.00
[Train] Epoch: 2 [597824/620022]    Loss: 0.010512   Batch Acc: 75.00
[Train] Epoch: 2 [597888/620022]    Loss: 0.007920   Batch Acc: 82.81
[Train] Epoch: 2 [597952/620022]    Loss: 0.007590   Batch Acc: 85.94
[Train] Epoch: 2 [598016/620022]    Loss: 0.005655   Batch Acc: 93.75
[Train] Epoch: 2 [598080/620022]    Loss: 0.007436   Batch Acc: 79.69
[Train] Epoch: 2 [598144/620022]    Loss: 0.008145   Batch Acc: 79.69
[Train] Epoch: 2 [598208/620022]    Loss: 0.006825   Batch Acc: 90.62
[Train] Epoch: 2 [598272/620022]    Loss: 0.007207   Batch Acc: 82.81
[Train] Epoch: 2 [598336/620022]    Loss: 0.010513   Batch Acc: 70.31
[Train] Epoch: 2 [598400/620022]    Loss: 0.008843   Batch Acc: 78.12
[Train] Epoch: 2 [598464/620022]    Loss: 0.007189   Batch Acc: 79.69
[Train] Epoch: 2 [598528/620022]    Loss: 0.010612   Batch Acc: 75.00
[Train] Epoch: 2 [598592/620022]    Loss: 0.009139   Batch Acc: 79.69
[Train] Epoch: 2 [598656/620022]    Loss: 0.006821   Batch Acc: 81.25
[Train] Epoch: 2 [598720/620022]    Loss: 0.006595   Batch Acc: 87.50
[Train] Epoch: 2 [598784/620022]    Loss: 0.007645   Batch Acc: 81.25
[Train] Epoch: 2 [598848/620022]    Loss: 0.008832   Batch Acc: 76.56
[Train] Epoch: 2 [598912/620022]    Loss: 0.008927   Batch Acc: 78.12
[Train] Epoch: 2 [598976/620022]    Loss: 0.008166   Batch Acc: 79.69
[Train] Epoch: 2 [599040/620022]    Loss: 0.009777   Batch Acc: 76.56
[Train] Epoch: 2 [599104/620022]    Loss: 0.008129   Batch Acc: 78.12
[Train] Epoch: 2 [599168/620022]    Loss: 0.006927   Batch Acc: 84.38
[Train] Epoch: 2 [599232/620022]    Loss: 0.009306   Batch Acc: 78.12
[Train] Epoch: 2 [599296/620022]    Loss: 0.009600   Batch Acc: 81.25
[Train] Epoch: 2 [599360/620022]    Loss: 0.009474   Batch Acc: 76.56
[Train] Epoch: 2 [599424/620022]    Loss: 0.008881   Batch Acc: 78.12
[Train] Epoch: 2 [599488/620022]    Loss: 0.009276   Batch Acc: 71.88
[Train] Epoch: 2 [599552/620022]    Loss: 0.009381   Batch Acc: 78.12
[Train] Epoch: 2 [599616/620022]    Loss: 0.009802   Batch Acc: 73.44
[Train] Epoch: 2 [599680/620022]    Loss: 0.008039   Batch Acc: 81.25
[Train] Epoch: 2 [599744/620022]    Loss: 0.008777   Batch Acc: 73.44
[Train] Epoch: 2 [599808/620022]    Loss: 0.008883   Batch Acc: 78.12
[Train] Epoch: 2 [599872/620022]    Loss: 0.010014   Batch Acc: 76.56
[Train] Epoch: 2 [599936/620022]    Loss: 0.007833   Batch Acc: 78.12
[Train] Epoch: 2 [600000/620022]    Loss: 0.008811   Batch Acc: 78.12
[Train] Epoch: 2 [600064/620022]    Loss: 0.008292   Batch Acc: 75.00
[Train] Epoch: 2 [600128/620022]    Loss: 0.009266   Batch Acc: 75.00
[Train] Epoch: 2 [600192/620022]    Loss: 0.007049   Batch Acc: 87.50
[Train] Epoch: 2 [600256/620022]    Loss: 0.009162   Batch Acc: 73.44
[Train] Epoch: 2 [600320/620022]    Loss: 0.008593   Batch Acc: 76.56
[Train] Epoch: 2 [600384/620022]    Loss: 0.008059   Batch Acc: 82.81
[Train] Epoch: 2 [600448/620022]    Loss: 0.008429   Batch Acc: 76.56
[Train] Epoch: 2 [600512/620022]    Loss: 0.006041   Batch Acc: 87.50
[Train] Epoch: 2 [600576/620022]    Loss: 0.009046   Batch Acc: 73.44
[Train] Epoch: 2 [600640/620022]    Loss: 0.007527   Batch Acc: 82.81
[Train] Epoch: 2 [600704/620022]    Loss: 0.006077   Batch Acc: 84.38
[Train] Epoch: 2 [600768/620022]    Loss: 0.010396   Batch Acc: 68.75
[Train] Epoch: 2 [600832/620022]    Loss: 0.009188   Batch Acc: 82.81
[Train] Epoch: 2 [600896/620022]    Loss: 0.006872   Batch Acc: 82.81
[Train] Epoch: 2 [600960/620022]    Loss: 0.009107   Batch Acc: 76.56
[Train] Epoch: 2 [601024/620022]    Loss: 0.008125   Batch Acc: 76.56
[Train] Epoch: 2 [601088/620022]    Loss: 0.008989   Batch Acc: 78.12
[Train] Epoch: 2 [601152/620022]    Loss: 0.006031   Batch Acc: 87.50
[Train] Epoch: 2 [601216/620022]    Loss: 0.010210   Batch Acc: 70.31
[Train] Epoch: 2 [601280/620022]    Loss: 0.007546   Batch Acc: 78.12
[Train] Epoch: 2 [601344/620022]    Loss: 0.008146   Batch Acc: 79.69
[Train] Epoch: 2 [601408/620022]    Loss: 0.009768   Batch Acc: 67.19
[Train] Epoch: 2 [601472/620022]    Loss: 0.009839   Batch Acc: 71.88
[Train] Epoch: 2 [601536/620022]    Loss: 0.010007   Batch Acc: 79.69
[Train] Epoch: 2 [601600/620022]    Loss: 0.007493   Batch Acc: 82.81
[Train] Epoch: 2 [601664/620022]    Loss: 0.007844   Batch Acc: 82.81
[Train] Epoch: 2 [601728/620022]    Loss: 0.009620   Batch Acc: 79.69
[Train] Epoch: 2 [601792/620022]    Loss: 0.009224   Batch Acc: 73.44
[Train] Epoch: 2 [601856/620022]    Loss: 0.010417   Batch Acc: 79.69
[Train] Epoch: 2 [601920/620022]    Loss: 0.008143   Batch Acc: 73.44
[Train] Epoch: 2 [601984/620022]    Loss: 0.010349   Batch Acc: 78.12
[Train] Epoch: 2 [602048/620022]    Loss: 0.010553   Batch Acc: 70.31
[Train] Epoch: 2 [602112/620022]    Loss: 0.008835   Batch Acc: 81.25
[Train] Epoch: 2 [602176/620022]    Loss: 0.007993   Batch Acc: 78.12
[Train] Epoch: 2 [602240/620022]    Loss: 0.010233   Batch Acc: 71.88
[Train] Epoch: 2 [602304/620022]    Loss: 0.007999   Batch Acc: 79.69
[Train] Epoch: 2 [602368/620022]    Loss: 0.006929   Batch Acc: 85.94
[Train] Epoch: 2 [602432/620022]    Loss: 0.007381   Batch Acc: 81.25
[Train] Epoch: 2 [602496/620022]    Loss: 0.009201   Batch Acc: 73.44
[Train] Epoch: 2 [602560/620022]    Loss: 0.008623   Batch Acc: 78.12
[Train] Epoch: 2 [602624/620022]    Loss: 0.009176   Batch Acc: 81.25
[Train] Epoch: 2 [602688/620022]    Loss: 0.008638   Batch Acc: 78.12
[Train] Epoch: 2 [602752/620022]    Loss: 0.007307   Batch Acc: 82.81
[Train] Epoch: 2 [602816/620022]    Loss: 0.007123   Batch Acc: 79.69
[Train] Epoch: 2 [602880/620022]    Loss: 0.009666   Batch Acc: 71.88
[Train] Epoch: 2 [602944/620022]    Loss: 0.009128   Batch Acc: 76.56
[Train] Epoch: 2 [603008/620022]    Loss: 0.007992   Batch Acc: 82.81
[Train] Epoch: 2 [603072/620022]    Loss: 0.007638   Batch Acc: 78.12
[Train] Epoch: 2 [603136/620022]    Loss: 0.006669   Batch Acc: 89.06
[Train] Epoch: 2 [603200/620022]    Loss: 0.008757   Batch Acc: 79.69
[Train] Epoch: 2 [603264/620022]    Loss: 0.010026   Batch Acc: 71.88
[Train] Epoch: 2 [603328/620022]    Loss: 0.007821   Batch Acc: 75.00
[Train] Epoch: 2 [603392/620022]    Loss: 0.008330   Batch Acc: 79.69
[Train] Epoch: 2 [603456/620022]    Loss: 0.009120   Batch Acc: 79.69
[Train] Epoch: 2 [603520/620022]    Loss: 0.008919   Batch Acc: 76.56
[Train] Epoch: 2 [603584/620022]    Loss: 0.008608   Batch Acc: 78.12
[Train] Epoch: 2 [603648/620022]    Loss: 0.007604   Batch Acc: 79.69
[Train] Epoch: 2 [603712/620022]    Loss: 0.012513   Batch Acc: 65.62
[Train] Epoch: 2 [603776/620022]    Loss: 0.007274   Batch Acc: 85.94
[Train] Epoch: 2 [603840/620022]    Loss: 0.009822   Batch Acc: 68.75
[Train] Epoch: 2 [603904/620022]    Loss: 0.005237   Batch Acc: 89.06
[Train] Epoch: 2 [603968/620022]    Loss: 0.009432   Batch Acc: 79.69
[Train] Epoch: 2 [604032/620022]    Loss: 0.011059   Batch Acc: 70.31
[Train] Epoch: 2 [604096/620022]    Loss: 0.007476   Batch Acc: 84.38
[Train] Epoch: 2 [604160/620022]    Loss: 0.006948   Batch Acc: 85.94
[Train] Epoch: 2 [604224/620022]    Loss: 0.009500   Batch Acc: 76.56
[Train] Epoch: 2 [604288/620022]    Loss: 0.007941   Batch Acc: 78.12
[Train] Epoch: 2 [604352/620022]    Loss: 0.010040   Batch Acc: 73.44
[Train] Epoch: 2 [604416/620022]    Loss: 0.006953   Batch Acc: 84.38
[Train] Epoch: 2 [604480/620022]    Loss: 0.008305   Batch Acc: 75.00
[Train] Epoch: 2 [604544/620022]    Loss: 0.010926   Batch Acc: 73.44
[Train] Epoch: 2 [604608/620022]    Loss: 0.006847   Batch Acc: 85.94
[Train] Epoch: 2 [604672/620022]    Loss: 0.008516   Batch Acc: 78.12
[Train] Epoch: 2 [604736/620022]    Loss: 0.006488   Batch Acc: 87.50
[Train] Epoch: 2 [604800/620022]    Loss: 0.009490   Batch Acc: 73.44
[Train] Epoch: 2 [604864/620022]    Loss: 0.008159   Batch Acc: 76.56
[Train] Epoch: 2 [604928/620022]    Loss: 0.008174   Batch Acc: 81.25
[Train] Epoch: 2 [604992/620022]    Loss: 0.008683   Batch Acc: 76.56
[Train] Epoch: 2 [605056/620022]    Loss: 0.009773   Batch Acc: 81.25
[Train] Epoch: 2 [605120/620022]    Loss: 0.009881   Batch Acc: 73.44
[Train] Epoch: 2 [605184/620022]    Loss: 0.005186   Batch Acc: 92.19
[Train] Epoch: 2 [605248/620022]    Loss: 0.008922   Batch Acc: 75.00
[Train] Epoch: 2 [605312/620022]    Loss: 0.008195   Batch Acc: 84.38
[Train] Epoch: 2 [605376/620022]    Loss: 0.009258   Batch Acc: 75.00
[Train] Epoch: 2 [605440/620022]    Loss: 0.007742   Batch Acc: 79.69
[Train] Epoch: 2 [605504/620022]    Loss: 0.008959   Batch Acc: 70.31
[Train] Epoch: 2 [605568/620022]    Loss: 0.010409   Batch Acc: 71.88
[Train] Epoch: 2 [605632/620022]    Loss: 0.007622   Batch Acc: 82.81
[Train] Epoch: 2 [605696/620022]    Loss: 0.007982   Batch Acc: 84.38
[Train] Epoch: 2 [605760/620022]    Loss: 0.008231   Batch Acc: 79.69
[Train] Epoch: 2 [605824/620022]    Loss: 0.009155   Batch Acc: 71.88
[Train] Epoch: 2 [605888/620022]    Loss: 0.007345   Batch Acc: 87.50
[Train] Epoch: 2 [605952/620022]    Loss: 0.009428   Batch Acc: 70.31
[Train] Epoch: 2 [606016/620022]    Loss: 0.007216   Batch Acc: 84.38
[Train] Epoch: 2 [606080/620022]    Loss: 0.006092   Batch Acc: 84.38
[Train] Epoch: 2 [606144/620022]    Loss: 0.007134   Batch Acc: 84.38
[Train] Epoch: 2 [606208/620022]    Loss: 0.008973   Batch Acc: 76.56
[Train] Epoch: 2 [606272/620022]    Loss: 0.010403   Batch Acc: 76.56
[Train] Epoch: 2 [606336/620022]    Loss: 0.007754   Batch Acc: 84.38
[Train] Epoch: 2 [606400/620022]    Loss: 0.008907   Batch Acc: 76.56
[Train] Epoch: 2 [606464/620022]    Loss: 0.008669   Batch Acc: 79.69
[Train] Epoch: 2 [606528/620022]    Loss: 0.007695   Batch Acc: 79.69
[Train] Epoch: 2 [606592/620022]    Loss: 0.008595   Batch Acc: 81.25
[Train] Epoch: 2 [606656/620022]    Loss: 0.005802   Batch Acc: 90.62
[Train] Epoch: 2 [606720/620022]    Loss: 0.008422   Batch Acc: 81.25
[Train] Epoch: 2 [606784/620022]    Loss: 0.009336   Batch Acc: 75.00
[Train] Epoch: 2 [606848/620022]    Loss: 0.009110   Batch Acc: 71.88
[Train] Epoch: 2 [606912/620022]    Loss: 0.007530   Batch Acc: 85.94
[Train] Epoch: 2 [606976/620022]    Loss: 0.009828   Batch Acc: 68.75
[Train] Epoch: 2 [607040/620022]    Loss: 0.007854   Batch Acc: 81.25
[Train] Epoch: 2 [607104/620022]    Loss: 0.008415   Batch Acc: 81.25
[Train] Epoch: 2 [607168/620022]    Loss: 0.007762   Batch Acc: 79.69
[Train] Epoch: 2 [607232/620022]    Loss: 0.005504   Batch Acc: 85.94
[Train] Epoch: 2 [607296/620022]    Loss: 0.006546   Batch Acc: 89.06
[Train] Epoch: 2 [607360/620022]    Loss: 0.007716   Batch Acc: 81.25
[Train] Epoch: 2 [607424/620022]    Loss: 0.008573   Batch Acc: 76.56
[Train] Epoch: 2 [607488/620022]    Loss: 0.010226   Batch Acc: 73.44
[Train] Epoch: 2 [607552/620022]    Loss: 0.007832   Batch Acc: 78.12
[Train] Epoch: 2 [607616/620022]    Loss: 0.008387   Batch Acc: 71.88
[Train] Epoch: 2 [607680/620022]    Loss: 0.008675   Batch Acc: 81.25
[Train] Epoch: 2 [607744/620022]    Loss: 0.006951   Batch Acc: 78.12
[Train] Epoch: 2 [607808/620022]    Loss: 0.010372   Batch Acc: 73.44
[Train] Epoch: 2 [607872/620022]    Loss: 0.008814   Batch Acc: 76.56
[Train] Epoch: 2 [607936/620022]    Loss: 0.007248   Batch Acc: 79.69
[Train] Epoch: 2 [608000/620022]    Loss: 0.010961   Batch Acc: 73.44
[Train] Epoch: 2 [608064/620022]    Loss: 0.007469   Batch Acc: 85.94
[Train] Epoch: 2 [608128/620022]    Loss: 0.008160   Batch Acc: 79.69
[Train] Epoch: 2 [608192/620022]    Loss: 0.008093   Batch Acc: 75.00
[Train] Epoch: 2 [608256/620022]    Loss: 0.009565   Batch Acc: 73.44
[Train] Epoch: 2 [608320/620022]    Loss: 0.009337   Batch Acc: 79.69
[Train] Epoch: 2 [608384/620022]    Loss: 0.008482   Batch Acc: 82.81
[Train] Epoch: 2 [608448/620022]    Loss: 0.009721   Batch Acc: 73.44
[Train] Epoch: 2 [608512/620022]    Loss: 0.007493   Batch Acc: 85.94
[Train] Epoch: 2 [608576/620022]    Loss: 0.010232   Batch Acc: 79.69
[Train] Epoch: 2 [608640/620022]    Loss: 0.010256   Batch Acc: 71.88
[Train] Epoch: 2 [608704/620022]    Loss: 0.009011   Batch Acc: 73.44
[Train] Epoch: 2 [608768/620022]    Loss: 0.007033   Batch Acc: 76.56
[Train] Epoch: 2 [608832/620022]    Loss: 0.007668   Batch Acc: 81.25
[Train] Epoch: 2 [608896/620022]    Loss: 0.009934   Batch Acc: 73.44
[Train] Epoch: 2 [608960/620022]    Loss: 0.013482   Batch Acc: 64.06
[Train] Epoch: 2 [609024/620022]    Loss: 0.011507   Batch Acc: 73.44
[Train] Epoch: 2 [609088/620022]    Loss: 0.008919   Batch Acc: 76.56
[Train] Epoch: 2 [609152/620022]    Loss: 0.008896   Batch Acc: 75.00
[Train] Epoch: 2 [609216/620022]    Loss: 0.011095   Batch Acc: 68.75
[Train] Epoch: 2 [609280/620022]    Loss: 0.006669   Batch Acc: 87.50
[Train] Epoch: 2 [609344/620022]    Loss: 0.010565   Batch Acc: 79.69
[Train] Epoch: 2 [609408/620022]    Loss: 0.008146   Batch Acc: 84.38
[Train] Epoch: 2 [609472/620022]    Loss: 0.011642   Batch Acc: 73.44
[Train] Epoch: 2 [609536/620022]    Loss: 0.010216   Batch Acc: 67.19
[Train] Epoch: 2 [609600/620022]    Loss: 0.005751   Batch Acc: 89.06
[Train] Epoch: 2 [609664/620022]    Loss: 0.008720   Batch Acc: 82.81
[Train] Epoch: 2 [609728/620022]    Loss: 0.007407   Batch Acc: 79.69
[Train] Epoch: 2 [609792/620022]    Loss: 0.008993   Batch Acc: 82.81
[Train] Epoch: 2 [609856/620022]    Loss: 0.011491   Batch Acc: 70.31
[Train] Epoch: 2 [609920/620022]    Loss: 0.009806   Batch Acc: 76.56
[Train] Epoch: 2 [609984/620022]    Loss: 0.007593   Batch Acc: 82.81
[Train] Epoch: 2 [610048/620022]    Loss: 0.008610   Batch Acc: 73.44
[Train] Epoch: 2 [610112/620022]    Loss: 0.009474   Batch Acc: 79.69
[Train] Epoch: 2 [610176/620022]    Loss: 0.008506   Batch Acc: 73.44
[Train] Epoch: 2 [610240/620022]    Loss: 0.010436   Batch Acc: 75.00
[Train] Epoch: 2 [610304/620022]    Loss: 0.008899   Batch Acc: 78.12
[Train] Epoch: 2 [610368/620022]    Loss: 0.010482   Batch Acc: 68.75
[Train] Epoch: 2 [610432/620022]    Loss: 0.010105   Batch Acc: 75.00
[Train] Epoch: 2 [610496/620022]    Loss: 0.008023   Batch Acc: 81.25
[Train] Epoch: 2 [610560/620022]    Loss: 0.008486   Batch Acc: 81.25
[Train] Epoch: 2 [610624/620022]    Loss: 0.006118   Batch Acc: 84.38
[Train] Epoch: 2 [610688/620022]    Loss: 0.009268   Batch Acc: 78.12
[Train] Epoch: 2 [610752/620022]    Loss: 0.007169   Batch Acc: 84.38
[Train] Epoch: 2 [610816/620022]    Loss: 0.008514   Batch Acc: 79.69
[Train] Epoch: 2 [610880/620022]    Loss: 0.010359   Batch Acc: 78.12
[Train] Epoch: 2 [610944/620022]    Loss: 0.008965   Batch Acc: 76.56
[Train] Epoch: 2 [611008/620022]    Loss: 0.007081   Batch Acc: 84.38
[Train] Epoch: 2 [611072/620022]    Loss: 0.005974   Batch Acc: 87.50
[Train] Epoch: 2 [611136/620022]    Loss: 0.008800   Batch Acc: 76.56
[Train] Epoch: 2 [611200/620022]    Loss: 0.008646   Batch Acc: 79.69
[Train] Epoch: 2 [611264/620022]    Loss: 0.007583   Batch Acc: 82.81
[Train] Epoch: 2 [611328/620022]    Loss: 0.009270   Batch Acc: 75.00
[Train] Epoch: 2 [611392/620022]    Loss: 0.007255   Batch Acc: 79.69
[Train] Epoch: 2 [611456/620022]    Loss: 0.010168   Batch Acc: 71.88
[Train] Epoch: 2 [611520/620022]    Loss: 0.007981   Batch Acc: 78.12
[Train] Epoch: 2 [611584/620022]    Loss: 0.009487   Batch Acc: 73.44
[Train] Epoch: 2 [611648/620022]    Loss: 0.006439   Batch Acc: 87.50
[Train] Epoch: 2 [611712/620022]    Loss: 0.007359   Batch Acc: 78.12
[Train] Epoch: 2 [611776/620022]    Loss: 0.006933   Batch Acc: 84.38
[Train] Epoch: 2 [611840/620022]    Loss: 0.009352   Batch Acc: 76.56
[Train] Epoch: 2 [611904/620022]    Loss: 0.008225   Batch Acc: 84.38
[Train] Epoch: 2 [611968/620022]    Loss: 0.008467   Batch Acc: 82.81
[Train] Epoch: 2 [612032/620022]    Loss: 0.009657   Batch Acc: 75.00
[Train] Epoch: 2 [612096/620022]    Loss: 0.009515   Batch Acc: 71.88
[Train] Epoch: 2 [612160/620022]    Loss: 0.008041   Batch Acc: 73.44
[Train] Epoch: 2 [612224/620022]    Loss: 0.009314   Batch Acc: 73.44
[Train] Epoch: 2 [612288/620022]    Loss: 0.007368   Batch Acc: 81.25
[Train] Epoch: 2 [612352/620022]    Loss: 0.008244   Batch Acc: 78.12
[Train] Epoch: 2 [612416/620022]    Loss: 0.010462   Batch Acc: 73.44
[Train] Epoch: 2 [612480/620022]    Loss: 0.008069   Batch Acc: 76.56
[Train] Epoch: 2 [612544/620022]    Loss: 0.010626   Batch Acc: 75.00
[Train] Epoch: 2 [612608/620022]    Loss: 0.007969   Batch Acc: 84.38
[Train] Epoch: 2 [612672/620022]    Loss: 0.007316   Batch Acc: 82.81
[Train] Epoch: 2 [612736/620022]    Loss: 0.008768   Batch Acc: 75.00
[Train] Epoch: 2 [612800/620022]    Loss: 0.008139   Batch Acc: 76.56
[Train] Epoch: 2 [612864/620022]    Loss: 0.010741   Batch Acc: 70.31
[Train] Epoch: 2 [612928/620022]    Loss: 0.007716   Batch Acc: 82.81
[Train] Epoch: 2 [612992/620022]    Loss: 0.007222   Batch Acc: 85.94
[Train] Epoch: 2 [613056/620022]    Loss: 0.009386   Batch Acc: 73.44
[Train] Epoch: 2 [613120/620022]    Loss: 0.008833   Batch Acc: 78.12
[Train] Epoch: 2 [613184/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 2 [613248/620022]    Loss: 0.008726   Batch Acc: 78.12
[Train] Epoch: 2 [613312/620022]    Loss: 0.008815   Batch Acc: 78.12
[Train] Epoch: 2 [613376/620022]    Loss: 0.007800   Batch Acc: 82.81
[Train] Epoch: 2 [613440/620022]    Loss: 0.008145   Batch Acc: 76.56
[Train] Epoch: 2 [613504/620022]    Loss: 0.008815   Batch Acc: 81.25
[Train] Epoch: 2 [613568/620022]    Loss: 0.008360   Batch Acc: 76.56
[Train] Epoch: 2 [613632/620022]    Loss: 0.010312   Batch Acc: 75.00
[Train] Epoch: 2 [613696/620022]    Loss: 0.010574   Batch Acc: 67.19
[Train] Epoch: 2 [613760/620022]    Loss: 0.010856   Batch Acc: 73.44
[Train] Epoch: 2 [613824/620022]    Loss: 0.008593   Batch Acc: 78.12
[Train] Epoch: 2 [613888/620022]    Loss: 0.007922   Batch Acc: 85.94
[Train] Epoch: 2 [613952/620022]    Loss: 0.007388   Batch Acc: 79.69
[Train] Epoch: 2 [614016/620022]    Loss: 0.008400   Batch Acc: 84.38
[Train] Epoch: 2 [614080/620022]    Loss: 0.005703   Batch Acc: 87.50
[Train] Epoch: 2 [614144/620022]    Loss: 0.008854   Batch Acc: 79.69
[Train] Epoch: 2 [614208/620022]    Loss: 0.007919   Batch Acc: 73.44
[Train] Epoch: 2 [614272/620022]    Loss: 0.007913   Batch Acc: 79.69
[Train] Epoch: 2 [614336/620022]    Loss: 0.010488   Batch Acc: 70.31
[Train] Epoch: 2 [614400/620022]    Loss: 0.009280   Batch Acc: 75.00
[Train] Epoch: 2 [614464/620022]    Loss: 0.008302   Batch Acc: 78.12
[Train] Epoch: 2 [614528/620022]    Loss: 0.009450   Batch Acc: 73.44
[Train] Epoch: 2 [614592/620022]    Loss: 0.007558   Batch Acc: 81.25
[Train] Epoch: 2 [614656/620022]    Loss: 0.014177   Batch Acc: 60.94
[Train] Epoch: 2 [614720/620022]    Loss: 0.008349   Batch Acc: 76.56
[Train] Epoch: 2 [614784/620022]    Loss: 0.007087   Batch Acc: 84.38
[Train] Epoch: 2 [614848/620022]    Loss: 0.008957   Batch Acc: 70.31
[Train] Epoch: 2 [614912/620022]    Loss: 0.007851   Batch Acc: 84.38
[Train] Epoch: 2 [614976/620022]    Loss: 0.008399   Batch Acc: 78.12
[Train] Epoch: 2 [615040/620022]    Loss: 0.009117   Batch Acc: 76.56
[Train] Epoch: 2 [615104/620022]    Loss: 0.008320   Batch Acc: 75.00
[Train] Epoch: 2 [615168/620022]    Loss: 0.007512   Batch Acc: 76.56
[Train] Epoch: 2 [615232/620022]    Loss: 0.009402   Batch Acc: 71.88
[Train] Epoch: 2 [615296/620022]    Loss: 0.006827   Batch Acc: 84.38
[Train] Epoch: 2 [615360/620022]    Loss: 0.007323   Batch Acc: 79.69
[Train] Epoch: 2 [615424/620022]    Loss: 0.008736   Batch Acc: 73.44
[Train] Epoch: 2 [615488/620022]    Loss: 0.008334   Batch Acc: 76.56
[Train] Epoch: 2 [615552/620022]    Loss: 0.007637   Batch Acc: 79.69
[Train] Epoch: 2 [615616/620022]    Loss: 0.009706   Batch Acc: 75.00
[Train] Epoch: 2 [615680/620022]    Loss: 0.007544   Batch Acc: 79.69
[Train] Epoch: 2 [615744/620022]    Loss: 0.007998   Batch Acc: 79.69
[Train] Epoch: 2 [615808/620022]    Loss: 0.007103   Batch Acc: 81.25
[Train] Epoch: 2 [615872/620022]    Loss: 0.010641   Batch Acc: 71.88
[Train] Epoch: 2 [615936/620022]    Loss: 0.007479   Batch Acc: 85.94
[Train] Epoch: 2 [616000/620022]    Loss: 0.007954   Batch Acc: 78.12
[Train] Epoch: 2 [616064/620022]    Loss: 0.009583   Batch Acc: 73.44
[Train] Epoch: 2 [616128/620022]    Loss: 0.008174   Batch Acc: 81.25
[Train] Epoch: 2 [616192/620022]    Loss: 0.008855   Batch Acc: 79.69
[Train] Epoch: 2 [616256/620022]    Loss: 0.010649   Batch Acc: 73.44
[Train] Epoch: 2 [616320/620022]    Loss: 0.007064   Batch Acc: 85.94
[Train] Epoch: 2 [616384/620022]    Loss: 0.009408   Batch Acc: 76.56
[Train] Epoch: 2 [616448/620022]    Loss: 0.008371   Batch Acc: 82.81
[Train] Epoch: 2 [616512/620022]    Loss: 0.008097   Batch Acc: 78.12
[Train] Epoch: 2 [616576/620022]    Loss: 0.006290   Batch Acc: 82.81
[Train] Epoch: 2 [616640/620022]    Loss: 0.008116   Batch Acc: 81.25
[Train] Epoch: 2 [616704/620022]    Loss: 0.008321   Batch Acc: 79.69
[Train] Epoch: 2 [616768/620022]    Loss: 0.006859   Batch Acc: 85.94
[Train] Epoch: 2 [616832/620022]    Loss: 0.009012   Batch Acc: 78.12
[Train] Epoch: 2 [616896/620022]    Loss: 0.007156   Batch Acc: 85.94
[Train] Epoch: 2 [616960/620022]    Loss: 0.008870   Batch Acc: 81.25
[Train] Epoch: 2 [617024/620022]    Loss: 0.009023   Batch Acc: 79.69
[Train] Epoch: 2 [617088/620022]    Loss: 0.007813   Batch Acc: 84.38
[Train] Epoch: 2 [617152/620022]    Loss: 0.008944   Batch Acc: 71.88
[Train] Epoch: 2 [617216/620022]    Loss: 0.007046   Batch Acc: 81.25
[Train] Epoch: 2 [617280/620022]    Loss: 0.009822   Batch Acc: 70.31
[Train] Epoch: 2 [617344/620022]    Loss: 0.009157   Batch Acc: 73.44
[Train] Epoch: 2 [617408/620022]    Loss: 0.006877   Batch Acc: 79.69
[Train] Epoch: 2 [617472/620022]    Loss: 0.009121   Batch Acc: 73.44
[Train] Epoch: 2 [617536/620022]    Loss: 0.007530   Batch Acc: 84.38
[Train] Epoch: 2 [617600/620022]    Loss: 0.008372   Batch Acc: 78.12
[Train] Epoch: 2 [617664/620022]    Loss: 0.008160   Batch Acc: 81.25
[Train] Epoch: 2 [617728/620022]    Loss: 0.008127   Batch Acc: 81.25
[Train] Epoch: 2 [617792/620022]    Loss: 0.009842   Batch Acc: 78.12
[Train] Epoch: 2 [617856/620022]    Loss: 0.010150   Batch Acc: 73.44
[Train] Epoch: 2 [617920/620022]    Loss: 0.007333   Batch Acc: 84.38
[Train] Epoch: 2 [617984/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 2 [618048/620022]    Loss: 0.011185   Batch Acc: 71.88
[Train] Epoch: 2 [618112/620022]    Loss: 0.007940   Batch Acc: 78.12
[Train] Epoch: 2 [618176/620022]    Loss: 0.007711   Batch Acc: 81.25
[Train] Epoch: 2 [618240/620022]    Loss: 0.007936   Batch Acc: 75.00
[Train] Epoch: 2 [618304/620022]    Loss: 0.007630   Batch Acc: 76.56
[Train] Epoch: 2 [618368/620022]    Loss: 0.010067   Batch Acc: 75.00
[Train] Epoch: 2 [618432/620022]    Loss: 0.006697   Batch Acc: 85.94
[Train] Epoch: 2 [618496/620022]    Loss: 0.009215   Batch Acc: 76.56
[Train] Epoch: 2 [618560/620022]    Loss: 0.007927   Batch Acc: 78.12
[Train] Epoch: 2 [618624/620022]    Loss: 0.010166   Batch Acc: 76.56
[Train] Epoch: 2 [618688/620022]    Loss: 0.008215   Batch Acc: 79.69
[Train] Epoch: 2 [618752/620022]    Loss: 0.009283   Batch Acc: 73.44
[Train] Epoch: 2 [618816/620022]    Loss: 0.009169   Batch Acc: 71.88
[Train] Epoch: 2 [618880/620022]    Loss: 0.006008   Batch Acc: 84.38
[Train] Epoch: 2 [618944/620022]    Loss: 0.008837   Batch Acc: 78.12
[Train] Epoch: 2 [619008/620022]    Loss: 0.009100   Batch Acc: 76.56
[Train] Epoch: 2 [619072/620022]    Loss: 0.006730   Batch Acc: 84.38
[Train] Epoch: 2 [619136/620022]    Loss: 0.006809   Batch Acc: 84.38
[Train] Epoch: 2 [619200/620022]    Loss: 0.010538   Batch Acc: 73.44
[Train] Epoch: 2 [619264/620022]    Loss: 0.009880   Batch Acc: 75.00
[Train] Epoch: 2 [619328/620022]    Loss: 0.007844   Batch Acc: 79.69
[Train] Epoch: 2 [619392/620022]    Loss: 0.009430   Batch Acc: 73.44
[Train] Epoch: 2 [619456/620022]    Loss: 0.008716   Batch Acc: 84.38
[Train] Epoch: 2 [619520/620022]    Loss: 0.009088   Batch Acc: 78.12
[Train] Epoch: 2 [619584/620022]    Loss: 0.010535   Batch Acc: 70.31
[Train] Epoch: 2 [619648/620022]    Loss: 0.011995   Batch Acc: 57.81
[Train] Epoch: 2 [619712/620022]    Loss: 0.008567   Batch Acc: 81.25
[Train] Epoch: 2 [619776/620022]    Loss: 0.007085   Batch Acc: 79.69
[Train] Epoch: 2 [619840/620022]    Loss: 0.009001   Batch Acc: 76.56
[Train] Epoch: 2 [619904/620022]    Loss: 0.007298   Batch Acc: 87.50
[Train] Epoch: 2 [619968/620022]    Loss: 0.009856   Batch Acc: 78.12
[Train] Epoch: 2 [523152/620022]    Loss: 0.013285   Batch Acc: 70.37
Validation Done: [64/154214]
Validation Done: [128/154214]
Validation Done: [192/154214]
Validation Done: [256/154214]
Validation Done: [320/154214]
Validation Done: [384/154214]
Validation Done: [448/154214]
Validation Done: [512/154214]
Validation Done: [576/154214]
Validation Done: [640/154214]
Validation Done: [704/154214]
Validation Done: [768/154214]
Validation Done: [832/154214]
Validation Done: [896/154214]
Validation Done: [960/154214]
Validation Done: [1024/154214]
Validation Done: [1088/154214]
Validation Done: [1152/154214]
Validation Done: [1216/154214]
Validation Done: [1280/154214]
Validation Done: [1344/154214]
Validation Done: [1408/154214]
Validation Done: [1472/154214]
Validation Done: [1536/154214]
Validation Done: [1600/154214]
Validation Done: [1664/154214]
Validation Done: [1728/154214]
Validation Done: [1792/154214]
Validation Done: [1856/154214]
Validation Done: [1920/154214]
Validation Done: [1984/154214]
Validation Done: [2048/154214]
Validation Done: [2112/154214]
Validation Done: [2176/154214]
Validation Done: [2240/154214]
Validation Done: [2304/154214]
Validation Done: [2368/154214]
Validation Done: [2432/154214]
Validation Done: [2496/154214]
Validation Done: [2560/154214]
Validation Done: [2624/154214]
Validation Done: [2688/154214]
Validation Done: [2752/154214]
Validation Done: [2816/154214]
Validation Done: [2880/154214]
Validation Done: [2944/154214]
Validation Done: [3008/154214]
Validation Done: [3072/154214]
Validation Done: [3136/154214]
Validation Done: [3200/154214]
Validation Done: [3264/154214]
Validation Done: [3328/154214]
Validation Done: [3392/154214]
Validation Done: [3456/154214]
Validation Done: [3520/154214]
Validation Done: [3584/154214]
Validation Done: [3648/154214]
Validation Done: [3712/154214]
Validation Done: [3776/154214]
Validation Done: [3840/154214]
Validation Done: [3904/154214]
Validation Done: [3968/154214]
Validation Done: [4032/154214]
Validation Done: [4096/154214]
Validation Done: [4160/154214]
Validation Done: [4224/154214]
Validation Done: [4288/154214]
Validation Done: [4352/154214]
Validation Done: [4416/154214]
Validation Done: [4480/154214]
Validation Done: [4544/154214]
Validation Done: [4608/154214]
Validation Done: [4672/154214]
Validation Done: [4736/154214]
Validation Done: [4800/154214]
Validation Done: [4864/154214]
Validation Done: [4928/154214]
Validation Done: [4992/154214]
Validation Done: [5056/154214]
Validation Done: [5120/154214]
Validation Done: [5184/154214]
Validation Done: [5248/154214]
Validation Done: [5312/154214]
Validation Done: [5376/154214]
Validation Done: [5440/154214]
Validation Done: [5504/154214]
Validation Done: [5568/154214]
Validation Done: [5632/154214]
Validation Done: [5696/154214]
Validation Done: [5760/154214]
Validation Done: [5824/154214]
Validation Done: [5888/154214]
Validation Done: [5952/154214]
Validation Done: [6016/154214]
Validation Done: [6080/154214]
Validation Done: [6144/154214]
Validation Done: [6208/154214]
Validation Done: [6272/154214]
Validation Done: [6336/154214]
Validation Done: [6400/154214]
Validation Done: [6464/154214]
Validation Done: [6528/154214]
Validation Done: [6592/154214]
Validation Done: [6656/154214]
Validation Done: [6720/154214]
Validation Done: [6784/154214]
Validation Done: [6848/154214]
Validation Done: [6912/154214]
Validation Done: [6976/154214]
Validation Done: [7040/154214]
Validation Done: [7104/154214]
Validation Done: [7168/154214]
Validation Done: [7232/154214]
Validation Done: [7296/154214]
Validation Done: [7360/154214]
Validation Done: [7424/154214]
Validation Done: [7488/154214]
Validation Done: [7552/154214]
Validation Done: [7616/154214]
Validation Done: [7680/154214]
Validation Done: [7744/154214]
Validation Done: [7808/154214]
Validation Done: [7872/154214]
Validation Done: [7936/154214]
Validation Done: [8000/154214]
Validation Done: [8064/154214]
Validation Done: [8128/154214]
Validation Done: [8192/154214]
Validation Done: [8256/154214]
Validation Done: [8320/154214]
Validation Done: [8384/154214]
Validation Done: [8448/154214]
Validation Done: [8512/154214]
Validation Done: [8576/154214]
Validation Done: [8640/154214]
Validation Done: [8704/154214]
Validation Done: [8768/154214]
Validation Done: [8832/154214]
Validation Done: [8896/154214]
Validation Done: [8960/154214]
Validation Done: [9024/154214]
Validation Done: [9088/154214]
Validation Done: [9152/154214]
Validation Done: [9216/154214]
Validation Done: [9280/154214]
Validation Done: [9344/154214]
Validation Done: [9408/154214]
Validation Done: [9472/154214]
Validation Done: [9536/154214]
Validation Done: [9600/154214]
Validation Done: [9664/154214]
Validation Done: [9728/154214]
Validation Done: [9792/154214]
Validation Done: [9856/154214]
Validation Done: [9920/154214]
Validation Done: [9984/154214]
Validation Done: [10048/154214]
Validation Done: [10112/154214]
Validation Done: [10176/154214]
Validation Done: [10240/154214]
Validation Done: [10304/154214]
Validation Done: [10368/154214]
Validation Done: [10432/154214]
Validation Done: [10496/154214]
Validation Done: [10560/154214]
Validation Done: [10624/154214]
Validation Done: [10688/154214]
Validation Done: [10752/154214]
Validation Done: [10816/154214]
Validation Done: [10880/154214]
Validation Done: [10944/154214]
Validation Done: [11008/154214]
Validation Done: [11072/154214]
Validation Done: [11136/154214]
Validation Done: [11200/154214]
Validation Done: [11264/154214]
Validation Done: [11328/154214]
Validation Done: [11392/154214]
Validation Done: [11456/154214]
Validation Done: [11520/154214]
Validation Done: [11584/154214]
Validation Done: [11648/154214]
Validation Done: [11712/154214]
Validation Done: [11776/154214]
Validation Done: [11840/154214]
Validation Done: [11904/154214]
Validation Done: [11968/154214]
Validation Done: [12032/154214]
Validation Done: [12096/154214]
Validation Done: [12160/154214]
Validation Done: [12224/154214]
Validation Done: [12288/154214]
Validation Done: [12352/154214]
Validation Done: [12416/154214]
Validation Done: [12480/154214]
Validation Done: [12544/154214]
Validation Done: [12608/154214]
Validation Done: [12672/154214]
Validation Done: [12736/154214]
Validation Done: [12800/154214]
Validation Done: [12864/154214]
Validation Done: [12928/154214]
Validation Done: [12992/154214]
Validation Done: [13056/154214]
Validation Done: [13120/154214]
Validation Done: [13184/154214]
Validation Done: [13248/154214]
Validation Done: [13312/154214]
Validation Done: [13376/154214]
Validation Done: [13440/154214]
Validation Done: [13504/154214]
Validation Done: [13568/154214]
Validation Done: [13632/154214]
Validation Done: [13696/154214]
Validation Done: [13760/154214]
Validation Done: [13824/154214]
Validation Done: [13888/154214]
Validation Done: [13952/154214]
Validation Done: [14016/154214]
Validation Done: [14080/154214]
Validation Done: [14144/154214]
Validation Done: [14208/154214]
Validation Done: [14272/154214]
Validation Done: [14336/154214]
Validation Done: [14400/154214]
Validation Done: [14464/154214]
Validation Done: [14528/154214]
Validation Done: [14592/154214]
Validation Done: [14656/154214]
Validation Done: [14720/154214]
Validation Done: [14784/154214]
Validation Done: [14848/154214]
Validation Done: [14912/154214]
Validation Done: [14976/154214]
Validation Done: [15040/154214]
Validation Done: [15104/154214]
Validation Done: [15168/154214]
Validation Done: [15232/154214]
Validation Done: [15296/154214]
Validation Done: [15360/154214]
Validation Done: [15424/154214]
Validation Done: [15488/154214]
Validation Done: [15552/154214]
Validation Done: [15616/154214]
Validation Done: [15680/154214]
Validation Done: [15744/154214]
Validation Done: [15808/154214]
Validation Done: [15872/154214]
Validation Done: [15936/154214]
Validation Done: [16000/154214]
Validation Done: [16064/154214]
Validation Done: [16128/154214]
Validation Done: [16192/154214]
Validation Done: [16256/154214]
Validation Done: [16320/154214]
Validation Done: [16384/154214]
Validation Done: [16448/154214]
Validation Done: [16512/154214]
Validation Done: [16576/154214]
Validation Done: [16640/154214]
Validation Done: [16704/154214]
Validation Done: [16768/154214]
Validation Done: [16832/154214]
Validation Done: [16896/154214]
Validation Done: [16960/154214]
Validation Done: [17024/154214]
Validation Done: [17088/154214]
Validation Done: [17152/154214]
Validation Done: [17216/154214]
Validation Done: [17280/154214]
Validation Done: [17344/154214]
Validation Done: [17408/154214]
Validation Done: [17472/154214]
Validation Done: [17536/154214]
Validation Done: [17600/154214]
Validation Done: [17664/154214]
Validation Done: [17728/154214]
Validation Done: [17792/154214]
Validation Done: [17856/154214]
Validation Done: [17920/154214]
Validation Done: [17984/154214]
Validation Done: [18048/154214]
Validation Done: [18112/154214]
Validation Done: [18176/154214]
Validation Done: [18240/154214]
Validation Done: [18304/154214]
Validation Done: [18368/154214]
Validation Done: [18432/154214]
Validation Done: [18496/154214]
Validation Done: [18560/154214]
Validation Done: [18624/154214]
Validation Done: [18688/154214]
Validation Done: [18752/154214]
Validation Done: [18816/154214]
Validation Done: [18880/154214]
Validation Done: [18944/154214]
Validation Done: [19008/154214]
Validation Done: [19072/154214]
Validation Done: [19136/154214]
Validation Done: [19200/154214]
Validation Done: [19264/154214]
Validation Done: [19328/154214]
Validation Done: [19392/154214]
Validation Done: [19456/154214]
Validation Done: [19520/154214]
Validation Done: [19584/154214]
Validation Done: [19648/154214]
Validation Done: [19712/154214]
Validation Done: [19776/154214]
Validation Done: [19840/154214]
Validation Done: [19904/154214]
Validation Done: [19968/154214]
Validation Done: [20032/154214]
Validation Done: [20096/154214]
Validation Done: [20160/154214]
Validation Done: [20224/154214]
Validation Done: [20288/154214]
Validation Done: [20352/154214]
Validation Done: [20416/154214]
Validation Done: [20480/154214]
Validation Done: [20544/154214]
Validation Done: [20608/154214]
Validation Done: [20672/154214]
Validation Done: [20736/154214]
Validation Done: [20800/154214]
Validation Done: [20864/154214]
Validation Done: [20928/154214]
Validation Done: [20992/154214]
Validation Done: [21056/154214]
Validation Done: [21120/154214]
Validation Done: [21184/154214]
Validation Done: [21248/154214]
Validation Done: [21312/154214]
Validation Done: [21376/154214]
Validation Done: [21440/154214]
Validation Done: [21504/154214]
Validation Done: [21568/154214]
Validation Done: [21632/154214]
Validation Done: [21696/154214]
Validation Done: [21760/154214]
Validation Done: [21824/154214]
Validation Done: [21888/154214]
Validation Done: [21952/154214]
Validation Done: [22016/154214]
Validation Done: [22080/154214]
Validation Done: [22144/154214]
Validation Done: [22208/154214]
Validation Done: [22272/154214]
Validation Done: [22336/154214]
Validation Done: [22400/154214]
Validation Done: [22464/154214]
Validation Done: [22528/154214]
Validation Done: [22592/154214]
Validation Done: [22656/154214]
Validation Done: [22720/154214]
Validation Done: [22784/154214]
Validation Done: [22848/154214]
Validation Done: [22912/154214]
Validation Done: [22976/154214]
Validation Done: [23040/154214]
Validation Done: [23104/154214]
Validation Done: [23168/154214]
Validation Done: [23232/154214]
Validation Done: [23296/154214]
Validation Done: [23360/154214]
Validation Done: [23424/154214]
Validation Done: [23488/154214]
Validation Done: [23552/154214]
Validation Done: [23616/154214]
Validation Done: [23680/154214]
Validation Done: [23744/154214]
Validation Done: [23808/154214]
Validation Done: [23872/154214]
Validation Done: [23936/154214]
Validation Done: [24000/154214]
Validation Done: [24064/154214]
Validation Done: [24128/154214]
Validation Done: [24192/154214]
Validation Done: [24256/154214]
Validation Done: [24320/154214]
Validation Done: [24384/154214]
Validation Done: [24448/154214]
Validation Done: [24512/154214]
Validation Done: [24576/154214]
Validation Done: [24640/154214]
Validation Done: [24704/154214]
Validation Done: [24768/154214]
Validation Done: [24832/154214]
Validation Done: [24896/154214]
Validation Done: [24960/154214]
Validation Done: [25024/154214]
Validation Done: [25088/154214]
Validation Done: [25152/154214]
Validation Done: [25216/154214]
Validation Done: [25280/154214]
Validation Done: [25344/154214]
Validation Done: [25408/154214]
Validation Done: [25472/154214]
Validation Done: [25536/154214]
Validation Done: [25600/154214]
Validation Done: [25664/154214]
Validation Done: [25728/154214]
Validation Done: [25792/154214]
Validation Done: [25856/154214]
Validation Done: [25920/154214]
Validation Done: [25984/154214]
Validation Done: [26048/154214]
Validation Done: [26112/154214]
Validation Done: [26176/154214]
Validation Done: [26240/154214]
Validation Done: [26304/154214]
Validation Done: [26368/154214]
Validation Done: [26432/154214]
Validation Done: [26496/154214]
Validation Done: [26560/154214]
Validation Done: [26624/154214]
Validation Done: [26688/154214]
Validation Done: [26752/154214]
Validation Done: [26816/154214]
Validation Done: [26880/154214]
Validation Done: [26944/154214]
Validation Done: [27008/154214]
Validation Done: [27072/154214]
Validation Done: [27136/154214]
Validation Done: [27200/154214]
Validation Done: [27264/154214]
Validation Done: [27328/154214]
Validation Done: [27392/154214]
Validation Done: [27456/154214]
Validation Done: [27520/154214]
Validation Done: [27584/154214]
Validation Done: [27648/154214]
Validation Done: [27712/154214]
Validation Done: [27776/154214]
Validation Done: [27840/154214]
Validation Done: [27904/154214]
Validation Done: [27968/154214]
Validation Done: [28032/154214]
Validation Done: [28096/154214]
Validation Done: [28160/154214]
Validation Done: [28224/154214]
Validation Done: [28288/154214]
Validation Done: [28352/154214]
Validation Done: [28416/154214]
Validation Done: [28480/154214]
Validation Done: [28544/154214]
Validation Done: [28608/154214]
Validation Done: [28672/154214]
Validation Done: [28736/154214]
Validation Done: [28800/154214]
Validation Done: [28864/154214]
Validation Done: [28928/154214]
Validation Done: [28992/154214]
Validation Done: [29056/154214]
Validation Done: [29120/154214]
Validation Done: [29184/154214]
Validation Done: [29248/154214]
Validation Done: [29312/154214]
Validation Done: [29376/154214]
Validation Done: [29440/154214]
Validation Done: [29504/154214]
Validation Done: [29568/154214]
Validation Done: [29632/154214]
Validation Done: [29696/154214]
Validation Done: [29760/154214]
Validation Done: [29824/154214]
Validation Done: [29888/154214]
Validation Done: [29952/154214]
Validation Done: [30016/154214]
Validation Done: [30080/154214]
Validation Done: [30144/154214]
Validation Done: [30208/154214]
Validation Done: [30272/154214]
Validation Done: [30336/154214]
Validation Done: [30400/154214]
Validation Done: [30464/154214]
Validation Done: [30528/154214]
Validation Done: [30592/154214]
Validation Done: [30656/154214]
Validation Done: [30720/154214]
Validation Done: [30784/154214]
Validation Done: [30848/154214]
Validation Done: [30912/154214]
Validation Done: [30976/154214]
Validation Done: [31040/154214]
Validation Done: [31104/154214]
Validation Done: [31168/154214]
Validation Done: [31232/154214]
Validation Done: [31296/154214]
Validation Done: [31360/154214]
Validation Done: [31424/154214]
Validation Done: [31488/154214]
Validation Done: [31552/154214]
Validation Done: [31616/154214]
Validation Done: [31680/154214]
Validation Done: [31744/154214]
Validation Done: [31808/154214]
Validation Done: [31872/154214]
Validation Done: [31936/154214]
Validation Done: [32000/154214]
Validation Done: [32064/154214]
Validation Done: [32128/154214]
Validation Done: [32192/154214]
Validation Done: [32256/154214]
Validation Done: [32320/154214]
Validation Done: [32384/154214]
Validation Done: [32448/154214]
Validation Done: [32512/154214]
Validation Done: [32576/154214]
Validation Done: [32640/154214]
Validation Done: [32704/154214]
Validation Done: [32768/154214]
Validation Done: [32832/154214]
Validation Done: [32896/154214]
Validation Done: [32960/154214]
Validation Done: [33024/154214]
Validation Done: [33088/154214]
Validation Done: [33152/154214]
Validation Done: [33216/154214]
Validation Done: [33280/154214]
Validation Done: [33344/154214]
Validation Done: [33408/154214]
Validation Done: [33472/154214]
Validation Done: [33536/154214]
Validation Done: [33600/154214]
Validation Done: [33664/154214]
Validation Done: [33728/154214]
Validation Done: [33792/154214]
Validation Done: [33856/154214]
Validation Done: [33920/154214]
Validation Done: [33984/154214]
Validation Done: [34048/154214]
Validation Done: [34112/154214]
Validation Done: [34176/154214]
Validation Done: [34240/154214]
Validation Done: [34304/154214]
Validation Done: [34368/154214]
Validation Done: [34432/154214]
Validation Done: [34496/154214]
Validation Done: [34560/154214]
Validation Done: [34624/154214]
Validation Done: [34688/154214]
Validation Done: [34752/154214]
Validation Done: [34816/154214]
Validation Done: [34880/154214]
Validation Done: [34944/154214]
Validation Done: [35008/154214]
Validation Done: [35072/154214]
Validation Done: [35136/154214]
Validation Done: [35200/154214]
Validation Done: [35264/154214]
Validation Done: [35328/154214]
Validation Done: [35392/154214]
Validation Done: [35456/154214]
Validation Done: [35520/154214]
Validation Done: [35584/154214]
Validation Done: [35648/154214]
Validation Done: [35712/154214]
Validation Done: [35776/154214]
Validation Done: [35840/154214]
Validation Done: [35904/154214]
Validation Done: [35968/154214]
Validation Done: [36032/154214]
Validation Done: [36096/154214]
Validation Done: [36160/154214]
Validation Done: [36224/154214]
Validation Done: [36288/154214]
Validation Done: [36352/154214]
Validation Done: [36416/154214]
Validation Done: [36480/154214]
Validation Done: [36544/154214]
Validation Done: [36608/154214]
Validation Done: [36672/154214]
Validation Done: [36736/154214]
Validation Done: [36800/154214]
Validation Done: [36864/154214]
Validation Done: [36928/154214]
Validation Done: [36992/154214]
Validation Done: [37056/154214]
Validation Done: [37120/154214]
Validation Done: [37184/154214]
Validation Done: [37248/154214]
Validation Done: [37312/154214]
Validation Done: [37376/154214]
Validation Done: [37440/154214]
Validation Done: [37504/154214]
Validation Done: [37568/154214]
Validation Done: [37632/154214]
Validation Done: [37696/154214]
Validation Done: [37760/154214]
Validation Done: [37824/154214]
Validation Done: [37888/154214]
Validation Done: [37952/154214]
Validation Done: [38016/154214]
Validation Done: [38080/154214]
Validation Done: [38144/154214]
Validation Done: [38208/154214]
Validation Done: [38272/154214]
Validation Done: [38336/154214]
Validation Done: [38400/154214]
Validation Done: [38464/154214]
Validation Done: [38528/154214]
Validation Done: [38592/154214]
Validation Done: [38656/154214]
Validation Done: [38720/154214]
Validation Done: [38784/154214]
Validation Done: [38848/154214]
Validation Done: [38912/154214]
Validation Done: [38976/154214]
Validation Done: [39040/154214]
Validation Done: [39104/154214]
Validation Done: [39168/154214]
Validation Done: [39232/154214]
Validation Done: [39296/154214]
Validation Done: [39360/154214]
Validation Done: [39424/154214]
Validation Done: [39488/154214]
Validation Done: [39552/154214]
Validation Done: [39616/154214]
Validation Done: [39680/154214]
Validation Done: [39744/154214]
Validation Done: [39808/154214]
Validation Done: [39872/154214]
Validation Done: [39936/154214]
Validation Done: [40000/154214]
Validation Done: [40064/154214]
Validation Done: [40128/154214]
Validation Done: [40192/154214]
Validation Done: [40256/154214]
Validation Done: [40320/154214]
Validation Done: [40384/154214]
Validation Done: [40448/154214]
Validation Done: [40512/154214]
Validation Done: [40576/154214]
Validation Done: [40640/154214]
Validation Done: [40704/154214]
Validation Done: [40768/154214]
Validation Done: [40832/154214]
Validation Done: [40896/154214]
Validation Done: [40960/154214]
Validation Done: [41024/154214]
Validation Done: [41088/154214]
Validation Done: [41152/154214]
Validation Done: [41216/154214]
Validation Done: [41280/154214]
Validation Done: [41344/154214]
Validation Done: [41408/154214]
Validation Done: [41472/154214]
Validation Done: [41536/154214]
Validation Done: [41600/154214]
Validation Done: [41664/154214]
Validation Done: [41728/154214]
Validation Done: [41792/154214]
Validation Done: [41856/154214]
Validation Done: [41920/154214]
Validation Done: [41984/154214]
Validation Done: [42048/154214]
Validation Done: [42112/154214]
Validation Done: [42176/154214]
Validation Done: [42240/154214]
Validation Done: [42304/154214]
Validation Done: [42368/154214]
Validation Done: [42432/154214]
Validation Done: [42496/154214]
Validation Done: [42560/154214]
Validation Done: [42624/154214]
Validation Done: [42688/154214]
Validation Done: [42752/154214]
Validation Done: [42816/154214]
Validation Done: [42880/154214]
Validation Done: [42944/154214]
Validation Done: [43008/154214]
Validation Done: [43072/154214]
Validation Done: [43136/154214]
Validation Done: [43200/154214]
Validation Done: [43264/154214]
Validation Done: [43328/154214]
Validation Done: [43392/154214]
Validation Done: [43456/154214]
Validation Done: [43520/154214]
Validation Done: [43584/154214]
Validation Done: [43648/154214]
Validation Done: [43712/154214]
Validation Done: [43776/154214]
Validation Done: [43840/154214]
Validation Done: [43904/154214]
Validation Done: [43968/154214]
Validation Done: [44032/154214]
Validation Done: [44096/154214]
Validation Done: [44160/154214]
Validation Done: [44224/154214]
Validation Done: [44288/154214]
Validation Done: [44352/154214]
Validation Done: [44416/154214]
Validation Done: [44480/154214]
Validation Done: [44544/154214]
Validation Done: [44608/154214]
Validation Done: [44672/154214]
Validation Done: [44736/154214]
Validation Done: [44800/154214]
Validation Done: [44864/154214]
Validation Done: [44928/154214]
Validation Done: [44992/154214]
Validation Done: [45056/154214]
Validation Done: [45120/154214]
Validation Done: [45184/154214]
Validation Done: [45248/154214]
Validation Done: [45312/154214]
Validation Done: [45376/154214]
Validation Done: [45440/154214]
Validation Done: [45504/154214]
Validation Done: [45568/154214]
Validation Done: [45632/154214]
Validation Done: [45696/154214]
Validation Done: [45760/154214]
Validation Done: [45824/154214]
Validation Done: [45888/154214]
Validation Done: [45952/154214]
Validation Done: [46016/154214]
Validation Done: [46080/154214]
Validation Done: [46144/154214]
Validation Done: [46208/154214]
Validation Done: [46272/154214]
Validation Done: [46336/154214]
Validation Done: [46400/154214]
Validation Done: [46464/154214]
Validation Done: [46528/154214]
Validation Done: [46592/154214]
Validation Done: [46656/154214]
Validation Done: [46720/154214]
Validation Done: [46784/154214]
Validation Done: [46848/154214]
Validation Done: [46912/154214]
Validation Done: [46976/154214]
Validation Done: [47040/154214]
Validation Done: [47104/154214]
Validation Done: [47168/154214]
Validation Done: [47232/154214]
Validation Done: [47296/154214]
Validation Done: [47360/154214]
Validation Done: [47424/154214]
Validation Done: [47488/154214]
Validation Done: [47552/154214]
Validation Done: [47616/154214]
Validation Done: [47680/154214]
Validation Done: [47744/154214]
Validation Done: [47808/154214]
Validation Done: [47872/154214]
Validation Done: [47936/154214]
Validation Done: [48000/154214]
Validation Done: [48064/154214]
Validation Done: [48128/154214]
Validation Done: [48192/154214]
Validation Done: [48256/154214]
Validation Done: [48320/154214]
Validation Done: [48384/154214]
Validation Done: [48448/154214]
Validation Done: [48512/154214]
Validation Done: [48576/154214]
Validation Done: [48640/154214]
Validation Done: [48704/154214]
Validation Done: [48768/154214]
Validation Done: [48832/154214]
Validation Done: [48896/154214]
Validation Done: [48960/154214]
Validation Done: [49024/154214]
Validation Done: [49088/154214]
Validation Done: [49152/154214]
Validation Done: [49216/154214]
Validation Done: [49280/154214]
Validation Done: [49344/154214]
Validation Done: [49408/154214]
Validation Done: [49472/154214]
Validation Done: [49536/154214]
Validation Done: [49600/154214]
Validation Done: [49664/154214]
Validation Done: [49728/154214]
Validation Done: [49792/154214]
Validation Done: [49856/154214]
Validation Done: [49920/154214]
Validation Done: [49984/154214]
Validation Done: [50048/154214]
Validation Done: [50112/154214]
Validation Done: [50176/154214]
Validation Done: [50240/154214]
Validation Done: [50304/154214]
Validation Done: [50368/154214]
Validation Done: [50432/154214]
Validation Done: [50496/154214]
Validation Done: [50560/154214]
Validation Done: [50624/154214]
Validation Done: [50688/154214]
Validation Done: [50752/154214]
Validation Done: [50816/154214]
Validation Done: [50880/154214]
Validation Done: [50944/154214]
Validation Done: [51008/154214]
Validation Done: [51072/154214]
Validation Done: [51136/154214]
Validation Done: [51200/154214]
Validation Done: [51264/154214]
Validation Done: [51328/154214]
Validation Done: [51392/154214]
Validation Done: [51456/154214]
Validation Done: [51520/154214]
Validation Done: [51584/154214]
Validation Done: [51648/154214]
Validation Done: [51712/154214]
Validation Done: [51776/154214]
Validation Done: [51840/154214]
Validation Done: [51904/154214]
Validation Done: [51968/154214]
Validation Done: [52032/154214]
Validation Done: [52096/154214]
Validation Done: [52160/154214]
Validation Done: [52224/154214]
Validation Done: [52288/154214]
Validation Done: [52352/154214]
Validation Done: [52416/154214]
Validation Done: [52480/154214]
Validation Done: [52544/154214]
Validation Done: [52608/154214]
Validation Done: [52672/154214]
Validation Done: [52736/154214]
Validation Done: [52800/154214]
Validation Done: [52864/154214]
Validation Done: [52928/154214]
Validation Done: [52992/154214]
Validation Done: [53056/154214]
Validation Done: [53120/154214]
Validation Done: [53184/154214]
Validation Done: [53248/154214]
Validation Done: [53312/154214]
Validation Done: [53376/154214]
Validation Done: [53440/154214]
Validation Done: [53504/154214]
Validation Done: [53568/154214]
Validation Done: [53632/154214]
Validation Done: [53696/154214]
Validation Done: [53760/154214]
Validation Done: [53824/154214]
Validation Done: [53888/154214]
Validation Done: [53952/154214]
Validation Done: [54016/154214]
Validation Done: [54080/154214]
Validation Done: [54144/154214]
Validation Done: [54208/154214]
Validation Done: [54272/154214]
Validation Done: [54336/154214]
Validation Done: [54400/154214]
Validation Done: [54464/154214]
Validation Done: [54528/154214]
Validation Done: [54592/154214]
Validation Done: [54656/154214]
Validation Done: [54720/154214]
Validation Done: [54784/154214]
Validation Done: [54848/154214]
Validation Done: [54912/154214]
Validation Done: [54976/154214]
Validation Done: [55040/154214]
Validation Done: [55104/154214]
Validation Done: [55168/154214]
Validation Done: [55232/154214]
Validation Done: [55296/154214]
Validation Done: [55360/154214]
Validation Done: [55424/154214]
Validation Done: [55488/154214]
Validation Done: [55552/154214]
Validation Done: [55616/154214]
Validation Done: [55680/154214]
Validation Done: [55744/154214]
Validation Done: [55808/154214]
Validation Done: [55872/154214]
Validation Done: [55936/154214]
Validation Done: [56000/154214]
Validation Done: [56064/154214]
Validation Done: [56128/154214]
Validation Done: [56192/154214]
Validation Done: [56256/154214]
Validation Done: [56320/154214]
Validation Done: [56384/154214]
Validation Done: [56448/154214]
Validation Done: [56512/154214]
Validation Done: [56576/154214]
Validation Done: [56640/154214]
Validation Done: [56704/154214]
Validation Done: [56768/154214]
Validation Done: [56832/154214]
Validation Done: [56896/154214]
Validation Done: [56960/154214]
Validation Done: [57024/154214]
Validation Done: [57088/154214]
Validation Done: [57152/154214]
Validation Done: [57216/154214]
Validation Done: [57280/154214]
Validation Done: [57344/154214]
Validation Done: [57408/154214]
Validation Done: [57472/154214]
Validation Done: [57536/154214]
Validation Done: [57600/154214]
Validation Done: [57664/154214]
Validation Done: [57728/154214]
Validation Done: [57792/154214]
Validation Done: [57856/154214]
Validation Done: [57920/154214]
Validation Done: [57984/154214]
Validation Done: [58048/154214]
Validation Done: [58112/154214]
Validation Done: [58176/154214]
Validation Done: [58240/154214]
Validation Done: [58304/154214]
Validation Done: [58368/154214]
Validation Done: [58432/154214]
Validation Done: [58496/154214]
Validation Done: [58560/154214]
Validation Done: [58624/154214]
Validation Done: [58688/154214]
Validation Done: [58752/154214]
Validation Done: [58816/154214]
Validation Done: [58880/154214]
Validation Done: [58944/154214]
Validation Done: [59008/154214]
Validation Done: [59072/154214]
Validation Done: [59136/154214]
Validation Done: [59200/154214]
Validation Done: [59264/154214]
Validation Done: [59328/154214]
Validation Done: [59392/154214]
Validation Done: [59456/154214]
Validation Done: [59520/154214]
Validation Done: [59584/154214]
Validation Done: [59648/154214]
Validation Done: [59712/154214]
Validation Done: [59776/154214]
Validation Done: [59840/154214]
Validation Done: [59904/154214]
Validation Done: [59968/154214]
Validation Done: [60032/154214]
Validation Done: [60096/154214]
Validation Done: [60160/154214]
Validation Done: [60224/154214]
Validation Done: [60288/154214]
Validation Done: [60352/154214]
Validation Done: [60416/154214]
Validation Done: [60480/154214]
Validation Done: [60544/154214]
Validation Done: [60608/154214]
Validation Done: [60672/154214]
Validation Done: [60736/154214]
Validation Done: [60800/154214]
Validation Done: [60864/154214]
Validation Done: [60928/154214]
Validation Done: [60992/154214]
Validation Done: [61056/154214]
Validation Done: [61120/154214]
Validation Done: [61184/154214]
Validation Done: [61248/154214]
Validation Done: [61312/154214]
Validation Done: [61376/154214]
Validation Done: [61440/154214]
Validation Done: [61504/154214]
Validation Done: [61568/154214]
Validation Done: [61632/154214]
Validation Done: [61696/154214]
Validation Done: [61760/154214]
Validation Done: [61824/154214]
Validation Done: [61888/154214]
Validation Done: [61952/154214]
Validation Done: [62016/154214]
Validation Done: [62080/154214]
Validation Done: [62144/154214]
Validation Done: [62208/154214]
Validation Done: [62272/154214]
Validation Done: [62336/154214]
Validation Done: [62400/154214]
Validation Done: [62464/154214]
Validation Done: [62528/154214]
Validation Done: [62592/154214]
Validation Done: [62656/154214]
Validation Done: [62720/154214]
Validation Done: [62784/154214]
Validation Done: [62848/154214]
Validation Done: [62912/154214]
Validation Done: [62976/154214]
Validation Done: [63040/154214]
Validation Done: [63104/154214]
Validation Done: [63168/154214]
Validation Done: [63232/154214]
Validation Done: [63296/154214]
Validation Done: [63360/154214]
Validation Done: [63424/154214]
Validation Done: [63488/154214]
Validation Done: [63552/154214]
Validation Done: [63616/154214]
Validation Done: [63680/154214]
Validation Done: [63744/154214]
Validation Done: [63808/154214]
Validation Done: [63872/154214]
Validation Done: [63936/154214]
Validation Done: [64000/154214]
Validation Done: [64064/154214]
Validation Done: [64128/154214]
Validation Done: [64192/154214]
Validation Done: [64256/154214]
Validation Done: [64320/154214]
Validation Done: [64384/154214]
Validation Done: [64448/154214]
Validation Done: [64512/154214]
Validation Done: [64576/154214]
Validation Done: [64640/154214]
Validation Done: [64704/154214]
Validation Done: [64768/154214]
Validation Done: [64832/154214]
Validation Done: [64896/154214]
Validation Done: [64960/154214]
Validation Done: [65024/154214]
Validation Done: [65088/154214]
Validation Done: [65152/154214]
Validation Done: [65216/154214]
Validation Done: [65280/154214]
Validation Done: [65344/154214]
Validation Done: [65408/154214]
Validation Done: [65472/154214]
Validation Done: [65536/154214]
Validation Done: [65600/154214]
Validation Done: [65664/154214]
Validation Done: [65728/154214]
Validation Done: [65792/154214]
Validation Done: [65856/154214]
Validation Done: [65920/154214]
Validation Done: [65984/154214]
Validation Done: [66048/154214]
Validation Done: [66112/154214]
Validation Done: [66176/154214]
Validation Done: [66240/154214]
Validation Done: [66304/154214]
Validation Done: [66368/154214]
Validation Done: [66432/154214]
Validation Done: [66496/154214]
Validation Done: [66560/154214]
Validation Done: [66624/154214]
Validation Done: [66688/154214]
Validation Done: [66752/154214]
Validation Done: [66816/154214]
Validation Done: [66880/154214]
Validation Done: [66944/154214]
Validation Done: [67008/154214]
Validation Done: [67072/154214]
Validation Done: [67136/154214]
Validation Done: [67200/154214]
Validation Done: [67264/154214]
Validation Done: [67328/154214]
Validation Done: [67392/154214]
Validation Done: [67456/154214]
Validation Done: [67520/154214]
Validation Done: [67584/154214]
Validation Done: [67648/154214]
Validation Done: [67712/154214]
Validation Done: [67776/154214]
Validation Done: [67840/154214]
Validation Done: [67904/154214]
Validation Done: [67968/154214]
Validation Done: [68032/154214]
Validation Done: [68096/154214]
Validation Done: [68160/154214]
Validation Done: [68224/154214]
Validation Done: [68288/154214]
Validation Done: [68352/154214]
Validation Done: [68416/154214]
Validation Done: [68480/154214]
Validation Done: [68544/154214]
Validation Done: [68608/154214]
Validation Done: [68672/154214]
Validation Done: [68736/154214]
Validation Done: [68800/154214]
Validation Done: [68864/154214]
Validation Done: [68928/154214]
Validation Done: [68992/154214]
Validation Done: [69056/154214]
Validation Done: [69120/154214]
Validation Done: [69184/154214]
Validation Done: [69248/154214]
Validation Done: [69312/154214]
Validation Done: [69376/154214]
Validation Done: [69440/154214]
Validation Done: [69504/154214]
Validation Done: [69568/154214]
Validation Done: [69632/154214]
Validation Done: [69696/154214]
Validation Done: [69760/154214]
Validation Done: [69824/154214]
Validation Done: [69888/154214]
Validation Done: [69952/154214]
Validation Done: [70016/154214]
Validation Done: [70080/154214]
Validation Done: [70144/154214]
Validation Done: [70208/154214]
Validation Done: [70272/154214]
Validation Done: [70336/154214]
Validation Done: [70400/154214]
Validation Done: [70464/154214]
Validation Done: [70528/154214]
Validation Done: [70592/154214]
Validation Done: [70656/154214]
Validation Done: [70720/154214]
Validation Done: [70784/154214]
Validation Done: [70848/154214]
Validation Done: [70912/154214]
Validation Done: [70976/154214]
Validation Done: [71040/154214]
Validation Done: [71104/154214]
Validation Done: [71168/154214]
Validation Done: [71232/154214]
Validation Done: [71296/154214]
Validation Done: [71360/154214]
Validation Done: [71424/154214]
Validation Done: [71488/154214]
Validation Done: [71552/154214]
Validation Done: [71616/154214]
Validation Done: [71680/154214]
Validation Done: [71744/154214]
Validation Done: [71808/154214]
Validation Done: [71872/154214]
Validation Done: [71936/154214]
Validation Done: [72000/154214]
Validation Done: [72064/154214]
Validation Done: [72128/154214]
Validation Done: [72192/154214]
Validation Done: [72256/154214]
Validation Done: [72320/154214]
Validation Done: [72384/154214]
Validation Done: [72448/154214]
Validation Done: [72512/154214]
Validation Done: [72576/154214]
Validation Done: [72640/154214]
Validation Done: [72704/154214]
Validation Done: [72768/154214]
Validation Done: [72832/154214]
Validation Done: [72896/154214]
Validation Done: [72960/154214]
Validation Done: [73024/154214]
Validation Done: [73088/154214]
Validation Done: [73152/154214]
Validation Done: [73216/154214]
Validation Done: [73280/154214]
Validation Done: [73344/154214]
Validation Done: [73408/154214]
Validation Done: [73472/154214]
Validation Done: [73536/154214]
Validation Done: [73600/154214]
Validation Done: [73664/154214]
Validation Done: [73728/154214]
Validation Done: [73792/154214]
Validation Done: [73856/154214]
Validation Done: [73920/154214]
Validation Done: [73984/154214]
Validation Done: [74048/154214]
Validation Done: [74112/154214]
Validation Done: [74176/154214]
Validation Done: [74240/154214]
Validation Done: [74304/154214]
Validation Done: [74368/154214]
Validation Done: [74432/154214]
Validation Done: [74496/154214]
Validation Done: [74560/154214]
Validation Done: [74624/154214]
Validation Done: [74688/154214]
Validation Done: [74752/154214]
Validation Done: [74816/154214]
Validation Done: [74880/154214]
Validation Done: [74944/154214]
Validation Done: [75008/154214]
Validation Done: [75072/154214]
Validation Done: [75136/154214]
Validation Done: [75200/154214]
Validation Done: [75264/154214]
Validation Done: [75328/154214]
Validation Done: [75392/154214]
Validation Done: [75456/154214]
Validation Done: [75520/154214]
Validation Done: [75584/154214]
Validation Done: [75648/154214]
Validation Done: [75712/154214]
Validation Done: [75776/154214]
Validation Done: [75840/154214]
Validation Done: [75904/154214]
Validation Done: [75968/154214]
Validation Done: [76032/154214]
Validation Done: [76096/154214]
Validation Done: [76160/154214]
Validation Done: [76224/154214]
Validation Done: [76288/154214]
Validation Done: [76352/154214]
Validation Done: [76416/154214]
Validation Done: [76480/154214]
Validation Done: [76544/154214]
Validation Done: [76608/154214]
Validation Done: [76672/154214]
Validation Done: [76736/154214]
Validation Done: [76800/154214]
Validation Done: [76864/154214]
Validation Done: [76928/154214]
Validation Done: [76992/154214]
Validation Done: [77056/154214]
Validation Done: [77120/154214]
Validation Done: [77184/154214]
Validation Done: [77248/154214]
Validation Done: [77312/154214]
Validation Done: [77376/154214]
Validation Done: [77440/154214]
Validation Done: [77504/154214]
Validation Done: [77568/154214]
Validation Done: [77632/154214]
Validation Done: [77696/154214]
Validation Done: [77760/154214]
Validation Done: [77824/154214]
Validation Done: [77888/154214]
Validation Done: [77952/154214]
Validation Done: [78016/154214]
Validation Done: [78080/154214]
Validation Done: [78144/154214]
Validation Done: [78208/154214]
Validation Done: [78272/154214]
Validation Done: [78336/154214]
Validation Done: [78400/154214]
Validation Done: [78464/154214]
Validation Done: [78528/154214]
Validation Done: [78592/154214]
Validation Done: [78656/154214]
Validation Done: [78720/154214]
Validation Done: [78784/154214]
Validation Done: [78848/154214]
Validation Done: [78912/154214]
Validation Done: [78976/154214]
Validation Done: [79040/154214]
Validation Done: [79104/154214]
Validation Done: [79168/154214]
Validation Done: [79232/154214]
Validation Done: [79296/154214]
Validation Done: [79360/154214]
Validation Done: [79424/154214]
Validation Done: [79488/154214]
Validation Done: [79552/154214]
Validation Done: [79616/154214]
Validation Done: [79680/154214]
Validation Done: [79744/154214]
Validation Done: [79808/154214]
Validation Done: [79872/154214]
Validation Done: [79936/154214]
Validation Done: [80000/154214]
Validation Done: [80064/154214]
Validation Done: [80128/154214]
Validation Done: [80192/154214]
Validation Done: [80256/154214]
Validation Done: [80320/154214]
Validation Done: [80384/154214]
Validation Done: [80448/154214]
Validation Done: [80512/154214]
Validation Done: [80576/154214]
Validation Done: [80640/154214]
Validation Done: [80704/154214]
Validation Done: [80768/154214]
Validation Done: [80832/154214]
Validation Done: [80896/154214]
Validation Done: [80960/154214]
Validation Done: [81024/154214]
Validation Done: [81088/154214]
Validation Done: [81152/154214]
Validation Done: [81216/154214]
Validation Done: [81280/154214]
Validation Done: [81344/154214]
Validation Done: [81408/154214]
Validation Done: [81472/154214]
Validation Done: [81536/154214]
Validation Done: [81600/154214]
Validation Done: [81664/154214]
Validation Done: [81728/154214]
Validation Done: [81792/154214]
Validation Done: [81856/154214]
Validation Done: [81920/154214]
Validation Done: [81984/154214]
Validation Done: [82048/154214]
Validation Done: [82112/154214]
Validation Done: [82176/154214]
Validation Done: [82240/154214]
Validation Done: [82304/154214]
Validation Done: [82368/154214]
Validation Done: [82432/154214]
Validation Done: [82496/154214]
Validation Done: [82560/154214]
Validation Done: [82624/154214]
Validation Done: [82688/154214]
Validation Done: [82752/154214]
Validation Done: [82816/154214]
Validation Done: [82880/154214]
Validation Done: [82944/154214]
Validation Done: [83008/154214]
Validation Done: [83072/154214]
Validation Done: [83136/154214]
Validation Done: [83200/154214]
Validation Done: [83264/154214]
Validation Done: [83328/154214]
Validation Done: [83392/154214]
Validation Done: [83456/154214]
Validation Done: [83520/154214]
Validation Done: [83584/154214]
Validation Done: [83648/154214]
Validation Done: [83712/154214]
Validation Done: [83776/154214]
Validation Done: [83840/154214]
Validation Done: [83904/154214]
Validation Done: [83968/154214]
Validation Done: [84032/154214]
Validation Done: [84096/154214]
Validation Done: [84160/154214]
Validation Done: [84224/154214]
Validation Done: [84288/154214]
Validation Done: [84352/154214]
Validation Done: [84416/154214]
Validation Done: [84480/154214]
Validation Done: [84544/154214]
Validation Done: [84608/154214]
Validation Done: [84672/154214]
Validation Done: [84736/154214]
Validation Done: [84800/154214]
Validation Done: [84864/154214]
Validation Done: [84928/154214]
Validation Done: [84992/154214]
Validation Done: [85056/154214]
Validation Done: [85120/154214]
Validation Done: [85184/154214]
Validation Done: [85248/154214]
Validation Done: [85312/154214]
Validation Done: [85376/154214]
Validation Done: [85440/154214]
Validation Done: [85504/154214]
Validation Done: [85568/154214]
Validation Done: [85632/154214]
Validation Done: [85696/154214]
Validation Done: [85760/154214]
Validation Done: [85824/154214]
Validation Done: [85888/154214]
Validation Done: [85952/154214]
Validation Done: [86016/154214]
Validation Done: [86080/154214]
Validation Done: [86144/154214]
Validation Done: [86208/154214]
Validation Done: [86272/154214]
Validation Done: [86336/154214]
Validation Done: [86400/154214]
Validation Done: [86464/154214]
Validation Done: [86528/154214]
Validation Done: [86592/154214]
Validation Done: [86656/154214]
Validation Done: [86720/154214]
Validation Done: [86784/154214]
Validation Done: [86848/154214]
Validation Done: [86912/154214]
Validation Done: [86976/154214]
Validation Done: [87040/154214]
Validation Done: [87104/154214]
Validation Done: [87168/154214]
Validation Done: [87232/154214]
Validation Done: [87296/154214]
Validation Done: [87360/154214]
Validation Done: [87424/154214]
Validation Done: [87488/154214]
Validation Done: [87552/154214]
Validation Done: [87616/154214]
Validation Done: [87680/154214]
Validation Done: [87744/154214]
Validation Done: [87808/154214]
Validation Done: [87872/154214]
Validation Done: [87936/154214]
Validation Done: [88000/154214]
Validation Done: [88064/154214]
Validation Done: [88128/154214]
Validation Done: [88192/154214]
Validation Done: [88256/154214]
Validation Done: [88320/154214]
Validation Done: [88384/154214]
Validation Done: [88448/154214]
Validation Done: [88512/154214]
Validation Done: [88576/154214]
Validation Done: [88640/154214]
Validation Done: [88704/154214]
Validation Done: [88768/154214]
Validation Done: [88832/154214]
Validation Done: [88896/154214]
Validation Done: [88960/154214]
Validation Done: [89024/154214]
Validation Done: [89088/154214]
Validation Done: [89152/154214]
Validation Done: [89216/154214]
Validation Done: [89280/154214]
Validation Done: [89344/154214]
Validation Done: [89408/154214]
Validation Done: [89472/154214]
Validation Done: [89536/154214]
Validation Done: [89600/154214]
Validation Done: [89664/154214]
Validation Done: [89728/154214]
Validation Done: [89792/154214]
Validation Done: [89856/154214]
Validation Done: [89920/154214]
Validation Done: [89984/154214]
Validation Done: [90048/154214]
Validation Done: [90112/154214]
Validation Done: [90176/154214]
Validation Done: [90240/154214]
Validation Done: [90304/154214]
Validation Done: [90368/154214]
Validation Done: [90432/154214]
Validation Done: [90496/154214]
Validation Done: [90560/154214]
Validation Done: [90624/154214]
Validation Done: [90688/154214]
Validation Done: [90752/154214]
Validation Done: [90816/154214]
Validation Done: [90880/154214]
Validation Done: [90944/154214]
Validation Done: [91008/154214]
Validation Done: [91072/154214]
Validation Done: [91136/154214]
Validation Done: [91200/154214]
Validation Done: [91264/154214]
Validation Done: [91328/154214]
Validation Done: [91392/154214]
Validation Done: [91456/154214]
Validation Done: [91520/154214]
Validation Done: [91584/154214]
Validation Done: [91648/154214]
Validation Done: [91712/154214]
Validation Done: [91776/154214]
Validation Done: [91840/154214]
Validation Done: [91904/154214]
Validation Done: [91968/154214]
Validation Done: [92032/154214]
Validation Done: [92096/154214]
Validation Done: [92160/154214]
Validation Done: [92224/154214]
Validation Done: [92288/154214]
Validation Done: [92352/154214]
Validation Done: [92416/154214]
Validation Done: [92480/154214]
Validation Done: [92544/154214]
Validation Done: [92608/154214]
Validation Done: [92672/154214]
Validation Done: [92736/154214]
Validation Done: [92800/154214]
Validation Done: [92864/154214]
Validation Done: [92928/154214]
Validation Done: [92992/154214]
Validation Done: [93056/154214]
Validation Done: [93120/154214]
Validation Done: [93184/154214]
Validation Done: [93248/154214]
Validation Done: [93312/154214]
Validation Done: [93376/154214]
Validation Done: [93440/154214]
Validation Done: [93504/154214]
Validation Done: [93568/154214]
Validation Done: [93632/154214]
Validation Done: [93696/154214]
Validation Done: [93760/154214]
Validation Done: [93824/154214]
Validation Done: [93888/154214]
Validation Done: [93952/154214]
Validation Done: [94016/154214]
Validation Done: [94080/154214]
Validation Done: [94144/154214]
Validation Done: [94208/154214]
Validation Done: [94272/154214]
Validation Done: [94336/154214]
Validation Done: [94400/154214]
Validation Done: [94464/154214]
Validation Done: [94528/154214]
Validation Done: [94592/154214]
Validation Done: [94656/154214]
Validation Done: [94720/154214]
Validation Done: [94784/154214]
Validation Done: [94848/154214]
Validation Done: [94912/154214]
Validation Done: [94976/154214]
Validation Done: [95040/154214]
Validation Done: [95104/154214]
Validation Done: [95168/154214]
Validation Done: [95232/154214]
Validation Done: [95296/154214]
Validation Done: [95360/154214]
Validation Done: [95424/154214]
Validation Done: [95488/154214]
Validation Done: [95552/154214]
Validation Done: [95616/154214]
Validation Done: [95680/154214]
Validation Done: [95744/154214]
Validation Done: [95808/154214]
Validation Done: [95872/154214]
Validation Done: [95936/154214]
Validation Done: [96000/154214]
Validation Done: [96064/154214]
Validation Done: [96128/154214]
Validation Done: [96192/154214]
Validation Done: [96256/154214]
Validation Done: [96320/154214]
Validation Done: [96384/154214]
Validation Done: [96448/154214]
Validation Done: [96512/154214]
Validation Done: [96576/154214]
Validation Done: [96640/154214]
Validation Done: [96704/154214]
Validation Done: [96768/154214]
Validation Done: [96832/154214]
Validation Done: [96896/154214]
Validation Done: [96960/154214]
Validation Done: [97024/154214]
Validation Done: [97088/154214]
Validation Done: [97152/154214]
Validation Done: [97216/154214]
Validation Done: [97280/154214]
Validation Done: [97344/154214]
Validation Done: [97408/154214]
Validation Done: [97472/154214]
Validation Done: [97536/154214]
Validation Done: [97600/154214]
Validation Done: [97664/154214]
Validation Done: [97728/154214]
Validation Done: [97792/154214]
Validation Done: [97856/154214]
Validation Done: [97920/154214]
Validation Done: [97984/154214]
Validation Done: [98048/154214]
Validation Done: [98112/154214]
Validation Done: [98176/154214]
Validation Done: [98240/154214]
Validation Done: [98304/154214]
Validation Done: [98368/154214]
Validation Done: [98432/154214]
Validation Done: [98496/154214]
Validation Done: [98560/154214]
Validation Done: [98624/154214]
Validation Done: [98688/154214]
Validation Done: [98752/154214]
Validation Done: [98816/154214]
Validation Done: [98880/154214]
Validation Done: [98944/154214]
Validation Done: [99008/154214]
Validation Done: [99072/154214]
Validation Done: [99136/154214]
Validation Done: [99200/154214]
Validation Done: [99264/154214]
Validation Done: [99328/154214]
Validation Done: [99392/154214]
Validation Done: [99456/154214]
Validation Done: [99520/154214]
Validation Done: [99584/154214]
Validation Done: [99648/154214]
Validation Done: [99712/154214]
Validation Done: [99776/154214]
Validation Done: [99840/154214]
Validation Done: [99904/154214]
Validation Done: [99968/154214]
Validation Done: [100032/154214]
Validation Done: [100096/154214]
Validation Done: [100160/154214]
Validation Done: [100224/154214]
Validation Done: [100288/154214]
Validation Done: [100352/154214]
Validation Done: [100416/154214]
Validation Done: [100480/154214]
Validation Done: [100544/154214]
Validation Done: [100608/154214]
Validation Done: [100672/154214]
Validation Done: [100736/154214]
Validation Done: [100800/154214]
Validation Done: [100864/154214]
Validation Done: [100928/154214]
Validation Done: [100992/154214]
Validation Done: [101056/154214]
Validation Done: [101120/154214]
Validation Done: [101184/154214]
Validation Done: [101248/154214]
Validation Done: [101312/154214]
Validation Done: [101376/154214]
Validation Done: [101440/154214]
Validation Done: [101504/154214]
Validation Done: [101568/154214]
Validation Done: [101632/154214]
Validation Done: [101696/154214]
Validation Done: [101760/154214]
Validation Done: [101824/154214]
Validation Done: [101888/154214]
Validation Done: [101952/154214]
Validation Done: [102016/154214]
Validation Done: [102080/154214]
Validation Done: [102144/154214]
Validation Done: [102208/154214]
Validation Done: [102272/154214]
Validation Done: [102336/154214]
Validation Done: [102400/154214]
Validation Done: [102464/154214]
Validation Done: [102528/154214]
Validation Done: [102592/154214]
Validation Done: [102656/154214]
Validation Done: [102720/154214]
Validation Done: [102784/154214]
Validation Done: [102848/154214]
Validation Done: [102912/154214]
Validation Done: [102976/154214]
Validation Done: [103040/154214]
Validation Done: [103104/154214]
Validation Done: [103168/154214]
Validation Done: [103232/154214]
Validation Done: [103296/154214]
Validation Done: [103360/154214]
Validation Done: [103424/154214]
Validation Done: [103488/154214]
Validation Done: [103552/154214]
Validation Done: [103616/154214]
Validation Done: [103680/154214]
Validation Done: [103744/154214]
Validation Done: [103808/154214]
Validation Done: [103872/154214]
Validation Done: [103936/154214]
Validation Done: [104000/154214]
Validation Done: [104064/154214]
Validation Done: [104128/154214]
Validation Done: [104192/154214]
Validation Done: [104256/154214]
Validation Done: [104320/154214]
Validation Done: [104384/154214]
Validation Done: [104448/154214]
Validation Done: [104512/154214]
Validation Done: [104576/154214]
Validation Done: [104640/154214]
Validation Done: [104704/154214]
Validation Done: [104768/154214]
Validation Done: [104832/154214]
Validation Done: [104896/154214]
Validation Done: [104960/154214]
Validation Done: [105024/154214]
Validation Done: [105088/154214]
Validation Done: [105152/154214]
Validation Done: [105216/154214]
Validation Done: [105280/154214]
Validation Done: [105344/154214]
Validation Done: [105408/154214]
Validation Done: [105472/154214]
Validation Done: [105536/154214]
Validation Done: [105600/154214]
Validation Done: [105664/154214]
Validation Done: [105728/154214]
Validation Done: [105792/154214]
Validation Done: [105856/154214]
Validation Done: [105920/154214]
Validation Done: [105984/154214]
Validation Done: [106048/154214]
Validation Done: [106112/154214]
Validation Done: [106176/154214]
Validation Done: [106240/154214]
Validation Done: [106304/154214]
Validation Done: [106368/154214]
Validation Done: [106432/154214]
Validation Done: [106496/154214]
Validation Done: [106560/154214]
Validation Done: [106624/154214]
Validation Done: [106688/154214]
Validation Done: [106752/154214]
Validation Done: [106816/154214]
Validation Done: [106880/154214]
Validation Done: [106944/154214]
Validation Done: [107008/154214]
Validation Done: [107072/154214]
Validation Done: [107136/154214]
Validation Done: [107200/154214]
Validation Done: [107264/154214]
Validation Done: [107328/154214]
Validation Done: [107392/154214]
Validation Done: [107456/154214]
Validation Done: [107520/154214]
Validation Done: [107584/154214]
Validation Done: [107648/154214]
Validation Done: [107712/154214]
Validation Done: [107776/154214]
Validation Done: [107840/154214]
Validation Done: [107904/154214]
Validation Done: [107968/154214]
Validation Done: [108032/154214]
Validation Done: [108096/154214]
Validation Done: [108160/154214]
Validation Done: [108224/154214]
Validation Done: [108288/154214]
Validation Done: [108352/154214]
Validation Done: [108416/154214]
Validation Done: [108480/154214]
Validation Done: [108544/154214]
Validation Done: [108608/154214]
Validation Done: [108672/154214]
Validation Done: [108736/154214]
Validation Done: [108800/154214]
Validation Done: [108864/154214]
Validation Done: [108928/154214]
Validation Done: [108992/154214]
Validation Done: [109056/154214]
Validation Done: [109120/154214]
Validation Done: [109184/154214]
Validation Done: [109248/154214]
Validation Done: [109312/154214]
Validation Done: [109376/154214]
Validation Done: [109440/154214]
Validation Done: [109504/154214]
Validation Done: [109568/154214]
Validation Done: [109632/154214]
Validation Done: [109696/154214]
Validation Done: [109760/154214]
Validation Done: [109824/154214]
Validation Done: [109888/154214]
Validation Done: [109952/154214]
Validation Done: [110016/154214]
Validation Done: [110080/154214]
Validation Done: [110144/154214]
Validation Done: [110208/154214]
Validation Done: [110272/154214]
Validation Done: [110336/154214]
Validation Done: [110400/154214]
Validation Done: [110464/154214]
Validation Done: [110528/154214]
Validation Done: [110592/154214]
Validation Done: [110656/154214]
Validation Done: [110720/154214]
Validation Done: [110784/154214]
Validation Done: [110848/154214]
Validation Done: [110912/154214]
Validation Done: [110976/154214]
Validation Done: [111040/154214]
Validation Done: [111104/154214]
Validation Done: [111168/154214]
Validation Done: [111232/154214]
Validation Done: [111296/154214]
Validation Done: [111360/154214]
Validation Done: [111424/154214]
Validation Done: [111488/154214]
Validation Done: [111552/154214]
Validation Done: [111616/154214]
Validation Done: [111680/154214]
Validation Done: [111744/154214]
Validation Done: [111808/154214]
Validation Done: [111872/154214]
Validation Done: [111936/154214]
Validation Done: [112000/154214]
Validation Done: [112064/154214]
Validation Done: [112128/154214]
Validation Done: [112192/154214]
Validation Done: [112256/154214]
Validation Done: [112320/154214]
Validation Done: [112384/154214]
Validation Done: [112448/154214]
Validation Done: [112512/154214]
Validation Done: [112576/154214]
Validation Done: [112640/154214]
Validation Done: [112704/154214]
Validation Done: [112768/154214]
Validation Done: [112832/154214]
Validation Done: [112896/154214]
Validation Done: [112960/154214]
Validation Done: [113024/154214]
Validation Done: [113088/154214]
Validation Done: [113152/154214]
Validation Done: [113216/154214]
Validation Done: [113280/154214]
Validation Done: [113344/154214]
Validation Done: [113408/154214]
Validation Done: [113472/154214]
Validation Done: [113536/154214]
Validation Done: [113600/154214]
Validation Done: [113664/154214]
Validation Done: [113728/154214]
Validation Done: [113792/154214]
Validation Done: [113856/154214]
Validation Done: [113920/154214]
Validation Done: [113984/154214]
Validation Done: [114048/154214]
Validation Done: [114112/154214]
Validation Done: [114176/154214]
Validation Done: [114240/154214]
Validation Done: [114304/154214]
Validation Done: [114368/154214]
Validation Done: [114432/154214]
Validation Done: [114496/154214]
Validation Done: [114560/154214]
Validation Done: [114624/154214]
Validation Done: [114688/154214]
Validation Done: [114752/154214]
Validation Done: [114816/154214]
Validation Done: [114880/154214]
Validation Done: [114944/154214]
Validation Done: [115008/154214]
Validation Done: [115072/154214]
Validation Done: [115136/154214]
Validation Done: [115200/154214]
Validation Done: [115264/154214]
Validation Done: [115328/154214]
Validation Done: [115392/154214]
Validation Done: [115456/154214]
Validation Done: [115520/154214]
Validation Done: [115584/154214]
Validation Done: [115648/154214]
Validation Done: [115712/154214]
Validation Done: [115776/154214]
Validation Done: [115840/154214]
Validation Done: [115904/154214]
Validation Done: [115968/154214]
Validation Done: [116032/154214]
Validation Done: [116096/154214]
Validation Done: [116160/154214]
Validation Done: [116224/154214]
Validation Done: [116288/154214]
Validation Done: [116352/154214]
Validation Done: [116416/154214]
Validation Done: [116480/154214]
Validation Done: [116544/154214]
Validation Done: [116608/154214]
Validation Done: [116672/154214]
Validation Done: [116736/154214]
Validation Done: [116800/154214]
Validation Done: [116864/154214]
Validation Done: [116928/154214]
Validation Done: [116992/154214]
Validation Done: [117056/154214]
Validation Done: [117120/154214]
Validation Done: [117184/154214]
Validation Done: [117248/154214]
Validation Done: [117312/154214]
Validation Done: [117376/154214]
Validation Done: [117440/154214]
Validation Done: [117504/154214]
Validation Done: [117568/154214]
Validation Done: [117632/154214]
Validation Done: [117696/154214]
Validation Done: [117760/154214]
Validation Done: [117824/154214]
Validation Done: [117888/154214]
Validation Done: [117952/154214]
Validation Done: [118016/154214]
Validation Done: [118080/154214]
Validation Done: [118144/154214]
Validation Done: [118208/154214]
Validation Done: [118272/154214]
Validation Done: [118336/154214]
Validation Done: [118400/154214]
Validation Done: [118464/154214]
Validation Done: [118528/154214]
Validation Done: [118592/154214]
Validation Done: [118656/154214]
Validation Done: [118720/154214]
Validation Done: [118784/154214]
Validation Done: [118848/154214]
Validation Done: [118912/154214]
Validation Done: [118976/154214]
Validation Done: [119040/154214]
Validation Done: [119104/154214]
Validation Done: [119168/154214]
Validation Done: [119232/154214]
Validation Done: [119296/154214]
Validation Done: [119360/154214]
Validation Done: [119424/154214]
Validation Done: [119488/154214]
Validation Done: [119552/154214]
Validation Done: [119616/154214]
Validation Done: [119680/154214]
Validation Done: [119744/154214]
Validation Done: [119808/154214]
Validation Done: [119872/154214]
Validation Done: [119936/154214]
Validation Done: [120000/154214]
Validation Done: [120064/154214]
Validation Done: [120128/154214]
Validation Done: [120192/154214]
Validation Done: [120256/154214]
Validation Done: [120320/154214]
Validation Done: [120384/154214]
Validation Done: [120448/154214]
Validation Done: [120512/154214]
Validation Done: [120576/154214]
Validation Done: [120640/154214]
Validation Done: [120704/154214]
Validation Done: [120768/154214]
Validation Done: [120832/154214]
Validation Done: [120896/154214]
Validation Done: [120960/154214]
Validation Done: [121024/154214]
Validation Done: [121088/154214]
Validation Done: [121152/154214]
Validation Done: [121216/154214]
Validation Done: [121280/154214]
Validation Done: [121344/154214]
Validation Done: [121408/154214]
Validation Done: [121472/154214]
Validation Done: [121536/154214]
Validation Done: [121600/154214]
Validation Done: [121664/154214]
Validation Done: [121728/154214]
Validation Done: [121792/154214]
Validation Done: [121856/154214]
Validation Done: [121920/154214]
Validation Done: [121984/154214]
Validation Done: [122048/154214]
Validation Done: [122112/154214]
Validation Done: [122176/154214]
Validation Done: [122240/154214]
Validation Done: [122304/154214]
Validation Done: [122368/154214]
Validation Done: [122432/154214]
Validation Done: [122496/154214]
Validation Done: [122560/154214]
Validation Done: [122624/154214]
Validation Done: [122688/154214]
Validation Done: [122752/154214]
Validation Done: [122816/154214]
Validation Done: [122880/154214]
Validation Done: [122944/154214]
Validation Done: [123008/154214]
Validation Done: [123072/154214]
Validation Done: [123136/154214]
Validation Done: [123200/154214]
Validation Done: [123264/154214]
Validation Done: [123328/154214]
Validation Done: [123392/154214]
Validation Done: [123456/154214]
Validation Done: [123520/154214]
Validation Done: [123584/154214]
Validation Done: [123648/154214]
Validation Done: [123712/154214]
Validation Done: [123776/154214]
Validation Done: [123840/154214]
Validation Done: [123904/154214]
Validation Done: [123968/154214]
Validation Done: [124032/154214]
Validation Done: [124096/154214]
Validation Done: [124160/154214]
Validation Done: [124224/154214]
Validation Done: [124288/154214]
Validation Done: [124352/154214]
Validation Done: [124416/154214]
Validation Done: [124480/154214]
Validation Done: [124544/154214]
Validation Done: [124608/154214]
Validation Done: [124672/154214]
Validation Done: [124736/154214]
Validation Done: [124800/154214]
Validation Done: [124864/154214]
Validation Done: [124928/154214]
Validation Done: [124992/154214]
Validation Done: [125056/154214]
Validation Done: [125120/154214]
Validation Done: [125184/154214]
Validation Done: [125248/154214]
Validation Done: [125312/154214]
Validation Done: [125376/154214]
Validation Done: [125440/154214]
Validation Done: [125504/154214]
Validation Done: [125568/154214]
Validation Done: [125632/154214]
Validation Done: [125696/154214]
Validation Done: [125760/154214]
Validation Done: [125824/154214]
Validation Done: [125888/154214]
Validation Done: [125952/154214]
Validation Done: [126016/154214]
Validation Done: [126080/154214]
Validation Done: [126144/154214]
Validation Done: [126208/154214]
Validation Done: [126272/154214]
Validation Done: [126336/154214]
Validation Done: [126400/154214]
Validation Done: [126464/154214]
Validation Done: [126528/154214]
Validation Done: [126592/154214]
Validation Done: [126656/154214]
Validation Done: [126720/154214]
Validation Done: [126784/154214]
Validation Done: [126848/154214]
Validation Done: [126912/154214]
Validation Done: [126976/154214]
Validation Done: [127040/154214]
Validation Done: [127104/154214]
Validation Done: [127168/154214]
Validation Done: [127232/154214]
Validation Done: [127296/154214]
Validation Done: [127360/154214]
Validation Done: [127424/154214]
Validation Done: [127488/154214]
Validation Done: [127552/154214]
Validation Done: [127616/154214]
Validation Done: [127680/154214]
Validation Done: [127744/154214]
Validation Done: [127808/154214]
Validation Done: [127872/154214]
Validation Done: [127936/154214]
Validation Done: [128000/154214]
Validation Done: [128064/154214]
Validation Done: [128128/154214]
Validation Done: [128192/154214]
Validation Done: [128256/154214]
Validation Done: [128320/154214]
Validation Done: [128384/154214]
Validation Done: [128448/154214]
Validation Done: [128512/154214]
Validation Done: [128576/154214]
Validation Done: [128640/154214]
Validation Done: [128704/154214]
Validation Done: [128768/154214]
Validation Done: [128832/154214]
Validation Done: [128896/154214]
Validation Done: [128960/154214]
Validation Done: [129024/154214]
Validation Done: [129088/154214]
Validation Done: [129152/154214]
Validation Done: [129216/154214]
Validation Done: [129280/154214]
Validation Done: [129344/154214]
Validation Done: [129408/154214]
Validation Done: [129472/154214]
Validation Done: [129536/154214]
Validation Done: [129600/154214]
Validation Done: [129664/154214]
Validation Done: [129728/154214]
Validation Done: [129792/154214]
Validation Done: [129856/154214]
Validation Done: [129920/154214]
Validation Done: [129984/154214]
Validation Done: [130048/154214]
Validation Done: [130112/154214]
Validation Done: [130176/154214]
Validation Done: [130240/154214]
Validation Done: [130304/154214]
Validation Done: [130368/154214]
Validation Done: [130432/154214]
Validation Done: [130496/154214]
Validation Done: [130560/154214]
Validation Done: [130624/154214]
Validation Done: [130688/154214]
Validation Done: [130752/154214]
Validation Done: [130816/154214]
Validation Done: [130880/154214]
Validation Done: [130944/154214]
Validation Done: [131008/154214]
Validation Done: [131072/154214]
Validation Done: [131136/154214]
Validation Done: [131200/154214]
Validation Done: [131264/154214]
Validation Done: [131328/154214]
Validation Done: [131392/154214]
Validation Done: [131456/154214]
Validation Done: [131520/154214]
Validation Done: [131584/154214]
Validation Done: [131648/154214]
Validation Done: [131712/154214]
Validation Done: [131776/154214]
Validation Done: [131840/154214]
Validation Done: [131904/154214]
Validation Done: [131968/154214]
Validation Done: [132032/154214]
Validation Done: [132096/154214]
Validation Done: [132160/154214]
Validation Done: [132224/154214]
Validation Done: [132288/154214]
Validation Done: [132352/154214]
Validation Done: [132416/154214]
Validation Done: [132480/154214]
Validation Done: [132544/154214]
Validation Done: [132608/154214]
Validation Done: [132672/154214]
Validation Done: [132736/154214]
Validation Done: [132800/154214]
Validation Done: [132864/154214]
Validation Done: [132928/154214]
Validation Done: [132992/154214]
Validation Done: [133056/154214]
Validation Done: [133120/154214]
Validation Done: [133184/154214]
Validation Done: [133248/154214]
Validation Done: [133312/154214]
Validation Done: [133376/154214]
Validation Done: [133440/154214]
Validation Done: [133504/154214]
Validation Done: [133568/154214]
Validation Done: [133632/154214]
Validation Done: [133696/154214]
Validation Done: [133760/154214]
Validation Done: [133824/154214]
Validation Done: [133888/154214]
Validation Done: [133952/154214]
Validation Done: [134016/154214]
Validation Done: [134080/154214]
Validation Done: [134144/154214]
Validation Done: [134208/154214]
Validation Done: [134272/154214]
Validation Done: [134336/154214]
Validation Done: [134400/154214]
Validation Done: [134464/154214]
Validation Done: [134528/154214]
Validation Done: [134592/154214]
Validation Done: [134656/154214]
Validation Done: [134720/154214]
Validation Done: [134784/154214]
Validation Done: [134848/154214]
Validation Done: [134912/154214]
Validation Done: [134976/154214]
Validation Done: [135040/154214]
Validation Done: [135104/154214]
Validation Done: [135168/154214]
Validation Done: [135232/154214]
Validation Done: [135296/154214]
Validation Done: [135360/154214]
Validation Done: [135424/154214]
Validation Done: [135488/154214]
Validation Done: [135552/154214]
Validation Done: [135616/154214]
Validation Done: [135680/154214]
Validation Done: [135744/154214]
Validation Done: [135808/154214]
Validation Done: [135872/154214]
Validation Done: [135936/154214]
Validation Done: [136000/154214]
Validation Done: [136064/154214]
Validation Done: [136128/154214]
Validation Done: [136192/154214]
Validation Done: [136256/154214]
Validation Done: [136320/154214]
Validation Done: [136384/154214]
Validation Done: [136448/154214]
Validation Done: [136512/154214]
Validation Done: [136576/154214]
Validation Done: [136640/154214]
Validation Done: [136704/154214]
Validation Done: [136768/154214]
Validation Done: [136832/154214]
Validation Done: [136896/154214]
Validation Done: [136960/154214]
Validation Done: [137024/154214]
Validation Done: [137088/154214]
Validation Done: [137152/154214]
Validation Done: [137216/154214]
Validation Done: [137280/154214]
Validation Done: [137344/154214]
Validation Done: [137408/154214]
Validation Done: [137472/154214]
Validation Done: [137536/154214]
Validation Done: [137600/154214]
Validation Done: [137664/154214]
Validation Done: [137728/154214]
Validation Done: [137792/154214]
Validation Done: [137856/154214]
Validation Done: [137920/154214]
Validation Done: [137984/154214]
Validation Done: [138048/154214]
Validation Done: [138112/154214]
Validation Done: [138176/154214]
Validation Done: [138240/154214]
Validation Done: [138304/154214]
Validation Done: [138368/154214]
Validation Done: [138432/154214]
Validation Done: [138496/154214]
Validation Done: [138560/154214]
Validation Done: [138624/154214]
Validation Done: [138688/154214]
Validation Done: [138752/154214]
Validation Done: [138816/154214]
Validation Done: [138880/154214]
Validation Done: [138944/154214]
Validation Done: [139008/154214]
Validation Done: [139072/154214]
Validation Done: [139136/154214]
Validation Done: [139200/154214]
Validation Done: [139264/154214]
Validation Done: [139328/154214]
Validation Done: [139392/154214]
Validation Done: [139456/154214]
Validation Done: [139520/154214]
Validation Done: [139584/154214]
Validation Done: [139648/154214]
Validation Done: [139712/154214]
Validation Done: [139776/154214]
Validation Done: [139840/154214]
Validation Done: [139904/154214]
Validation Done: [139968/154214]
Validation Done: [140032/154214]
Validation Done: [140096/154214]
Validation Done: [140160/154214]
Validation Done: [140224/154214]
Validation Done: [140288/154214]
Validation Done: [140352/154214]
Validation Done: [140416/154214]
Validation Done: [140480/154214]
Validation Done: [140544/154214]
Validation Done: [140608/154214]
Validation Done: [140672/154214]
Validation Done: [140736/154214]
Validation Done: [140800/154214]
Validation Done: [140864/154214]
Validation Done: [140928/154214]
Validation Done: [140992/154214]
Validation Done: [141056/154214]
Validation Done: [141120/154214]
Validation Done: [141184/154214]
Validation Done: [141248/154214]
Validation Done: [141312/154214]
Validation Done: [141376/154214]
Validation Done: [141440/154214]
Validation Done: [141504/154214]
Validation Done: [141568/154214]
Validation Done: [141632/154214]
Validation Done: [141696/154214]
Validation Done: [141760/154214]
Validation Done: [141824/154214]
Validation Done: [141888/154214]
Validation Done: [141952/154214]
Validation Done: [142016/154214]
Validation Done: [142080/154214]
Validation Done: [142144/154214]
Validation Done: [142208/154214]
Validation Done: [142272/154214]
Validation Done: [142336/154214]
Validation Done: [142400/154214]
Validation Done: [142464/154214]
Validation Done: [142528/154214]
Validation Done: [142592/154214]
Validation Done: [142656/154214]
Validation Done: [142720/154214]
Validation Done: [142784/154214]
Validation Done: [142848/154214]
Validation Done: [142912/154214]
Validation Done: [142976/154214]
Validation Done: [143040/154214]
Validation Done: [143104/154214]
Validation Done: [143168/154214]
Validation Done: [143232/154214]
Validation Done: [143296/154214]
Validation Done: [143360/154214]
Validation Done: [143424/154214]
Validation Done: [143488/154214]
Validation Done: [143552/154214]
Validation Done: [143616/154214]
Validation Done: [143680/154214]
Validation Done: [143744/154214]
Validation Done: [143808/154214]
Validation Done: [143872/154214]
Validation Done: [143936/154214]
Validation Done: [144000/154214]
Validation Done: [144064/154214]
Validation Done: [144128/154214]
Validation Done: [144192/154214]
Validation Done: [144256/154214]
Validation Done: [144320/154214]
Validation Done: [144384/154214]
Validation Done: [144448/154214]
Validation Done: [144512/154214]
Validation Done: [144576/154214]
Validation Done: [144640/154214]
Validation Done: [144704/154214]
Validation Done: [144768/154214]
Validation Done: [144832/154214]
Validation Done: [144896/154214]
Validation Done: [144960/154214]
Validation Done: [145024/154214]
Validation Done: [145088/154214]
Validation Done: [145152/154214]
Validation Done: [145216/154214]
Validation Done: [145280/154214]
Validation Done: [145344/154214]
Validation Done: [145408/154214]
Validation Done: [145472/154214]
Validation Done: [145536/154214]
Validation Done: [145600/154214]
Validation Done: [145664/154214]
Validation Done: [145728/154214]
Validation Done: [145792/154214]
Validation Done: [145856/154214]
Validation Done: [145920/154214]
Validation Done: [145984/154214]
Validation Done: [146048/154214]
Validation Done: [146112/154214]
Validation Done: [146176/154214]
Validation Done: [146240/154214]
Validation Done: [146304/154214]
Validation Done: [146368/154214]
Validation Done: [146432/154214]
Validation Done: [146496/154214]
Validation Done: [146560/154214]
Validation Done: [146624/154214]
Validation Done: [146688/154214]
Validation Done: [146752/154214]
Validation Done: [146816/154214]
Validation Done: [146880/154214]
Validation Done: [146944/154214]
Validation Done: [147008/154214]
Validation Done: [147072/154214]
Validation Done: [147136/154214]
Validation Done: [147200/154214]
Validation Done: [147264/154214]
Validation Done: [147328/154214]
Validation Done: [147392/154214]
Validation Done: [147456/154214]
Validation Done: [147520/154214]
Validation Done: [147584/154214]
Validation Done: [147648/154214]
Validation Done: [147712/154214]
Validation Done: [147776/154214]
Validation Done: [147840/154214]
Validation Done: [147904/154214]
Validation Done: [147968/154214]
Validation Done: [148032/154214]
Validation Done: [148096/154214]
Validation Done: [148160/154214]
Validation Done: [148224/154214]
Validation Done: [148288/154214]
Validation Done: [148352/154214]
Validation Done: [148416/154214]
Validation Done: [148480/154214]
Validation Done: [148544/154214]
Validation Done: [148608/154214]
Validation Done: [148672/154214]
Validation Done: [148736/154214]
Validation Done: [148800/154214]
Validation Done: [148864/154214]
Validation Done: [148928/154214]
Validation Done: [148992/154214]
Validation Done: [149056/154214]
Validation Done: [149120/154214]
Validation Done: [149184/154214]
Validation Done: [149248/154214]
Validation Done: [149312/154214]
Validation Done: [149376/154214]
Validation Done: [149440/154214]
Validation Done: [149504/154214]
Validation Done: [149568/154214]
Validation Done: [149632/154214]
Validation Done: [149696/154214]
Validation Done: [149760/154214]
Validation Done: [149824/154214]
Validation Done: [149888/154214]
Validation Done: [149952/154214]
Validation Done: [150016/154214]
Validation Done: [150080/154214]
Validation Done: [150144/154214]
Validation Done: [150208/154214]
Validation Done: [150272/154214]
Validation Done: [150336/154214]
Validation Done: [150400/154214]
Validation Done: [150464/154214]
Validation Done: [150528/154214]
Validation Done: [150592/154214]
Validation Done: [150656/154214]
Validation Done: [150720/154214]
Validation Done: [150784/154214]
Validation Done: [150848/154214]
Validation Done: [150912/154214]
Validation Done: [150976/154214]
Validation Done: [151040/154214]
Validation Done: [151104/154214]
Validation Done: [151168/154214]
Validation Done: [151232/154214]
Validation Done: [151296/154214]
Validation Done: [151360/154214]
Validation Done: [151424/154214]
Validation Done: [151488/154214]
Validation Done: [151552/154214]
Validation Done: [151616/154214]
Validation Done: [151680/154214]
Validation Done: [151744/154214]
Validation Done: [151808/154214]
Validation Done: [151872/154214]
Validation Done: [151936/154214]
Validation Done: [152000/154214]
Validation Done: [152064/154214]
Validation Done: [152128/154214]
Validation Done: [152192/154214]
Validation Done: [152256/154214]
Validation Done: [152320/154214]
Validation Done: [152384/154214]
Validation Done: [152448/154214]
Validation Done: [152512/154214]
Validation Done: [152576/154214]
Validation Done: [152640/154214]
Validation Done: [152704/154214]
Validation Done: [152768/154214]
Validation Done: [152832/154214]
Validation Done: [152896/154214]
Validation Done: [152960/154214]
Validation Done: [153024/154214]
Validation Done: [153088/154214]
Validation Done: [153152/154214]
Validation Done: [153216/154214]
Validation Done: [153280/154214]
Validation Done: [153344/154214]
Validation Done: [153408/154214]
Validation Done: [153472/154214]
Validation Done: [153536/154214]
Validation Done: [153600/154214]
Validation Done: [153664/154214]
Validation Done: [153728/154214]
Validation Done: [153792/154214]
Validation Done: [153856/154214]
Validation Done: [153920/154214]
Validation Done: [153984/154214]
Validation Done: [154048/154214]
Validation Done: [154112/154214]
Validation Done: [154176/154214]
Validation Done: [91580/154214]
[Test] Epoch: 2 Test set: Average loss: 0.0083, Accuracy: 121278/154214 (78.64%)
{'KIRC': {'recall': 0.8669943694700152, 'support': 55945, 'precision': 0.7495364074669304, 'f1-score': 0.8039981103458566}, 'weighted avg': {'recall': 0.7864266538705954, 'support': 154214, 'precision': 0.791446943949621, 'f1-score': 0.7859685932596167}, 'KICH': {'recall': 0.7463439752832132, 'support': 58260, 'precision': 0.8534081764832878, 'f1-score': 0.7962934136671215}, 'accuracy': 0.7864266538705954, 'macro avg': {'recall': 0.7818245381058588, 'support': 154214, 'precision': 0.7875897439397583, 'f1-score': 0.7820048460898658}, 'KIRP': {'recall': 0.732135269564348, 'support': 40009, 'precision': 0.7598246478690566, 'f1-score': 0.7457230142566192}}
[Train] Epoch: 3 [64/620022]    Loss: 0.008268   Batch Acc: 79.69
[Train] Epoch: 3 [128/620022]    Loss: 0.008891   Batch Acc: 73.44
[Train] Epoch: 3 [192/620022]    Loss: 0.008054   Batch Acc: 78.12
[Train] Epoch: 3 [256/620022]    Loss: 0.009996   Batch Acc: 70.31
[Train] Epoch: 3 [320/620022]    Loss: 0.008583   Batch Acc: 79.69
[Train] Epoch: 3 [384/620022]    Loss: 0.008694   Batch Acc: 73.44
[Train] Epoch: 3 [448/620022]    Loss: 0.009769   Batch Acc: 68.75
[Train] Epoch: 3 [512/620022]    Loss: 0.012642   Batch Acc: 67.19
[Train] Epoch: 3 [576/620022]    Loss: 0.005884   Batch Acc: 85.94
[Train] Epoch: 3 [640/620022]    Loss: 0.008363   Batch Acc: 81.25
[Train] Epoch: 3 [704/620022]    Loss: 0.007295   Batch Acc: 84.38
[Train] Epoch: 3 [768/620022]    Loss: 0.010705   Batch Acc: 70.31
[Train] Epoch: 3 [832/620022]    Loss: 0.008105   Batch Acc: 78.12
[Train] Epoch: 3 [896/620022]    Loss: 0.007020   Batch Acc: 82.81
[Train] Epoch: 3 [960/620022]    Loss: 0.007825   Batch Acc: 79.69
[Train] Epoch: 3 [1024/620022]    Loss: 0.009181   Batch Acc: 75.00
[Train] Epoch: 3 [1088/620022]    Loss: 0.009732   Batch Acc: 79.69
[Train] Epoch: 3 [1152/620022]    Loss: 0.008558   Batch Acc: 73.44
[Train] Epoch: 3 [1216/620022]    Loss: 0.009607   Batch Acc: 78.12
[Train] Epoch: 3 [1280/620022]    Loss: 0.010705   Batch Acc: 71.88
[Train] Epoch: 3 [1344/620022]    Loss: 0.008808   Batch Acc: 76.56
[Train] Epoch: 3 [1408/620022]    Loss: 0.009728   Batch Acc: 75.00
[Train] Epoch: 3 [1472/620022]    Loss: 0.008352   Batch Acc: 84.38
[Train] Epoch: 3 [1536/620022]    Loss: 0.006785   Batch Acc: 81.25
[Train] Epoch: 3 [1600/620022]    Loss: 0.008008   Batch Acc: 81.25
[Train] Epoch: 3 [1664/620022]    Loss: 0.009080   Batch Acc: 75.00
[Train] Epoch: 3 [1728/620022]    Loss: 0.009648   Batch Acc: 71.88
[Train] Epoch: 3 [1792/620022]    Loss: 0.006817   Batch Acc: 89.06
[Train] Epoch: 3 [1856/620022]    Loss: 0.006653   Batch Acc: 84.38
[Train] Epoch: 3 [1920/620022]    Loss: 0.008626   Batch Acc: 79.69
[Train] Epoch: 3 [1984/620022]    Loss: 0.008307   Batch Acc: 81.25
[Train] Epoch: 3 [2048/620022]    Loss: 0.010053   Batch Acc: 75.00
[Train] Epoch: 3 [2112/620022]    Loss: 0.007852   Batch Acc: 79.69
[Train] Epoch: 3 [2176/620022]    Loss: 0.007860   Batch Acc: 76.56
[Train] Epoch: 3 [2240/620022]    Loss: 0.007796   Batch Acc: 79.69
[Train] Epoch: 3 [2304/620022]    Loss: 0.010740   Batch Acc: 68.75
[Train] Epoch: 3 [2368/620022]    Loss: 0.009327   Batch Acc: 79.69
[Train] Epoch: 3 [2432/620022]    Loss: 0.008210   Batch Acc: 82.81
[Train] Epoch: 3 [2496/620022]    Loss: 0.010053   Batch Acc: 79.69
[Train] Epoch: 3 [2560/620022]    Loss: 0.009035   Batch Acc: 81.25
[Train] Epoch: 3 [2624/620022]    Loss: 0.006765   Batch Acc: 81.25
[Train] Epoch: 3 [2688/620022]    Loss: 0.008638   Batch Acc: 76.56
[Train] Epoch: 3 [2752/620022]    Loss: 0.008803   Batch Acc: 81.25
[Train] Epoch: 3 [2816/620022]    Loss: 0.008162   Batch Acc: 78.12
[Train] Epoch: 3 [2880/620022]    Loss: 0.007960   Batch Acc: 78.12
[Train] Epoch: 3 [2944/620022]    Loss: 0.010510   Batch Acc: 75.00
[Train] Epoch: 3 [3008/620022]    Loss: 0.009631   Batch Acc: 79.69
[Train] Epoch: 3 [3072/620022]    Loss: 0.008811   Batch Acc: 78.12
[Train] Epoch: 3 [3136/620022]    Loss: 0.007698   Batch Acc: 81.25
[Train] Epoch: 3 [3200/620022]    Loss: 0.008619   Batch Acc: 79.69
[Train] Epoch: 3 [3264/620022]    Loss: 0.009526   Batch Acc: 73.44
[Train] Epoch: 3 [3328/620022]    Loss: 0.008755   Batch Acc: 79.69
[Train] Epoch: 3 [3392/620022]    Loss: 0.007091   Batch Acc: 84.38
[Train] Epoch: 3 [3456/620022]    Loss: 0.009556   Batch Acc: 75.00
[Train] Epoch: 3 [3520/620022]    Loss: 0.008090   Batch Acc: 81.25
[Train] Epoch: 3 [3584/620022]    Loss: 0.009289   Batch Acc: 73.44
[Train] Epoch: 3 [3648/620022]    Loss: 0.007677   Batch Acc: 85.94
[Train] Epoch: 3 [3712/620022]    Loss: 0.010868   Batch Acc: 76.56
[Train] Epoch: 3 [3776/620022]    Loss: 0.009994   Batch Acc: 81.25
[Train] Epoch: 3 [3840/620022]    Loss: 0.007320   Batch Acc: 79.69
[Train] Epoch: 3 [3904/620022]    Loss: 0.011021   Batch Acc: 71.88
[Train] Epoch: 3 [3968/620022]    Loss: 0.009965   Batch Acc: 79.69
[Train] Epoch: 3 [4032/620022]    Loss: 0.005893   Batch Acc: 87.50
[Train] Epoch: 3 [4096/620022]    Loss: 0.009283   Batch Acc: 76.56
[Train] Epoch: 3 [4160/620022]    Loss: 0.009738   Batch Acc: 73.44
[Train] Epoch: 3 [4224/620022]    Loss: 0.008172   Batch Acc: 85.94
[Train] Epoch: 3 [4288/620022]    Loss: 0.005858   Batch Acc: 87.50
[Train] Epoch: 3 [4352/620022]    Loss: 0.009179   Batch Acc: 78.12
[Train] Epoch: 3 [4416/620022]    Loss: 0.010015   Batch Acc: 75.00
[Train] Epoch: 3 [4480/620022]    Loss: 0.007951   Batch Acc: 76.56
[Train] Epoch: 3 [4544/620022]    Loss: 0.009123   Batch Acc: 75.00
[Train] Epoch: 3 [4608/620022]    Loss: 0.010391   Batch Acc: 75.00
[Train] Epoch: 3 [4672/620022]    Loss: 0.007339   Batch Acc: 82.81
[Train] Epoch: 3 [4736/620022]    Loss: 0.009888   Batch Acc: 75.00
[Train] Epoch: 3 [4800/620022]    Loss: 0.009334   Batch Acc: 75.00
[Train] Epoch: 3 [4864/620022]    Loss: 0.007123   Batch Acc: 81.25
[Train] Epoch: 3 [4928/620022]    Loss: 0.008304   Batch Acc: 78.12
[Train] Epoch: 3 [4992/620022]    Loss: 0.007980   Batch Acc: 78.12
[Train] Epoch: 3 [5056/620022]    Loss: 0.007897   Batch Acc: 79.69
[Train] Epoch: 3 [5120/620022]    Loss: 0.007322   Batch Acc: 85.94
[Train] Epoch: 3 [5184/620022]    Loss: 0.010220   Batch Acc: 76.56
[Train] Epoch: 3 [5248/620022]    Loss: 0.009461   Batch Acc: 76.56
[Train] Epoch: 3 [5312/620022]    Loss: 0.006861   Batch Acc: 82.81
[Train] Epoch: 3 [5376/620022]    Loss: 0.007673   Batch Acc: 79.69
[Train] Epoch: 3 [5440/620022]    Loss: 0.006617   Batch Acc: 82.81
[Train] Epoch: 3 [5504/620022]    Loss: 0.009531   Batch Acc: 79.69
[Train] Epoch: 3 [5568/620022]    Loss: 0.007141   Batch Acc: 82.81
[Train] Epoch: 3 [5632/620022]    Loss: 0.010972   Batch Acc: 70.31
[Train] Epoch: 3 [5696/620022]    Loss: 0.009012   Batch Acc: 81.25
[Train] Epoch: 3 [5760/620022]    Loss: 0.008246   Batch Acc: 76.56
[Train] Epoch: 3 [5824/620022]    Loss: 0.011864   Batch Acc: 67.19
[Train] Epoch: 3 [5888/620022]    Loss: 0.007583   Batch Acc: 82.81
[Train] Epoch: 3 [5952/620022]    Loss: 0.006255   Batch Acc: 82.81
[Train] Epoch: 3 [6016/620022]    Loss: 0.008682   Batch Acc: 73.44
[Train] Epoch: 3 [6080/620022]    Loss: 0.008792   Batch Acc: 68.75
[Train] Epoch: 3 [6144/620022]    Loss: 0.009205   Batch Acc: 71.88
[Train] Epoch: 3 [6208/620022]    Loss: 0.011380   Batch Acc: 75.00
[Train] Epoch: 3 [6272/620022]    Loss: 0.007424   Batch Acc: 81.25
[Train] Epoch: 3 [6336/620022]    Loss: 0.010195   Batch Acc: 76.56
[Train] Epoch: 3 [6400/620022]    Loss: 0.010905   Batch Acc: 73.44
[Train] Epoch: 3 [6464/620022]    Loss: 0.008053   Batch Acc: 75.00
[Train] Epoch: 3 [6528/620022]    Loss: 0.009835   Batch Acc: 73.44
[Train] Epoch: 3 [6592/620022]    Loss: 0.008698   Batch Acc: 79.69
[Train] Epoch: 3 [6656/620022]    Loss: 0.010145   Batch Acc: 78.12
[Train] Epoch: 3 [6720/620022]    Loss: 0.008752   Batch Acc: 81.25
[Train] Epoch: 3 [6784/620022]    Loss: 0.007747   Batch Acc: 82.81
[Train] Epoch: 3 [6848/620022]    Loss: 0.007164   Batch Acc: 84.38
[Train] Epoch: 3 [6912/620022]    Loss: 0.007420   Batch Acc: 79.69
[Train] Epoch: 3 [6976/620022]    Loss: 0.010280   Batch Acc: 71.88
[Train] Epoch: 3 [7040/620022]    Loss: 0.006764   Batch Acc: 79.69
[Train] Epoch: 3 [7104/620022]    Loss: 0.009857   Batch Acc: 70.31
[Train] Epoch: 3 [7168/620022]    Loss: 0.007430   Batch Acc: 79.69
[Train] Epoch: 3 [7232/620022]    Loss: 0.008837   Batch Acc: 78.12
[Train] Epoch: 3 [7296/620022]    Loss: 0.008373   Batch Acc: 82.81
[Train] Epoch: 3 [7360/620022]    Loss: 0.008177   Batch Acc: 81.25
[Train] Epoch: 3 [7424/620022]    Loss: 0.009652   Batch Acc: 76.56
[Train] Epoch: 3 [7488/620022]    Loss: 0.007666   Batch Acc: 84.38
[Train] Epoch: 3 [7552/620022]    Loss: 0.007955   Batch Acc: 81.25
[Train] Epoch: 3 [7616/620022]    Loss: 0.005731   Batch Acc: 85.94
[Train] Epoch: 3 [7680/620022]    Loss: 0.010981   Batch Acc: 70.31
[Train] Epoch: 3 [7744/620022]    Loss: 0.008794   Batch Acc: 79.69
[Train] Epoch: 3 [7808/620022]    Loss: 0.007394   Batch Acc: 82.81
[Train] Epoch: 3 [7872/620022]    Loss: 0.005743   Batch Acc: 87.50
[Train] Epoch: 3 [7936/620022]    Loss: 0.009304   Batch Acc: 75.00
[Train] Epoch: 3 [8000/620022]    Loss: 0.007804   Batch Acc: 78.12
[Train] Epoch: 3 [8064/620022]    Loss: 0.009021   Batch Acc: 75.00
[Train] Epoch: 3 [8128/620022]    Loss: 0.008837   Batch Acc: 79.69
[Train] Epoch: 3 [8192/620022]    Loss: 0.006932   Batch Acc: 85.94
[Train] Epoch: 3 [8256/620022]    Loss: 0.009967   Batch Acc: 76.56
[Train] Epoch: 3 [8320/620022]    Loss: 0.009007   Batch Acc: 75.00
[Train] Epoch: 3 [8384/620022]    Loss: 0.008198   Batch Acc: 82.81
[Train] Epoch: 3 [8448/620022]    Loss: 0.008299   Batch Acc: 79.69
[Train] Epoch: 3 [8512/620022]    Loss: 0.006634   Batch Acc: 84.38
[Train] Epoch: 3 [8576/620022]    Loss: 0.007542   Batch Acc: 81.25
[Train] Epoch: 3 [8640/620022]    Loss: 0.007311   Batch Acc: 85.94
[Train] Epoch: 3 [8704/620022]    Loss: 0.008687   Batch Acc: 76.56
[Train] Epoch: 3 [8768/620022]    Loss: 0.007503   Batch Acc: 79.69
[Train] Epoch: 3 [8832/620022]    Loss: 0.010365   Batch Acc: 62.50
[Train] Epoch: 3 [8896/620022]    Loss: 0.006680   Batch Acc: 81.25
[Train] Epoch: 3 [8960/620022]    Loss: 0.008638   Batch Acc: 79.69
[Train] Epoch: 3 [9024/620022]    Loss: 0.008060   Batch Acc: 79.69
[Train] Epoch: 3 [9088/620022]    Loss: 0.008494   Batch Acc: 73.44
[Train] Epoch: 3 [9152/620022]    Loss: 0.008177   Batch Acc: 76.56
[Train] Epoch: 3 [9216/620022]    Loss: 0.007175   Batch Acc: 82.81
[Train] Epoch: 3 [9280/620022]    Loss: 0.010821   Batch Acc: 78.12
[Train] Epoch: 3 [9344/620022]    Loss: 0.006466   Batch Acc: 85.94
[Train] Epoch: 3 [9408/620022]    Loss: 0.006101   Batch Acc: 84.38
[Train] Epoch: 3 [9472/620022]    Loss: 0.007475   Batch Acc: 76.56
[Train] Epoch: 3 [9536/620022]    Loss: 0.008850   Batch Acc: 78.12
[Train] Epoch: 3 [9600/620022]    Loss: 0.007965   Batch Acc: 73.44
[Train] Epoch: 3 [9664/620022]    Loss: 0.008253   Batch Acc: 78.12
[Train] Epoch: 3 [9728/620022]    Loss: 0.008293   Batch Acc: 81.25
[Train] Epoch: 3 [9792/620022]    Loss: 0.010184   Batch Acc: 68.75
[Train] Epoch: 3 [9856/620022]    Loss: 0.007218   Batch Acc: 79.69
[Train] Epoch: 3 [9920/620022]    Loss: 0.009427   Batch Acc: 78.12
[Train] Epoch: 3 [9984/620022]    Loss: 0.008891   Batch Acc: 78.12
[Train] Epoch: 3 [10048/620022]    Loss: 0.009129   Batch Acc: 75.00
[Train] Epoch: 3 [10112/620022]    Loss: 0.009008   Batch Acc: 75.00
[Train] Epoch: 3 [10176/620022]    Loss: 0.009699   Batch Acc: 70.31
[Train] Epoch: 3 [10240/620022]    Loss: 0.007971   Batch Acc: 81.25
[Train] Epoch: 3 [10304/620022]    Loss: 0.006572   Batch Acc: 85.94
[Train] Epoch: 3 [10368/620022]    Loss: 0.007859   Batch Acc: 78.12
[Train] Epoch: 3 [10432/620022]    Loss: 0.010118   Batch Acc: 75.00
[Train] Epoch: 3 [10496/620022]    Loss: 0.008810   Batch Acc: 73.44
[Train] Epoch: 3 [10560/620022]    Loss: 0.011151   Batch Acc: 68.75
[Train] Epoch: 3 [10624/620022]    Loss: 0.008944   Batch Acc: 75.00
[Train] Epoch: 3 [10688/620022]    Loss: 0.008971   Batch Acc: 78.12
[Train] Epoch: 3 [10752/620022]    Loss: 0.007156   Batch Acc: 79.69
[Train] Epoch: 3 [10816/620022]    Loss: 0.009073   Batch Acc: 71.88
[Train] Epoch: 3 [10880/620022]    Loss: 0.006504   Batch Acc: 85.94
[Train] Epoch: 3 [10944/620022]    Loss: 0.007498   Batch Acc: 78.12
[Train] Epoch: 3 [11008/620022]    Loss: 0.006184   Batch Acc: 85.94
[Train] Epoch: 3 [11072/620022]    Loss: 0.007658   Batch Acc: 78.12
[Train] Epoch: 3 [11136/620022]    Loss: 0.006913   Batch Acc: 78.12
[Train] Epoch: 3 [11200/620022]    Loss: 0.007460   Batch Acc: 84.38
[Train] Epoch: 3 [11264/620022]    Loss: 0.009678   Batch Acc: 75.00
[Train] Epoch: 3 [11328/620022]    Loss: 0.007128   Batch Acc: 85.94
[Train] Epoch: 3 [11392/620022]    Loss: 0.009651   Batch Acc: 76.56
[Train] Epoch: 3 [11456/620022]    Loss: 0.008460   Batch Acc: 78.12
[Train] Epoch: 3 [11520/620022]    Loss: 0.007885   Batch Acc: 81.25
[Train] Epoch: 3 [11584/620022]    Loss: 0.009588   Batch Acc: 75.00
[Train] Epoch: 3 [11648/620022]    Loss: 0.007557   Batch Acc: 82.81
[Train] Epoch: 3 [11712/620022]    Loss: 0.008828   Batch Acc: 76.56
[Train] Epoch: 3 [11776/620022]    Loss: 0.006153   Batch Acc: 89.06
[Train] Epoch: 3 [11840/620022]    Loss: 0.007042   Batch Acc: 85.94
[Train] Epoch: 3 [11904/620022]    Loss: 0.008920   Batch Acc: 73.44
[Train] Epoch: 3 [11968/620022]    Loss: 0.007858   Batch Acc: 76.56
[Train] Epoch: 3 [12032/620022]    Loss: 0.008637   Batch Acc: 79.69
[Train] Epoch: 3 [12096/620022]    Loss: 0.008651   Batch Acc: 73.44
[Train] Epoch: 3 [12160/620022]    Loss: 0.011798   Batch Acc: 68.75
[Train] Epoch: 3 [12224/620022]    Loss: 0.007492   Batch Acc: 78.12
[Train] Epoch: 3 [12288/620022]    Loss: 0.007604   Batch Acc: 78.12
[Train] Epoch: 3 [12352/620022]    Loss: 0.011165   Batch Acc: 70.31
[Train] Epoch: 3 [12416/620022]    Loss: 0.007639   Batch Acc: 81.25
[Train] Epoch: 3 [12480/620022]    Loss: 0.007598   Batch Acc: 82.81
[Train] Epoch: 3 [12544/620022]    Loss: 0.010395   Batch Acc: 73.44
[Train] Epoch: 3 [12608/620022]    Loss: 0.009342   Batch Acc: 71.88
[Train] Epoch: 3 [12672/620022]    Loss: 0.010178   Batch Acc: 79.69
[Train] Epoch: 3 [12736/620022]    Loss: 0.008396   Batch Acc: 73.44
[Train] Epoch: 3 [12800/620022]    Loss: 0.007553   Batch Acc: 84.38
[Train] Epoch: 3 [12864/620022]    Loss: 0.008369   Batch Acc: 76.56
[Train] Epoch: 3 [12928/620022]    Loss: 0.008440   Batch Acc: 79.69
[Train] Epoch: 3 [12992/620022]    Loss: 0.008439   Batch Acc: 82.81
[Train] Epoch: 3 [13056/620022]    Loss: 0.010648   Batch Acc: 75.00
[Train] Epoch: 3 [13120/620022]    Loss: 0.007255   Batch Acc: 78.12
[Train] Epoch: 3 [13184/620022]    Loss: 0.008657   Batch Acc: 82.81
[Train] Epoch: 3 [13248/620022]    Loss: 0.010572   Batch Acc: 75.00
[Train] Epoch: 3 [13312/620022]    Loss: 0.010228   Batch Acc: 70.31
[Train] Epoch: 3 [13376/620022]    Loss: 0.007068   Batch Acc: 85.94
[Train] Epoch: 3 [13440/620022]    Loss: 0.007297   Batch Acc: 82.81
[Train] Epoch: 3 [13504/620022]    Loss: 0.008152   Batch Acc: 81.25
[Train] Epoch: 3 [13568/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 3 [13632/620022]    Loss: 0.008156   Batch Acc: 76.56
[Train] Epoch: 3 [13696/620022]    Loss: 0.007361   Batch Acc: 81.25
[Train] Epoch: 3 [13760/620022]    Loss: 0.006950   Batch Acc: 76.56
[Train] Epoch: 3 [13824/620022]    Loss: 0.008923   Batch Acc: 75.00
[Train] Epoch: 3 [13888/620022]    Loss: 0.008062   Batch Acc: 81.25
[Train] Epoch: 3 [13952/620022]    Loss: 0.009693   Batch Acc: 70.31
[Train] Epoch: 3 [14016/620022]    Loss: 0.008070   Batch Acc: 71.88
[Train] Epoch: 3 [14080/620022]    Loss: 0.008169   Batch Acc: 78.12
[Train] Epoch: 3 [14144/620022]    Loss: 0.007443   Batch Acc: 79.69
[Train] Epoch: 3 [14208/620022]    Loss: 0.007801   Batch Acc: 79.69
[Train] Epoch: 3 [14272/620022]    Loss: 0.009498   Batch Acc: 73.44
[Train] Epoch: 3 [14336/620022]    Loss: 0.009579   Batch Acc: 71.88
[Train] Epoch: 3 [14400/620022]    Loss: 0.005577   Batch Acc: 92.19
[Train] Epoch: 3 [14464/620022]    Loss: 0.009112   Batch Acc: 71.88
[Train] Epoch: 3 [14528/620022]    Loss: 0.007095   Batch Acc: 85.94
[Train] Epoch: 3 [14592/620022]    Loss: 0.009772   Batch Acc: 76.56
[Train] Epoch: 3 [14656/620022]    Loss: 0.009763   Batch Acc: 71.88
[Train] Epoch: 3 [14720/620022]    Loss: 0.007606   Batch Acc: 82.81
[Train] Epoch: 3 [14784/620022]    Loss: 0.009954   Batch Acc: 76.56
[Train] Epoch: 3 [14848/620022]    Loss: 0.010293   Batch Acc: 78.12
[Train] Epoch: 3 [14912/620022]    Loss: 0.006724   Batch Acc: 82.81
[Train] Epoch: 3 [14976/620022]    Loss: 0.007478   Batch Acc: 84.38
[Train] Epoch: 3 [15040/620022]    Loss: 0.009365   Batch Acc: 75.00
[Train] Epoch: 3 [15104/620022]    Loss: 0.007233   Batch Acc: 81.25
[Train] Epoch: 3 [15168/620022]    Loss: 0.009623   Batch Acc: 76.56
[Train] Epoch: 3 [15232/620022]    Loss: 0.006078   Batch Acc: 84.38
[Train] Epoch: 3 [15296/620022]    Loss: 0.011813   Batch Acc: 64.06
[Train] Epoch: 3 [15360/620022]    Loss: 0.009127   Batch Acc: 76.56
[Train] Epoch: 3 [15424/620022]    Loss: 0.009047   Batch Acc: 75.00
[Train] Epoch: 3 [15488/620022]    Loss: 0.007218   Batch Acc: 79.69
[Train] Epoch: 3 [15552/620022]    Loss: 0.007930   Batch Acc: 79.69
[Train] Epoch: 3 [15616/620022]    Loss: 0.006977   Batch Acc: 76.56
[Train] Epoch: 3 [15680/620022]    Loss: 0.009806   Batch Acc: 73.44
[Train] Epoch: 3 [15744/620022]    Loss: 0.009610   Batch Acc: 70.31
[Train] Epoch: 3 [15808/620022]    Loss: 0.009202   Batch Acc: 75.00
[Train] Epoch: 3 [15872/620022]    Loss: 0.008462   Batch Acc: 76.56
[Train] Epoch: 3 [15936/620022]    Loss: 0.008581   Batch Acc: 76.56
[Train] Epoch: 3 [16000/620022]    Loss: 0.008457   Batch Acc: 75.00
[Train] Epoch: 3 [16064/620022]    Loss: 0.006059   Batch Acc: 87.50
[Train] Epoch: 3 [16128/620022]    Loss: 0.008489   Batch Acc: 78.12
[Train] Epoch: 3 [16192/620022]    Loss: 0.008826   Batch Acc: 75.00
[Train] Epoch: 3 [16256/620022]    Loss: 0.008467   Batch Acc: 79.69
[Train] Epoch: 3 [16320/620022]    Loss: 0.008791   Batch Acc: 79.69
[Train] Epoch: 3 [16384/620022]    Loss: 0.008664   Batch Acc: 78.12
[Train] Epoch: 3 [16448/620022]    Loss: 0.009956   Batch Acc: 68.75
[Train] Epoch: 3 [16512/620022]    Loss: 0.007126   Batch Acc: 79.69
[Train] Epoch: 3 [16576/620022]    Loss: 0.009072   Batch Acc: 76.56
[Train] Epoch: 3 [16640/620022]    Loss: 0.010068   Batch Acc: 75.00
[Train] Epoch: 3 [16704/620022]    Loss: 0.009678   Batch Acc: 70.31
[Train] Epoch: 3 [16768/620022]    Loss: 0.009798   Batch Acc: 79.69
[Train] Epoch: 3 [16832/620022]    Loss: 0.008934   Batch Acc: 70.31
[Train] Epoch: 3 [16896/620022]    Loss: 0.007693   Batch Acc: 79.69
[Train] Epoch: 3 [16960/620022]    Loss: 0.006960   Batch Acc: 85.94
[Train] Epoch: 3 [17024/620022]    Loss: 0.009578   Batch Acc: 75.00
[Train] Epoch: 3 [17088/620022]    Loss: 0.007797   Batch Acc: 79.69
[Train] Epoch: 3 [17152/620022]    Loss: 0.012369   Batch Acc: 64.06
[Train] Epoch: 3 [17216/620022]    Loss: 0.010031   Batch Acc: 76.56
[Train] Epoch: 3 [17280/620022]    Loss: 0.006420   Batch Acc: 84.38
[Train] Epoch: 3 [17344/620022]    Loss: 0.009213   Batch Acc: 79.69
[Train] Epoch: 3 [17408/620022]    Loss: 0.012523   Batch Acc: 67.19
[Train] Epoch: 3 [17472/620022]    Loss: 0.009651   Batch Acc: 75.00
[Train] Epoch: 3 [17536/620022]    Loss: 0.007174   Batch Acc: 84.38
[Train] Epoch: 3 [17600/620022]    Loss: 0.009206   Batch Acc: 81.25
[Train] Epoch: 3 [17664/620022]    Loss: 0.008593   Batch Acc: 75.00
[Train] Epoch: 3 [17728/620022]    Loss: 0.008333   Batch Acc: 79.69
[Train] Epoch: 3 [17792/620022]    Loss: 0.009417   Batch Acc: 78.12
[Train] Epoch: 3 [17856/620022]    Loss: 0.009725   Batch Acc: 75.00
[Train] Epoch: 3 [17920/620022]    Loss: 0.006970   Batch Acc: 85.94
[Train] Epoch: 3 [17984/620022]    Loss: 0.009196   Batch Acc: 76.56
[Train] Epoch: 3 [18048/620022]    Loss: 0.007708   Batch Acc: 78.12
[Train] Epoch: 3 [18112/620022]    Loss: 0.009158   Batch Acc: 75.00
[Train] Epoch: 3 [18176/620022]    Loss: 0.009162   Batch Acc: 73.44
[Train] Epoch: 3 [18240/620022]    Loss: 0.010527   Batch Acc: 76.56
[Train] Epoch: 3 [18304/620022]    Loss: 0.008084   Batch Acc: 76.56
[Train] Epoch: 3 [18368/620022]    Loss: 0.007996   Batch Acc: 81.25
[Train] Epoch: 3 [18432/620022]    Loss: 0.011012   Batch Acc: 70.31
[Train] Epoch: 3 [18496/620022]    Loss: 0.006709   Batch Acc: 84.38
[Train] Epoch: 3 [18560/620022]    Loss: 0.009219   Batch Acc: 76.56
[Train] Epoch: 3 [18624/620022]    Loss: 0.008161   Batch Acc: 79.69
[Train] Epoch: 3 [18688/620022]    Loss: 0.010793   Batch Acc: 73.44
[Train] Epoch: 3 [18752/620022]    Loss: 0.008399   Batch Acc: 75.00
[Train] Epoch: 3 [18816/620022]    Loss: 0.007794   Batch Acc: 76.56
[Train] Epoch: 3 [18880/620022]    Loss: 0.008971   Batch Acc: 79.69
[Train] Epoch: 3 [18944/620022]    Loss: 0.008416   Batch Acc: 85.94
[Train] Epoch: 3 [19008/620022]    Loss: 0.006439   Batch Acc: 87.50
[Train] Epoch: 3 [19072/620022]    Loss: 0.006634   Batch Acc: 82.81
[Train] Epoch: 3 [19136/620022]    Loss: 0.008626   Batch Acc: 76.56
[Train] Epoch: 3 [19200/620022]    Loss: 0.006166   Batch Acc: 85.94
[Train] Epoch: 3 [19264/620022]    Loss: 0.008299   Batch Acc: 78.12
[Train] Epoch: 3 [19328/620022]    Loss: 0.010873   Batch Acc: 71.88
[Train] Epoch: 3 [19392/620022]    Loss: 0.009830   Batch Acc: 75.00
[Train] Epoch: 3 [19456/620022]    Loss: 0.008896   Batch Acc: 78.12
[Train] Epoch: 3 [19520/620022]    Loss: 0.006125   Batch Acc: 85.94
[Train] Epoch: 3 [19584/620022]    Loss: 0.008520   Batch Acc: 81.25
[Train] Epoch: 3 [19648/620022]    Loss: 0.007176   Batch Acc: 84.38
[Train] Epoch: 3 [19712/620022]    Loss: 0.010344   Batch Acc: 68.75
[Train] Epoch: 3 [19776/620022]    Loss: 0.008398   Batch Acc: 73.44
[Train] Epoch: 3 [19840/620022]    Loss: 0.009263   Batch Acc: 76.56
[Train] Epoch: 3 [19904/620022]    Loss: 0.008730   Batch Acc: 78.12
[Train] Epoch: 3 [19968/620022]    Loss: 0.008447   Batch Acc: 79.69
[Train] Epoch: 3 [20032/620022]    Loss: 0.008282   Batch Acc: 73.44
[Train] Epoch: 3 [20096/620022]    Loss: 0.008800   Batch Acc: 79.69
[Train] Epoch: 3 [20160/620022]    Loss: 0.007511   Batch Acc: 82.81
[Train] Epoch: 3 [20224/620022]    Loss: 0.010400   Batch Acc: 68.75
[Train] Epoch: 3 [20288/620022]    Loss: 0.007460   Batch Acc: 81.25
[Train] Epoch: 3 [20352/620022]    Loss: 0.007015   Batch Acc: 89.06
[Train] Epoch: 3 [20416/620022]    Loss: 0.006257   Batch Acc: 90.62
[Train] Epoch: 3 [20480/620022]    Loss: 0.009280   Batch Acc: 75.00
[Train] Epoch: 3 [20544/620022]    Loss: 0.009823   Batch Acc: 73.44
[Train] Epoch: 3 [20608/620022]    Loss: 0.009580   Batch Acc: 68.75
[Train] Epoch: 3 [20672/620022]    Loss: 0.008416   Batch Acc: 81.25
[Train] Epoch: 3 [20736/620022]    Loss: 0.009344   Batch Acc: 73.44
[Train] Epoch: 3 [20800/620022]    Loss: 0.008890   Batch Acc: 71.88
[Train] Epoch: 3 [20864/620022]    Loss: 0.009142   Batch Acc: 76.56
[Train] Epoch: 3 [20928/620022]    Loss: 0.007350   Batch Acc: 84.38
[Train] Epoch: 3 [20992/620022]    Loss: 0.011305   Batch Acc: 68.75
[Train] Epoch: 3 [21056/620022]    Loss: 0.008023   Batch Acc: 79.69
[Train] Epoch: 3 [21120/620022]    Loss: 0.007163   Batch Acc: 79.69
[Train] Epoch: 3 [21184/620022]    Loss: 0.010077   Batch Acc: 73.44
[Train] Epoch: 3 [21248/620022]    Loss: 0.006832   Batch Acc: 84.38
[Train] Epoch: 3 [21312/620022]    Loss: 0.009089   Batch Acc: 75.00
[Train] Epoch: 3 [21376/620022]    Loss: 0.007068   Batch Acc: 81.25
[Train] Epoch: 3 [21440/620022]    Loss: 0.008397   Batch Acc: 81.25
[Train] Epoch: 3 [21504/620022]    Loss: 0.008778   Batch Acc: 76.56
[Train] Epoch: 3 [21568/620022]    Loss: 0.009395   Batch Acc: 76.56
[Train] Epoch: 3 [21632/620022]    Loss: 0.007063   Batch Acc: 82.81
[Train] Epoch: 3 [21696/620022]    Loss: 0.008001   Batch Acc: 81.25
[Train] Epoch: 3 [21760/620022]    Loss: 0.008167   Batch Acc: 79.69
[Train] Epoch: 3 [21824/620022]    Loss: 0.009472   Batch Acc: 81.25
[Train] Epoch: 3 [21888/620022]    Loss: 0.009997   Batch Acc: 79.69
[Train] Epoch: 3 [21952/620022]    Loss: 0.008020   Batch Acc: 79.69
[Train] Epoch: 3 [22016/620022]    Loss: 0.007411   Batch Acc: 84.38
[Train] Epoch: 3 [22080/620022]    Loss: 0.008096   Batch Acc: 76.56
[Train] Epoch: 3 [22144/620022]    Loss: 0.010607   Batch Acc: 67.19
[Train] Epoch: 3 [22208/620022]    Loss: 0.008982   Batch Acc: 73.44
[Train] Epoch: 3 [22272/620022]    Loss: 0.008997   Batch Acc: 73.44
[Train] Epoch: 3 [22336/620022]    Loss: 0.009701   Batch Acc: 71.88
[Train] Epoch: 3 [22400/620022]    Loss: 0.007016   Batch Acc: 85.94
[Train] Epoch: 3 [22464/620022]    Loss: 0.008594   Batch Acc: 76.56
[Train] Epoch: 3 [22528/620022]    Loss: 0.007274   Batch Acc: 85.94
[Train] Epoch: 3 [22592/620022]    Loss: 0.008701   Batch Acc: 75.00
[Train] Epoch: 3 [22656/620022]    Loss: 0.009843   Batch Acc: 73.44
[Train] Epoch: 3 [22720/620022]    Loss: 0.009658   Batch Acc: 73.44
[Train] Epoch: 3 [22784/620022]    Loss: 0.009384   Batch Acc: 76.56
[Train] Epoch: 3 [22848/620022]    Loss: 0.008280   Batch Acc: 73.44
[Train] Epoch: 3 [22912/620022]    Loss: 0.010177   Batch Acc: 75.00
[Train] Epoch: 3 [22976/620022]    Loss: 0.010814   Batch Acc: 70.31
[Train] Epoch: 3 [23040/620022]    Loss: 0.010559   Batch Acc: 78.12
[Train] Epoch: 3 [23104/620022]    Loss: 0.009702   Batch Acc: 68.75
[Train] Epoch: 3 [23168/620022]    Loss: 0.010663   Batch Acc: 68.75
[Train] Epoch: 3 [23232/620022]    Loss: 0.006613   Batch Acc: 82.81
[Train] Epoch: 3 [23296/620022]    Loss: 0.006527   Batch Acc: 79.69
[Train] Epoch: 3 [23360/620022]    Loss: 0.010281   Batch Acc: 75.00
[Train] Epoch: 3 [23424/620022]    Loss: 0.007938   Batch Acc: 78.12
[Train] Epoch: 3 [23488/620022]    Loss: 0.009127   Batch Acc: 78.12
[Train] Epoch: 3 [23552/620022]    Loss: 0.007082   Batch Acc: 84.38
[Train] Epoch: 3 [23616/620022]    Loss: 0.007739   Batch Acc: 81.25
[Train] Epoch: 3 [23680/620022]    Loss: 0.009808   Batch Acc: 78.12
[Train] Epoch: 3 [23744/620022]    Loss: 0.007473   Batch Acc: 81.25
[Train] Epoch: 3 [23808/620022]    Loss: 0.007213   Batch Acc: 82.81
[Train] Epoch: 3 [23872/620022]    Loss: 0.007872   Batch Acc: 79.69
[Train] Epoch: 3 [23936/620022]    Loss: 0.008650   Batch Acc: 84.38
[Train] Epoch: 3 [24000/620022]    Loss: 0.009914   Batch Acc: 78.12
[Train] Epoch: 3 [24064/620022]    Loss: 0.005970   Batch Acc: 82.81
[Train] Epoch: 3 [24128/620022]    Loss: 0.007095   Batch Acc: 84.38
[Train] Epoch: 3 [24192/620022]    Loss: 0.006800   Batch Acc: 79.69
[Train] Epoch: 3 [24256/620022]    Loss: 0.006580   Batch Acc: 85.94
[Train] Epoch: 3 [24320/620022]    Loss: 0.010365   Batch Acc: 73.44
[Train] Epoch: 3 [24384/620022]    Loss: 0.007544   Batch Acc: 81.25
[Train] Epoch: 3 [24448/620022]    Loss: 0.009522   Batch Acc: 70.31
[Train] Epoch: 3 [24512/620022]    Loss: 0.007327   Batch Acc: 82.81
[Train] Epoch: 3 [24576/620022]    Loss: 0.007737   Batch Acc: 82.81
[Train] Epoch: 3 [24640/620022]    Loss: 0.009455   Batch Acc: 75.00
[Train] Epoch: 3 [24704/620022]    Loss: 0.007371   Batch Acc: 81.25
[Train] Epoch: 3 [24768/620022]    Loss: 0.009212   Batch Acc: 81.25
[Train] Epoch: 3 [24832/620022]    Loss: 0.009504   Batch Acc: 76.56
[Train] Epoch: 3 [24896/620022]    Loss: 0.008732   Batch Acc: 82.81
[Train] Epoch: 3 [24960/620022]    Loss: 0.009007   Batch Acc: 75.00
[Train] Epoch: 3 [25024/620022]    Loss: 0.010600   Batch Acc: 71.88
[Train] Epoch: 3 [25088/620022]    Loss: 0.010022   Batch Acc: 71.88
[Train] Epoch: 3 [25152/620022]    Loss: 0.008635   Batch Acc: 82.81
[Train] Epoch: 3 [25216/620022]    Loss: 0.007383   Batch Acc: 82.81
[Train] Epoch: 3 [25280/620022]    Loss: 0.008078   Batch Acc: 73.44
[Train] Epoch: 3 [25344/620022]    Loss: 0.007856   Batch Acc: 82.81
[Train] Epoch: 3 [25408/620022]    Loss: 0.008177   Batch Acc: 87.50
[Train] Epoch: 3 [25472/620022]    Loss: 0.008067   Batch Acc: 79.69
[Train] Epoch: 3 [25536/620022]    Loss: 0.009929   Batch Acc: 75.00
[Train] Epoch: 3 [25600/620022]    Loss: 0.007379   Batch Acc: 81.25
[Train] Epoch: 3 [25664/620022]    Loss: 0.007950   Batch Acc: 73.44
[Train] Epoch: 3 [25728/620022]    Loss: 0.006291   Batch Acc: 81.25
[Train] Epoch: 3 [25792/620022]    Loss: 0.008957   Batch Acc: 79.69
[Train] Epoch: 3 [25856/620022]    Loss: 0.009243   Batch Acc: 75.00
[Train] Epoch: 3 [25920/620022]    Loss: 0.009105   Batch Acc: 82.81
[Train] Epoch: 3 [25984/620022]    Loss: 0.009292   Batch Acc: 78.12
[Train] Epoch: 3 [26048/620022]    Loss: 0.009392   Batch Acc: 79.69
[Train] Epoch: 3 [26112/620022]    Loss: 0.009346   Batch Acc: 78.12
[Train] Epoch: 3 [26176/620022]    Loss: 0.007734   Batch Acc: 79.69
[Train] Epoch: 3 [26240/620022]    Loss: 0.009645   Batch Acc: 78.12
[Train] Epoch: 3 [26304/620022]    Loss: 0.008325   Batch Acc: 75.00
[Train] Epoch: 3 [26368/620022]    Loss: 0.007211   Batch Acc: 82.81
[Train] Epoch: 3 [26432/620022]    Loss: 0.006915   Batch Acc: 85.94
[Train] Epoch: 3 [26496/620022]    Loss: 0.009183   Batch Acc: 78.12
[Train] Epoch: 3 [26560/620022]    Loss: 0.008759   Batch Acc: 78.12
[Train] Epoch: 3 [26624/620022]    Loss: 0.009274   Batch Acc: 79.69
[Train] Epoch: 3 [26688/620022]    Loss: 0.008243   Batch Acc: 78.12
[Train] Epoch: 3 [26752/620022]    Loss: 0.008787   Batch Acc: 78.12
[Train] Epoch: 3 [26816/620022]    Loss: 0.010526   Batch Acc: 70.31
[Train] Epoch: 3 [26880/620022]    Loss: 0.009304   Batch Acc: 78.12
[Train] Epoch: 3 [26944/620022]    Loss: 0.011032   Batch Acc: 64.06
[Train] Epoch: 3 [27008/620022]    Loss: 0.008193   Batch Acc: 81.25
[Train] Epoch: 3 [27072/620022]    Loss: 0.008271   Batch Acc: 79.69
[Train] Epoch: 3 [27136/620022]    Loss: 0.009573   Batch Acc: 71.88
[Train] Epoch: 3 [27200/620022]    Loss: 0.009696   Batch Acc: 75.00
[Train] Epoch: 3 [27264/620022]    Loss: 0.008883   Batch Acc: 79.69
[Train] Epoch: 3 [27328/620022]    Loss: 0.008320   Batch Acc: 78.12
[Train] Epoch: 3 [27392/620022]    Loss: 0.008545   Batch Acc: 76.56
[Train] Epoch: 3 [27456/620022]    Loss: 0.008279   Batch Acc: 76.56
[Train] Epoch: 3 [27520/620022]    Loss: 0.007686   Batch Acc: 85.94
[Train] Epoch: 3 [27584/620022]    Loss: 0.008345   Batch Acc: 79.69
[Train] Epoch: 3 [27648/620022]    Loss: 0.010622   Batch Acc: 70.31
[Train] Epoch: 3 [27712/620022]    Loss: 0.009159   Batch Acc: 78.12
[Train] Epoch: 3 [27776/620022]    Loss: 0.008663   Batch Acc: 76.56
[Train] Epoch: 3 [27840/620022]    Loss: 0.008130   Batch Acc: 84.38
[Train] Epoch: 3 [27904/620022]    Loss: 0.009411   Batch Acc: 81.25
[Train] Epoch: 3 [27968/620022]    Loss: 0.009207   Batch Acc: 71.88
[Train] Epoch: 3 [28032/620022]    Loss: 0.009332   Batch Acc: 75.00
[Train] Epoch: 3 [28096/620022]    Loss: 0.007720   Batch Acc: 78.12
[Train] Epoch: 3 [28160/620022]    Loss: 0.008598   Batch Acc: 76.56
[Train] Epoch: 3 [28224/620022]    Loss: 0.009592   Batch Acc: 71.88
[Train] Epoch: 3 [28288/620022]    Loss: 0.011151   Batch Acc: 70.31
[Train] Epoch: 3 [28352/620022]    Loss: 0.007732   Batch Acc: 82.81
[Train] Epoch: 3 [28416/620022]    Loss: 0.009512   Batch Acc: 79.69
[Train] Epoch: 3 [28480/620022]    Loss: 0.008357   Batch Acc: 76.56
[Train] Epoch: 3 [28544/620022]    Loss: 0.009883   Batch Acc: 70.31
[Train] Epoch: 3 [28608/620022]    Loss: 0.009072   Batch Acc: 79.69
[Train] Epoch: 3 [28672/620022]    Loss: 0.010208   Batch Acc: 75.00
[Train] Epoch: 3 [28736/620022]    Loss: 0.005803   Batch Acc: 89.06
[Train] Epoch: 3 [28800/620022]    Loss: 0.010635   Batch Acc: 73.44
[Train] Epoch: 3 [28864/620022]    Loss: 0.009675   Batch Acc: 71.88
[Train] Epoch: 3 [28928/620022]    Loss: 0.007884   Batch Acc: 78.12
[Train] Epoch: 3 [28992/620022]    Loss: 0.011145   Batch Acc: 73.44
[Train] Epoch: 3 [29056/620022]    Loss: 0.010074   Batch Acc: 70.31
[Train] Epoch: 3 [29120/620022]    Loss: 0.008144   Batch Acc: 78.12
[Train] Epoch: 3 [29184/620022]    Loss: 0.010100   Batch Acc: 73.44
[Train] Epoch: 3 [29248/620022]    Loss: 0.006608   Batch Acc: 81.25
[Train] Epoch: 3 [29312/620022]    Loss: 0.007003   Batch Acc: 84.38
[Train] Epoch: 3 [29376/620022]    Loss: 0.006732   Batch Acc: 81.25
[Train] Epoch: 3 [29440/620022]    Loss: 0.008163   Batch Acc: 84.38
[Train] Epoch: 3 [29504/620022]    Loss: 0.007531   Batch Acc: 79.69
[Train] Epoch: 3 [29568/620022]    Loss: 0.007909   Batch Acc: 78.12
[Train] Epoch: 3 [29632/620022]    Loss: 0.010926   Batch Acc: 68.75
[Train] Epoch: 3 [29696/620022]    Loss: 0.009443   Batch Acc: 73.44
[Train] Epoch: 3 [29760/620022]    Loss: 0.006464   Batch Acc: 87.50
[Train] Epoch: 3 [29824/620022]    Loss: 0.007252   Batch Acc: 81.25
[Train] Epoch: 3 [29888/620022]    Loss: 0.007543   Batch Acc: 84.38
[Train] Epoch: 3 [29952/620022]    Loss: 0.009137   Batch Acc: 73.44
[Train] Epoch: 3 [30016/620022]    Loss: 0.009915   Batch Acc: 67.19
[Train] Epoch: 3 [30080/620022]    Loss: 0.007070   Batch Acc: 82.81
[Train] Epoch: 3 [30144/620022]    Loss: 0.008500   Batch Acc: 82.81
[Train] Epoch: 3 [30208/620022]    Loss: 0.008314   Batch Acc: 78.12
[Train] Epoch: 3 [30272/620022]    Loss: 0.011220   Batch Acc: 68.75
[Train] Epoch: 3 [30336/620022]    Loss: 0.006597   Batch Acc: 82.81
[Train] Epoch: 3 [30400/620022]    Loss: 0.008798   Batch Acc: 73.44
[Train] Epoch: 3 [30464/620022]    Loss: 0.008414   Batch Acc: 75.00
[Train] Epoch: 3 [30528/620022]    Loss: 0.008504   Batch Acc: 78.12
[Train] Epoch: 3 [30592/620022]    Loss: 0.008031   Batch Acc: 79.69
[Train] Epoch: 3 [30656/620022]    Loss: 0.008620   Batch Acc: 73.44
[Train] Epoch: 3 [30720/620022]    Loss: 0.008636   Batch Acc: 76.56
[Train] Epoch: 3 [30784/620022]    Loss: 0.008709   Batch Acc: 78.12
[Train] Epoch: 3 [30848/620022]    Loss: 0.009677   Batch Acc: 67.19
[Train] Epoch: 3 [30912/620022]    Loss: 0.008059   Batch Acc: 79.69
[Train] Epoch: 3 [30976/620022]    Loss: 0.007089   Batch Acc: 82.81
[Train] Epoch: 3 [31040/620022]    Loss: 0.009887   Batch Acc: 70.31
[Train] Epoch: 3 [31104/620022]    Loss: 0.009040   Batch Acc: 70.31
[Train] Epoch: 3 [31168/620022]    Loss: 0.007760   Batch Acc: 81.25
[Train] Epoch: 3 [31232/620022]    Loss: 0.009584   Batch Acc: 71.88
[Train] Epoch: 3 [31296/620022]    Loss: 0.006932   Batch Acc: 81.25
[Train] Epoch: 3 [31360/620022]    Loss: 0.007615   Batch Acc: 87.50
[Train] Epoch: 3 [31424/620022]    Loss: 0.008720   Batch Acc: 84.38
[Train] Epoch: 3 [31488/620022]    Loss: 0.006938   Batch Acc: 84.38
[Train] Epoch: 3 [31552/620022]    Loss: 0.007186   Batch Acc: 82.81
[Train] Epoch: 3 [31616/620022]    Loss: 0.008276   Batch Acc: 79.69
[Train] Epoch: 3 [31680/620022]    Loss: 0.007635   Batch Acc: 76.56
[Train] Epoch: 3 [31744/620022]    Loss: 0.007641   Batch Acc: 81.25
[Train] Epoch: 3 [31808/620022]    Loss: 0.007205   Batch Acc: 84.38
[Train] Epoch: 3 [31872/620022]    Loss: 0.008160   Batch Acc: 82.81
[Train] Epoch: 3 [31936/620022]    Loss: 0.010131   Batch Acc: 68.75
[Train] Epoch: 3 [32000/620022]    Loss: 0.008449   Batch Acc: 78.12
[Train] Epoch: 3 [32064/620022]    Loss: 0.007289   Batch Acc: 81.25
[Train] Epoch: 3 [32128/620022]    Loss: 0.008965   Batch Acc: 73.44
[Train] Epoch: 3 [32192/620022]    Loss: 0.009829   Batch Acc: 71.88
[Train] Epoch: 3 [32256/620022]    Loss: 0.008713   Batch Acc: 81.25
[Train] Epoch: 3 [32320/620022]    Loss: 0.008589   Batch Acc: 75.00
[Train] Epoch: 3 [32384/620022]    Loss: 0.009216   Batch Acc: 71.88
[Train] Epoch: 3 [32448/620022]    Loss: 0.007816   Batch Acc: 81.25
[Train] Epoch: 3 [32512/620022]    Loss: 0.008100   Batch Acc: 79.69
[Train] Epoch: 3 [32576/620022]    Loss: 0.006433   Batch Acc: 89.06
[Train] Epoch: 3 [32640/620022]    Loss: 0.007815   Batch Acc: 79.69
[Train] Epoch: 3 [32704/620022]    Loss: 0.010364   Batch Acc: 71.88
[Train] Epoch: 3 [32768/620022]    Loss: 0.008475   Batch Acc: 76.56
[Train] Epoch: 3 [32832/620022]    Loss: 0.007448   Batch Acc: 79.69
[Train] Epoch: 3 [32896/620022]    Loss: 0.008889   Batch Acc: 82.81
[Train] Epoch: 3 [32960/620022]    Loss: 0.007233   Batch Acc: 79.69
[Train] Epoch: 3 [33024/620022]    Loss: 0.007561   Batch Acc: 84.38
[Train] Epoch: 3 [33088/620022]    Loss: 0.007092   Batch Acc: 82.81
[Train] Epoch: 3 [33152/620022]    Loss: 0.009838   Batch Acc: 71.88
[Train] Epoch: 3 [33216/620022]    Loss: 0.009480   Batch Acc: 73.44
[Train] Epoch: 3 [33280/620022]    Loss: 0.008605   Batch Acc: 75.00
[Train] Epoch: 3 [33344/620022]    Loss: 0.009482   Batch Acc: 70.31
[Train] Epoch: 3 [33408/620022]    Loss: 0.008245   Batch Acc: 78.12
[Train] Epoch: 3 [33472/620022]    Loss: 0.007917   Batch Acc: 79.69
[Train] Epoch: 3 [33536/620022]    Loss: 0.008088   Batch Acc: 79.69
[Train] Epoch: 3 [33600/620022]    Loss: 0.010267   Batch Acc: 71.88
[Train] Epoch: 3 [33664/620022]    Loss: 0.008954   Batch Acc: 75.00
[Train] Epoch: 3 [33728/620022]    Loss: 0.008036   Batch Acc: 76.56
[Train] Epoch: 3 [33792/620022]    Loss: 0.008657   Batch Acc: 76.56
[Train] Epoch: 3 [33856/620022]    Loss: 0.006538   Batch Acc: 89.06
[Train] Epoch: 3 [33920/620022]    Loss: 0.006747   Batch Acc: 82.81
[Train] Epoch: 3 [33984/620022]    Loss: 0.010959   Batch Acc: 64.06
[Train] Epoch: 3 [34048/620022]    Loss: 0.008446   Batch Acc: 78.12
[Train] Epoch: 3 [34112/620022]    Loss: 0.008495   Batch Acc: 75.00
[Train] Epoch: 3 [34176/620022]    Loss: 0.006862   Batch Acc: 84.38
[Train] Epoch: 3 [34240/620022]    Loss: 0.010900   Batch Acc: 75.00
[Train] Epoch: 3 [34304/620022]    Loss: 0.007704   Batch Acc: 78.12
[Train] Epoch: 3 [34368/620022]    Loss: 0.007643   Batch Acc: 82.81
[Train] Epoch: 3 [34432/620022]    Loss: 0.008090   Batch Acc: 75.00
[Train] Epoch: 3 [34496/620022]    Loss: 0.011822   Batch Acc: 65.62
[Train] Epoch: 3 [34560/620022]    Loss: 0.011401   Batch Acc: 62.50
[Train] Epoch: 3 [34624/620022]    Loss: 0.007882   Batch Acc: 82.81
[Train] Epoch: 3 [34688/620022]    Loss: 0.006723   Batch Acc: 82.81
[Train] Epoch: 3 [34752/620022]    Loss: 0.011791   Batch Acc: 71.88
[Train] Epoch: 3 [34816/620022]    Loss: 0.007339   Batch Acc: 82.81
[Train] Epoch: 3 [34880/620022]    Loss: 0.006888   Batch Acc: 85.94
[Train] Epoch: 3 [34944/620022]    Loss: 0.009754   Batch Acc: 68.75
[Train] Epoch: 3 [35008/620022]    Loss: 0.009143   Batch Acc: 82.81
[Train] Epoch: 3 [35072/620022]    Loss: 0.007501   Batch Acc: 78.12
[Train] Epoch: 3 [35136/620022]    Loss: 0.006821   Batch Acc: 79.69
[Train] Epoch: 3 [35200/620022]    Loss: 0.008032   Batch Acc: 85.94
[Train] Epoch: 3 [35264/620022]    Loss: 0.010828   Batch Acc: 76.56
[Train] Epoch: 3 [35328/620022]    Loss: 0.012474   Batch Acc: 67.19
[Train] Epoch: 3 [35392/620022]    Loss: 0.011199   Batch Acc: 67.19
[Train] Epoch: 3 [35456/620022]    Loss: 0.010648   Batch Acc: 75.00
[Train] Epoch: 3 [35520/620022]    Loss: 0.008325   Batch Acc: 78.12
[Train] Epoch: 3 [35584/620022]    Loss: 0.009221   Batch Acc: 79.69
[Train] Epoch: 3 [35648/620022]    Loss: 0.008552   Batch Acc: 76.56
[Train] Epoch: 3 [35712/620022]    Loss: 0.007770   Batch Acc: 79.69
[Train] Epoch: 3 [35776/620022]    Loss: 0.008161   Batch Acc: 81.25
[Train] Epoch: 3 [35840/620022]    Loss: 0.010048   Batch Acc: 78.12
[Train] Epoch: 3 [35904/620022]    Loss: 0.008725   Batch Acc: 81.25
[Train] Epoch: 3 [35968/620022]    Loss: 0.009965   Batch Acc: 70.31
[Train] Epoch: 3 [36032/620022]    Loss: 0.009604   Batch Acc: 79.69
[Train] Epoch: 3 [36096/620022]    Loss: 0.007266   Batch Acc: 82.81
[Train] Epoch: 3 [36160/620022]    Loss: 0.007940   Batch Acc: 81.25
[Train] Epoch: 3 [36224/620022]    Loss: 0.008072   Batch Acc: 85.94
[Train] Epoch: 3 [36288/620022]    Loss: 0.008396   Batch Acc: 78.12
[Train] Epoch: 3 [36352/620022]    Loss: 0.008021   Batch Acc: 76.56
[Train] Epoch: 3 [36416/620022]    Loss: 0.007278   Batch Acc: 81.25
[Train] Epoch: 3 [36480/620022]    Loss: 0.008361   Batch Acc: 78.12
[Train] Epoch: 3 [36544/620022]    Loss: 0.008085   Batch Acc: 79.69
[Train] Epoch: 3 [36608/620022]    Loss: 0.008074   Batch Acc: 81.25
[Train] Epoch: 3 [36672/620022]    Loss: 0.007827   Batch Acc: 76.56
[Train] Epoch: 3 [36736/620022]    Loss: 0.008735   Batch Acc: 78.12
[Train] Epoch: 3 [36800/620022]    Loss: 0.009820   Batch Acc: 76.56
[Train] Epoch: 3 [36864/620022]    Loss: 0.010837   Batch Acc: 71.88
[Train] Epoch: 3 [36928/620022]    Loss: 0.010140   Batch Acc: 71.88
[Train] Epoch: 3 [36992/620022]    Loss: 0.013810   Batch Acc: 60.94
[Train] Epoch: 3 [37056/620022]    Loss: 0.009767   Batch Acc: 79.69
[Train] Epoch: 3 [37120/620022]    Loss: 0.008508   Batch Acc: 79.69
[Train] Epoch: 3 [37184/620022]    Loss: 0.006889   Batch Acc: 84.38
[Train] Epoch: 3 [37248/620022]    Loss: 0.010467   Batch Acc: 76.56
[Train] Epoch: 3 [37312/620022]    Loss: 0.010140   Batch Acc: 76.56
[Train] Epoch: 3 [37376/620022]    Loss: 0.009097   Batch Acc: 71.88
[Train] Epoch: 3 [37440/620022]    Loss: 0.008137   Batch Acc: 76.56
[Train] Epoch: 3 [37504/620022]    Loss: 0.008338   Batch Acc: 78.12
[Train] Epoch: 3 [37568/620022]    Loss: 0.011303   Batch Acc: 65.62
[Train] Epoch: 3 [37632/620022]    Loss: 0.009318   Batch Acc: 71.88
[Train] Epoch: 3 [37696/620022]    Loss: 0.006966   Batch Acc: 84.38
[Train] Epoch: 3 [37760/620022]    Loss: 0.009573   Batch Acc: 79.69
[Train] Epoch: 3 [37824/620022]    Loss: 0.006063   Batch Acc: 92.19
[Train] Epoch: 3 [37888/620022]    Loss: 0.006150   Batch Acc: 87.50
[Train] Epoch: 3 [37952/620022]    Loss: 0.007572   Batch Acc: 81.25
[Train] Epoch: 3 [38016/620022]    Loss: 0.007508   Batch Acc: 81.25
[Train] Epoch: 3 [38080/620022]    Loss: 0.008434   Batch Acc: 75.00
[Train] Epoch: 3 [38144/620022]    Loss: 0.007747   Batch Acc: 76.56
[Train] Epoch: 3 [38208/620022]    Loss: 0.008205   Batch Acc: 78.12
[Train] Epoch: 3 [38272/620022]    Loss: 0.007706   Batch Acc: 82.81
[Train] Epoch: 3 [38336/620022]    Loss: 0.008154   Batch Acc: 78.12
[Train] Epoch: 3 [38400/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 3 [38464/620022]    Loss: 0.006784   Batch Acc: 84.38
[Train] Epoch: 3 [38528/620022]    Loss: 0.009472   Batch Acc: 73.44
[Train] Epoch: 3 [38592/620022]    Loss: 0.008777   Batch Acc: 75.00
[Train] Epoch: 3 [38656/620022]    Loss: 0.008852   Batch Acc: 75.00
[Train] Epoch: 3 [38720/620022]    Loss: 0.009567   Batch Acc: 76.56
[Train] Epoch: 3 [38784/620022]    Loss: 0.007239   Batch Acc: 87.50
[Train] Epoch: 3 [38848/620022]    Loss: 0.008036   Batch Acc: 78.12
[Train] Epoch: 3 [38912/620022]    Loss: 0.008542   Batch Acc: 81.25
[Train] Epoch: 3 [38976/620022]    Loss: 0.009634   Batch Acc: 68.75
[Train] Epoch: 3 [39040/620022]    Loss: 0.006755   Batch Acc: 85.94
[Train] Epoch: 3 [39104/620022]    Loss: 0.008539   Batch Acc: 75.00
[Train] Epoch: 3 [39168/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 3 [39232/620022]    Loss: 0.010453   Batch Acc: 70.31
[Train] Epoch: 3 [39296/620022]    Loss: 0.009261   Batch Acc: 71.88
[Train] Epoch: 3 [39360/620022]    Loss: 0.008733   Batch Acc: 82.81
[Train] Epoch: 3 [39424/620022]    Loss: 0.008425   Batch Acc: 81.25
[Train] Epoch: 3 [39488/620022]    Loss: 0.008121   Batch Acc: 70.31
[Train] Epoch: 3 [39552/620022]    Loss: 0.006737   Batch Acc: 85.94
[Train] Epoch: 3 [39616/620022]    Loss: 0.010933   Batch Acc: 75.00
[Train] Epoch: 3 [39680/620022]    Loss: 0.008224   Batch Acc: 81.25
[Train] Epoch: 3 [39744/620022]    Loss: 0.008801   Batch Acc: 71.88
[Train] Epoch: 3 [39808/620022]    Loss: 0.007750   Batch Acc: 84.38
[Train] Epoch: 3 [39872/620022]    Loss: 0.009401   Batch Acc: 75.00
[Train] Epoch: 3 [39936/620022]    Loss: 0.008354   Batch Acc: 71.88
[Train] Epoch: 3 [40000/620022]    Loss: 0.010469   Batch Acc: 68.75
[Train] Epoch: 3 [40064/620022]    Loss: 0.008652   Batch Acc: 75.00
[Train] Epoch: 3 [40128/620022]    Loss: 0.006266   Batch Acc: 85.94
[Train] Epoch: 3 [40192/620022]    Loss: 0.006809   Batch Acc: 84.38
[Train] Epoch: 3 [40256/620022]    Loss: 0.007001   Batch Acc: 87.50
[Train] Epoch: 3 [40320/620022]    Loss: 0.009139   Batch Acc: 79.69
[Train] Epoch: 3 [40384/620022]    Loss: 0.007605   Batch Acc: 82.81
[Train] Epoch: 3 [40448/620022]    Loss: 0.007747   Batch Acc: 79.69
[Train] Epoch: 3 [40512/620022]    Loss: 0.007045   Batch Acc: 82.81
[Train] Epoch: 3 [40576/620022]    Loss: 0.009814   Batch Acc: 73.44
[Train] Epoch: 3 [40640/620022]    Loss: 0.006773   Batch Acc: 84.38
[Train] Epoch: 3 [40704/620022]    Loss: 0.011164   Batch Acc: 70.31
[Train] Epoch: 3 [40768/620022]    Loss: 0.009920   Batch Acc: 73.44
[Train] Epoch: 3 [40832/620022]    Loss: 0.008098   Batch Acc: 78.12
[Train] Epoch: 3 [40896/620022]    Loss: 0.008455   Batch Acc: 82.81
[Train] Epoch: 3 [40960/620022]    Loss: 0.008580   Batch Acc: 75.00
[Train] Epoch: 3 [41024/620022]    Loss: 0.008155   Batch Acc: 75.00
[Train] Epoch: 3 [41088/620022]    Loss: 0.007382   Batch Acc: 85.94
[Train] Epoch: 3 [41152/620022]    Loss: 0.007451   Batch Acc: 79.69
[Train] Epoch: 3 [41216/620022]    Loss: 0.009713   Batch Acc: 75.00
[Train] Epoch: 3 [41280/620022]    Loss: 0.009767   Batch Acc: 79.69
[Train] Epoch: 3 [41344/620022]    Loss: 0.009373   Batch Acc: 78.12
[Train] Epoch: 3 [41408/620022]    Loss: 0.008594   Batch Acc: 75.00
[Train] Epoch: 3 [41472/620022]    Loss: 0.009584   Batch Acc: 70.31
[Train] Epoch: 3 [41536/620022]    Loss: 0.008041   Batch Acc: 82.81
[Train] Epoch: 3 [41600/620022]    Loss: 0.008315   Batch Acc: 75.00
[Train] Epoch: 3 [41664/620022]    Loss: 0.011569   Batch Acc: 73.44
[Train] Epoch: 3 [41728/620022]    Loss: 0.008042   Batch Acc: 79.69
[Train] Epoch: 3 [41792/620022]    Loss: 0.008123   Batch Acc: 73.44
[Train] Epoch: 3 [41856/620022]    Loss: 0.011166   Batch Acc: 71.88
[Train] Epoch: 3 [41920/620022]    Loss: 0.011695   Batch Acc: 62.50
[Train] Epoch: 3 [41984/620022]    Loss: 0.007106   Batch Acc: 87.50
[Train] Epoch: 3 [42048/620022]    Loss: 0.008105   Batch Acc: 76.56
[Train] Epoch: 3 [42112/620022]    Loss: 0.007061   Batch Acc: 78.12
[Train] Epoch: 3 [42176/620022]    Loss: 0.012213   Batch Acc: 71.88
[Train] Epoch: 3 [42240/620022]    Loss: 0.006009   Batch Acc: 85.94
[Train] Epoch: 3 [42304/620022]    Loss: 0.010073   Batch Acc: 73.44
[Train] Epoch: 3 [42368/620022]    Loss: 0.007915   Batch Acc: 87.50
[Train] Epoch: 3 [42432/620022]    Loss: 0.007254   Batch Acc: 79.69
[Train] Epoch: 3 [42496/620022]    Loss: 0.006957   Batch Acc: 87.50
[Train] Epoch: 3 [42560/620022]    Loss: 0.008546   Batch Acc: 79.69
[Train] Epoch: 3 [42624/620022]    Loss: 0.008210   Batch Acc: 78.12
[Train] Epoch: 3 [42688/620022]    Loss: 0.010887   Batch Acc: 70.31
[Train] Epoch: 3 [42752/620022]    Loss: 0.007114   Batch Acc: 79.69
[Train] Epoch: 3 [42816/620022]    Loss: 0.010437   Batch Acc: 62.50
[Train] Epoch: 3 [42880/620022]    Loss: 0.009253   Batch Acc: 75.00
[Train] Epoch: 3 [42944/620022]    Loss: 0.007614   Batch Acc: 81.25
[Train] Epoch: 3 [43008/620022]    Loss: 0.009773   Batch Acc: 78.12
[Train] Epoch: 3 [43072/620022]    Loss: 0.006858   Batch Acc: 82.81
[Train] Epoch: 3 [43136/620022]    Loss: 0.007301   Batch Acc: 85.94
[Train] Epoch: 3 [43200/620022]    Loss: 0.010148   Batch Acc: 67.19
[Train] Epoch: 3 [43264/620022]    Loss: 0.009220   Batch Acc: 75.00
[Train] Epoch: 3 [43328/620022]    Loss: 0.009816   Batch Acc: 78.12
[Train] Epoch: 3 [43392/620022]    Loss: 0.009718   Batch Acc: 76.56
[Train] Epoch: 3 [43456/620022]    Loss: 0.010120   Batch Acc: 78.12
[Train] Epoch: 3 [43520/620022]    Loss: 0.010774   Batch Acc: 70.31
[Train] Epoch: 3 [43584/620022]    Loss: 0.007185   Batch Acc: 79.69
[Train] Epoch: 3 [43648/620022]    Loss: 0.008216   Batch Acc: 73.44
[Train] Epoch: 3 [43712/620022]    Loss: 0.009406   Batch Acc: 65.62
[Train] Epoch: 3 [43776/620022]    Loss: 0.009149   Batch Acc: 75.00
[Train] Epoch: 3 [43840/620022]    Loss: 0.007516   Batch Acc: 81.25
[Train] Epoch: 3 [43904/620022]    Loss: 0.009373   Batch Acc: 73.44
[Train] Epoch: 3 [43968/620022]    Loss: 0.009688   Batch Acc: 76.56
[Train] Epoch: 3 [44032/620022]    Loss: 0.008860   Batch Acc: 78.12
[Train] Epoch: 3 [44096/620022]    Loss: 0.008932   Batch Acc: 82.81
[Train] Epoch: 3 [44160/620022]    Loss: 0.008822   Batch Acc: 70.31
[Train] Epoch: 3 [44224/620022]    Loss: 0.006872   Batch Acc: 84.38
[Train] Epoch: 3 [44288/620022]    Loss: 0.009303   Batch Acc: 76.56
[Train] Epoch: 3 [44352/620022]    Loss: 0.008637   Batch Acc: 79.69
[Train] Epoch: 3 [44416/620022]    Loss: 0.007033   Batch Acc: 87.50
[Train] Epoch: 3 [44480/620022]    Loss: 0.006639   Batch Acc: 87.50
[Train] Epoch: 3 [44544/620022]    Loss: 0.010030   Batch Acc: 78.12
[Train] Epoch: 3 [44608/620022]    Loss: 0.007605   Batch Acc: 84.38
[Train] Epoch: 3 [44672/620022]    Loss: 0.009066   Batch Acc: 76.56
[Train] Epoch: 3 [44736/620022]    Loss: 0.008421   Batch Acc: 75.00
[Train] Epoch: 3 [44800/620022]    Loss: 0.007116   Batch Acc: 85.94
[Train] Epoch: 3 [44864/620022]    Loss: 0.009110   Batch Acc: 71.88
[Train] Epoch: 3 [44928/620022]    Loss: 0.007414   Batch Acc: 84.38
[Train] Epoch: 3 [44992/620022]    Loss: 0.009000   Batch Acc: 78.12
[Train] Epoch: 3 [45056/620022]    Loss: 0.010611   Batch Acc: 73.44
[Train] Epoch: 3 [45120/620022]    Loss: 0.008966   Batch Acc: 73.44
[Train] Epoch: 3 [45184/620022]    Loss: 0.010470   Batch Acc: 73.44
[Train] Epoch: 3 [45248/620022]    Loss: 0.010575   Batch Acc: 78.12
[Train] Epoch: 3 [45312/620022]    Loss: 0.009138   Batch Acc: 76.56
[Train] Epoch: 3 [45376/620022]    Loss: 0.007906   Batch Acc: 78.12
[Train] Epoch: 3 [45440/620022]    Loss: 0.008886   Batch Acc: 79.69
[Train] Epoch: 3 [45504/620022]    Loss: 0.006600   Batch Acc: 87.50
[Train] Epoch: 3 [45568/620022]    Loss: 0.007900   Batch Acc: 79.69
[Train] Epoch: 3 [45632/620022]    Loss: 0.008557   Batch Acc: 79.69
[Train] Epoch: 3 [45696/620022]    Loss: 0.010395   Batch Acc: 73.44
[Train] Epoch: 3 [45760/620022]    Loss: 0.006554   Batch Acc: 89.06
[Train] Epoch: 3 [45824/620022]    Loss: 0.007286   Batch Acc: 82.81
[Train] Epoch: 3 [45888/620022]    Loss: 0.009386   Batch Acc: 79.69
[Train] Epoch: 3 [45952/620022]    Loss: 0.007618   Batch Acc: 79.69
[Train] Epoch: 3 [46016/620022]    Loss: 0.008599   Batch Acc: 75.00
[Train] Epoch: 3 [46080/620022]    Loss: 0.007837   Batch Acc: 78.12
[Train] Epoch: 3 [46144/620022]    Loss: 0.008978   Batch Acc: 71.88
[Train] Epoch: 3 [46208/620022]    Loss: 0.008459   Batch Acc: 75.00
[Train] Epoch: 3 [46272/620022]    Loss: 0.009874   Batch Acc: 73.44
[Train] Epoch: 3 [46336/620022]    Loss: 0.010084   Batch Acc: 79.69
[Train] Epoch: 3 [46400/620022]    Loss: 0.007810   Batch Acc: 84.38
[Train] Epoch: 3 [46464/620022]    Loss: 0.007436   Batch Acc: 87.50
[Train] Epoch: 3 [46528/620022]    Loss: 0.008321   Batch Acc: 71.88
[Train] Epoch: 3 [46592/620022]    Loss: 0.011390   Batch Acc: 70.31
[Train] Epoch: 3 [46656/620022]    Loss: 0.010103   Batch Acc: 70.31
[Train] Epoch: 3 [46720/620022]    Loss: 0.008729   Batch Acc: 76.56
[Train] Epoch: 3 [46784/620022]    Loss: 0.008313   Batch Acc: 82.81
[Train] Epoch: 3 [46848/620022]    Loss: 0.006994   Batch Acc: 81.25
[Train] Epoch: 3 [46912/620022]    Loss: 0.008660   Batch Acc: 79.69
[Train] Epoch: 3 [46976/620022]    Loss: 0.009349   Batch Acc: 75.00
[Train] Epoch: 3 [47040/620022]    Loss: 0.007254   Batch Acc: 79.69
[Train] Epoch: 3 [47104/620022]    Loss: 0.009845   Batch Acc: 73.44
[Train] Epoch: 3 [47168/620022]    Loss: 0.007668   Batch Acc: 81.25
[Train] Epoch: 3 [47232/620022]    Loss: 0.009053   Batch Acc: 75.00
[Train] Epoch: 3 [47296/620022]    Loss: 0.010323   Batch Acc: 70.31
[Train] Epoch: 3 [47360/620022]    Loss: 0.007418   Batch Acc: 81.25
[Train] Epoch: 3 [47424/620022]    Loss: 0.009900   Batch Acc: 75.00
[Train] Epoch: 3 [47488/620022]    Loss: 0.009261   Batch Acc: 75.00
[Train] Epoch: 3 [47552/620022]    Loss: 0.009183   Batch Acc: 79.69
[Train] Epoch: 3 [47616/620022]    Loss: 0.010062   Batch Acc: 76.56
[Train] Epoch: 3 [47680/620022]    Loss: 0.009203   Batch Acc: 73.44
[Train] Epoch: 3 [47744/620022]    Loss: 0.009332   Batch Acc: 78.12
[Train] Epoch: 3 [47808/620022]    Loss: 0.007524   Batch Acc: 81.25
[Train] Epoch: 3 [47872/620022]    Loss: 0.009723   Batch Acc: 75.00
[Train] Epoch: 3 [47936/620022]    Loss: 0.008628   Batch Acc: 81.25
[Train] Epoch: 3 [48000/620022]    Loss: 0.009952   Batch Acc: 76.56
[Train] Epoch: 3 [48064/620022]    Loss: 0.009838   Batch Acc: 68.75
[Train] Epoch: 3 [48128/620022]    Loss: 0.011206   Batch Acc: 71.88
[Train] Epoch: 3 [48192/620022]    Loss: 0.010147   Batch Acc: 76.56
[Train] Epoch: 3 [48256/620022]    Loss: 0.009856   Batch Acc: 79.69
[Train] Epoch: 3 [48320/620022]    Loss: 0.008858   Batch Acc: 73.44
[Train] Epoch: 3 [48384/620022]    Loss: 0.009947   Batch Acc: 73.44
[Train] Epoch: 3 [48448/620022]    Loss: 0.007822   Batch Acc: 79.69
[Train] Epoch: 3 [48512/620022]    Loss: 0.007342   Batch Acc: 82.81
[Train] Epoch: 3 [48576/620022]    Loss: 0.005975   Batch Acc: 85.94
[Train] Epoch: 3 [48640/620022]    Loss: 0.008635   Batch Acc: 82.81
[Train] Epoch: 3 [48704/620022]    Loss: 0.009371   Batch Acc: 75.00
[Train] Epoch: 3 [48768/620022]    Loss: 0.007711   Batch Acc: 85.94
[Train] Epoch: 3 [48832/620022]    Loss: 0.010623   Batch Acc: 70.31
[Train] Epoch: 3 [48896/620022]    Loss: 0.008359   Batch Acc: 78.12
[Train] Epoch: 3 [48960/620022]    Loss: 0.007723   Batch Acc: 84.38
[Train] Epoch: 3 [49024/620022]    Loss: 0.009542   Batch Acc: 78.12
[Train] Epoch: 3 [49088/620022]    Loss: 0.007503   Batch Acc: 82.81
[Train] Epoch: 3 [49152/620022]    Loss: 0.008950   Batch Acc: 73.44
[Train] Epoch: 3 [49216/620022]    Loss: 0.009562   Batch Acc: 78.12
[Train] Epoch: 3 [49280/620022]    Loss: 0.007929   Batch Acc: 84.38
[Train] Epoch: 3 [49344/620022]    Loss: 0.009238   Batch Acc: 78.12
[Train] Epoch: 3 [49408/620022]    Loss: 0.010098   Batch Acc: 73.44
[Train] Epoch: 3 [49472/620022]    Loss: 0.009833   Batch Acc: 78.12
[Train] Epoch: 3 [49536/620022]    Loss: 0.007845   Batch Acc: 82.81
[Train] Epoch: 3 [49600/620022]    Loss: 0.006642   Batch Acc: 82.81
[Train] Epoch: 3 [49664/620022]    Loss: 0.008515   Batch Acc: 76.56
[Train] Epoch: 3 [49728/620022]    Loss: 0.009469   Batch Acc: 81.25
[Train] Epoch: 3 [49792/620022]    Loss: 0.007279   Batch Acc: 79.69
[Train] Epoch: 3 [49856/620022]    Loss: 0.009502   Batch Acc: 78.12
[Train] Epoch: 3 [49920/620022]    Loss: 0.007614   Batch Acc: 76.56
[Train] Epoch: 3 [49984/620022]    Loss: 0.006482   Batch Acc: 81.25
[Train] Epoch: 3 [50048/620022]    Loss: 0.009460   Batch Acc: 70.31
[Train] Epoch: 3 [50112/620022]    Loss: 0.009151   Batch Acc: 75.00
[Train] Epoch: 3 [50176/620022]    Loss: 0.007494   Batch Acc: 82.81
[Train] Epoch: 3 [50240/620022]    Loss: 0.008666   Batch Acc: 78.12
[Train] Epoch: 3 [50304/620022]    Loss: 0.006730   Batch Acc: 82.81
[Train] Epoch: 3 [50368/620022]    Loss: 0.011442   Batch Acc: 68.75
[Train] Epoch: 3 [50432/620022]    Loss: 0.007950   Batch Acc: 82.81
[Train] Epoch: 3 [50496/620022]    Loss: 0.010332   Batch Acc: 81.25
[Train] Epoch: 3 [50560/620022]    Loss: 0.008883   Batch Acc: 79.69
[Train] Epoch: 3 [50624/620022]    Loss: 0.010336   Batch Acc: 68.75
[Train] Epoch: 3 [50688/620022]    Loss: 0.007333   Batch Acc: 82.81
[Train] Epoch: 3 [50752/620022]    Loss: 0.008033   Batch Acc: 76.56
[Train] Epoch: 3 [50816/620022]    Loss: 0.007036   Batch Acc: 87.50
[Train] Epoch: 3 [50880/620022]    Loss: 0.006033   Batch Acc: 87.50
[Train] Epoch: 3 [50944/620022]    Loss: 0.008347   Batch Acc: 81.25
[Train] Epoch: 3 [51008/620022]    Loss: 0.008163   Batch Acc: 76.56
[Train] Epoch: 3 [51072/620022]    Loss: 0.006347   Batch Acc: 82.81
[Train] Epoch: 3 [51136/620022]    Loss: 0.008386   Batch Acc: 82.81
[Train] Epoch: 3 [51200/620022]    Loss: 0.009037   Batch Acc: 71.88
[Train] Epoch: 3 [51264/620022]    Loss: 0.009572   Batch Acc: 73.44
[Train] Epoch: 3 [51328/620022]    Loss: 0.007255   Batch Acc: 82.81
[Train] Epoch: 3 [51392/620022]    Loss: 0.007757   Batch Acc: 81.25
[Train] Epoch: 3 [51456/620022]    Loss: 0.006809   Batch Acc: 81.25
[Train] Epoch: 3 [51520/620022]    Loss: 0.008382   Batch Acc: 79.69
[Train] Epoch: 3 [51584/620022]    Loss: 0.006708   Batch Acc: 89.06
[Train] Epoch: 3 [51648/620022]    Loss: 0.007229   Batch Acc: 84.38
[Train] Epoch: 3 [51712/620022]    Loss: 0.009653   Batch Acc: 76.56
[Train] Epoch: 3 [51776/620022]    Loss: 0.007750   Batch Acc: 79.69
[Train] Epoch: 3 [51840/620022]    Loss: 0.008952   Batch Acc: 78.12
[Train] Epoch: 3 [51904/620022]    Loss: 0.007464   Batch Acc: 81.25
[Train] Epoch: 3 [51968/620022]    Loss: 0.009320   Batch Acc: 76.56
[Train] Epoch: 3 [52032/620022]    Loss: 0.009354   Batch Acc: 76.56
[Train] Epoch: 3 [52096/620022]    Loss: 0.008542   Batch Acc: 76.56
[Train] Epoch: 3 [52160/620022]    Loss: 0.007896   Batch Acc: 82.81
[Train] Epoch: 3 [52224/620022]    Loss: 0.006640   Batch Acc: 82.81
[Train] Epoch: 3 [52288/620022]    Loss: 0.006584   Batch Acc: 82.81
[Train] Epoch: 3 [52352/620022]    Loss: 0.008872   Batch Acc: 78.12
[Train] Epoch: 3 [52416/620022]    Loss: 0.010467   Batch Acc: 79.69
[Train] Epoch: 3 [52480/620022]    Loss: 0.010712   Batch Acc: 71.88
[Train] Epoch: 3 [52544/620022]    Loss: 0.008991   Batch Acc: 79.69
[Train] Epoch: 3 [52608/620022]    Loss: 0.009198   Batch Acc: 73.44
[Train] Epoch: 3 [52672/620022]    Loss: 0.008984   Batch Acc: 71.88
[Train] Epoch: 3 [52736/620022]    Loss: 0.008093   Batch Acc: 82.81
[Train] Epoch: 3 [52800/620022]    Loss: 0.009719   Batch Acc: 76.56
[Train] Epoch: 3 [52864/620022]    Loss: 0.008171   Batch Acc: 73.44
[Train] Epoch: 3 [52928/620022]    Loss: 0.006627   Batch Acc: 82.81
[Train] Epoch: 3 [52992/620022]    Loss: 0.007166   Batch Acc: 85.94
[Train] Epoch: 3 [53056/620022]    Loss: 0.008620   Batch Acc: 75.00
[Train] Epoch: 3 [53120/620022]    Loss: 0.006154   Batch Acc: 85.94
[Train] Epoch: 3 [53184/620022]    Loss: 0.007835   Batch Acc: 73.44
[Train] Epoch: 3 [53248/620022]    Loss: 0.008939   Batch Acc: 79.69
[Train] Epoch: 3 [53312/620022]    Loss: 0.009798   Batch Acc: 76.56
[Train] Epoch: 3 [53376/620022]    Loss: 0.010347   Batch Acc: 75.00
[Train] Epoch: 3 [53440/620022]    Loss: 0.007745   Batch Acc: 82.81
[Train] Epoch: 3 [53504/620022]    Loss: 0.009672   Batch Acc: 81.25
[Train] Epoch: 3 [53568/620022]    Loss: 0.008816   Batch Acc: 81.25
[Train] Epoch: 3 [53632/620022]    Loss: 0.009261   Batch Acc: 76.56
[Train] Epoch: 3 [53696/620022]    Loss: 0.012171   Batch Acc: 68.75
[Train] Epoch: 3 [53760/620022]    Loss: 0.007927   Batch Acc: 78.12
[Train] Epoch: 3 [53824/620022]    Loss: 0.006131   Batch Acc: 87.50
[Train] Epoch: 3 [53888/620022]    Loss: 0.008848   Batch Acc: 75.00
[Train] Epoch: 3 [53952/620022]    Loss: 0.011025   Batch Acc: 64.06
[Train] Epoch: 3 [54016/620022]    Loss: 0.009365   Batch Acc: 73.44
[Train] Epoch: 3 [54080/620022]    Loss: 0.009165   Batch Acc: 73.44
[Train] Epoch: 3 [54144/620022]    Loss: 0.009130   Batch Acc: 81.25
[Train] Epoch: 3 [54208/620022]    Loss: 0.010377   Batch Acc: 71.88
[Train] Epoch: 3 [54272/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 3 [54336/620022]    Loss: 0.011156   Batch Acc: 71.88
[Train] Epoch: 3 [54400/620022]    Loss: 0.006009   Batch Acc: 87.50
[Train] Epoch: 3 [54464/620022]    Loss: 0.008247   Batch Acc: 84.38
[Train] Epoch: 3 [54528/620022]    Loss: 0.010470   Batch Acc: 70.31
[Train] Epoch: 3 [54592/620022]    Loss: 0.008190   Batch Acc: 78.12
[Train] Epoch: 3 [54656/620022]    Loss: 0.006248   Batch Acc: 85.94
[Train] Epoch: 3 [54720/620022]    Loss: 0.009085   Batch Acc: 73.44
[Train] Epoch: 3 [54784/620022]    Loss: 0.008319   Batch Acc: 78.12
[Train] Epoch: 3 [54848/620022]    Loss: 0.008120   Batch Acc: 75.00
[Train] Epoch: 3 [54912/620022]    Loss: 0.008139   Batch Acc: 78.12
[Train] Epoch: 3 [54976/620022]    Loss: 0.008655   Batch Acc: 76.56
[Train] Epoch: 3 [55040/620022]    Loss: 0.008987   Batch Acc: 82.81
[Train] Epoch: 3 [55104/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 3 [55168/620022]    Loss: 0.008913   Batch Acc: 73.44
[Train] Epoch: 3 [55232/620022]    Loss: 0.006868   Batch Acc: 82.81
[Train] Epoch: 3 [55296/620022]    Loss: 0.009907   Batch Acc: 73.44
[Train] Epoch: 3 [55360/620022]    Loss: 0.010080   Batch Acc: 79.69
[Train] Epoch: 3 [55424/620022]    Loss: 0.009507   Batch Acc: 76.56
[Train] Epoch: 3 [55488/620022]    Loss: 0.008422   Batch Acc: 75.00
[Train] Epoch: 3 [55552/620022]    Loss: 0.006963   Batch Acc: 81.25
[Train] Epoch: 3 [55616/620022]    Loss: 0.009256   Batch Acc: 78.12
[Train] Epoch: 3 [55680/620022]    Loss: 0.006404   Batch Acc: 84.38
[Train] Epoch: 3 [55744/620022]    Loss: 0.008540   Batch Acc: 81.25
[Train] Epoch: 3 [55808/620022]    Loss: 0.008886   Batch Acc: 81.25
[Train] Epoch: 3 [55872/620022]    Loss: 0.007765   Batch Acc: 81.25
[Train] Epoch: 3 [55936/620022]    Loss: 0.007950   Batch Acc: 78.12
[Train] Epoch: 3 [56000/620022]    Loss: 0.008425   Batch Acc: 81.25
[Train] Epoch: 3 [56064/620022]    Loss: 0.007255   Batch Acc: 82.81
[Train] Epoch: 3 [56128/620022]    Loss: 0.006713   Batch Acc: 90.62
[Train] Epoch: 3 [56192/620022]    Loss: 0.009327   Batch Acc: 76.56
[Train] Epoch: 3 [56256/620022]    Loss: 0.006966   Batch Acc: 84.38
[Train] Epoch: 3 [56320/620022]    Loss: 0.008595   Batch Acc: 81.25
[Train] Epoch: 3 [56384/620022]    Loss: 0.006480   Batch Acc: 84.38
[Train] Epoch: 3 [56448/620022]    Loss: 0.009512   Batch Acc: 76.56
[Train] Epoch: 3 [56512/620022]    Loss: 0.008042   Batch Acc: 78.12
[Train] Epoch: 3 [56576/620022]    Loss: 0.008483   Batch Acc: 84.38
[Train] Epoch: 3 [56640/620022]    Loss: 0.011306   Batch Acc: 71.88
[Train] Epoch: 3 [56704/620022]    Loss: 0.007120   Batch Acc: 79.69
[Train] Epoch: 3 [56768/620022]    Loss: 0.008503   Batch Acc: 78.12
[Train] Epoch: 3 [56832/620022]    Loss: 0.009422   Batch Acc: 70.31
[Train] Epoch: 3 [56896/620022]    Loss: 0.009749   Batch Acc: 73.44
[Train] Epoch: 3 [56960/620022]    Loss: 0.008075   Batch Acc: 76.56
[Train] Epoch: 3 [57024/620022]    Loss: 0.009658   Batch Acc: 73.44
[Train] Epoch: 3 [57088/620022]    Loss: 0.008118   Batch Acc: 84.38
[Train] Epoch: 3 [57152/620022]    Loss: 0.010737   Batch Acc: 70.31
[Train] Epoch: 3 [57216/620022]    Loss: 0.009878   Batch Acc: 76.56
[Train] Epoch: 3 [57280/620022]    Loss: 0.005995   Batch Acc: 85.94
[Train] Epoch: 3 [57344/620022]    Loss: 0.007759   Batch Acc: 79.69
[Train] Epoch: 3 [57408/620022]    Loss: 0.010110   Batch Acc: 67.19
[Train] Epoch: 3 [57472/620022]    Loss: 0.007825   Batch Acc: 79.69
[Train] Epoch: 3 [57536/620022]    Loss: 0.009385   Batch Acc: 76.56
[Train] Epoch: 3 [57600/620022]    Loss: 0.007386   Batch Acc: 81.25
[Train] Epoch: 3 [57664/620022]    Loss: 0.008198   Batch Acc: 78.12
[Train] Epoch: 3 [57728/620022]    Loss: 0.008401   Batch Acc: 76.56
[Train] Epoch: 3 [57792/620022]    Loss: 0.009583   Batch Acc: 79.69
[Train] Epoch: 3 [57856/620022]    Loss: 0.011052   Batch Acc: 78.12
[Train] Epoch: 3 [57920/620022]    Loss: 0.005632   Batch Acc: 90.62
[Train] Epoch: 3 [57984/620022]    Loss: 0.007016   Batch Acc: 79.69
[Train] Epoch: 3 [58048/620022]    Loss: 0.007291   Batch Acc: 85.94
[Train] Epoch: 3 [58112/620022]    Loss: 0.008823   Batch Acc: 79.69
[Train] Epoch: 3 [58176/620022]    Loss: 0.009143   Batch Acc: 73.44
[Train] Epoch: 3 [58240/620022]    Loss: 0.008633   Batch Acc: 75.00
[Train] Epoch: 3 [58304/620022]    Loss: 0.007989   Batch Acc: 76.56
[Train] Epoch: 3 [58368/620022]    Loss: 0.009977   Batch Acc: 79.69
[Train] Epoch: 3 [58432/620022]    Loss: 0.008538   Batch Acc: 75.00
[Train] Epoch: 3 [58496/620022]    Loss: 0.009423   Batch Acc: 73.44
[Train] Epoch: 3 [58560/620022]    Loss: 0.008772   Batch Acc: 71.88
[Train] Epoch: 3 [58624/620022]    Loss: 0.009099   Batch Acc: 71.88
[Train] Epoch: 3 [58688/620022]    Loss: 0.010694   Batch Acc: 73.44
[Train] Epoch: 3 [58752/620022]    Loss: 0.008302   Batch Acc: 78.12
[Train] Epoch: 3 [58816/620022]    Loss: 0.009449   Batch Acc: 81.25
[Train] Epoch: 3 [58880/620022]    Loss: 0.007173   Batch Acc: 84.38
[Train] Epoch: 3 [58944/620022]    Loss: 0.009298   Batch Acc: 78.12
[Train] Epoch: 3 [59008/620022]    Loss: 0.009516   Batch Acc: 76.56
[Train] Epoch: 3 [59072/620022]    Loss: 0.009210   Batch Acc: 79.69
[Train] Epoch: 3 [59136/620022]    Loss: 0.009763   Batch Acc: 73.44
[Train] Epoch: 3 [59200/620022]    Loss: 0.007642   Batch Acc: 84.38
[Train] Epoch: 3 [59264/620022]    Loss: 0.007508   Batch Acc: 82.81
[Train] Epoch: 3 [59328/620022]    Loss: 0.007457   Batch Acc: 85.94
[Train] Epoch: 3 [59392/620022]    Loss: 0.008663   Batch Acc: 71.88
[Train] Epoch: 3 [59456/620022]    Loss: 0.005806   Batch Acc: 87.50
[Train] Epoch: 3 [59520/620022]    Loss: 0.010123   Batch Acc: 70.31
[Train] Epoch: 3 [59584/620022]    Loss: 0.010490   Batch Acc: 68.75
[Train] Epoch: 3 [59648/620022]    Loss: 0.008828   Batch Acc: 75.00
[Train] Epoch: 3 [59712/620022]    Loss: 0.007729   Batch Acc: 81.25
[Train] Epoch: 3 [59776/620022]    Loss: 0.007671   Batch Acc: 79.69
[Train] Epoch: 3 [59840/620022]    Loss: 0.010960   Batch Acc: 71.88
[Train] Epoch: 3 [59904/620022]    Loss: 0.006640   Batch Acc: 82.81
[Train] Epoch: 3 [59968/620022]    Loss: 0.010464   Batch Acc: 70.31
[Train] Epoch: 3 [60032/620022]    Loss: 0.009042   Batch Acc: 76.56
[Train] Epoch: 3 [60096/620022]    Loss: 0.008437   Batch Acc: 78.12
[Train] Epoch: 3 [60160/620022]    Loss: 0.011704   Batch Acc: 67.19
[Train] Epoch: 3 [60224/620022]    Loss: 0.008861   Batch Acc: 79.69
[Train] Epoch: 3 [60288/620022]    Loss: 0.009567   Batch Acc: 71.88
[Train] Epoch: 3 [60352/620022]    Loss: 0.009300   Batch Acc: 76.56
[Train] Epoch: 3 [60416/620022]    Loss: 0.009390   Batch Acc: 73.44
[Train] Epoch: 3 [60480/620022]    Loss: 0.006907   Batch Acc: 89.06
[Train] Epoch: 3 [60544/620022]    Loss: 0.008890   Batch Acc: 76.56
[Train] Epoch: 3 [60608/620022]    Loss: 0.006495   Batch Acc: 89.06
[Train] Epoch: 3 [60672/620022]    Loss: 0.008376   Batch Acc: 78.12
[Train] Epoch: 3 [60736/620022]    Loss: 0.007901   Batch Acc: 81.25
[Train] Epoch: 3 [60800/620022]    Loss: 0.009638   Batch Acc: 76.56
[Train] Epoch: 3 [60864/620022]    Loss: 0.008543   Batch Acc: 78.12
[Train] Epoch: 3 [60928/620022]    Loss: 0.006837   Batch Acc: 89.06
[Train] Epoch: 3 [60992/620022]    Loss: 0.007607   Batch Acc: 81.25
[Train] Epoch: 3 [61056/620022]    Loss: 0.009986   Batch Acc: 75.00
[Train] Epoch: 3 [61120/620022]    Loss: 0.007714   Batch Acc: 81.25
[Train] Epoch: 3 [61184/620022]    Loss: 0.010230   Batch Acc: 68.75
[Train] Epoch: 3 [61248/620022]    Loss: 0.010771   Batch Acc: 75.00
[Train] Epoch: 3 [61312/620022]    Loss: 0.008633   Batch Acc: 81.25
[Train] Epoch: 3 [61376/620022]    Loss: 0.009914   Batch Acc: 70.31
[Train] Epoch: 3 [61440/620022]    Loss: 0.009495   Batch Acc: 76.56
[Train] Epoch: 3 [61504/620022]    Loss: 0.011404   Batch Acc: 70.31
[Train] Epoch: 3 [61568/620022]    Loss: 0.008401   Batch Acc: 76.56
[Train] Epoch: 3 [61632/620022]    Loss: 0.005534   Batch Acc: 84.38
[Train] Epoch: 3 [61696/620022]    Loss: 0.009983   Batch Acc: 78.12
[Train] Epoch: 3 [61760/620022]    Loss: 0.008640   Batch Acc: 78.12
[Train] Epoch: 3 [61824/620022]    Loss: 0.008258   Batch Acc: 84.38
[Train] Epoch: 3 [61888/620022]    Loss: 0.009531   Batch Acc: 75.00
[Train] Epoch: 3 [61952/620022]    Loss: 0.009503   Batch Acc: 70.31
[Train] Epoch: 3 [62016/620022]    Loss: 0.007015   Batch Acc: 85.94
[Train] Epoch: 3 [62080/620022]    Loss: 0.008119   Batch Acc: 81.25
[Train] Epoch: 3 [62144/620022]    Loss: 0.008104   Batch Acc: 76.56
[Train] Epoch: 3 [62208/620022]    Loss: 0.011226   Batch Acc: 65.62
[Train] Epoch: 3 [62272/620022]    Loss: 0.006924   Batch Acc: 79.69
[Train] Epoch: 3 [62336/620022]    Loss: 0.010227   Batch Acc: 75.00
[Train] Epoch: 3 [62400/620022]    Loss: 0.009701   Batch Acc: 73.44
[Train] Epoch: 3 [62464/620022]    Loss: 0.008423   Batch Acc: 78.12
[Train] Epoch: 3 [62528/620022]    Loss: 0.009261   Batch Acc: 78.12
[Train] Epoch: 3 [62592/620022]    Loss: 0.009313   Batch Acc: 79.69
[Train] Epoch: 3 [62656/620022]    Loss: 0.010808   Batch Acc: 71.88
[Train] Epoch: 3 [62720/620022]    Loss: 0.009390   Batch Acc: 79.69
[Train] Epoch: 3 [62784/620022]    Loss: 0.010664   Batch Acc: 75.00
[Train] Epoch: 3 [62848/620022]    Loss: 0.008782   Batch Acc: 78.12
[Train] Epoch: 3 [62912/620022]    Loss: 0.009755   Batch Acc: 78.12
[Train] Epoch: 3 [62976/620022]    Loss: 0.007678   Batch Acc: 79.69
[Train] Epoch: 3 [63040/620022]    Loss: 0.007148   Batch Acc: 84.38
[Train] Epoch: 3 [63104/620022]    Loss: 0.007188   Batch Acc: 81.25
[Train] Epoch: 3 [63168/620022]    Loss: 0.009332   Batch Acc: 73.44
[Train] Epoch: 3 [63232/620022]    Loss: 0.010426   Batch Acc: 64.06
[Train] Epoch: 3 [63296/620022]    Loss: 0.006810   Batch Acc: 84.38
[Train] Epoch: 3 [63360/620022]    Loss: 0.009090   Batch Acc: 73.44
[Train] Epoch: 3 [63424/620022]    Loss: 0.007487   Batch Acc: 84.38
[Train] Epoch: 3 [63488/620022]    Loss: 0.006476   Batch Acc: 85.94
[Train] Epoch: 3 [63552/620022]    Loss: 0.008425   Batch Acc: 76.56
[Train] Epoch: 3 [63616/620022]    Loss: 0.008551   Batch Acc: 78.12
[Train] Epoch: 3 [63680/620022]    Loss: 0.011315   Batch Acc: 73.44
[Train] Epoch: 3 [63744/620022]    Loss: 0.008891   Batch Acc: 78.12
[Train] Epoch: 3 [63808/620022]    Loss: 0.009302   Batch Acc: 71.88
[Train] Epoch: 3 [63872/620022]    Loss: 0.009122   Batch Acc: 75.00
[Train] Epoch: 3 [63936/620022]    Loss: 0.009327   Batch Acc: 70.31
[Train] Epoch: 3 [64000/620022]    Loss: 0.007239   Batch Acc: 81.25
[Train] Epoch: 3 [64064/620022]    Loss: 0.008532   Batch Acc: 79.69
[Train] Epoch: 3 [64128/620022]    Loss: 0.009699   Batch Acc: 81.25
[Train] Epoch: 3 [64192/620022]    Loss: 0.008694   Batch Acc: 79.69
[Train] Epoch: 3 [64256/620022]    Loss: 0.011122   Batch Acc: 70.31
[Train] Epoch: 3 [64320/620022]    Loss: 0.009474   Batch Acc: 68.75
[Train] Epoch: 3 [64384/620022]    Loss: 0.008593   Batch Acc: 79.69
[Train] Epoch: 3 [64448/620022]    Loss: 0.010347   Batch Acc: 67.19
[Train] Epoch: 3 [64512/620022]    Loss: 0.009637   Batch Acc: 75.00
[Train] Epoch: 3 [64576/620022]    Loss: 0.009058   Batch Acc: 70.31
[Train] Epoch: 3 [64640/620022]    Loss: 0.011003   Batch Acc: 67.19
[Train] Epoch: 3 [64704/620022]    Loss: 0.009606   Batch Acc: 79.69
[Train] Epoch: 3 [64768/620022]    Loss: 0.007884   Batch Acc: 84.38
[Train] Epoch: 3 [64832/620022]    Loss: 0.009786   Batch Acc: 73.44
[Train] Epoch: 3 [64896/620022]    Loss: 0.006734   Batch Acc: 85.94
[Train] Epoch: 3 [64960/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 3 [65024/620022]    Loss: 0.008616   Batch Acc: 79.69
[Train] Epoch: 3 [65088/620022]    Loss: 0.008815   Batch Acc: 73.44
[Train] Epoch: 3 [65152/620022]    Loss: 0.009449   Batch Acc: 76.56
[Train] Epoch: 3 [65216/620022]    Loss: 0.007793   Batch Acc: 82.81
[Train] Epoch: 3 [65280/620022]    Loss: 0.011903   Batch Acc: 68.75
[Train] Epoch: 3 [65344/620022]    Loss: 0.007983   Batch Acc: 81.25
[Train] Epoch: 3 [65408/620022]    Loss: 0.010954   Batch Acc: 71.88
[Train] Epoch: 3 [65472/620022]    Loss: 0.008697   Batch Acc: 81.25
[Train] Epoch: 3 [65536/620022]    Loss: 0.006779   Batch Acc: 81.25
[Train] Epoch: 3 [65600/620022]    Loss: 0.009058   Batch Acc: 73.44
[Train] Epoch: 3 [65664/620022]    Loss: 0.009638   Batch Acc: 70.31
[Train] Epoch: 3 [65728/620022]    Loss: 0.007831   Batch Acc: 79.69
[Train] Epoch: 3 [65792/620022]    Loss: 0.006516   Batch Acc: 84.38
[Train] Epoch: 3 [65856/620022]    Loss: 0.008387   Batch Acc: 75.00
[Train] Epoch: 3 [65920/620022]    Loss: 0.008115   Batch Acc: 71.88
[Train] Epoch: 3 [65984/620022]    Loss: 0.007778   Batch Acc: 79.69
[Train] Epoch: 3 [66048/620022]    Loss: 0.010816   Batch Acc: 75.00
[Train] Epoch: 3 [66112/620022]    Loss: 0.006647   Batch Acc: 82.81
[Train] Epoch: 3 [66176/620022]    Loss: 0.007565   Batch Acc: 82.81
[Train] Epoch: 3 [66240/620022]    Loss: 0.009104   Batch Acc: 75.00
[Train] Epoch: 3 [66304/620022]    Loss: 0.009693   Batch Acc: 71.88
[Train] Epoch: 3 [66368/620022]    Loss: 0.008415   Batch Acc: 81.25
[Train] Epoch: 3 [66432/620022]    Loss: 0.009110   Batch Acc: 70.31
[Train] Epoch: 3 [66496/620022]    Loss: 0.007198   Batch Acc: 76.56
[Train] Epoch: 3 [66560/620022]    Loss: 0.007924   Batch Acc: 81.25
[Train] Epoch: 3 [66624/620022]    Loss: 0.009624   Batch Acc: 70.31
[Train] Epoch: 3 [66688/620022]    Loss: 0.009829   Batch Acc: 73.44
[Train] Epoch: 3 [66752/620022]    Loss: 0.008071   Batch Acc: 76.56
[Train] Epoch: 3 [66816/620022]    Loss: 0.010599   Batch Acc: 78.12
[Train] Epoch: 3 [66880/620022]    Loss: 0.008734   Batch Acc: 76.56
[Train] Epoch: 3 [66944/620022]    Loss: 0.009720   Batch Acc: 71.88
[Train] Epoch: 3 [67008/620022]    Loss: 0.008673   Batch Acc: 76.56
[Train] Epoch: 3 [67072/620022]    Loss: 0.009267   Batch Acc: 81.25
[Train] Epoch: 3 [67136/620022]    Loss: 0.010493   Batch Acc: 70.31
[Train] Epoch: 3 [67200/620022]    Loss: 0.007220   Batch Acc: 79.69
[Train] Epoch: 3 [67264/620022]    Loss: 0.007104   Batch Acc: 79.69
[Train] Epoch: 3 [67328/620022]    Loss: 0.008176   Batch Acc: 84.38
[Train] Epoch: 3 [67392/620022]    Loss: 0.009650   Batch Acc: 76.56
[Train] Epoch: 3 [67456/620022]    Loss: 0.010489   Batch Acc: 75.00
[Train] Epoch: 3 [67520/620022]    Loss: 0.007768   Batch Acc: 78.12
[Train] Epoch: 3 [67584/620022]    Loss: 0.008473   Batch Acc: 76.56
[Train] Epoch: 3 [67648/620022]    Loss: 0.006005   Batch Acc: 89.06
[Train] Epoch: 3 [67712/620022]    Loss: 0.010438   Batch Acc: 70.31
[Train] Epoch: 3 [67776/620022]    Loss: 0.008005   Batch Acc: 79.69
[Train] Epoch: 3 [67840/620022]    Loss: 0.004972   Batch Acc: 89.06
[Train] Epoch: 3 [67904/620022]    Loss: 0.007153   Batch Acc: 84.38
[Train] Epoch: 3 [67968/620022]    Loss: 0.010602   Batch Acc: 67.19
[Train] Epoch: 3 [68032/620022]    Loss: 0.009039   Batch Acc: 79.69
[Train] Epoch: 3 [68096/620022]    Loss: 0.010420   Batch Acc: 73.44
[Train] Epoch: 3 [68160/620022]    Loss: 0.008453   Batch Acc: 75.00
[Train] Epoch: 3 [68224/620022]    Loss: 0.010381   Batch Acc: 75.00
[Train] Epoch: 3 [68288/620022]    Loss: 0.008504   Batch Acc: 79.69
[Train] Epoch: 3 [68352/620022]    Loss: 0.010209   Batch Acc: 76.56
[Train] Epoch: 3 [68416/620022]    Loss: 0.007465   Batch Acc: 81.25
[Train] Epoch: 3 [68480/620022]    Loss: 0.008619   Batch Acc: 79.69
[Train] Epoch: 3 [68544/620022]    Loss: 0.011206   Batch Acc: 67.19
[Train] Epoch: 3 [68608/620022]    Loss: 0.008417   Batch Acc: 79.69
[Train] Epoch: 3 [68672/620022]    Loss: 0.007562   Batch Acc: 82.81
[Train] Epoch: 3 [68736/620022]    Loss: 0.009293   Batch Acc: 78.12
[Train] Epoch: 3 [68800/620022]    Loss: 0.007606   Batch Acc: 82.81
[Train] Epoch: 3 [68864/620022]    Loss: 0.006673   Batch Acc: 87.50
[Train] Epoch: 3 [68928/620022]    Loss: 0.007263   Batch Acc: 82.81
[Train] Epoch: 3 [68992/620022]    Loss: 0.009369   Batch Acc: 75.00
[Train] Epoch: 3 [69056/620022]    Loss: 0.010038   Batch Acc: 78.12
[Train] Epoch: 3 [69120/620022]    Loss: 0.008185   Batch Acc: 79.69
[Train] Epoch: 3 [69184/620022]    Loss: 0.009009   Batch Acc: 75.00
[Train] Epoch: 3 [69248/620022]    Loss: 0.006364   Batch Acc: 81.25
[Train] Epoch: 3 [69312/620022]    Loss: 0.009099   Batch Acc: 75.00
[Train] Epoch: 3 [69376/620022]    Loss: 0.008798   Batch Acc: 78.12
[Train] Epoch: 3 [69440/620022]    Loss: 0.006881   Batch Acc: 81.25
[Train] Epoch: 3 [69504/620022]    Loss: 0.008783   Batch Acc: 78.12
[Train] Epoch: 3 [69568/620022]    Loss: 0.009343   Batch Acc: 75.00
[Train] Epoch: 3 [69632/620022]    Loss: 0.009061   Batch Acc: 75.00
[Train] Epoch: 3 [69696/620022]    Loss: 0.009073   Batch Acc: 76.56
[Train] Epoch: 3 [69760/620022]    Loss: 0.012596   Batch Acc: 62.50
[Train] Epoch: 3 [69824/620022]    Loss: 0.005808   Batch Acc: 87.50
[Train] Epoch: 3 [69888/620022]    Loss: 0.007924   Batch Acc: 78.12
[Train] Epoch: 3 [69952/620022]    Loss: 0.011143   Batch Acc: 65.62
[Train] Epoch: 3 [70016/620022]    Loss: 0.009524   Batch Acc: 71.88
[Train] Epoch: 3 [70080/620022]    Loss: 0.009511   Batch Acc: 70.31
[Train] Epoch: 3 [70144/620022]    Loss: 0.006931   Batch Acc: 85.94
[Train] Epoch: 3 [70208/620022]    Loss: 0.006514   Batch Acc: 85.94
[Train] Epoch: 3 [70272/620022]    Loss: 0.009623   Batch Acc: 73.44
[Train] Epoch: 3 [70336/620022]    Loss: 0.007780   Batch Acc: 76.56
[Train] Epoch: 3 [70400/620022]    Loss: 0.009030   Batch Acc: 79.69
[Train] Epoch: 3 [70464/620022]    Loss: 0.008017   Batch Acc: 81.25
[Train] Epoch: 3 [70528/620022]    Loss: 0.007878   Batch Acc: 82.81
[Train] Epoch: 3 [70592/620022]    Loss: 0.010741   Batch Acc: 71.88
[Train] Epoch: 3 [70656/620022]    Loss: 0.006437   Batch Acc: 85.94
[Train] Epoch: 3 [70720/620022]    Loss: 0.008347   Batch Acc: 73.44
[Train] Epoch: 3 [70784/620022]    Loss: 0.008815   Batch Acc: 76.56
[Train] Epoch: 3 [70848/620022]    Loss: 0.008180   Batch Acc: 75.00
[Train] Epoch: 3 [70912/620022]    Loss: 0.008734   Batch Acc: 76.56
[Train] Epoch: 3 [70976/620022]    Loss: 0.009634   Batch Acc: 71.88
[Train] Epoch: 3 [71040/620022]    Loss: 0.011542   Batch Acc: 68.75
[Train] Epoch: 3 [71104/620022]    Loss: 0.009425   Batch Acc: 76.56
[Train] Epoch: 3 [71168/620022]    Loss: 0.007302   Batch Acc: 79.69
[Train] Epoch: 3 [71232/620022]    Loss: 0.007048   Batch Acc: 84.38
[Train] Epoch: 3 [71296/620022]    Loss: 0.010392   Batch Acc: 70.31
[Train] Epoch: 3 [71360/620022]    Loss: 0.009246   Batch Acc: 73.44
[Train] Epoch: 3 [71424/620022]    Loss: 0.008706   Batch Acc: 81.25
[Train] Epoch: 3 [71488/620022]    Loss: 0.009740   Batch Acc: 71.88
[Train] Epoch: 3 [71552/620022]    Loss: 0.007265   Batch Acc: 85.94
[Train] Epoch: 3 [71616/620022]    Loss: 0.007640   Batch Acc: 79.69
[Train] Epoch: 3 [71680/620022]    Loss: 0.011045   Batch Acc: 68.75
[Train] Epoch: 3 [71744/620022]    Loss: 0.006858   Batch Acc: 85.94
[Train] Epoch: 3 [71808/620022]    Loss: 0.007031   Batch Acc: 84.38
[Train] Epoch: 3 [71872/620022]    Loss: 0.009153   Batch Acc: 81.25
[Train] Epoch: 3 [71936/620022]    Loss: 0.006079   Batch Acc: 85.94
[Train] Epoch: 3 [72000/620022]    Loss: 0.007907   Batch Acc: 79.69
[Train] Epoch: 3 [72064/620022]    Loss: 0.010195   Batch Acc: 70.31
[Train] Epoch: 3 [72128/620022]    Loss: 0.010053   Batch Acc: 75.00
[Train] Epoch: 3 [72192/620022]    Loss: 0.008075   Batch Acc: 79.69
[Train] Epoch: 3 [72256/620022]    Loss: 0.011613   Batch Acc: 64.06
[Train] Epoch: 3 [72320/620022]    Loss: 0.008576   Batch Acc: 82.81
[Train] Epoch: 3 [72384/620022]    Loss: 0.008000   Batch Acc: 84.38
[Train] Epoch: 3 [72448/620022]    Loss: 0.010836   Batch Acc: 68.75
[Train] Epoch: 3 [72512/620022]    Loss: 0.008563   Batch Acc: 78.12
[Train] Epoch: 3 [72576/620022]    Loss: 0.009087   Batch Acc: 75.00
[Train] Epoch: 3 [72640/620022]    Loss: 0.010877   Batch Acc: 75.00
[Train] Epoch: 3 [72704/620022]    Loss: 0.011939   Batch Acc: 68.75
[Train] Epoch: 3 [72768/620022]    Loss: 0.010312   Batch Acc: 70.31
[Train] Epoch: 3 [72832/620022]    Loss: 0.012162   Batch Acc: 65.62
[Train] Epoch: 3 [72896/620022]    Loss: 0.004848   Batch Acc: 92.19
[Train] Epoch: 3 [72960/620022]    Loss: 0.010034   Batch Acc: 75.00
[Train] Epoch: 3 [73024/620022]    Loss: 0.009817   Batch Acc: 70.31
[Train] Epoch: 3 [73088/620022]    Loss: 0.006505   Batch Acc: 84.38
[Train] Epoch: 3 [73152/620022]    Loss: 0.009106   Batch Acc: 76.56
[Train] Epoch: 3 [73216/620022]    Loss: 0.008424   Batch Acc: 78.12
[Train] Epoch: 3 [73280/620022]    Loss: 0.006849   Batch Acc: 81.25
[Train] Epoch: 3 [73344/620022]    Loss: 0.007308   Batch Acc: 84.38
[Train] Epoch: 3 [73408/620022]    Loss: 0.010739   Batch Acc: 71.88
[Train] Epoch: 3 [73472/620022]    Loss: 0.009902   Batch Acc: 71.88
[Train] Epoch: 3 [73536/620022]    Loss: 0.009768   Batch Acc: 67.19
[Train] Epoch: 3 [73600/620022]    Loss: 0.009248   Batch Acc: 73.44
[Train] Epoch: 3 [73664/620022]    Loss: 0.009620   Batch Acc: 73.44
[Train] Epoch: 3 [73728/620022]    Loss: 0.007743   Batch Acc: 85.94
[Train] Epoch: 3 [73792/620022]    Loss: 0.006632   Batch Acc: 84.38
[Train] Epoch: 3 [73856/620022]    Loss: 0.007498   Batch Acc: 81.25
[Train] Epoch: 3 [73920/620022]    Loss: 0.008773   Batch Acc: 75.00
[Train] Epoch: 3 [73984/620022]    Loss: 0.006761   Batch Acc: 84.38
[Train] Epoch: 3 [74048/620022]    Loss: 0.008544   Batch Acc: 73.44
[Train] Epoch: 3 [74112/620022]    Loss: 0.007859   Batch Acc: 79.69
[Train] Epoch: 3 [74176/620022]    Loss: 0.011356   Batch Acc: 67.19
[Train] Epoch: 3 [74240/620022]    Loss: 0.009191   Batch Acc: 75.00
[Train] Epoch: 3 [74304/620022]    Loss: 0.010052   Batch Acc: 68.75
[Train] Epoch: 3 [74368/620022]    Loss: 0.006189   Batch Acc: 90.62
[Train] Epoch: 3 [74432/620022]    Loss: 0.011021   Batch Acc: 71.88
[Train] Epoch: 3 [74496/620022]    Loss: 0.008300   Batch Acc: 81.25
[Train] Epoch: 3 [74560/620022]    Loss: 0.009403   Batch Acc: 78.12
[Train] Epoch: 3 [74624/620022]    Loss: 0.007105   Batch Acc: 85.94
[Train] Epoch: 3 [74688/620022]    Loss: 0.009168   Batch Acc: 82.81
[Train] Epoch: 3 [74752/620022]    Loss: 0.011464   Batch Acc: 70.31
[Train] Epoch: 3 [74816/620022]    Loss: 0.005594   Batch Acc: 82.81
[Train] Epoch: 3 [74880/620022]    Loss: 0.009699   Batch Acc: 76.56
[Train] Epoch: 3 [74944/620022]    Loss: 0.012428   Batch Acc: 68.75
[Train] Epoch: 3 [75008/620022]    Loss: 0.006367   Batch Acc: 90.62
[Train] Epoch: 3 [75072/620022]    Loss: 0.007286   Batch Acc: 82.81
[Train] Epoch: 3 [75136/620022]    Loss: 0.008444   Batch Acc: 79.69
[Train] Epoch: 3 [75200/620022]    Loss: 0.007583   Batch Acc: 81.25
[Train] Epoch: 3 [75264/620022]    Loss: 0.009620   Batch Acc: 81.25
[Train] Epoch: 3 [75328/620022]    Loss: 0.008233   Batch Acc: 75.00
[Train] Epoch: 3 [75392/620022]    Loss: 0.006214   Batch Acc: 84.38
[Train] Epoch: 3 [75456/620022]    Loss: 0.008990   Batch Acc: 81.25
[Train] Epoch: 3 [75520/620022]    Loss: 0.007739   Batch Acc: 76.56
[Train] Epoch: 3 [75584/620022]    Loss: 0.009094   Batch Acc: 75.00
[Train] Epoch: 3 [75648/620022]    Loss: 0.008595   Batch Acc: 79.69
[Train] Epoch: 3 [75712/620022]    Loss: 0.009049   Batch Acc: 78.12
[Train] Epoch: 3 [75776/620022]    Loss: 0.007472   Batch Acc: 79.69
[Train] Epoch: 3 [75840/620022]    Loss: 0.007320   Batch Acc: 79.69
[Train] Epoch: 3 [75904/620022]    Loss: 0.006957   Batch Acc: 87.50
[Train] Epoch: 3 [75968/620022]    Loss: 0.008205   Batch Acc: 81.25
[Train] Epoch: 3 [76032/620022]    Loss: 0.009030   Batch Acc: 75.00
[Train] Epoch: 3 [76096/620022]    Loss: 0.008798   Batch Acc: 76.56
[Train] Epoch: 3 [76160/620022]    Loss: 0.008479   Batch Acc: 75.00
[Train] Epoch: 3 [76224/620022]    Loss: 0.010715   Batch Acc: 68.75
[Train] Epoch: 3 [76288/620022]    Loss: 0.010068   Batch Acc: 75.00
[Train] Epoch: 3 [76352/620022]    Loss: 0.010936   Batch Acc: 68.75
[Train] Epoch: 3 [76416/620022]    Loss: 0.008572   Batch Acc: 82.81
[Train] Epoch: 3 [76480/620022]    Loss: 0.009292   Batch Acc: 73.44
[Train] Epoch: 3 [76544/620022]    Loss: 0.006224   Batch Acc: 87.50
[Train] Epoch: 3 [76608/620022]    Loss: 0.007585   Batch Acc: 75.00
[Train] Epoch: 3 [76672/620022]    Loss: 0.009472   Batch Acc: 81.25
[Train] Epoch: 3 [76736/620022]    Loss: 0.009138   Batch Acc: 78.12
[Train] Epoch: 3 [76800/620022]    Loss: 0.010119   Batch Acc: 73.44
[Train] Epoch: 3 [76864/620022]    Loss: 0.010082   Batch Acc: 71.88
[Train] Epoch: 3 [76928/620022]    Loss: 0.012690   Batch Acc: 67.19
[Train] Epoch: 3 [76992/620022]    Loss: 0.009775   Batch Acc: 78.12
[Train] Epoch: 3 [77056/620022]    Loss: 0.010362   Batch Acc: 71.88
[Train] Epoch: 3 [77120/620022]    Loss: 0.008201   Batch Acc: 82.81
[Train] Epoch: 3 [77184/620022]    Loss: 0.010350   Batch Acc: 67.19
[Train] Epoch: 3 [77248/620022]    Loss: 0.008819   Batch Acc: 84.38
[Train] Epoch: 3 [77312/620022]    Loss: 0.011206   Batch Acc: 62.50
[Train] Epoch: 3 [77376/620022]    Loss: 0.009454   Batch Acc: 76.56
[Train] Epoch: 3 [77440/620022]    Loss: 0.010038   Batch Acc: 78.12
[Train] Epoch: 3 [77504/620022]    Loss: 0.007136   Batch Acc: 78.12
[Train] Epoch: 3 [77568/620022]    Loss: 0.008014   Batch Acc: 85.94
[Train] Epoch: 3 [77632/620022]    Loss: 0.010778   Batch Acc: 73.44
[Train] Epoch: 3 [77696/620022]    Loss: 0.009434   Batch Acc: 78.12
[Train] Epoch: 3 [77760/620022]    Loss: 0.008110   Batch Acc: 76.56
[Train] Epoch: 3 [77824/620022]    Loss: 0.010182   Batch Acc: 75.00
[Train] Epoch: 3 [77888/620022]    Loss: 0.008507   Batch Acc: 73.44
[Train] Epoch: 3 [77952/620022]    Loss: 0.007265   Batch Acc: 82.81
[Train] Epoch: 3 [78016/620022]    Loss: 0.008636   Batch Acc: 81.25
[Train] Epoch: 3 [78080/620022]    Loss: 0.009904   Batch Acc: 75.00
[Train] Epoch: 3 [78144/620022]    Loss: 0.010892   Batch Acc: 64.06
[Train] Epoch: 3 [78208/620022]    Loss: 0.008513   Batch Acc: 81.25
[Train] Epoch: 3 [78272/620022]    Loss: 0.008849   Batch Acc: 79.69
[Train] Epoch: 3 [78336/620022]    Loss: 0.009108   Batch Acc: 78.12
[Train] Epoch: 3 [78400/620022]    Loss: 0.007934   Batch Acc: 75.00
[Train] Epoch: 3 [78464/620022]    Loss: 0.009297   Batch Acc: 71.88
[Train] Epoch: 3 [78528/620022]    Loss: 0.009955   Batch Acc: 71.88
[Train] Epoch: 3 [78592/620022]    Loss: 0.011221   Batch Acc: 68.75
[Train] Epoch: 3 [78656/620022]    Loss: 0.007356   Batch Acc: 84.38
[Train] Epoch: 3 [78720/620022]    Loss: 0.008915   Batch Acc: 70.31
[Train] Epoch: 3 [78784/620022]    Loss: 0.007757   Batch Acc: 79.69
[Train] Epoch: 3 [78848/620022]    Loss: 0.011373   Batch Acc: 67.19
[Train] Epoch: 3 [78912/620022]    Loss: 0.008090   Batch Acc: 76.56
[Train] Epoch: 3 [78976/620022]    Loss: 0.008767   Batch Acc: 79.69
[Train] Epoch: 3 [79040/620022]    Loss: 0.007769   Batch Acc: 78.12
[Train] Epoch: 3 [79104/620022]    Loss: 0.007490   Batch Acc: 84.38
[Train] Epoch: 3 [79168/620022]    Loss: 0.010911   Batch Acc: 75.00
[Train] Epoch: 3 [79232/620022]    Loss: 0.009795   Batch Acc: 81.25
[Train] Epoch: 3 [79296/620022]    Loss: 0.009323   Batch Acc: 78.12
[Train] Epoch: 3 [79360/620022]    Loss: 0.006901   Batch Acc: 85.94
[Train] Epoch: 3 [79424/620022]    Loss: 0.007467   Batch Acc: 81.25
[Train] Epoch: 3 [79488/620022]    Loss: 0.009040   Batch Acc: 76.56
[Train] Epoch: 3 [79552/620022]    Loss: 0.007554   Batch Acc: 84.38
[Train] Epoch: 3 [79616/620022]    Loss: 0.007516   Batch Acc: 81.25
[Train] Epoch: 3 [79680/620022]    Loss: 0.008126   Batch Acc: 81.25
[Train] Epoch: 3 [79744/620022]    Loss: 0.009197   Batch Acc: 76.56
[Train] Epoch: 3 [79808/620022]    Loss: 0.008655   Batch Acc: 79.69
[Train] Epoch: 3 [79872/620022]    Loss: 0.010701   Batch Acc: 73.44
[Train] Epoch: 3 [79936/620022]    Loss: 0.008565   Batch Acc: 78.12
[Train] Epoch: 3 [80000/620022]    Loss: 0.008797   Batch Acc: 79.69
[Train] Epoch: 3 [80064/620022]    Loss: 0.007231   Batch Acc: 81.25
[Train] Epoch: 3 [80128/620022]    Loss: 0.007667   Batch Acc: 79.69
[Train] Epoch: 3 [80192/620022]    Loss: 0.007368   Batch Acc: 81.25
[Train] Epoch: 3 [80256/620022]    Loss: 0.009767   Batch Acc: 67.19
[Train] Epoch: 3 [80320/620022]    Loss: 0.007384   Batch Acc: 76.56
[Train] Epoch: 3 [80384/620022]    Loss: 0.007243   Batch Acc: 82.81
[Train] Epoch: 3 [80448/620022]    Loss: 0.008372   Batch Acc: 79.69
[Train] Epoch: 3 [80512/620022]    Loss: 0.009501   Batch Acc: 76.56
[Train] Epoch: 3 [80576/620022]    Loss: 0.009560   Batch Acc: 73.44
[Train] Epoch: 3 [80640/620022]    Loss: 0.009035   Batch Acc: 79.69
[Train] Epoch: 3 [80704/620022]    Loss: 0.008305   Batch Acc: 79.69
[Train] Epoch: 3 [80768/620022]    Loss: 0.009137   Batch Acc: 70.31
[Train] Epoch: 3 [80832/620022]    Loss: 0.010140   Batch Acc: 70.31
[Train] Epoch: 3 [80896/620022]    Loss: 0.008780   Batch Acc: 79.69
[Train] Epoch: 3 [80960/620022]    Loss: 0.007073   Batch Acc: 84.38
[Train] Epoch: 3 [81024/620022]    Loss: 0.008952   Batch Acc: 71.88
[Train] Epoch: 3 [81088/620022]    Loss: 0.010363   Batch Acc: 71.88
[Train] Epoch: 3 [81152/620022]    Loss: 0.008180   Batch Acc: 81.25
[Train] Epoch: 3 [81216/620022]    Loss: 0.010375   Batch Acc: 71.88
[Train] Epoch: 3 [81280/620022]    Loss: 0.008315   Batch Acc: 78.12
[Train] Epoch: 3 [81344/620022]    Loss: 0.009314   Batch Acc: 73.44
[Train] Epoch: 3 [81408/620022]    Loss: 0.011839   Batch Acc: 67.19
[Train] Epoch: 3 [81472/620022]    Loss: 0.009662   Batch Acc: 81.25
[Train] Epoch: 3 [81536/620022]    Loss: 0.009467   Batch Acc: 75.00
[Train] Epoch: 3 [81600/620022]    Loss: 0.012219   Batch Acc: 60.94
[Train] Epoch: 3 [81664/620022]    Loss: 0.010078   Batch Acc: 68.75
[Train] Epoch: 3 [81728/620022]    Loss: 0.008880   Batch Acc: 79.69
[Train] Epoch: 3 [81792/620022]    Loss: 0.009170   Batch Acc: 71.88
[Train] Epoch: 3 [81856/620022]    Loss: 0.009214   Batch Acc: 71.88
[Train] Epoch: 3 [81920/620022]    Loss: 0.010141   Batch Acc: 70.31
[Train] Epoch: 3 [81984/620022]    Loss: 0.011224   Batch Acc: 67.19
[Train] Epoch: 3 [82048/620022]    Loss: 0.010698   Batch Acc: 70.31
[Train] Epoch: 3 [82112/620022]    Loss: 0.008539   Batch Acc: 82.81
[Train] Epoch: 3 [82176/620022]    Loss: 0.010063   Batch Acc: 75.00
[Train] Epoch: 3 [82240/620022]    Loss: 0.011232   Batch Acc: 67.19
[Train] Epoch: 3 [82304/620022]    Loss: 0.006632   Batch Acc: 89.06
[Train] Epoch: 3 [82368/620022]    Loss: 0.006697   Batch Acc: 85.94
[Train] Epoch: 3 [82432/620022]    Loss: 0.008048   Batch Acc: 78.12
[Train] Epoch: 3 [82496/620022]    Loss: 0.008674   Batch Acc: 78.12
[Train] Epoch: 3 [82560/620022]    Loss: 0.008114   Batch Acc: 78.12
[Train] Epoch: 3 [82624/620022]    Loss: 0.007812   Batch Acc: 81.25
[Train] Epoch: 3 [82688/620022]    Loss: 0.007494   Batch Acc: 89.06
[Train] Epoch: 3 [82752/620022]    Loss: 0.008565   Batch Acc: 76.56
[Train] Epoch: 3 [82816/620022]    Loss: 0.008376   Batch Acc: 79.69
[Train] Epoch: 3 [82880/620022]    Loss: 0.009801   Batch Acc: 73.44
[Train] Epoch: 3 [82944/620022]    Loss: 0.009193   Batch Acc: 79.69
[Train] Epoch: 3 [83008/620022]    Loss: 0.008930   Batch Acc: 76.56
[Train] Epoch: 3 [83072/620022]    Loss: 0.009578   Batch Acc: 75.00
[Train] Epoch: 3 [83136/620022]    Loss: 0.008927   Batch Acc: 76.56
[Train] Epoch: 3 [83200/620022]    Loss: 0.009496   Batch Acc: 71.88
[Train] Epoch: 3 [83264/620022]    Loss: 0.006324   Batch Acc: 84.38
[Train] Epoch: 3 [83328/620022]    Loss: 0.007141   Batch Acc: 82.81
[Train] Epoch: 3 [83392/620022]    Loss: 0.007819   Batch Acc: 84.38
[Train] Epoch: 3 [83456/620022]    Loss: 0.008536   Batch Acc: 79.69
[Train] Epoch: 3 [83520/620022]    Loss: 0.009058   Batch Acc: 76.56
[Train] Epoch: 3 [83584/620022]    Loss: 0.007827   Batch Acc: 79.69
[Train] Epoch: 3 [83648/620022]    Loss: 0.011387   Batch Acc: 65.62
[Train] Epoch: 3 [83712/620022]    Loss: 0.008969   Batch Acc: 73.44
[Train] Epoch: 3 [83776/620022]    Loss: 0.010127   Batch Acc: 75.00
[Train] Epoch: 3 [83840/620022]    Loss: 0.008812   Batch Acc: 70.31
[Train] Epoch: 3 [83904/620022]    Loss: 0.008541   Batch Acc: 78.12
[Train] Epoch: 3 [83968/620022]    Loss: 0.008338   Batch Acc: 76.56
[Train] Epoch: 3 [84032/620022]    Loss: 0.010375   Batch Acc: 78.12
[Train] Epoch: 3 [84096/620022]    Loss: 0.009078   Batch Acc: 79.69
[Train] Epoch: 3 [84160/620022]    Loss: 0.006722   Batch Acc: 89.06
[Train] Epoch: 3 [84224/620022]    Loss: 0.007269   Batch Acc: 79.69
[Train] Epoch: 3 [84288/620022]    Loss: 0.007557   Batch Acc: 78.12
[Train] Epoch: 3 [84352/620022]    Loss: 0.008350   Batch Acc: 78.12
[Train] Epoch: 3 [84416/620022]    Loss: 0.009317   Batch Acc: 79.69
[Train] Epoch: 3 [84480/620022]    Loss: 0.006032   Batch Acc: 90.62
[Train] Epoch: 3 [84544/620022]    Loss: 0.008513   Batch Acc: 76.56
[Train] Epoch: 3 [84608/620022]    Loss: 0.010335   Batch Acc: 71.88
[Train] Epoch: 3 [84672/620022]    Loss: 0.008620   Batch Acc: 78.12
[Train] Epoch: 3 [84736/620022]    Loss: 0.007891   Batch Acc: 81.25
[Train] Epoch: 3 [84800/620022]    Loss: 0.010147   Batch Acc: 78.12
[Train] Epoch: 3 [84864/620022]    Loss: 0.012795   Batch Acc: 65.62
[Train] Epoch: 3 [84928/620022]    Loss: 0.008258   Batch Acc: 73.44
[Train] Epoch: 3 [84992/620022]    Loss: 0.007991   Batch Acc: 79.69
[Train] Epoch: 3 [85056/620022]    Loss: 0.006779   Batch Acc: 87.50
[Train] Epoch: 3 [85120/620022]    Loss: 0.008436   Batch Acc: 73.44
[Train] Epoch: 3 [85184/620022]    Loss: 0.008427   Batch Acc: 71.88
[Train] Epoch: 3 [85248/620022]    Loss: 0.006954   Batch Acc: 82.81
[Train] Epoch: 3 [85312/620022]    Loss: 0.010537   Batch Acc: 70.31
[Train] Epoch: 3 [85376/620022]    Loss: 0.013672   Batch Acc: 71.88
[Train] Epoch: 3 [85440/620022]    Loss: 0.010834   Batch Acc: 73.44
[Train] Epoch: 3 [85504/620022]    Loss: 0.011064   Batch Acc: 71.88
[Train] Epoch: 3 [85568/620022]    Loss: 0.009791   Batch Acc: 76.56
[Train] Epoch: 3 [85632/620022]    Loss: 0.009822   Batch Acc: 76.56
[Train] Epoch: 3 [85696/620022]    Loss: 0.009605   Batch Acc: 75.00
[Train] Epoch: 3 [85760/620022]    Loss: 0.007867   Batch Acc: 76.56
[Train] Epoch: 3 [85824/620022]    Loss: 0.006358   Batch Acc: 81.25
[Train] Epoch: 3 [85888/620022]    Loss: 0.010880   Batch Acc: 71.88
[Train] Epoch: 3 [85952/620022]    Loss: 0.007598   Batch Acc: 78.12
[Train] Epoch: 3 [86016/620022]    Loss: 0.010683   Batch Acc: 73.44
[Train] Epoch: 3 [86080/620022]    Loss: 0.008206   Batch Acc: 79.69
[Train] Epoch: 3 [86144/620022]    Loss: 0.012932   Batch Acc: 70.31
[Train] Epoch: 3 [86208/620022]    Loss: 0.007249   Batch Acc: 81.25
[Train] Epoch: 3 [86272/620022]    Loss: 0.008915   Batch Acc: 78.12
[Train] Epoch: 3 [86336/620022]    Loss: 0.009080   Batch Acc: 76.56
[Train] Epoch: 3 [86400/620022]    Loss: 0.010427   Batch Acc: 71.88
[Train] Epoch: 3 [86464/620022]    Loss: 0.008591   Batch Acc: 79.69
[Train] Epoch: 3 [86528/620022]    Loss: 0.007763   Batch Acc: 84.38
[Train] Epoch: 3 [86592/620022]    Loss: 0.009802   Batch Acc: 71.88
[Train] Epoch: 3 [86656/620022]    Loss: 0.008524   Batch Acc: 78.12
[Train] Epoch: 3 [86720/620022]    Loss: 0.008950   Batch Acc: 70.31
[Train] Epoch: 3 [86784/620022]    Loss: 0.008537   Batch Acc: 76.56
[Train] Epoch: 3 [86848/620022]    Loss: 0.007983   Batch Acc: 81.25
[Train] Epoch: 3 [86912/620022]    Loss: 0.009643   Batch Acc: 76.56
[Train] Epoch: 3 [86976/620022]    Loss: 0.007572   Batch Acc: 81.25
[Train] Epoch: 3 [87040/620022]    Loss: 0.008381   Batch Acc: 82.81
[Train] Epoch: 3 [87104/620022]    Loss: 0.006656   Batch Acc: 81.25
[Train] Epoch: 3 [87168/620022]    Loss: 0.009147   Batch Acc: 79.69
[Train] Epoch: 3 [87232/620022]    Loss: 0.009815   Batch Acc: 76.56
[Train] Epoch: 3 [87296/620022]    Loss: 0.008128   Batch Acc: 82.81
[Train] Epoch: 3 [87360/620022]    Loss: 0.008641   Batch Acc: 76.56
[Train] Epoch: 3 [87424/620022]    Loss: 0.008701   Batch Acc: 82.81
[Train] Epoch: 3 [87488/620022]    Loss: 0.006567   Batch Acc: 84.38
[Train] Epoch: 3 [87552/620022]    Loss: 0.008953   Batch Acc: 76.56
[Train] Epoch: 3 [87616/620022]    Loss: 0.008355   Batch Acc: 81.25
[Train] Epoch: 3 [87680/620022]    Loss: 0.007409   Batch Acc: 85.94
[Train] Epoch: 3 [87744/620022]    Loss: 0.008739   Batch Acc: 78.12
[Train] Epoch: 3 [87808/620022]    Loss: 0.009212   Batch Acc: 76.56
[Train] Epoch: 3 [87872/620022]    Loss: 0.010412   Batch Acc: 76.56
[Train] Epoch: 3 [87936/620022]    Loss: 0.008205   Batch Acc: 75.00
[Train] Epoch: 3 [88000/620022]    Loss: 0.007596   Batch Acc: 81.25
[Train] Epoch: 3 [88064/620022]    Loss: 0.006674   Batch Acc: 89.06
[Train] Epoch: 3 [88128/620022]    Loss: 0.009991   Batch Acc: 78.12
[Train] Epoch: 3 [88192/620022]    Loss: 0.009514   Batch Acc: 78.12
[Train] Epoch: 3 [88256/620022]    Loss: 0.007431   Batch Acc: 82.81
[Train] Epoch: 3 [88320/620022]    Loss: 0.009378   Batch Acc: 76.56
[Train] Epoch: 3 [88384/620022]    Loss: 0.008830   Batch Acc: 79.69
[Train] Epoch: 3 [88448/620022]    Loss: 0.008094   Batch Acc: 79.69
[Train] Epoch: 3 [88512/620022]    Loss: 0.008660   Batch Acc: 78.12
[Train] Epoch: 3 [88576/620022]    Loss: 0.008262   Batch Acc: 76.56
[Train] Epoch: 3 [88640/620022]    Loss: 0.008231   Batch Acc: 78.12
[Train] Epoch: 3 [88704/620022]    Loss: 0.007954   Batch Acc: 79.69
[Train] Epoch: 3 [88768/620022]    Loss: 0.008917   Batch Acc: 76.56
[Train] Epoch: 3 [88832/620022]    Loss: 0.010558   Batch Acc: 70.31
[Train] Epoch: 3 [88896/620022]    Loss: 0.007772   Batch Acc: 81.25
[Train] Epoch: 3 [88960/620022]    Loss: 0.012160   Batch Acc: 60.94
[Train] Epoch: 3 [89024/620022]    Loss: 0.007061   Batch Acc: 85.94
[Train] Epoch: 3 [89088/620022]    Loss: 0.011192   Batch Acc: 71.88
[Train] Epoch: 3 [89152/620022]    Loss: 0.008611   Batch Acc: 81.25
[Train] Epoch: 3 [89216/620022]    Loss: 0.008128   Batch Acc: 73.44
[Train] Epoch: 3 [89280/620022]    Loss: 0.006831   Batch Acc: 81.25
[Train] Epoch: 3 [89344/620022]    Loss: 0.007808   Batch Acc: 82.81
[Train] Epoch: 3 [89408/620022]    Loss: 0.007463   Batch Acc: 76.56
[Train] Epoch: 3 [89472/620022]    Loss: 0.010026   Batch Acc: 73.44
[Train] Epoch: 3 [89536/620022]    Loss: 0.007574   Batch Acc: 82.81
[Train] Epoch: 3 [89600/620022]    Loss: 0.008932   Batch Acc: 78.12
[Train] Epoch: 3 [89664/620022]    Loss: 0.006980   Batch Acc: 81.25
[Train] Epoch: 3 [89728/620022]    Loss: 0.010378   Batch Acc: 73.44
[Train] Epoch: 3 [89792/620022]    Loss: 0.008628   Batch Acc: 76.56
[Train] Epoch: 3 [89856/620022]    Loss: 0.009344   Batch Acc: 75.00
[Train] Epoch: 3 [89920/620022]    Loss: 0.009034   Batch Acc: 73.44
[Train] Epoch: 3 [89984/620022]    Loss: 0.007163   Batch Acc: 82.81
[Train] Epoch: 3 [90048/620022]    Loss: 0.009063   Batch Acc: 79.69
[Train] Epoch: 3 [90112/620022]    Loss: 0.006738   Batch Acc: 82.81
[Train] Epoch: 3 [90176/620022]    Loss: 0.009871   Batch Acc: 76.56
[Train] Epoch: 3 [90240/620022]    Loss: 0.008515   Batch Acc: 79.69
[Train] Epoch: 3 [90304/620022]    Loss: 0.007779   Batch Acc: 84.38
[Train] Epoch: 3 [90368/620022]    Loss: 0.008428   Batch Acc: 78.12
[Train] Epoch: 3 [90432/620022]    Loss: 0.007936   Batch Acc: 81.25
[Train] Epoch: 3 [90496/620022]    Loss: 0.010823   Batch Acc: 70.31
[Train] Epoch: 3 [90560/620022]    Loss: 0.010524   Batch Acc: 73.44
[Train] Epoch: 3 [90624/620022]    Loss: 0.007628   Batch Acc: 78.12
[Train] Epoch: 3 [90688/620022]    Loss: 0.009226   Batch Acc: 78.12
[Train] Epoch: 3 [90752/620022]    Loss: 0.009223   Batch Acc: 75.00
[Train] Epoch: 3 [90816/620022]    Loss: 0.007976   Batch Acc: 84.38
[Train] Epoch: 3 [90880/620022]    Loss: 0.008982   Batch Acc: 76.56
[Train] Epoch: 3 [90944/620022]    Loss: 0.008060   Batch Acc: 85.94
[Train] Epoch: 3 [91008/620022]    Loss: 0.012517   Batch Acc: 64.06
[Train] Epoch: 3 [91072/620022]    Loss: 0.009521   Batch Acc: 73.44
[Train] Epoch: 3 [91136/620022]    Loss: 0.007996   Batch Acc: 81.25
[Train] Epoch: 3 [91200/620022]    Loss: 0.006524   Batch Acc: 84.38
[Train] Epoch: 3 [91264/620022]    Loss: 0.010438   Batch Acc: 71.88
[Train] Epoch: 3 [91328/620022]    Loss: 0.008528   Batch Acc: 76.56
[Train] Epoch: 3 [91392/620022]    Loss: 0.010460   Batch Acc: 76.56
[Train] Epoch: 3 [91456/620022]    Loss: 0.008316   Batch Acc: 81.25
[Train] Epoch: 3 [91520/620022]    Loss: 0.009047   Batch Acc: 75.00
[Train] Epoch: 3 [91584/620022]    Loss: 0.009830   Batch Acc: 75.00
[Train] Epoch: 3 [91648/620022]    Loss: 0.009008   Batch Acc: 73.44
[Train] Epoch: 3 [91712/620022]    Loss: 0.010507   Batch Acc: 75.00
[Train] Epoch: 3 [91776/620022]    Loss: 0.006605   Batch Acc: 87.50
[Train] Epoch: 3 [91840/620022]    Loss: 0.010914   Batch Acc: 68.75
[Train] Epoch: 3 [91904/620022]    Loss: 0.008725   Batch Acc: 76.56
[Train] Epoch: 3 [91968/620022]    Loss: 0.010086   Batch Acc: 71.88
[Train] Epoch: 3 [92032/620022]    Loss: 0.010226   Batch Acc: 76.56
[Train] Epoch: 3 [92096/620022]    Loss: 0.008021   Batch Acc: 78.12
[Train] Epoch: 3 [92160/620022]    Loss: 0.008670   Batch Acc: 81.25
[Train] Epoch: 3 [92224/620022]    Loss: 0.006126   Batch Acc: 81.25
[Train] Epoch: 3 [92288/620022]    Loss: 0.008463   Batch Acc: 78.12
[Train] Epoch: 3 [92352/620022]    Loss: 0.009802   Batch Acc: 82.81
[Train] Epoch: 3 [92416/620022]    Loss: 0.007978   Batch Acc: 78.12
[Train] Epoch: 3 [92480/620022]    Loss: 0.012928   Batch Acc: 67.19
[Train] Epoch: 3 [92544/620022]    Loss: 0.008602   Batch Acc: 78.12
[Train] Epoch: 3 [92608/620022]    Loss: 0.007314   Batch Acc: 81.25
[Train] Epoch: 3 [92672/620022]    Loss: 0.009585   Batch Acc: 75.00
[Train] Epoch: 3 [92736/620022]    Loss: 0.007480   Batch Acc: 78.12
[Train] Epoch: 3 [92800/620022]    Loss: 0.008100   Batch Acc: 76.56
[Train] Epoch: 3 [92864/620022]    Loss: 0.008874   Batch Acc: 84.38
[Train] Epoch: 3 [92928/620022]    Loss: 0.007432   Batch Acc: 75.00
[Train] Epoch: 3 [92992/620022]    Loss: 0.009515   Batch Acc: 75.00
[Train] Epoch: 3 [93056/620022]    Loss: 0.007311   Batch Acc: 78.12
[Train] Epoch: 3 [93120/620022]    Loss: 0.009538   Batch Acc: 76.56
[Train] Epoch: 3 [93184/620022]    Loss: 0.007569   Batch Acc: 87.50
[Train] Epoch: 3 [93248/620022]    Loss: 0.009908   Batch Acc: 75.00
[Train] Epoch: 3 [93312/620022]    Loss: 0.007408   Batch Acc: 82.81
[Train] Epoch: 3 [93376/620022]    Loss: 0.008151   Batch Acc: 81.25
[Train] Epoch: 3 [93440/620022]    Loss: 0.009688   Batch Acc: 75.00
[Train] Epoch: 3 [93504/620022]    Loss: 0.007053   Batch Acc: 82.81
[Train] Epoch: 3 [93568/620022]    Loss: 0.009505   Batch Acc: 78.12
[Train] Epoch: 3 [93632/620022]    Loss: 0.006335   Batch Acc: 85.94
[Train] Epoch: 3 [93696/620022]    Loss: 0.008041   Batch Acc: 76.56
[Train] Epoch: 3 [93760/620022]    Loss: 0.009232   Batch Acc: 71.88
[Train] Epoch: 3 [93824/620022]    Loss: 0.007768   Batch Acc: 81.25
[Train] Epoch: 3 [93888/620022]    Loss: 0.008833   Batch Acc: 73.44
[Train] Epoch: 3 [93952/620022]    Loss: 0.008986   Batch Acc: 76.56
[Train] Epoch: 3 [94016/620022]    Loss: 0.008732   Batch Acc: 75.00
[Train] Epoch: 3 [94080/620022]    Loss: 0.009744   Batch Acc: 73.44
[Train] Epoch: 3 [94144/620022]    Loss: 0.008444   Batch Acc: 76.56
[Train] Epoch: 3 [94208/620022]    Loss: 0.007354   Batch Acc: 84.38
[Train] Epoch: 3 [94272/620022]    Loss: 0.008565   Batch Acc: 76.56
[Train] Epoch: 3 [94336/620022]    Loss: 0.007699   Batch Acc: 78.12
[Train] Epoch: 3 [94400/620022]    Loss: 0.007151   Batch Acc: 82.81
[Train] Epoch: 3 [94464/620022]    Loss: 0.008288   Batch Acc: 75.00
[Train] Epoch: 3 [94528/620022]    Loss: 0.008092   Batch Acc: 79.69
[Train] Epoch: 3 [94592/620022]    Loss: 0.011929   Batch Acc: 71.88
[Train] Epoch: 3 [94656/620022]    Loss: 0.010750   Batch Acc: 67.19
[Train] Epoch: 3 [94720/620022]    Loss: 0.009013   Batch Acc: 79.69
[Train] Epoch: 3 [94784/620022]    Loss: 0.007580   Batch Acc: 76.56
[Train] Epoch: 3 [94848/620022]    Loss: 0.011170   Batch Acc: 73.44
[Train] Epoch: 3 [94912/620022]    Loss: 0.007989   Batch Acc: 79.69
[Train] Epoch: 3 [94976/620022]    Loss: 0.010381   Batch Acc: 70.31
[Train] Epoch: 3 [95040/620022]    Loss: 0.009504   Batch Acc: 75.00
[Train] Epoch: 3 [95104/620022]    Loss: 0.009060   Batch Acc: 78.12
[Train] Epoch: 3 [95168/620022]    Loss: 0.010057   Batch Acc: 73.44
[Train] Epoch: 3 [95232/620022]    Loss: 0.007527   Batch Acc: 78.12
[Train] Epoch: 3 [95296/620022]    Loss: 0.009621   Batch Acc: 75.00
[Train] Epoch: 3 [95360/620022]    Loss: 0.010775   Batch Acc: 68.75
[Train] Epoch: 3 [95424/620022]    Loss: 0.006368   Batch Acc: 87.50
[Train] Epoch: 3 [95488/620022]    Loss: 0.008711   Batch Acc: 81.25
[Train] Epoch: 3 [95552/620022]    Loss: 0.010630   Batch Acc: 68.75
[Train] Epoch: 3 [95616/620022]    Loss: 0.006569   Batch Acc: 82.81
[Train] Epoch: 3 [95680/620022]    Loss: 0.008583   Batch Acc: 78.12
[Train] Epoch: 3 [95744/620022]    Loss: 0.009031   Batch Acc: 73.44
[Train] Epoch: 3 [95808/620022]    Loss: 0.010032   Batch Acc: 75.00
[Train] Epoch: 3 [95872/620022]    Loss: 0.005819   Batch Acc: 89.06
[Train] Epoch: 3 [95936/620022]    Loss: 0.009824   Batch Acc: 68.75
[Train] Epoch: 3 [96000/620022]    Loss: 0.008276   Batch Acc: 73.44
[Train] Epoch: 3 [96064/620022]    Loss: 0.009281   Batch Acc: 78.12
[Train] Epoch: 3 [96128/620022]    Loss: 0.009153   Batch Acc: 76.56
[Train] Epoch: 3 [96192/620022]    Loss: 0.007445   Batch Acc: 84.38
[Train] Epoch: 3 [96256/620022]    Loss: 0.009217   Batch Acc: 70.31
[Train] Epoch: 3 [96320/620022]    Loss: 0.005446   Batch Acc: 93.75
[Train] Epoch: 3 [96384/620022]    Loss: 0.007945   Batch Acc: 79.69
[Train] Epoch: 3 [96448/620022]    Loss: 0.006875   Batch Acc: 82.81
[Train] Epoch: 3 [96512/620022]    Loss: 0.009028   Batch Acc: 78.12
[Train] Epoch: 3 [96576/620022]    Loss: 0.009672   Batch Acc: 75.00
[Train] Epoch: 3 [96640/620022]    Loss: 0.009755   Batch Acc: 75.00
[Train] Epoch: 3 [96704/620022]    Loss: 0.009293   Batch Acc: 75.00
[Train] Epoch: 3 [96768/620022]    Loss: 0.006469   Batch Acc: 82.81
[Train] Epoch: 3 [96832/620022]    Loss: 0.007391   Batch Acc: 82.81
[Train] Epoch: 3 [96896/620022]    Loss: 0.007885   Batch Acc: 79.69
[Train] Epoch: 3 [96960/620022]    Loss: 0.007419   Batch Acc: 85.94
[Train] Epoch: 3 [97024/620022]    Loss: 0.011242   Batch Acc: 71.88
[Train] Epoch: 3 [97088/620022]    Loss: 0.011125   Batch Acc: 68.75
[Train] Epoch: 3 [97152/620022]    Loss: 0.007980   Batch Acc: 81.25
[Train] Epoch: 3 [97216/620022]    Loss: 0.008427   Batch Acc: 79.69
[Train] Epoch: 3 [97280/620022]    Loss: 0.009537   Batch Acc: 81.25
[Train] Epoch: 3 [97344/620022]    Loss: 0.011065   Batch Acc: 70.31
[Train] Epoch: 3 [97408/620022]    Loss: 0.010233   Batch Acc: 79.69
[Train] Epoch: 3 [97472/620022]    Loss: 0.007697   Batch Acc: 81.25
[Train] Epoch: 3 [97536/620022]    Loss: 0.008754   Batch Acc: 79.69
[Train] Epoch: 3 [97600/620022]    Loss: 0.008900   Batch Acc: 78.12
[Train] Epoch: 3 [97664/620022]    Loss: 0.009208   Batch Acc: 78.12
[Train] Epoch: 3 [97728/620022]    Loss: 0.009083   Batch Acc: 73.44
[Train] Epoch: 3 [97792/620022]    Loss: 0.009374   Batch Acc: 73.44
[Train] Epoch: 3 [97856/620022]    Loss: 0.008551   Batch Acc: 79.69
[Train] Epoch: 3 [97920/620022]    Loss: 0.007368   Batch Acc: 82.81
[Train] Epoch: 3 [97984/620022]    Loss: 0.008153   Batch Acc: 79.69
[Train] Epoch: 3 [98048/620022]    Loss: 0.007972   Batch Acc: 81.25
[Train] Epoch: 3 [98112/620022]    Loss: 0.008208   Batch Acc: 79.69
[Train] Epoch: 3 [98176/620022]    Loss: 0.007457   Batch Acc: 78.12
[Train] Epoch: 3 [98240/620022]    Loss: 0.009886   Batch Acc: 75.00
[Train] Epoch: 3 [98304/620022]    Loss: 0.007865   Batch Acc: 84.38
[Train] Epoch: 3 [98368/620022]    Loss: 0.009035   Batch Acc: 81.25
[Train] Epoch: 3 [98432/620022]    Loss: 0.005950   Batch Acc: 85.94
[Train] Epoch: 3 [98496/620022]    Loss: 0.010676   Batch Acc: 70.31
[Train] Epoch: 3 [98560/620022]    Loss: 0.009437   Batch Acc: 71.88
[Train] Epoch: 3 [98624/620022]    Loss: 0.010020   Batch Acc: 73.44
[Train] Epoch: 3 [98688/620022]    Loss: 0.008682   Batch Acc: 79.69
[Train] Epoch: 3 [98752/620022]    Loss: 0.009287   Batch Acc: 79.69
[Train] Epoch: 3 [98816/620022]    Loss: 0.007712   Batch Acc: 81.25
[Train] Epoch: 3 [98880/620022]    Loss: 0.007225   Batch Acc: 84.38
[Train] Epoch: 3 [98944/620022]    Loss: 0.010414   Batch Acc: 75.00
[Train] Epoch: 3 [99008/620022]    Loss: 0.006624   Batch Acc: 85.94
[Train] Epoch: 3 [99072/620022]    Loss: 0.008913   Batch Acc: 78.12
[Train] Epoch: 3 [99136/620022]    Loss: 0.007200   Batch Acc: 78.12
[Train] Epoch: 3 [99200/620022]    Loss: 0.011479   Batch Acc: 70.31
[Train] Epoch: 3 [99264/620022]    Loss: 0.007873   Batch Acc: 84.38
[Train] Epoch: 3 [99328/620022]    Loss: 0.010039   Batch Acc: 75.00
[Train] Epoch: 3 [99392/620022]    Loss: 0.007131   Batch Acc: 87.50
[Train] Epoch: 3 [99456/620022]    Loss: 0.007717   Batch Acc: 78.12
[Train] Epoch: 3 [99520/620022]    Loss: 0.006455   Batch Acc: 85.94
[Train] Epoch: 3 [99584/620022]    Loss: 0.007504   Batch Acc: 81.25
[Train] Epoch: 3 [99648/620022]    Loss: 0.009740   Batch Acc: 70.31
[Train] Epoch: 3 [99712/620022]    Loss: 0.008286   Batch Acc: 81.25
[Train] Epoch: 3 [99776/620022]    Loss: 0.009143   Batch Acc: 75.00
[Train] Epoch: 3 [99840/620022]    Loss: 0.007508   Batch Acc: 81.25
[Train] Epoch: 3 [99904/620022]    Loss: 0.008755   Batch Acc: 76.56
[Train] Epoch: 3 [99968/620022]    Loss: 0.008083   Batch Acc: 78.12
[Train] Epoch: 3 [100032/620022]    Loss: 0.010072   Batch Acc: 71.88
[Train] Epoch: 3 [100096/620022]    Loss: 0.009064   Batch Acc: 81.25
[Train] Epoch: 3 [100160/620022]    Loss: 0.008319   Batch Acc: 70.31
[Train] Epoch: 3 [100224/620022]    Loss: 0.006750   Batch Acc: 82.81
[Train] Epoch: 3 [100288/620022]    Loss: 0.006153   Batch Acc: 89.06
[Train] Epoch: 3 [100352/620022]    Loss: 0.008275   Batch Acc: 79.69
[Train] Epoch: 3 [100416/620022]    Loss: 0.008779   Batch Acc: 78.12
[Train] Epoch: 3 [100480/620022]    Loss: 0.010086   Batch Acc: 70.31
[Train] Epoch: 3 [100544/620022]    Loss: 0.007323   Batch Acc: 84.38
[Train] Epoch: 3 [100608/620022]    Loss: 0.006533   Batch Acc: 85.94
[Train] Epoch: 3 [100672/620022]    Loss: 0.007729   Batch Acc: 78.12
[Train] Epoch: 3 [100736/620022]    Loss: 0.009711   Batch Acc: 71.88
[Train] Epoch: 3 [100800/620022]    Loss: 0.009817   Batch Acc: 75.00
[Train] Epoch: 3 [100864/620022]    Loss: 0.009162   Batch Acc: 79.69
[Train] Epoch: 3 [100928/620022]    Loss: 0.008048   Batch Acc: 76.56
[Train] Epoch: 3 [100992/620022]    Loss: 0.010794   Batch Acc: 68.75
[Train] Epoch: 3 [101056/620022]    Loss: 0.009495   Batch Acc: 71.88
[Train] Epoch: 3 [101120/620022]    Loss: 0.008193   Batch Acc: 79.69
[Train] Epoch: 3 [101184/620022]    Loss: 0.008573   Batch Acc: 76.56
[Train] Epoch: 3 [101248/620022]    Loss: 0.007211   Batch Acc: 81.25
[Train] Epoch: 3 [101312/620022]    Loss: 0.007461   Batch Acc: 76.56
[Train] Epoch: 3 [101376/620022]    Loss: 0.007587   Batch Acc: 76.56
[Train] Epoch: 3 [101440/620022]    Loss: 0.009273   Batch Acc: 82.81
[Train] Epoch: 3 [101504/620022]    Loss: 0.007425   Batch Acc: 82.81
[Train] Epoch: 3 [101568/620022]    Loss: 0.009797   Batch Acc: 70.31
[Train] Epoch: 3 [101632/620022]    Loss: 0.008100   Batch Acc: 81.25
[Train] Epoch: 3 [101696/620022]    Loss: 0.006977   Batch Acc: 87.50
[Train] Epoch: 3 [101760/620022]    Loss: 0.008806   Batch Acc: 82.81
[Train] Epoch: 3 [101824/620022]    Loss: 0.008468   Batch Acc: 76.56
[Train] Epoch: 3 [101888/620022]    Loss: 0.009830   Batch Acc: 68.75
[Train] Epoch: 3 [101952/620022]    Loss: 0.008947   Batch Acc: 76.56
[Train] Epoch: 3 [102016/620022]    Loss: 0.009938   Batch Acc: 70.31
[Train] Epoch: 3 [102080/620022]    Loss: 0.006758   Batch Acc: 84.38
[Train] Epoch: 3 [102144/620022]    Loss: 0.008294   Batch Acc: 81.25
[Train] Epoch: 3 [102208/620022]    Loss: 0.008113   Batch Acc: 75.00
[Train] Epoch: 3 [102272/620022]    Loss: 0.007248   Batch Acc: 79.69
[Train] Epoch: 3 [102336/620022]    Loss: 0.009267   Batch Acc: 76.56
[Train] Epoch: 3 [102400/620022]    Loss: 0.009137   Batch Acc: 76.56
[Train] Epoch: 3 [102464/620022]    Loss: 0.007338   Batch Acc: 76.56
[Train] Epoch: 3 [102528/620022]    Loss: 0.010685   Batch Acc: 68.75
[Train] Epoch: 3 [102592/620022]    Loss: 0.008005   Batch Acc: 75.00
[Train] Epoch: 3 [102656/620022]    Loss: 0.008756   Batch Acc: 75.00
[Train] Epoch: 3 [102720/620022]    Loss: 0.008530   Batch Acc: 76.56
[Train] Epoch: 3 [102784/620022]    Loss: 0.007660   Batch Acc: 79.69
[Train] Epoch: 3 [102848/620022]    Loss: 0.008488   Batch Acc: 76.56
[Train] Epoch: 3 [102912/620022]    Loss: 0.008008   Batch Acc: 76.56
[Train] Epoch: 3 [102976/620022]    Loss: 0.009337   Batch Acc: 73.44
[Train] Epoch: 3 [103040/620022]    Loss: 0.008234   Batch Acc: 78.12
[Train] Epoch: 3 [103104/620022]    Loss: 0.008466   Batch Acc: 73.44
[Train] Epoch: 3 [103168/620022]    Loss: 0.007451   Batch Acc: 76.56
[Train] Epoch: 3 [103232/620022]    Loss: 0.008670   Batch Acc: 81.25
[Train] Epoch: 3 [103296/620022]    Loss: 0.007557   Batch Acc: 82.81
[Train] Epoch: 3 [103360/620022]    Loss: 0.007950   Batch Acc: 76.56
[Train] Epoch: 3 [103424/620022]    Loss: 0.009504   Batch Acc: 73.44
[Train] Epoch: 3 [103488/620022]    Loss: 0.009189   Batch Acc: 67.19
[Train] Epoch: 3 [103552/620022]    Loss: 0.011108   Batch Acc: 71.88
[Train] Epoch: 3 [103616/620022]    Loss: 0.009790   Batch Acc: 78.12
[Train] Epoch: 3 [103680/620022]    Loss: 0.007823   Batch Acc: 79.69
[Train] Epoch: 3 [103744/620022]    Loss: 0.009171   Batch Acc: 75.00
[Train] Epoch: 3 [103808/620022]    Loss: 0.008230   Batch Acc: 78.12
[Train] Epoch: 3 [103872/620022]    Loss: 0.009269   Batch Acc: 76.56
[Train] Epoch: 3 [103936/620022]    Loss: 0.008653   Batch Acc: 82.81
[Train] Epoch: 3 [104000/620022]    Loss: 0.009625   Batch Acc: 75.00
[Train] Epoch: 3 [104064/620022]    Loss: 0.007452   Batch Acc: 81.25
[Train] Epoch: 3 [104128/620022]    Loss: 0.006786   Batch Acc: 81.25
[Train] Epoch: 3 [104192/620022]    Loss: 0.009373   Batch Acc: 73.44
[Train] Epoch: 3 [104256/620022]    Loss: 0.009822   Batch Acc: 78.12
[Train] Epoch: 3 [104320/620022]    Loss: 0.008378   Batch Acc: 84.38
[Train] Epoch: 3 [104384/620022]    Loss: 0.009789   Batch Acc: 73.44
[Train] Epoch: 3 [104448/620022]    Loss: 0.008754   Batch Acc: 81.25
[Train] Epoch: 3 [104512/620022]    Loss: 0.010842   Batch Acc: 73.44
[Train] Epoch: 3 [104576/620022]    Loss: 0.007742   Batch Acc: 79.69
[Train] Epoch: 3 [104640/620022]    Loss: 0.011391   Batch Acc: 76.56
[Train] Epoch: 3 [104704/620022]    Loss: 0.008869   Batch Acc: 76.56
[Train] Epoch: 3 [104768/620022]    Loss: 0.008034   Batch Acc: 79.69
[Train] Epoch: 3 [104832/620022]    Loss: 0.007704   Batch Acc: 82.81
[Train] Epoch: 3 [104896/620022]    Loss: 0.006261   Batch Acc: 89.06
[Train] Epoch: 3 [104960/620022]    Loss: 0.007666   Batch Acc: 78.12
[Train] Epoch: 3 [105024/620022]    Loss: 0.007505   Batch Acc: 81.25
[Train] Epoch: 3 [105088/620022]    Loss: 0.008441   Batch Acc: 81.25
[Train] Epoch: 3 [105152/620022]    Loss: 0.008082   Batch Acc: 79.69
[Train] Epoch: 3 [105216/620022]    Loss: 0.009533   Batch Acc: 65.62
[Train] Epoch: 3 [105280/620022]    Loss: 0.009605   Batch Acc: 73.44
[Train] Epoch: 3 [105344/620022]    Loss: 0.009299   Batch Acc: 78.12
[Train] Epoch: 3 [105408/620022]    Loss: 0.008504   Batch Acc: 78.12
[Train] Epoch: 3 [105472/620022]    Loss: 0.006750   Batch Acc: 84.38
[Train] Epoch: 3 [105536/620022]    Loss: 0.010014   Batch Acc: 75.00
[Train] Epoch: 3 [105600/620022]    Loss: 0.008270   Batch Acc: 78.12
[Train] Epoch: 3 [105664/620022]    Loss: 0.009345   Batch Acc: 75.00
[Train] Epoch: 3 [105728/620022]    Loss: 0.007915   Batch Acc: 79.69
[Train] Epoch: 3 [105792/620022]    Loss: 0.009007   Batch Acc: 78.12
[Train] Epoch: 3 [105856/620022]    Loss: 0.008488   Batch Acc: 79.69
[Train] Epoch: 3 [105920/620022]    Loss: 0.007940   Batch Acc: 82.81
[Train] Epoch: 3 [105984/620022]    Loss: 0.009352   Batch Acc: 76.56
[Train] Epoch: 3 [106048/620022]    Loss: 0.008344   Batch Acc: 78.12
[Train] Epoch: 3 [106112/620022]    Loss: 0.009005   Batch Acc: 78.12
[Train] Epoch: 3 [106176/620022]    Loss: 0.011126   Batch Acc: 68.75
[Train] Epoch: 3 [106240/620022]    Loss: 0.007927   Batch Acc: 84.38
[Train] Epoch: 3 [106304/620022]    Loss: 0.006313   Batch Acc: 85.94
[Train] Epoch: 3 [106368/620022]    Loss: 0.008749   Batch Acc: 79.69
[Train] Epoch: 3 [106432/620022]    Loss: 0.009625   Batch Acc: 73.44
[Train] Epoch: 3 [106496/620022]    Loss: 0.008872   Batch Acc: 76.56
[Train] Epoch: 3 [106560/620022]    Loss: 0.009806   Batch Acc: 76.56
[Train] Epoch: 3 [106624/620022]    Loss: 0.009373   Batch Acc: 79.69
[Train] Epoch: 3 [106688/620022]    Loss: 0.009192   Batch Acc: 78.12
[Train] Epoch: 3 [106752/620022]    Loss: 0.007762   Batch Acc: 84.38
[Train] Epoch: 3 [106816/620022]    Loss: 0.007186   Batch Acc: 81.25
[Train] Epoch: 3 [106880/620022]    Loss: 0.007788   Batch Acc: 82.81
[Train] Epoch: 3 [106944/620022]    Loss: 0.008287   Batch Acc: 75.00
[Train] Epoch: 3 [107008/620022]    Loss: 0.011540   Batch Acc: 67.19
[Train] Epoch: 3 [107072/620022]    Loss: 0.008337   Batch Acc: 81.25
[Train] Epoch: 3 [107136/620022]    Loss: 0.009455   Batch Acc: 79.69
[Train] Epoch: 3 [107200/620022]    Loss: 0.007353   Batch Acc: 78.12
[Train] Epoch: 3 [107264/620022]    Loss: 0.009748   Batch Acc: 75.00
[Train] Epoch: 3 [107328/620022]    Loss: 0.008900   Batch Acc: 76.56
[Train] Epoch: 3 [107392/620022]    Loss: 0.008382   Batch Acc: 76.56
[Train] Epoch: 3 [107456/620022]    Loss: 0.008171   Batch Acc: 78.12
[Train] Epoch: 3 [107520/620022]    Loss: 0.008148   Batch Acc: 79.69
[Train] Epoch: 3 [107584/620022]    Loss: 0.010103   Batch Acc: 70.31
[Train] Epoch: 3 [107648/620022]    Loss: 0.008065   Batch Acc: 79.69
[Train] Epoch: 3 [107712/620022]    Loss: 0.009919   Batch Acc: 78.12
[Train] Epoch: 3 [107776/620022]    Loss: 0.010377   Batch Acc: 67.19
[Train] Epoch: 3 [107840/620022]    Loss: 0.008082   Batch Acc: 79.69
[Train] Epoch: 3 [107904/620022]    Loss: 0.010366   Batch Acc: 75.00
[Train] Epoch: 3 [107968/620022]    Loss: 0.009723   Batch Acc: 73.44
[Train] Epoch: 3 [108032/620022]    Loss: 0.008090   Batch Acc: 75.00
[Train] Epoch: 3 [108096/620022]    Loss: 0.007912   Batch Acc: 78.12
[Train] Epoch: 3 [108160/620022]    Loss: 0.008310   Batch Acc: 82.81
[Train] Epoch: 3 [108224/620022]    Loss: 0.006440   Batch Acc: 87.50
[Train] Epoch: 3 [108288/620022]    Loss: 0.008671   Batch Acc: 78.12
[Train] Epoch: 3 [108352/620022]    Loss: 0.008221   Batch Acc: 79.69
[Train] Epoch: 3 [108416/620022]    Loss: 0.008372   Batch Acc: 82.81
[Train] Epoch: 3 [108480/620022]    Loss: 0.008656   Batch Acc: 79.69
[Train] Epoch: 3 [108544/620022]    Loss: 0.007629   Batch Acc: 82.81
[Train] Epoch: 3 [108608/620022]    Loss: 0.007801   Batch Acc: 82.81
[Train] Epoch: 3 [108672/620022]    Loss: 0.008746   Batch Acc: 78.12
[Train] Epoch: 3 [108736/620022]    Loss: 0.006519   Batch Acc: 81.25
[Train] Epoch: 3 [108800/620022]    Loss: 0.008853   Batch Acc: 78.12
[Train] Epoch: 3 [108864/620022]    Loss: 0.010786   Batch Acc: 71.88
[Train] Epoch: 3 [108928/620022]    Loss: 0.008926   Batch Acc: 75.00
[Train] Epoch: 3 [108992/620022]    Loss: 0.010041   Batch Acc: 71.88
[Train] Epoch: 3 [109056/620022]    Loss: 0.008534   Batch Acc: 79.69
[Train] Epoch: 3 [109120/620022]    Loss: 0.009355   Batch Acc: 71.88
[Train] Epoch: 3 [109184/620022]    Loss: 0.007953   Batch Acc: 81.25
[Train] Epoch: 3 [109248/620022]    Loss: 0.008623   Batch Acc: 75.00
[Train] Epoch: 3 [109312/620022]    Loss: 0.007497   Batch Acc: 81.25
[Train] Epoch: 3 [109376/620022]    Loss: 0.009952   Batch Acc: 70.31
[Train] Epoch: 3 [109440/620022]    Loss: 0.010699   Batch Acc: 64.06
[Train] Epoch: 3 [109504/620022]    Loss: 0.010224   Batch Acc: 71.88
[Train] Epoch: 3 [109568/620022]    Loss: 0.009578   Batch Acc: 81.25
[Train] Epoch: 3 [109632/620022]    Loss: 0.006824   Batch Acc: 87.50
[Train] Epoch: 3 [109696/620022]    Loss: 0.008971   Batch Acc: 75.00
[Train] Epoch: 3 [109760/620022]    Loss: 0.010330   Batch Acc: 75.00
[Train] Epoch: 3 [109824/620022]    Loss: 0.007672   Batch Acc: 78.12
[Train] Epoch: 3 [109888/620022]    Loss: 0.006737   Batch Acc: 82.81
[Train] Epoch: 3 [109952/620022]    Loss: 0.007349   Batch Acc: 82.81
[Train] Epoch: 3 [110016/620022]    Loss: 0.009423   Batch Acc: 79.69
[Train] Epoch: 3 [110080/620022]    Loss: 0.007158   Batch Acc: 87.50
[Train] Epoch: 3 [110144/620022]    Loss: 0.008202   Batch Acc: 79.69
[Train] Epoch: 3 [110208/620022]    Loss: 0.007946   Batch Acc: 79.69
[Train] Epoch: 3 [110272/620022]    Loss: 0.008749   Batch Acc: 78.12
[Train] Epoch: 3 [110336/620022]    Loss: 0.008328   Batch Acc: 76.56
[Train] Epoch: 3 [110400/620022]    Loss: 0.009940   Batch Acc: 65.62
[Train] Epoch: 3 [110464/620022]    Loss: 0.007617   Batch Acc: 76.56
[Train] Epoch: 3 [110528/620022]    Loss: 0.008096   Batch Acc: 78.12
[Train] Epoch: 3 [110592/620022]    Loss: 0.008801   Batch Acc: 78.12
[Train] Epoch: 3 [110656/620022]    Loss: 0.011342   Batch Acc: 67.19
[Train] Epoch: 3 [110720/620022]    Loss: 0.007651   Batch Acc: 79.69
[Train] Epoch: 3 [110784/620022]    Loss: 0.007341   Batch Acc: 85.94
[Train] Epoch: 3 [110848/620022]    Loss: 0.006609   Batch Acc: 84.38
[Train] Epoch: 3 [110912/620022]    Loss: 0.008690   Batch Acc: 79.69
[Train] Epoch: 3 [110976/620022]    Loss: 0.009645   Batch Acc: 78.12
[Train] Epoch: 3 [111040/620022]    Loss: 0.008298   Batch Acc: 78.12
[Train] Epoch: 3 [111104/620022]    Loss: 0.008388   Batch Acc: 79.69
[Train] Epoch: 3 [111168/620022]    Loss: 0.008599   Batch Acc: 78.12
[Train] Epoch: 3 [111232/620022]    Loss: 0.010817   Batch Acc: 67.19
[Train] Epoch: 3 [111296/620022]    Loss: 0.009116   Batch Acc: 73.44
[Train] Epoch: 3 [111360/620022]    Loss: 0.009635   Batch Acc: 75.00
[Train] Epoch: 3 [111424/620022]    Loss: 0.007295   Batch Acc: 81.25
[Train] Epoch: 3 [111488/620022]    Loss: 0.010149   Batch Acc: 71.88
[Train] Epoch: 3 [111552/620022]    Loss: 0.006638   Batch Acc: 84.38
[Train] Epoch: 3 [111616/620022]    Loss: 0.010816   Batch Acc: 71.88
[Train] Epoch: 3 [111680/620022]    Loss: 0.008248   Batch Acc: 81.25
[Train] Epoch: 3 [111744/620022]    Loss: 0.007564   Batch Acc: 85.94
[Train] Epoch: 3 [111808/620022]    Loss: 0.008988   Batch Acc: 76.56
[Train] Epoch: 3 [111872/620022]    Loss: 0.008005   Batch Acc: 81.25
[Train] Epoch: 3 [111936/620022]    Loss: 0.008631   Batch Acc: 76.56
[Train] Epoch: 3 [112000/620022]    Loss: 0.007856   Batch Acc: 82.81
[Train] Epoch: 3 [112064/620022]    Loss: 0.010105   Batch Acc: 75.00
[Train] Epoch: 3 [112128/620022]    Loss: 0.008515   Batch Acc: 76.56
[Train] Epoch: 3 [112192/620022]    Loss: 0.009725   Batch Acc: 68.75
[Train] Epoch: 3 [112256/620022]    Loss: 0.012074   Batch Acc: 59.38
[Train] Epoch: 3 [112320/620022]    Loss: 0.006606   Batch Acc: 85.94
[Train] Epoch: 3 [112384/620022]    Loss: 0.008975   Batch Acc: 78.12
[Train] Epoch: 3 [112448/620022]    Loss: 0.008351   Batch Acc: 79.69
[Train] Epoch: 3 [112512/620022]    Loss: 0.007945   Batch Acc: 76.56
[Train] Epoch: 3 [112576/620022]    Loss: 0.007124   Batch Acc: 81.25
[Train] Epoch: 3 [112640/620022]    Loss: 0.006961   Batch Acc: 82.81
[Train] Epoch: 3 [112704/620022]    Loss: 0.007984   Batch Acc: 79.69
[Train] Epoch: 3 [112768/620022]    Loss: 0.009774   Batch Acc: 73.44
[Train] Epoch: 3 [112832/620022]    Loss: 0.008346   Batch Acc: 78.12
[Train] Epoch: 3 [112896/620022]    Loss: 0.010342   Batch Acc: 67.19
[Train] Epoch: 3 [112960/620022]    Loss: 0.009043   Batch Acc: 76.56
[Train] Epoch: 3 [113024/620022]    Loss: 0.007663   Batch Acc: 78.12
[Train] Epoch: 3 [113088/620022]    Loss: 0.010640   Batch Acc: 76.56
[Train] Epoch: 3 [113152/620022]    Loss: 0.008843   Batch Acc: 76.56
[Train] Epoch: 3 [113216/620022]    Loss: 0.008300   Batch Acc: 79.69
[Train] Epoch: 3 [113280/620022]    Loss: 0.007323   Batch Acc: 82.81
[Train] Epoch: 3 [113344/620022]    Loss: 0.008178   Batch Acc: 76.56
[Train] Epoch: 3 [113408/620022]    Loss: 0.009302   Batch Acc: 75.00
[Train] Epoch: 3 [113472/620022]    Loss: 0.007323   Batch Acc: 79.69
[Train] Epoch: 3 [113536/620022]    Loss: 0.010304   Batch Acc: 71.88
[Train] Epoch: 3 [113600/620022]    Loss: 0.009557   Batch Acc: 79.69
[Train] Epoch: 3 [113664/620022]    Loss: 0.009909   Batch Acc: 79.69
[Train] Epoch: 3 [113728/620022]    Loss: 0.008091   Batch Acc: 76.56
[Train] Epoch: 3 [113792/620022]    Loss: 0.008183   Batch Acc: 82.81
[Train] Epoch: 3 [113856/620022]    Loss: 0.008756   Batch Acc: 75.00
[Train] Epoch: 3 [113920/620022]    Loss: 0.007676   Batch Acc: 81.25
[Train] Epoch: 3 [113984/620022]    Loss: 0.009865   Batch Acc: 76.56
[Train] Epoch: 3 [114048/620022]    Loss: 0.009287   Batch Acc: 65.62
[Train] Epoch: 3 [114112/620022]    Loss: 0.010229   Batch Acc: 71.88
[Train] Epoch: 3 [114176/620022]    Loss: 0.008346   Batch Acc: 79.69
[Train] Epoch: 3 [114240/620022]    Loss: 0.008707   Batch Acc: 79.69
[Train] Epoch: 3 [114304/620022]    Loss: 0.007494   Batch Acc: 87.50
[Train] Epoch: 3 [114368/620022]    Loss: 0.006780   Batch Acc: 87.50
[Train] Epoch: 3 [114432/620022]    Loss: 0.007975   Batch Acc: 84.38
[Train] Epoch: 3 [114496/620022]    Loss: 0.008421   Batch Acc: 81.25
[Train] Epoch: 3 [114560/620022]    Loss: 0.007580   Batch Acc: 79.69
[Train] Epoch: 3 [114624/620022]    Loss: 0.007116   Batch Acc: 81.25
[Train] Epoch: 3 [114688/620022]    Loss: 0.010169   Batch Acc: 71.88
[Train] Epoch: 3 [114752/620022]    Loss: 0.007614   Batch Acc: 85.94
[Train] Epoch: 3 [114816/620022]    Loss: 0.007949   Batch Acc: 81.25
[Train] Epoch: 3 [114880/620022]    Loss: 0.007570   Batch Acc: 82.81
[Train] Epoch: 3 [114944/620022]    Loss: 0.006752   Batch Acc: 79.69
[Train] Epoch: 3 [115008/620022]    Loss: 0.007953   Batch Acc: 82.81
[Train] Epoch: 3 [115072/620022]    Loss: 0.008836   Batch Acc: 79.69
[Train] Epoch: 3 [115136/620022]    Loss: 0.006015   Batch Acc: 89.06
[Train] Epoch: 3 [115200/620022]    Loss: 0.008068   Batch Acc: 82.81
[Train] Epoch: 3 [115264/620022]    Loss: 0.008390   Batch Acc: 79.69
[Train] Epoch: 3 [115328/620022]    Loss: 0.009579   Batch Acc: 73.44
[Train] Epoch: 3 [115392/620022]    Loss: 0.010581   Batch Acc: 70.31
[Train] Epoch: 3 [115456/620022]    Loss: 0.009939   Batch Acc: 75.00
[Train] Epoch: 3 [115520/620022]    Loss: 0.008710   Batch Acc: 78.12
[Train] Epoch: 3 [115584/620022]    Loss: 0.008912   Batch Acc: 73.44
[Train] Epoch: 3 [115648/620022]    Loss: 0.008960   Batch Acc: 76.56
[Train] Epoch: 3 [115712/620022]    Loss: 0.008726   Batch Acc: 78.12
[Train] Epoch: 3 [115776/620022]    Loss: 0.008067   Batch Acc: 78.12
[Train] Epoch: 3 [115840/620022]    Loss: 0.008967   Batch Acc: 82.81
[Train] Epoch: 3 [115904/620022]    Loss: 0.007204   Batch Acc: 84.38
[Train] Epoch: 3 [115968/620022]    Loss: 0.008836   Batch Acc: 71.88
[Train] Epoch: 3 [116032/620022]    Loss: 0.010386   Batch Acc: 73.44
[Train] Epoch: 3 [116096/620022]    Loss: 0.008905   Batch Acc: 75.00
[Train] Epoch: 3 [116160/620022]    Loss: 0.009093   Batch Acc: 81.25
[Train] Epoch: 3 [116224/620022]    Loss: 0.008673   Batch Acc: 82.81
[Train] Epoch: 3 [116288/620022]    Loss: 0.006128   Batch Acc: 87.50
[Train] Epoch: 3 [116352/620022]    Loss: 0.007654   Batch Acc: 79.69
[Train] Epoch: 3 [116416/620022]    Loss: 0.009267   Batch Acc: 79.69
[Train] Epoch: 3 [116480/620022]    Loss: 0.007912   Batch Acc: 73.44
[Train] Epoch: 3 [116544/620022]    Loss: 0.008546   Batch Acc: 79.69
[Train] Epoch: 3 [116608/620022]    Loss: 0.008276   Batch Acc: 76.56
[Train] Epoch: 3 [116672/620022]    Loss: 0.008886   Batch Acc: 81.25
[Train] Epoch: 3 [116736/620022]    Loss: 0.009003   Batch Acc: 76.56
[Train] Epoch: 3 [116800/620022]    Loss: 0.006460   Batch Acc: 87.50
[Train] Epoch: 3 [116864/620022]    Loss: 0.006534   Batch Acc: 81.25
[Train] Epoch: 3 [116928/620022]    Loss: 0.005237   Batch Acc: 89.06
[Train] Epoch: 3 [116992/620022]    Loss: 0.006626   Batch Acc: 79.69
[Train] Epoch: 3 [117056/620022]    Loss: 0.006823   Batch Acc: 84.38
[Train] Epoch: 3 [117120/620022]    Loss: 0.009261   Batch Acc: 76.56
[Train] Epoch: 3 [117184/620022]    Loss: 0.009400   Batch Acc: 75.00
[Train] Epoch: 3 [117248/620022]    Loss: 0.009718   Batch Acc: 73.44
[Train] Epoch: 3 [117312/620022]    Loss: 0.009073   Batch Acc: 81.25
[Train] Epoch: 3 [117376/620022]    Loss: 0.010400   Batch Acc: 75.00
[Train] Epoch: 3 [117440/620022]    Loss: 0.005831   Batch Acc: 85.94
[Train] Epoch: 3 [117504/620022]    Loss: 0.007966   Batch Acc: 81.25
[Train] Epoch: 3 [117568/620022]    Loss: 0.006818   Batch Acc: 76.56
[Train] Epoch: 3 [117632/620022]    Loss: 0.007549   Batch Acc: 76.56
[Train] Epoch: 3 [117696/620022]    Loss: 0.006911   Batch Acc: 82.81
[Train] Epoch: 3 [117760/620022]    Loss: 0.010515   Batch Acc: 76.56
[Train] Epoch: 3 [117824/620022]    Loss: 0.007959   Batch Acc: 79.69
[Train] Epoch: 3 [117888/620022]    Loss: 0.008189   Batch Acc: 82.81
[Train] Epoch: 3 [117952/620022]    Loss: 0.011599   Batch Acc: 67.19
[Train] Epoch: 3 [118016/620022]    Loss: 0.007289   Batch Acc: 79.69
[Train] Epoch: 3 [118080/620022]    Loss: 0.007667   Batch Acc: 78.12
[Train] Epoch: 3 [118144/620022]    Loss: 0.006555   Batch Acc: 90.62
[Train] Epoch: 3 [118208/620022]    Loss: 0.006823   Batch Acc: 87.50
[Train] Epoch: 3 [118272/620022]    Loss: 0.007295   Batch Acc: 84.38
[Train] Epoch: 3 [118336/620022]    Loss: 0.010123   Batch Acc: 75.00
[Train] Epoch: 3 [118400/620022]    Loss: 0.008251   Batch Acc: 76.56
[Train] Epoch: 3 [118464/620022]    Loss: 0.005737   Batch Acc: 87.50
[Train] Epoch: 3 [118528/620022]    Loss: 0.008119   Batch Acc: 76.56
[Train] Epoch: 3 [118592/620022]    Loss: 0.008359   Batch Acc: 79.69
[Train] Epoch: 3 [118656/620022]    Loss: 0.009317   Batch Acc: 76.56
[Train] Epoch: 3 [118720/620022]    Loss: 0.006585   Batch Acc: 81.25
[Train] Epoch: 3 [118784/620022]    Loss: 0.009745   Batch Acc: 70.31
[Train] Epoch: 3 [118848/620022]    Loss: 0.009840   Batch Acc: 73.44
[Train] Epoch: 3 [118912/620022]    Loss: 0.008588   Batch Acc: 78.12
[Train] Epoch: 3 [118976/620022]    Loss: 0.007824   Batch Acc: 82.81
[Train] Epoch: 3 [119040/620022]    Loss: 0.005198   Batch Acc: 95.31
[Train] Epoch: 3 [119104/620022]    Loss: 0.007049   Batch Acc: 82.81
[Train] Epoch: 3 [119168/620022]    Loss: 0.009285   Batch Acc: 75.00
[Train] Epoch: 3 [119232/620022]    Loss: 0.007010   Batch Acc: 82.81
[Train] Epoch: 3 [119296/620022]    Loss: 0.007396   Batch Acc: 84.38
[Train] Epoch: 3 [119360/620022]    Loss: 0.006477   Batch Acc: 87.50
[Train] Epoch: 3 [119424/620022]    Loss: 0.008754   Batch Acc: 76.56
[Train] Epoch: 3 [119488/620022]    Loss: 0.006174   Batch Acc: 82.81
[Train] Epoch: 3 [119552/620022]    Loss: 0.008413   Batch Acc: 78.12
[Train] Epoch: 3 [119616/620022]    Loss: 0.006683   Batch Acc: 82.81
[Train] Epoch: 3 [119680/620022]    Loss: 0.007846   Batch Acc: 81.25
[Train] Epoch: 3 [119744/620022]    Loss: 0.008107   Batch Acc: 81.25
[Train] Epoch: 3 [119808/620022]    Loss: 0.009417   Batch Acc: 73.44
[Train] Epoch: 3 [119872/620022]    Loss: 0.008453   Batch Acc: 76.56
[Train] Epoch: 3 [119936/620022]    Loss: 0.010079   Batch Acc: 75.00
[Train] Epoch: 3 [120000/620022]    Loss: 0.010748   Batch Acc: 71.88
[Train] Epoch: 3 [120064/620022]    Loss: 0.010483   Batch Acc: 64.06
[Train] Epoch: 3 [120128/620022]    Loss: 0.010735   Batch Acc: 65.62
[Train] Epoch: 3 [120192/620022]    Loss: 0.008639   Batch Acc: 70.31
[Train] Epoch: 3 [120256/620022]    Loss: 0.009080   Batch Acc: 78.12
[Train] Epoch: 3 [120320/620022]    Loss: 0.008557   Batch Acc: 76.56
[Train] Epoch: 3 [120384/620022]    Loss: 0.008962   Batch Acc: 84.38
[Train] Epoch: 3 [120448/620022]    Loss: 0.008584   Batch Acc: 76.56
[Train] Epoch: 3 [120512/620022]    Loss: 0.007924   Batch Acc: 81.25
[Train] Epoch: 3 [120576/620022]    Loss: 0.007646   Batch Acc: 78.12
[Train] Epoch: 3 [120640/620022]    Loss: 0.011898   Batch Acc: 67.19
[Train] Epoch: 3 [120704/620022]    Loss: 0.009589   Batch Acc: 73.44
[Train] Epoch: 3 [120768/620022]    Loss: 0.008235   Batch Acc: 73.44
[Train] Epoch: 3 [120832/620022]    Loss: 0.008529   Batch Acc: 76.56
[Train] Epoch: 3 [120896/620022]    Loss: 0.010428   Batch Acc: 65.62
[Train] Epoch: 3 [120960/620022]    Loss: 0.007576   Batch Acc: 75.00
[Train] Epoch: 3 [121024/620022]    Loss: 0.008276   Batch Acc: 79.69
[Train] Epoch: 3 [121088/620022]    Loss: 0.007904   Batch Acc: 84.38
[Train] Epoch: 3 [121152/620022]    Loss: 0.010407   Batch Acc: 73.44
[Train] Epoch: 3 [121216/620022]    Loss: 0.011156   Batch Acc: 70.31
[Train] Epoch: 3 [121280/620022]    Loss: 0.009310   Batch Acc: 71.88
[Train] Epoch: 3 [121344/620022]    Loss: 0.007564   Batch Acc: 81.25
[Train] Epoch: 3 [121408/620022]    Loss: 0.008326   Batch Acc: 81.25
[Train] Epoch: 3 [121472/620022]    Loss: 0.008399   Batch Acc: 79.69
[Train] Epoch: 3 [121536/620022]    Loss: 0.005244   Batch Acc: 90.62
[Train] Epoch: 3 [121600/620022]    Loss: 0.006422   Batch Acc: 85.94
[Train] Epoch: 3 [121664/620022]    Loss: 0.010051   Batch Acc: 73.44
[Train] Epoch: 3 [121728/620022]    Loss: 0.007283   Batch Acc: 82.81
[Train] Epoch: 3 [121792/620022]    Loss: 0.010330   Batch Acc: 73.44
[Train] Epoch: 3 [121856/620022]    Loss: 0.009726   Batch Acc: 75.00
[Train] Epoch: 3 [121920/620022]    Loss: 0.007168   Batch Acc: 81.25
[Train] Epoch: 3 [121984/620022]    Loss: 0.006488   Batch Acc: 85.94
[Train] Epoch: 3 [122048/620022]    Loss: 0.007570   Batch Acc: 79.69
[Train] Epoch: 3 [122112/620022]    Loss: 0.009626   Batch Acc: 71.88
[Train] Epoch: 3 [122176/620022]    Loss: 0.008425   Batch Acc: 76.56
[Train] Epoch: 3 [122240/620022]    Loss: 0.010914   Batch Acc: 68.75
[Train] Epoch: 3 [122304/620022]    Loss: 0.010167   Batch Acc: 71.88
[Train] Epoch: 3 [122368/620022]    Loss: 0.009716   Batch Acc: 81.25
[Train] Epoch: 3 [122432/620022]    Loss: 0.011413   Batch Acc: 70.31
[Train] Epoch: 3 [122496/620022]    Loss: 0.009449   Batch Acc: 73.44
[Train] Epoch: 3 [122560/620022]    Loss: 0.007586   Batch Acc: 82.81
[Train] Epoch: 3 [122624/620022]    Loss: 0.008787   Batch Acc: 79.69
[Train] Epoch: 3 [122688/620022]    Loss: 0.009259   Batch Acc: 76.56
[Train] Epoch: 3 [122752/620022]    Loss: 0.009571   Batch Acc: 71.88
[Train] Epoch: 3 [122816/620022]    Loss: 0.008317   Batch Acc: 82.81
[Train] Epoch: 3 [122880/620022]    Loss: 0.012202   Batch Acc: 67.19
[Train] Epoch: 3 [122944/620022]    Loss: 0.008320   Batch Acc: 79.69
[Train] Epoch: 3 [123008/620022]    Loss: 0.009607   Batch Acc: 75.00
[Train] Epoch: 3 [123072/620022]    Loss: 0.008494   Batch Acc: 79.69
[Train] Epoch: 3 [123136/620022]    Loss: 0.008718   Batch Acc: 75.00
[Train] Epoch: 3 [123200/620022]    Loss: 0.006076   Batch Acc: 85.94
[Train] Epoch: 3 [123264/620022]    Loss: 0.007362   Batch Acc: 79.69
[Train] Epoch: 3 [123328/620022]    Loss: 0.008739   Batch Acc: 71.88
[Train] Epoch: 3 [123392/620022]    Loss: 0.010632   Batch Acc: 76.56
[Train] Epoch: 3 [123456/620022]    Loss: 0.009979   Batch Acc: 75.00
[Train] Epoch: 3 [123520/620022]    Loss: 0.009167   Batch Acc: 73.44
[Train] Epoch: 3 [123584/620022]    Loss: 0.008895   Batch Acc: 78.12
[Train] Epoch: 3 [123648/620022]    Loss: 0.010080   Batch Acc: 75.00
[Train] Epoch: 3 [123712/620022]    Loss: 0.008575   Batch Acc: 75.00
[Train] Epoch: 3 [123776/620022]    Loss: 0.008206   Batch Acc: 81.25
[Train] Epoch: 3 [123840/620022]    Loss: 0.008514   Batch Acc: 79.69
[Train] Epoch: 3 [123904/620022]    Loss: 0.008439   Batch Acc: 78.12
[Train] Epoch: 3 [123968/620022]    Loss: 0.009456   Batch Acc: 70.31
[Train] Epoch: 3 [124032/620022]    Loss: 0.010890   Batch Acc: 78.12
[Train] Epoch: 3 [124096/620022]    Loss: 0.010238   Batch Acc: 73.44
[Train] Epoch: 3 [124160/620022]    Loss: 0.009289   Batch Acc: 75.00
[Train] Epoch: 3 [124224/620022]    Loss: 0.007865   Batch Acc: 81.25
[Train] Epoch: 3 [124288/620022]    Loss: 0.010076   Batch Acc: 65.62
[Train] Epoch: 3 [124352/620022]    Loss: 0.007220   Batch Acc: 84.38
[Train] Epoch: 3 [124416/620022]    Loss: 0.007040   Batch Acc: 82.81
[Train] Epoch: 3 [124480/620022]    Loss: 0.008154   Batch Acc: 81.25
[Train] Epoch: 3 [124544/620022]    Loss: 0.009187   Batch Acc: 76.56
[Train] Epoch: 3 [124608/620022]    Loss: 0.009547   Batch Acc: 71.88
[Train] Epoch: 3 [124672/620022]    Loss: 0.009565   Batch Acc: 71.88
[Train] Epoch: 3 [124736/620022]    Loss: 0.007563   Batch Acc: 84.38
[Train] Epoch: 3 [124800/620022]    Loss: 0.009383   Batch Acc: 75.00
[Train] Epoch: 3 [124864/620022]    Loss: 0.006828   Batch Acc: 82.81
[Train] Epoch: 3 [124928/620022]    Loss: 0.008581   Batch Acc: 81.25
[Train] Epoch: 3 [124992/620022]    Loss: 0.009033   Batch Acc: 81.25
[Train] Epoch: 3 [125056/620022]    Loss: 0.008641   Batch Acc: 79.69
[Train] Epoch: 3 [125120/620022]    Loss: 0.007362   Batch Acc: 84.38
[Train] Epoch: 3 [125184/620022]    Loss: 0.006721   Batch Acc: 81.25
[Train] Epoch: 3 [125248/620022]    Loss: 0.008642   Batch Acc: 78.12
[Train] Epoch: 3 [125312/620022]    Loss: 0.006933   Batch Acc: 84.38
[Train] Epoch: 3 [125376/620022]    Loss: 0.008128   Batch Acc: 78.12
[Train] Epoch: 3 [125440/620022]    Loss: 0.011543   Batch Acc: 70.31
[Train] Epoch: 3 [125504/620022]    Loss: 0.007242   Batch Acc: 81.25
[Train] Epoch: 3 [125568/620022]    Loss: 0.007789   Batch Acc: 76.56
[Train] Epoch: 3 [125632/620022]    Loss: 0.009508   Batch Acc: 76.56
[Train] Epoch: 3 [125696/620022]    Loss: 0.011502   Batch Acc: 67.19
[Train] Epoch: 3 [125760/620022]    Loss: 0.007063   Batch Acc: 76.56
[Train] Epoch: 3 [125824/620022]    Loss: 0.007070   Batch Acc: 85.94
[Train] Epoch: 3 [125888/620022]    Loss: 0.009501   Batch Acc: 75.00
[Train] Epoch: 3 [125952/620022]    Loss: 0.008867   Batch Acc: 71.88
[Train] Epoch: 3 [126016/620022]    Loss: 0.009136   Batch Acc: 79.69
[Train] Epoch: 3 [126080/620022]    Loss: 0.010055   Batch Acc: 76.56
[Train] Epoch: 3 [126144/620022]    Loss: 0.008160   Batch Acc: 82.81
[Train] Epoch: 3 [126208/620022]    Loss: 0.007074   Batch Acc: 84.38
[Train] Epoch: 3 [126272/620022]    Loss: 0.009308   Batch Acc: 75.00
[Train] Epoch: 3 [126336/620022]    Loss: 0.006165   Batch Acc: 85.94
[Train] Epoch: 3 [126400/620022]    Loss: 0.010153   Batch Acc: 76.56
[Train] Epoch: 3 [126464/620022]    Loss: 0.008757   Batch Acc: 78.12
[Train] Epoch: 3 [126528/620022]    Loss: 0.008119   Batch Acc: 81.25
[Train] Epoch: 3 [126592/620022]    Loss: 0.007570   Batch Acc: 84.38
[Train] Epoch: 3 [126656/620022]    Loss: 0.008752   Batch Acc: 75.00
[Train] Epoch: 3 [126720/620022]    Loss: 0.013181   Batch Acc: 67.19
[Train] Epoch: 3 [126784/620022]    Loss: 0.008570   Batch Acc: 78.12
[Train] Epoch: 3 [126848/620022]    Loss: 0.008471   Batch Acc: 79.69
[Train] Epoch: 3 [126912/620022]    Loss: 0.006888   Batch Acc: 84.38
[Train] Epoch: 3 [126976/620022]    Loss: 0.010848   Batch Acc: 70.31
[Train] Epoch: 3 [127040/620022]    Loss: 0.006698   Batch Acc: 84.38
[Train] Epoch: 3 [127104/620022]    Loss: 0.008590   Batch Acc: 78.12
[Train] Epoch: 3 [127168/620022]    Loss: 0.009129   Batch Acc: 79.69
[Train] Epoch: 3 [127232/620022]    Loss: 0.009378   Batch Acc: 78.12
[Train] Epoch: 3 [127296/620022]    Loss: 0.008907   Batch Acc: 81.25
[Train] Epoch: 3 [127360/620022]    Loss: 0.011527   Batch Acc: 62.50
[Train] Epoch: 3 [127424/620022]    Loss: 0.010287   Batch Acc: 71.88
[Train] Epoch: 3 [127488/620022]    Loss: 0.010259   Batch Acc: 73.44
[Train] Epoch: 3 [127552/620022]    Loss: 0.008797   Batch Acc: 71.88
[Train] Epoch: 3 [127616/620022]    Loss: 0.009895   Batch Acc: 68.75
[Train] Epoch: 3 [127680/620022]    Loss: 0.008368   Batch Acc: 76.56
[Train] Epoch: 3 [127744/620022]    Loss: 0.008916   Batch Acc: 71.88
[Train] Epoch: 3 [127808/620022]    Loss: 0.007922   Batch Acc: 75.00
[Train] Epoch: 3 [127872/620022]    Loss: 0.010892   Batch Acc: 68.75
[Train] Epoch: 3 [127936/620022]    Loss: 0.011532   Batch Acc: 71.88
[Train] Epoch: 3 [128000/620022]    Loss: 0.010972   Batch Acc: 76.56
[Train] Epoch: 3 [128064/620022]    Loss: 0.008148   Batch Acc: 76.56
[Train] Epoch: 3 [128128/620022]    Loss: 0.007036   Batch Acc: 87.50
[Train] Epoch: 3 [128192/620022]    Loss: 0.009205   Batch Acc: 78.12
[Train] Epoch: 3 [128256/620022]    Loss: 0.007484   Batch Acc: 82.81
[Train] Epoch: 3 [128320/620022]    Loss: 0.008478   Batch Acc: 78.12
[Train] Epoch: 3 [128384/620022]    Loss: 0.007465   Batch Acc: 81.25
[Train] Epoch: 3 [128448/620022]    Loss: 0.006149   Batch Acc: 84.38
[Train] Epoch: 3 [128512/620022]    Loss: 0.008480   Batch Acc: 78.12
[Train] Epoch: 3 [128576/620022]    Loss: 0.006436   Batch Acc: 82.81
[Train] Epoch: 3 [128640/620022]    Loss: 0.007891   Batch Acc: 79.69
[Train] Epoch: 3 [128704/620022]    Loss: 0.006064   Batch Acc: 89.06
[Train] Epoch: 3 [128768/620022]    Loss: 0.008371   Batch Acc: 75.00
[Train] Epoch: 3 [128832/620022]    Loss: 0.008238   Batch Acc: 79.69
[Train] Epoch: 3 [128896/620022]    Loss: 0.007197   Batch Acc: 81.25
[Train] Epoch: 3 [128960/620022]    Loss: 0.010653   Batch Acc: 70.31
[Train] Epoch: 3 [129024/620022]    Loss: 0.007433   Batch Acc: 75.00
[Train] Epoch: 3 [129088/620022]    Loss: 0.009337   Batch Acc: 70.31
[Train] Epoch: 3 [129152/620022]    Loss: 0.010097   Batch Acc: 75.00
[Train] Epoch: 3 [129216/620022]    Loss: 0.008024   Batch Acc: 78.12
[Train] Epoch: 3 [129280/620022]    Loss: 0.010381   Batch Acc: 67.19
[Train] Epoch: 3 [129344/620022]    Loss: 0.009148   Batch Acc: 76.56
[Train] Epoch: 3 [129408/620022]    Loss: 0.007070   Batch Acc: 81.25
[Train] Epoch: 3 [129472/620022]    Loss: 0.006529   Batch Acc: 85.94
[Train] Epoch: 3 [129536/620022]    Loss: 0.008021   Batch Acc: 78.12
[Train] Epoch: 3 [129600/620022]    Loss: 0.006469   Batch Acc: 92.19
[Train] Epoch: 3 [129664/620022]    Loss: 0.007186   Batch Acc: 82.81
[Train] Epoch: 3 [129728/620022]    Loss: 0.005916   Batch Acc: 90.62
[Train] Epoch: 3 [129792/620022]    Loss: 0.012827   Batch Acc: 67.19
[Train] Epoch: 3 [129856/620022]    Loss: 0.008793   Batch Acc: 78.12
[Train] Epoch: 3 [129920/620022]    Loss: 0.010189   Batch Acc: 70.31
[Train] Epoch: 3 [129984/620022]    Loss: 0.009280   Batch Acc: 75.00
[Train] Epoch: 3 [130048/620022]    Loss: 0.008675   Batch Acc: 79.69
[Train] Epoch: 3 [130112/620022]    Loss: 0.006778   Batch Acc: 85.94
[Train] Epoch: 3 [130176/620022]    Loss: 0.009258   Batch Acc: 71.88
[Train] Epoch: 3 [130240/620022]    Loss: 0.010380   Batch Acc: 75.00
[Train] Epoch: 3 [130304/620022]    Loss: 0.009193   Batch Acc: 79.69
[Train] Epoch: 3 [130368/620022]    Loss: 0.009652   Batch Acc: 73.44
[Train] Epoch: 3 [130432/620022]    Loss: 0.010396   Batch Acc: 73.44
[Train] Epoch: 3 [130496/620022]    Loss: 0.007182   Batch Acc: 79.69
[Train] Epoch: 3 [130560/620022]    Loss: 0.007987   Batch Acc: 84.38
[Train] Epoch: 3 [130624/620022]    Loss: 0.009343   Batch Acc: 76.56
[Train] Epoch: 3 [130688/620022]    Loss: 0.010256   Batch Acc: 70.31
[Train] Epoch: 3 [130752/620022]    Loss: 0.009622   Batch Acc: 73.44
[Train] Epoch: 3 [130816/620022]    Loss: 0.007457   Batch Acc: 82.81
[Train] Epoch: 3 [130880/620022]    Loss: 0.007937   Batch Acc: 81.25
[Train] Epoch: 3 [130944/620022]    Loss: 0.011410   Batch Acc: 65.62
[Train] Epoch: 3 [131008/620022]    Loss: 0.007680   Batch Acc: 82.81
[Train] Epoch: 3 [131072/620022]    Loss: 0.008454   Batch Acc: 76.56
[Train] Epoch: 3 [131136/620022]    Loss: 0.008318   Batch Acc: 76.56
[Train] Epoch: 3 [131200/620022]    Loss: 0.008253   Batch Acc: 76.56
[Train] Epoch: 3 [131264/620022]    Loss: 0.007741   Batch Acc: 79.69
[Train] Epoch: 3 [131328/620022]    Loss: 0.007103   Batch Acc: 79.69
[Train] Epoch: 3 [131392/620022]    Loss: 0.008758   Batch Acc: 81.25
[Train] Epoch: 3 [131456/620022]    Loss: 0.008683   Batch Acc: 78.12
[Train] Epoch: 3 [131520/620022]    Loss: 0.008812   Batch Acc: 76.56
[Train] Epoch: 3 [131584/620022]    Loss: 0.008713   Batch Acc: 81.25
[Train] Epoch: 3 [131648/620022]    Loss: 0.009129   Batch Acc: 75.00
[Train] Epoch: 3 [131712/620022]    Loss: 0.014120   Batch Acc: 60.94
[Train] Epoch: 3 [131776/620022]    Loss: 0.007589   Batch Acc: 84.38
[Train] Epoch: 3 [131840/620022]    Loss: 0.011671   Batch Acc: 65.62
[Train] Epoch: 3 [131904/620022]    Loss: 0.008693   Batch Acc: 75.00
[Train] Epoch: 3 [131968/620022]    Loss: 0.008513   Batch Acc: 81.25
[Train] Epoch: 3 [132032/620022]    Loss: 0.006143   Batch Acc: 85.94
[Train] Epoch: 3 [132096/620022]    Loss: 0.007783   Batch Acc: 76.56
[Train] Epoch: 3 [132160/620022]    Loss: 0.009855   Batch Acc: 76.56
[Train] Epoch: 3 [132224/620022]    Loss: 0.007053   Batch Acc: 81.25
[Train] Epoch: 3 [132288/620022]    Loss: 0.008469   Batch Acc: 81.25
[Train] Epoch: 3 [132352/620022]    Loss: 0.007410   Batch Acc: 81.25
[Train] Epoch: 3 [132416/620022]    Loss: 0.008871   Batch Acc: 75.00
[Train] Epoch: 3 [132480/620022]    Loss: 0.010946   Batch Acc: 68.75
[Train] Epoch: 3 [132544/620022]    Loss: 0.008431   Batch Acc: 75.00
[Train] Epoch: 3 [132608/620022]    Loss: 0.007977   Batch Acc: 79.69
[Train] Epoch: 3 [132672/620022]    Loss: 0.010829   Batch Acc: 67.19
[Train] Epoch: 3 [132736/620022]    Loss: 0.006811   Batch Acc: 84.38
[Train] Epoch: 3 [132800/620022]    Loss: 0.010076   Batch Acc: 71.88
[Train] Epoch: 3 [132864/620022]    Loss: 0.008415   Batch Acc: 79.69
[Train] Epoch: 3 [132928/620022]    Loss: 0.009610   Batch Acc: 75.00
[Train] Epoch: 3 [132992/620022]    Loss: 0.007634   Batch Acc: 84.38
[Train] Epoch: 3 [133056/620022]    Loss: 0.009365   Batch Acc: 73.44
[Train] Epoch: 3 [133120/620022]    Loss: 0.008571   Batch Acc: 73.44
[Train] Epoch: 3 [133184/620022]    Loss: 0.008372   Batch Acc: 75.00
[Train] Epoch: 3 [133248/620022]    Loss: 0.009062   Batch Acc: 79.69
[Train] Epoch: 3 [133312/620022]    Loss: 0.008888   Batch Acc: 76.56
[Train] Epoch: 3 [133376/620022]    Loss: 0.009036   Batch Acc: 70.31
[Train] Epoch: 3 [133440/620022]    Loss: 0.010384   Batch Acc: 73.44
[Train] Epoch: 3 [133504/620022]    Loss: 0.010518   Batch Acc: 71.88
[Train] Epoch: 3 [133568/620022]    Loss: 0.006846   Batch Acc: 85.94
[Train] Epoch: 3 [133632/620022]    Loss: 0.009039   Batch Acc: 78.12
[Train] Epoch: 3 [133696/620022]    Loss: 0.007320   Batch Acc: 82.81
[Train] Epoch: 3 [133760/620022]    Loss: 0.009380   Batch Acc: 81.25
[Train] Epoch: 3 [133824/620022]    Loss: 0.008578   Batch Acc: 75.00
[Train] Epoch: 3 [133888/620022]    Loss: 0.008328   Batch Acc: 78.12
[Train] Epoch: 3 [133952/620022]    Loss: 0.009159   Batch Acc: 76.56
[Train] Epoch: 3 [134016/620022]    Loss: 0.009076   Batch Acc: 78.12
[Train] Epoch: 3 [134080/620022]    Loss: 0.007754   Batch Acc: 84.38
[Train] Epoch: 3 [134144/620022]    Loss: 0.006677   Batch Acc: 90.62
[Train] Epoch: 3 [134208/620022]    Loss: 0.011441   Batch Acc: 70.31
[Train] Epoch: 3 [134272/620022]    Loss: 0.007963   Batch Acc: 76.56
[Train] Epoch: 3 [134336/620022]    Loss: 0.007951   Batch Acc: 81.25
[Train] Epoch: 3 [134400/620022]    Loss: 0.008986   Batch Acc: 76.56
[Train] Epoch: 3 [134464/620022]    Loss: 0.007033   Batch Acc: 87.50
[Train] Epoch: 3 [134528/620022]    Loss: 0.006983   Batch Acc: 84.38
[Train] Epoch: 3 [134592/620022]    Loss: 0.009046   Batch Acc: 78.12
[Train] Epoch: 3 [134656/620022]    Loss: 0.010925   Batch Acc: 71.88
[Train] Epoch: 3 [134720/620022]    Loss: 0.007299   Batch Acc: 79.69
[Train] Epoch: 3 [134784/620022]    Loss: 0.008560   Batch Acc: 81.25
[Train] Epoch: 3 [134848/620022]    Loss: 0.008636   Batch Acc: 76.56
[Train] Epoch: 3 [134912/620022]    Loss: 0.008663   Batch Acc: 78.12
[Train] Epoch: 3 [134976/620022]    Loss: 0.009539   Batch Acc: 75.00
[Train] Epoch: 3 [135040/620022]    Loss: 0.009456   Batch Acc: 73.44
[Train] Epoch: 3 [135104/620022]    Loss: 0.009406   Batch Acc: 73.44
[Train] Epoch: 3 [135168/620022]    Loss: 0.007634   Batch Acc: 81.25
[Train] Epoch: 3 [135232/620022]    Loss: 0.004917   Batch Acc: 90.62
[Train] Epoch: 3 [135296/620022]    Loss: 0.008752   Batch Acc: 76.56
[Train] Epoch: 3 [135360/620022]    Loss: 0.008538   Batch Acc: 81.25
[Train] Epoch: 3 [135424/620022]    Loss: 0.008308   Batch Acc: 76.56
[Train] Epoch: 3 [135488/620022]    Loss: 0.006953   Batch Acc: 81.25
[Train] Epoch: 3 [135552/620022]    Loss: 0.005325   Batch Acc: 87.50
[Train] Epoch: 3 [135616/620022]    Loss: 0.011232   Batch Acc: 71.88
[Train] Epoch: 3 [135680/620022]    Loss: 0.007291   Batch Acc: 85.94
[Train] Epoch: 3 [135744/620022]    Loss: 0.010004   Batch Acc: 75.00
[Train] Epoch: 3 [135808/620022]    Loss: 0.007797   Batch Acc: 81.25
[Train] Epoch: 3 [135872/620022]    Loss: 0.006018   Batch Acc: 87.50
[Train] Epoch: 3 [135936/620022]    Loss: 0.008114   Batch Acc: 79.69
[Train] Epoch: 3 [136000/620022]    Loss: 0.011260   Batch Acc: 75.00
[Train] Epoch: 3 [136064/620022]    Loss: 0.008144   Batch Acc: 78.12
[Train] Epoch: 3 [136128/620022]    Loss: 0.009333   Batch Acc: 78.12
[Train] Epoch: 3 [136192/620022]    Loss: 0.009373   Batch Acc: 79.69
[Train] Epoch: 3 [136256/620022]    Loss: 0.007440   Batch Acc: 79.69
[Train] Epoch: 3 [136320/620022]    Loss: 0.010169   Batch Acc: 67.19
[Train] Epoch: 3 [136384/620022]    Loss: 0.007457   Batch Acc: 84.38
[Train] Epoch: 3 [136448/620022]    Loss: 0.008737   Batch Acc: 78.12
[Train] Epoch: 3 [136512/620022]    Loss: 0.009511   Batch Acc: 73.44
[Train] Epoch: 3 [136576/620022]    Loss: 0.006346   Batch Acc: 79.69
[Train] Epoch: 3 [136640/620022]    Loss: 0.010899   Batch Acc: 64.06
[Train] Epoch: 3 [136704/620022]    Loss: 0.008063   Batch Acc: 79.69
[Train] Epoch: 3 [136768/620022]    Loss: 0.008834   Batch Acc: 71.88
[Train] Epoch: 3 [136832/620022]    Loss: 0.008228   Batch Acc: 76.56
[Train] Epoch: 3 [136896/620022]    Loss: 0.008919   Batch Acc: 76.56
[Train] Epoch: 3 [136960/620022]    Loss: 0.009066   Batch Acc: 79.69
[Train] Epoch: 3 [137024/620022]    Loss: 0.010314   Batch Acc: 71.88
[Train] Epoch: 3 [137088/620022]    Loss: 0.007756   Batch Acc: 84.38
[Train] Epoch: 3 [137152/620022]    Loss: 0.008014   Batch Acc: 82.81
[Train] Epoch: 3 [137216/620022]    Loss: 0.008252   Batch Acc: 76.56
[Train] Epoch: 3 [137280/620022]    Loss: 0.011348   Batch Acc: 70.31
[Train] Epoch: 3 [137344/620022]    Loss: 0.008727   Batch Acc: 78.12
[Train] Epoch: 3 [137408/620022]    Loss: 0.010347   Batch Acc: 75.00
[Train] Epoch: 3 [137472/620022]    Loss: 0.009805   Batch Acc: 71.88
[Train] Epoch: 3 [137536/620022]    Loss: 0.008247   Batch Acc: 78.12
[Train] Epoch: 3 [137600/620022]    Loss: 0.008096   Batch Acc: 84.38
[Train] Epoch: 3 [137664/620022]    Loss: 0.010312   Batch Acc: 73.44
[Train] Epoch: 3 [137728/620022]    Loss: 0.007646   Batch Acc: 78.12
[Train] Epoch: 3 [137792/620022]    Loss: 0.008452   Batch Acc: 81.25
[Train] Epoch: 3 [137856/620022]    Loss: 0.008031   Batch Acc: 79.69
[Train] Epoch: 3 [137920/620022]    Loss: 0.009461   Batch Acc: 73.44
[Train] Epoch: 3 [137984/620022]    Loss: 0.008484   Batch Acc: 79.69
[Train] Epoch: 3 [138048/620022]    Loss: 0.008338   Batch Acc: 82.81
[Train] Epoch: 3 [138112/620022]    Loss: 0.009400   Batch Acc: 75.00
[Train] Epoch: 3 [138176/620022]    Loss: 0.009115   Batch Acc: 73.44
[Train] Epoch: 3 [138240/620022]    Loss: 0.006944   Batch Acc: 85.94
[Train] Epoch: 3 [138304/620022]    Loss: 0.008792   Batch Acc: 78.12
[Train] Epoch: 3 [138368/620022]    Loss: 0.009069   Batch Acc: 76.56
[Train] Epoch: 3 [138432/620022]    Loss: 0.007628   Batch Acc: 84.38
[Train] Epoch: 3 [138496/620022]    Loss: 0.007423   Batch Acc: 81.25
[Train] Epoch: 3 [138560/620022]    Loss: 0.009341   Batch Acc: 78.12
[Train] Epoch: 3 [138624/620022]    Loss: 0.010457   Batch Acc: 71.88
[Train] Epoch: 3 [138688/620022]    Loss: 0.011065   Batch Acc: 64.06
[Train] Epoch: 3 [138752/620022]    Loss: 0.010392   Batch Acc: 71.88
[Train] Epoch: 3 [138816/620022]    Loss: 0.008550   Batch Acc: 75.00
[Train] Epoch: 3 [138880/620022]    Loss: 0.010239   Batch Acc: 71.88
[Train] Epoch: 3 [138944/620022]    Loss: 0.007473   Batch Acc: 76.56
[Train] Epoch: 3 [139008/620022]    Loss: 0.009807   Batch Acc: 76.56
[Train] Epoch: 3 [139072/620022]    Loss: 0.008668   Batch Acc: 78.12
[Train] Epoch: 3 [139136/620022]    Loss: 0.006947   Batch Acc: 85.94
[Train] Epoch: 3 [139200/620022]    Loss: 0.009408   Batch Acc: 79.69
[Train] Epoch: 3 [139264/620022]    Loss: 0.009483   Batch Acc: 82.81
[Train] Epoch: 3 [139328/620022]    Loss: 0.007921   Batch Acc: 79.69
[Train] Epoch: 3 [139392/620022]    Loss: 0.009165   Batch Acc: 71.88
[Train] Epoch: 3 [139456/620022]    Loss: 0.007986   Batch Acc: 81.25
[Train] Epoch: 3 [139520/620022]    Loss: 0.009206   Batch Acc: 78.12
[Train] Epoch: 3 [139584/620022]    Loss: 0.008368   Batch Acc: 81.25
[Train] Epoch: 3 [139648/620022]    Loss: 0.007982   Batch Acc: 82.81
[Train] Epoch: 3 [139712/620022]    Loss: 0.008371   Batch Acc: 79.69
[Train] Epoch: 3 [139776/620022]    Loss: 0.007035   Batch Acc: 81.25
[Train] Epoch: 3 [139840/620022]    Loss: 0.008835   Batch Acc: 81.25
[Train] Epoch: 3 [139904/620022]    Loss: 0.008947   Batch Acc: 75.00
[Train] Epoch: 3 [139968/620022]    Loss: 0.008356   Batch Acc: 81.25
[Train] Epoch: 3 [140032/620022]    Loss: 0.007590   Batch Acc: 81.25
[Train] Epoch: 3 [140096/620022]    Loss: 0.009698   Batch Acc: 71.88
[Train] Epoch: 3 [140160/620022]    Loss: 0.009869   Batch Acc: 70.31
[Train] Epoch: 3 [140224/620022]    Loss: 0.010193   Batch Acc: 71.88
[Train] Epoch: 3 [140288/620022]    Loss: 0.011429   Batch Acc: 67.19
[Train] Epoch: 3 [140352/620022]    Loss: 0.007531   Batch Acc: 82.81
[Train] Epoch: 3 [140416/620022]    Loss: 0.011168   Batch Acc: 71.88
[Train] Epoch: 3 [140480/620022]    Loss: 0.010424   Batch Acc: 71.88
[Train] Epoch: 3 [140544/620022]    Loss: 0.007543   Batch Acc: 84.38
[Train] Epoch: 3 [140608/620022]    Loss: 0.008214   Batch Acc: 79.69
[Train] Epoch: 3 [140672/620022]    Loss: 0.009209   Batch Acc: 73.44
[Train] Epoch: 3 [140736/620022]    Loss: 0.008065   Batch Acc: 81.25
[Train] Epoch: 3 [140800/620022]    Loss: 0.009103   Batch Acc: 78.12
[Train] Epoch: 3 [140864/620022]    Loss: 0.008157   Batch Acc: 79.69
[Train] Epoch: 3 [140928/620022]    Loss: 0.010748   Batch Acc: 71.88
[Train] Epoch: 3 [140992/620022]    Loss: 0.009509   Batch Acc: 68.75
[Train] Epoch: 3 [141056/620022]    Loss: 0.012277   Batch Acc: 64.06
[Train] Epoch: 3 [141120/620022]    Loss: 0.008314   Batch Acc: 75.00
[Train] Epoch: 3 [141184/620022]    Loss: 0.008260   Batch Acc: 76.56
[Train] Epoch: 3 [141248/620022]    Loss: 0.010122   Batch Acc: 67.19
[Train] Epoch: 3 [141312/620022]    Loss: 0.008191   Batch Acc: 81.25
[Train] Epoch: 3 [141376/620022]    Loss: 0.009292   Batch Acc: 81.25
[Train] Epoch: 3 [141440/620022]    Loss: 0.007130   Batch Acc: 85.94
[Train] Epoch: 3 [141504/620022]    Loss: 0.010305   Batch Acc: 76.56
[Train] Epoch: 3 [141568/620022]    Loss: 0.010316   Batch Acc: 73.44
[Train] Epoch: 3 [141632/620022]    Loss: 0.009090   Batch Acc: 81.25
[Train] Epoch: 3 [141696/620022]    Loss: 0.008107   Batch Acc: 82.81
[Train] Epoch: 3 [141760/620022]    Loss: 0.008853   Batch Acc: 73.44
[Train] Epoch: 3 [141824/620022]    Loss: 0.008384   Batch Acc: 78.12
[Train] Epoch: 3 [141888/620022]    Loss: 0.007355   Batch Acc: 78.12
[Train] Epoch: 3 [141952/620022]    Loss: 0.008600   Batch Acc: 73.44
[Train] Epoch: 3 [142016/620022]    Loss: 0.010014   Batch Acc: 75.00
[Train] Epoch: 3 [142080/620022]    Loss: 0.007176   Batch Acc: 79.69
[Train] Epoch: 3 [142144/620022]    Loss: 0.006494   Batch Acc: 84.38
[Train] Epoch: 3 [142208/620022]    Loss: 0.008824   Batch Acc: 71.88
[Train] Epoch: 3 [142272/620022]    Loss: 0.008289   Batch Acc: 78.12
[Train] Epoch: 3 [142336/620022]    Loss: 0.006493   Batch Acc: 87.50
[Train] Epoch: 3 [142400/620022]    Loss: 0.008416   Batch Acc: 79.69
[Train] Epoch: 3 [142464/620022]    Loss: 0.007694   Batch Acc: 84.38
[Train] Epoch: 3 [142528/620022]    Loss: 0.007993   Batch Acc: 78.12
[Train] Epoch: 3 [142592/620022]    Loss: 0.010486   Batch Acc: 67.19
[Train] Epoch: 3 [142656/620022]    Loss: 0.008375   Batch Acc: 82.81
[Train] Epoch: 3 [142720/620022]    Loss: 0.011488   Batch Acc: 73.44
[Train] Epoch: 3 [142784/620022]    Loss: 0.008692   Batch Acc: 78.12
[Train] Epoch: 3 [142848/620022]    Loss: 0.007576   Batch Acc: 81.25
[Train] Epoch: 3 [142912/620022]    Loss: 0.007125   Batch Acc: 81.25
[Train] Epoch: 3 [142976/620022]    Loss: 0.010765   Batch Acc: 73.44
[Train] Epoch: 3 [143040/620022]    Loss: 0.007152   Batch Acc: 82.81
[Train] Epoch: 3 [143104/620022]    Loss: 0.007221   Batch Acc: 82.81
[Train] Epoch: 3 [143168/620022]    Loss: 0.008910   Batch Acc: 73.44
[Train] Epoch: 3 [143232/620022]    Loss: 0.008610   Batch Acc: 82.81
[Train] Epoch: 3 [143296/620022]    Loss: 0.009380   Batch Acc: 78.12
[Train] Epoch: 3 [143360/620022]    Loss: 0.008648   Batch Acc: 81.25
[Train] Epoch: 3 [143424/620022]    Loss: 0.009639   Batch Acc: 73.44
[Train] Epoch: 3 [143488/620022]    Loss: 0.008866   Batch Acc: 81.25
[Train] Epoch: 3 [143552/620022]    Loss: 0.008400   Batch Acc: 76.56
[Train] Epoch: 3 [143616/620022]    Loss: 0.008933   Batch Acc: 73.44
[Train] Epoch: 3 [143680/620022]    Loss: 0.010838   Batch Acc: 75.00
[Train] Epoch: 3 [143744/620022]    Loss: 0.008377   Batch Acc: 78.12
[Train] Epoch: 3 [143808/620022]    Loss: 0.008166   Batch Acc: 84.38
[Train] Epoch: 3 [143872/620022]    Loss: 0.011193   Batch Acc: 65.62
[Train] Epoch: 3 [143936/620022]    Loss: 0.010591   Batch Acc: 70.31
[Train] Epoch: 3 [144000/620022]    Loss: 0.007842   Batch Acc: 78.12
[Train] Epoch: 3 [144064/620022]    Loss: 0.006536   Batch Acc: 87.50
[Train] Epoch: 3 [144128/620022]    Loss: 0.006219   Batch Acc: 84.38
[Train] Epoch: 3 [144192/620022]    Loss: 0.009515   Batch Acc: 71.88
[Train] Epoch: 3 [144256/620022]    Loss: 0.009250   Batch Acc: 73.44
[Train] Epoch: 3 [144320/620022]    Loss: 0.007754   Batch Acc: 84.38
[Train] Epoch: 3 [144384/620022]    Loss: 0.011484   Batch Acc: 60.94
[Train] Epoch: 3 [144448/620022]    Loss: 0.008168   Batch Acc: 81.25
[Train] Epoch: 3 [144512/620022]    Loss: 0.008320   Batch Acc: 79.69
[Train] Epoch: 3 [144576/620022]    Loss: 0.008588   Batch Acc: 78.12
[Train] Epoch: 3 [144640/620022]    Loss: 0.010122   Batch Acc: 76.56
[Train] Epoch: 3 [144704/620022]    Loss: 0.007122   Batch Acc: 78.12
[Train] Epoch: 3 [144768/620022]    Loss: 0.009217   Batch Acc: 76.56
[Train] Epoch: 3 [144832/620022]    Loss: 0.008620   Batch Acc: 81.25
[Train] Epoch: 3 [144896/620022]    Loss: 0.008945   Batch Acc: 75.00
[Train] Epoch: 3 [144960/620022]    Loss: 0.006979   Batch Acc: 82.81
[Train] Epoch: 3 [145024/620022]    Loss: 0.007731   Batch Acc: 78.12
[Train] Epoch: 3 [145088/620022]    Loss: 0.007068   Batch Acc: 85.94
[Train] Epoch: 3 [145152/620022]    Loss: 0.008511   Batch Acc: 78.12
[Train] Epoch: 3 [145216/620022]    Loss: 0.010955   Batch Acc: 71.88
[Train] Epoch: 3 [145280/620022]    Loss: 0.008952   Batch Acc: 76.56
[Train] Epoch: 3 [145344/620022]    Loss: 0.007525   Batch Acc: 82.81
[Train] Epoch: 3 [145408/620022]    Loss: 0.007707   Batch Acc: 84.38
[Train] Epoch: 3 [145472/620022]    Loss: 0.008384   Batch Acc: 78.12
[Train] Epoch: 3 [145536/620022]    Loss: 0.007740   Batch Acc: 85.94
[Train] Epoch: 3 [145600/620022]    Loss: 0.006974   Batch Acc: 79.69
[Train] Epoch: 3 [145664/620022]    Loss: 0.007822   Batch Acc: 79.69
[Train] Epoch: 3 [145728/620022]    Loss: 0.007336   Batch Acc: 87.50
[Train] Epoch: 3 [145792/620022]    Loss: 0.009631   Batch Acc: 73.44
[Train] Epoch: 3 [145856/620022]    Loss: 0.008070   Batch Acc: 78.12
[Train] Epoch: 3 [145920/620022]    Loss: 0.007266   Batch Acc: 79.69
[Train] Epoch: 3 [145984/620022]    Loss: 0.012239   Batch Acc: 65.62
[Train] Epoch: 3 [146048/620022]    Loss: 0.007765   Batch Acc: 82.81
[Train] Epoch: 3 [146112/620022]    Loss: 0.009127   Batch Acc: 81.25
[Train] Epoch: 3 [146176/620022]    Loss: 0.009002   Batch Acc: 76.56
[Train] Epoch: 3 [146240/620022]    Loss: 0.008884   Batch Acc: 76.56
[Train] Epoch: 3 [146304/620022]    Loss: 0.007611   Batch Acc: 89.06
[Train] Epoch: 3 [146368/620022]    Loss: 0.011332   Batch Acc: 75.00
[Train] Epoch: 3 [146432/620022]    Loss: 0.009889   Batch Acc: 70.31
[Train] Epoch: 3 [146496/620022]    Loss: 0.008041   Batch Acc: 81.25
[Train] Epoch: 3 [146560/620022]    Loss: 0.008932   Batch Acc: 70.31
[Train] Epoch: 3 [146624/620022]    Loss: 0.010133   Batch Acc: 73.44
[Train] Epoch: 3 [146688/620022]    Loss: 0.010953   Batch Acc: 76.56
[Train] Epoch: 3 [146752/620022]    Loss: 0.012317   Batch Acc: 60.94
[Train] Epoch: 3 [146816/620022]    Loss: 0.010795   Batch Acc: 70.31
[Train] Epoch: 3 [146880/620022]    Loss: 0.008651   Batch Acc: 78.12
[Train] Epoch: 3 [146944/620022]    Loss: 0.008330   Batch Acc: 75.00
[Train] Epoch: 3 [147008/620022]    Loss: 0.009011   Batch Acc: 73.44
[Train] Epoch: 3 [147072/620022]    Loss: 0.008311   Batch Acc: 73.44
[Train] Epoch: 3 [147136/620022]    Loss: 0.007715   Batch Acc: 84.38
[Train] Epoch: 3 [147200/620022]    Loss: 0.008077   Batch Acc: 78.12
[Train] Epoch: 3 [147264/620022]    Loss: 0.007088   Batch Acc: 84.38
[Train] Epoch: 3 [147328/620022]    Loss: 0.007483   Batch Acc: 81.25
[Train] Epoch: 3 [147392/620022]    Loss: 0.008373   Batch Acc: 73.44
[Train] Epoch: 3 [147456/620022]    Loss: 0.009331   Batch Acc: 71.88
[Train] Epoch: 3 [147520/620022]    Loss: 0.006785   Batch Acc: 82.81
[Train] Epoch: 3 [147584/620022]    Loss: 0.009552   Batch Acc: 71.88
[Train] Epoch: 3 [147648/620022]    Loss: 0.011014   Batch Acc: 67.19
[Train] Epoch: 3 [147712/620022]    Loss: 0.007212   Batch Acc: 81.25
[Train] Epoch: 3 [147776/620022]    Loss: 0.009739   Batch Acc: 73.44
[Train] Epoch: 3 [147840/620022]    Loss: 0.008171   Batch Acc: 79.69
[Train] Epoch: 3 [147904/620022]    Loss: 0.010344   Batch Acc: 75.00
[Train] Epoch: 3 [147968/620022]    Loss: 0.010512   Batch Acc: 65.62
[Train] Epoch: 3 [148032/620022]    Loss: 0.007002   Batch Acc: 79.69
[Train] Epoch: 3 [148096/620022]    Loss: 0.008388   Batch Acc: 81.25
[Train] Epoch: 3 [148160/620022]    Loss: 0.010082   Batch Acc: 70.31
[Train] Epoch: 3 [148224/620022]    Loss: 0.009653   Batch Acc: 76.56
[Train] Epoch: 3 [148288/620022]    Loss: 0.007959   Batch Acc: 75.00
[Train] Epoch: 3 [148352/620022]    Loss: 0.008776   Batch Acc: 76.56
[Train] Epoch: 3 [148416/620022]    Loss: 0.007160   Batch Acc: 78.12
[Train] Epoch: 3 [148480/620022]    Loss: 0.008948   Batch Acc: 75.00
[Train] Epoch: 3 [148544/620022]    Loss: 0.009021   Batch Acc: 79.69
[Train] Epoch: 3 [148608/620022]    Loss: 0.009582   Batch Acc: 78.12
[Train] Epoch: 3 [148672/620022]    Loss: 0.010714   Batch Acc: 75.00
[Train] Epoch: 3 [148736/620022]    Loss: 0.009663   Batch Acc: 73.44
[Train] Epoch: 3 [148800/620022]    Loss: 0.007960   Batch Acc: 76.56
[Train] Epoch: 3 [148864/620022]    Loss: 0.009204   Batch Acc: 71.88
[Train] Epoch: 3 [148928/620022]    Loss: 0.009338   Batch Acc: 76.56
[Train] Epoch: 3 [148992/620022]    Loss: 0.008836   Batch Acc: 82.81
[Train] Epoch: 3 [149056/620022]    Loss: 0.008539   Batch Acc: 75.00
[Train] Epoch: 3 [149120/620022]    Loss: 0.010004   Batch Acc: 78.12
[Train] Epoch: 3 [149184/620022]    Loss: 0.008007   Batch Acc: 82.81
[Train] Epoch: 3 [149248/620022]    Loss: 0.008009   Batch Acc: 81.25
[Train] Epoch: 3 [149312/620022]    Loss: 0.009314   Batch Acc: 75.00
[Train] Epoch: 3 [149376/620022]    Loss: 0.006307   Batch Acc: 85.94
[Train] Epoch: 3 [149440/620022]    Loss: 0.008957   Batch Acc: 70.31
[Train] Epoch: 3 [149504/620022]    Loss: 0.006920   Batch Acc: 84.38
[Train] Epoch: 3 [149568/620022]    Loss: 0.007520   Batch Acc: 84.38
[Train] Epoch: 3 [149632/620022]    Loss: 0.008008   Batch Acc: 79.69
[Train] Epoch: 3 [149696/620022]    Loss: 0.008052   Batch Acc: 78.12
[Train] Epoch: 3 [149760/620022]    Loss: 0.009994   Batch Acc: 70.31
[Train] Epoch: 3 [149824/620022]    Loss: 0.009105   Batch Acc: 76.56
[Train] Epoch: 3 [149888/620022]    Loss: 0.010031   Batch Acc: 68.75
[Train] Epoch: 3 [149952/620022]    Loss: 0.008563   Batch Acc: 82.81
[Train] Epoch: 3 [150016/620022]    Loss: 0.008770   Batch Acc: 81.25
[Train] Epoch: 3 [150080/620022]    Loss: 0.011883   Batch Acc: 64.06
[Train] Epoch: 3 [150144/620022]    Loss: 0.006684   Batch Acc: 84.38
[Train] Epoch: 3 [150208/620022]    Loss: 0.008735   Batch Acc: 70.31
[Train] Epoch: 3 [150272/620022]    Loss: 0.009420   Batch Acc: 79.69
[Train] Epoch: 3 [150336/620022]    Loss: 0.007865   Batch Acc: 78.12
[Train] Epoch: 3 [150400/620022]    Loss: 0.009664   Batch Acc: 73.44
[Train] Epoch: 3 [150464/620022]    Loss: 0.008291   Batch Acc: 82.81
[Train] Epoch: 3 [150528/620022]    Loss: 0.011112   Batch Acc: 71.88
[Train] Epoch: 3 [150592/620022]    Loss: 0.006739   Batch Acc: 85.94
[Train] Epoch: 3 [150656/620022]    Loss: 0.006916   Batch Acc: 85.94
[Train] Epoch: 3 [150720/620022]    Loss: 0.007999   Batch Acc: 79.69
[Train] Epoch: 3 [150784/620022]    Loss: 0.011431   Batch Acc: 67.19
[Train] Epoch: 3 [150848/620022]    Loss: 0.009112   Batch Acc: 70.31
[Train] Epoch: 3 [150912/620022]    Loss: 0.010788   Batch Acc: 70.31
[Train] Epoch: 3 [150976/620022]    Loss: 0.008840   Batch Acc: 76.56
[Train] Epoch: 3 [151040/620022]    Loss: 0.008312   Batch Acc: 75.00
[Train] Epoch: 3 [151104/620022]    Loss: 0.009066   Batch Acc: 75.00
[Train] Epoch: 3 [151168/620022]    Loss: 0.007052   Batch Acc: 79.69
[Train] Epoch: 3 [151232/620022]    Loss: 0.007257   Batch Acc: 82.81
[Train] Epoch: 3 [151296/620022]    Loss: 0.011227   Batch Acc: 67.19
[Train] Epoch: 3 [151360/620022]    Loss: 0.008652   Batch Acc: 78.12
[Train] Epoch: 3 [151424/620022]    Loss: 0.008565   Batch Acc: 75.00
[Train] Epoch: 3 [151488/620022]    Loss: 0.011406   Batch Acc: 70.31
[Train] Epoch: 3 [151552/620022]    Loss: 0.007772   Batch Acc: 81.25
[Train] Epoch: 3 [151616/620022]    Loss: 0.008412   Batch Acc: 81.25
[Train] Epoch: 3 [151680/620022]    Loss: 0.006916   Batch Acc: 76.56
[Train] Epoch: 3 [151744/620022]    Loss: 0.009376   Batch Acc: 71.88
[Train] Epoch: 3 [151808/620022]    Loss: 0.007826   Batch Acc: 76.56
[Train] Epoch: 3 [151872/620022]    Loss: 0.009860   Batch Acc: 76.56
[Train] Epoch: 3 [151936/620022]    Loss: 0.009328   Batch Acc: 75.00
[Train] Epoch: 3 [152000/620022]    Loss: 0.009274   Batch Acc: 76.56
[Train] Epoch: 3 [152064/620022]    Loss: 0.008144   Batch Acc: 76.56
[Train] Epoch: 3 [152128/620022]    Loss: 0.009001   Batch Acc: 76.56
[Train] Epoch: 3 [152192/620022]    Loss: 0.008471   Batch Acc: 75.00
[Train] Epoch: 3 [152256/620022]    Loss: 0.007483   Batch Acc: 79.69
[Train] Epoch: 3 [152320/620022]    Loss: 0.007771   Batch Acc: 81.25
[Train] Epoch: 3 [152384/620022]    Loss: 0.008737   Batch Acc: 78.12
[Train] Epoch: 3 [152448/620022]    Loss: 0.009516   Batch Acc: 71.88
[Train] Epoch: 3 [152512/620022]    Loss: 0.009449   Batch Acc: 76.56
[Train] Epoch: 3 [152576/620022]    Loss: 0.008663   Batch Acc: 78.12
[Train] Epoch: 3 [152640/620022]    Loss: 0.009323   Batch Acc: 76.56
[Train] Epoch: 3 [152704/620022]    Loss: 0.008346   Batch Acc: 81.25
[Train] Epoch: 3 [152768/620022]    Loss: 0.008779   Batch Acc: 78.12
[Train] Epoch: 3 [152832/620022]    Loss: 0.009356   Batch Acc: 75.00
[Train] Epoch: 3 [152896/620022]    Loss: 0.009293   Batch Acc: 73.44
[Train] Epoch: 3 [152960/620022]    Loss: 0.007811   Batch Acc: 81.25
[Train] Epoch: 3 [153024/620022]    Loss: 0.009491   Batch Acc: 78.12
[Train] Epoch: 3 [153088/620022]    Loss: 0.007957   Batch Acc: 76.56
[Train] Epoch: 3 [153152/620022]    Loss: 0.008249   Batch Acc: 73.44
[Train] Epoch: 3 [153216/620022]    Loss: 0.006609   Batch Acc: 85.94
[Train] Epoch: 3 [153280/620022]    Loss: 0.008994   Batch Acc: 70.31
[Train] Epoch: 3 [153344/620022]    Loss: 0.010304   Batch Acc: 71.88
[Train] Epoch: 3 [153408/620022]    Loss: 0.006200   Batch Acc: 87.50
[Train] Epoch: 3 [153472/620022]    Loss: 0.007230   Batch Acc: 79.69
[Train] Epoch: 3 [153536/620022]    Loss: 0.007703   Batch Acc: 78.12
[Train] Epoch: 3 [153600/620022]    Loss: 0.006491   Batch Acc: 81.25
[Train] Epoch: 3 [153664/620022]    Loss: 0.010191   Batch Acc: 73.44
[Train] Epoch: 3 [153728/620022]    Loss: 0.008613   Batch Acc: 81.25
[Train] Epoch: 3 [153792/620022]    Loss: 0.010535   Batch Acc: 71.88
[Train] Epoch: 3 [153856/620022]    Loss: 0.006789   Batch Acc: 82.81
[Train] Epoch: 3 [153920/620022]    Loss: 0.007122   Batch Acc: 87.50
[Train] Epoch: 3 [153984/620022]    Loss: 0.009406   Batch Acc: 75.00
[Train] Epoch: 3 [154048/620022]    Loss: 0.009136   Batch Acc: 76.56
[Train] Epoch: 3 [154112/620022]    Loss: 0.006599   Batch Acc: 84.38
[Train] Epoch: 3 [154176/620022]    Loss: 0.006515   Batch Acc: 82.81
[Train] Epoch: 3 [154240/620022]    Loss: 0.008457   Batch Acc: 81.25
[Train] Epoch: 3 [154304/620022]    Loss: 0.009148   Batch Acc: 76.56
[Train] Epoch: 3 [154368/620022]    Loss: 0.009552   Batch Acc: 65.62
[Train] Epoch: 3 [154432/620022]    Loss: 0.008443   Batch Acc: 73.44
[Train] Epoch: 3 [154496/620022]    Loss: 0.007357   Batch Acc: 79.69
[Train] Epoch: 3 [154560/620022]    Loss: 0.007905   Batch Acc: 81.25
[Train] Epoch: 3 [154624/620022]    Loss: 0.006876   Batch Acc: 87.50
[Train] Epoch: 3 [154688/620022]    Loss: 0.007895   Batch Acc: 82.81
[Train] Epoch: 3 [154752/620022]    Loss: 0.008793   Batch Acc: 76.56
[Train] Epoch: 3 [154816/620022]    Loss: 0.009548   Batch Acc: 73.44
[Train] Epoch: 3 [154880/620022]    Loss: 0.007685   Batch Acc: 79.69
[Train] Epoch: 3 [154944/620022]    Loss: 0.008248   Batch Acc: 76.56
[Train] Epoch: 3 [155008/620022]    Loss: 0.007459   Batch Acc: 87.50
[Train] Epoch: 3 [155072/620022]    Loss: 0.008998   Batch Acc: 76.56
[Train] Epoch: 3 [155136/620022]    Loss: 0.009193   Batch Acc: 73.44
[Train] Epoch: 3 [155200/620022]    Loss: 0.007148   Batch Acc: 82.81
[Train] Epoch: 3 [155264/620022]    Loss: 0.009777   Batch Acc: 73.44
[Train] Epoch: 3 [155328/620022]    Loss: 0.008389   Batch Acc: 81.25
[Train] Epoch: 3 [155392/620022]    Loss: 0.010616   Batch Acc: 75.00
[Train] Epoch: 3 [155456/620022]    Loss: 0.008269   Batch Acc: 79.69
[Train] Epoch: 3 [155520/620022]    Loss: 0.007264   Batch Acc: 84.38
[Train] Epoch: 3 [155584/620022]    Loss: 0.008147   Batch Acc: 78.12
[Train] Epoch: 3 [155648/620022]    Loss: 0.006654   Batch Acc: 81.25
[Train] Epoch: 3 [155712/620022]    Loss: 0.010608   Batch Acc: 70.31
[Train] Epoch: 3 [155776/620022]    Loss: 0.009814   Batch Acc: 71.88
[Train] Epoch: 3 [155840/620022]    Loss: 0.008457   Batch Acc: 78.12
[Train] Epoch: 3 [155904/620022]    Loss: 0.010085   Batch Acc: 75.00
[Train] Epoch: 3 [155968/620022]    Loss: 0.009438   Batch Acc: 81.25
[Train] Epoch: 3 [156032/620022]    Loss: 0.008916   Batch Acc: 76.56
[Train] Epoch: 3 [156096/620022]    Loss: 0.007851   Batch Acc: 82.81
[Train] Epoch: 3 [156160/620022]    Loss: 0.008512   Batch Acc: 84.38
[Train] Epoch: 3 [156224/620022]    Loss: 0.010447   Batch Acc: 76.56
[Train] Epoch: 3 [156288/620022]    Loss: 0.008875   Batch Acc: 75.00
[Train] Epoch: 3 [156352/620022]    Loss: 0.008628   Batch Acc: 76.56
[Train] Epoch: 3 [156416/620022]    Loss: 0.010792   Batch Acc: 71.88
[Train] Epoch: 3 [156480/620022]    Loss: 0.008594   Batch Acc: 79.69
[Train] Epoch: 3 [156544/620022]    Loss: 0.009249   Batch Acc: 73.44
[Train] Epoch: 3 [156608/620022]    Loss: 0.006392   Batch Acc: 87.50
[Train] Epoch: 3 [156672/620022]    Loss: 0.009435   Batch Acc: 78.12
[Train] Epoch: 3 [156736/620022]    Loss: 0.009318   Batch Acc: 73.44
[Train] Epoch: 3 [156800/620022]    Loss: 0.008674   Batch Acc: 79.69
[Train] Epoch: 3 [156864/620022]    Loss: 0.007006   Batch Acc: 87.50
[Train] Epoch: 3 [156928/620022]    Loss: 0.006263   Batch Acc: 82.81
[Train] Epoch: 3 [156992/620022]    Loss: 0.007904   Batch Acc: 82.81
[Train] Epoch: 3 [157056/620022]    Loss: 0.010954   Batch Acc: 73.44
[Train] Epoch: 3 [157120/620022]    Loss: 0.008506   Batch Acc: 76.56
[Train] Epoch: 3 [157184/620022]    Loss: 0.010804   Batch Acc: 70.31
[Train] Epoch: 3 [157248/620022]    Loss: 0.008689   Batch Acc: 81.25
[Train] Epoch: 3 [157312/620022]    Loss: 0.007530   Batch Acc: 85.94
[Train] Epoch: 3 [157376/620022]    Loss: 0.008138   Batch Acc: 82.81
[Train] Epoch: 3 [157440/620022]    Loss: 0.007969   Batch Acc: 84.38
[Train] Epoch: 3 [157504/620022]    Loss: 0.008035   Batch Acc: 73.44
[Train] Epoch: 3 [157568/620022]    Loss: 0.009084   Batch Acc: 82.81
[Train] Epoch: 3 [157632/620022]    Loss: 0.008454   Batch Acc: 82.81
[Train] Epoch: 3 [157696/620022]    Loss: 0.009273   Batch Acc: 75.00
[Train] Epoch: 3 [157760/620022]    Loss: 0.006452   Batch Acc: 84.38
[Train] Epoch: 3 [157824/620022]    Loss: 0.008106   Batch Acc: 79.69
[Train] Epoch: 3 [157888/620022]    Loss: 0.008842   Batch Acc: 75.00
[Train] Epoch: 3 [157952/620022]    Loss: 0.011864   Batch Acc: 68.75
[Train] Epoch: 3 [158016/620022]    Loss: 0.009071   Batch Acc: 73.44
[Train] Epoch: 3 [158080/620022]    Loss: 0.007665   Batch Acc: 84.38
[Train] Epoch: 3 [158144/620022]    Loss: 0.007869   Batch Acc: 76.56
[Train] Epoch: 3 [158208/620022]    Loss: 0.010403   Batch Acc: 75.00
[Train] Epoch: 3 [158272/620022]    Loss: 0.007701   Batch Acc: 81.25
[Train] Epoch: 3 [158336/620022]    Loss: 0.007198   Batch Acc: 81.25
[Train] Epoch: 3 [158400/620022]    Loss: 0.010754   Batch Acc: 71.88
[Train] Epoch: 3 [158464/620022]    Loss: 0.010618   Batch Acc: 71.88
[Train] Epoch: 3 [158528/620022]    Loss: 0.010586   Batch Acc: 75.00
[Train] Epoch: 3 [158592/620022]    Loss: 0.008612   Batch Acc: 79.69
[Train] Epoch: 3 [158656/620022]    Loss: 0.007067   Batch Acc: 85.94
[Train] Epoch: 3 [158720/620022]    Loss: 0.010749   Batch Acc: 70.31
[Train] Epoch: 3 [158784/620022]    Loss: 0.006722   Batch Acc: 87.50
[Train] Epoch: 3 [158848/620022]    Loss: 0.006946   Batch Acc: 82.81
[Train] Epoch: 3 [158912/620022]    Loss: 0.009022   Batch Acc: 79.69
[Train] Epoch: 3 [158976/620022]    Loss: 0.008323   Batch Acc: 78.12
[Train] Epoch: 3 [159040/620022]    Loss: 0.010877   Batch Acc: 70.31
[Train] Epoch: 3 [159104/620022]    Loss: 0.008395   Batch Acc: 84.38
[Train] Epoch: 3 [159168/620022]    Loss: 0.007543   Batch Acc: 84.38
[Train] Epoch: 3 [159232/620022]    Loss: 0.009273   Batch Acc: 75.00
[Train] Epoch: 3 [159296/620022]    Loss: 0.009114   Batch Acc: 76.56
[Train] Epoch: 3 [159360/620022]    Loss: 0.007892   Batch Acc: 79.69
[Train] Epoch: 3 [159424/620022]    Loss: 0.007626   Batch Acc: 75.00
[Train] Epoch: 3 [159488/620022]    Loss: 0.008319   Batch Acc: 75.00
[Train] Epoch: 3 [159552/620022]    Loss: 0.009504   Batch Acc: 76.56
[Train] Epoch: 3 [159616/620022]    Loss: 0.008473   Batch Acc: 76.56
[Train] Epoch: 3 [159680/620022]    Loss: 0.008826   Batch Acc: 78.12
[Train] Epoch: 3 [159744/620022]    Loss: 0.008054   Batch Acc: 82.81
[Train] Epoch: 3 [159808/620022]    Loss: 0.007820   Batch Acc: 79.69
[Train] Epoch: 3 [159872/620022]    Loss: 0.008866   Batch Acc: 81.25
[Train] Epoch: 3 [159936/620022]    Loss: 0.008255   Batch Acc: 75.00
[Train] Epoch: 3 [160000/620022]    Loss: 0.006726   Batch Acc: 79.69
[Train] Epoch: 3 [160064/620022]    Loss: 0.008188   Batch Acc: 79.69
[Train] Epoch: 3 [160128/620022]    Loss: 0.008675   Batch Acc: 75.00
[Train] Epoch: 3 [160192/620022]    Loss: 0.009933   Batch Acc: 75.00
[Train] Epoch: 3 [160256/620022]    Loss: 0.009666   Batch Acc: 73.44
[Train] Epoch: 3 [160320/620022]    Loss: 0.005926   Batch Acc: 84.38
[Train] Epoch: 3 [160384/620022]    Loss: 0.007934   Batch Acc: 79.69
[Train] Epoch: 3 [160448/620022]    Loss: 0.007416   Batch Acc: 82.81
[Train] Epoch: 3 [160512/620022]    Loss: 0.008899   Batch Acc: 76.56
[Train] Epoch: 3 [160576/620022]    Loss: 0.007716   Batch Acc: 84.38
[Train] Epoch: 3 [160640/620022]    Loss: 0.007927   Batch Acc: 76.56
[Train] Epoch: 3 [160704/620022]    Loss: 0.008583   Batch Acc: 75.00
[Train] Epoch: 3 [160768/620022]    Loss: 0.008953   Batch Acc: 76.56
[Train] Epoch: 3 [160832/620022]    Loss: 0.008429   Batch Acc: 75.00
[Train] Epoch: 3 [160896/620022]    Loss: 0.011100   Batch Acc: 67.19
[Train] Epoch: 3 [160960/620022]    Loss: 0.009104   Batch Acc: 76.56
[Train] Epoch: 3 [161024/620022]    Loss: 0.008298   Batch Acc: 76.56
[Train] Epoch: 3 [161088/620022]    Loss: 0.009323   Batch Acc: 75.00
[Train] Epoch: 3 [161152/620022]    Loss: 0.009219   Batch Acc: 79.69
[Train] Epoch: 3 [161216/620022]    Loss: 0.009477   Batch Acc: 70.31
[Train] Epoch: 3 [161280/620022]    Loss: 0.008861   Batch Acc: 76.56
[Train] Epoch: 3 [161344/620022]    Loss: 0.009635   Batch Acc: 79.69
[Train] Epoch: 3 [161408/620022]    Loss: 0.007395   Batch Acc: 82.81
[Train] Epoch: 3 [161472/620022]    Loss: 0.007758   Batch Acc: 81.25
[Train] Epoch: 3 [161536/620022]    Loss: 0.006197   Batch Acc: 87.50
[Train] Epoch: 3 [161600/620022]    Loss: 0.007639   Batch Acc: 81.25
[Train] Epoch: 3 [161664/620022]    Loss: 0.010601   Batch Acc: 75.00
[Train] Epoch: 3 [161728/620022]    Loss: 0.008516   Batch Acc: 79.69
[Train] Epoch: 3 [161792/620022]    Loss: 0.007597   Batch Acc: 84.38
[Train] Epoch: 3 [161856/620022]    Loss: 0.007672   Batch Acc: 79.69
[Train] Epoch: 3 [161920/620022]    Loss: 0.010606   Batch Acc: 70.31
[Train] Epoch: 3 [161984/620022]    Loss: 0.009297   Batch Acc: 78.12
[Train] Epoch: 3 [162048/620022]    Loss: 0.006689   Batch Acc: 84.38
[Train] Epoch: 3 [162112/620022]    Loss: 0.006122   Batch Acc: 87.50
[Train] Epoch: 3 [162176/620022]    Loss: 0.009236   Batch Acc: 73.44
[Train] Epoch: 3 [162240/620022]    Loss: 0.010534   Batch Acc: 73.44
[Train] Epoch: 3 [162304/620022]    Loss: 0.009548   Batch Acc: 73.44
[Train] Epoch: 3 [162368/620022]    Loss: 0.008526   Batch Acc: 78.12
[Train] Epoch: 3 [162432/620022]    Loss: 0.008227   Batch Acc: 78.12
[Train] Epoch: 3 [162496/620022]    Loss: 0.009159   Batch Acc: 79.69
[Train] Epoch: 3 [162560/620022]    Loss: 0.007435   Batch Acc: 82.81
[Train] Epoch: 3 [162624/620022]    Loss: 0.006205   Batch Acc: 84.38
[Train] Epoch: 3 [162688/620022]    Loss: 0.012143   Batch Acc: 68.75
[Train] Epoch: 3 [162752/620022]    Loss: 0.009575   Batch Acc: 75.00
[Train] Epoch: 3 [162816/620022]    Loss: 0.009550   Batch Acc: 68.75
[Train] Epoch: 3 [162880/620022]    Loss: 0.011322   Batch Acc: 67.19
[Train] Epoch: 3 [162944/620022]    Loss: 0.009876   Batch Acc: 75.00
[Train] Epoch: 3 [163008/620022]    Loss: 0.008910   Batch Acc: 78.12
[Train] Epoch: 3 [163072/620022]    Loss: 0.006908   Batch Acc: 84.38
[Train] Epoch: 3 [163136/620022]    Loss: 0.008441   Batch Acc: 73.44
[Train] Epoch: 3 [163200/620022]    Loss: 0.010894   Batch Acc: 71.88
[Train] Epoch: 3 [163264/620022]    Loss: 0.008985   Batch Acc: 76.56
[Train] Epoch: 3 [163328/620022]    Loss: 0.007607   Batch Acc: 78.12
[Train] Epoch: 3 [163392/620022]    Loss: 0.008358   Batch Acc: 78.12
[Train] Epoch: 3 [163456/620022]    Loss: 0.009731   Batch Acc: 73.44
[Train] Epoch: 3 [163520/620022]    Loss: 0.009111   Batch Acc: 75.00
[Train] Epoch: 3 [163584/620022]    Loss: 0.009490   Batch Acc: 73.44
[Train] Epoch: 3 [163648/620022]    Loss: 0.008386   Batch Acc: 78.12
[Train] Epoch: 3 [163712/620022]    Loss: 0.007386   Batch Acc: 78.12
[Train] Epoch: 3 [163776/620022]    Loss: 0.008485   Batch Acc: 78.12
[Train] Epoch: 3 [163840/620022]    Loss: 0.006275   Batch Acc: 84.38
[Train] Epoch: 3 [163904/620022]    Loss: 0.007930   Batch Acc: 76.56
[Train] Epoch: 3 [163968/620022]    Loss: 0.007977   Batch Acc: 82.81
[Train] Epoch: 3 [164032/620022]    Loss: 0.005662   Batch Acc: 89.06
[Train] Epoch: 3 [164096/620022]    Loss: 0.010354   Batch Acc: 73.44
[Train] Epoch: 3 [164160/620022]    Loss: 0.010427   Batch Acc: 67.19
[Train] Epoch: 3 [164224/620022]    Loss: 0.010199   Batch Acc: 79.69
[Train] Epoch: 3 [164288/620022]    Loss: 0.009589   Batch Acc: 81.25
[Train] Epoch: 3 [164352/620022]    Loss: 0.008525   Batch Acc: 71.88
[Train] Epoch: 3 [164416/620022]    Loss: 0.008553   Batch Acc: 82.81
[Train] Epoch: 3 [164480/620022]    Loss: 0.010351   Batch Acc: 71.88
[Train] Epoch: 3 [164544/620022]    Loss: 0.009376   Batch Acc: 76.56
[Train] Epoch: 3 [164608/620022]    Loss: 0.011861   Batch Acc: 70.31
[Train] Epoch: 3 [164672/620022]    Loss: 0.009127   Batch Acc: 78.12
[Train] Epoch: 3 [164736/620022]    Loss: 0.007045   Batch Acc: 87.50
[Train] Epoch: 3 [164800/620022]    Loss: 0.008241   Batch Acc: 76.56
[Train] Epoch: 3 [164864/620022]    Loss: 0.012158   Batch Acc: 65.62
[Train] Epoch: 3 [164928/620022]    Loss: 0.008954   Batch Acc: 78.12
[Train] Epoch: 3 [164992/620022]    Loss: 0.011876   Batch Acc: 64.06
[Train] Epoch: 3 [165056/620022]    Loss: 0.007182   Batch Acc: 85.94
[Train] Epoch: 3 [165120/620022]    Loss: 0.008263   Batch Acc: 78.12
[Train] Epoch: 3 [165184/620022]    Loss: 0.008721   Batch Acc: 71.88
[Train] Epoch: 3 [165248/620022]    Loss: 0.010305   Batch Acc: 75.00
[Train] Epoch: 3 [165312/620022]    Loss: 0.007270   Batch Acc: 85.94
[Train] Epoch: 3 [165376/620022]    Loss: 0.007991   Batch Acc: 79.69
[Train] Epoch: 3 [165440/620022]    Loss: 0.009666   Batch Acc: 75.00
[Train] Epoch: 3 [165504/620022]    Loss: 0.011023   Batch Acc: 76.56
[Train] Epoch: 3 [165568/620022]    Loss: 0.011672   Batch Acc: 68.75
[Train] Epoch: 3 [165632/620022]    Loss: 0.010423   Batch Acc: 73.44
[Train] Epoch: 3 [165696/620022]    Loss: 0.008510   Batch Acc: 76.56
[Train] Epoch: 3 [165760/620022]    Loss: 0.010405   Batch Acc: 73.44
[Train] Epoch: 3 [165824/620022]    Loss: 0.008915   Batch Acc: 78.12
[Train] Epoch: 3 [165888/620022]    Loss: 0.008721   Batch Acc: 78.12
[Train] Epoch: 3 [165952/620022]    Loss: 0.008768   Batch Acc: 78.12
[Train] Epoch: 3 [166016/620022]    Loss: 0.010504   Batch Acc: 68.75
[Train] Epoch: 3 [166080/620022]    Loss: 0.011867   Batch Acc: 71.88
[Train] Epoch: 3 [166144/620022]    Loss: 0.006627   Batch Acc: 82.81
[Train] Epoch: 3 [166208/620022]    Loss: 0.007839   Batch Acc: 81.25
[Train] Epoch: 3 [166272/620022]    Loss: 0.007719   Batch Acc: 79.69
[Train] Epoch: 3 [166336/620022]    Loss: 0.008259   Batch Acc: 84.38
[Train] Epoch: 3 [166400/620022]    Loss: 0.007360   Batch Acc: 81.25
[Train] Epoch: 3 [166464/620022]    Loss: 0.009095   Batch Acc: 75.00
[Train] Epoch: 3 [166528/620022]    Loss: 0.009275   Batch Acc: 71.88
[Train] Epoch: 3 [166592/620022]    Loss: 0.007666   Batch Acc: 84.38
[Train] Epoch: 3 [166656/620022]    Loss: 0.008091   Batch Acc: 79.69
[Train] Epoch: 3 [166720/620022]    Loss: 0.010175   Batch Acc: 70.31
[Train] Epoch: 3 [166784/620022]    Loss: 0.008353   Batch Acc: 76.56
[Train] Epoch: 3 [166848/620022]    Loss: 0.010083   Batch Acc: 76.56
[Train] Epoch: 3 [166912/620022]    Loss: 0.008426   Batch Acc: 75.00
[Train] Epoch: 3 [166976/620022]    Loss: 0.010536   Batch Acc: 73.44
[Train] Epoch: 3 [167040/620022]    Loss: 0.011208   Batch Acc: 73.44
[Train] Epoch: 3 [167104/620022]    Loss: 0.008280   Batch Acc: 81.25
[Train] Epoch: 3 [167168/620022]    Loss: 0.009028   Batch Acc: 76.56
[Train] Epoch: 3 [167232/620022]    Loss: 0.006272   Batch Acc: 87.50
[Train] Epoch: 3 [167296/620022]    Loss: 0.007486   Batch Acc: 82.81
[Train] Epoch: 3 [167360/620022]    Loss: 0.010957   Batch Acc: 75.00
[Train] Epoch: 3 [167424/620022]    Loss: 0.007019   Batch Acc: 82.81
[Train] Epoch: 3 [167488/620022]    Loss: 0.009326   Batch Acc: 78.12
[Train] Epoch: 3 [167552/620022]    Loss: 0.006914   Batch Acc: 84.38
[Train] Epoch: 3 [167616/620022]    Loss: 0.008370   Batch Acc: 82.81
[Train] Epoch: 3 [167680/620022]    Loss: 0.010423   Batch Acc: 76.56
[Train] Epoch: 3 [167744/620022]    Loss: 0.008796   Batch Acc: 76.56
[Train] Epoch: 3 [167808/620022]    Loss: 0.008398   Batch Acc: 79.69
[Train] Epoch: 3 [167872/620022]    Loss: 0.008867   Batch Acc: 81.25
[Train] Epoch: 3 [167936/620022]    Loss: 0.012412   Batch Acc: 64.06
[Train] Epoch: 3 [168000/620022]    Loss: 0.007043   Batch Acc: 84.38
[Train] Epoch: 3 [168064/620022]    Loss: 0.008266   Batch Acc: 78.12
[Train] Epoch: 3 [168128/620022]    Loss: 0.008846   Batch Acc: 79.69
[Train] Epoch: 3 [168192/620022]    Loss: 0.008146   Batch Acc: 79.69
[Train] Epoch: 3 [168256/620022]    Loss: 0.008171   Batch Acc: 76.56
[Train] Epoch: 3 [168320/620022]    Loss: 0.007704   Batch Acc: 84.38
[Train] Epoch: 3 [168384/620022]    Loss: 0.009463   Batch Acc: 75.00
[Train] Epoch: 3 [168448/620022]    Loss: 0.007666   Batch Acc: 84.38
[Train] Epoch: 3 [168512/620022]    Loss: 0.007366   Batch Acc: 82.81
[Train] Epoch: 3 [168576/620022]    Loss: 0.010222   Batch Acc: 75.00
[Train] Epoch: 3 [168640/620022]    Loss: 0.007356   Batch Acc: 87.50
[Train] Epoch: 3 [168704/620022]    Loss: 0.010216   Batch Acc: 75.00
[Train] Epoch: 3 [168768/620022]    Loss: 0.010083   Batch Acc: 78.12
[Train] Epoch: 3 [168832/620022]    Loss: 0.009164   Batch Acc: 73.44
[Train] Epoch: 3 [168896/620022]    Loss: 0.008446   Batch Acc: 82.81
[Train] Epoch: 3 [168960/620022]    Loss: 0.007451   Batch Acc: 79.69
[Train] Epoch: 3 [169024/620022]    Loss: 0.008090   Batch Acc: 85.94
[Train] Epoch: 3 [169088/620022]    Loss: 0.006982   Batch Acc: 85.94
[Train] Epoch: 3 [169152/620022]    Loss: 0.009042   Batch Acc: 75.00
[Train] Epoch: 3 [169216/620022]    Loss: 0.011659   Batch Acc: 70.31
[Train] Epoch: 3 [169280/620022]    Loss: 0.005887   Batch Acc: 85.94
[Train] Epoch: 3 [169344/620022]    Loss: 0.006517   Batch Acc: 89.06
[Train] Epoch: 3 [169408/620022]    Loss: 0.007712   Batch Acc: 81.25
[Train] Epoch: 3 [169472/620022]    Loss: 0.008926   Batch Acc: 70.31
[Train] Epoch: 3 [169536/620022]    Loss: 0.008195   Batch Acc: 79.69
[Train] Epoch: 3 [169600/620022]    Loss: 0.007843   Batch Acc: 79.69
[Train] Epoch: 3 [169664/620022]    Loss: 0.009270   Batch Acc: 76.56
[Train] Epoch: 3 [169728/620022]    Loss: 0.008559   Batch Acc: 79.69
[Train] Epoch: 3 [169792/620022]    Loss: 0.006274   Batch Acc: 85.94
[Train] Epoch: 3 [169856/620022]    Loss: 0.008097   Batch Acc: 81.25
[Train] Epoch: 3 [169920/620022]    Loss: 0.008514   Batch Acc: 79.69
[Train] Epoch: 3 [169984/620022]    Loss: 0.006843   Batch Acc: 82.81
[Train] Epoch: 3 [170048/620022]    Loss: 0.009214   Batch Acc: 81.25
[Train] Epoch: 3 [170112/620022]    Loss: 0.009593   Batch Acc: 78.12
[Train] Epoch: 3 [170176/620022]    Loss: 0.005903   Batch Acc: 82.81
[Train] Epoch: 3 [170240/620022]    Loss: 0.008285   Batch Acc: 70.31
[Train] Epoch: 3 [170304/620022]    Loss: 0.008443   Batch Acc: 76.56
[Train] Epoch: 3 [170368/620022]    Loss: 0.010720   Batch Acc: 76.56
[Train] Epoch: 3 [170432/620022]    Loss: 0.008479   Batch Acc: 78.12
[Train] Epoch: 3 [170496/620022]    Loss: 0.008269   Batch Acc: 79.69
[Train] Epoch: 3 [170560/620022]    Loss: 0.012737   Batch Acc: 65.62
[Train] Epoch: 3 [170624/620022]    Loss: 0.008222   Batch Acc: 79.69
[Train] Epoch: 3 [170688/620022]    Loss: 0.008161   Batch Acc: 81.25
[Train] Epoch: 3 [170752/620022]    Loss: 0.006554   Batch Acc: 85.94
[Train] Epoch: 3 [170816/620022]    Loss: 0.008209   Batch Acc: 76.56
[Train] Epoch: 3 [170880/620022]    Loss: 0.008351   Batch Acc: 79.69
[Train] Epoch: 3 [170944/620022]    Loss: 0.006958   Batch Acc: 84.38
[Train] Epoch: 3 [171008/620022]    Loss: 0.010598   Batch Acc: 73.44
[Train] Epoch: 3 [171072/620022]    Loss: 0.008819   Batch Acc: 81.25
[Train] Epoch: 3 [171136/620022]    Loss: 0.009359   Batch Acc: 79.69
[Train] Epoch: 3 [171200/620022]    Loss: 0.006425   Batch Acc: 89.06
[Train] Epoch: 3 [171264/620022]    Loss: 0.008131   Batch Acc: 79.69
[Train] Epoch: 3 [171328/620022]    Loss: 0.009386   Batch Acc: 76.56
[Train] Epoch: 3 [171392/620022]    Loss: 0.010009   Batch Acc: 75.00
[Train] Epoch: 3 [171456/620022]    Loss: 0.008882   Batch Acc: 79.69
[Train] Epoch: 3 [171520/620022]    Loss: 0.007008   Batch Acc: 82.81
[Train] Epoch: 3 [171584/620022]    Loss: 0.008946   Batch Acc: 81.25
[Train] Epoch: 3 [171648/620022]    Loss: 0.008416   Batch Acc: 82.81
[Train] Epoch: 3 [171712/620022]    Loss: 0.007379   Batch Acc: 81.25
[Train] Epoch: 3 [171776/620022]    Loss: 0.005859   Batch Acc: 87.50
[Train] Epoch: 3 [171840/620022]    Loss: 0.006733   Batch Acc: 85.94
[Train] Epoch: 3 [171904/620022]    Loss: 0.007411   Batch Acc: 79.69
[Train] Epoch: 3 [171968/620022]    Loss: 0.008857   Batch Acc: 78.12
[Train] Epoch: 3 [172032/620022]    Loss: 0.009391   Batch Acc: 75.00
[Train] Epoch: 3 [172096/620022]    Loss: 0.008466   Batch Acc: 75.00
[Train] Epoch: 3 [172160/620022]    Loss: 0.009709   Batch Acc: 71.88
[Train] Epoch: 3 [172224/620022]    Loss: 0.007471   Batch Acc: 79.69
[Train] Epoch: 3 [172288/620022]    Loss: 0.009322   Batch Acc: 75.00
[Train] Epoch: 3 [172352/620022]    Loss: 0.009905   Batch Acc: 75.00
[Train] Epoch: 3 [172416/620022]    Loss: 0.008919   Batch Acc: 71.88
[Train] Epoch: 3 [172480/620022]    Loss: 0.010130   Batch Acc: 70.31
[Train] Epoch: 3 [172544/620022]    Loss: 0.009809   Batch Acc: 75.00
[Train] Epoch: 3 [172608/620022]    Loss: 0.009104   Batch Acc: 75.00
[Train] Epoch: 3 [172672/620022]    Loss: 0.008719   Batch Acc: 79.69
[Train] Epoch: 3 [172736/620022]    Loss: 0.009532   Batch Acc: 75.00
[Train] Epoch: 3 [172800/620022]    Loss: 0.006555   Batch Acc: 90.62
[Train] Epoch: 3 [172864/620022]    Loss: 0.007001   Batch Acc: 85.94
[Train] Epoch: 3 [172928/620022]    Loss: 0.008799   Batch Acc: 82.81
[Train] Epoch: 3 [172992/620022]    Loss: 0.008338   Batch Acc: 75.00
[Train] Epoch: 3 [173056/620022]    Loss: 0.010066   Batch Acc: 70.31
[Train] Epoch: 3 [173120/620022]    Loss: 0.007647   Batch Acc: 82.81
[Train] Epoch: 3 [173184/620022]    Loss: 0.007891   Batch Acc: 78.12
[Train] Epoch: 3 [173248/620022]    Loss: 0.008630   Batch Acc: 79.69
[Train] Epoch: 3 [173312/620022]    Loss: 0.006399   Batch Acc: 87.50
[Train] Epoch: 3 [173376/620022]    Loss: 0.007234   Batch Acc: 87.50
[Train] Epoch: 3 [173440/620022]    Loss: 0.009240   Batch Acc: 76.56
[Train] Epoch: 3 [173504/620022]    Loss: 0.009017   Batch Acc: 78.12
[Train] Epoch: 3 [173568/620022]    Loss: 0.009200   Batch Acc: 75.00
[Train] Epoch: 3 [173632/620022]    Loss: 0.010086   Batch Acc: 71.88
[Train] Epoch: 3 [173696/620022]    Loss: 0.009446   Batch Acc: 75.00
[Train] Epoch: 3 [173760/620022]    Loss: 0.010597   Batch Acc: 68.75
[Train] Epoch: 3 [173824/620022]    Loss: 0.009268   Batch Acc: 79.69
[Train] Epoch: 3 [173888/620022]    Loss: 0.008793   Batch Acc: 75.00
[Train] Epoch: 3 [173952/620022]    Loss: 0.007389   Batch Acc: 79.69
[Train] Epoch: 3 [174016/620022]    Loss: 0.007153   Batch Acc: 79.69
[Train] Epoch: 3 [174080/620022]    Loss: 0.009346   Batch Acc: 78.12
[Train] Epoch: 3 [174144/620022]    Loss: 0.009959   Batch Acc: 67.19
[Train] Epoch: 3 [174208/620022]    Loss: 0.009010   Batch Acc: 70.31
[Train] Epoch: 3 [174272/620022]    Loss: 0.007284   Batch Acc: 81.25
[Train] Epoch: 3 [174336/620022]    Loss: 0.007790   Batch Acc: 79.69
[Train] Epoch: 3 [174400/620022]    Loss: 0.009413   Batch Acc: 73.44
[Train] Epoch: 3 [174464/620022]    Loss: 0.007664   Batch Acc: 84.38
[Train] Epoch: 3 [174528/620022]    Loss: 0.008157   Batch Acc: 79.69
[Train] Epoch: 3 [174592/620022]    Loss: 0.008468   Batch Acc: 79.69
[Train] Epoch: 3 [174656/620022]    Loss: 0.009047   Batch Acc: 75.00
[Train] Epoch: 3 [174720/620022]    Loss: 0.007682   Batch Acc: 78.12
[Train] Epoch: 3 [174784/620022]    Loss: 0.009656   Batch Acc: 79.69
[Train] Epoch: 3 [174848/620022]    Loss: 0.010670   Batch Acc: 70.31
[Train] Epoch: 3 [174912/620022]    Loss: 0.007807   Batch Acc: 79.69
[Train] Epoch: 3 [174976/620022]    Loss: 0.010908   Batch Acc: 68.75
[Train] Epoch: 3 [175040/620022]    Loss: 0.009846   Batch Acc: 68.75
[Train] Epoch: 3 [175104/620022]    Loss: 0.008321   Batch Acc: 78.12
[Train] Epoch: 3 [175168/620022]    Loss: 0.009776   Batch Acc: 71.88
[Train] Epoch: 3 [175232/620022]    Loss: 0.010020   Batch Acc: 73.44
[Train] Epoch: 3 [175296/620022]    Loss: 0.009532   Batch Acc: 79.69
[Train] Epoch: 3 [175360/620022]    Loss: 0.009878   Batch Acc: 76.56
[Train] Epoch: 3 [175424/620022]    Loss: 0.007296   Batch Acc: 79.69
[Train] Epoch: 3 [175488/620022]    Loss: 0.009144   Batch Acc: 73.44
[Train] Epoch: 3 [175552/620022]    Loss: 0.007805   Batch Acc: 81.25
[Train] Epoch: 3 [175616/620022]    Loss: 0.009504   Batch Acc: 78.12
[Train] Epoch: 3 [175680/620022]    Loss: 0.010244   Batch Acc: 73.44
[Train] Epoch: 3 [175744/620022]    Loss: 0.007190   Batch Acc: 78.12
[Train] Epoch: 3 [175808/620022]    Loss: 0.007692   Batch Acc: 73.44
[Train] Epoch: 3 [175872/620022]    Loss: 0.007993   Batch Acc: 76.56
[Train] Epoch: 3 [175936/620022]    Loss: 0.008703   Batch Acc: 81.25
[Train] Epoch: 3 [176000/620022]    Loss: 0.007834   Batch Acc: 82.81
[Train] Epoch: 3 [176064/620022]    Loss: 0.008794   Batch Acc: 81.25
[Train] Epoch: 3 [176128/620022]    Loss: 0.008198   Batch Acc: 78.12
[Train] Epoch: 3 [176192/620022]    Loss: 0.008297   Batch Acc: 78.12
[Train] Epoch: 3 [176256/620022]    Loss: 0.006380   Batch Acc: 85.94
[Train] Epoch: 3 [176320/620022]    Loss: 0.006914   Batch Acc: 81.25
[Train] Epoch: 3 [176384/620022]    Loss: 0.008394   Batch Acc: 81.25
[Train] Epoch: 3 [176448/620022]    Loss: 0.009135   Batch Acc: 75.00
[Train] Epoch: 3 [176512/620022]    Loss: 0.005394   Batch Acc: 89.06
[Train] Epoch: 3 [176576/620022]    Loss: 0.007682   Batch Acc: 81.25
[Train] Epoch: 3 [176640/620022]    Loss: 0.010813   Batch Acc: 71.88
[Train] Epoch: 3 [176704/620022]    Loss: 0.008264   Batch Acc: 79.69
[Train] Epoch: 3 [176768/620022]    Loss: 0.008628   Batch Acc: 75.00
[Train] Epoch: 3 [176832/620022]    Loss: 0.007806   Batch Acc: 82.81
[Train] Epoch: 3 [176896/620022]    Loss: 0.007982   Batch Acc: 75.00
[Train] Epoch: 3 [176960/620022]    Loss: 0.009765   Batch Acc: 81.25
[Train] Epoch: 3 [177024/620022]    Loss: 0.007757   Batch Acc: 82.81
[Train] Epoch: 3 [177088/620022]    Loss: 0.008139   Batch Acc: 82.81
[Train] Epoch: 3 [177152/620022]    Loss: 0.009143   Batch Acc: 79.69
[Train] Epoch: 3 [177216/620022]    Loss: 0.008823   Batch Acc: 79.69
[Train] Epoch: 3 [177280/620022]    Loss: 0.007515   Batch Acc: 81.25
[Train] Epoch: 3 [177344/620022]    Loss: 0.008651   Batch Acc: 78.12
[Train] Epoch: 3 [177408/620022]    Loss: 0.007502   Batch Acc: 79.69
[Train] Epoch: 3 [177472/620022]    Loss: 0.008534   Batch Acc: 76.56
[Train] Epoch: 3 [177536/620022]    Loss: 0.009363   Batch Acc: 71.88
[Train] Epoch: 3 [177600/620022]    Loss: 0.010752   Batch Acc: 73.44
[Train] Epoch: 3 [177664/620022]    Loss: 0.009595   Batch Acc: 76.56
[Train] Epoch: 3 [177728/620022]    Loss: 0.007568   Batch Acc: 82.81
[Train] Epoch: 3 [177792/620022]    Loss: 0.008783   Batch Acc: 75.00
[Train] Epoch: 3 [177856/620022]    Loss: 0.007555   Batch Acc: 79.69
[Train] Epoch: 3 [177920/620022]    Loss: 0.009028   Batch Acc: 76.56
[Train] Epoch: 3 [177984/620022]    Loss: 0.007348   Batch Acc: 78.12
[Train] Epoch: 3 [178048/620022]    Loss: 0.009903   Batch Acc: 73.44
[Train] Epoch: 3 [178112/620022]    Loss: 0.009110   Batch Acc: 78.12
[Train] Epoch: 3 [178176/620022]    Loss: 0.010413   Batch Acc: 70.31
[Train] Epoch: 3 [178240/620022]    Loss: 0.009065   Batch Acc: 76.56
[Train] Epoch: 3 [178304/620022]    Loss: 0.010089   Batch Acc: 73.44
[Train] Epoch: 3 [178368/620022]    Loss: 0.009328   Batch Acc: 78.12
[Train] Epoch: 3 [178432/620022]    Loss: 0.009281   Batch Acc: 81.25
[Train] Epoch: 3 [178496/620022]    Loss: 0.010044   Batch Acc: 76.56
[Train] Epoch: 3 [178560/620022]    Loss: 0.010803   Batch Acc: 70.31
[Train] Epoch: 3 [178624/620022]    Loss: 0.010107   Batch Acc: 68.75
[Train] Epoch: 3 [178688/620022]    Loss: 0.007016   Batch Acc: 79.69
[Train] Epoch: 3 [178752/620022]    Loss: 0.010516   Batch Acc: 75.00
[Train] Epoch: 3 [178816/620022]    Loss: 0.006426   Batch Acc: 92.19
[Train] Epoch: 3 [178880/620022]    Loss: 0.006291   Batch Acc: 85.94
[Train] Epoch: 3 [178944/620022]    Loss: 0.007088   Batch Acc: 84.38
[Train] Epoch: 3 [179008/620022]    Loss: 0.005822   Batch Acc: 89.06
[Train] Epoch: 3 [179072/620022]    Loss: 0.007054   Batch Acc: 84.38
[Train] Epoch: 3 [179136/620022]    Loss: 0.008918   Batch Acc: 78.12
[Train] Epoch: 3 [179200/620022]    Loss: 0.011127   Batch Acc: 68.75
[Train] Epoch: 3 [179264/620022]    Loss: 0.012241   Batch Acc: 64.06
[Train] Epoch: 3 [179328/620022]    Loss: 0.008023   Batch Acc: 84.38
[Train] Epoch: 3 [179392/620022]    Loss: 0.009482   Batch Acc: 79.69
[Train] Epoch: 3 [179456/620022]    Loss: 0.008224   Batch Acc: 81.25
[Train] Epoch: 3 [179520/620022]    Loss: 0.007158   Batch Acc: 84.38
[Train] Epoch: 3 [179584/620022]    Loss: 0.010625   Batch Acc: 71.88
[Train] Epoch: 3 [179648/620022]    Loss: 0.009272   Batch Acc: 73.44
[Train] Epoch: 3 [179712/620022]    Loss: 0.008008   Batch Acc: 79.69
[Train] Epoch: 3 [179776/620022]    Loss: 0.008405   Batch Acc: 78.12
[Train] Epoch: 3 [179840/620022]    Loss: 0.010809   Batch Acc: 65.62
[Train] Epoch: 3 [179904/620022]    Loss: 0.008550   Batch Acc: 82.81
[Train] Epoch: 3 [179968/620022]    Loss: 0.010058   Batch Acc: 75.00
[Train] Epoch: 3 [180032/620022]    Loss: 0.009035   Batch Acc: 75.00
[Train] Epoch: 3 [180096/620022]    Loss: 0.006410   Batch Acc: 85.94
[Train] Epoch: 3 [180160/620022]    Loss: 0.007198   Batch Acc: 82.81
[Train] Epoch: 3 [180224/620022]    Loss: 0.006523   Batch Acc: 87.50
[Train] Epoch: 3 [180288/620022]    Loss: 0.007551   Batch Acc: 81.25
[Train] Epoch: 3 [180352/620022]    Loss: 0.010426   Batch Acc: 73.44
[Train] Epoch: 3 [180416/620022]    Loss: 0.006558   Batch Acc: 85.94
[Train] Epoch: 3 [180480/620022]    Loss: 0.007892   Batch Acc: 85.94
[Train] Epoch: 3 [180544/620022]    Loss: 0.007795   Batch Acc: 84.38
[Train] Epoch: 3 [180608/620022]    Loss: 0.009747   Batch Acc: 68.75
[Train] Epoch: 3 [180672/620022]    Loss: 0.009552   Batch Acc: 73.44
[Train] Epoch: 3 [180736/620022]    Loss: 0.008131   Batch Acc: 79.69
[Train] Epoch: 3 [180800/620022]    Loss: 0.009080   Batch Acc: 79.69
[Train] Epoch: 3 [180864/620022]    Loss: 0.007365   Batch Acc: 82.81
[Train] Epoch: 3 [180928/620022]    Loss: 0.007560   Batch Acc: 81.25
[Train] Epoch: 3 [180992/620022]    Loss: 0.006571   Batch Acc: 84.38
[Train] Epoch: 3 [181056/620022]    Loss: 0.010603   Batch Acc: 76.56
[Train] Epoch: 3 [181120/620022]    Loss: 0.010437   Batch Acc: 75.00
[Train] Epoch: 3 [181184/620022]    Loss: 0.007896   Batch Acc: 84.38
[Train] Epoch: 3 [181248/620022]    Loss: 0.007292   Batch Acc: 81.25
[Train] Epoch: 3 [181312/620022]    Loss: 0.008388   Batch Acc: 73.44
[Train] Epoch: 3 [181376/620022]    Loss: 0.006505   Batch Acc: 85.94
[Train] Epoch: 3 [181440/620022]    Loss: 0.009301   Batch Acc: 75.00
[Train] Epoch: 3 [181504/620022]    Loss: 0.007339   Batch Acc: 85.94
[Train] Epoch: 3 [181568/620022]    Loss: 0.011097   Batch Acc: 71.88
[Train] Epoch: 3 [181632/620022]    Loss: 0.008453   Batch Acc: 79.69
[Train] Epoch: 3 [181696/620022]    Loss: 0.008156   Batch Acc: 75.00
[Train] Epoch: 3 [181760/620022]    Loss: 0.009880   Batch Acc: 78.12
[Train] Epoch: 3 [181824/620022]    Loss: 0.008081   Batch Acc: 82.81
[Train] Epoch: 3 [181888/620022]    Loss: 0.008063   Batch Acc: 78.12
[Train] Epoch: 3 [181952/620022]    Loss: 0.008268   Batch Acc: 76.56
[Train] Epoch: 3 [182016/620022]    Loss: 0.009692   Batch Acc: 75.00
[Train] Epoch: 3 [182080/620022]    Loss: 0.008872   Batch Acc: 75.00
[Train] Epoch: 3 [182144/620022]    Loss: 0.006538   Batch Acc: 84.38
[Train] Epoch: 3 [182208/620022]    Loss: 0.010191   Batch Acc: 73.44
[Train] Epoch: 3 [182272/620022]    Loss: 0.008823   Batch Acc: 76.56
[Train] Epoch: 3 [182336/620022]    Loss: 0.008483   Batch Acc: 81.25
[Train] Epoch: 3 [182400/620022]    Loss: 0.007328   Batch Acc: 82.81
[Train] Epoch: 3 [182464/620022]    Loss: 0.008716   Batch Acc: 76.56
[Train] Epoch: 3 [182528/620022]    Loss: 0.008095   Batch Acc: 79.69
[Train] Epoch: 3 [182592/620022]    Loss: 0.009200   Batch Acc: 73.44
[Train] Epoch: 3 [182656/620022]    Loss: 0.012119   Batch Acc: 68.75
[Train] Epoch: 3 [182720/620022]    Loss: 0.009826   Batch Acc: 73.44
[Train] Epoch: 3 [182784/620022]    Loss: 0.011078   Batch Acc: 73.44
[Train] Epoch: 3 [182848/620022]    Loss: 0.010426   Batch Acc: 70.31
[Train] Epoch: 3 [182912/620022]    Loss: 0.008253   Batch Acc: 78.12
[Train] Epoch: 3 [182976/620022]    Loss: 0.006593   Batch Acc: 84.38
[Train] Epoch: 3 [183040/620022]    Loss: 0.009431   Batch Acc: 79.69
[Train] Epoch: 3 [183104/620022]    Loss: 0.007656   Batch Acc: 82.81
[Train] Epoch: 3 [183168/620022]    Loss: 0.007993   Batch Acc: 85.94
[Train] Epoch: 3 [183232/620022]    Loss: 0.008700   Batch Acc: 78.12
[Train] Epoch: 3 [183296/620022]    Loss: 0.011244   Batch Acc: 65.62
[Train] Epoch: 3 [183360/620022]    Loss: 0.011241   Batch Acc: 70.31
[Train] Epoch: 3 [183424/620022]    Loss: 0.008081   Batch Acc: 81.25
[Train] Epoch: 3 [183488/620022]    Loss: 0.007499   Batch Acc: 84.38
[Train] Epoch: 3 [183552/620022]    Loss: 0.009823   Batch Acc: 79.69
[Train] Epoch: 3 [183616/620022]    Loss: 0.008918   Batch Acc: 79.69
[Train] Epoch: 3 [183680/620022]    Loss: 0.008615   Batch Acc: 73.44
[Train] Epoch: 3 [183744/620022]    Loss: 0.010940   Batch Acc: 68.75
[Train] Epoch: 3 [183808/620022]    Loss: 0.008976   Batch Acc: 71.88
[Train] Epoch: 3 [183872/620022]    Loss: 0.010120   Batch Acc: 75.00
[Train] Epoch: 3 [183936/620022]    Loss: 0.007828   Batch Acc: 81.25
[Train] Epoch: 3 [184000/620022]    Loss: 0.008849   Batch Acc: 79.69
[Train] Epoch: 3 [184064/620022]    Loss: 0.010348   Batch Acc: 68.75
[Train] Epoch: 3 [184128/620022]    Loss: 0.008451   Batch Acc: 81.25
[Train] Epoch: 3 [184192/620022]    Loss: 0.008195   Batch Acc: 75.00
[Train] Epoch: 3 [184256/620022]    Loss: 0.009421   Batch Acc: 81.25
[Train] Epoch: 3 [184320/620022]    Loss: 0.008275   Batch Acc: 79.69
[Train] Epoch: 3 [184384/620022]    Loss: 0.009930   Batch Acc: 76.56
[Train] Epoch: 3 [184448/620022]    Loss: 0.009165   Batch Acc: 75.00
[Train] Epoch: 3 [184512/620022]    Loss: 0.009576   Batch Acc: 70.31
[Train] Epoch: 3 [184576/620022]    Loss: 0.006802   Batch Acc: 84.38
[Train] Epoch: 3 [184640/620022]    Loss: 0.007320   Batch Acc: 75.00
[Train] Epoch: 3 [184704/620022]    Loss: 0.008812   Batch Acc: 76.56
[Train] Epoch: 3 [184768/620022]    Loss: 0.008555   Batch Acc: 78.12
[Train] Epoch: 3 [184832/620022]    Loss: 0.009850   Batch Acc: 75.00
[Train] Epoch: 3 [184896/620022]    Loss: 0.008358   Batch Acc: 73.44
[Train] Epoch: 3 [184960/620022]    Loss: 0.008159   Batch Acc: 82.81
[Train] Epoch: 3 [185024/620022]    Loss: 0.007285   Batch Acc: 84.38
[Train] Epoch: 3 [185088/620022]    Loss: 0.007537   Batch Acc: 85.94
[Train] Epoch: 3 [185152/620022]    Loss: 0.007549   Batch Acc: 84.38
[Train] Epoch: 3 [185216/620022]    Loss: 0.008370   Batch Acc: 76.56
[Train] Epoch: 3 [185280/620022]    Loss: 0.008507   Batch Acc: 81.25
[Train] Epoch: 3 [185344/620022]    Loss: 0.008201   Batch Acc: 81.25
[Train] Epoch: 3 [185408/620022]    Loss: 0.007668   Batch Acc: 76.56
[Train] Epoch: 3 [185472/620022]    Loss: 0.008118   Batch Acc: 75.00
[Train] Epoch: 3 [185536/620022]    Loss: 0.010126   Batch Acc: 78.12
[Train] Epoch: 3 [185600/620022]    Loss: 0.008993   Batch Acc: 73.44
[Train] Epoch: 3 [185664/620022]    Loss: 0.007619   Batch Acc: 79.69
[Train] Epoch: 3 [185728/620022]    Loss: 0.007412   Batch Acc: 84.38
[Train] Epoch: 3 [185792/620022]    Loss: 0.008344   Batch Acc: 81.25
[Train] Epoch: 3 [185856/620022]    Loss: 0.009575   Batch Acc: 82.81
[Train] Epoch: 3 [185920/620022]    Loss: 0.008920   Batch Acc: 70.31
[Train] Epoch: 3 [185984/620022]    Loss: 0.008984   Batch Acc: 78.12
[Train] Epoch: 3 [186048/620022]    Loss: 0.009140   Batch Acc: 71.88
[Train] Epoch: 3 [186112/620022]    Loss: 0.007168   Batch Acc: 82.81
[Train] Epoch: 3 [186176/620022]    Loss: 0.007826   Batch Acc: 75.00
[Train] Epoch: 3 [186240/620022]    Loss: 0.010287   Batch Acc: 79.69
[Train] Epoch: 3 [186304/620022]    Loss: 0.008789   Batch Acc: 75.00
[Train] Epoch: 3 [186368/620022]    Loss: 0.010380   Batch Acc: 78.12
[Train] Epoch: 3 [186432/620022]    Loss: 0.009020   Batch Acc: 73.44
[Train] Epoch: 3 [186496/620022]    Loss: 0.008206   Batch Acc: 78.12
[Train] Epoch: 3 [186560/620022]    Loss: 0.008977   Batch Acc: 76.56
[Train] Epoch: 3 [186624/620022]    Loss: 0.008811   Batch Acc: 78.12
[Train] Epoch: 3 [186688/620022]    Loss: 0.011373   Batch Acc: 68.75
[Train] Epoch: 3 [186752/620022]    Loss: 0.008640   Batch Acc: 73.44
[Train] Epoch: 3 [186816/620022]    Loss: 0.006742   Batch Acc: 81.25
[Train] Epoch: 3 [186880/620022]    Loss: 0.007398   Batch Acc: 78.12
[Train] Epoch: 3 [186944/620022]    Loss: 0.008368   Batch Acc: 79.69
[Train] Epoch: 3 [187008/620022]    Loss: 0.007514   Batch Acc: 79.69
[Train] Epoch: 3 [187072/620022]    Loss: 0.009182   Batch Acc: 81.25
[Train] Epoch: 3 [187136/620022]    Loss: 0.008893   Batch Acc: 81.25
[Train] Epoch: 3 [187200/620022]    Loss: 0.007327   Batch Acc: 76.56
[Train] Epoch: 3 [187264/620022]    Loss: 0.010911   Batch Acc: 65.62
[Train] Epoch: 3 [187328/620022]    Loss: 0.008493   Batch Acc: 79.69
[Train] Epoch: 3 [187392/620022]    Loss: 0.009417   Batch Acc: 75.00
[Train] Epoch: 3 [187456/620022]    Loss: 0.007178   Batch Acc: 78.12
[Train] Epoch: 3 [187520/620022]    Loss: 0.010595   Batch Acc: 76.56
[Train] Epoch: 3 [187584/620022]    Loss: 0.008400   Batch Acc: 73.44
[Train] Epoch: 3 [187648/620022]    Loss: 0.007868   Batch Acc: 81.25
[Train] Epoch: 3 [187712/620022]    Loss: 0.008682   Batch Acc: 73.44
[Train] Epoch: 3 [187776/620022]    Loss: 0.008084   Batch Acc: 78.12
[Train] Epoch: 3 [187840/620022]    Loss: 0.010680   Batch Acc: 75.00
[Train] Epoch: 3 [187904/620022]    Loss: 0.010529   Batch Acc: 73.44
[Train] Epoch: 3 [187968/620022]    Loss: 0.009018   Batch Acc: 71.88
[Train] Epoch: 3 [188032/620022]    Loss: 0.007957   Batch Acc: 79.69
[Train] Epoch: 3 [188096/620022]    Loss: 0.007394   Batch Acc: 84.38
[Train] Epoch: 3 [188160/620022]    Loss: 0.009349   Batch Acc: 78.12
[Train] Epoch: 3 [188224/620022]    Loss: 0.006264   Batch Acc: 89.06
[Train] Epoch: 3 [188288/620022]    Loss: 0.009421   Batch Acc: 76.56
[Train] Epoch: 3 [188352/620022]    Loss: 0.008042   Batch Acc: 79.69
[Train] Epoch: 3 [188416/620022]    Loss: 0.008411   Batch Acc: 81.25
[Train] Epoch: 3 [188480/620022]    Loss: 0.010300   Batch Acc: 70.31
[Train] Epoch: 3 [188544/620022]    Loss: 0.012877   Batch Acc: 57.81
[Train] Epoch: 3 [188608/620022]    Loss: 0.008241   Batch Acc: 78.12
[Train] Epoch: 3 [188672/620022]    Loss: 0.007883   Batch Acc: 76.56
[Train] Epoch: 3 [188736/620022]    Loss: 0.009154   Batch Acc: 75.00
[Train] Epoch: 3 [188800/620022]    Loss: 0.010550   Batch Acc: 70.31
[Train] Epoch: 3 [188864/620022]    Loss: 0.008772   Batch Acc: 78.12
[Train] Epoch: 3 [188928/620022]    Loss: 0.008213   Batch Acc: 76.56
[Train] Epoch: 3 [188992/620022]    Loss: 0.008442   Batch Acc: 75.00
[Train] Epoch: 3 [189056/620022]    Loss: 0.010513   Batch Acc: 68.75
[Train] Epoch: 3 [189120/620022]    Loss: 0.009809   Batch Acc: 71.88
[Train] Epoch: 3 [189184/620022]    Loss: 0.005084   Batch Acc: 85.94
[Train] Epoch: 3 [189248/620022]    Loss: 0.011654   Batch Acc: 64.06
[Train] Epoch: 3 [189312/620022]    Loss: 0.008964   Batch Acc: 75.00
[Train] Epoch: 3 [189376/620022]    Loss: 0.005600   Batch Acc: 87.50
[Train] Epoch: 3 [189440/620022]    Loss: 0.007162   Batch Acc: 79.69
[Train] Epoch: 3 [189504/620022]    Loss: 0.006644   Batch Acc: 85.94
[Train] Epoch: 3 [189568/620022]    Loss: 0.009655   Batch Acc: 70.31
[Train] Epoch: 3 [189632/620022]    Loss: 0.008724   Batch Acc: 81.25
[Train] Epoch: 3 [189696/620022]    Loss: 0.007757   Batch Acc: 82.81
[Train] Epoch: 3 [189760/620022]    Loss: 0.008613   Batch Acc: 73.44
[Train] Epoch: 3 [189824/620022]    Loss: 0.008627   Batch Acc: 78.12
[Train] Epoch: 3 [189888/620022]    Loss: 0.009360   Batch Acc: 78.12
[Train] Epoch: 3 [189952/620022]    Loss: 0.008444   Batch Acc: 82.81
[Train] Epoch: 3 [190016/620022]    Loss: 0.008688   Batch Acc: 71.88
[Train] Epoch: 3 [190080/620022]    Loss: 0.007337   Batch Acc: 78.12
[Train] Epoch: 3 [190144/620022]    Loss: 0.009914   Batch Acc: 70.31
[Train] Epoch: 3 [190208/620022]    Loss: 0.007818   Batch Acc: 84.38
[Train] Epoch: 3 [190272/620022]    Loss: 0.010952   Batch Acc: 73.44
[Train] Epoch: 3 [190336/620022]    Loss: 0.007604   Batch Acc: 81.25
[Train] Epoch: 3 [190400/620022]    Loss: 0.008241   Batch Acc: 76.56
[Train] Epoch: 3 [190464/620022]    Loss: 0.007099   Batch Acc: 76.56
[Train] Epoch: 3 [190528/620022]    Loss: 0.007787   Batch Acc: 81.25
[Train] Epoch: 3 [190592/620022]    Loss: 0.010752   Batch Acc: 73.44
[Train] Epoch: 3 [190656/620022]    Loss: 0.007434   Batch Acc: 84.38
[Train] Epoch: 3 [190720/620022]    Loss: 0.006939   Batch Acc: 87.50
[Train] Epoch: 3 [190784/620022]    Loss: 0.007911   Batch Acc: 81.25
[Train] Epoch: 3 [190848/620022]    Loss: 0.008615   Batch Acc: 82.81
[Train] Epoch: 3 [190912/620022]    Loss: 0.009607   Batch Acc: 73.44
[Train] Epoch: 3 [190976/620022]    Loss: 0.009725   Batch Acc: 70.31
[Train] Epoch: 3 [191040/620022]    Loss: 0.008595   Batch Acc: 79.69
[Train] Epoch: 3 [191104/620022]    Loss: 0.009419   Batch Acc: 75.00
[Train] Epoch: 3 [191168/620022]    Loss: 0.008125   Batch Acc: 81.25
[Train] Epoch: 3 [191232/620022]    Loss: 0.009419   Batch Acc: 78.12
[Train] Epoch: 3 [191296/620022]    Loss: 0.007847   Batch Acc: 81.25
[Train] Epoch: 3 [191360/620022]    Loss: 0.007362   Batch Acc: 79.69
[Train] Epoch: 3 [191424/620022]    Loss: 0.008027   Batch Acc: 82.81
[Train] Epoch: 3 [191488/620022]    Loss: 0.010228   Batch Acc: 68.75
[Train] Epoch: 3 [191552/620022]    Loss: 0.009457   Batch Acc: 68.75
[Train] Epoch: 3 [191616/620022]    Loss: 0.008583   Batch Acc: 76.56
[Train] Epoch: 3 [191680/620022]    Loss: 0.009802   Batch Acc: 76.56
[Train] Epoch: 3 [191744/620022]    Loss: 0.009282   Batch Acc: 75.00
[Train] Epoch: 3 [191808/620022]    Loss: 0.007372   Batch Acc: 87.50
[Train] Epoch: 3 [191872/620022]    Loss: 0.008481   Batch Acc: 81.25
[Train] Epoch: 3 [191936/620022]    Loss: 0.007610   Batch Acc: 82.81
[Train] Epoch: 3 [192000/620022]    Loss: 0.007772   Batch Acc: 79.69
[Train] Epoch: 3 [192064/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 3 [192128/620022]    Loss: 0.009028   Batch Acc: 76.56
[Train] Epoch: 3 [192192/620022]    Loss: 0.008724   Batch Acc: 76.56
[Train] Epoch: 3 [192256/620022]    Loss: 0.009436   Batch Acc: 75.00
[Train] Epoch: 3 [192320/620022]    Loss: 0.007676   Batch Acc: 81.25
[Train] Epoch: 3 [192384/620022]    Loss: 0.008847   Batch Acc: 75.00
[Train] Epoch: 3 [192448/620022]    Loss: 0.009841   Batch Acc: 73.44
[Train] Epoch: 3 [192512/620022]    Loss: 0.008596   Batch Acc: 78.12
[Train] Epoch: 3 [192576/620022]    Loss: 0.008687   Batch Acc: 82.81
[Train] Epoch: 3 [192640/620022]    Loss: 0.008872   Batch Acc: 78.12
[Train] Epoch: 3 [192704/620022]    Loss: 0.011189   Batch Acc: 67.19
[Train] Epoch: 3 [192768/620022]    Loss: 0.008542   Batch Acc: 81.25
[Train] Epoch: 3 [192832/620022]    Loss: 0.007416   Batch Acc: 82.81
[Train] Epoch: 3 [192896/620022]    Loss: 0.007933   Batch Acc: 76.56
[Train] Epoch: 3 [192960/620022]    Loss: 0.007027   Batch Acc: 81.25
[Train] Epoch: 3 [193024/620022]    Loss: 0.007389   Batch Acc: 81.25
[Train] Epoch: 3 [193088/620022]    Loss: 0.007416   Batch Acc: 78.12
[Train] Epoch: 3 [193152/620022]    Loss: 0.006601   Batch Acc: 82.81
[Train] Epoch: 3 [193216/620022]    Loss: 0.009273   Batch Acc: 78.12
[Train] Epoch: 3 [193280/620022]    Loss: 0.007984   Batch Acc: 84.38
[Train] Epoch: 3 [193344/620022]    Loss: 0.007142   Batch Acc: 81.25
[Train] Epoch: 3 [193408/620022]    Loss: 0.009482   Batch Acc: 76.56
[Train] Epoch: 3 [193472/620022]    Loss: 0.008079   Batch Acc: 79.69
[Train] Epoch: 3 [193536/620022]    Loss: 0.006814   Batch Acc: 87.50
[Train] Epoch: 3 [193600/620022]    Loss: 0.009253   Batch Acc: 78.12
[Train] Epoch: 3 [193664/620022]    Loss: 0.008148   Batch Acc: 82.81
[Train] Epoch: 3 [193728/620022]    Loss: 0.010023   Batch Acc: 73.44
[Train] Epoch: 3 [193792/620022]    Loss: 0.007672   Batch Acc: 82.81
[Train] Epoch: 3 [193856/620022]    Loss: 0.008535   Batch Acc: 75.00
[Train] Epoch: 3 [193920/620022]    Loss: 0.008296   Batch Acc: 84.38
[Train] Epoch: 3 [193984/620022]    Loss: 0.009660   Batch Acc: 76.56
[Train] Epoch: 3 [194048/620022]    Loss: 0.007900   Batch Acc: 79.69
[Train] Epoch: 3 [194112/620022]    Loss: 0.011256   Batch Acc: 71.88
[Train] Epoch: 3 [194176/620022]    Loss: 0.011465   Batch Acc: 65.62
[Train] Epoch: 3 [194240/620022]    Loss: 0.008154   Batch Acc: 85.94
[Train] Epoch: 3 [194304/620022]    Loss: 0.011177   Batch Acc: 68.75
[Train] Epoch: 3 [194368/620022]    Loss: 0.008138   Batch Acc: 82.81
[Train] Epoch: 3 [194432/620022]    Loss: 0.006028   Batch Acc: 85.94
[Train] Epoch: 3 [194496/620022]    Loss: 0.008398   Batch Acc: 78.12
[Train] Epoch: 3 [194560/620022]    Loss: 0.008197   Batch Acc: 78.12
[Train] Epoch: 3 [194624/620022]    Loss: 0.010381   Batch Acc: 71.88
[Train] Epoch: 3 [194688/620022]    Loss: 0.011219   Batch Acc: 71.88
[Train] Epoch: 3 [194752/620022]    Loss: 0.008378   Batch Acc: 73.44
[Train] Epoch: 3 [194816/620022]    Loss: 0.009670   Batch Acc: 78.12
[Train] Epoch: 3 [194880/620022]    Loss: 0.006519   Batch Acc: 85.94
[Train] Epoch: 3 [194944/620022]    Loss: 0.010233   Batch Acc: 73.44
[Train] Epoch: 3 [195008/620022]    Loss: 0.007750   Batch Acc: 82.81
[Train] Epoch: 3 [195072/620022]    Loss: 0.008047   Batch Acc: 81.25
[Train] Epoch: 3 [195136/620022]    Loss: 0.008805   Batch Acc: 71.88
[Train] Epoch: 3 [195200/620022]    Loss: 0.007103   Batch Acc: 75.00
[Train] Epoch: 3 [195264/620022]    Loss: 0.008233   Batch Acc: 75.00
[Train] Epoch: 3 [195328/620022]    Loss: 0.009250   Batch Acc: 75.00
[Train] Epoch: 3 [195392/620022]    Loss: 0.006767   Batch Acc: 79.69
[Train] Epoch: 3 [195456/620022]    Loss: 0.007591   Batch Acc: 81.25
[Train] Epoch: 3 [195520/620022]    Loss: 0.006883   Batch Acc: 81.25
[Train] Epoch: 3 [195584/620022]    Loss: 0.008473   Batch Acc: 75.00
[Train] Epoch: 3 [195648/620022]    Loss: 0.006896   Batch Acc: 82.81
[Train] Epoch: 3 [195712/620022]    Loss: 0.009567   Batch Acc: 73.44
[Train] Epoch: 3 [195776/620022]    Loss: 0.008580   Batch Acc: 76.56
[Train] Epoch: 3 [195840/620022]    Loss: 0.006788   Batch Acc: 84.38
[Train] Epoch: 3 [195904/620022]    Loss: 0.008322   Batch Acc: 81.25
[Train] Epoch: 3 [195968/620022]    Loss: 0.008637   Batch Acc: 78.12
[Train] Epoch: 3 [196032/620022]    Loss: 0.008992   Batch Acc: 76.56
[Train] Epoch: 3 [196096/620022]    Loss: 0.010785   Batch Acc: 78.12
[Train] Epoch: 3 [196160/620022]    Loss: 0.011159   Batch Acc: 75.00
[Train] Epoch: 3 [196224/620022]    Loss: 0.007094   Batch Acc: 89.06
[Train] Epoch: 3 [196288/620022]    Loss: 0.011585   Batch Acc: 70.31
[Train] Epoch: 3 [196352/620022]    Loss: 0.008533   Batch Acc: 81.25
[Train] Epoch: 3 [196416/620022]    Loss: 0.007963   Batch Acc: 79.69
[Train] Epoch: 3 [196480/620022]    Loss: 0.007792   Batch Acc: 79.69
[Train] Epoch: 3 [196544/620022]    Loss: 0.009260   Batch Acc: 75.00
[Train] Epoch: 3 [196608/620022]    Loss: 0.010221   Batch Acc: 73.44
[Train] Epoch: 3 [196672/620022]    Loss: 0.008770   Batch Acc: 76.56
[Train] Epoch: 3 [196736/620022]    Loss: 0.007422   Batch Acc: 82.81
[Train] Epoch: 3 [196800/620022]    Loss: 0.007691   Batch Acc: 82.81
[Train] Epoch: 3 [196864/620022]    Loss: 0.009390   Batch Acc: 73.44
[Train] Epoch: 3 [196928/620022]    Loss: 0.006606   Batch Acc: 84.38
[Train] Epoch: 3 [196992/620022]    Loss: 0.009057   Batch Acc: 73.44
[Train] Epoch: 3 [197056/620022]    Loss: 0.012565   Batch Acc: 64.06
[Train] Epoch: 3 [197120/620022]    Loss: 0.011338   Batch Acc: 73.44
[Train] Epoch: 3 [197184/620022]    Loss: 0.009467   Batch Acc: 82.81
[Train] Epoch: 3 [197248/620022]    Loss: 0.008957   Batch Acc: 79.69
[Train] Epoch: 3 [197312/620022]    Loss: 0.008739   Batch Acc: 75.00
[Train] Epoch: 3 [197376/620022]    Loss: 0.008761   Batch Acc: 79.69
[Train] Epoch: 3 [197440/620022]    Loss: 0.006051   Batch Acc: 84.38
[Train] Epoch: 3 [197504/620022]    Loss: 0.009167   Batch Acc: 81.25
[Train] Epoch: 3 [197568/620022]    Loss: 0.009360   Batch Acc: 76.56
[Train] Epoch: 3 [197632/620022]    Loss: 0.008494   Batch Acc: 75.00
[Train] Epoch: 3 [197696/620022]    Loss: 0.011866   Batch Acc: 71.88
[Train] Epoch: 3 [197760/620022]    Loss: 0.006769   Batch Acc: 89.06
[Train] Epoch: 3 [197824/620022]    Loss: 0.010542   Batch Acc: 67.19
[Train] Epoch: 3 [197888/620022]    Loss: 0.012208   Batch Acc: 68.75
[Train] Epoch: 3 [197952/620022]    Loss: 0.008606   Batch Acc: 79.69
[Train] Epoch: 3 [198016/620022]    Loss: 0.011282   Batch Acc: 70.31
[Train] Epoch: 3 [198080/620022]    Loss: 0.008034   Batch Acc: 78.12
[Train] Epoch: 3 [198144/620022]    Loss: 0.010387   Batch Acc: 71.88
[Train] Epoch: 3 [198208/620022]    Loss: 0.007481   Batch Acc: 70.31
[Train] Epoch: 3 [198272/620022]    Loss: 0.009122   Batch Acc: 71.88
[Train] Epoch: 3 [198336/620022]    Loss: 0.008481   Batch Acc: 81.25
[Train] Epoch: 3 [198400/620022]    Loss: 0.006942   Batch Acc: 84.38
[Train] Epoch: 3 [198464/620022]    Loss: 0.008300   Batch Acc: 81.25
[Train] Epoch: 3 [198528/620022]    Loss: 0.007976   Batch Acc: 82.81
[Train] Epoch: 3 [198592/620022]    Loss: 0.007518   Batch Acc: 76.56
[Train] Epoch: 3 [198656/620022]    Loss: 0.005907   Batch Acc: 85.94
[Train] Epoch: 3 [198720/620022]    Loss: 0.008801   Batch Acc: 79.69
[Train] Epoch: 3 [198784/620022]    Loss: 0.007279   Batch Acc: 85.94
[Train] Epoch: 3 [198848/620022]    Loss: 0.007880   Batch Acc: 85.94
[Train] Epoch: 3 [198912/620022]    Loss: 0.009285   Batch Acc: 73.44
[Train] Epoch: 3 [198976/620022]    Loss: 0.009422   Batch Acc: 75.00
[Train] Epoch: 3 [199040/620022]    Loss: 0.008625   Batch Acc: 75.00
[Train] Epoch: 3 [199104/620022]    Loss: 0.009801   Batch Acc: 76.56
[Train] Epoch: 3 [199168/620022]    Loss: 0.008093   Batch Acc: 79.69
[Train] Epoch: 3 [199232/620022]    Loss: 0.010459   Batch Acc: 75.00
[Train] Epoch: 3 [199296/620022]    Loss: 0.009632   Batch Acc: 73.44
[Train] Epoch: 3 [199360/620022]    Loss: 0.008201   Batch Acc: 76.56
[Train] Epoch: 3 [199424/620022]    Loss: 0.007330   Batch Acc: 82.81
[Train] Epoch: 3 [199488/620022]    Loss: 0.008725   Batch Acc: 76.56
[Train] Epoch: 3 [199552/620022]    Loss: 0.009087   Batch Acc: 75.00
[Train] Epoch: 3 [199616/620022]    Loss: 0.007923   Batch Acc: 84.38
[Train] Epoch: 3 [199680/620022]    Loss: 0.007161   Batch Acc: 82.81
[Train] Epoch: 3 [199744/620022]    Loss: 0.007289   Batch Acc: 84.38
[Train] Epoch: 3 [199808/620022]    Loss: 0.008616   Batch Acc: 75.00
[Train] Epoch: 3 [199872/620022]    Loss: 0.007879   Batch Acc: 87.50
[Train] Epoch: 3 [199936/620022]    Loss: 0.008645   Batch Acc: 79.69
[Train] Epoch: 3 [200000/620022]    Loss: 0.008296   Batch Acc: 76.56
[Train] Epoch: 3 [200064/620022]    Loss: 0.007071   Batch Acc: 87.50
[Train] Epoch: 3 [200128/620022]    Loss: 0.008692   Batch Acc: 78.12
[Train] Epoch: 3 [200192/620022]    Loss: 0.008538   Batch Acc: 79.69
[Train] Epoch: 3 [200256/620022]    Loss: 0.011437   Batch Acc: 70.31
[Train] Epoch: 3 [200320/620022]    Loss: 0.007735   Batch Acc: 81.25
[Train] Epoch: 3 [200384/620022]    Loss: 0.009143   Batch Acc: 75.00
[Train] Epoch: 3 [200448/620022]    Loss: 0.007849   Batch Acc: 79.69
[Train] Epoch: 3 [200512/620022]    Loss: 0.007846   Batch Acc: 82.81
[Train] Epoch: 3 [200576/620022]    Loss: 0.010874   Batch Acc: 67.19
[Train] Epoch: 3 [200640/620022]    Loss: 0.006303   Batch Acc: 85.94
[Train] Epoch: 3 [200704/620022]    Loss: 0.008024   Batch Acc: 78.12
[Train] Epoch: 3 [200768/620022]    Loss: 0.007885   Batch Acc: 79.69
[Train] Epoch: 3 [200832/620022]    Loss: 0.006949   Batch Acc: 84.38
[Train] Epoch: 3 [200896/620022]    Loss: 0.007414   Batch Acc: 85.94
[Train] Epoch: 3 [200960/620022]    Loss: 0.010511   Batch Acc: 70.31
[Train] Epoch: 3 [201024/620022]    Loss: 0.008998   Batch Acc: 76.56
[Train] Epoch: 3 [201088/620022]    Loss: 0.007854   Batch Acc: 79.69
[Train] Epoch: 3 [201152/620022]    Loss: 0.009305   Batch Acc: 73.44
[Train] Epoch: 3 [201216/620022]    Loss: 0.008088   Batch Acc: 82.81
[Train] Epoch: 3 [201280/620022]    Loss: 0.009262   Batch Acc: 71.88
[Train] Epoch: 3 [201344/620022]    Loss: 0.007761   Batch Acc: 81.25
[Train] Epoch: 3 [201408/620022]    Loss: 0.009302   Batch Acc: 71.88
[Train] Epoch: 3 [201472/620022]    Loss: 0.007088   Batch Acc: 84.38
[Train] Epoch: 3 [201536/620022]    Loss: 0.010885   Batch Acc: 68.75
[Train] Epoch: 3 [201600/620022]    Loss: 0.010480   Batch Acc: 76.56
[Train] Epoch: 3 [201664/620022]    Loss: 0.006482   Batch Acc: 82.81
[Train] Epoch: 3 [201728/620022]    Loss: 0.007277   Batch Acc: 79.69
[Train] Epoch: 3 [201792/620022]    Loss: 0.007616   Batch Acc: 79.69
[Train] Epoch: 3 [201856/620022]    Loss: 0.008600   Batch Acc: 82.81
[Train] Epoch: 3 [201920/620022]    Loss: 0.008883   Batch Acc: 71.88
[Train] Epoch: 3 [201984/620022]    Loss: 0.006757   Batch Acc: 84.38
[Train] Epoch: 3 [202048/620022]    Loss: 0.008587   Batch Acc: 70.31
[Train] Epoch: 3 [202112/620022]    Loss: 0.010807   Batch Acc: 70.31
[Train] Epoch: 3 [202176/620022]    Loss: 0.008953   Batch Acc: 79.69
[Train] Epoch: 3 [202240/620022]    Loss: 0.006308   Batch Acc: 84.38
[Train] Epoch: 3 [202304/620022]    Loss: 0.008698   Batch Acc: 78.12
[Train] Epoch: 3 [202368/620022]    Loss: 0.008971   Batch Acc: 76.56
[Train] Epoch: 3 [202432/620022]    Loss: 0.007418   Batch Acc: 79.69
[Train] Epoch: 3 [202496/620022]    Loss: 0.010518   Batch Acc: 70.31
[Train] Epoch: 3 [202560/620022]    Loss: 0.007857   Batch Acc: 79.69
[Train] Epoch: 3 [202624/620022]    Loss: 0.009678   Batch Acc: 70.31
[Train] Epoch: 3 [202688/620022]    Loss: 0.008752   Batch Acc: 71.88
[Train] Epoch: 3 [202752/620022]    Loss: 0.008217   Batch Acc: 82.81
[Train] Epoch: 3 [202816/620022]    Loss: 0.010011   Batch Acc: 75.00
[Train] Epoch: 3 [202880/620022]    Loss: 0.008587   Batch Acc: 79.69
[Train] Epoch: 3 [202944/620022]    Loss: 0.011253   Batch Acc: 68.75
[Train] Epoch: 3 [203008/620022]    Loss: 0.010922   Batch Acc: 67.19
[Train] Epoch: 3 [203072/620022]    Loss: 0.008237   Batch Acc: 79.69
[Train] Epoch: 3 [203136/620022]    Loss: 0.007274   Batch Acc: 87.50
[Train] Epoch: 3 [203200/620022]    Loss: 0.011414   Batch Acc: 73.44
[Train] Epoch: 3 [203264/620022]    Loss: 0.008053   Batch Acc: 79.69
[Train] Epoch: 3 [203328/620022]    Loss: 0.007097   Batch Acc: 84.38
[Train] Epoch: 3 [203392/620022]    Loss: 0.008292   Batch Acc: 79.69
[Train] Epoch: 3 [203456/620022]    Loss: 0.008044   Batch Acc: 81.25
[Train] Epoch: 3 [203520/620022]    Loss: 0.006588   Batch Acc: 82.81
[Train] Epoch: 3 [203584/620022]    Loss: 0.009909   Batch Acc: 79.69
[Train] Epoch: 3 [203648/620022]    Loss: 0.007916   Batch Acc: 79.69
[Train] Epoch: 3 [203712/620022]    Loss: 0.008658   Batch Acc: 76.56
[Train] Epoch: 3 [203776/620022]    Loss: 0.008219   Batch Acc: 78.12
[Train] Epoch: 3 [203840/620022]    Loss: 0.008772   Batch Acc: 76.56
[Train] Epoch: 3 [203904/620022]    Loss: 0.009241   Batch Acc: 79.69
[Train] Epoch: 3 [203968/620022]    Loss: 0.008494   Batch Acc: 75.00
[Train] Epoch: 3 [204032/620022]    Loss: 0.008777   Batch Acc: 81.25
[Train] Epoch: 3 [204096/620022]    Loss: 0.008523   Batch Acc: 76.56
[Train] Epoch: 3 [204160/620022]    Loss: 0.008895   Batch Acc: 78.12
[Train] Epoch: 3 [204224/620022]    Loss: 0.007916   Batch Acc: 82.81
[Train] Epoch: 3 [204288/620022]    Loss: 0.007812   Batch Acc: 78.12
[Train] Epoch: 3 [204352/620022]    Loss: 0.008435   Batch Acc: 81.25
[Train] Epoch: 3 [204416/620022]    Loss: 0.007466   Batch Acc: 76.56
[Train] Epoch: 3 [204480/620022]    Loss: 0.010286   Batch Acc: 71.88
[Train] Epoch: 3 [204544/620022]    Loss: 0.007742   Batch Acc: 79.69
[Train] Epoch: 3 [204608/620022]    Loss: 0.007793   Batch Acc: 79.69
[Train] Epoch: 3 [204672/620022]    Loss: 0.007627   Batch Acc: 84.38
[Train] Epoch: 3 [204736/620022]    Loss: 0.008461   Batch Acc: 75.00
[Train] Epoch: 3 [204800/620022]    Loss: 0.008768   Batch Acc: 79.69
[Train] Epoch: 3 [204864/620022]    Loss: 0.007506   Batch Acc: 84.38
[Train] Epoch: 3 [204928/620022]    Loss: 0.008500   Batch Acc: 76.56
[Train] Epoch: 3 [204992/620022]    Loss: 0.007399   Batch Acc: 85.94
[Train] Epoch: 3 [205056/620022]    Loss: 0.010542   Batch Acc: 71.88
[Train] Epoch: 3 [205120/620022]    Loss: 0.008330   Batch Acc: 79.69
[Train] Epoch: 3 [205184/620022]    Loss: 0.007153   Batch Acc: 85.94
[Train] Epoch: 3 [205248/620022]    Loss: 0.006266   Batch Acc: 82.81
[Train] Epoch: 3 [205312/620022]    Loss: 0.007168   Batch Acc: 78.12
[Train] Epoch: 3 [205376/620022]    Loss: 0.009905   Batch Acc: 70.31
[Train] Epoch: 3 [205440/620022]    Loss: 0.008376   Batch Acc: 76.56
[Train] Epoch: 3 [205504/620022]    Loss: 0.006988   Batch Acc: 84.38
[Train] Epoch: 3 [205568/620022]    Loss: 0.007738   Batch Acc: 81.25
[Train] Epoch: 3 [205632/620022]    Loss: 0.006725   Batch Acc: 82.81
[Train] Epoch: 3 [205696/620022]    Loss: 0.007809   Batch Acc: 78.12
[Train] Epoch: 3 [205760/620022]    Loss: 0.007031   Batch Acc: 84.38
[Train] Epoch: 3 [205824/620022]    Loss: 0.009814   Batch Acc: 73.44
[Train] Epoch: 3 [205888/620022]    Loss: 0.010149   Batch Acc: 68.75
[Train] Epoch: 3 [205952/620022]    Loss: 0.007931   Batch Acc: 82.81
[Train] Epoch: 3 [206016/620022]    Loss: 0.009343   Batch Acc: 76.56
[Train] Epoch: 3 [206080/620022]    Loss: 0.009379   Batch Acc: 82.81
[Train] Epoch: 3 [206144/620022]    Loss: 0.007655   Batch Acc: 84.38
[Train] Epoch: 3 [206208/620022]    Loss: 0.006331   Batch Acc: 82.81
[Train] Epoch: 3 [206272/620022]    Loss: 0.007341   Batch Acc: 82.81
[Train] Epoch: 3 [206336/620022]    Loss: 0.009636   Batch Acc: 76.56
[Train] Epoch: 3 [206400/620022]    Loss: 0.008303   Batch Acc: 81.25
[Train] Epoch: 3 [206464/620022]    Loss: 0.011233   Batch Acc: 56.25
[Train] Epoch: 3 [206528/620022]    Loss: 0.009597   Batch Acc: 71.88
[Train] Epoch: 3 [206592/620022]    Loss: 0.005551   Batch Acc: 87.50
[Train] Epoch: 3 [206656/620022]    Loss: 0.006309   Batch Acc: 85.94
[Train] Epoch: 3 [206720/620022]    Loss: 0.009833   Batch Acc: 75.00
[Train] Epoch: 3 [206784/620022]    Loss: 0.009107   Batch Acc: 75.00
[Train] Epoch: 3 [206848/620022]    Loss: 0.009458   Batch Acc: 73.44
[Train] Epoch: 3 [206912/620022]    Loss: 0.008824   Batch Acc: 71.88
[Train] Epoch: 3 [206976/620022]    Loss: 0.009135   Batch Acc: 76.56
[Train] Epoch: 3 [207040/620022]    Loss: 0.007748   Batch Acc: 82.81
[Train] Epoch: 3 [207104/620022]    Loss: 0.009938   Batch Acc: 73.44
[Train] Epoch: 3 [207168/620022]    Loss: 0.007644   Batch Acc: 79.69
[Train] Epoch: 3 [207232/620022]    Loss: 0.005719   Batch Acc: 87.50
[Train] Epoch: 3 [207296/620022]    Loss: 0.010304   Batch Acc: 76.56
[Train] Epoch: 3 [207360/620022]    Loss: 0.008511   Batch Acc: 82.81
[Train] Epoch: 3 [207424/620022]    Loss: 0.009284   Batch Acc: 78.12
[Train] Epoch: 3 [207488/620022]    Loss: 0.009377   Batch Acc: 76.56
[Train] Epoch: 3 [207552/620022]    Loss: 0.007981   Batch Acc: 81.25
[Train] Epoch: 3 [207616/620022]    Loss: 0.007617   Batch Acc: 75.00
[Train] Epoch: 3 [207680/620022]    Loss: 0.007930   Batch Acc: 79.69
[Train] Epoch: 3 [207744/620022]    Loss: 0.005685   Batch Acc: 90.62
[Train] Epoch: 3 [207808/620022]    Loss: 0.007401   Batch Acc: 81.25
[Train] Epoch: 3 [207872/620022]    Loss: 0.007350   Batch Acc: 81.25
[Train] Epoch: 3 [207936/620022]    Loss: 0.007965   Batch Acc: 76.56
[Train] Epoch: 3 [208000/620022]    Loss: 0.008971   Batch Acc: 75.00
[Train] Epoch: 3 [208064/620022]    Loss: 0.011778   Batch Acc: 68.75
[Train] Epoch: 3 [208128/620022]    Loss: 0.007917   Batch Acc: 79.69
[Train] Epoch: 3 [208192/620022]    Loss: 0.009404   Batch Acc: 71.88
[Train] Epoch: 3 [208256/620022]    Loss: 0.008586   Batch Acc: 78.12
[Train] Epoch: 3 [208320/620022]    Loss: 0.009958   Batch Acc: 68.75
[Train] Epoch: 3 [208384/620022]    Loss: 0.008600   Batch Acc: 75.00
[Train] Epoch: 3 [208448/620022]    Loss: 0.008242   Batch Acc: 79.69
[Train] Epoch: 3 [208512/620022]    Loss: 0.009070   Batch Acc: 81.25
[Train] Epoch: 3 [208576/620022]    Loss: 0.007380   Batch Acc: 84.38
[Train] Epoch: 3 [208640/620022]    Loss: 0.011351   Batch Acc: 71.88
[Train] Epoch: 3 [208704/620022]    Loss: 0.009358   Batch Acc: 79.69
[Train] Epoch: 3 [208768/620022]    Loss: 0.007029   Batch Acc: 84.38
[Train] Epoch: 3 [208832/620022]    Loss: 0.007554   Batch Acc: 85.94
[Train] Epoch: 3 [208896/620022]    Loss: 0.008508   Batch Acc: 76.56
[Train] Epoch: 3 [208960/620022]    Loss: 0.006361   Batch Acc: 84.38
[Train] Epoch: 3 [209024/620022]    Loss: 0.008789   Batch Acc: 73.44
[Train] Epoch: 3 [209088/620022]    Loss: 0.009519   Batch Acc: 78.12
[Train] Epoch: 3 [209152/620022]    Loss: 0.008066   Batch Acc: 81.25
[Train] Epoch: 3 [209216/620022]    Loss: 0.008499   Batch Acc: 76.56
[Train] Epoch: 3 [209280/620022]    Loss: 0.007486   Batch Acc: 81.25
[Train] Epoch: 3 [209344/620022]    Loss: 0.008849   Batch Acc: 75.00
[Train] Epoch: 3 [209408/620022]    Loss: 0.008666   Batch Acc: 73.44
[Train] Epoch: 3 [209472/620022]    Loss: 0.007354   Batch Acc: 81.25
[Train] Epoch: 3 [209536/620022]    Loss: 0.008383   Batch Acc: 79.69
[Train] Epoch: 3 [209600/620022]    Loss: 0.009833   Batch Acc: 70.31
[Train] Epoch: 3 [209664/620022]    Loss: 0.006824   Batch Acc: 87.50
[Train] Epoch: 3 [209728/620022]    Loss: 0.009284   Batch Acc: 71.88
[Train] Epoch: 3 [209792/620022]    Loss: 0.008987   Batch Acc: 75.00
[Train] Epoch: 3 [209856/620022]    Loss: 0.010821   Batch Acc: 75.00
[Train] Epoch: 3 [209920/620022]    Loss: 0.006350   Batch Acc: 89.06
[Train] Epoch: 3 [209984/620022]    Loss: 0.007100   Batch Acc: 85.94
[Train] Epoch: 3 [210048/620022]    Loss: 0.007674   Batch Acc: 79.69
[Train] Epoch: 3 [210112/620022]    Loss: 0.008656   Batch Acc: 79.69
[Train] Epoch: 3 [210176/620022]    Loss: 0.007092   Batch Acc: 79.69
[Train] Epoch: 3 [210240/620022]    Loss: 0.009449   Batch Acc: 75.00
[Train] Epoch: 3 [210304/620022]    Loss: 0.007667   Batch Acc: 81.25
[Train] Epoch: 3 [210368/620022]    Loss: 0.008542   Batch Acc: 78.12
[Train] Epoch: 3 [210432/620022]    Loss: 0.008131   Batch Acc: 79.69
[Train] Epoch: 3 [210496/620022]    Loss: 0.007505   Batch Acc: 81.25
[Train] Epoch: 3 [210560/620022]    Loss: 0.006060   Batch Acc: 85.94
[Train] Epoch: 3 [210624/620022]    Loss: 0.007542   Batch Acc: 79.69
[Train] Epoch: 3 [210688/620022]    Loss: 0.008653   Batch Acc: 75.00
[Train] Epoch: 3 [210752/620022]    Loss: 0.010763   Batch Acc: 75.00
[Train] Epoch: 3 [210816/620022]    Loss: 0.007345   Batch Acc: 78.12
[Train] Epoch: 3 [210880/620022]    Loss: 0.008892   Batch Acc: 73.44
[Train] Epoch: 3 [210944/620022]    Loss: 0.008331   Batch Acc: 76.56
[Train] Epoch: 3 [211008/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 3 [211072/620022]    Loss: 0.008030   Batch Acc: 79.69
[Train] Epoch: 3 [211136/620022]    Loss: 0.009101   Batch Acc: 73.44
[Train] Epoch: 3 [211200/620022]    Loss: 0.009299   Batch Acc: 75.00
[Train] Epoch: 3 [211264/620022]    Loss: 0.012884   Batch Acc: 75.00
[Train] Epoch: 3 [211328/620022]    Loss: 0.009708   Batch Acc: 76.56
[Train] Epoch: 3 [211392/620022]    Loss: 0.006871   Batch Acc: 87.50
[Train] Epoch: 3 [211456/620022]    Loss: 0.009026   Batch Acc: 73.44
[Train] Epoch: 3 [211520/620022]    Loss: 0.007811   Batch Acc: 78.12
[Train] Epoch: 3 [211584/620022]    Loss: 0.007903   Batch Acc: 78.12
[Train] Epoch: 3 [211648/620022]    Loss: 0.008252   Batch Acc: 78.12
[Train] Epoch: 3 [211712/620022]    Loss: 0.007832   Batch Acc: 84.38
[Train] Epoch: 3 [211776/620022]    Loss: 0.008156   Batch Acc: 78.12
[Train] Epoch: 3 [211840/620022]    Loss: 0.010881   Batch Acc: 79.69
[Train] Epoch: 3 [211904/620022]    Loss: 0.008712   Batch Acc: 76.56
[Train] Epoch: 3 [211968/620022]    Loss: 0.009478   Batch Acc: 73.44
[Train] Epoch: 3 [212032/620022]    Loss: 0.008824   Batch Acc: 79.69
[Train] Epoch: 3 [212096/620022]    Loss: 0.007283   Batch Acc: 82.81
[Train] Epoch: 3 [212160/620022]    Loss: 0.008004   Batch Acc: 78.12
[Train] Epoch: 3 [212224/620022]    Loss: 0.006138   Batch Acc: 84.38
[Train] Epoch: 3 [212288/620022]    Loss: 0.008574   Batch Acc: 75.00
[Train] Epoch: 3 [212352/620022]    Loss: 0.009056   Batch Acc: 75.00
[Train] Epoch: 3 [212416/620022]    Loss: 0.008032   Batch Acc: 76.56
[Train] Epoch: 3 [212480/620022]    Loss: 0.010282   Batch Acc: 70.31
[Train] Epoch: 3 [212544/620022]    Loss: 0.008281   Batch Acc: 82.81
[Train] Epoch: 3 [212608/620022]    Loss: 0.010191   Batch Acc: 67.19
[Train] Epoch: 3 [212672/620022]    Loss: 0.008763   Batch Acc: 79.69
[Train] Epoch: 3 [212736/620022]    Loss: 0.006582   Batch Acc: 87.50
[Train] Epoch: 3 [212800/620022]    Loss: 0.009461   Batch Acc: 70.31
[Train] Epoch: 3 [212864/620022]    Loss: 0.008260   Batch Acc: 75.00
[Train] Epoch: 3 [212928/620022]    Loss: 0.009903   Batch Acc: 73.44
[Train] Epoch: 3 [212992/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 3 [213056/620022]    Loss: 0.006750   Batch Acc: 84.38
[Train] Epoch: 3 [213120/620022]    Loss: 0.009159   Batch Acc: 73.44
[Train] Epoch: 3 [213184/620022]    Loss: 0.007709   Batch Acc: 79.69
[Train] Epoch: 3 [213248/620022]    Loss: 0.008960   Batch Acc: 79.69
[Train] Epoch: 3 [213312/620022]    Loss: 0.008148   Batch Acc: 82.81
[Train] Epoch: 3 [213376/620022]    Loss: 0.010101   Batch Acc: 70.31
[Train] Epoch: 3 [213440/620022]    Loss: 0.006412   Batch Acc: 87.50
[Train] Epoch: 3 [213504/620022]    Loss: 0.009830   Batch Acc: 78.12
[Train] Epoch: 3 [213568/620022]    Loss: 0.009658   Batch Acc: 71.88
[Train] Epoch: 3 [213632/620022]    Loss: 0.007516   Batch Acc: 84.38
[Train] Epoch: 3 [213696/620022]    Loss: 0.007125   Batch Acc: 82.81
[Train] Epoch: 3 [213760/620022]    Loss: 0.007106   Batch Acc: 82.81
[Train] Epoch: 3 [213824/620022]    Loss: 0.007560   Batch Acc: 85.94
[Train] Epoch: 3 [213888/620022]    Loss: 0.006792   Batch Acc: 76.56
[Train] Epoch: 3 [213952/620022]    Loss: 0.007529   Batch Acc: 82.81
[Train] Epoch: 3 [214016/620022]    Loss: 0.011209   Batch Acc: 71.88
[Train] Epoch: 3 [214080/620022]    Loss: 0.009972   Batch Acc: 75.00
[Train] Epoch: 3 [214144/620022]    Loss: 0.009368   Batch Acc: 71.88
[Train] Epoch: 3 [214208/620022]    Loss: 0.007757   Batch Acc: 82.81
[Train] Epoch: 3 [214272/620022]    Loss: 0.007456   Batch Acc: 78.12
[Train] Epoch: 3 [214336/620022]    Loss: 0.008563   Batch Acc: 76.56
[Train] Epoch: 3 [214400/620022]    Loss: 0.007622   Batch Acc: 82.81
[Train] Epoch: 3 [214464/620022]    Loss: 0.008688   Batch Acc: 79.69
[Train] Epoch: 3 [214528/620022]    Loss: 0.008216   Batch Acc: 79.69
[Train] Epoch: 3 [214592/620022]    Loss: 0.010454   Batch Acc: 71.88
[Train] Epoch: 3 [214656/620022]    Loss: 0.009870   Batch Acc: 76.56
[Train] Epoch: 3 [214720/620022]    Loss: 0.009496   Batch Acc: 76.56
[Train] Epoch: 3 [214784/620022]    Loss: 0.006377   Batch Acc: 89.06
[Train] Epoch: 3 [214848/620022]    Loss: 0.009183   Batch Acc: 79.69
[Train] Epoch: 3 [214912/620022]    Loss: 0.009015   Batch Acc: 76.56
[Train] Epoch: 3 [214976/620022]    Loss: 0.009052   Batch Acc: 82.81
[Train] Epoch: 3 [215040/620022]    Loss: 0.007184   Batch Acc: 84.38
[Train] Epoch: 3 [215104/620022]    Loss: 0.007953   Batch Acc: 75.00
[Train] Epoch: 3 [215168/620022]    Loss: 0.008377   Batch Acc: 82.81
[Train] Epoch: 3 [215232/620022]    Loss: 0.007616   Batch Acc: 82.81
[Train] Epoch: 3 [215296/620022]    Loss: 0.009761   Batch Acc: 71.88
[Train] Epoch: 3 [215360/620022]    Loss: 0.009337   Batch Acc: 78.12
[Train] Epoch: 3 [215424/620022]    Loss: 0.007744   Batch Acc: 81.25
[Train] Epoch: 3 [215488/620022]    Loss: 0.009674   Batch Acc: 71.88
[Train] Epoch: 3 [215552/620022]    Loss: 0.008289   Batch Acc: 81.25
[Train] Epoch: 3 [215616/620022]    Loss: 0.007658   Batch Acc: 81.25
[Train] Epoch: 3 [215680/620022]    Loss: 0.008061   Batch Acc: 76.56
[Train] Epoch: 3 [215744/620022]    Loss: 0.009018   Batch Acc: 76.56
[Train] Epoch: 3 [215808/620022]    Loss: 0.008815   Batch Acc: 75.00
[Train] Epoch: 3 [215872/620022]    Loss: 0.008348   Batch Acc: 81.25
[Train] Epoch: 3 [215936/620022]    Loss: 0.010517   Batch Acc: 73.44
[Train] Epoch: 3 [216000/620022]    Loss: 0.008090   Batch Acc: 84.38
[Train] Epoch: 3 [216064/620022]    Loss: 0.008062   Batch Acc: 81.25
[Train] Epoch: 3 [216128/620022]    Loss: 0.008654   Batch Acc: 76.56
[Train] Epoch: 3 [216192/620022]    Loss: 0.008723   Batch Acc: 76.56
[Train] Epoch: 3 [216256/620022]    Loss: 0.008613   Batch Acc: 73.44
[Train] Epoch: 3 [216320/620022]    Loss: 0.009034   Batch Acc: 70.31
[Train] Epoch: 3 [216384/620022]    Loss: 0.010881   Batch Acc: 68.75
[Train] Epoch: 3 [216448/620022]    Loss: 0.006282   Batch Acc: 85.94
[Train] Epoch: 3 [216512/620022]    Loss: 0.008465   Batch Acc: 81.25
[Train] Epoch: 3 [216576/620022]    Loss: 0.008602   Batch Acc: 76.56
[Train] Epoch: 3 [216640/620022]    Loss: 0.008908   Batch Acc: 78.12
[Train] Epoch: 3 [216704/620022]    Loss: 0.007186   Batch Acc: 79.69
[Train] Epoch: 3 [216768/620022]    Loss: 0.006138   Batch Acc: 85.94
[Train] Epoch: 3 [216832/620022]    Loss: 0.008618   Batch Acc: 82.81
[Train] Epoch: 3 [216896/620022]    Loss: 0.008078   Batch Acc: 75.00
[Train] Epoch: 3 [216960/620022]    Loss: 0.009210   Batch Acc: 78.12
[Train] Epoch: 3 [217024/620022]    Loss: 0.007187   Batch Acc: 82.81
[Train] Epoch: 3 [217088/620022]    Loss: 0.010115   Batch Acc: 73.44
[Train] Epoch: 3 [217152/620022]    Loss: 0.006737   Batch Acc: 92.19
[Train] Epoch: 3 [217216/620022]    Loss: 0.007401   Batch Acc: 81.25
[Train] Epoch: 3 [217280/620022]    Loss: 0.008231   Batch Acc: 81.25
[Train] Epoch: 3 [217344/620022]    Loss: 0.007441   Batch Acc: 82.81
[Train] Epoch: 3 [217408/620022]    Loss: 0.008640   Batch Acc: 81.25
[Train] Epoch: 3 [217472/620022]    Loss: 0.008242   Batch Acc: 78.12
[Train] Epoch: 3 [217536/620022]    Loss: 0.009265   Batch Acc: 81.25
[Train] Epoch: 3 [217600/620022]    Loss: 0.006115   Batch Acc: 84.38
[Train] Epoch: 3 [217664/620022]    Loss: 0.008500   Batch Acc: 76.56
[Train] Epoch: 3 [217728/620022]    Loss: 0.007604   Batch Acc: 81.25
[Train] Epoch: 3 [217792/620022]    Loss: 0.008097   Batch Acc: 84.38
[Train] Epoch: 3 [217856/620022]    Loss: 0.007851   Batch Acc: 73.44
[Train] Epoch: 3 [217920/620022]    Loss: 0.008451   Batch Acc: 79.69
[Train] Epoch: 3 [217984/620022]    Loss: 0.007851   Batch Acc: 79.69
[Train] Epoch: 3 [218048/620022]    Loss: 0.006210   Batch Acc: 84.38
[Train] Epoch: 3 [218112/620022]    Loss: 0.010666   Batch Acc: 68.75
[Train] Epoch: 3 [218176/620022]    Loss: 0.007264   Batch Acc: 76.56
[Train] Epoch: 3 [218240/620022]    Loss: 0.008419   Batch Acc: 81.25
[Train] Epoch: 3 [218304/620022]    Loss: 0.011137   Batch Acc: 71.88
[Train] Epoch: 3 [218368/620022]    Loss: 0.005888   Batch Acc: 87.50
[Train] Epoch: 3 [218432/620022]    Loss: 0.009299   Batch Acc: 73.44
[Train] Epoch: 3 [218496/620022]    Loss: 0.009903   Batch Acc: 73.44
[Train] Epoch: 3 [218560/620022]    Loss: 0.007723   Batch Acc: 81.25
[Train] Epoch: 3 [218624/620022]    Loss: 0.006230   Batch Acc: 87.50
[Train] Epoch: 3 [218688/620022]    Loss: 0.007923   Batch Acc: 81.25
[Train] Epoch: 3 [218752/620022]    Loss: 0.008912   Batch Acc: 76.56
[Train] Epoch: 3 [218816/620022]    Loss: 0.006081   Batch Acc: 87.50
[Train] Epoch: 3 [218880/620022]    Loss: 0.009409   Batch Acc: 75.00
[Train] Epoch: 3 [218944/620022]    Loss: 0.008117   Batch Acc: 81.25
[Train] Epoch: 3 [219008/620022]    Loss: 0.007174   Batch Acc: 87.50
[Train] Epoch: 3 [219072/620022]    Loss: 0.011336   Batch Acc: 70.31
[Train] Epoch: 3 [219136/620022]    Loss: 0.008721   Batch Acc: 78.12
[Train] Epoch: 3 [219200/620022]    Loss: 0.006689   Batch Acc: 87.50
[Train] Epoch: 3 [219264/620022]    Loss: 0.009889   Batch Acc: 75.00
[Train] Epoch: 3 [219328/620022]    Loss: 0.007786   Batch Acc: 85.94
[Train] Epoch: 3 [219392/620022]    Loss: 0.007396   Batch Acc: 82.81
[Train] Epoch: 3 [219456/620022]    Loss: 0.008474   Batch Acc: 79.69
[Train] Epoch: 3 [219520/620022]    Loss: 0.008854   Batch Acc: 75.00
[Train] Epoch: 3 [219584/620022]    Loss: 0.008644   Batch Acc: 76.56
[Train] Epoch: 3 [219648/620022]    Loss: 0.009941   Batch Acc: 68.75
[Train] Epoch: 3 [219712/620022]    Loss: 0.006935   Batch Acc: 79.69
[Train] Epoch: 3 [219776/620022]    Loss: 0.007983   Batch Acc: 85.94
[Train] Epoch: 3 [219840/620022]    Loss: 0.006368   Batch Acc: 90.62
[Train] Epoch: 3 [219904/620022]    Loss: 0.009326   Batch Acc: 78.12
[Train] Epoch: 3 [219968/620022]    Loss: 0.008092   Batch Acc: 78.12
[Train] Epoch: 3 [220032/620022]    Loss: 0.008023   Batch Acc: 78.12
[Train] Epoch: 3 [220096/620022]    Loss: 0.006855   Batch Acc: 89.06
[Train] Epoch: 3 [220160/620022]    Loss: 0.008374   Batch Acc: 78.12
[Train] Epoch: 3 [220224/620022]    Loss: 0.011545   Batch Acc: 70.31
[Train] Epoch: 3 [220288/620022]    Loss: 0.008219   Batch Acc: 76.56
[Train] Epoch: 3 [220352/620022]    Loss: 0.007303   Batch Acc: 79.69
[Train] Epoch: 3 [220416/620022]    Loss: 0.007279   Batch Acc: 82.81
[Train] Epoch: 3 [220480/620022]    Loss: 0.010766   Batch Acc: 76.56
[Train] Epoch: 3 [220544/620022]    Loss: 0.008323   Batch Acc: 84.38
[Train] Epoch: 3 [220608/620022]    Loss: 0.008656   Batch Acc: 71.88
[Train] Epoch: 3 [220672/620022]    Loss: 0.007526   Batch Acc: 75.00
[Train] Epoch: 3 [220736/620022]    Loss: 0.009146   Batch Acc: 76.56
[Train] Epoch: 3 [220800/620022]    Loss: 0.007764   Batch Acc: 79.69
[Train] Epoch: 3 [220864/620022]    Loss: 0.012341   Batch Acc: 65.62
[Train] Epoch: 3 [220928/620022]    Loss: 0.008440   Batch Acc: 78.12
[Train] Epoch: 3 [220992/620022]    Loss: 0.009528   Batch Acc: 76.56
[Train] Epoch: 3 [221056/620022]    Loss: 0.007970   Batch Acc: 79.69
[Train] Epoch: 3 [221120/620022]    Loss: 0.008015   Batch Acc: 81.25
[Train] Epoch: 3 [221184/620022]    Loss: 0.010093   Batch Acc: 65.62
[Train] Epoch: 3 [221248/620022]    Loss: 0.009753   Batch Acc: 76.56
[Train] Epoch: 3 [221312/620022]    Loss: 0.008993   Batch Acc: 79.69
[Train] Epoch: 3 [221376/620022]    Loss: 0.010430   Batch Acc: 71.88
[Train] Epoch: 3 [221440/620022]    Loss: 0.008361   Batch Acc: 79.69
[Train] Epoch: 3 [221504/620022]    Loss: 0.008523   Batch Acc: 76.56
[Train] Epoch: 3 [221568/620022]    Loss: 0.007275   Batch Acc: 82.81
[Train] Epoch: 3 [221632/620022]    Loss: 0.009593   Batch Acc: 78.12
[Train] Epoch: 3 [221696/620022]    Loss: 0.010329   Batch Acc: 73.44
[Train] Epoch: 3 [221760/620022]    Loss: 0.008841   Batch Acc: 78.12
[Train] Epoch: 3 [221824/620022]    Loss: 0.006188   Batch Acc: 82.81
[Train] Epoch: 3 [221888/620022]    Loss: 0.006430   Batch Acc: 85.94
[Train] Epoch: 3 [221952/620022]    Loss: 0.009379   Batch Acc: 75.00
[Train] Epoch: 3 [222016/620022]    Loss: 0.010554   Batch Acc: 70.31
[Train] Epoch: 3 [222080/620022]    Loss: 0.008877   Batch Acc: 76.56
[Train] Epoch: 3 [222144/620022]    Loss: 0.009078   Batch Acc: 76.56
[Train] Epoch: 3 [222208/620022]    Loss: 0.008609   Batch Acc: 78.12
[Train] Epoch: 3 [222272/620022]    Loss: 0.006064   Batch Acc: 87.50
[Train] Epoch: 3 [222336/620022]    Loss: 0.008414   Batch Acc: 79.69
[Train] Epoch: 3 [222400/620022]    Loss: 0.010935   Batch Acc: 73.44
[Train] Epoch: 3 [222464/620022]    Loss: 0.007129   Batch Acc: 78.12
[Train] Epoch: 3 [222528/620022]    Loss: 0.006496   Batch Acc: 89.06
[Train] Epoch: 3 [222592/620022]    Loss: 0.009214   Batch Acc: 79.69
[Train] Epoch: 3 [222656/620022]    Loss: 0.008515   Batch Acc: 79.69
[Train] Epoch: 3 [222720/620022]    Loss: 0.007083   Batch Acc: 82.81
[Train] Epoch: 3 [222784/620022]    Loss: 0.007223   Batch Acc: 79.69
[Train] Epoch: 3 [222848/620022]    Loss: 0.007752   Batch Acc: 76.56
[Train] Epoch: 3 [222912/620022]    Loss: 0.010075   Batch Acc: 71.88
[Train] Epoch: 3 [222976/620022]    Loss: 0.010162   Batch Acc: 70.31
[Train] Epoch: 3 [223040/620022]    Loss: 0.008140   Batch Acc: 78.12
[Train] Epoch: 3 [223104/620022]    Loss: 0.007948   Batch Acc: 79.69
[Train] Epoch: 3 [223168/620022]    Loss: 0.008270   Batch Acc: 79.69
[Train] Epoch: 3 [223232/620022]    Loss: 0.007354   Batch Acc: 84.38
[Train] Epoch: 3 [223296/620022]    Loss: 0.010022   Batch Acc: 71.88
[Train] Epoch: 3 [223360/620022]    Loss: 0.008694   Batch Acc: 73.44
[Train] Epoch: 3 [223424/620022]    Loss: 0.007542   Batch Acc: 81.25
[Train] Epoch: 3 [223488/620022]    Loss: 0.009727   Batch Acc: 73.44
[Train] Epoch: 3 [223552/620022]    Loss: 0.008665   Batch Acc: 76.56
[Train] Epoch: 3 [223616/620022]    Loss: 0.011263   Batch Acc: 70.31
[Train] Epoch: 3 [223680/620022]    Loss: 0.006551   Batch Acc: 85.94
[Train] Epoch: 3 [223744/620022]    Loss: 0.009324   Batch Acc: 79.69
[Train] Epoch: 3 [223808/620022]    Loss: 0.007449   Batch Acc: 81.25
[Train] Epoch: 3 [223872/620022]    Loss: 0.007478   Batch Acc: 82.81
[Train] Epoch: 3 [223936/620022]    Loss: 0.010979   Batch Acc: 70.31
[Train] Epoch: 3 [224000/620022]    Loss: 0.008515   Batch Acc: 75.00
[Train] Epoch: 3 [224064/620022]    Loss: 0.012584   Batch Acc: 67.19
[Train] Epoch: 3 [224128/620022]    Loss: 0.008566   Batch Acc: 76.56
[Train] Epoch: 3 [224192/620022]    Loss: 0.007510   Batch Acc: 82.81
[Train] Epoch: 3 [224256/620022]    Loss: 0.011975   Batch Acc: 64.06
[Train] Epoch: 3 [224320/620022]    Loss: 0.007671   Batch Acc: 81.25
[Train] Epoch: 3 [224384/620022]    Loss: 0.010083   Batch Acc: 67.19
[Train] Epoch: 3 [224448/620022]    Loss: 0.008333   Batch Acc: 81.25
[Train] Epoch: 3 [224512/620022]    Loss: 0.008294   Batch Acc: 79.69
[Train] Epoch: 3 [224576/620022]    Loss: 0.010858   Batch Acc: 68.75
[Train] Epoch: 3 [224640/620022]    Loss: 0.006891   Batch Acc: 85.94
[Train] Epoch: 3 [224704/620022]    Loss: 0.010024   Batch Acc: 75.00
[Train] Epoch: 3 [224768/620022]    Loss: 0.008653   Batch Acc: 73.44
[Train] Epoch: 3 [224832/620022]    Loss: 0.011403   Batch Acc: 71.88
[Train] Epoch: 3 [224896/620022]    Loss: 0.006381   Batch Acc: 89.06
[Train] Epoch: 3 [224960/620022]    Loss: 0.009156   Batch Acc: 78.12
[Train] Epoch: 3 [225024/620022]    Loss: 0.008126   Batch Acc: 79.69
[Train] Epoch: 3 [225088/620022]    Loss: 0.008335   Batch Acc: 73.44
[Train] Epoch: 3 [225152/620022]    Loss: 0.007857   Batch Acc: 78.12
[Train] Epoch: 3 [225216/620022]    Loss: 0.008184   Batch Acc: 78.12
[Train] Epoch: 3 [225280/620022]    Loss: 0.008512   Batch Acc: 75.00
[Train] Epoch: 3 [225344/620022]    Loss: 0.008472   Batch Acc: 79.69
[Train] Epoch: 3 [225408/620022]    Loss: 0.009690   Batch Acc: 71.88
[Train] Epoch: 3 [225472/620022]    Loss: 0.007744   Batch Acc: 81.25
[Train] Epoch: 3 [225536/620022]    Loss: 0.007827   Batch Acc: 79.69
[Train] Epoch: 3 [225600/620022]    Loss: 0.009405   Batch Acc: 75.00
[Train] Epoch: 3 [225664/620022]    Loss: 0.009322   Batch Acc: 76.56
[Train] Epoch: 3 [225728/620022]    Loss: 0.006255   Batch Acc: 90.62
[Train] Epoch: 3 [225792/620022]    Loss: 0.008278   Batch Acc: 78.12
[Train] Epoch: 3 [225856/620022]    Loss: 0.009364   Batch Acc: 76.56
[Train] Epoch: 3 [225920/620022]    Loss: 0.010614   Batch Acc: 70.31
[Train] Epoch: 3 [225984/620022]    Loss: 0.009484   Batch Acc: 76.56
[Train] Epoch: 3 [226048/620022]    Loss: 0.007569   Batch Acc: 82.81
[Train] Epoch: 3 [226112/620022]    Loss: 0.008379   Batch Acc: 81.25
[Train] Epoch: 3 [226176/620022]    Loss: 0.008795   Batch Acc: 73.44
[Train] Epoch: 3 [226240/620022]    Loss: 0.009523   Batch Acc: 73.44
[Train] Epoch: 3 [226304/620022]    Loss: 0.006759   Batch Acc: 84.38
[Train] Epoch: 3 [226368/620022]    Loss: 0.006538   Batch Acc: 84.38
[Train] Epoch: 3 [226432/620022]    Loss: 0.007337   Batch Acc: 79.69
[Train] Epoch: 3 [226496/620022]    Loss: 0.009185   Batch Acc: 79.69
[Train] Epoch: 3 [226560/620022]    Loss: 0.008234   Batch Acc: 79.69
[Train] Epoch: 3 [226624/620022]    Loss: 0.009844   Batch Acc: 73.44
[Train] Epoch: 3 [226688/620022]    Loss: 0.008813   Batch Acc: 78.12
[Train] Epoch: 3 [226752/620022]    Loss: 0.008282   Batch Acc: 78.12
[Train] Epoch: 3 [226816/620022]    Loss: 0.009145   Batch Acc: 68.75
[Train] Epoch: 3 [226880/620022]    Loss: 0.008073   Batch Acc: 79.69
[Train] Epoch: 3 [226944/620022]    Loss: 0.010020   Batch Acc: 75.00
[Train] Epoch: 3 [227008/620022]    Loss: 0.006093   Batch Acc: 89.06
[Train] Epoch: 3 [227072/620022]    Loss: 0.011908   Batch Acc: 62.50
[Train] Epoch: 3 [227136/620022]    Loss: 0.006979   Batch Acc: 78.12
[Train] Epoch: 3 [227200/620022]    Loss: 0.008951   Batch Acc: 81.25
[Train] Epoch: 3 [227264/620022]    Loss: 0.011240   Batch Acc: 64.06
[Train] Epoch: 3 [227328/620022]    Loss: 0.007074   Batch Acc: 85.94
[Train] Epoch: 3 [227392/620022]    Loss: 0.007994   Batch Acc: 82.81
[Train] Epoch: 3 [227456/620022]    Loss: 0.008037   Batch Acc: 81.25
[Train] Epoch: 3 [227520/620022]    Loss: 0.008647   Batch Acc: 75.00
[Train] Epoch: 3 [227584/620022]    Loss: 0.008375   Batch Acc: 75.00
[Train] Epoch: 3 [227648/620022]    Loss: 0.009316   Batch Acc: 75.00
[Train] Epoch: 3 [227712/620022]    Loss: 0.008400   Batch Acc: 81.25
[Train] Epoch: 3 [227776/620022]    Loss: 0.006135   Batch Acc: 82.81
[Train] Epoch: 3 [227840/620022]    Loss: 0.006748   Batch Acc: 84.38
[Train] Epoch: 3 [227904/620022]    Loss: 0.008318   Batch Acc: 87.50
[Train] Epoch: 3 [227968/620022]    Loss: 0.009618   Batch Acc: 71.88
[Train] Epoch: 3 [228032/620022]    Loss: 0.008583   Batch Acc: 76.56
[Train] Epoch: 3 [228096/620022]    Loss: 0.009796   Batch Acc: 78.12
[Train] Epoch: 3 [228160/620022]    Loss: 0.007481   Batch Acc: 84.38
[Train] Epoch: 3 [228224/620022]    Loss: 0.007790   Batch Acc: 84.38
[Train] Epoch: 3 [228288/620022]    Loss: 0.009186   Batch Acc: 76.56
[Train] Epoch: 3 [228352/620022]    Loss: 0.008096   Batch Acc: 85.94
[Train] Epoch: 3 [228416/620022]    Loss: 0.010595   Batch Acc: 81.25
[Train] Epoch: 3 [228480/620022]    Loss: 0.008046   Batch Acc: 75.00
[Train] Epoch: 3 [228544/620022]    Loss: 0.007550   Batch Acc: 81.25
[Train] Epoch: 3 [228608/620022]    Loss: 0.007402   Batch Acc: 82.81
[Train] Epoch: 3 [228672/620022]    Loss: 0.006215   Batch Acc: 87.50
[Train] Epoch: 3 [228736/620022]    Loss: 0.009887   Batch Acc: 78.12
[Train] Epoch: 3 [228800/620022]    Loss: 0.009240   Batch Acc: 70.31
[Train] Epoch: 3 [228864/620022]    Loss: 0.007254   Batch Acc: 82.81
[Train] Epoch: 3 [228928/620022]    Loss: 0.007924   Batch Acc: 73.44
[Train] Epoch: 3 [228992/620022]    Loss: 0.009055   Batch Acc: 81.25
[Train] Epoch: 3 [229056/620022]    Loss: 0.007012   Batch Acc: 76.56
[Train] Epoch: 3 [229120/620022]    Loss: 0.009532   Batch Acc: 76.56
[Train] Epoch: 3 [229184/620022]    Loss: 0.009537   Batch Acc: 79.69
[Train] Epoch: 3 [229248/620022]    Loss: 0.008034   Batch Acc: 78.12
[Train] Epoch: 3 [229312/620022]    Loss: 0.010176   Batch Acc: 71.88
[Train] Epoch: 3 [229376/620022]    Loss: 0.007819   Batch Acc: 84.38
[Train] Epoch: 3 [229440/620022]    Loss: 0.007511   Batch Acc: 81.25
[Train] Epoch: 3 [229504/620022]    Loss: 0.011990   Batch Acc: 64.06
[Train] Epoch: 3 [229568/620022]    Loss: 0.007377   Batch Acc: 78.12
[Train] Epoch: 3 [229632/620022]    Loss: 0.009927   Batch Acc: 76.56
[Train] Epoch: 3 [229696/620022]    Loss: 0.008729   Batch Acc: 81.25
[Train] Epoch: 3 [229760/620022]    Loss: 0.006920   Batch Acc: 82.81
[Train] Epoch: 3 [229824/620022]    Loss: 0.008725   Batch Acc: 79.69
[Train] Epoch: 3 [229888/620022]    Loss: 0.008447   Batch Acc: 78.12
[Train] Epoch: 3 [229952/620022]    Loss: 0.007663   Batch Acc: 76.56
[Train] Epoch: 3 [230016/620022]    Loss: 0.009402   Batch Acc: 71.88
[Train] Epoch: 3 [230080/620022]    Loss: 0.010156   Batch Acc: 68.75
[Train] Epoch: 3 [230144/620022]    Loss: 0.010246   Batch Acc: 70.31
[Train] Epoch: 3 [230208/620022]    Loss: 0.008264   Batch Acc: 82.81
[Train] Epoch: 3 [230272/620022]    Loss: 0.009848   Batch Acc: 73.44
[Train] Epoch: 3 [230336/620022]    Loss: 0.008813   Batch Acc: 75.00
[Train] Epoch: 3 [230400/620022]    Loss: 0.007199   Batch Acc: 84.38
[Train] Epoch: 3 [230464/620022]    Loss: 0.008293   Batch Acc: 75.00
[Train] Epoch: 3 [230528/620022]    Loss: 0.009289   Batch Acc: 76.56
[Train] Epoch: 3 [230592/620022]    Loss: 0.011177   Batch Acc: 75.00
[Train] Epoch: 3 [230656/620022]    Loss: 0.007742   Batch Acc: 82.81
[Train] Epoch: 3 [230720/620022]    Loss: 0.010808   Batch Acc: 73.44
[Train] Epoch: 3 [230784/620022]    Loss: 0.008954   Batch Acc: 81.25
[Train] Epoch: 3 [230848/620022]    Loss: 0.007939   Batch Acc: 79.69
[Train] Epoch: 3 [230912/620022]    Loss: 0.009582   Batch Acc: 75.00
[Train] Epoch: 3 [230976/620022]    Loss: 0.006985   Batch Acc: 81.25
[Train] Epoch: 3 [231040/620022]    Loss: 0.007259   Batch Acc: 81.25
[Train] Epoch: 3 [231104/620022]    Loss: 0.007356   Batch Acc: 79.69
[Train] Epoch: 3 [231168/620022]    Loss: 0.007340   Batch Acc: 84.38
[Train] Epoch: 3 [231232/620022]    Loss: 0.008494   Batch Acc: 81.25
[Train] Epoch: 3 [231296/620022]    Loss: 0.007412   Batch Acc: 79.69
[Train] Epoch: 3 [231360/620022]    Loss: 0.008493   Batch Acc: 81.25
[Train] Epoch: 3 [231424/620022]    Loss: 0.010507   Batch Acc: 71.88
[Train] Epoch: 3 [231488/620022]    Loss: 0.008655   Batch Acc: 75.00
[Train] Epoch: 3 [231552/620022]    Loss: 0.009610   Batch Acc: 70.31
[Train] Epoch: 3 [231616/620022]    Loss: 0.008176   Batch Acc: 81.25
[Train] Epoch: 3 [231680/620022]    Loss: 0.009943   Batch Acc: 71.88
[Train] Epoch: 3 [231744/620022]    Loss: 0.010641   Batch Acc: 75.00
[Train] Epoch: 3 [231808/620022]    Loss: 0.009347   Batch Acc: 76.56
[Train] Epoch: 3 [231872/620022]    Loss: 0.009950   Batch Acc: 71.88
[Train] Epoch: 3 [231936/620022]    Loss: 0.007906   Batch Acc: 79.69
[Train] Epoch: 3 [232000/620022]    Loss: 0.009516   Batch Acc: 75.00
[Train] Epoch: 3 [232064/620022]    Loss: 0.008021   Batch Acc: 79.69
[Train] Epoch: 3 [232128/620022]    Loss: 0.005679   Batch Acc: 85.94
[Train] Epoch: 3 [232192/620022]    Loss: 0.008800   Batch Acc: 84.38
[Train] Epoch: 3 [232256/620022]    Loss: 0.010523   Batch Acc: 76.56
[Train] Epoch: 3 [232320/620022]    Loss: 0.011032   Batch Acc: 70.31
[Train] Epoch: 3 [232384/620022]    Loss: 0.008617   Batch Acc: 79.69
[Train] Epoch: 3 [232448/620022]    Loss: 0.009573   Batch Acc: 73.44
[Train] Epoch: 3 [232512/620022]    Loss: 0.009294   Batch Acc: 76.56
[Train] Epoch: 3 [232576/620022]    Loss: 0.009171   Batch Acc: 76.56
[Train] Epoch: 3 [232640/620022]    Loss: 0.009459   Batch Acc: 78.12
[Train] Epoch: 3 [232704/620022]    Loss: 0.008160   Batch Acc: 78.12
[Train] Epoch: 3 [232768/620022]    Loss: 0.008207   Batch Acc: 89.06
[Train] Epoch: 3 [232832/620022]    Loss: 0.007553   Batch Acc: 78.12
[Train] Epoch: 3 [232896/620022]    Loss: 0.009871   Batch Acc: 78.12
[Train] Epoch: 3 [232960/620022]    Loss: 0.006729   Batch Acc: 84.38
[Train] Epoch: 3 [233024/620022]    Loss: 0.008779   Batch Acc: 75.00
[Train] Epoch: 3 [233088/620022]    Loss: 0.011116   Batch Acc: 70.31
[Train] Epoch: 3 [233152/620022]    Loss: 0.007881   Batch Acc: 81.25
[Train] Epoch: 3 [233216/620022]    Loss: 0.008654   Batch Acc: 75.00
[Train] Epoch: 3 [233280/620022]    Loss: 0.009079   Batch Acc: 76.56
[Train] Epoch: 3 [233344/620022]    Loss: 0.008999   Batch Acc: 73.44
[Train] Epoch: 3 [233408/620022]    Loss: 0.007115   Batch Acc: 82.81
[Train] Epoch: 3 [233472/620022]    Loss: 0.008284   Batch Acc: 75.00
[Train] Epoch: 3 [233536/620022]    Loss: 0.009264   Batch Acc: 71.88
[Train] Epoch: 3 [233600/620022]    Loss: 0.008068   Batch Acc: 79.69
[Train] Epoch: 3 [233664/620022]    Loss: 0.007030   Batch Acc: 82.81
[Train] Epoch: 3 [233728/620022]    Loss: 0.008463   Batch Acc: 79.69
[Train] Epoch: 3 [233792/620022]    Loss: 0.006660   Batch Acc: 82.81
[Train] Epoch: 3 [233856/620022]    Loss: 0.010611   Batch Acc: 67.19
[Train] Epoch: 3 [233920/620022]    Loss: 0.011010   Batch Acc: 65.62
[Train] Epoch: 3 [233984/620022]    Loss: 0.008925   Batch Acc: 75.00
[Train] Epoch: 3 [234048/620022]    Loss: 0.009451   Batch Acc: 75.00
[Train] Epoch: 3 [234112/620022]    Loss: 0.010812   Batch Acc: 73.44
[Train] Epoch: 3 [234176/620022]    Loss: 0.007746   Batch Acc: 79.69
[Train] Epoch: 3 [234240/620022]    Loss: 0.007139   Batch Acc: 84.38
[Train] Epoch: 3 [234304/620022]    Loss: 0.007336   Batch Acc: 79.69
[Train] Epoch: 3 [234368/620022]    Loss: 0.008531   Batch Acc: 78.12
[Train] Epoch: 3 [234432/620022]    Loss: 0.008448   Batch Acc: 84.38
[Train] Epoch: 3 [234496/620022]    Loss: 0.007066   Batch Acc: 85.94
[Train] Epoch: 3 [234560/620022]    Loss: 0.012905   Batch Acc: 71.88
[Train] Epoch: 3 [234624/620022]    Loss: 0.008295   Batch Acc: 81.25
[Train] Epoch: 3 [234688/620022]    Loss: 0.006354   Batch Acc: 85.94
[Train] Epoch: 3 [234752/620022]    Loss: 0.008262   Batch Acc: 75.00
[Train] Epoch: 3 [234816/620022]    Loss: 0.008467   Batch Acc: 82.81
[Train] Epoch: 3 [234880/620022]    Loss: 0.009940   Batch Acc: 75.00
[Train] Epoch: 3 [234944/620022]    Loss: 0.009550   Batch Acc: 78.12
[Train] Epoch: 3 [235008/620022]    Loss: 0.007393   Batch Acc: 84.38
[Train] Epoch: 3 [235072/620022]    Loss: 0.006488   Batch Acc: 81.25
[Train] Epoch: 3 [235136/620022]    Loss: 0.009510   Batch Acc: 78.12
[Train] Epoch: 3 [235200/620022]    Loss: 0.009992   Batch Acc: 76.56
[Train] Epoch: 3 [235264/620022]    Loss: 0.007879   Batch Acc: 79.69
[Train] Epoch: 3 [235328/620022]    Loss: 0.012017   Batch Acc: 62.50
[Train] Epoch: 3 [235392/620022]    Loss: 0.010303   Batch Acc: 70.31
[Train] Epoch: 3 [235456/620022]    Loss: 0.008562   Batch Acc: 75.00
[Train] Epoch: 3 [235520/620022]    Loss: 0.007544   Batch Acc: 79.69
[Train] Epoch: 3 [235584/620022]    Loss: 0.008688   Batch Acc: 76.56
[Train] Epoch: 3 [235648/620022]    Loss: 0.008956   Batch Acc: 78.12
[Train] Epoch: 3 [235712/620022]    Loss: 0.009153   Batch Acc: 79.69
[Train] Epoch: 3 [235776/620022]    Loss: 0.009813   Batch Acc: 71.88
[Train] Epoch: 3 [235840/620022]    Loss: 0.009135   Batch Acc: 76.56
[Train] Epoch: 3 [235904/620022]    Loss: 0.008370   Batch Acc: 85.94
[Train] Epoch: 3 [235968/620022]    Loss: 0.007814   Batch Acc: 76.56
[Train] Epoch: 3 [236032/620022]    Loss: 0.008142   Batch Acc: 78.12
[Train] Epoch: 3 [236096/620022]    Loss: 0.010726   Batch Acc: 75.00
[Train] Epoch: 3 [236160/620022]    Loss: 0.009380   Batch Acc: 76.56
[Train] Epoch: 3 [236224/620022]    Loss: 0.009312   Batch Acc: 70.31
[Train] Epoch: 3 [236288/620022]    Loss: 0.008050   Batch Acc: 82.81
[Train] Epoch: 3 [236352/620022]    Loss: 0.008797   Batch Acc: 79.69
[Train] Epoch: 3 [236416/620022]    Loss: 0.008295   Batch Acc: 82.81
[Train] Epoch: 3 [236480/620022]    Loss: 0.009638   Batch Acc: 75.00
[Train] Epoch: 3 [236544/620022]    Loss: 0.007244   Batch Acc: 81.25
[Train] Epoch: 3 [236608/620022]    Loss: 0.006907   Batch Acc: 85.94
[Train] Epoch: 3 [236672/620022]    Loss: 0.006958   Batch Acc: 85.94
[Train] Epoch: 3 [236736/620022]    Loss: 0.006699   Batch Acc: 87.50
[Train] Epoch: 3 [236800/620022]    Loss: 0.007767   Batch Acc: 78.12
[Train] Epoch: 3 [236864/620022]    Loss: 0.009246   Batch Acc: 70.31
[Train] Epoch: 3 [236928/620022]    Loss: 0.005902   Batch Acc: 84.38
[Train] Epoch: 3 [236992/620022]    Loss: 0.009235   Batch Acc: 73.44
[Train] Epoch: 3 [237056/620022]    Loss: 0.007065   Batch Acc: 82.81
[Train] Epoch: 3 [237120/620022]    Loss: 0.010066   Batch Acc: 76.56
[Train] Epoch: 3 [237184/620022]    Loss: 0.009147   Batch Acc: 75.00
[Train] Epoch: 3 [237248/620022]    Loss: 0.009734   Batch Acc: 76.56
[Train] Epoch: 3 [237312/620022]    Loss: 0.009812   Batch Acc: 73.44
[Train] Epoch: 3 [237376/620022]    Loss: 0.009132   Batch Acc: 75.00
[Train] Epoch: 3 [237440/620022]    Loss: 0.011143   Batch Acc: 70.31
[Train] Epoch: 3 [237504/620022]    Loss: 0.008747   Batch Acc: 76.56
[Train] Epoch: 3 [237568/620022]    Loss: 0.009882   Batch Acc: 79.69
[Train] Epoch: 3 [237632/620022]    Loss: 0.007491   Batch Acc: 79.69
[Train] Epoch: 3 [237696/620022]    Loss: 0.010391   Batch Acc: 71.88
[Train] Epoch: 3 [237760/620022]    Loss: 0.008229   Batch Acc: 78.12
[Train] Epoch: 3 [237824/620022]    Loss: 0.008105   Batch Acc: 81.25
[Train] Epoch: 3 [237888/620022]    Loss: 0.011278   Batch Acc: 71.88
[Train] Epoch: 3 [237952/620022]    Loss: 0.007037   Batch Acc: 87.50
[Train] Epoch: 3 [238016/620022]    Loss: 0.010969   Batch Acc: 71.88
[Train] Epoch: 3 [238080/620022]    Loss: 0.008579   Batch Acc: 75.00
[Train] Epoch: 3 [238144/620022]    Loss: 0.008369   Batch Acc: 76.56
[Train] Epoch: 3 [238208/620022]    Loss: 0.009237   Batch Acc: 76.56
[Train] Epoch: 3 [238272/620022]    Loss: 0.008695   Batch Acc: 79.69
[Train] Epoch: 3 [238336/620022]    Loss: 0.007809   Batch Acc: 82.81
[Train] Epoch: 3 [238400/620022]    Loss: 0.009431   Batch Acc: 71.88
[Train] Epoch: 3 [238464/620022]    Loss: 0.011671   Batch Acc: 73.44
[Train] Epoch: 3 [238528/620022]    Loss: 0.009844   Batch Acc: 78.12
[Train] Epoch: 3 [238592/620022]    Loss: 0.005482   Batch Acc: 89.06
[Train] Epoch: 3 [238656/620022]    Loss: 0.006502   Batch Acc: 85.94
[Train] Epoch: 3 [238720/620022]    Loss: 0.009146   Batch Acc: 73.44
[Train] Epoch: 3 [238784/620022]    Loss: 0.007711   Batch Acc: 82.81
[Train] Epoch: 3 [238848/620022]    Loss: 0.010671   Batch Acc: 71.88
[Train] Epoch: 3 [238912/620022]    Loss: 0.007431   Batch Acc: 84.38
[Train] Epoch: 3 [238976/620022]    Loss: 0.008656   Batch Acc: 73.44
[Train] Epoch: 3 [239040/620022]    Loss: 0.008632   Batch Acc: 76.56
[Train] Epoch: 3 [239104/620022]    Loss: 0.009540   Batch Acc: 76.56
[Train] Epoch: 3 [239168/620022]    Loss: 0.008127   Batch Acc: 78.12
[Train] Epoch: 3 [239232/620022]    Loss: 0.008790   Batch Acc: 70.31
[Train] Epoch: 3 [239296/620022]    Loss: 0.007923   Batch Acc: 79.69
[Train] Epoch: 3 [239360/620022]    Loss: 0.008590   Batch Acc: 78.12
[Train] Epoch: 3 [239424/620022]    Loss: 0.006963   Batch Acc: 82.81
[Train] Epoch: 3 [239488/620022]    Loss: 0.010551   Batch Acc: 73.44
[Train] Epoch: 3 [239552/620022]    Loss: 0.009525   Batch Acc: 71.88
[Train] Epoch: 3 [239616/620022]    Loss: 0.006796   Batch Acc: 87.50
[Train] Epoch: 3 [239680/620022]    Loss: 0.006904   Batch Acc: 84.38
[Train] Epoch: 3 [239744/620022]    Loss: 0.007266   Batch Acc: 82.81
[Train] Epoch: 3 [239808/620022]    Loss: 0.007817   Batch Acc: 79.69
[Train] Epoch: 3 [239872/620022]    Loss: 0.009639   Batch Acc: 73.44
[Train] Epoch: 3 [239936/620022]    Loss: 0.008144   Batch Acc: 81.25
[Train] Epoch: 3 [240000/620022]    Loss: 0.008029   Batch Acc: 81.25
[Train] Epoch: 3 [240064/620022]    Loss: 0.007356   Batch Acc: 82.81
[Train] Epoch: 3 [240128/620022]    Loss: 0.008820   Batch Acc: 78.12
[Train] Epoch: 3 [240192/620022]    Loss: 0.006237   Batch Acc: 85.94
[Train] Epoch: 3 [240256/620022]    Loss: 0.009335   Batch Acc: 75.00
[Train] Epoch: 3 [240320/620022]    Loss: 0.010542   Batch Acc: 65.62
[Train] Epoch: 3 [240384/620022]    Loss: 0.007158   Batch Acc: 84.38
[Train] Epoch: 3 [240448/620022]    Loss: 0.008970   Batch Acc: 71.88
[Train] Epoch: 3 [240512/620022]    Loss: 0.009640   Batch Acc: 76.56
[Train] Epoch: 3 [240576/620022]    Loss: 0.009460   Batch Acc: 78.12
[Train] Epoch: 3 [240640/620022]    Loss: 0.007242   Batch Acc: 82.81
[Train] Epoch: 3 [240704/620022]    Loss: 0.009065   Batch Acc: 84.38
[Train] Epoch: 3 [240768/620022]    Loss: 0.008820   Batch Acc: 71.88
[Train] Epoch: 3 [240832/620022]    Loss: 0.008012   Batch Acc: 79.69
[Train] Epoch: 3 [240896/620022]    Loss: 0.008621   Batch Acc: 76.56
[Train] Epoch: 3 [240960/620022]    Loss: 0.008099   Batch Acc: 78.12
[Train] Epoch: 3 [241024/620022]    Loss: 0.005601   Batch Acc: 90.62
[Train] Epoch: 3 [241088/620022]    Loss: 0.009343   Batch Acc: 75.00
[Train] Epoch: 3 [241152/620022]    Loss: 0.011390   Batch Acc: 67.19
[Train] Epoch: 3 [241216/620022]    Loss: 0.008020   Batch Acc: 84.38
[Train] Epoch: 3 [241280/620022]    Loss: 0.010627   Batch Acc: 76.56
[Train] Epoch: 3 [241344/620022]    Loss: 0.008743   Batch Acc: 84.38
[Train] Epoch: 3 [241408/620022]    Loss: 0.009643   Batch Acc: 78.12
[Train] Epoch: 3 [241472/620022]    Loss: 0.010667   Batch Acc: 73.44
[Train] Epoch: 3 [241536/620022]    Loss: 0.008755   Batch Acc: 76.56
[Train] Epoch: 3 [241600/620022]    Loss: 0.008539   Batch Acc: 81.25
[Train] Epoch: 3 [241664/620022]    Loss: 0.008336   Batch Acc: 73.44
[Train] Epoch: 3 [241728/620022]    Loss: 0.007682   Batch Acc: 82.81
[Train] Epoch: 3 [241792/620022]    Loss: 0.008613   Batch Acc: 76.56
[Train] Epoch: 3 [241856/620022]    Loss: 0.009526   Batch Acc: 79.69
[Train] Epoch: 3 [241920/620022]    Loss: 0.009277   Batch Acc: 70.31
[Train] Epoch: 3 [241984/620022]    Loss: 0.009972   Batch Acc: 70.31
[Train] Epoch: 3 [242048/620022]    Loss: 0.008349   Batch Acc: 78.12
[Train] Epoch: 3 [242112/620022]    Loss: 0.012940   Batch Acc: 71.88
[Train] Epoch: 3 [242176/620022]    Loss: 0.008181   Batch Acc: 71.88
[Train] Epoch: 3 [242240/620022]    Loss: 0.010226   Batch Acc: 71.88
[Train] Epoch: 3 [242304/620022]    Loss: 0.008845   Batch Acc: 82.81
[Train] Epoch: 3 [242368/620022]    Loss: 0.007861   Batch Acc: 79.69
[Train] Epoch: 3 [242432/620022]    Loss: 0.008712   Batch Acc: 78.12
[Train] Epoch: 3 [242496/620022]    Loss: 0.007606   Batch Acc: 81.25
[Train] Epoch: 3 [242560/620022]    Loss: 0.007927   Batch Acc: 75.00
[Train] Epoch: 3 [242624/620022]    Loss: 0.009186   Batch Acc: 76.56
[Train] Epoch: 3 [242688/620022]    Loss: 0.009584   Batch Acc: 71.88
[Train] Epoch: 3 [242752/620022]    Loss: 0.009284   Batch Acc: 81.25
[Train] Epoch: 3 [242816/620022]    Loss: 0.007981   Batch Acc: 81.25
[Train] Epoch: 3 [242880/620022]    Loss: 0.010480   Batch Acc: 67.19
[Train] Epoch: 3 [242944/620022]    Loss: 0.009816   Batch Acc: 79.69
[Train] Epoch: 3 [243008/620022]    Loss: 0.010402   Batch Acc: 75.00
[Train] Epoch: 3 [243072/620022]    Loss: 0.008716   Batch Acc: 81.25
[Train] Epoch: 3 [243136/620022]    Loss: 0.008034   Batch Acc: 82.81
[Train] Epoch: 3 [243200/620022]    Loss: 0.008555   Batch Acc: 79.69
[Train] Epoch: 3 [243264/620022]    Loss: 0.009799   Batch Acc: 70.31
[Train] Epoch: 3 [243328/620022]    Loss: 0.008362   Batch Acc: 82.81
[Train] Epoch: 3 [243392/620022]    Loss: 0.009609   Batch Acc: 76.56
[Train] Epoch: 3 [243456/620022]    Loss: 0.007064   Batch Acc: 84.38
[Train] Epoch: 3 [243520/620022]    Loss: 0.009810   Batch Acc: 76.56
[Train] Epoch: 3 [243584/620022]    Loss: 0.008803   Batch Acc: 76.56
[Train] Epoch: 3 [243648/620022]    Loss: 0.008971   Batch Acc: 75.00
[Train] Epoch: 3 [243712/620022]    Loss: 0.008110   Batch Acc: 82.81
[Train] Epoch: 3 [243776/620022]    Loss: 0.007675   Batch Acc: 82.81
[Train] Epoch: 3 [243840/620022]    Loss: 0.009520   Batch Acc: 79.69
[Train] Epoch: 3 [243904/620022]    Loss: 0.007896   Batch Acc: 82.81
[Train] Epoch: 3 [243968/620022]    Loss: 0.009120   Batch Acc: 70.31
[Train] Epoch: 3 [244032/620022]    Loss: 0.008998   Batch Acc: 76.56
[Train] Epoch: 3 [244096/620022]    Loss: 0.008790   Batch Acc: 78.12
[Train] Epoch: 3 [244160/620022]    Loss: 0.008893   Batch Acc: 81.25
[Train] Epoch: 3 [244224/620022]    Loss: 0.008091   Batch Acc: 71.88
[Train] Epoch: 3 [244288/620022]    Loss: 0.008813   Batch Acc: 76.56
[Train] Epoch: 3 [244352/620022]    Loss: 0.010673   Batch Acc: 70.31
[Train] Epoch: 3 [244416/620022]    Loss: 0.010159   Batch Acc: 75.00
[Train] Epoch: 3 [244480/620022]    Loss: 0.009864   Batch Acc: 68.75
[Train] Epoch: 3 [244544/620022]    Loss: 0.007335   Batch Acc: 81.25
[Train] Epoch: 3 [244608/620022]    Loss: 0.008924   Batch Acc: 82.81
[Train] Epoch: 3 [244672/620022]    Loss: 0.006164   Batch Acc: 87.50
[Train] Epoch: 3 [244736/620022]    Loss: 0.005615   Batch Acc: 89.06
[Train] Epoch: 3 [244800/620022]    Loss: 0.009385   Batch Acc: 75.00
[Train] Epoch: 3 [244864/620022]    Loss: 0.008700   Batch Acc: 76.56
[Train] Epoch: 3 [244928/620022]    Loss: 0.006913   Batch Acc: 81.25
[Train] Epoch: 3 [244992/620022]    Loss: 0.012632   Batch Acc: 64.06
[Train] Epoch: 3 [245056/620022]    Loss: 0.007403   Batch Acc: 79.69
[Train] Epoch: 3 [245120/620022]    Loss: 0.007513   Batch Acc: 84.38
[Train] Epoch: 3 [245184/620022]    Loss: 0.007792   Batch Acc: 82.81
[Train] Epoch: 3 [245248/620022]    Loss: 0.009755   Batch Acc: 78.12
[Train] Epoch: 3 [245312/620022]    Loss: 0.007963   Batch Acc: 78.12
[Train] Epoch: 3 [245376/620022]    Loss: 0.008728   Batch Acc: 81.25
[Train] Epoch: 3 [245440/620022]    Loss: 0.009277   Batch Acc: 78.12
[Train] Epoch: 3 [245504/620022]    Loss: 0.010420   Batch Acc: 71.88
[Train] Epoch: 3 [245568/620022]    Loss: 0.008897   Batch Acc: 79.69
[Train] Epoch: 3 [245632/620022]    Loss: 0.010383   Batch Acc: 70.31
[Train] Epoch: 3 [245696/620022]    Loss: 0.008342   Batch Acc: 73.44
[Train] Epoch: 3 [245760/620022]    Loss: 0.010302   Batch Acc: 75.00
[Train] Epoch: 3 [245824/620022]    Loss: 0.009911   Batch Acc: 71.88
[Train] Epoch: 3 [245888/620022]    Loss: 0.009721   Batch Acc: 71.88
[Train] Epoch: 3 [245952/620022]    Loss: 0.008337   Batch Acc: 82.81
[Train] Epoch: 3 [246016/620022]    Loss: 0.009151   Batch Acc: 78.12
[Train] Epoch: 3 [246080/620022]    Loss: 0.010783   Batch Acc: 68.75
[Train] Epoch: 3 [246144/620022]    Loss: 0.008555   Batch Acc: 76.56
[Train] Epoch: 3 [246208/620022]    Loss: 0.009292   Batch Acc: 76.56
[Train] Epoch: 3 [246272/620022]    Loss: 0.007680   Batch Acc: 87.50
[Train] Epoch: 3 [246336/620022]    Loss: 0.008853   Batch Acc: 75.00
[Train] Epoch: 3 [246400/620022]    Loss: 0.009621   Batch Acc: 78.12
[Train] Epoch: 3 [246464/620022]    Loss: 0.007360   Batch Acc: 79.69
[Train] Epoch: 3 [246528/620022]    Loss: 0.010291   Batch Acc: 73.44
[Train] Epoch: 3 [246592/620022]    Loss: 0.008316   Batch Acc: 81.25
[Train] Epoch: 3 [246656/620022]    Loss: 0.009036   Batch Acc: 76.56
[Train] Epoch: 3 [246720/620022]    Loss: 0.008390   Batch Acc: 81.25
[Train] Epoch: 3 [246784/620022]    Loss: 0.009776   Batch Acc: 75.00
[Train] Epoch: 3 [246848/620022]    Loss: 0.009857   Batch Acc: 76.56
[Train] Epoch: 3 [246912/620022]    Loss: 0.011882   Batch Acc: 76.56
[Train] Epoch: 3 [246976/620022]    Loss: 0.010028   Batch Acc: 75.00
[Train] Epoch: 3 [247040/620022]    Loss: 0.006419   Batch Acc: 84.38
[Train] Epoch: 3 [247104/620022]    Loss: 0.008923   Batch Acc: 76.56
[Train] Epoch: 3 [247168/620022]    Loss: 0.009406   Batch Acc: 76.56
[Train] Epoch: 3 [247232/620022]    Loss: 0.010436   Batch Acc: 68.75
[Train] Epoch: 3 [247296/620022]    Loss: 0.008548   Batch Acc: 78.12
[Train] Epoch: 3 [247360/620022]    Loss: 0.008943   Batch Acc: 79.69
[Train] Epoch: 3 [247424/620022]    Loss: 0.008276   Batch Acc: 82.81
[Train] Epoch: 3 [247488/620022]    Loss: 0.011093   Batch Acc: 68.75
[Train] Epoch: 3 [247552/620022]    Loss: 0.010264   Batch Acc: 71.88
[Train] Epoch: 3 [247616/620022]    Loss: 0.009411   Batch Acc: 76.56
[Train] Epoch: 3 [247680/620022]    Loss: 0.008535   Batch Acc: 75.00
[Train] Epoch: 3 [247744/620022]    Loss: 0.007917   Batch Acc: 81.25
[Train] Epoch: 3 [247808/620022]    Loss: 0.010593   Batch Acc: 78.12
[Train] Epoch: 3 [247872/620022]    Loss: 0.008435   Batch Acc: 82.81
[Train] Epoch: 3 [247936/620022]    Loss: 0.006952   Batch Acc: 89.06
[Train] Epoch: 3 [248000/620022]    Loss: 0.010356   Batch Acc: 70.31
[Train] Epoch: 3 [248064/620022]    Loss: 0.008839   Batch Acc: 82.81
[Train] Epoch: 3 [248128/620022]    Loss: 0.008450   Batch Acc: 81.25
[Train] Epoch: 3 [248192/620022]    Loss: 0.008242   Batch Acc: 79.69
[Train] Epoch: 3 [248256/620022]    Loss: 0.005937   Batch Acc: 82.81
[Train] Epoch: 3 [248320/620022]    Loss: 0.008751   Batch Acc: 75.00
[Train] Epoch: 3 [248384/620022]    Loss: 0.007541   Batch Acc: 81.25
[Train] Epoch: 3 [248448/620022]    Loss: 0.007303   Batch Acc: 85.94
[Train] Epoch: 3 [248512/620022]    Loss: 0.009074   Batch Acc: 76.56
[Train] Epoch: 3 [248576/620022]    Loss: 0.007696   Batch Acc: 82.81
[Train] Epoch: 3 [248640/620022]    Loss: 0.008557   Batch Acc: 76.56
[Train] Epoch: 3 [248704/620022]    Loss: 0.009346   Batch Acc: 75.00
[Train] Epoch: 3 [248768/620022]    Loss: 0.006937   Batch Acc: 82.81
[Train] Epoch: 3 [248832/620022]    Loss: 0.008516   Batch Acc: 79.69
[Train] Epoch: 3 [248896/620022]    Loss: 0.007094   Batch Acc: 81.25
[Train] Epoch: 3 [248960/620022]    Loss: 0.007116   Batch Acc: 84.38
[Train] Epoch: 3 [249024/620022]    Loss: 0.009522   Batch Acc: 76.56
[Train] Epoch: 3 [249088/620022]    Loss: 0.008518   Batch Acc: 75.00
[Train] Epoch: 3 [249152/620022]    Loss: 0.006207   Batch Acc: 87.50
[Train] Epoch: 3 [249216/620022]    Loss: 0.008217   Batch Acc: 79.69
[Train] Epoch: 3 [249280/620022]    Loss: 0.008080   Batch Acc: 76.56
[Train] Epoch: 3 [249344/620022]    Loss: 0.012456   Batch Acc: 62.50
[Train] Epoch: 3 [249408/620022]    Loss: 0.009699   Batch Acc: 76.56
[Train] Epoch: 3 [249472/620022]    Loss: 0.012120   Batch Acc: 62.50
[Train] Epoch: 3 [249536/620022]    Loss: 0.008413   Batch Acc: 78.12
[Train] Epoch: 3 [249600/620022]    Loss: 0.009447   Batch Acc: 76.56
[Train] Epoch: 3 [249664/620022]    Loss: 0.009384   Batch Acc: 75.00
[Train] Epoch: 3 [249728/620022]    Loss: 0.007922   Batch Acc: 81.25
[Train] Epoch: 3 [249792/620022]    Loss: 0.006178   Batch Acc: 85.94
[Train] Epoch: 3 [249856/620022]    Loss: 0.010731   Batch Acc: 68.75
[Train] Epoch: 3 [249920/620022]    Loss: 0.011676   Batch Acc: 65.62
[Train] Epoch: 3 [249984/620022]    Loss: 0.008416   Batch Acc: 79.69
[Train] Epoch: 3 [250048/620022]    Loss: 0.008160   Batch Acc: 79.69
[Train] Epoch: 3 [250112/620022]    Loss: 0.010230   Batch Acc: 75.00
[Train] Epoch: 3 [250176/620022]    Loss: 0.009085   Batch Acc: 75.00
[Train] Epoch: 3 [250240/620022]    Loss: 0.009491   Batch Acc: 73.44
[Train] Epoch: 3 [250304/620022]    Loss: 0.006580   Batch Acc: 87.50
[Train] Epoch: 3 [250368/620022]    Loss: 0.010022   Batch Acc: 67.19
[Train] Epoch: 3 [250432/620022]    Loss: 0.010434   Batch Acc: 65.62
[Train] Epoch: 3 [250496/620022]    Loss: 0.009228   Batch Acc: 76.56
[Train] Epoch: 3 [250560/620022]    Loss: 0.006710   Batch Acc: 85.94
[Train] Epoch: 3 [250624/620022]    Loss: 0.010095   Batch Acc: 73.44
[Train] Epoch: 3 [250688/620022]    Loss: 0.008471   Batch Acc: 81.25
[Train] Epoch: 3 [250752/620022]    Loss: 0.007799   Batch Acc: 79.69
[Train] Epoch: 3 [250816/620022]    Loss: 0.006850   Batch Acc: 87.50
[Train] Epoch: 3 [250880/620022]    Loss: 0.006718   Batch Acc: 84.38
[Train] Epoch: 3 [250944/620022]    Loss: 0.009760   Batch Acc: 81.25
[Train] Epoch: 3 [251008/620022]    Loss: 0.007696   Batch Acc: 79.69
[Train] Epoch: 3 [251072/620022]    Loss: 0.012010   Batch Acc: 67.19
[Train] Epoch: 3 [251136/620022]    Loss: 0.009254   Batch Acc: 73.44
[Train] Epoch: 3 [251200/620022]    Loss: 0.007846   Batch Acc: 81.25
[Train] Epoch: 3 [251264/620022]    Loss: 0.006316   Batch Acc: 87.50
[Train] Epoch: 3 [251328/620022]    Loss: 0.006890   Batch Acc: 85.94
[Train] Epoch: 3 [251392/620022]    Loss: 0.010144   Batch Acc: 76.56
[Train] Epoch: 3 [251456/620022]    Loss: 0.010321   Batch Acc: 71.88
[Train] Epoch: 3 [251520/620022]    Loss: 0.007731   Batch Acc: 78.12
[Train] Epoch: 3 [251584/620022]    Loss: 0.008496   Batch Acc: 79.69
[Train] Epoch: 3 [251648/620022]    Loss: 0.008573   Batch Acc: 78.12
[Train] Epoch: 3 [251712/620022]    Loss: 0.009621   Batch Acc: 70.31
[Train] Epoch: 3 [251776/620022]    Loss: 0.007891   Batch Acc: 78.12
[Train] Epoch: 3 [251840/620022]    Loss: 0.008415   Batch Acc: 81.25
[Train] Epoch: 3 [251904/620022]    Loss: 0.007315   Batch Acc: 82.81
[Train] Epoch: 3 [251968/620022]    Loss: 0.008372   Batch Acc: 78.12
[Train] Epoch: 3 [252032/620022]    Loss: 0.009924   Batch Acc: 73.44
[Train] Epoch: 3 [252096/620022]    Loss: 0.008487   Batch Acc: 81.25
[Train] Epoch: 3 [252160/620022]    Loss: 0.009499   Batch Acc: 75.00
[Train] Epoch: 3 [252224/620022]    Loss: 0.008238   Batch Acc: 78.12
[Train] Epoch: 3 [252288/620022]    Loss: 0.007213   Batch Acc: 81.25
[Train] Epoch: 3 [252352/620022]    Loss: 0.007338   Batch Acc: 81.25
[Train] Epoch: 3 [252416/620022]    Loss: 0.008638   Batch Acc: 73.44
[Train] Epoch: 3 [252480/620022]    Loss: 0.007438   Batch Acc: 84.38
[Train] Epoch: 3 [252544/620022]    Loss: 0.008371   Batch Acc: 79.69
[Train] Epoch: 3 [252608/620022]    Loss: 0.008047   Batch Acc: 79.69
[Train] Epoch: 3 [252672/620022]    Loss: 0.009272   Batch Acc: 75.00
[Train] Epoch: 3 [252736/620022]    Loss: 0.011117   Batch Acc: 70.31
[Train] Epoch: 3 [252800/620022]    Loss: 0.008946   Batch Acc: 70.31
[Train] Epoch: 3 [252864/620022]    Loss: 0.007234   Batch Acc: 84.38
[Train] Epoch: 3 [252928/620022]    Loss: 0.010480   Batch Acc: 75.00
[Train] Epoch: 3 [252992/620022]    Loss: 0.010872   Batch Acc: 71.88
[Train] Epoch: 3 [253056/620022]    Loss: 0.009991   Batch Acc: 68.75
[Train] Epoch: 3 [253120/620022]    Loss: 0.008176   Batch Acc: 81.25
[Train] Epoch: 3 [253184/620022]    Loss: 0.010074   Batch Acc: 68.75
[Train] Epoch: 3 [253248/620022]    Loss: 0.010175   Batch Acc: 70.31
[Train] Epoch: 3 [253312/620022]    Loss: 0.008953   Batch Acc: 78.12
[Train] Epoch: 3 [253376/620022]    Loss: 0.006756   Batch Acc: 87.50
[Train] Epoch: 3 [253440/620022]    Loss: 0.008479   Batch Acc: 76.56
[Train] Epoch: 3 [253504/620022]    Loss: 0.008381   Batch Acc: 78.12
[Train] Epoch: 3 [253568/620022]    Loss: 0.010834   Batch Acc: 64.06
[Train] Epoch: 3 [253632/620022]    Loss: 0.005036   Batch Acc: 89.06
[Train] Epoch: 3 [253696/620022]    Loss: 0.007254   Batch Acc: 85.94
[Train] Epoch: 3 [253760/620022]    Loss: 0.009351   Batch Acc: 76.56
[Train] Epoch: 3 [253824/620022]    Loss: 0.009580   Batch Acc: 76.56
[Train] Epoch: 3 [253888/620022]    Loss: 0.009095   Batch Acc: 75.00
[Train] Epoch: 3 [253952/620022]    Loss: 0.008293   Batch Acc: 81.25
[Train] Epoch: 3 [254016/620022]    Loss: 0.009514   Batch Acc: 75.00
[Train] Epoch: 3 [254080/620022]    Loss: 0.011107   Batch Acc: 62.50
[Train] Epoch: 3 [254144/620022]    Loss: 0.009096   Batch Acc: 75.00
[Train] Epoch: 3 [254208/620022]    Loss: 0.008547   Batch Acc: 75.00
[Train] Epoch: 3 [254272/620022]    Loss: 0.008888   Batch Acc: 81.25
[Train] Epoch: 3 [254336/620022]    Loss: 0.009226   Batch Acc: 75.00
[Train] Epoch: 3 [254400/620022]    Loss: 0.008235   Batch Acc: 79.69
[Train] Epoch: 3 [254464/620022]    Loss: 0.012408   Batch Acc: 60.94
[Train] Epoch: 3 [254528/620022]    Loss: 0.007325   Batch Acc: 81.25
[Train] Epoch: 3 [254592/620022]    Loss: 0.009408   Batch Acc: 79.69
[Train] Epoch: 3 [254656/620022]    Loss: 0.006724   Batch Acc: 87.50
[Train] Epoch: 3 [254720/620022]    Loss: 0.009284   Batch Acc: 68.75
[Train] Epoch: 3 [254784/620022]    Loss: 0.006928   Batch Acc: 84.38
[Train] Epoch: 3 [254848/620022]    Loss: 0.006202   Batch Acc: 85.94
[Train] Epoch: 3 [254912/620022]    Loss: 0.011942   Batch Acc: 64.06
[Train] Epoch: 3 [254976/620022]    Loss: 0.010895   Batch Acc: 75.00
[Train] Epoch: 3 [255040/620022]    Loss: 0.010057   Batch Acc: 79.69
[Train] Epoch: 3 [255104/620022]    Loss: 0.007651   Batch Acc: 81.25
[Train] Epoch: 3 [255168/620022]    Loss: 0.006616   Batch Acc: 89.06
[Train] Epoch: 3 [255232/620022]    Loss: 0.009022   Batch Acc: 75.00
[Train] Epoch: 3 [255296/620022]    Loss: 0.005954   Batch Acc: 84.38
[Train] Epoch: 3 [255360/620022]    Loss: 0.008633   Batch Acc: 73.44
[Train] Epoch: 3 [255424/620022]    Loss: 0.008799   Batch Acc: 78.12
[Train] Epoch: 3 [255488/620022]    Loss: 0.008475   Batch Acc: 71.88
[Train] Epoch: 3 [255552/620022]    Loss: 0.007837   Batch Acc: 81.25
[Train] Epoch: 3 [255616/620022]    Loss: 0.005541   Batch Acc: 85.94
[Train] Epoch: 3 [255680/620022]    Loss: 0.010335   Batch Acc: 73.44
[Train] Epoch: 3 [255744/620022]    Loss: 0.011803   Batch Acc: 73.44
[Train] Epoch: 3 [255808/620022]    Loss: 0.007630   Batch Acc: 78.12
[Train] Epoch: 3 [255872/620022]    Loss: 0.007392   Batch Acc: 84.38
[Train] Epoch: 3 [255936/620022]    Loss: 0.008728   Batch Acc: 76.56
[Train] Epoch: 3 [256000/620022]    Loss: 0.007133   Batch Acc: 76.56
[Train] Epoch: 3 [256064/620022]    Loss: 0.009586   Batch Acc: 73.44
[Train] Epoch: 3 [256128/620022]    Loss: 0.010666   Batch Acc: 65.62
[Train] Epoch: 3 [256192/620022]    Loss: 0.008411   Batch Acc: 78.12
[Train] Epoch: 3 [256256/620022]    Loss: 0.008516   Batch Acc: 78.12
[Train] Epoch: 3 [256320/620022]    Loss: 0.008424   Batch Acc: 76.56
[Train] Epoch: 3 [256384/620022]    Loss: 0.007493   Batch Acc: 79.69
[Train] Epoch: 3 [256448/620022]    Loss: 0.012038   Batch Acc: 73.44
[Train] Epoch: 3 [256512/620022]    Loss: 0.009024   Batch Acc: 82.81
[Train] Epoch: 3 [256576/620022]    Loss: 0.007186   Batch Acc: 81.25
[Train] Epoch: 3 [256640/620022]    Loss: 0.006677   Batch Acc: 84.38
[Train] Epoch: 3 [256704/620022]    Loss: 0.007131   Batch Acc: 82.81
[Train] Epoch: 3 [256768/620022]    Loss: 0.009856   Batch Acc: 75.00
[Train] Epoch: 3 [256832/620022]    Loss: 0.007031   Batch Acc: 82.81
[Train] Epoch: 3 [256896/620022]    Loss: 0.010081   Batch Acc: 76.56
[Train] Epoch: 3 [256960/620022]    Loss: 0.007286   Batch Acc: 82.81
[Train] Epoch: 3 [257024/620022]    Loss: 0.007778   Batch Acc: 82.81
[Train] Epoch: 3 [257088/620022]    Loss: 0.009118   Batch Acc: 75.00
[Train] Epoch: 3 [257152/620022]    Loss: 0.007058   Batch Acc: 79.69
[Train] Epoch: 3 [257216/620022]    Loss: 0.012717   Batch Acc: 65.62
[Train] Epoch: 3 [257280/620022]    Loss: 0.008719   Batch Acc: 79.69
[Train] Epoch: 3 [257344/620022]    Loss: 0.007038   Batch Acc: 87.50
[Train] Epoch: 3 [257408/620022]    Loss: 0.010694   Batch Acc: 67.19
[Train] Epoch: 3 [257472/620022]    Loss: 0.008668   Batch Acc: 78.12
[Train] Epoch: 3 [257536/620022]    Loss: 0.006622   Batch Acc: 87.50
[Train] Epoch: 3 [257600/620022]    Loss: 0.008907   Batch Acc: 75.00
[Train] Epoch: 3 [257664/620022]    Loss: 0.009976   Batch Acc: 75.00
[Train] Epoch: 3 [257728/620022]    Loss: 0.006094   Batch Acc: 85.94
[Train] Epoch: 3 [257792/620022]    Loss: 0.009127   Batch Acc: 79.69
[Train] Epoch: 3 [257856/620022]    Loss: 0.009992   Batch Acc: 78.12
[Train] Epoch: 3 [257920/620022]    Loss: 0.009270   Batch Acc: 73.44
[Train] Epoch: 3 [257984/620022]    Loss: 0.009443   Batch Acc: 75.00
[Train] Epoch: 3 [258048/620022]    Loss: 0.007963   Batch Acc: 79.69
[Train] Epoch: 3 [258112/620022]    Loss: 0.009722   Batch Acc: 82.81
[Train] Epoch: 3 [258176/620022]    Loss: 0.007641   Batch Acc: 84.38
[Train] Epoch: 3 [258240/620022]    Loss: 0.008123   Batch Acc: 79.69
[Train] Epoch: 3 [258304/620022]    Loss: 0.008087   Batch Acc: 76.56
[Train] Epoch: 3 [258368/620022]    Loss: 0.007269   Batch Acc: 84.38
[Train] Epoch: 3 [258432/620022]    Loss: 0.007125   Batch Acc: 79.69
[Train] Epoch: 3 [258496/620022]    Loss: 0.007591   Batch Acc: 82.81
[Train] Epoch: 3 [258560/620022]    Loss: 0.007765   Batch Acc: 76.56
[Train] Epoch: 3 [258624/620022]    Loss: 0.009420   Batch Acc: 79.69
[Train] Epoch: 3 [258688/620022]    Loss: 0.008245   Batch Acc: 79.69
[Train] Epoch: 3 [258752/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 3 [258816/620022]    Loss: 0.008775   Batch Acc: 76.56
[Train] Epoch: 3 [258880/620022]    Loss: 0.007611   Batch Acc: 84.38
[Train] Epoch: 3 [258944/620022]    Loss: 0.007931   Batch Acc: 82.81
[Train] Epoch: 3 [259008/620022]    Loss: 0.007564   Batch Acc: 82.81
[Train] Epoch: 3 [259072/620022]    Loss: 0.009429   Batch Acc: 78.12
[Train] Epoch: 3 [259136/620022]    Loss: 0.008105   Batch Acc: 78.12
[Train] Epoch: 3 [259200/620022]    Loss: 0.010420   Batch Acc: 71.88
[Train] Epoch: 3 [259264/620022]    Loss: 0.009411   Batch Acc: 79.69
[Train] Epoch: 3 [259328/620022]    Loss: 0.011316   Batch Acc: 68.75
[Train] Epoch: 3 [259392/620022]    Loss: 0.010463   Batch Acc: 75.00
[Train] Epoch: 3 [259456/620022]    Loss: 0.009584   Batch Acc: 75.00
[Train] Epoch: 3 [259520/620022]    Loss: 0.007977   Batch Acc: 81.25
[Train] Epoch: 3 [259584/620022]    Loss: 0.009527   Batch Acc: 71.88
[Train] Epoch: 3 [259648/620022]    Loss: 0.006916   Batch Acc: 81.25
[Train] Epoch: 3 [259712/620022]    Loss: 0.007551   Batch Acc: 82.81
[Train] Epoch: 3 [259776/620022]    Loss: 0.009204   Batch Acc: 76.56
[Train] Epoch: 3 [259840/620022]    Loss: 0.008984   Batch Acc: 78.12
[Train] Epoch: 3 [259904/620022]    Loss: 0.008289   Batch Acc: 82.81
[Train] Epoch: 3 [259968/620022]    Loss: 0.007610   Batch Acc: 81.25
[Train] Epoch: 3 [260032/620022]    Loss: 0.009513   Batch Acc: 71.88
[Train] Epoch: 3 [260096/620022]    Loss: 0.009513   Batch Acc: 75.00
[Train] Epoch: 3 [260160/620022]    Loss: 0.008570   Batch Acc: 82.81
[Train] Epoch: 3 [260224/620022]    Loss: 0.009811   Batch Acc: 75.00
[Train] Epoch: 3 [260288/620022]    Loss: 0.009201   Batch Acc: 81.25
[Train] Epoch: 3 [260352/620022]    Loss: 0.009601   Batch Acc: 64.06
[Train] Epoch: 3 [260416/620022]    Loss: 0.009531   Batch Acc: 78.12
[Train] Epoch: 3 [260480/620022]    Loss: 0.009173   Batch Acc: 78.12
[Train] Epoch: 3 [260544/620022]    Loss: 0.007833   Batch Acc: 75.00
[Train] Epoch: 3 [260608/620022]    Loss: 0.009705   Batch Acc: 71.88
[Train] Epoch: 3 [260672/620022]    Loss: 0.008601   Batch Acc: 73.44
[Train] Epoch: 3 [260736/620022]    Loss: 0.006572   Batch Acc: 81.25
[Train] Epoch: 3 [260800/620022]    Loss: 0.008108   Batch Acc: 82.81
[Train] Epoch: 3 [260864/620022]    Loss: 0.007616   Batch Acc: 84.38
[Train] Epoch: 3 [260928/620022]    Loss: 0.011445   Batch Acc: 76.56
[Train] Epoch: 3 [260992/620022]    Loss: 0.007351   Batch Acc: 79.69
[Train] Epoch: 3 [261056/620022]    Loss: 0.011102   Batch Acc: 70.31
[Train] Epoch: 3 [261120/620022]    Loss: 0.007076   Batch Acc: 84.38
[Train] Epoch: 3 [261184/620022]    Loss: 0.009673   Batch Acc: 78.12
[Train] Epoch: 3 [261248/620022]    Loss: 0.009467   Batch Acc: 82.81
[Train] Epoch: 3 [261312/620022]    Loss: 0.009618   Batch Acc: 73.44
[Train] Epoch: 3 [261376/620022]    Loss: 0.011025   Batch Acc: 67.19
[Train] Epoch: 3 [261440/620022]    Loss: 0.007718   Batch Acc: 78.12
[Train] Epoch: 3 [261504/620022]    Loss: 0.008957   Batch Acc: 76.56
[Train] Epoch: 3 [261568/620022]    Loss: 0.007247   Batch Acc: 87.50
[Train] Epoch: 3 [261632/620022]    Loss: 0.008540   Batch Acc: 81.25
[Train] Epoch: 3 [261696/620022]    Loss: 0.009731   Batch Acc: 78.12
[Train] Epoch: 3 [261760/620022]    Loss: 0.008142   Batch Acc: 76.56
[Train] Epoch: 3 [261824/620022]    Loss: 0.007144   Batch Acc: 82.81
[Train] Epoch: 3 [261888/620022]    Loss: 0.006098   Batch Acc: 85.94
[Train] Epoch: 3 [261952/620022]    Loss: 0.009009   Batch Acc: 73.44
[Train] Epoch: 3 [262016/620022]    Loss: 0.011008   Batch Acc: 71.88
[Train] Epoch: 3 [262080/620022]    Loss: 0.008236   Batch Acc: 78.12
[Train] Epoch: 3 [262144/620022]    Loss: 0.010164   Batch Acc: 75.00
[Train] Epoch: 3 [262208/620022]    Loss: 0.008047   Batch Acc: 78.12
[Train] Epoch: 3 [262272/620022]    Loss: 0.009641   Batch Acc: 82.81
[Train] Epoch: 3 [262336/620022]    Loss: 0.007687   Batch Acc: 78.12
[Train] Epoch: 3 [262400/620022]    Loss: 0.010695   Batch Acc: 75.00
[Train] Epoch: 3 [262464/620022]    Loss: 0.009054   Batch Acc: 76.56
[Train] Epoch: 3 [262528/620022]    Loss: 0.008310   Batch Acc: 78.12
[Train] Epoch: 3 [262592/620022]    Loss: 0.007678   Batch Acc: 85.94
[Train] Epoch: 3 [262656/620022]    Loss: 0.007888   Batch Acc: 84.38
[Train] Epoch: 3 [262720/620022]    Loss: 0.007312   Batch Acc: 79.69
[Train] Epoch: 3 [262784/620022]    Loss: 0.009461   Batch Acc: 75.00
[Train] Epoch: 3 [262848/620022]    Loss: 0.007157   Batch Acc: 79.69
[Train] Epoch: 3 [262912/620022]    Loss: 0.010246   Batch Acc: 75.00
[Train] Epoch: 3 [262976/620022]    Loss: 0.008914   Batch Acc: 68.75
[Train] Epoch: 3 [263040/620022]    Loss: 0.007287   Batch Acc: 81.25
[Train] Epoch: 3 [263104/620022]    Loss: 0.009617   Batch Acc: 70.31
[Train] Epoch: 3 [263168/620022]    Loss: 0.009393   Batch Acc: 73.44
[Train] Epoch: 3 [263232/620022]    Loss: 0.009756   Batch Acc: 71.88
[Train] Epoch: 3 [263296/620022]    Loss: 0.008124   Batch Acc: 75.00
[Train] Epoch: 3 [263360/620022]    Loss: 0.007625   Batch Acc: 78.12
[Train] Epoch: 3 [263424/620022]    Loss: 0.006876   Batch Acc: 87.50
[Train] Epoch: 3 [263488/620022]    Loss: 0.008670   Batch Acc: 79.69
[Train] Epoch: 3 [263552/620022]    Loss: 0.006922   Batch Acc: 84.38
[Train] Epoch: 3 [263616/620022]    Loss: 0.006882   Batch Acc: 85.94
[Train] Epoch: 3 [263680/620022]    Loss: 0.010205   Batch Acc: 71.88
[Train] Epoch: 3 [263744/620022]    Loss: 0.009594   Batch Acc: 73.44
[Train] Epoch: 3 [263808/620022]    Loss: 0.007785   Batch Acc: 79.69
[Train] Epoch: 3 [263872/620022]    Loss: 0.009142   Batch Acc: 73.44
[Train] Epoch: 3 [263936/620022]    Loss: 0.008809   Batch Acc: 75.00
[Train] Epoch: 3 [264000/620022]    Loss: 0.008619   Batch Acc: 78.12
[Train] Epoch: 3 [264064/620022]    Loss: 0.007351   Batch Acc: 84.38
[Train] Epoch: 3 [264128/620022]    Loss: 0.009162   Batch Acc: 71.88
[Train] Epoch: 3 [264192/620022]    Loss: 0.010029   Batch Acc: 75.00
[Train] Epoch: 3 [264256/620022]    Loss: 0.009524   Batch Acc: 75.00
[Train] Epoch: 3 [264320/620022]    Loss: 0.008957   Batch Acc: 78.12
[Train] Epoch: 3 [264384/620022]    Loss: 0.007530   Batch Acc: 79.69
[Train] Epoch: 3 [264448/620022]    Loss: 0.009444   Batch Acc: 75.00
[Train] Epoch: 3 [264512/620022]    Loss: 0.011605   Batch Acc: 68.75
[Train] Epoch: 3 [264576/620022]    Loss: 0.008590   Batch Acc: 76.56
[Train] Epoch: 3 [264640/620022]    Loss: 0.007335   Batch Acc: 85.94
[Train] Epoch: 3 [264704/620022]    Loss: 0.011431   Batch Acc: 65.62
[Train] Epoch: 3 [264768/620022]    Loss: 0.009602   Batch Acc: 71.88
[Train] Epoch: 3 [264832/620022]    Loss: 0.005836   Batch Acc: 85.94
[Train] Epoch: 3 [264896/620022]    Loss: 0.007771   Batch Acc: 79.69
[Train] Epoch: 3 [264960/620022]    Loss: 0.008284   Batch Acc: 79.69
[Train] Epoch: 3 [265024/620022]    Loss: 0.006787   Batch Acc: 85.94
[Train] Epoch: 3 [265088/620022]    Loss: 0.006034   Batch Acc: 87.50
[Train] Epoch: 3 [265152/620022]    Loss: 0.006379   Batch Acc: 81.25
[Train] Epoch: 3 [265216/620022]    Loss: 0.010065   Batch Acc: 78.12
[Train] Epoch: 3 [265280/620022]    Loss: 0.007040   Batch Acc: 81.25
[Train] Epoch: 3 [265344/620022]    Loss: 0.009791   Batch Acc: 73.44
[Train] Epoch: 3 [265408/620022]    Loss: 0.010046   Batch Acc: 71.88
[Train] Epoch: 3 [265472/620022]    Loss: 0.008061   Batch Acc: 84.38
[Train] Epoch: 3 [265536/620022]    Loss: 0.009423   Batch Acc: 73.44
[Train] Epoch: 3 [265600/620022]    Loss: 0.010712   Batch Acc: 70.31
[Train] Epoch: 3 [265664/620022]    Loss: 0.009006   Batch Acc: 76.56
[Train] Epoch: 3 [265728/620022]    Loss: 0.007563   Batch Acc: 82.81
[Train] Epoch: 3 [265792/620022]    Loss: 0.008055   Batch Acc: 79.69
[Train] Epoch: 3 [265856/620022]    Loss: 0.008585   Batch Acc: 79.69
[Train] Epoch: 3 [265920/620022]    Loss: 0.007960   Batch Acc: 79.69
[Train] Epoch: 3 [265984/620022]    Loss: 0.007899   Batch Acc: 81.25
[Train] Epoch: 3 [266048/620022]    Loss: 0.007747   Batch Acc: 79.69
[Train] Epoch: 3 [266112/620022]    Loss: 0.009201   Batch Acc: 76.56
[Train] Epoch: 3 [266176/620022]    Loss: 0.009112   Batch Acc: 76.56
[Train] Epoch: 3 [266240/620022]    Loss: 0.011655   Batch Acc: 73.44
[Train] Epoch: 3 [266304/620022]    Loss: 0.008435   Batch Acc: 82.81
[Train] Epoch: 3 [266368/620022]    Loss: 0.009604   Batch Acc: 70.31
[Train] Epoch: 3 [266432/620022]    Loss: 0.008763   Batch Acc: 78.12
[Train] Epoch: 3 [266496/620022]    Loss: 0.009978   Batch Acc: 75.00
[Train] Epoch: 3 [266560/620022]    Loss: 0.007732   Batch Acc: 82.81
[Train] Epoch: 3 [266624/620022]    Loss: 0.008699   Batch Acc: 73.44
[Train] Epoch: 3 [266688/620022]    Loss: 0.011675   Batch Acc: 70.31
[Train] Epoch: 3 [266752/620022]    Loss: 0.006477   Batch Acc: 85.94
[Train] Epoch: 3 [266816/620022]    Loss: 0.008304   Batch Acc: 81.25
[Train] Epoch: 3 [266880/620022]    Loss: 0.007641   Batch Acc: 82.81
[Train] Epoch: 3 [266944/620022]    Loss: 0.009124   Batch Acc: 78.12
[Train] Epoch: 3 [267008/620022]    Loss: 0.009902   Batch Acc: 73.44
[Train] Epoch: 3 [267072/620022]    Loss: 0.009301   Batch Acc: 71.88
[Train] Epoch: 3 [267136/620022]    Loss: 0.007281   Batch Acc: 82.81
[Train] Epoch: 3 [267200/620022]    Loss: 0.012337   Batch Acc: 65.62
[Train] Epoch: 3 [267264/620022]    Loss: 0.009985   Batch Acc: 73.44
[Train] Epoch: 3 [267328/620022]    Loss: 0.011039   Batch Acc: 68.75
[Train] Epoch: 3 [267392/620022]    Loss: 0.008946   Batch Acc: 73.44
[Train] Epoch: 3 [267456/620022]    Loss: 0.007221   Batch Acc: 85.94
[Train] Epoch: 3 [267520/620022]    Loss: 0.008504   Batch Acc: 78.12
[Train] Epoch: 3 [267584/620022]    Loss: 0.007645   Batch Acc: 85.94
[Train] Epoch: 3 [267648/620022]    Loss: 0.009192   Batch Acc: 78.12
[Train] Epoch: 3 [267712/620022]    Loss: 0.007598   Batch Acc: 81.25
[Train] Epoch: 3 [267776/620022]    Loss: 0.010405   Batch Acc: 73.44
[Train] Epoch: 3 [267840/620022]    Loss: 0.008757   Batch Acc: 81.25
[Train] Epoch: 3 [267904/620022]    Loss: 0.009135   Batch Acc: 75.00
[Train] Epoch: 3 [267968/620022]    Loss: 0.007813   Batch Acc: 76.56
[Train] Epoch: 3 [268032/620022]    Loss: 0.008029   Batch Acc: 81.25
[Train] Epoch: 3 [268096/620022]    Loss: 0.010948   Batch Acc: 71.88
[Train] Epoch: 3 [268160/620022]    Loss: 0.008640   Batch Acc: 78.12
[Train] Epoch: 3 [268224/620022]    Loss: 0.008055   Batch Acc: 81.25
[Train] Epoch: 3 [268288/620022]    Loss: 0.006989   Batch Acc: 84.38
[Train] Epoch: 3 [268352/620022]    Loss: 0.007174   Batch Acc: 87.50
[Train] Epoch: 3 [268416/620022]    Loss: 0.006816   Batch Acc: 84.38
[Train] Epoch: 3 [268480/620022]    Loss: 0.008365   Batch Acc: 71.88
[Train] Epoch: 3 [268544/620022]    Loss: 0.007790   Batch Acc: 84.38
[Train] Epoch: 3 [268608/620022]    Loss: 0.009086   Batch Acc: 81.25
[Train] Epoch: 3 [268672/620022]    Loss: 0.009026   Batch Acc: 78.12
[Train] Epoch: 3 [268736/620022]    Loss: 0.009041   Batch Acc: 76.56
[Train] Epoch: 3 [268800/620022]    Loss: 0.006613   Batch Acc: 85.94
[Train] Epoch: 3 [268864/620022]    Loss: 0.008702   Batch Acc: 82.81
[Train] Epoch: 3 [268928/620022]    Loss: 0.009977   Batch Acc: 78.12
[Train] Epoch: 3 [268992/620022]    Loss: 0.007971   Batch Acc: 79.69
[Train] Epoch: 3 [269056/620022]    Loss: 0.007464   Batch Acc: 84.38
[Train] Epoch: 3 [269120/620022]    Loss: 0.008879   Batch Acc: 76.56
[Train] Epoch: 3 [269184/620022]    Loss: 0.009136   Batch Acc: 75.00
[Train] Epoch: 3 [269248/620022]    Loss: 0.008818   Batch Acc: 79.69
[Train] Epoch: 3 [269312/620022]    Loss: 0.007488   Batch Acc: 84.38
[Train] Epoch: 3 [269376/620022]    Loss: 0.009361   Batch Acc: 71.88
[Train] Epoch: 3 [269440/620022]    Loss: 0.007758   Batch Acc: 87.50
[Train] Epoch: 3 [269504/620022]    Loss: 0.007748   Batch Acc: 78.12
[Train] Epoch: 3 [269568/620022]    Loss: 0.008392   Batch Acc: 82.81
[Train] Epoch: 3 [269632/620022]    Loss: 0.007871   Batch Acc: 76.56
[Train] Epoch: 3 [269696/620022]    Loss: 0.010855   Batch Acc: 76.56
[Train] Epoch: 3 [269760/620022]    Loss: 0.008757   Batch Acc: 71.88
[Train] Epoch: 3 [269824/620022]    Loss: 0.007836   Batch Acc: 81.25
[Train] Epoch: 3 [269888/620022]    Loss: 0.009658   Batch Acc: 70.31
[Train] Epoch: 3 [269952/620022]    Loss: 0.008211   Batch Acc: 78.12
[Train] Epoch: 3 [270016/620022]    Loss: 0.011203   Batch Acc: 73.44
[Train] Epoch: 3 [270080/620022]    Loss: 0.008201   Batch Acc: 75.00
[Train] Epoch: 3 [270144/620022]    Loss: 0.005560   Batch Acc: 92.19
[Train] Epoch: 3 [270208/620022]    Loss: 0.009165   Batch Acc: 81.25
[Train] Epoch: 3 [270272/620022]    Loss: 0.010526   Batch Acc: 70.31
[Train] Epoch: 3 [270336/620022]    Loss: 0.008864   Batch Acc: 82.81
[Train] Epoch: 3 [270400/620022]    Loss: 0.010188   Batch Acc: 70.31
[Train] Epoch: 3 [270464/620022]    Loss: 0.007956   Batch Acc: 78.12
[Train] Epoch: 3 [270528/620022]    Loss: 0.008388   Batch Acc: 81.25
[Train] Epoch: 3 [270592/620022]    Loss: 0.009073   Batch Acc: 75.00
[Train] Epoch: 3 [270656/620022]    Loss: 0.009685   Batch Acc: 71.88
[Train] Epoch: 3 [270720/620022]    Loss: 0.007697   Batch Acc: 79.69
[Train] Epoch: 3 [270784/620022]    Loss: 0.008237   Batch Acc: 76.56
[Train] Epoch: 3 [270848/620022]    Loss: 0.010246   Batch Acc: 71.88
[Train] Epoch: 3 [270912/620022]    Loss: 0.011349   Batch Acc: 70.31
[Train] Epoch: 3 [270976/620022]    Loss: 0.011334   Batch Acc: 71.88
[Train] Epoch: 3 [271040/620022]    Loss: 0.007912   Batch Acc: 79.69
[Train] Epoch: 3 [271104/620022]    Loss: 0.008213   Batch Acc: 79.69
[Train] Epoch: 3 [271168/620022]    Loss: 0.007508   Batch Acc: 84.38
[Train] Epoch: 3 [271232/620022]    Loss: 0.006800   Batch Acc: 82.81
[Train] Epoch: 3 [271296/620022]    Loss: 0.008065   Batch Acc: 78.12
[Train] Epoch: 3 [271360/620022]    Loss: 0.009107   Batch Acc: 76.56
[Train] Epoch: 3 [271424/620022]    Loss: 0.010061   Batch Acc: 76.56
[Train] Epoch: 3 [271488/620022]    Loss: 0.008136   Batch Acc: 78.12
[Train] Epoch: 3 [271552/620022]    Loss: 0.007342   Batch Acc: 81.25
[Train] Epoch: 3 [271616/620022]    Loss: 0.009523   Batch Acc: 82.81
[Train] Epoch: 3 [271680/620022]    Loss: 0.008796   Batch Acc: 76.56
[Train] Epoch: 3 [271744/620022]    Loss: 0.008665   Batch Acc: 81.25
[Train] Epoch: 3 [271808/620022]    Loss: 0.008143   Batch Acc: 78.12
[Train] Epoch: 3 [271872/620022]    Loss: 0.009752   Batch Acc: 76.56
[Train] Epoch: 3 [271936/620022]    Loss: 0.010835   Batch Acc: 73.44
[Train] Epoch: 3 [272000/620022]    Loss: 0.011515   Batch Acc: 64.06
[Train] Epoch: 3 [272064/620022]    Loss: 0.005723   Batch Acc: 89.06
[Train] Epoch: 3 [272128/620022]    Loss: 0.007005   Batch Acc: 84.38
[Train] Epoch: 3 [272192/620022]    Loss: 0.008187   Batch Acc: 78.12
[Train] Epoch: 3 [272256/620022]    Loss: 0.010718   Batch Acc: 75.00
[Train] Epoch: 3 [272320/620022]    Loss: 0.009906   Batch Acc: 68.75
[Train] Epoch: 3 [272384/620022]    Loss: 0.007229   Batch Acc: 78.12
[Train] Epoch: 3 [272448/620022]    Loss: 0.010593   Batch Acc: 76.56
[Train] Epoch: 3 [272512/620022]    Loss: 0.007554   Batch Acc: 81.25
[Train] Epoch: 3 [272576/620022]    Loss: 0.005754   Batch Acc: 85.94
[Train] Epoch: 3 [272640/620022]    Loss: 0.008967   Batch Acc: 79.69
[Train] Epoch: 3 [272704/620022]    Loss: 0.011174   Batch Acc: 75.00
[Train] Epoch: 3 [272768/620022]    Loss: 0.007834   Batch Acc: 82.81
[Train] Epoch: 3 [272832/620022]    Loss: 0.007450   Batch Acc: 81.25
[Train] Epoch: 3 [272896/620022]    Loss: 0.010792   Batch Acc: 73.44
[Train] Epoch: 3 [272960/620022]    Loss: 0.007325   Batch Acc: 89.06
[Train] Epoch: 3 [273024/620022]    Loss: 0.006462   Batch Acc: 84.38
[Train] Epoch: 3 [273088/620022]    Loss: 0.006242   Batch Acc: 89.06
[Train] Epoch: 3 [273152/620022]    Loss: 0.010307   Batch Acc: 68.75
[Train] Epoch: 3 [273216/620022]    Loss: 0.010231   Batch Acc: 71.88
[Train] Epoch: 3 [273280/620022]    Loss: 0.008777   Batch Acc: 82.81
[Train] Epoch: 3 [273344/620022]    Loss: 0.007557   Batch Acc: 81.25
[Train] Epoch: 3 [273408/620022]    Loss: 0.008804   Batch Acc: 73.44
[Train] Epoch: 3 [273472/620022]    Loss: 0.011161   Batch Acc: 73.44
[Train] Epoch: 3 [273536/620022]    Loss: 0.007547   Batch Acc: 82.81
[Train] Epoch: 3 [273600/620022]    Loss: 0.008166   Batch Acc: 78.12
[Train] Epoch: 3 [273664/620022]    Loss: 0.009276   Batch Acc: 78.12
[Train] Epoch: 3 [273728/620022]    Loss: 0.008381   Batch Acc: 78.12
[Train] Epoch: 3 [273792/620022]    Loss: 0.010749   Batch Acc: 68.75
[Train] Epoch: 3 [273856/620022]    Loss: 0.008600   Batch Acc: 76.56
[Train] Epoch: 3 [273920/620022]    Loss: 0.007783   Batch Acc: 73.44
[Train] Epoch: 3 [273984/620022]    Loss: 0.008605   Batch Acc: 76.56
[Train] Epoch: 3 [274048/620022]    Loss: 0.006501   Batch Acc: 85.94
[Train] Epoch: 3 [274112/620022]    Loss: 0.008095   Batch Acc: 78.12
[Train] Epoch: 3 [274176/620022]    Loss: 0.006638   Batch Acc: 84.38
[Train] Epoch: 3 [274240/620022]    Loss: 0.006423   Batch Acc: 87.50
[Train] Epoch: 3 [274304/620022]    Loss: 0.007502   Batch Acc: 79.69
[Train] Epoch: 3 [274368/620022]    Loss: 0.007827   Batch Acc: 84.38
[Train] Epoch: 3 [274432/620022]    Loss: 0.007444   Batch Acc: 76.56
[Train] Epoch: 3 [274496/620022]    Loss: 0.007879   Batch Acc: 76.56
[Train] Epoch: 3 [274560/620022]    Loss: 0.007638   Batch Acc: 78.12
[Train] Epoch: 3 [274624/620022]    Loss: 0.007335   Batch Acc: 85.94
[Train] Epoch: 3 [274688/620022]    Loss: 0.007599   Batch Acc: 81.25
[Train] Epoch: 3 [274752/620022]    Loss: 0.008087   Batch Acc: 78.12
[Train] Epoch: 3 [274816/620022]    Loss: 0.008597   Batch Acc: 79.69
[Train] Epoch: 3 [274880/620022]    Loss: 0.007946   Batch Acc: 84.38
[Train] Epoch: 3 [274944/620022]    Loss: 0.009541   Batch Acc: 71.88
[Train] Epoch: 3 [275008/620022]    Loss: 0.010179   Batch Acc: 68.75
[Train] Epoch: 3 [275072/620022]    Loss: 0.008991   Batch Acc: 73.44
[Train] Epoch: 3 [275136/620022]    Loss: 0.009452   Batch Acc: 76.56
[Train] Epoch: 3 [275200/620022]    Loss: 0.011618   Batch Acc: 67.19
[Train] Epoch: 3 [275264/620022]    Loss: 0.007546   Batch Acc: 82.81
[Train] Epoch: 3 [275328/620022]    Loss: 0.008155   Batch Acc: 85.94
[Train] Epoch: 3 [275392/620022]    Loss: 0.008382   Batch Acc: 76.56
[Train] Epoch: 3 [275456/620022]    Loss: 0.008418   Batch Acc: 81.25
[Train] Epoch: 3 [275520/620022]    Loss: 0.011189   Batch Acc: 70.31
[Train] Epoch: 3 [275584/620022]    Loss: 0.010650   Batch Acc: 70.31
[Train] Epoch: 3 [275648/620022]    Loss: 0.008324   Batch Acc: 76.56
[Train] Epoch: 3 [275712/620022]    Loss: 0.010111   Batch Acc: 73.44
[Train] Epoch: 3 [275776/620022]    Loss: 0.007035   Batch Acc: 82.81
[Train] Epoch: 3 [275840/620022]    Loss: 0.009133   Batch Acc: 73.44
[Train] Epoch: 3 [275904/620022]    Loss: 0.008231   Batch Acc: 79.69
[Train] Epoch: 3 [275968/620022]    Loss: 0.008053   Batch Acc: 79.69
[Train] Epoch: 3 [276032/620022]    Loss: 0.008332   Batch Acc: 79.69
[Train] Epoch: 3 [276096/620022]    Loss: 0.007044   Batch Acc: 82.81
[Train] Epoch: 3 [276160/620022]    Loss: 0.007984   Batch Acc: 78.12
[Train] Epoch: 3 [276224/620022]    Loss: 0.007267   Batch Acc: 82.81
[Train] Epoch: 3 [276288/620022]    Loss: 0.009273   Batch Acc: 71.88
[Train] Epoch: 3 [276352/620022]    Loss: 0.008966   Batch Acc: 73.44
[Train] Epoch: 3 [276416/620022]    Loss: 0.008018   Batch Acc: 76.56
[Train] Epoch: 3 [276480/620022]    Loss: 0.008698   Batch Acc: 76.56
[Train] Epoch: 3 [276544/620022]    Loss: 0.008663   Batch Acc: 75.00
[Train] Epoch: 3 [276608/620022]    Loss: 0.007159   Batch Acc: 85.94
[Train] Epoch: 3 [276672/620022]    Loss: 0.008377   Batch Acc: 79.69
[Train] Epoch: 3 [276736/620022]    Loss: 0.006401   Batch Acc: 79.69
[Train] Epoch: 3 [276800/620022]    Loss: 0.007665   Batch Acc: 79.69
[Train] Epoch: 3 [276864/620022]    Loss: 0.008762   Batch Acc: 78.12
[Train] Epoch: 3 [276928/620022]    Loss: 0.009098   Batch Acc: 76.56
[Train] Epoch: 3 [276992/620022]    Loss: 0.006738   Batch Acc: 85.94
[Train] Epoch: 3 [277056/620022]    Loss: 0.007458   Batch Acc: 85.94
[Train] Epoch: 3 [277120/620022]    Loss: 0.007832   Batch Acc: 81.25
[Train] Epoch: 3 [277184/620022]    Loss: 0.008823   Batch Acc: 75.00
[Train] Epoch: 3 [277248/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 3 [277312/620022]    Loss: 0.008863   Batch Acc: 84.38
[Train] Epoch: 3 [277376/620022]    Loss: 0.009358   Batch Acc: 73.44
[Train] Epoch: 3 [277440/620022]    Loss: 0.009898   Batch Acc: 76.56
[Train] Epoch: 3 [277504/620022]    Loss: 0.009632   Batch Acc: 75.00
[Train] Epoch: 3 [277568/620022]    Loss: 0.009366   Batch Acc: 84.38
[Train] Epoch: 3 [277632/620022]    Loss: 0.010583   Batch Acc: 71.88
[Train] Epoch: 3 [277696/620022]    Loss: 0.006774   Batch Acc: 90.62
[Train] Epoch: 3 [277760/620022]    Loss: 0.007730   Batch Acc: 79.69
[Train] Epoch: 3 [277824/620022]    Loss: 0.008747   Batch Acc: 85.94
[Train] Epoch: 3 [277888/620022]    Loss: 0.009729   Batch Acc: 70.31
[Train] Epoch: 3 [277952/620022]    Loss: 0.009073   Batch Acc: 71.88
[Train] Epoch: 3 [278016/620022]    Loss: 0.009798   Batch Acc: 71.88
[Train] Epoch: 3 [278080/620022]    Loss: 0.006965   Batch Acc: 82.81
[Train] Epoch: 3 [278144/620022]    Loss: 0.007301   Batch Acc: 79.69
[Train] Epoch: 3 [278208/620022]    Loss: 0.008525   Batch Acc: 75.00
[Train] Epoch: 3 [278272/620022]    Loss: 0.007183   Batch Acc: 81.25
[Train] Epoch: 3 [278336/620022]    Loss: 0.007055   Batch Acc: 84.38
[Train] Epoch: 3 [278400/620022]    Loss: 0.007328   Batch Acc: 84.38
[Train] Epoch: 3 [278464/620022]    Loss: 0.006518   Batch Acc: 87.50
[Train] Epoch: 3 [278528/620022]    Loss: 0.007362   Batch Acc: 85.94
[Train] Epoch: 3 [278592/620022]    Loss: 0.011137   Batch Acc: 65.62
[Train] Epoch: 3 [278656/620022]    Loss: 0.008455   Batch Acc: 81.25
[Train] Epoch: 3 [278720/620022]    Loss: 0.009640   Batch Acc: 76.56
[Train] Epoch: 3 [278784/620022]    Loss: 0.008571   Batch Acc: 79.69
[Train] Epoch: 3 [278848/620022]    Loss: 0.007793   Batch Acc: 84.38
[Train] Epoch: 3 [278912/620022]    Loss: 0.008521   Batch Acc: 81.25
[Train] Epoch: 3 [278976/620022]    Loss: 0.006969   Batch Acc: 84.38
[Train] Epoch: 3 [279040/620022]    Loss: 0.006503   Batch Acc: 82.81
[Train] Epoch: 3 [279104/620022]    Loss: 0.007166   Batch Acc: 84.38
[Train] Epoch: 3 [279168/620022]    Loss: 0.007966   Batch Acc: 82.81
[Train] Epoch: 3 [279232/620022]    Loss: 0.007830   Batch Acc: 75.00
[Train] Epoch: 3 [279296/620022]    Loss: 0.010538   Batch Acc: 68.75
[Train] Epoch: 3 [279360/620022]    Loss: 0.008640   Batch Acc: 78.12
[Train] Epoch: 3 [279424/620022]    Loss: 0.007409   Batch Acc: 82.81
[Train] Epoch: 3 [279488/620022]    Loss: 0.010486   Batch Acc: 75.00
[Train] Epoch: 3 [279552/620022]    Loss: 0.009304   Batch Acc: 73.44
[Train] Epoch: 3 [279616/620022]    Loss: 0.010224   Batch Acc: 75.00
[Train] Epoch: 3 [279680/620022]    Loss: 0.008629   Batch Acc: 75.00
[Train] Epoch: 3 [279744/620022]    Loss: 0.009449   Batch Acc: 76.56
[Train] Epoch: 3 [279808/620022]    Loss: 0.009824   Batch Acc: 73.44
[Train] Epoch: 3 [279872/620022]    Loss: 0.009490   Batch Acc: 75.00
[Train] Epoch: 3 [279936/620022]    Loss: 0.011114   Batch Acc: 73.44
[Train] Epoch: 3 [280000/620022]    Loss: 0.005895   Batch Acc: 89.06
[Train] Epoch: 3 [280064/620022]    Loss: 0.007444   Batch Acc: 79.69
[Train] Epoch: 3 [280128/620022]    Loss: 0.006780   Batch Acc: 85.94
[Train] Epoch: 3 [280192/620022]    Loss: 0.007489   Batch Acc: 84.38
[Train] Epoch: 3 [280256/620022]    Loss: 0.009672   Batch Acc: 68.75
[Train] Epoch: 3 [280320/620022]    Loss: 0.009846   Batch Acc: 75.00
[Train] Epoch: 3 [280384/620022]    Loss: 0.008859   Batch Acc: 78.12
[Train] Epoch: 3 [280448/620022]    Loss: 0.009260   Batch Acc: 75.00
[Train] Epoch: 3 [280512/620022]    Loss: 0.010971   Batch Acc: 70.31
[Train] Epoch: 3 [280576/620022]    Loss: 0.008594   Batch Acc: 79.69
[Train] Epoch: 3 [280640/620022]    Loss: 0.006052   Batch Acc: 90.62
[Train] Epoch: 3 [280704/620022]    Loss: 0.009948   Batch Acc: 65.62
[Train] Epoch: 3 [280768/620022]    Loss: 0.010100   Batch Acc: 70.31
[Train] Epoch: 3 [280832/620022]    Loss: 0.009445   Batch Acc: 79.69
[Train] Epoch: 3 [280896/620022]    Loss: 0.008380   Batch Acc: 82.81
[Train] Epoch: 3 [280960/620022]    Loss: 0.007451   Batch Acc: 85.94
[Train] Epoch: 3 [281024/620022]    Loss: 0.008085   Batch Acc: 76.56
[Train] Epoch: 3 [281088/620022]    Loss: 0.007519   Batch Acc: 79.69
[Train] Epoch: 3 [281152/620022]    Loss: 0.007844   Batch Acc: 78.12
[Train] Epoch: 3 [281216/620022]    Loss: 0.010232   Batch Acc: 59.38
[Train] Epoch: 3 [281280/620022]    Loss: 0.009970   Batch Acc: 70.31
[Train] Epoch: 3 [281344/620022]    Loss: 0.007633   Batch Acc: 82.81
[Train] Epoch: 3 [281408/620022]    Loss: 0.010503   Batch Acc: 71.88
[Train] Epoch: 3 [281472/620022]    Loss: 0.010583   Batch Acc: 75.00
[Train] Epoch: 3 [281536/620022]    Loss: 0.007788   Batch Acc: 82.81
[Train] Epoch: 3 [281600/620022]    Loss: 0.007635   Batch Acc: 79.69
[Train] Epoch: 3 [281664/620022]    Loss: 0.009551   Batch Acc: 68.75
[Train] Epoch: 3 [281728/620022]    Loss: 0.008352   Batch Acc: 76.56
[Train] Epoch: 3 [281792/620022]    Loss: 0.010892   Batch Acc: 70.31
[Train] Epoch: 3 [281856/620022]    Loss: 0.007862   Batch Acc: 79.69
[Train] Epoch: 3 [281920/620022]    Loss: 0.008703   Batch Acc: 76.56
[Train] Epoch: 3 [281984/620022]    Loss: 0.009110   Batch Acc: 76.56
[Train] Epoch: 3 [282048/620022]    Loss: 0.008797   Batch Acc: 75.00
[Train] Epoch: 3 [282112/620022]    Loss: 0.006432   Batch Acc: 84.38
[Train] Epoch: 3 [282176/620022]    Loss: 0.008890   Batch Acc: 76.56
[Train] Epoch: 3 [282240/620022]    Loss: 0.008746   Batch Acc: 75.00
[Train] Epoch: 3 [282304/620022]    Loss: 0.007728   Batch Acc: 81.25
[Train] Epoch: 3 [282368/620022]    Loss: 0.008725   Batch Acc: 75.00
[Train] Epoch: 3 [282432/620022]    Loss: 0.008086   Batch Acc: 81.25
[Train] Epoch: 3 [282496/620022]    Loss: 0.009650   Batch Acc: 73.44
[Train] Epoch: 3 [282560/620022]    Loss: 0.007882   Batch Acc: 78.12
[Train] Epoch: 3 [282624/620022]    Loss: 0.007130   Batch Acc: 81.25
[Train] Epoch: 3 [282688/620022]    Loss: 0.006987   Batch Acc: 82.81
[Train] Epoch: 3 [282752/620022]    Loss: 0.007692   Batch Acc: 75.00
[Train] Epoch: 3 [282816/620022]    Loss: 0.009053   Batch Acc: 78.12
[Train] Epoch: 3 [282880/620022]    Loss: 0.009794   Batch Acc: 70.31
[Train] Epoch: 3 [282944/620022]    Loss: 0.007792   Batch Acc: 85.94
[Train] Epoch: 3 [283008/620022]    Loss: 0.008712   Batch Acc: 78.12
[Train] Epoch: 3 [283072/620022]    Loss: 0.007716   Batch Acc: 79.69
[Train] Epoch: 3 [283136/620022]    Loss: 0.009800   Batch Acc: 71.88
[Train] Epoch: 3 [283200/620022]    Loss: 0.009381   Batch Acc: 71.88
[Train] Epoch: 3 [283264/620022]    Loss: 0.009476   Batch Acc: 81.25
[Train] Epoch: 3 [283328/620022]    Loss: 0.008961   Batch Acc: 78.12
[Train] Epoch: 3 [283392/620022]    Loss: 0.007144   Batch Acc: 76.56
[Train] Epoch: 3 [283456/620022]    Loss: 0.008470   Batch Acc: 81.25
[Train] Epoch: 3 [283520/620022]    Loss: 0.008613   Batch Acc: 81.25
[Train] Epoch: 3 [283584/620022]    Loss: 0.008667   Batch Acc: 78.12
[Train] Epoch: 3 [283648/620022]    Loss: 0.009310   Batch Acc: 73.44
[Train] Epoch: 3 [283712/620022]    Loss: 0.009486   Batch Acc: 75.00
[Train] Epoch: 3 [283776/620022]    Loss: 0.006756   Batch Acc: 82.81
[Train] Epoch: 3 [283840/620022]    Loss: 0.008724   Batch Acc: 76.56
[Train] Epoch: 3 [283904/620022]    Loss: 0.008507   Batch Acc: 76.56
[Train] Epoch: 3 [283968/620022]    Loss: 0.006836   Batch Acc: 84.38
[Train] Epoch: 3 [284032/620022]    Loss: 0.008506   Batch Acc: 75.00
[Train] Epoch: 3 [284096/620022]    Loss: 0.008832   Batch Acc: 79.69
[Train] Epoch: 3 [284160/620022]    Loss: 0.009390   Batch Acc: 78.12
[Train] Epoch: 3 [284224/620022]    Loss: 0.008782   Batch Acc: 81.25
[Train] Epoch: 3 [284288/620022]    Loss: 0.006663   Batch Acc: 82.81
[Train] Epoch: 3 [284352/620022]    Loss: 0.007288   Batch Acc: 84.38
[Train] Epoch: 3 [284416/620022]    Loss: 0.008075   Batch Acc: 73.44
[Train] Epoch: 3 [284480/620022]    Loss: 0.006925   Batch Acc: 85.94
[Train] Epoch: 3 [284544/620022]    Loss: 0.010659   Batch Acc: 75.00
[Train] Epoch: 3 [284608/620022]    Loss: 0.007232   Batch Acc: 79.69
[Train] Epoch: 3 [284672/620022]    Loss: 0.007048   Batch Acc: 82.81
[Train] Epoch: 3 [284736/620022]    Loss: 0.009405   Batch Acc: 75.00
[Train] Epoch: 3 [284800/620022]    Loss: 0.008618   Batch Acc: 81.25
[Train] Epoch: 3 [284864/620022]    Loss: 0.007357   Batch Acc: 82.81
[Train] Epoch: 3 [284928/620022]    Loss: 0.007419   Batch Acc: 84.38
[Train] Epoch: 3 [284992/620022]    Loss: 0.008185   Batch Acc: 81.25
[Train] Epoch: 3 [285056/620022]    Loss: 0.008657   Batch Acc: 73.44
[Train] Epoch: 3 [285120/620022]    Loss: 0.008198   Batch Acc: 79.69
[Train] Epoch: 3 [285184/620022]    Loss: 0.007924   Batch Acc: 82.81
[Train] Epoch: 3 [285248/620022]    Loss: 0.009644   Batch Acc: 71.88
[Train] Epoch: 3 [285312/620022]    Loss: 0.010149   Batch Acc: 75.00
[Train] Epoch: 3 [285376/620022]    Loss: 0.006713   Batch Acc: 85.94
[Train] Epoch: 3 [285440/620022]    Loss: 0.010938   Batch Acc: 70.31
[Train] Epoch: 3 [285504/620022]    Loss: 0.010089   Batch Acc: 76.56
[Train] Epoch: 3 [285568/620022]    Loss: 0.010931   Batch Acc: 68.75
[Train] Epoch: 3 [285632/620022]    Loss: 0.008623   Batch Acc: 75.00
[Train] Epoch: 3 [285696/620022]    Loss: 0.008911   Batch Acc: 73.44
[Train] Epoch: 3 [285760/620022]    Loss: 0.008971   Batch Acc: 76.56
[Train] Epoch: 3 [285824/620022]    Loss: 0.011414   Batch Acc: 70.31
[Train] Epoch: 3 [285888/620022]    Loss: 0.008647   Batch Acc: 78.12
[Train] Epoch: 3 [285952/620022]    Loss: 0.009908   Batch Acc: 76.56
[Train] Epoch: 3 [286016/620022]    Loss: 0.008636   Batch Acc: 81.25
[Train] Epoch: 3 [286080/620022]    Loss: 0.007379   Batch Acc: 81.25
[Train] Epoch: 3 [286144/620022]    Loss: 0.007068   Batch Acc: 84.38
[Train] Epoch: 3 [286208/620022]    Loss: 0.010829   Batch Acc: 76.56
[Train] Epoch: 3 [286272/620022]    Loss: 0.010257   Batch Acc: 71.88
[Train] Epoch: 3 [286336/620022]    Loss: 0.010730   Batch Acc: 71.88
[Train] Epoch: 3 [286400/620022]    Loss: 0.008236   Batch Acc: 79.69
[Train] Epoch: 3 [286464/620022]    Loss: 0.007220   Batch Acc: 84.38
[Train] Epoch: 3 [286528/620022]    Loss: 0.006702   Batch Acc: 82.81
[Train] Epoch: 3 [286592/620022]    Loss: 0.009516   Batch Acc: 75.00
[Train] Epoch: 3 [286656/620022]    Loss: 0.008597   Batch Acc: 73.44
[Train] Epoch: 3 [286720/620022]    Loss: 0.010014   Batch Acc: 75.00
[Train] Epoch: 3 [286784/620022]    Loss: 0.010216   Batch Acc: 78.12
[Train] Epoch: 3 [286848/620022]    Loss: 0.006588   Batch Acc: 84.38
[Train] Epoch: 3 [286912/620022]    Loss: 0.010550   Batch Acc: 67.19
[Train] Epoch: 3 [286976/620022]    Loss: 0.006452   Batch Acc: 89.06
[Train] Epoch: 3 [287040/620022]    Loss: 0.006998   Batch Acc: 87.50
[Train] Epoch: 3 [287104/620022]    Loss: 0.010215   Batch Acc: 71.88
[Train] Epoch: 3 [287168/620022]    Loss: 0.009607   Batch Acc: 79.69
[Train] Epoch: 3 [287232/620022]    Loss: 0.011295   Batch Acc: 65.62
[Train] Epoch: 3 [287296/620022]    Loss: 0.009576   Batch Acc: 79.69
[Train] Epoch: 3 [287360/620022]    Loss: 0.007686   Batch Acc: 79.69
[Train] Epoch: 3 [287424/620022]    Loss: 0.006407   Batch Acc: 82.81
[Train] Epoch: 3 [287488/620022]    Loss: 0.009379   Batch Acc: 75.00
[Train] Epoch: 3 [287552/620022]    Loss: 0.009028   Batch Acc: 73.44
[Train] Epoch: 3 [287616/620022]    Loss: 0.007932   Batch Acc: 82.81
[Train] Epoch: 3 [287680/620022]    Loss: 0.009568   Batch Acc: 75.00
[Train] Epoch: 3 [287744/620022]    Loss: 0.009479   Batch Acc: 78.12
[Train] Epoch: 3 [287808/620022]    Loss: 0.006690   Batch Acc: 85.94
[Train] Epoch: 3 [287872/620022]    Loss: 0.006237   Batch Acc: 84.38
[Train] Epoch: 3 [287936/620022]    Loss: 0.009014   Batch Acc: 75.00
[Train] Epoch: 3 [288000/620022]    Loss: 0.005760   Batch Acc: 84.38
[Train] Epoch: 3 [288064/620022]    Loss: 0.008262   Batch Acc: 75.00
[Train] Epoch: 3 [288128/620022]    Loss: 0.007403   Batch Acc: 78.12
[Train] Epoch: 3 [288192/620022]    Loss: 0.008892   Batch Acc: 78.12
[Train] Epoch: 3 [288256/620022]    Loss: 0.009345   Batch Acc: 70.31
[Train] Epoch: 3 [288320/620022]    Loss: 0.008000   Batch Acc: 81.25
[Train] Epoch: 3 [288384/620022]    Loss: 0.006313   Batch Acc: 84.38
[Train] Epoch: 3 [288448/620022]    Loss: 0.009612   Batch Acc: 76.56
[Train] Epoch: 3 [288512/620022]    Loss: 0.008297   Batch Acc: 73.44
[Train] Epoch: 3 [288576/620022]    Loss: 0.008442   Batch Acc: 81.25
[Train] Epoch: 3 [288640/620022]    Loss: 0.007416   Batch Acc: 89.06
[Train] Epoch: 3 [288704/620022]    Loss: 0.006835   Batch Acc: 87.50
[Train] Epoch: 3 [288768/620022]    Loss: 0.009656   Batch Acc: 73.44
[Train] Epoch: 3 [288832/620022]    Loss: 0.008223   Batch Acc: 81.25
[Train] Epoch: 3 [288896/620022]    Loss: 0.009256   Batch Acc: 70.31
[Train] Epoch: 3 [288960/620022]    Loss: 0.012199   Batch Acc: 71.88
[Train] Epoch: 3 [289024/620022]    Loss: 0.007363   Batch Acc: 85.94
[Train] Epoch: 3 [289088/620022]    Loss: 0.008402   Batch Acc: 76.56
[Train] Epoch: 3 [289152/620022]    Loss: 0.010688   Batch Acc: 75.00
[Train] Epoch: 3 [289216/620022]    Loss: 0.007326   Batch Acc: 84.38
[Train] Epoch: 3 [289280/620022]    Loss: 0.009781   Batch Acc: 70.31
[Train] Epoch: 3 [289344/620022]    Loss: 0.007556   Batch Acc: 78.12
[Train] Epoch: 3 [289408/620022]    Loss: 0.007196   Batch Acc: 82.81
[Train] Epoch: 3 [289472/620022]    Loss: 0.008476   Batch Acc: 79.69
[Train] Epoch: 3 [289536/620022]    Loss: 0.008475   Batch Acc: 84.38
[Train] Epoch: 3 [289600/620022]    Loss: 0.010456   Batch Acc: 70.31
[Train] Epoch: 3 [289664/620022]    Loss: 0.009978   Batch Acc: 71.88
[Train] Epoch: 3 [289728/620022]    Loss: 0.008788   Batch Acc: 75.00
[Train] Epoch: 3 [289792/620022]    Loss: 0.009468   Batch Acc: 76.56
[Train] Epoch: 3 [289856/620022]    Loss: 0.008916   Batch Acc: 79.69
[Train] Epoch: 3 [289920/620022]    Loss: 0.007028   Batch Acc: 84.38
[Train] Epoch: 3 [289984/620022]    Loss: 0.007827   Batch Acc: 82.81
[Train] Epoch: 3 [290048/620022]    Loss: 0.011899   Batch Acc: 67.19
[Train] Epoch: 3 [290112/620022]    Loss: 0.009532   Batch Acc: 75.00
[Train] Epoch: 3 [290176/620022]    Loss: 0.008024   Batch Acc: 78.12
[Train] Epoch: 3 [290240/620022]    Loss: 0.009761   Batch Acc: 68.75
[Train] Epoch: 3 [290304/620022]    Loss: 0.011077   Batch Acc: 68.75
[Train] Epoch: 3 [290368/620022]    Loss: 0.007327   Batch Acc: 85.94
[Train] Epoch: 3 [290432/620022]    Loss: 0.008320   Batch Acc: 73.44
[Train] Epoch: 3 [290496/620022]    Loss: 0.008901   Batch Acc: 75.00
[Train] Epoch: 3 [290560/620022]    Loss: 0.009419   Batch Acc: 79.69
[Train] Epoch: 3 [290624/620022]    Loss: 0.008860   Batch Acc: 81.25
[Train] Epoch: 3 [290688/620022]    Loss: 0.006083   Batch Acc: 89.06
[Train] Epoch: 3 [290752/620022]    Loss: 0.008232   Batch Acc: 84.38
[Train] Epoch: 3 [290816/620022]    Loss: 0.007951   Batch Acc: 79.69
[Train] Epoch: 3 [290880/620022]    Loss: 0.008726   Batch Acc: 75.00
[Train] Epoch: 3 [290944/620022]    Loss: 0.008541   Batch Acc: 75.00
[Train] Epoch: 3 [291008/620022]    Loss: 0.009892   Batch Acc: 76.56
[Train] Epoch: 3 [291072/620022]    Loss: 0.008587   Batch Acc: 82.81
[Train] Epoch: 3 [291136/620022]    Loss: 0.009070   Batch Acc: 81.25
[Train] Epoch: 3 [291200/620022]    Loss: 0.009720   Batch Acc: 79.69
[Train] Epoch: 3 [291264/620022]    Loss: 0.006345   Batch Acc: 85.94
[Train] Epoch: 3 [291328/620022]    Loss: 0.009586   Batch Acc: 76.56
[Train] Epoch: 3 [291392/620022]    Loss: 0.009373   Batch Acc: 78.12
[Train] Epoch: 3 [291456/620022]    Loss: 0.012074   Batch Acc: 65.62
[Train] Epoch: 3 [291520/620022]    Loss: 0.007454   Batch Acc: 82.81
[Train] Epoch: 3 [291584/620022]    Loss: 0.006784   Batch Acc: 82.81
[Train] Epoch: 3 [291648/620022]    Loss: 0.009404   Batch Acc: 75.00
[Train] Epoch: 3 [291712/620022]    Loss: 0.009129   Batch Acc: 75.00
[Train] Epoch: 3 [291776/620022]    Loss: 0.009249   Batch Acc: 76.56
[Train] Epoch: 3 [291840/620022]    Loss: 0.010985   Batch Acc: 68.75
[Train] Epoch: 3 [291904/620022]    Loss: 0.011468   Batch Acc: 65.62
[Train] Epoch: 3 [291968/620022]    Loss: 0.010765   Batch Acc: 67.19
[Train] Epoch: 3 [292032/620022]    Loss: 0.007248   Batch Acc: 84.38
[Train] Epoch: 3 [292096/620022]    Loss: 0.008391   Batch Acc: 79.69
[Train] Epoch: 3 [292160/620022]    Loss: 0.008936   Batch Acc: 71.88
[Train] Epoch: 3 [292224/620022]    Loss: 0.009022   Batch Acc: 75.00
[Train] Epoch: 3 [292288/620022]    Loss: 0.008767   Batch Acc: 76.56
[Train] Epoch: 3 [292352/620022]    Loss: 0.006539   Batch Acc: 79.69
[Train] Epoch: 3 [292416/620022]    Loss: 0.010214   Batch Acc: 67.19
[Train] Epoch: 3 [292480/620022]    Loss: 0.009731   Batch Acc: 76.56
[Train] Epoch: 3 [292544/620022]    Loss: 0.009728   Batch Acc: 68.75
[Train] Epoch: 3 [292608/620022]    Loss: 0.007337   Batch Acc: 82.81
[Train] Epoch: 3 [292672/620022]    Loss: 0.012047   Batch Acc: 71.88
[Train] Epoch: 3 [292736/620022]    Loss: 0.008550   Batch Acc: 79.69
[Train] Epoch: 3 [292800/620022]    Loss: 0.007261   Batch Acc: 85.94
[Train] Epoch: 3 [292864/620022]    Loss: 0.009060   Batch Acc: 76.56
[Train] Epoch: 3 [292928/620022]    Loss: 0.008051   Batch Acc: 85.94
[Train] Epoch: 3 [292992/620022]    Loss: 0.006337   Batch Acc: 89.06
[Train] Epoch: 3 [293056/620022]    Loss: 0.007336   Batch Acc: 78.12
[Train] Epoch: 3 [293120/620022]    Loss: 0.007241   Batch Acc: 79.69
[Train] Epoch: 3 [293184/620022]    Loss: 0.008430   Batch Acc: 79.69
[Train] Epoch: 3 [293248/620022]    Loss: 0.010211   Batch Acc: 71.88
[Train] Epoch: 3 [293312/620022]    Loss: 0.010558   Batch Acc: 67.19
[Train] Epoch: 3 [293376/620022]    Loss: 0.007539   Batch Acc: 78.12
[Train] Epoch: 3 [293440/620022]    Loss: 0.009547   Batch Acc: 73.44
[Train] Epoch: 3 [293504/620022]    Loss: 0.007919   Batch Acc: 84.38
[Train] Epoch: 3 [293568/620022]    Loss: 0.008208   Batch Acc: 73.44
[Train] Epoch: 3 [293632/620022]    Loss: 0.008252   Batch Acc: 75.00
[Train] Epoch: 3 [293696/620022]    Loss: 0.006321   Batch Acc: 82.81
[Train] Epoch: 3 [293760/620022]    Loss: 0.010675   Batch Acc: 71.88
[Train] Epoch: 3 [293824/620022]    Loss: 0.007899   Batch Acc: 82.81
[Train] Epoch: 3 [293888/620022]    Loss: 0.009039   Batch Acc: 75.00
[Train] Epoch: 3 [293952/620022]    Loss: 0.006211   Batch Acc: 90.62
[Train] Epoch: 3 [294016/620022]    Loss: 0.009424   Batch Acc: 78.12
[Train] Epoch: 3 [294080/620022]    Loss: 0.008018   Batch Acc: 78.12
[Train] Epoch: 3 [294144/620022]    Loss: 0.010320   Batch Acc: 71.88
[Train] Epoch: 3 [294208/620022]    Loss: 0.009294   Batch Acc: 71.88
[Train] Epoch: 3 [294272/620022]    Loss: 0.008850   Batch Acc: 78.12
[Train] Epoch: 3 [294336/620022]    Loss: 0.009001   Batch Acc: 75.00
[Train] Epoch: 3 [294400/620022]    Loss: 0.009671   Batch Acc: 73.44
[Train] Epoch: 3 [294464/620022]    Loss: 0.008497   Batch Acc: 78.12
[Train] Epoch: 3 [294528/620022]    Loss: 0.007152   Batch Acc: 79.69
[Train] Epoch: 3 [294592/620022]    Loss: 0.005828   Batch Acc: 85.94
[Train] Epoch: 3 [294656/620022]    Loss: 0.011587   Batch Acc: 73.44
[Train] Epoch: 3 [294720/620022]    Loss: 0.008354   Batch Acc: 76.56
[Train] Epoch: 3 [294784/620022]    Loss: 0.008294   Batch Acc: 81.25
[Train] Epoch: 3 [294848/620022]    Loss: 0.007985   Batch Acc: 78.12
[Train] Epoch: 3 [294912/620022]    Loss: 0.008647   Batch Acc: 78.12
[Train] Epoch: 3 [294976/620022]    Loss: 0.008574   Batch Acc: 75.00
[Train] Epoch: 3 [295040/620022]    Loss: 0.007954   Batch Acc: 87.50
[Train] Epoch: 3 [295104/620022]    Loss: 0.007918   Batch Acc: 82.81
[Train] Epoch: 3 [295168/620022]    Loss: 0.009944   Batch Acc: 76.56
[Train] Epoch: 3 [295232/620022]    Loss: 0.010052   Batch Acc: 76.56
[Train] Epoch: 3 [295296/620022]    Loss: 0.006720   Batch Acc: 84.38
[Train] Epoch: 3 [295360/620022]    Loss: 0.008950   Batch Acc: 71.88
[Train] Epoch: 3 [295424/620022]    Loss: 0.008988   Batch Acc: 75.00
[Train] Epoch: 3 [295488/620022]    Loss: 0.007612   Batch Acc: 85.94
[Train] Epoch: 3 [295552/620022]    Loss: 0.009471   Batch Acc: 73.44
[Train] Epoch: 3 [295616/620022]    Loss: 0.007404   Batch Acc: 78.12
[Train] Epoch: 3 [295680/620022]    Loss: 0.010418   Batch Acc: 78.12
[Train] Epoch: 3 [295744/620022]    Loss: 0.009006   Batch Acc: 73.44
[Train] Epoch: 3 [295808/620022]    Loss: 0.007891   Batch Acc: 82.81
[Train] Epoch: 3 [295872/620022]    Loss: 0.007154   Batch Acc: 87.50
[Train] Epoch: 3 [295936/620022]    Loss: 0.006001   Batch Acc: 87.50
[Train] Epoch: 3 [296000/620022]    Loss: 0.008253   Batch Acc: 81.25
[Train] Epoch: 3 [296064/620022]    Loss: 0.009129   Batch Acc: 75.00
[Train] Epoch: 3 [296128/620022]    Loss: 0.007866   Batch Acc: 84.38
[Train] Epoch: 3 [296192/620022]    Loss: 0.010031   Batch Acc: 78.12
[Train] Epoch: 3 [296256/620022]    Loss: 0.007736   Batch Acc: 84.38
[Train] Epoch: 3 [296320/620022]    Loss: 0.009497   Batch Acc: 75.00
[Train] Epoch: 3 [296384/620022]    Loss: 0.005678   Batch Acc: 87.50
[Train] Epoch: 3 [296448/620022]    Loss: 0.010595   Batch Acc: 78.12
[Train] Epoch: 3 [296512/620022]    Loss: 0.007648   Batch Acc: 82.81
[Train] Epoch: 3 [296576/620022]    Loss: 0.009529   Batch Acc: 76.56
[Train] Epoch: 3 [296640/620022]    Loss: 0.008553   Batch Acc: 78.12
[Train] Epoch: 3 [296704/620022]    Loss: 0.009216   Batch Acc: 68.75
[Train] Epoch: 3 [296768/620022]    Loss: 0.011230   Batch Acc: 71.88
[Train] Epoch: 3 [296832/620022]    Loss: 0.007624   Batch Acc: 81.25
[Train] Epoch: 3 [296896/620022]    Loss: 0.009483   Batch Acc: 76.56
[Train] Epoch: 3 [296960/620022]    Loss: 0.007509   Batch Acc: 85.94
[Train] Epoch: 3 [297024/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 3 [297088/620022]    Loss: 0.012079   Batch Acc: 65.62
[Train] Epoch: 3 [297152/620022]    Loss: 0.009777   Batch Acc: 75.00
[Train] Epoch: 3 [297216/620022]    Loss: 0.009667   Batch Acc: 73.44
[Train] Epoch: 3 [297280/620022]    Loss: 0.009735   Batch Acc: 73.44
[Train] Epoch: 3 [297344/620022]    Loss: 0.009847   Batch Acc: 75.00
[Train] Epoch: 3 [297408/620022]    Loss: 0.007047   Batch Acc: 87.50
[Train] Epoch: 3 [297472/620022]    Loss: 0.009059   Batch Acc: 79.69
[Train] Epoch: 3 [297536/620022]    Loss: 0.010418   Batch Acc: 73.44
[Train] Epoch: 3 [297600/620022]    Loss: 0.008922   Batch Acc: 78.12
[Train] Epoch: 3 [297664/620022]    Loss: 0.008694   Batch Acc: 81.25
[Train] Epoch: 3 [297728/620022]    Loss: 0.010781   Batch Acc: 75.00
[Train] Epoch: 3 [297792/620022]    Loss: 0.009005   Batch Acc: 79.69
[Train] Epoch: 3 [297856/620022]    Loss: 0.007731   Batch Acc: 76.56
[Train] Epoch: 3 [297920/620022]    Loss: 0.008624   Batch Acc: 84.38
[Train] Epoch: 3 [297984/620022]    Loss: 0.007357   Batch Acc: 81.25
[Train] Epoch: 3 [298048/620022]    Loss: 0.007060   Batch Acc: 82.81
[Train] Epoch: 3 [298112/620022]    Loss: 0.009576   Batch Acc: 71.88
[Train] Epoch: 3 [298176/620022]    Loss: 0.009799   Batch Acc: 75.00
[Train] Epoch: 3 [298240/620022]    Loss: 0.009215   Batch Acc: 76.56
[Train] Epoch: 3 [298304/620022]    Loss: 0.009293   Batch Acc: 78.12
[Train] Epoch: 3 [298368/620022]    Loss: 0.007350   Batch Acc: 79.69
[Train] Epoch: 3 [298432/620022]    Loss: 0.007710   Batch Acc: 78.12
[Train] Epoch: 3 [298496/620022]    Loss: 0.010642   Batch Acc: 70.31
[Train] Epoch: 3 [298560/620022]    Loss: 0.010122   Batch Acc: 68.75
[Train] Epoch: 3 [298624/620022]    Loss: 0.008064   Batch Acc: 81.25
[Train] Epoch: 3 [298688/620022]    Loss: 0.007431   Batch Acc: 84.38
[Train] Epoch: 3 [298752/620022]    Loss: 0.006734   Batch Acc: 84.38
[Train] Epoch: 3 [298816/620022]    Loss: 0.008682   Batch Acc: 81.25
[Train] Epoch: 3 [298880/620022]    Loss: 0.006793   Batch Acc: 82.81
[Train] Epoch: 3 [298944/620022]    Loss: 0.006524   Batch Acc: 87.50
[Train] Epoch: 3 [299008/620022]    Loss: 0.009504   Batch Acc: 76.56
[Train] Epoch: 3 [299072/620022]    Loss: 0.009116   Batch Acc: 78.12
[Train] Epoch: 3 [299136/620022]    Loss: 0.008671   Batch Acc: 76.56
[Train] Epoch: 3 [299200/620022]    Loss: 0.008172   Batch Acc: 81.25
[Train] Epoch: 3 [299264/620022]    Loss: 0.008837   Batch Acc: 79.69
[Train] Epoch: 3 [299328/620022]    Loss: 0.010400   Batch Acc: 68.75
[Train] Epoch: 3 [299392/620022]    Loss: 0.008193   Batch Acc: 78.12
[Train] Epoch: 3 [299456/620022]    Loss: 0.010556   Batch Acc: 78.12
[Train] Epoch: 3 [299520/620022]    Loss: 0.010264   Batch Acc: 70.31
[Train] Epoch: 3 [299584/620022]    Loss: 0.007446   Batch Acc: 79.69
[Train] Epoch: 3 [299648/620022]    Loss: 0.007699   Batch Acc: 84.38
[Train] Epoch: 3 [299712/620022]    Loss: 0.008490   Batch Acc: 75.00
[Train] Epoch: 3 [299776/620022]    Loss: 0.007850   Batch Acc: 78.12
[Train] Epoch: 3 [299840/620022]    Loss: 0.007063   Batch Acc: 82.81
[Train] Epoch: 3 [299904/620022]    Loss: 0.008741   Batch Acc: 71.88
[Train] Epoch: 3 [299968/620022]    Loss: 0.006746   Batch Acc: 81.25
[Train] Epoch: 3 [300032/620022]    Loss: 0.009480   Batch Acc: 73.44
[Train] Epoch: 3 [300096/620022]    Loss: 0.008798   Batch Acc: 78.12
[Train] Epoch: 3 [300160/620022]    Loss: 0.009191   Batch Acc: 78.12
[Train] Epoch: 3 [300224/620022]    Loss: 0.008166   Batch Acc: 79.69
[Train] Epoch: 3 [300288/620022]    Loss: 0.009179   Batch Acc: 73.44
[Train] Epoch: 3 [300352/620022]    Loss: 0.008971   Batch Acc: 82.81
[Train] Epoch: 3 [300416/620022]    Loss: 0.007900   Batch Acc: 82.81
[Train] Epoch: 3 [300480/620022]    Loss: 0.008722   Batch Acc: 75.00
[Train] Epoch: 3 [300544/620022]    Loss: 0.010534   Batch Acc: 73.44
[Train] Epoch: 3 [300608/620022]    Loss: 0.007753   Batch Acc: 76.56
[Train] Epoch: 3 [300672/620022]    Loss: 0.009845   Batch Acc: 76.56
[Train] Epoch: 3 [300736/620022]    Loss: 0.009491   Batch Acc: 81.25
[Train] Epoch: 3 [300800/620022]    Loss: 0.007506   Batch Acc: 82.81
[Train] Epoch: 3 [300864/620022]    Loss: 0.008925   Batch Acc: 76.56
[Train] Epoch: 3 [300928/620022]    Loss: 0.009928   Batch Acc: 76.56
[Train] Epoch: 3 [300992/620022]    Loss: 0.010114   Batch Acc: 70.31
[Train] Epoch: 3 [301056/620022]    Loss: 0.006660   Batch Acc: 87.50
[Train] Epoch: 3 [301120/620022]    Loss: 0.008394   Batch Acc: 78.12
[Train] Epoch: 3 [301184/620022]    Loss: 0.007633   Batch Acc: 82.81
[Train] Epoch: 3 [301248/620022]    Loss: 0.006108   Batch Acc: 90.62
[Train] Epoch: 3 [301312/620022]    Loss: 0.009407   Batch Acc: 81.25
[Train] Epoch: 3 [301376/620022]    Loss: 0.009783   Batch Acc: 75.00
[Train] Epoch: 3 [301440/620022]    Loss: 0.006970   Batch Acc: 79.69
[Train] Epoch: 3 [301504/620022]    Loss: 0.008609   Batch Acc: 82.81
[Train] Epoch: 3 [301568/620022]    Loss: 0.007618   Batch Acc: 82.81
[Train] Epoch: 3 [301632/620022]    Loss: 0.008025   Batch Acc: 79.69
[Train] Epoch: 3 [301696/620022]    Loss: 0.008826   Batch Acc: 73.44
[Train] Epoch: 3 [301760/620022]    Loss: 0.008715   Batch Acc: 82.81
[Train] Epoch: 3 [301824/620022]    Loss: 0.009625   Batch Acc: 79.69
[Train] Epoch: 3 [301888/620022]    Loss: 0.006897   Batch Acc: 84.38
[Train] Epoch: 3 [301952/620022]    Loss: 0.011516   Batch Acc: 71.88
[Train] Epoch: 3 [302016/620022]    Loss: 0.010528   Batch Acc: 68.75
[Train] Epoch: 3 [302080/620022]    Loss: 0.008336   Batch Acc: 79.69
[Train] Epoch: 3 [302144/620022]    Loss: 0.008660   Batch Acc: 79.69
[Train] Epoch: 3 [302208/620022]    Loss: 0.007206   Batch Acc: 84.38
[Train] Epoch: 3 [302272/620022]    Loss: 0.008511   Batch Acc: 82.81
[Train] Epoch: 3 [302336/620022]    Loss: 0.011752   Batch Acc: 68.75
[Train] Epoch: 3 [302400/620022]    Loss: 0.006575   Batch Acc: 76.56
[Train] Epoch: 3 [302464/620022]    Loss: 0.008934   Batch Acc: 73.44
[Train] Epoch: 3 [302528/620022]    Loss: 0.007408   Batch Acc: 84.38
[Train] Epoch: 3 [302592/620022]    Loss: 0.008689   Batch Acc: 78.12
[Train] Epoch: 3 [302656/620022]    Loss: 0.006017   Batch Acc: 89.06
[Train] Epoch: 3 [302720/620022]    Loss: 0.008399   Batch Acc: 78.12
[Train] Epoch: 3 [302784/620022]    Loss: 0.008635   Batch Acc: 76.56
[Train] Epoch: 3 [302848/620022]    Loss: 0.007829   Batch Acc: 79.69
[Train] Epoch: 3 [302912/620022]    Loss: 0.008750   Batch Acc: 85.94
[Train] Epoch: 3 [302976/620022]    Loss: 0.007099   Batch Acc: 79.69
[Train] Epoch: 3 [303040/620022]    Loss: 0.009820   Batch Acc: 68.75
[Train] Epoch: 3 [303104/620022]    Loss: 0.008589   Batch Acc: 79.69
[Train] Epoch: 3 [303168/620022]    Loss: 0.009510   Batch Acc: 65.62
[Train] Epoch: 3 [303232/620022]    Loss: 0.010741   Batch Acc: 67.19
[Train] Epoch: 3 [303296/620022]    Loss: 0.009622   Batch Acc: 73.44
[Train] Epoch: 3 [303360/620022]    Loss: 0.007911   Batch Acc: 84.38
[Train] Epoch: 3 [303424/620022]    Loss: 0.007431   Batch Acc: 81.25
[Train] Epoch: 3 [303488/620022]    Loss: 0.010436   Batch Acc: 76.56
[Train] Epoch: 3 [303552/620022]    Loss: 0.006767   Batch Acc: 84.38
[Train] Epoch: 3 [303616/620022]    Loss: 0.009222   Batch Acc: 75.00
[Train] Epoch: 3 [303680/620022]    Loss: 0.006639   Batch Acc: 82.81
[Train] Epoch: 3 [303744/620022]    Loss: 0.008601   Batch Acc: 76.56
[Train] Epoch: 3 [303808/620022]    Loss: 0.007072   Batch Acc: 89.06
[Train] Epoch: 3 [303872/620022]    Loss: 0.008848   Batch Acc: 79.69
[Train] Epoch: 3 [303936/620022]    Loss: 0.007856   Batch Acc: 78.12
[Train] Epoch: 3 [304000/620022]    Loss: 0.007617   Batch Acc: 84.38
[Train] Epoch: 3 [304064/620022]    Loss: 0.008445   Batch Acc: 71.88
[Train] Epoch: 3 [304128/620022]    Loss: 0.007565   Batch Acc: 75.00
[Train] Epoch: 3 [304192/620022]    Loss: 0.010131   Batch Acc: 73.44
[Train] Epoch: 3 [304256/620022]    Loss: 0.007262   Batch Acc: 79.69
[Train] Epoch: 3 [304320/620022]    Loss: 0.006740   Batch Acc: 82.81
[Train] Epoch: 3 [304384/620022]    Loss: 0.010827   Batch Acc: 67.19
[Train] Epoch: 3 [304448/620022]    Loss: 0.006376   Batch Acc: 87.50
[Train] Epoch: 3 [304512/620022]    Loss: 0.006522   Batch Acc: 79.69
[Train] Epoch: 3 [304576/620022]    Loss: 0.009649   Batch Acc: 75.00
[Train] Epoch: 3 [304640/620022]    Loss: 0.008404   Batch Acc: 73.44
[Train] Epoch: 3 [304704/620022]    Loss: 0.008780   Batch Acc: 76.56
[Train] Epoch: 3 [304768/620022]    Loss: 0.009290   Batch Acc: 75.00
[Train] Epoch: 3 [304832/620022]    Loss: 0.009926   Batch Acc: 73.44
[Train] Epoch: 3 [304896/620022]    Loss: 0.010921   Batch Acc: 75.00
[Train] Epoch: 3 [304960/620022]    Loss: 0.007376   Batch Acc: 82.81
[Train] Epoch: 3 [305024/620022]    Loss: 0.008898   Batch Acc: 81.25
[Train] Epoch: 3 [305088/620022]    Loss: 0.008127   Batch Acc: 76.56
[Train] Epoch: 3 [305152/620022]    Loss: 0.008471   Batch Acc: 76.56
[Train] Epoch: 3 [305216/620022]    Loss: 0.007093   Batch Acc: 85.94
[Train] Epoch: 3 [305280/620022]    Loss: 0.011252   Batch Acc: 67.19
[Train] Epoch: 3 [305344/620022]    Loss: 0.009402   Batch Acc: 78.12
[Train] Epoch: 3 [305408/620022]    Loss: 0.011055   Batch Acc: 78.12
[Train] Epoch: 3 [305472/620022]    Loss: 0.009792   Batch Acc: 81.25
[Train] Epoch: 3 [305536/620022]    Loss: 0.011367   Batch Acc: 67.19
[Train] Epoch: 3 [305600/620022]    Loss: 0.010501   Batch Acc: 73.44
[Train] Epoch: 3 [305664/620022]    Loss: 0.008884   Batch Acc: 75.00
[Train] Epoch: 3 [305728/620022]    Loss: 0.010201   Batch Acc: 75.00
[Train] Epoch: 3 [305792/620022]    Loss: 0.009527   Batch Acc: 73.44
[Train] Epoch: 3 [305856/620022]    Loss: 0.008105   Batch Acc: 82.81
[Train] Epoch: 3 [305920/620022]    Loss: 0.009472   Batch Acc: 75.00
[Train] Epoch: 3 [305984/620022]    Loss: 0.009994   Batch Acc: 71.88
[Train] Epoch: 3 [306048/620022]    Loss: 0.009564   Batch Acc: 84.38
[Train] Epoch: 3 [306112/620022]    Loss: 0.007814   Batch Acc: 76.56
[Train] Epoch: 3 [306176/620022]    Loss: 0.008213   Batch Acc: 78.12
[Train] Epoch: 3 [306240/620022]    Loss: 0.007668   Batch Acc: 81.25
[Train] Epoch: 3 [306304/620022]    Loss: 0.008145   Batch Acc: 75.00
[Train] Epoch: 3 [306368/620022]    Loss: 0.010477   Batch Acc: 65.62
[Train] Epoch: 3 [306432/620022]    Loss: 0.008345   Batch Acc: 76.56
[Train] Epoch: 3 [306496/620022]    Loss: 0.008435   Batch Acc: 79.69
[Train] Epoch: 3 [306560/620022]    Loss: 0.009072   Batch Acc: 73.44
[Train] Epoch: 3 [306624/620022]    Loss: 0.008318   Batch Acc: 81.25
[Train] Epoch: 3 [306688/620022]    Loss: 0.007751   Batch Acc: 82.81
[Train] Epoch: 3 [306752/620022]    Loss: 0.008177   Batch Acc: 76.56
[Train] Epoch: 3 [306816/620022]    Loss: 0.009002   Batch Acc: 76.56
[Train] Epoch: 3 [306880/620022]    Loss: 0.008970   Batch Acc: 71.88
[Train] Epoch: 3 [306944/620022]    Loss: 0.009996   Batch Acc: 71.88
[Train] Epoch: 3 [307008/620022]    Loss: 0.007194   Batch Acc: 85.94
[Train] Epoch: 3 [307072/620022]    Loss: 0.009854   Batch Acc: 68.75
[Train] Epoch: 3 [307136/620022]    Loss: 0.008683   Batch Acc: 71.88
[Train] Epoch: 3 [307200/620022]    Loss: 0.009534   Batch Acc: 76.56
[Train] Epoch: 3 [307264/620022]    Loss: 0.009093   Batch Acc: 78.12
[Train] Epoch: 3 [307328/620022]    Loss: 0.008475   Batch Acc: 81.25
[Train] Epoch: 3 [307392/620022]    Loss: 0.008205   Batch Acc: 79.69
[Train] Epoch: 3 [307456/620022]    Loss: 0.008708   Batch Acc: 76.56
[Train] Epoch: 3 [307520/620022]    Loss: 0.009136   Batch Acc: 73.44
[Train] Epoch: 3 [307584/620022]    Loss: 0.007938   Batch Acc: 76.56
[Train] Epoch: 3 [307648/620022]    Loss: 0.008442   Batch Acc: 78.12
[Train] Epoch: 3 [307712/620022]    Loss: 0.009114   Batch Acc: 73.44
[Train] Epoch: 3 [307776/620022]    Loss: 0.008133   Batch Acc: 79.69
[Train] Epoch: 3 [307840/620022]    Loss: 0.008717   Batch Acc: 81.25
[Train] Epoch: 3 [307904/620022]    Loss: 0.008355   Batch Acc: 82.81
[Train] Epoch: 3 [307968/620022]    Loss: 0.007591   Batch Acc: 82.81
[Train] Epoch: 3 [308032/620022]    Loss: 0.008829   Batch Acc: 81.25
[Train] Epoch: 3 [308096/620022]    Loss: 0.007733   Batch Acc: 78.12
[Train] Epoch: 3 [308160/620022]    Loss: 0.009738   Batch Acc: 68.75
[Train] Epoch: 3 [308224/620022]    Loss: 0.008199   Batch Acc: 75.00
[Train] Epoch: 3 [308288/620022]    Loss: 0.008638   Batch Acc: 76.56
[Train] Epoch: 3 [308352/620022]    Loss: 0.009704   Batch Acc: 71.88
[Train] Epoch: 3 [308416/620022]    Loss: 0.010327   Batch Acc: 76.56
[Train] Epoch: 3 [308480/620022]    Loss: 0.010305   Batch Acc: 68.75
[Train] Epoch: 3 [308544/620022]    Loss: 0.010109   Batch Acc: 70.31
[Train] Epoch: 3 [308608/620022]    Loss: 0.009480   Batch Acc: 73.44
[Train] Epoch: 3 [308672/620022]    Loss: 0.007220   Batch Acc: 82.81
[Train] Epoch: 3 [308736/620022]    Loss: 0.006401   Batch Acc: 84.38
[Train] Epoch: 3 [308800/620022]    Loss: 0.009969   Batch Acc: 71.88
[Train] Epoch: 3 [308864/620022]    Loss: 0.010222   Batch Acc: 62.50
[Train] Epoch: 3 [308928/620022]    Loss: 0.008343   Batch Acc: 82.81
[Train] Epoch: 3 [308992/620022]    Loss: 0.007927   Batch Acc: 81.25
[Train] Epoch: 3 [309056/620022]    Loss: 0.006814   Batch Acc: 84.38
[Train] Epoch: 3 [309120/620022]    Loss: 0.009038   Batch Acc: 70.31
[Train] Epoch: 3 [309184/620022]    Loss: 0.008787   Batch Acc: 76.56
[Train] Epoch: 3 [309248/620022]    Loss: 0.011815   Batch Acc: 68.75
[Train] Epoch: 3 [309312/620022]    Loss: 0.009146   Batch Acc: 78.12
[Train] Epoch: 3 [309376/620022]    Loss: 0.008758   Batch Acc: 84.38
[Train] Epoch: 3 [309440/620022]    Loss: 0.009588   Batch Acc: 78.12
[Train] Epoch: 3 [309504/620022]    Loss: 0.007925   Batch Acc: 81.25
[Train] Epoch: 3 [309568/620022]    Loss: 0.008837   Batch Acc: 78.12
[Train] Epoch: 3 [309632/620022]    Loss: 0.011359   Batch Acc: 70.31
[Train] Epoch: 3 [309696/620022]    Loss: 0.006734   Batch Acc: 89.06
[Train] Epoch: 3 [309760/620022]    Loss: 0.008343   Batch Acc: 75.00
[Train] Epoch: 3 [309824/620022]    Loss: 0.009555   Batch Acc: 73.44
[Train] Epoch: 3 [309888/620022]    Loss: 0.007962   Batch Acc: 81.25
[Train] Epoch: 3 [309952/620022]    Loss: 0.010040   Batch Acc: 65.62
[Train] Epoch: 3 [310016/620022]    Loss: 0.008161   Batch Acc: 79.69
[Train] Epoch: 3 [310080/620022]    Loss: 0.008282   Batch Acc: 75.00
[Train] Epoch: 3 [310144/620022]    Loss: 0.008948   Batch Acc: 76.56
[Train] Epoch: 3 [310208/620022]    Loss: 0.008013   Batch Acc: 84.38
[Train] Epoch: 3 [310272/620022]    Loss: 0.009992   Batch Acc: 73.44
[Train] Epoch: 3 [310336/620022]    Loss: 0.007872   Batch Acc: 81.25
[Train] Epoch: 3 [310400/620022]    Loss: 0.007765   Batch Acc: 76.56
[Train] Epoch: 3 [310464/620022]    Loss: 0.006680   Batch Acc: 82.81
[Train] Epoch: 3 [310528/620022]    Loss: 0.009036   Batch Acc: 75.00
[Train] Epoch: 3 [310592/620022]    Loss: 0.006074   Batch Acc: 87.50
[Train] Epoch: 3 [310656/620022]    Loss: 0.012167   Batch Acc: 68.75
[Train] Epoch: 3 [310720/620022]    Loss: 0.006129   Batch Acc: 89.06
[Train] Epoch: 3 [310784/620022]    Loss: 0.009742   Batch Acc: 75.00
[Train] Epoch: 3 [310848/620022]    Loss: 0.009472   Batch Acc: 81.25
[Train] Epoch: 3 [310912/620022]    Loss: 0.007495   Batch Acc: 82.81
[Train] Epoch: 3 [310976/620022]    Loss: 0.009684   Batch Acc: 75.00
[Train] Epoch: 3 [311040/620022]    Loss: 0.009219   Batch Acc: 78.12
[Train] Epoch: 3 [311104/620022]    Loss: 0.006824   Batch Acc: 78.12
[Train] Epoch: 3 [311168/620022]    Loss: 0.007164   Batch Acc: 84.38
[Train] Epoch: 3 [311232/620022]    Loss: 0.008669   Batch Acc: 70.31
[Train] Epoch: 3 [311296/620022]    Loss: 0.008875   Batch Acc: 75.00
[Train] Epoch: 3 [311360/620022]    Loss: 0.008972   Batch Acc: 75.00
[Train] Epoch: 3 [311424/620022]    Loss: 0.007424   Batch Acc: 85.94
[Train] Epoch: 3 [311488/620022]    Loss: 0.011187   Batch Acc: 70.31
[Train] Epoch: 3 [311552/620022]    Loss: 0.010567   Batch Acc: 71.88
[Train] Epoch: 3 [311616/620022]    Loss: 0.008185   Batch Acc: 82.81
[Train] Epoch: 3 [311680/620022]    Loss: 0.007797   Batch Acc: 76.56
[Train] Epoch: 3 [311744/620022]    Loss: 0.010480   Batch Acc: 71.88
[Train] Epoch: 3 [311808/620022]    Loss: 0.006756   Batch Acc: 84.38
[Train] Epoch: 3 [311872/620022]    Loss: 0.010693   Batch Acc: 76.56
[Train] Epoch: 3 [311936/620022]    Loss: 0.007881   Batch Acc: 81.25
[Train] Epoch: 3 [312000/620022]    Loss: 0.010882   Batch Acc: 71.88
[Train] Epoch: 3 [312064/620022]    Loss: 0.009856   Batch Acc: 70.31
[Train] Epoch: 3 [312128/620022]    Loss: 0.006684   Batch Acc: 81.25
[Train] Epoch: 3 [312192/620022]    Loss: 0.009609   Batch Acc: 75.00
[Train] Epoch: 3 [312256/620022]    Loss: 0.007463   Batch Acc: 79.69
[Train] Epoch: 3 [312320/620022]    Loss: 0.009411   Batch Acc: 73.44
[Train] Epoch: 3 [312384/620022]    Loss: 0.006750   Batch Acc: 85.94
[Train] Epoch: 3 [312448/620022]    Loss: 0.009803   Batch Acc: 78.12
[Train] Epoch: 3 [312512/620022]    Loss: 0.007490   Batch Acc: 82.81
[Train] Epoch: 3 [312576/620022]    Loss: 0.007982   Batch Acc: 81.25
[Train] Epoch: 3 [312640/620022]    Loss: 0.011699   Batch Acc: 65.62
[Train] Epoch: 3 [312704/620022]    Loss: 0.010430   Batch Acc: 75.00
[Train] Epoch: 3 [312768/620022]    Loss: 0.008226   Batch Acc: 78.12
[Train] Epoch: 3 [312832/620022]    Loss: 0.009277   Batch Acc: 78.12
[Train] Epoch: 3 [312896/620022]    Loss: 0.008568   Batch Acc: 79.69
[Train] Epoch: 3 [312960/620022]    Loss: 0.007305   Batch Acc: 79.69
[Train] Epoch: 3 [313024/620022]    Loss: 0.009781   Batch Acc: 70.31
[Train] Epoch: 3 [313088/620022]    Loss: 0.007374   Batch Acc: 78.12
[Train] Epoch: 3 [313152/620022]    Loss: 0.009739   Batch Acc: 70.31
[Train] Epoch: 3 [313216/620022]    Loss: 0.009897   Batch Acc: 73.44
[Train] Epoch: 3 [313280/620022]    Loss: 0.009619   Batch Acc: 76.56
[Train] Epoch: 3 [313344/620022]    Loss: 0.008616   Batch Acc: 84.38
[Train] Epoch: 3 [313408/620022]    Loss: 0.006808   Batch Acc: 82.81
[Train] Epoch: 3 [313472/620022]    Loss: 0.006252   Batch Acc: 89.06
[Train] Epoch: 3 [313536/620022]    Loss: 0.010021   Batch Acc: 73.44
[Train] Epoch: 3 [313600/620022]    Loss: 0.009998   Batch Acc: 82.81
[Train] Epoch: 3 [313664/620022]    Loss: 0.007797   Batch Acc: 82.81
[Train] Epoch: 3 [313728/620022]    Loss: 0.010035   Batch Acc: 67.19
[Train] Epoch: 3 [313792/620022]    Loss: 0.008840   Batch Acc: 70.31
[Train] Epoch: 3 [313856/620022]    Loss: 0.010262   Batch Acc: 73.44
[Train] Epoch: 3 [313920/620022]    Loss: 0.007581   Batch Acc: 81.25
[Train] Epoch: 3 [313984/620022]    Loss: 0.006925   Batch Acc: 82.81
[Train] Epoch: 3 [314048/620022]    Loss: 0.008826   Batch Acc: 78.12
[Train] Epoch: 3 [314112/620022]    Loss: 0.008740   Batch Acc: 73.44
[Train] Epoch: 3 [314176/620022]    Loss: 0.006922   Batch Acc: 82.81
[Train] Epoch: 3 [314240/620022]    Loss: 0.009200   Batch Acc: 76.56
[Train] Epoch: 3 [314304/620022]    Loss: 0.008964   Batch Acc: 70.31
[Train] Epoch: 3 [314368/620022]    Loss: 0.007285   Batch Acc: 81.25
[Train] Epoch: 3 [314432/620022]    Loss: 0.007105   Batch Acc: 84.38
[Train] Epoch: 3 [314496/620022]    Loss: 0.009664   Batch Acc: 78.12
[Train] Epoch: 3 [314560/620022]    Loss: 0.009131   Batch Acc: 81.25
[Train] Epoch: 3 [314624/620022]    Loss: 0.006380   Batch Acc: 81.25
[Train] Epoch: 3 [314688/620022]    Loss: 0.008854   Batch Acc: 79.69
[Train] Epoch: 3 [314752/620022]    Loss: 0.008159   Batch Acc: 79.69
[Train] Epoch: 3 [314816/620022]    Loss: 0.008918   Batch Acc: 75.00
[Train] Epoch: 3 [314880/620022]    Loss: 0.009102   Batch Acc: 78.12
[Train] Epoch: 3 [314944/620022]    Loss: 0.006846   Batch Acc: 76.56
[Train] Epoch: 3 [315008/620022]    Loss: 0.007179   Batch Acc: 84.38
[Train] Epoch: 3 [315072/620022]    Loss: 0.007065   Batch Acc: 81.25
[Train] Epoch: 3 [315136/620022]    Loss: 0.006558   Batch Acc: 84.38
[Train] Epoch: 3 [315200/620022]    Loss: 0.010247   Batch Acc: 73.44
[Train] Epoch: 3 [315264/620022]    Loss: 0.008142   Batch Acc: 76.56
[Train] Epoch: 3 [315328/620022]    Loss: 0.007422   Batch Acc: 78.12
[Train] Epoch: 3 [315392/620022]    Loss: 0.008766   Batch Acc: 73.44
[Train] Epoch: 3 [315456/620022]    Loss: 0.010149   Batch Acc: 75.00
[Train] Epoch: 3 [315520/620022]    Loss: 0.007627   Batch Acc: 81.25
[Train] Epoch: 3 [315584/620022]    Loss: 0.007939   Batch Acc: 81.25
[Train] Epoch: 3 [315648/620022]    Loss: 0.007271   Batch Acc: 81.25
[Train] Epoch: 3 [315712/620022]    Loss: 0.009007   Batch Acc: 75.00
[Train] Epoch: 3 [315776/620022]    Loss: 0.007363   Batch Acc: 84.38
[Train] Epoch: 3 [315840/620022]    Loss: 0.010267   Batch Acc: 73.44
[Train] Epoch: 3 [315904/620022]    Loss: 0.007773   Batch Acc: 76.56
[Train] Epoch: 3 [315968/620022]    Loss: 0.007776   Batch Acc: 78.12
[Train] Epoch: 3 [316032/620022]    Loss: 0.006474   Batch Acc: 87.50
[Train] Epoch: 3 [316096/620022]    Loss: 0.006889   Batch Acc: 85.94
[Train] Epoch: 3 [316160/620022]    Loss: 0.008144   Batch Acc: 79.69
[Train] Epoch: 3 [316224/620022]    Loss: 0.007374   Batch Acc: 85.94
[Train] Epoch: 3 [316288/620022]    Loss: 0.008500   Batch Acc: 79.69
[Train] Epoch: 3 [316352/620022]    Loss: 0.009456   Batch Acc: 78.12
[Train] Epoch: 3 [316416/620022]    Loss: 0.011519   Batch Acc: 68.75
[Train] Epoch: 3 [316480/620022]    Loss: 0.008543   Batch Acc: 79.69
[Train] Epoch: 3 [316544/620022]    Loss: 0.009790   Batch Acc: 75.00
[Train] Epoch: 3 [316608/620022]    Loss: 0.009759   Batch Acc: 71.88
[Train] Epoch: 3 [316672/620022]    Loss: 0.007198   Batch Acc: 84.38
[Train] Epoch: 3 [316736/620022]    Loss: 0.009810   Batch Acc: 81.25
[Train] Epoch: 3 [316800/620022]    Loss: 0.010054   Batch Acc: 73.44
[Train] Epoch: 3 [316864/620022]    Loss: 0.010491   Batch Acc: 73.44
[Train] Epoch: 3 [316928/620022]    Loss: 0.006690   Batch Acc: 84.38
[Train] Epoch: 3 [316992/620022]    Loss: 0.008950   Batch Acc: 79.69
[Train] Epoch: 3 [317056/620022]    Loss: 0.006401   Batch Acc: 84.38
[Train] Epoch: 3 [317120/620022]    Loss: 0.008729   Batch Acc: 75.00
[Train] Epoch: 3 [317184/620022]    Loss: 0.008387   Batch Acc: 78.12
[Train] Epoch: 3 [317248/620022]    Loss: 0.008357   Batch Acc: 79.69
[Train] Epoch: 3 [317312/620022]    Loss: 0.007741   Batch Acc: 82.81
[Train] Epoch: 3 [317376/620022]    Loss: 0.009056   Batch Acc: 71.88
[Train] Epoch: 3 [317440/620022]    Loss: 0.009835   Batch Acc: 76.56
[Train] Epoch: 3 [317504/620022]    Loss: 0.007005   Batch Acc: 85.94
[Train] Epoch: 3 [317568/620022]    Loss: 0.007661   Batch Acc: 78.12
[Train] Epoch: 3 [317632/620022]    Loss: 0.008590   Batch Acc: 79.69
[Train] Epoch: 3 [317696/620022]    Loss: 0.007663   Batch Acc: 84.38
[Train] Epoch: 3 [317760/620022]    Loss: 0.010134   Batch Acc: 71.88
[Train] Epoch: 3 [317824/620022]    Loss: 0.005932   Batch Acc: 87.50
[Train] Epoch: 3 [317888/620022]    Loss: 0.005489   Batch Acc: 92.19
[Train] Epoch: 3 [317952/620022]    Loss: 0.007706   Batch Acc: 84.38
[Train] Epoch: 3 [318016/620022]    Loss: 0.008884   Batch Acc: 75.00
[Train] Epoch: 3 [318080/620022]    Loss: 0.010010   Batch Acc: 73.44
[Train] Epoch: 3 [318144/620022]    Loss: 0.008660   Batch Acc: 81.25
[Train] Epoch: 3 [318208/620022]    Loss: 0.007341   Batch Acc: 79.69
[Train] Epoch: 3 [318272/620022]    Loss: 0.009809   Batch Acc: 75.00
[Train] Epoch: 3 [318336/620022]    Loss: 0.010478   Batch Acc: 71.88
[Train] Epoch: 3 [318400/620022]    Loss: 0.008442   Batch Acc: 79.69
[Train] Epoch: 3 [318464/620022]    Loss: 0.006485   Batch Acc: 87.50
[Train] Epoch: 3 [318528/620022]    Loss: 0.006465   Batch Acc: 82.81
[Train] Epoch: 3 [318592/620022]    Loss: 0.008681   Batch Acc: 70.31
[Train] Epoch: 3 [318656/620022]    Loss: 0.009636   Batch Acc: 79.69
[Train] Epoch: 3 [318720/620022]    Loss: 0.009359   Batch Acc: 73.44
[Train] Epoch: 3 [318784/620022]    Loss: 0.006551   Batch Acc: 82.81
[Train] Epoch: 3 [318848/620022]    Loss: 0.008677   Batch Acc: 79.69
[Train] Epoch: 3 [318912/620022]    Loss: 0.009647   Batch Acc: 70.31
[Train] Epoch: 3 [318976/620022]    Loss: 0.007211   Batch Acc: 81.25
[Train] Epoch: 3 [319040/620022]    Loss: 0.007721   Batch Acc: 85.94
[Train] Epoch: 3 [319104/620022]    Loss: 0.007388   Batch Acc: 82.81
[Train] Epoch: 3 [319168/620022]    Loss: 0.008563   Batch Acc: 79.69
[Train] Epoch: 3 [319232/620022]    Loss: 0.008505   Batch Acc: 79.69
[Train] Epoch: 3 [319296/620022]    Loss: 0.008078   Batch Acc: 73.44
[Train] Epoch: 3 [319360/620022]    Loss: 0.008721   Batch Acc: 82.81
[Train] Epoch: 3 [319424/620022]    Loss: 0.008861   Batch Acc: 71.88
[Train] Epoch: 3 [319488/620022]    Loss: 0.007532   Batch Acc: 82.81
[Train] Epoch: 3 [319552/620022]    Loss: 0.006990   Batch Acc: 87.50
[Train] Epoch: 3 [319616/620022]    Loss: 0.008696   Batch Acc: 75.00
[Train] Epoch: 3 [319680/620022]    Loss: 0.007728   Batch Acc: 82.81
[Train] Epoch: 3 [319744/620022]    Loss: 0.006544   Batch Acc: 85.94
[Train] Epoch: 3 [319808/620022]    Loss: 0.009588   Batch Acc: 71.88
[Train] Epoch: 3 [319872/620022]    Loss: 0.008335   Batch Acc: 78.12
[Train] Epoch: 3 [319936/620022]    Loss: 0.007542   Batch Acc: 82.81
[Train] Epoch: 3 [320000/620022]    Loss: 0.011546   Batch Acc: 64.06
[Train] Epoch: 3 [320064/620022]    Loss: 0.010281   Batch Acc: 76.56
[Train] Epoch: 3 [320128/620022]    Loss: 0.008170   Batch Acc: 79.69
[Train] Epoch: 3 [320192/620022]    Loss: 0.005151   Batch Acc: 90.62
[Train] Epoch: 3 [320256/620022]    Loss: 0.008835   Batch Acc: 75.00
[Train] Epoch: 3 [320320/620022]    Loss: 0.009348   Batch Acc: 76.56
[Train] Epoch: 3 [320384/620022]    Loss: 0.007920   Batch Acc: 82.81
[Train] Epoch: 3 [320448/620022]    Loss: 0.010359   Batch Acc: 71.88
[Train] Epoch: 3 [320512/620022]    Loss: 0.008045   Batch Acc: 81.25
[Train] Epoch: 3 [320576/620022]    Loss: 0.008623   Batch Acc: 76.56
[Train] Epoch: 3 [320640/620022]    Loss: 0.008610   Batch Acc: 78.12
[Train] Epoch: 3 [320704/620022]    Loss: 0.007741   Batch Acc: 79.69
[Train] Epoch: 3 [320768/620022]    Loss: 0.006490   Batch Acc: 87.50
[Train] Epoch: 3 [320832/620022]    Loss: 0.006676   Batch Acc: 92.19
[Train] Epoch: 3 [320896/620022]    Loss: 0.009700   Batch Acc: 75.00
[Train] Epoch: 3 [320960/620022]    Loss: 0.006599   Batch Acc: 87.50
[Train] Epoch: 3 [321024/620022]    Loss: 0.007757   Batch Acc: 84.38
[Train] Epoch: 3 [321088/620022]    Loss: 0.010355   Batch Acc: 78.12
[Train] Epoch: 3 [321152/620022]    Loss: 0.006169   Batch Acc: 85.94
[Train] Epoch: 3 [321216/620022]    Loss: 0.009869   Batch Acc: 68.75
[Train] Epoch: 3 [321280/620022]    Loss: 0.007489   Batch Acc: 78.12
[Train] Epoch: 3 [321344/620022]    Loss: 0.011092   Batch Acc: 71.88
[Train] Epoch: 3 [321408/620022]    Loss: 0.007734   Batch Acc: 79.69
[Train] Epoch: 3 [321472/620022]    Loss: 0.011093   Batch Acc: 70.31
[Train] Epoch: 3 [321536/620022]    Loss: 0.008056   Batch Acc: 75.00
[Train] Epoch: 3 [321600/620022]    Loss: 0.007454   Batch Acc: 81.25
[Train] Epoch: 3 [321664/620022]    Loss: 0.009293   Batch Acc: 73.44
[Train] Epoch: 3 [321728/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 3 [321792/620022]    Loss: 0.009576   Batch Acc: 75.00
[Train] Epoch: 3 [321856/620022]    Loss: 0.008015   Batch Acc: 78.12
[Train] Epoch: 3 [321920/620022]    Loss: 0.006901   Batch Acc: 82.81
[Train] Epoch: 3 [321984/620022]    Loss: 0.008006   Batch Acc: 82.81
[Train] Epoch: 3 [322048/620022]    Loss: 0.008892   Batch Acc: 78.12
[Train] Epoch: 3 [322112/620022]    Loss: 0.008808   Batch Acc: 76.56
[Train] Epoch: 3 [322176/620022]    Loss: 0.007391   Batch Acc: 87.50
[Train] Epoch: 3 [322240/620022]    Loss: 0.009103   Batch Acc: 75.00
[Train] Epoch: 3 [322304/620022]    Loss: 0.007966   Batch Acc: 81.25
[Train] Epoch: 3 [322368/620022]    Loss: 0.008422   Batch Acc: 70.31
[Train] Epoch: 3 [322432/620022]    Loss: 0.007038   Batch Acc: 79.69
[Train] Epoch: 3 [322496/620022]    Loss: 0.007980   Batch Acc: 81.25
[Train] Epoch: 3 [322560/620022]    Loss: 0.008352   Batch Acc: 78.12
[Train] Epoch: 3 [322624/620022]    Loss: 0.009225   Batch Acc: 75.00
[Train] Epoch: 3 [322688/620022]    Loss: 0.008397   Batch Acc: 73.44
[Train] Epoch: 3 [322752/620022]    Loss: 0.008463   Batch Acc: 78.12
[Train] Epoch: 3 [322816/620022]    Loss: 0.008967   Batch Acc: 71.88
[Train] Epoch: 3 [322880/620022]    Loss: 0.009068   Batch Acc: 71.88
[Train] Epoch: 3 [322944/620022]    Loss: 0.008755   Batch Acc: 82.81
[Train] Epoch: 3 [323008/620022]    Loss: 0.009246   Batch Acc: 78.12
[Train] Epoch: 3 [323072/620022]    Loss: 0.007628   Batch Acc: 82.81
[Train] Epoch: 3 [323136/620022]    Loss: 0.010058   Batch Acc: 71.88
[Train] Epoch: 3 [323200/620022]    Loss: 0.007555   Batch Acc: 76.56
[Train] Epoch: 3 [323264/620022]    Loss: 0.009502   Batch Acc: 79.69
[Train] Epoch: 3 [323328/620022]    Loss: 0.008869   Batch Acc: 81.25
[Train] Epoch: 3 [323392/620022]    Loss: 0.007754   Batch Acc: 79.69
[Train] Epoch: 3 [323456/620022]    Loss: 0.011033   Batch Acc: 73.44
[Train] Epoch: 3 [323520/620022]    Loss: 0.009410   Batch Acc: 71.88
[Train] Epoch: 3 [323584/620022]    Loss: 0.010749   Batch Acc: 65.62
[Train] Epoch: 3 [323648/620022]    Loss: 0.010976   Batch Acc: 71.88
[Train] Epoch: 3 [323712/620022]    Loss: 0.009194   Batch Acc: 75.00
[Train] Epoch: 3 [323776/620022]    Loss: 0.009125   Batch Acc: 75.00
[Train] Epoch: 3 [323840/620022]    Loss: 0.009855   Batch Acc: 75.00
[Train] Epoch: 3 [323904/620022]    Loss: 0.008198   Batch Acc: 79.69
[Train] Epoch: 3 [323968/620022]    Loss: 0.010692   Batch Acc: 71.88
[Train] Epoch: 3 [324032/620022]    Loss: 0.007848   Batch Acc: 79.69
[Train] Epoch: 3 [324096/620022]    Loss: 0.007325   Batch Acc: 82.81
[Train] Epoch: 3 [324160/620022]    Loss: 0.010005   Batch Acc: 75.00
[Train] Epoch: 3 [324224/620022]    Loss: 0.007659   Batch Acc: 81.25
[Train] Epoch: 3 [324288/620022]    Loss: 0.008969   Batch Acc: 79.69
[Train] Epoch: 3 [324352/620022]    Loss: 0.008080   Batch Acc: 76.56
[Train] Epoch: 3 [324416/620022]    Loss: 0.010572   Batch Acc: 76.56
[Train] Epoch: 3 [324480/620022]    Loss: 0.008949   Batch Acc: 71.88
[Train] Epoch: 3 [324544/620022]    Loss: 0.011919   Batch Acc: 64.06
[Train] Epoch: 3 [324608/620022]    Loss: 0.010821   Batch Acc: 75.00
[Train] Epoch: 3 [324672/620022]    Loss: 0.011067   Batch Acc: 71.88
[Train] Epoch: 3 [324736/620022]    Loss: 0.006877   Batch Acc: 84.38
[Train] Epoch: 3 [324800/620022]    Loss: 0.006618   Batch Acc: 84.38
[Train] Epoch: 3 [324864/620022]    Loss: 0.010625   Batch Acc: 68.75
[Train] Epoch: 3 [324928/620022]    Loss: 0.010277   Batch Acc: 70.31
[Train] Epoch: 3 [324992/620022]    Loss: 0.007952   Batch Acc: 75.00
[Train] Epoch: 3 [325056/620022]    Loss: 0.008351   Batch Acc: 78.12
[Train] Epoch: 3 [325120/620022]    Loss: 0.008612   Batch Acc: 81.25
[Train] Epoch: 3 [325184/620022]    Loss: 0.008420   Batch Acc: 79.69
[Train] Epoch: 3 [325248/620022]    Loss: 0.010187   Batch Acc: 68.75
[Train] Epoch: 3 [325312/620022]    Loss: 0.009777   Batch Acc: 75.00
[Train] Epoch: 3 [325376/620022]    Loss: 0.007042   Batch Acc: 81.25
[Train] Epoch: 3 [325440/620022]    Loss: 0.008479   Batch Acc: 76.56
[Train] Epoch: 3 [325504/620022]    Loss: 0.009207   Batch Acc: 75.00
[Train] Epoch: 3 [325568/620022]    Loss: 0.007796   Batch Acc: 81.25
[Train] Epoch: 3 [325632/620022]    Loss: 0.008951   Batch Acc: 78.12
[Train] Epoch: 3 [325696/620022]    Loss: 0.008167   Batch Acc: 76.56
[Train] Epoch: 3 [325760/620022]    Loss: 0.011016   Batch Acc: 62.50
[Train] Epoch: 3 [325824/620022]    Loss: 0.008484   Batch Acc: 79.69
[Train] Epoch: 3 [325888/620022]    Loss: 0.008851   Batch Acc: 76.56
[Train] Epoch: 3 [325952/620022]    Loss: 0.009967   Batch Acc: 76.56
[Train] Epoch: 3 [326016/620022]    Loss: 0.008080   Batch Acc: 73.44
[Train] Epoch: 3 [326080/620022]    Loss: 0.011432   Batch Acc: 68.75
[Train] Epoch: 3 [326144/620022]    Loss: 0.005543   Batch Acc: 89.06
[Train] Epoch: 3 [326208/620022]    Loss: 0.010948   Batch Acc: 73.44
[Train] Epoch: 3 [326272/620022]    Loss: 0.008705   Batch Acc: 78.12
[Train] Epoch: 3 [326336/620022]    Loss: 0.009154   Batch Acc: 78.12
[Train] Epoch: 3 [326400/620022]    Loss: 0.007047   Batch Acc: 84.38
[Train] Epoch: 3 [326464/620022]    Loss: 0.008358   Batch Acc: 75.00
[Train] Epoch: 3 [326528/620022]    Loss: 0.008972   Batch Acc: 73.44
[Train] Epoch: 3 [326592/620022]    Loss: 0.006637   Batch Acc: 82.81
[Train] Epoch: 3 [326656/620022]    Loss: 0.010820   Batch Acc: 73.44
[Train] Epoch: 3 [326720/620022]    Loss: 0.009139   Batch Acc: 79.69
[Train] Epoch: 3 [326784/620022]    Loss: 0.009269   Batch Acc: 78.12
[Train] Epoch: 3 [326848/620022]    Loss: 0.007865   Batch Acc: 85.94
[Train] Epoch: 3 [326912/620022]    Loss: 0.007650   Batch Acc: 85.94
[Train] Epoch: 3 [326976/620022]    Loss: 0.008734   Batch Acc: 75.00
[Train] Epoch: 3 [327040/620022]    Loss: 0.009926   Batch Acc: 75.00
[Train] Epoch: 3 [327104/620022]    Loss: 0.008349   Batch Acc: 78.12
[Train] Epoch: 3 [327168/620022]    Loss: 0.009401   Batch Acc: 75.00
[Train] Epoch: 3 [327232/620022]    Loss: 0.007483   Batch Acc: 78.12
[Train] Epoch: 3 [327296/620022]    Loss: 0.009393   Batch Acc: 75.00
[Train] Epoch: 3 [327360/620022]    Loss: 0.008513   Batch Acc: 73.44
[Train] Epoch: 3 [327424/620022]    Loss: 0.009009   Batch Acc: 76.56
[Train] Epoch: 3 [327488/620022]    Loss: 0.009751   Batch Acc: 70.31
[Train] Epoch: 3 [327552/620022]    Loss: 0.007210   Batch Acc: 76.56
[Train] Epoch: 3 [327616/620022]    Loss: 0.007729   Batch Acc: 79.69
[Train] Epoch: 3 [327680/620022]    Loss: 0.007926   Batch Acc: 76.56
[Train] Epoch: 3 [327744/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 3 [327808/620022]    Loss: 0.008795   Batch Acc: 76.56
[Train] Epoch: 3 [327872/620022]    Loss: 0.005958   Batch Acc: 84.38
[Train] Epoch: 3 [327936/620022]    Loss: 0.010380   Batch Acc: 70.31
[Train] Epoch: 3 [328000/620022]    Loss: 0.011108   Batch Acc: 76.56
[Train] Epoch: 3 [328064/620022]    Loss: 0.009888   Batch Acc: 70.31
[Train] Epoch: 3 [328128/620022]    Loss: 0.006655   Batch Acc: 84.38
[Train] Epoch: 3 [328192/620022]    Loss: 0.006863   Batch Acc: 84.38
[Train] Epoch: 3 [328256/620022]    Loss: 0.007573   Batch Acc: 79.69
[Train] Epoch: 3 [328320/620022]    Loss: 0.006472   Batch Acc: 89.06
[Train] Epoch: 3 [328384/620022]    Loss: 0.006546   Batch Acc: 87.50
[Train] Epoch: 3 [328448/620022]    Loss: 0.007360   Batch Acc: 79.69
[Train] Epoch: 3 [328512/620022]    Loss: 0.007673   Batch Acc: 76.56
[Train] Epoch: 3 [328576/620022]    Loss: 0.009559   Batch Acc: 73.44
[Train] Epoch: 3 [328640/620022]    Loss: 0.008472   Batch Acc: 79.69
[Train] Epoch: 3 [328704/620022]    Loss: 0.012135   Batch Acc: 68.75
[Train] Epoch: 3 [328768/620022]    Loss: 0.010499   Batch Acc: 67.19
[Train] Epoch: 3 [328832/620022]    Loss: 0.006650   Batch Acc: 89.06
[Train] Epoch: 3 [328896/620022]    Loss: 0.009927   Batch Acc: 70.31
[Train] Epoch: 3 [328960/620022]    Loss: 0.009935   Batch Acc: 71.88
[Train] Epoch: 3 [329024/620022]    Loss: 0.011265   Batch Acc: 75.00
[Train] Epoch: 3 [329088/620022]    Loss: 0.011575   Batch Acc: 70.31
[Train] Epoch: 3 [329152/620022]    Loss: 0.009328   Batch Acc: 73.44
[Train] Epoch: 3 [329216/620022]    Loss: 0.009062   Batch Acc: 78.12
[Train] Epoch: 3 [329280/620022]    Loss: 0.007228   Batch Acc: 82.81
[Train] Epoch: 3 [329344/620022]    Loss: 0.008422   Batch Acc: 75.00
[Train] Epoch: 3 [329408/620022]    Loss: 0.008453   Batch Acc: 78.12
[Train] Epoch: 3 [329472/620022]    Loss: 0.008618   Batch Acc: 82.81
[Train] Epoch: 3 [329536/620022]    Loss: 0.007510   Batch Acc: 78.12
[Train] Epoch: 3 [329600/620022]    Loss: 0.009465   Batch Acc: 75.00
[Train] Epoch: 3 [329664/620022]    Loss: 0.009988   Batch Acc: 70.31
[Train] Epoch: 3 [329728/620022]    Loss: 0.010708   Batch Acc: 73.44
[Train] Epoch: 3 [329792/620022]    Loss: 0.008109   Batch Acc: 78.12
[Train] Epoch: 3 [329856/620022]    Loss: 0.008632   Batch Acc: 79.69
[Train] Epoch: 3 [329920/620022]    Loss: 0.008594   Batch Acc: 78.12
[Train] Epoch: 3 [329984/620022]    Loss: 0.008438   Batch Acc: 75.00
[Train] Epoch: 3 [330048/620022]    Loss: 0.007678   Batch Acc: 81.25
[Train] Epoch: 3 [330112/620022]    Loss: 0.008385   Batch Acc: 78.12
[Train] Epoch: 3 [330176/620022]    Loss: 0.010725   Batch Acc: 71.88
[Train] Epoch: 3 [330240/620022]    Loss: 0.006965   Batch Acc: 84.38
[Train] Epoch: 3 [330304/620022]    Loss: 0.010997   Batch Acc: 68.75
[Train] Epoch: 3 [330368/620022]    Loss: 0.009567   Batch Acc: 76.56
[Train] Epoch: 3 [330432/620022]    Loss: 0.011586   Batch Acc: 70.31
[Train] Epoch: 3 [330496/620022]    Loss: 0.009882   Batch Acc: 68.75
[Train] Epoch: 3 [330560/620022]    Loss: 0.008834   Batch Acc: 76.56
[Train] Epoch: 3 [330624/620022]    Loss: 0.007801   Batch Acc: 81.25
[Train] Epoch: 3 [330688/620022]    Loss: 0.010062   Batch Acc: 73.44
[Train] Epoch: 3 [330752/620022]    Loss: 0.009412   Batch Acc: 76.56
[Train] Epoch: 3 [330816/620022]    Loss: 0.009461   Batch Acc: 71.88
[Train] Epoch: 3 [330880/620022]    Loss: 0.008438   Batch Acc: 81.25
[Train] Epoch: 3 [330944/620022]    Loss: 0.007702   Batch Acc: 78.12
[Train] Epoch: 3 [331008/620022]    Loss: 0.010414   Batch Acc: 70.31
[Train] Epoch: 3 [331072/620022]    Loss: 0.007838   Batch Acc: 81.25
[Train] Epoch: 3 [331136/620022]    Loss: 0.007660   Batch Acc: 81.25
[Train] Epoch: 3 [331200/620022]    Loss: 0.007398   Batch Acc: 79.69
[Train] Epoch: 3 [331264/620022]    Loss: 0.007218   Batch Acc: 81.25
[Train] Epoch: 3 [331328/620022]    Loss: 0.007975   Batch Acc: 79.69
[Train] Epoch: 3 [331392/620022]    Loss: 0.007715   Batch Acc: 78.12
[Train] Epoch: 3 [331456/620022]    Loss: 0.009823   Batch Acc: 76.56
[Train] Epoch: 3 [331520/620022]    Loss: 0.010288   Batch Acc: 70.31
[Train] Epoch: 3 [331584/620022]    Loss: 0.009269   Batch Acc: 76.56
[Train] Epoch: 3 [331648/620022]    Loss: 0.007716   Batch Acc: 81.25
[Train] Epoch: 3 [331712/620022]    Loss: 0.008100   Batch Acc: 75.00
[Train] Epoch: 3 [331776/620022]    Loss: 0.010434   Batch Acc: 78.12
[Train] Epoch: 3 [331840/620022]    Loss: 0.008017   Batch Acc: 79.69
[Train] Epoch: 3 [331904/620022]    Loss: 0.008160   Batch Acc: 81.25
[Train] Epoch: 3 [331968/620022]    Loss: 0.007296   Batch Acc: 79.69
[Train] Epoch: 3 [332032/620022]    Loss: 0.008956   Batch Acc: 71.88
[Train] Epoch: 3 [332096/620022]    Loss: 0.009082   Batch Acc: 81.25
[Train] Epoch: 3 [332160/620022]    Loss: 0.007643   Batch Acc: 81.25
[Train] Epoch: 3 [332224/620022]    Loss: 0.008286   Batch Acc: 78.12
[Train] Epoch: 3 [332288/620022]    Loss: 0.008686   Batch Acc: 71.88
[Train] Epoch: 3 [332352/620022]    Loss: 0.008743   Batch Acc: 78.12
[Train] Epoch: 3 [332416/620022]    Loss: 0.010109   Batch Acc: 73.44
[Train] Epoch: 3 [332480/620022]    Loss: 0.007560   Batch Acc: 82.81
[Train] Epoch: 3 [332544/620022]    Loss: 0.008712   Batch Acc: 76.56
[Train] Epoch: 3 [332608/620022]    Loss: 0.007516   Batch Acc: 82.81
[Train] Epoch: 3 [332672/620022]    Loss: 0.009814   Batch Acc: 73.44
[Train] Epoch: 3 [332736/620022]    Loss: 0.007796   Batch Acc: 75.00
[Train] Epoch: 3 [332800/620022]    Loss: 0.005359   Batch Acc: 89.06
[Train] Epoch: 3 [332864/620022]    Loss: 0.008340   Batch Acc: 78.12
[Train] Epoch: 3 [332928/620022]    Loss: 0.011057   Batch Acc: 64.06
[Train] Epoch: 3 [332992/620022]    Loss: 0.009693   Batch Acc: 76.56
[Train] Epoch: 3 [333056/620022]    Loss: 0.008918   Batch Acc: 75.00
[Train] Epoch: 3 [333120/620022]    Loss: 0.008437   Batch Acc: 78.12
[Train] Epoch: 3 [333184/620022]    Loss: 0.010143   Batch Acc: 73.44
[Train] Epoch: 3 [333248/620022]    Loss: 0.006339   Batch Acc: 90.62
[Train] Epoch: 3 [333312/620022]    Loss: 0.007839   Batch Acc: 78.12
[Train] Epoch: 3 [333376/620022]    Loss: 0.010371   Batch Acc: 70.31
[Train] Epoch: 3 [333440/620022]    Loss: 0.007059   Batch Acc: 87.50
[Train] Epoch: 3 [333504/620022]    Loss: 0.007303   Batch Acc: 79.69
[Train] Epoch: 3 [333568/620022]    Loss: 0.008605   Batch Acc: 78.12
[Train] Epoch: 3 [333632/620022]    Loss: 0.007875   Batch Acc: 76.56
[Train] Epoch: 3 [333696/620022]    Loss: 0.010384   Batch Acc: 76.56
[Train] Epoch: 3 [333760/620022]    Loss: 0.007472   Batch Acc: 84.38
[Train] Epoch: 3 [333824/620022]    Loss: 0.008174   Batch Acc: 82.81
[Train] Epoch: 3 [333888/620022]    Loss: 0.006742   Batch Acc: 85.94
[Train] Epoch: 3 [333952/620022]    Loss: 0.008414   Batch Acc: 73.44
[Train] Epoch: 3 [334016/620022]    Loss: 0.011232   Batch Acc: 75.00
[Train] Epoch: 3 [334080/620022]    Loss: 0.008187   Batch Acc: 82.81
[Train] Epoch: 3 [334144/620022]    Loss: 0.008789   Batch Acc: 79.69
[Train] Epoch: 3 [334208/620022]    Loss: 0.008055   Batch Acc: 75.00
[Train] Epoch: 3 [334272/620022]    Loss: 0.008595   Batch Acc: 81.25
[Train] Epoch: 3 [334336/620022]    Loss: 0.008945   Batch Acc: 75.00
[Train] Epoch: 3 [334400/620022]    Loss: 0.008089   Batch Acc: 82.81
[Train] Epoch: 3 [334464/620022]    Loss: 0.008188   Batch Acc: 78.12
[Train] Epoch: 3 [334528/620022]    Loss: 0.009898   Batch Acc: 73.44
[Train] Epoch: 3 [334592/620022]    Loss: 0.011031   Batch Acc: 70.31
[Train] Epoch: 3 [334656/620022]    Loss: 0.008607   Batch Acc: 71.88
[Train] Epoch: 3 [334720/620022]    Loss: 0.008453   Batch Acc: 76.56
[Train] Epoch: 3 [334784/620022]    Loss: 0.009463   Batch Acc: 76.56
[Train] Epoch: 3 [334848/620022]    Loss: 0.006227   Batch Acc: 84.38
[Train] Epoch: 3 [334912/620022]    Loss: 0.010729   Batch Acc: 76.56
[Train] Epoch: 3 [334976/620022]    Loss: 0.008551   Batch Acc: 81.25
[Train] Epoch: 3 [335040/620022]    Loss: 0.008589   Batch Acc: 73.44
[Train] Epoch: 3 [335104/620022]    Loss: 0.009553   Batch Acc: 71.88
[Train] Epoch: 3 [335168/620022]    Loss: 0.008296   Batch Acc: 73.44
[Train] Epoch: 3 [335232/620022]    Loss: 0.008873   Batch Acc: 75.00
[Train] Epoch: 3 [335296/620022]    Loss: 0.008883   Batch Acc: 81.25
[Train] Epoch: 3 [335360/620022]    Loss: 0.008581   Batch Acc: 78.12
[Train] Epoch: 3 [335424/620022]    Loss: 0.009527   Batch Acc: 70.31
[Train] Epoch: 3 [335488/620022]    Loss: 0.008471   Batch Acc: 75.00
[Train] Epoch: 3 [335552/620022]    Loss: 0.011183   Batch Acc: 68.75
[Train] Epoch: 3 [335616/620022]    Loss: 0.008278   Batch Acc: 76.56
[Train] Epoch: 3 [335680/620022]    Loss: 0.008295   Batch Acc: 76.56
[Train] Epoch: 3 [335744/620022]    Loss: 0.008293   Batch Acc: 81.25
[Train] Epoch: 3 [335808/620022]    Loss: 0.007038   Batch Acc: 81.25
[Train] Epoch: 3 [335872/620022]    Loss: 0.009582   Batch Acc: 78.12
[Train] Epoch: 3 [335936/620022]    Loss: 0.007450   Batch Acc: 76.56
[Train] Epoch: 3 [336000/620022]    Loss: 0.008099   Batch Acc: 84.38
[Train] Epoch: 3 [336064/620022]    Loss: 0.007939   Batch Acc: 78.12
[Train] Epoch: 3 [336128/620022]    Loss: 0.010030   Batch Acc: 70.31
[Train] Epoch: 3 [336192/620022]    Loss: 0.011542   Batch Acc: 64.06
[Train] Epoch: 3 [336256/620022]    Loss: 0.009381   Batch Acc: 78.12
[Train] Epoch: 3 [336320/620022]    Loss: 0.008318   Batch Acc: 78.12
[Train] Epoch: 3 [336384/620022]    Loss: 0.009072   Batch Acc: 73.44
[Train] Epoch: 3 [336448/620022]    Loss: 0.010105   Batch Acc: 75.00
[Train] Epoch: 3 [336512/620022]    Loss: 0.009530   Batch Acc: 79.69
[Train] Epoch: 3 [336576/620022]    Loss: 0.008827   Batch Acc: 79.69
[Train] Epoch: 3 [336640/620022]    Loss: 0.008085   Batch Acc: 82.81
[Train] Epoch: 3 [336704/620022]    Loss: 0.007607   Batch Acc: 82.81
[Train] Epoch: 3 [336768/620022]    Loss: 0.007080   Batch Acc: 79.69
[Train] Epoch: 3 [336832/620022]    Loss: 0.009792   Batch Acc: 75.00
[Train] Epoch: 3 [336896/620022]    Loss: 0.007977   Batch Acc: 79.69
[Train] Epoch: 3 [336960/620022]    Loss: 0.008245   Batch Acc: 76.56
[Train] Epoch: 3 [337024/620022]    Loss: 0.006977   Batch Acc: 81.25
[Train] Epoch: 3 [337088/620022]    Loss: 0.008355   Batch Acc: 79.69
[Train] Epoch: 3 [337152/620022]    Loss: 0.010810   Batch Acc: 71.88
[Train] Epoch: 3 [337216/620022]    Loss: 0.007925   Batch Acc: 82.81
[Train] Epoch: 3 [337280/620022]    Loss: 0.010263   Batch Acc: 73.44
[Train] Epoch: 3 [337344/620022]    Loss: 0.009487   Batch Acc: 76.56
[Train] Epoch: 3 [337408/620022]    Loss: 0.008689   Batch Acc: 81.25
[Train] Epoch: 3 [337472/620022]    Loss: 0.007348   Batch Acc: 81.25
[Train] Epoch: 3 [337536/620022]    Loss: 0.008626   Batch Acc: 79.69
[Train] Epoch: 3 [337600/620022]    Loss: 0.008048   Batch Acc: 78.12
[Train] Epoch: 3 [337664/620022]    Loss: 0.007927   Batch Acc: 81.25
[Train] Epoch: 3 [337728/620022]    Loss: 0.009518   Batch Acc: 75.00
[Train] Epoch: 3 [337792/620022]    Loss: 0.005837   Batch Acc: 90.62
[Train] Epoch: 3 [337856/620022]    Loss: 0.009327   Batch Acc: 75.00
[Train] Epoch: 3 [337920/620022]    Loss: 0.007740   Batch Acc: 79.69
[Train] Epoch: 3 [337984/620022]    Loss: 0.007440   Batch Acc: 78.12
[Train] Epoch: 3 [338048/620022]    Loss: 0.007480   Batch Acc: 79.69
[Train] Epoch: 3 [338112/620022]    Loss: 0.007195   Batch Acc: 84.38
[Train] Epoch: 3 [338176/620022]    Loss: 0.009853   Batch Acc: 73.44
[Train] Epoch: 3 [338240/620022]    Loss: 0.008304   Batch Acc: 76.56
[Train] Epoch: 3 [338304/620022]    Loss: 0.008093   Batch Acc: 75.00
[Train] Epoch: 3 [338368/620022]    Loss: 0.007493   Batch Acc: 87.50
[Train] Epoch: 3 [338432/620022]    Loss: 0.008290   Batch Acc: 76.56
[Train] Epoch: 3 [338496/620022]    Loss: 0.008355   Batch Acc: 75.00
[Train] Epoch: 3 [338560/620022]    Loss: 0.007559   Batch Acc: 82.81
[Train] Epoch: 3 [338624/620022]    Loss: 0.008462   Batch Acc: 75.00
[Train] Epoch: 3 [338688/620022]    Loss: 0.008022   Batch Acc: 79.69
[Train] Epoch: 3 [338752/620022]    Loss: 0.010456   Batch Acc: 65.62
[Train] Epoch: 3 [338816/620022]    Loss: 0.008327   Batch Acc: 78.12
[Train] Epoch: 3 [338880/620022]    Loss: 0.007309   Batch Acc: 84.38
[Train] Epoch: 3 [338944/620022]    Loss: 0.006125   Batch Acc: 84.38
[Train] Epoch: 3 [339008/620022]    Loss: 0.009109   Batch Acc: 78.12
[Train] Epoch: 3 [339072/620022]    Loss: 0.007352   Batch Acc: 82.81
[Train] Epoch: 3 [339136/620022]    Loss: 0.012562   Batch Acc: 65.62
[Train] Epoch: 3 [339200/620022]    Loss: 0.008728   Batch Acc: 78.12
[Train] Epoch: 3 [339264/620022]    Loss: 0.010578   Batch Acc: 76.56
[Train] Epoch: 3 [339328/620022]    Loss: 0.008856   Batch Acc: 79.69
[Train] Epoch: 3 [339392/620022]    Loss: 0.010171   Batch Acc: 75.00
[Train] Epoch: 3 [339456/620022]    Loss: 0.009012   Batch Acc: 70.31
[Train] Epoch: 3 [339520/620022]    Loss: 0.008287   Batch Acc: 79.69
[Train] Epoch: 3 [339584/620022]    Loss: 0.009653   Batch Acc: 73.44
[Train] Epoch: 3 [339648/620022]    Loss: 0.010026   Batch Acc: 78.12
[Train] Epoch: 3 [339712/620022]    Loss: 0.008255   Batch Acc: 84.38
[Train] Epoch: 3 [339776/620022]    Loss: 0.007537   Batch Acc: 79.69
[Train] Epoch: 3 [339840/620022]    Loss: 0.009298   Batch Acc: 73.44
[Train] Epoch: 3 [339904/620022]    Loss: 0.007603   Batch Acc: 81.25
[Train] Epoch: 3 [339968/620022]    Loss: 0.009263   Batch Acc: 78.12
[Train] Epoch: 3 [340032/620022]    Loss: 0.009446   Batch Acc: 78.12
[Train] Epoch: 3 [340096/620022]    Loss: 0.007788   Batch Acc: 79.69
[Train] Epoch: 3 [340160/620022]    Loss: 0.007936   Batch Acc: 79.69
[Train] Epoch: 3 [340224/620022]    Loss: 0.008796   Batch Acc: 79.69
[Train] Epoch: 3 [340288/620022]    Loss: 0.007572   Batch Acc: 78.12
[Train] Epoch: 3 [340352/620022]    Loss: 0.007646   Batch Acc: 84.38
[Train] Epoch: 3 [340416/620022]    Loss: 0.006599   Batch Acc: 89.06
[Train] Epoch: 3 [340480/620022]    Loss: 0.010637   Batch Acc: 68.75
[Train] Epoch: 3 [340544/620022]    Loss: 0.009992   Batch Acc: 71.88
[Train] Epoch: 3 [340608/620022]    Loss: 0.007290   Batch Acc: 79.69
[Train] Epoch: 3 [340672/620022]    Loss: 0.008667   Batch Acc: 82.81
[Train] Epoch: 3 [340736/620022]    Loss: 0.009690   Batch Acc: 75.00
[Train] Epoch: 3 [340800/620022]    Loss: 0.009773   Batch Acc: 76.56
[Train] Epoch: 3 [340864/620022]    Loss: 0.010810   Batch Acc: 75.00
[Train] Epoch: 3 [340928/620022]    Loss: 0.007605   Batch Acc: 84.38
[Train] Epoch: 3 [340992/620022]    Loss: 0.008066   Batch Acc: 78.12
[Train] Epoch: 3 [341056/620022]    Loss: 0.011127   Batch Acc: 64.06
[Train] Epoch: 3 [341120/620022]    Loss: 0.007173   Batch Acc: 79.69
[Train] Epoch: 3 [341184/620022]    Loss: 0.010433   Batch Acc: 68.75
[Train] Epoch: 3 [341248/620022]    Loss: 0.007701   Batch Acc: 81.25
[Train] Epoch: 3 [341312/620022]    Loss: 0.007674   Batch Acc: 75.00
[Train] Epoch: 3 [341376/620022]    Loss: 0.008759   Batch Acc: 78.12
[Train] Epoch: 3 [341440/620022]    Loss: 0.010566   Batch Acc: 73.44
[Train] Epoch: 3 [341504/620022]    Loss: 0.008151   Batch Acc: 73.44
[Train] Epoch: 3 [341568/620022]    Loss: 0.009036   Batch Acc: 82.81
[Train] Epoch: 3 [341632/620022]    Loss: 0.009838   Batch Acc: 75.00
[Train] Epoch: 3 [341696/620022]    Loss: 0.010128   Batch Acc: 73.44
[Train] Epoch: 3 [341760/620022]    Loss: 0.008690   Batch Acc: 78.12
[Train] Epoch: 3 [341824/620022]    Loss: 0.007968   Batch Acc: 79.69
[Train] Epoch: 3 [341888/620022]    Loss: 0.008002   Batch Acc: 79.69
[Train] Epoch: 3 [341952/620022]    Loss: 0.008384   Batch Acc: 73.44
[Train] Epoch: 3 [342016/620022]    Loss: 0.011060   Batch Acc: 67.19
[Train] Epoch: 3 [342080/620022]    Loss: 0.007020   Batch Acc: 87.50
[Train] Epoch: 3 [342144/620022]    Loss: 0.005901   Batch Acc: 87.50
[Train] Epoch: 3 [342208/620022]    Loss: 0.008446   Batch Acc: 78.12
[Train] Epoch: 3 [342272/620022]    Loss: 0.008522   Batch Acc: 78.12
[Train] Epoch: 3 [342336/620022]    Loss: 0.007828   Batch Acc: 76.56
[Train] Epoch: 3 [342400/620022]    Loss: 0.008510   Batch Acc: 76.56
[Train] Epoch: 3 [342464/620022]    Loss: 0.009129   Batch Acc: 78.12
[Train] Epoch: 3 [342528/620022]    Loss: 0.009619   Batch Acc: 71.88
[Train] Epoch: 3 [342592/620022]    Loss: 0.009706   Batch Acc: 70.31
[Train] Epoch: 3 [342656/620022]    Loss: 0.008765   Batch Acc: 78.12
[Train] Epoch: 3 [342720/620022]    Loss: 0.008312   Batch Acc: 81.25
[Train] Epoch: 3 [342784/620022]    Loss: 0.013379   Batch Acc: 59.38
[Train] Epoch: 3 [342848/620022]    Loss: 0.008035   Batch Acc: 82.81
[Train] Epoch: 3 [342912/620022]    Loss: 0.009278   Batch Acc: 73.44
[Train] Epoch: 3 [342976/620022]    Loss: 0.009458   Batch Acc: 78.12
[Train] Epoch: 3 [343040/620022]    Loss: 0.008836   Batch Acc: 78.12
[Train] Epoch: 3 [343104/620022]    Loss: 0.009235   Batch Acc: 75.00
[Train] Epoch: 3 [343168/620022]    Loss: 0.008802   Batch Acc: 78.12
[Train] Epoch: 3 [343232/620022]    Loss: 0.007901   Batch Acc: 79.69
[Train] Epoch: 3 [343296/620022]    Loss: 0.010512   Batch Acc: 71.88
[Train] Epoch: 3 [343360/620022]    Loss: 0.008516   Batch Acc: 79.69
[Train] Epoch: 3 [343424/620022]    Loss: 0.008650   Batch Acc: 76.56
[Train] Epoch: 3 [343488/620022]    Loss: 0.007257   Batch Acc: 85.94
[Train] Epoch: 3 [343552/620022]    Loss: 0.007485   Batch Acc: 79.69
[Train] Epoch: 3 [343616/620022]    Loss: 0.009429   Batch Acc: 79.69
[Train] Epoch: 3 [343680/620022]    Loss: 0.007599   Batch Acc: 79.69
[Train] Epoch: 3 [343744/620022]    Loss: 0.009293   Batch Acc: 73.44
[Train] Epoch: 3 [343808/620022]    Loss: 0.006451   Batch Acc: 85.94
[Train] Epoch: 3 [343872/620022]    Loss: 0.007008   Batch Acc: 84.38
[Train] Epoch: 3 [343936/620022]    Loss: 0.008718   Batch Acc: 76.56
[Train] Epoch: 3 [344000/620022]    Loss: 0.008178   Batch Acc: 79.69
[Train] Epoch: 3 [344064/620022]    Loss: 0.008557   Batch Acc: 78.12
[Train] Epoch: 3 [344128/620022]    Loss: 0.007989   Batch Acc: 79.69
[Train] Epoch: 3 [344192/620022]    Loss: 0.008818   Batch Acc: 78.12
[Train] Epoch: 3 [344256/620022]    Loss: 0.006162   Batch Acc: 87.50
[Train] Epoch: 3 [344320/620022]    Loss: 0.010548   Batch Acc: 75.00
[Train] Epoch: 3 [344384/620022]    Loss: 0.009824   Batch Acc: 73.44
[Train] Epoch: 3 [344448/620022]    Loss: 0.008313   Batch Acc: 76.56
[Train] Epoch: 3 [344512/620022]    Loss: 0.008557   Batch Acc: 75.00
[Train] Epoch: 3 [344576/620022]    Loss: 0.008787   Batch Acc: 76.56
[Train] Epoch: 3 [344640/620022]    Loss: 0.008508   Batch Acc: 73.44
[Train] Epoch: 3 [344704/620022]    Loss: 0.007406   Batch Acc: 75.00
[Train] Epoch: 3 [344768/620022]    Loss: 0.009066   Batch Acc: 79.69
[Train] Epoch: 3 [344832/620022]    Loss: 0.009545   Batch Acc: 79.69
[Train] Epoch: 3 [344896/620022]    Loss: 0.009018   Batch Acc: 79.69
[Train] Epoch: 3 [344960/620022]    Loss: 0.010704   Batch Acc: 76.56
[Train] Epoch: 3 [345024/620022]    Loss: 0.009109   Batch Acc: 71.88
[Train] Epoch: 3 [345088/620022]    Loss: 0.008400   Batch Acc: 82.81
[Train] Epoch: 3 [345152/620022]    Loss: 0.007006   Batch Acc: 84.38
[Train] Epoch: 3 [345216/620022]    Loss: 0.008386   Batch Acc: 76.56
[Train] Epoch: 3 [345280/620022]    Loss: 0.007143   Batch Acc: 79.69
[Train] Epoch: 3 [345344/620022]    Loss: 0.008529   Batch Acc: 76.56
[Train] Epoch: 3 [345408/620022]    Loss: 0.007315   Batch Acc: 87.50
[Train] Epoch: 3 [345472/620022]    Loss: 0.009138   Batch Acc: 79.69
[Train] Epoch: 3 [345536/620022]    Loss: 0.010256   Batch Acc: 76.56
[Train] Epoch: 3 [345600/620022]    Loss: 0.007463   Batch Acc: 79.69
[Train] Epoch: 3 [345664/620022]    Loss: 0.007295   Batch Acc: 76.56
[Train] Epoch: 3 [345728/620022]    Loss: 0.008697   Batch Acc: 79.69
[Train] Epoch: 3 [345792/620022]    Loss: 0.006992   Batch Acc: 79.69
[Train] Epoch: 3 [345856/620022]    Loss: 0.008315   Batch Acc: 79.69
[Train] Epoch: 3 [345920/620022]    Loss: 0.009668   Batch Acc: 78.12
[Train] Epoch: 3 [345984/620022]    Loss: 0.009241   Batch Acc: 78.12
[Train] Epoch: 3 [346048/620022]    Loss: 0.009735   Batch Acc: 76.56
[Train] Epoch: 3 [346112/620022]    Loss: 0.009367   Batch Acc: 76.56
[Train] Epoch: 3 [346176/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 3 [346240/620022]    Loss: 0.008668   Batch Acc: 81.25
[Train] Epoch: 3 [346304/620022]    Loss: 0.006474   Batch Acc: 85.94
[Train] Epoch: 3 [346368/620022]    Loss: 0.008857   Batch Acc: 79.69
[Train] Epoch: 3 [346432/620022]    Loss: 0.007320   Batch Acc: 82.81
[Train] Epoch: 3 [346496/620022]    Loss: 0.007000   Batch Acc: 85.94
[Train] Epoch: 3 [346560/620022]    Loss: 0.007709   Batch Acc: 81.25
[Train] Epoch: 3 [346624/620022]    Loss: 0.007650   Batch Acc: 84.38
[Train] Epoch: 3 [346688/620022]    Loss: 0.010325   Batch Acc: 71.88
[Train] Epoch: 3 [346752/620022]    Loss: 0.009508   Batch Acc: 78.12
[Train] Epoch: 3 [346816/620022]    Loss: 0.008277   Batch Acc: 78.12
[Train] Epoch: 3 [346880/620022]    Loss: 0.009242   Batch Acc: 75.00
[Train] Epoch: 3 [346944/620022]    Loss: 0.009128   Batch Acc: 79.69
[Train] Epoch: 3 [347008/620022]    Loss: 0.008006   Batch Acc: 78.12
[Train] Epoch: 3 [347072/620022]    Loss: 0.007915   Batch Acc: 85.94
[Train] Epoch: 3 [347136/620022]    Loss: 0.007075   Batch Acc: 84.38
[Train] Epoch: 3 [347200/620022]    Loss: 0.008301   Batch Acc: 81.25
[Train] Epoch: 3 [347264/620022]    Loss: 0.007850   Batch Acc: 82.81
[Train] Epoch: 3 [347328/620022]    Loss: 0.013313   Batch Acc: 67.19
[Train] Epoch: 3 [347392/620022]    Loss: 0.010160   Batch Acc: 82.81
[Train] Epoch: 3 [347456/620022]    Loss: 0.008424   Batch Acc: 79.69
[Train] Epoch: 3 [347520/620022]    Loss: 0.007788   Batch Acc: 76.56
[Train] Epoch: 3 [347584/620022]    Loss: 0.006235   Batch Acc: 84.38
[Train] Epoch: 3 [347648/620022]    Loss: 0.007410   Batch Acc: 84.38
[Train] Epoch: 3 [347712/620022]    Loss: 0.009668   Batch Acc: 68.75
[Train] Epoch: 3 [347776/620022]    Loss: 0.008141   Batch Acc: 79.69
[Train] Epoch: 3 [347840/620022]    Loss: 0.009187   Batch Acc: 73.44
[Train] Epoch: 3 [347904/620022]    Loss: 0.009049   Batch Acc: 75.00
[Train] Epoch: 3 [347968/620022]    Loss: 0.009475   Batch Acc: 73.44
[Train] Epoch: 3 [348032/620022]    Loss: 0.007095   Batch Acc: 85.94
[Train] Epoch: 3 [348096/620022]    Loss: 0.009053   Batch Acc: 76.56
[Train] Epoch: 3 [348160/620022]    Loss: 0.008264   Batch Acc: 78.12
[Train] Epoch: 3 [348224/620022]    Loss: 0.007199   Batch Acc: 84.38
[Train] Epoch: 3 [348288/620022]    Loss: 0.011492   Batch Acc: 65.62
[Train] Epoch: 3 [348352/620022]    Loss: 0.010979   Batch Acc: 71.88
[Train] Epoch: 3 [348416/620022]    Loss: 0.010092   Batch Acc: 71.88
[Train] Epoch: 3 [348480/620022]    Loss: 0.009319   Batch Acc: 75.00
[Train] Epoch: 3 [348544/620022]    Loss: 0.007652   Batch Acc: 78.12
[Train] Epoch: 3 [348608/620022]    Loss: 0.009613   Batch Acc: 75.00
[Train] Epoch: 3 [348672/620022]    Loss: 0.007819   Batch Acc: 79.69
[Train] Epoch: 3 [348736/620022]    Loss: 0.008988   Batch Acc: 76.56
[Train] Epoch: 3 [348800/620022]    Loss: 0.011054   Batch Acc: 73.44
[Train] Epoch: 3 [348864/620022]    Loss: 0.007498   Batch Acc: 81.25
[Train] Epoch: 3 [348928/620022]    Loss: 0.006431   Batch Acc: 87.50
[Train] Epoch: 3 [348992/620022]    Loss: 0.010248   Batch Acc: 70.31
[Train] Epoch: 3 [349056/620022]    Loss: 0.009349   Batch Acc: 71.88
[Train] Epoch: 3 [349120/620022]    Loss: 0.008546   Batch Acc: 78.12
[Train] Epoch: 3 [349184/620022]    Loss: 0.009249   Batch Acc: 78.12
[Train] Epoch: 3 [349248/620022]    Loss: 0.008630   Batch Acc: 75.00
[Train] Epoch: 3 [349312/620022]    Loss: 0.008978   Batch Acc: 75.00
[Train] Epoch: 3 [349376/620022]    Loss: 0.009680   Batch Acc: 73.44
[Train] Epoch: 3 [349440/620022]    Loss: 0.008488   Batch Acc: 76.56
[Train] Epoch: 3 [349504/620022]    Loss: 0.009221   Batch Acc: 71.88
[Train] Epoch: 3 [349568/620022]    Loss: 0.011026   Batch Acc: 68.75
[Train] Epoch: 3 [349632/620022]    Loss: 0.007507   Batch Acc: 82.81
[Train] Epoch: 3 [349696/620022]    Loss: 0.010239   Batch Acc: 68.75
[Train] Epoch: 3 [349760/620022]    Loss: 0.009270   Batch Acc: 73.44
[Train] Epoch: 3 [349824/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 3 [349888/620022]    Loss: 0.008678   Batch Acc: 76.56
[Train] Epoch: 3 [349952/620022]    Loss: 0.006416   Batch Acc: 84.38
[Train] Epoch: 3 [350016/620022]    Loss: 0.009499   Batch Acc: 71.88
[Train] Epoch: 3 [350080/620022]    Loss: 0.009396   Batch Acc: 78.12
[Train] Epoch: 3 [350144/620022]    Loss: 0.009164   Batch Acc: 73.44
[Train] Epoch: 3 [350208/620022]    Loss: 0.009242   Batch Acc: 78.12
[Train] Epoch: 3 [350272/620022]    Loss: 0.008773   Batch Acc: 79.69
[Train] Epoch: 3 [350336/620022]    Loss: 0.008651   Batch Acc: 78.12
[Train] Epoch: 3 [350400/620022]    Loss: 0.010265   Batch Acc: 68.75
[Train] Epoch: 3 [350464/620022]    Loss: 0.010099   Batch Acc: 67.19
[Train] Epoch: 3 [350528/620022]    Loss: 0.010058   Batch Acc: 70.31
[Train] Epoch: 3 [350592/620022]    Loss: 0.009281   Batch Acc: 71.88
[Train] Epoch: 3 [350656/620022]    Loss: 0.008743   Batch Acc: 81.25
[Train] Epoch: 3 [350720/620022]    Loss: 0.007760   Batch Acc: 82.81
[Train] Epoch: 3 [350784/620022]    Loss: 0.009609   Batch Acc: 76.56
[Train] Epoch: 3 [350848/620022]    Loss: 0.006796   Batch Acc: 82.81
[Train] Epoch: 3 [350912/620022]    Loss: 0.009122   Batch Acc: 71.88
[Train] Epoch: 3 [350976/620022]    Loss: 0.006414   Batch Acc: 85.94
[Train] Epoch: 3 [351040/620022]    Loss: 0.008378   Batch Acc: 79.69
[Train] Epoch: 3 [351104/620022]    Loss: 0.008695   Batch Acc: 75.00
[Train] Epoch: 3 [351168/620022]    Loss: 0.008311   Batch Acc: 82.81
[Train] Epoch: 3 [351232/620022]    Loss: 0.008334   Batch Acc: 73.44
[Train] Epoch: 3 [351296/620022]    Loss: 0.008356   Batch Acc: 81.25
[Train] Epoch: 3 [351360/620022]    Loss: 0.007789   Batch Acc: 79.69
[Train] Epoch: 3 [351424/620022]    Loss: 0.007680   Batch Acc: 81.25
[Train] Epoch: 3 [351488/620022]    Loss: 0.008127   Batch Acc: 75.00
[Train] Epoch: 3 [351552/620022]    Loss: 0.007631   Batch Acc: 78.12
[Train] Epoch: 3 [351616/620022]    Loss: 0.009232   Batch Acc: 70.31
[Train] Epoch: 3 [351680/620022]    Loss: 0.009253   Batch Acc: 76.56
[Train] Epoch: 3 [351744/620022]    Loss: 0.008020   Batch Acc: 78.12
[Train] Epoch: 3 [351808/620022]    Loss: 0.009646   Batch Acc: 70.31
[Train] Epoch: 3 [351872/620022]    Loss: 0.009188   Batch Acc: 76.56
[Train] Epoch: 3 [351936/620022]    Loss: 0.009854   Batch Acc: 68.75
[Train] Epoch: 3 [352000/620022]    Loss: 0.009893   Batch Acc: 75.00
[Train] Epoch: 3 [352064/620022]    Loss: 0.010380   Batch Acc: 71.88
[Train] Epoch: 3 [352128/620022]    Loss: 0.009385   Batch Acc: 70.31
[Train] Epoch: 3 [352192/620022]    Loss: 0.009650   Batch Acc: 73.44
[Train] Epoch: 3 [352256/620022]    Loss: 0.007981   Batch Acc: 73.44
[Train] Epoch: 3 [352320/620022]    Loss: 0.007506   Batch Acc: 82.81
[Train] Epoch: 3 [352384/620022]    Loss: 0.010139   Batch Acc: 76.56
[Train] Epoch: 3 [352448/620022]    Loss: 0.006036   Batch Acc: 90.62
[Train] Epoch: 3 [352512/620022]    Loss: 0.007613   Batch Acc: 84.38
[Train] Epoch: 3 [352576/620022]    Loss: 0.007799   Batch Acc: 84.38
[Train] Epoch: 3 [352640/620022]    Loss: 0.008286   Batch Acc: 73.44
[Train] Epoch: 3 [352704/620022]    Loss: 0.009112   Batch Acc: 81.25
[Train] Epoch: 3 [352768/620022]    Loss: 0.007706   Batch Acc: 84.38
[Train] Epoch: 3 [352832/620022]    Loss: 0.008956   Batch Acc: 76.56
[Train] Epoch: 3 [352896/620022]    Loss: 0.009022   Batch Acc: 79.69
[Train] Epoch: 3 [352960/620022]    Loss: 0.006277   Batch Acc: 84.38
[Train] Epoch: 3 [353024/620022]    Loss: 0.007430   Batch Acc: 84.38
[Train] Epoch: 3 [353088/620022]    Loss: 0.009156   Batch Acc: 73.44
[Train] Epoch: 3 [353152/620022]    Loss: 0.009844   Batch Acc: 76.56
[Train] Epoch: 3 [353216/620022]    Loss: 0.009705   Batch Acc: 73.44
[Train] Epoch: 3 [353280/620022]    Loss: 0.007808   Batch Acc: 79.69
[Train] Epoch: 3 [353344/620022]    Loss: 0.010028   Batch Acc: 73.44
[Train] Epoch: 3 [353408/620022]    Loss: 0.011061   Batch Acc: 64.06
[Train] Epoch: 3 [353472/620022]    Loss: 0.006590   Batch Acc: 90.62
[Train] Epoch: 3 [353536/620022]    Loss: 0.009656   Batch Acc: 73.44
[Train] Epoch: 3 [353600/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 3 [353664/620022]    Loss: 0.009055   Batch Acc: 73.44
[Train] Epoch: 3 [353728/620022]    Loss: 0.008523   Batch Acc: 76.56
[Train] Epoch: 3 [353792/620022]    Loss: 0.009348   Batch Acc: 75.00
[Train] Epoch: 3 [353856/620022]    Loss: 0.011192   Batch Acc: 70.31
[Train] Epoch: 3 [353920/620022]    Loss: 0.007480   Batch Acc: 84.38
[Train] Epoch: 3 [353984/620022]    Loss: 0.010231   Batch Acc: 75.00
[Train] Epoch: 3 [354048/620022]    Loss: 0.009403   Batch Acc: 76.56
[Train] Epoch: 3 [354112/620022]    Loss: 0.009520   Batch Acc: 75.00
[Train] Epoch: 3 [354176/620022]    Loss: 0.010777   Batch Acc: 70.31
[Train] Epoch: 3 [354240/620022]    Loss: 0.005779   Batch Acc: 92.19
[Train] Epoch: 3 [354304/620022]    Loss: 0.010517   Batch Acc: 68.75
[Train] Epoch: 3 [354368/620022]    Loss: 0.006556   Batch Acc: 82.81
[Train] Epoch: 3 [354432/620022]    Loss: 0.010350   Batch Acc: 67.19
[Train] Epoch: 3 [354496/620022]    Loss: 0.008630   Batch Acc: 78.12
[Train] Epoch: 3 [354560/620022]    Loss: 0.008717   Batch Acc: 75.00
[Train] Epoch: 3 [354624/620022]    Loss: 0.011125   Batch Acc: 73.44
[Train] Epoch: 3 [354688/620022]    Loss: 0.006854   Batch Acc: 84.38
[Train] Epoch: 3 [354752/620022]    Loss: 0.010829   Batch Acc: 65.62
[Train] Epoch: 3 [354816/620022]    Loss: 0.010626   Batch Acc: 76.56
[Train] Epoch: 3 [354880/620022]    Loss: 0.008046   Batch Acc: 78.12
[Train] Epoch: 3 [354944/620022]    Loss: 0.008186   Batch Acc: 79.69
[Train] Epoch: 3 [355008/620022]    Loss: 0.007723   Batch Acc: 78.12
[Train] Epoch: 3 [355072/620022]    Loss: 0.010328   Batch Acc: 76.56
[Train] Epoch: 3 [355136/620022]    Loss: 0.008309   Batch Acc: 81.25
[Train] Epoch: 3 [355200/620022]    Loss: 0.010291   Batch Acc: 70.31
[Train] Epoch: 3 [355264/620022]    Loss: 0.010690   Batch Acc: 73.44
[Train] Epoch: 3 [355328/620022]    Loss: 0.007146   Batch Acc: 82.81
[Train] Epoch: 3 [355392/620022]    Loss: 0.011543   Batch Acc: 70.31
[Train] Epoch: 3 [355456/620022]    Loss: 0.007746   Batch Acc: 82.81
[Train] Epoch: 3 [355520/620022]    Loss: 0.007469   Batch Acc: 82.81
[Train] Epoch: 3 [355584/620022]    Loss: 0.008617   Batch Acc: 76.56
[Train] Epoch: 3 [355648/620022]    Loss: 0.007168   Batch Acc: 81.25
[Train] Epoch: 3 [355712/620022]    Loss: 0.008952   Batch Acc: 75.00
[Train] Epoch: 3 [355776/620022]    Loss: 0.009339   Batch Acc: 76.56
[Train] Epoch: 3 [355840/620022]    Loss: 0.008849   Batch Acc: 75.00
[Train] Epoch: 3 [355904/620022]    Loss: 0.009702   Batch Acc: 76.56
[Train] Epoch: 3 [355968/620022]    Loss: 0.009711   Batch Acc: 70.31
[Train] Epoch: 3 [356032/620022]    Loss: 0.009486   Batch Acc: 73.44
[Train] Epoch: 3 [356096/620022]    Loss: 0.010502   Batch Acc: 71.88
[Train] Epoch: 3 [356160/620022]    Loss: 0.008611   Batch Acc: 76.56
[Train] Epoch: 3 [356224/620022]    Loss: 0.009681   Batch Acc: 65.62
[Train] Epoch: 3 [356288/620022]    Loss: 0.006945   Batch Acc: 87.50
[Train] Epoch: 3 [356352/620022]    Loss: 0.009676   Batch Acc: 73.44
[Train] Epoch: 3 [356416/620022]    Loss: 0.008127   Batch Acc: 81.25
[Train] Epoch: 3 [356480/620022]    Loss: 0.007396   Batch Acc: 85.94
[Train] Epoch: 3 [356544/620022]    Loss: 0.007930   Batch Acc: 79.69
[Train] Epoch: 3 [356608/620022]    Loss: 0.009604   Batch Acc: 76.56
[Train] Epoch: 3 [356672/620022]    Loss: 0.009208   Batch Acc: 79.69
[Train] Epoch: 3 [356736/620022]    Loss: 0.013451   Batch Acc: 68.75
[Train] Epoch: 3 [356800/620022]    Loss: 0.009774   Batch Acc: 73.44
[Train] Epoch: 3 [356864/620022]    Loss: 0.006590   Batch Acc: 85.94
[Train] Epoch: 3 [356928/620022]    Loss: 0.011095   Batch Acc: 76.56
[Train] Epoch: 3 [356992/620022]    Loss: 0.007731   Batch Acc: 78.12
[Train] Epoch: 3 [357056/620022]    Loss: 0.009604   Batch Acc: 76.56
[Train] Epoch: 3 [357120/620022]    Loss: 0.009322   Batch Acc: 70.31
[Train] Epoch: 3 [357184/620022]    Loss: 0.006979   Batch Acc: 84.38
[Train] Epoch: 3 [357248/620022]    Loss: 0.011168   Batch Acc: 70.31
[Train] Epoch: 3 [357312/620022]    Loss: 0.009073   Batch Acc: 78.12
[Train] Epoch: 3 [357376/620022]    Loss: 0.008502   Batch Acc: 78.12
[Train] Epoch: 3 [357440/620022]    Loss: 0.009991   Batch Acc: 70.31
[Train] Epoch: 3 [357504/620022]    Loss: 0.009438   Batch Acc: 78.12
[Train] Epoch: 3 [357568/620022]    Loss: 0.007000   Batch Acc: 79.69
[Train] Epoch: 3 [357632/620022]    Loss: 0.011424   Batch Acc: 67.19
[Train] Epoch: 3 [357696/620022]    Loss: 0.009076   Batch Acc: 81.25
[Train] Epoch: 3 [357760/620022]    Loss: 0.008595   Batch Acc: 73.44
[Train] Epoch: 3 [357824/620022]    Loss: 0.008568   Batch Acc: 79.69
[Train] Epoch: 3 [357888/620022]    Loss: 0.005835   Batch Acc: 87.50
[Train] Epoch: 3 [357952/620022]    Loss: 0.007321   Batch Acc: 79.69
[Train] Epoch: 3 [358016/620022]    Loss: 0.006495   Batch Acc: 87.50
[Train] Epoch: 3 [358080/620022]    Loss: 0.007673   Batch Acc: 84.38
[Train] Epoch: 3 [358144/620022]    Loss: 0.009875   Batch Acc: 73.44
[Train] Epoch: 3 [358208/620022]    Loss: 0.009365   Batch Acc: 78.12
[Train] Epoch: 3 [358272/620022]    Loss: 0.009196   Batch Acc: 76.56
[Train] Epoch: 3 [358336/620022]    Loss: 0.007454   Batch Acc: 81.25
[Train] Epoch: 3 [358400/620022]    Loss: 0.006858   Batch Acc: 84.38
[Train] Epoch: 3 [358464/620022]    Loss: 0.008325   Batch Acc: 79.69
[Train] Epoch: 3 [358528/620022]    Loss: 0.007790   Batch Acc: 81.25
[Train] Epoch: 3 [358592/620022]    Loss: 0.007887   Batch Acc: 78.12
[Train] Epoch: 3 [358656/620022]    Loss: 0.009183   Batch Acc: 76.56
[Train] Epoch: 3 [358720/620022]    Loss: 0.006585   Batch Acc: 89.06
[Train] Epoch: 3 [358784/620022]    Loss: 0.007588   Batch Acc: 85.94
[Train] Epoch: 3 [358848/620022]    Loss: 0.008646   Batch Acc: 82.81
[Train] Epoch: 3 [358912/620022]    Loss: 0.009413   Batch Acc: 79.69
[Train] Epoch: 3 [358976/620022]    Loss: 0.010048   Batch Acc: 73.44
[Train] Epoch: 3 [359040/620022]    Loss: 0.009169   Batch Acc: 76.56
[Train] Epoch: 3 [359104/620022]    Loss: 0.010514   Batch Acc: 68.75
[Train] Epoch: 3 [359168/620022]    Loss: 0.007445   Batch Acc: 84.38
[Train] Epoch: 3 [359232/620022]    Loss: 0.008862   Batch Acc: 79.69
[Train] Epoch: 3 [359296/620022]    Loss: 0.006787   Batch Acc: 85.94
[Train] Epoch: 3 [359360/620022]    Loss: 0.008673   Batch Acc: 76.56
[Train] Epoch: 3 [359424/620022]    Loss: 0.007935   Batch Acc: 82.81
[Train] Epoch: 3 [359488/620022]    Loss: 0.010734   Batch Acc: 64.06
[Train] Epoch: 3 [359552/620022]    Loss: 0.006686   Batch Acc: 84.38
[Train] Epoch: 3 [359616/620022]    Loss: 0.008977   Batch Acc: 81.25
[Train] Epoch: 3 [359680/620022]    Loss: 0.007324   Batch Acc: 82.81
[Train] Epoch: 3 [359744/620022]    Loss: 0.006586   Batch Acc: 84.38
[Train] Epoch: 3 [359808/620022]    Loss: 0.008488   Batch Acc: 76.56
[Train] Epoch: 3 [359872/620022]    Loss: 0.009128   Batch Acc: 73.44
[Train] Epoch: 3 [359936/620022]    Loss: 0.009948   Batch Acc: 76.56
[Train] Epoch: 3 [360000/620022]    Loss: 0.007614   Batch Acc: 82.81
[Train] Epoch: 3 [360064/620022]    Loss: 0.008787   Batch Acc: 75.00
[Train] Epoch: 3 [360128/620022]    Loss: 0.008912   Batch Acc: 78.12
[Train] Epoch: 3 [360192/620022]    Loss: 0.012572   Batch Acc: 64.06
[Train] Epoch: 3 [360256/620022]    Loss: 0.007328   Batch Acc: 81.25
[Train] Epoch: 3 [360320/620022]    Loss: 0.008229   Batch Acc: 79.69
[Train] Epoch: 3 [360384/620022]    Loss: 0.008407   Batch Acc: 78.12
[Train] Epoch: 3 [360448/620022]    Loss: 0.010590   Batch Acc: 71.88
[Train] Epoch: 3 [360512/620022]    Loss: 0.007596   Batch Acc: 82.81
[Train] Epoch: 3 [360576/620022]    Loss: 0.009992   Batch Acc: 73.44
[Train] Epoch: 3 [360640/620022]    Loss: 0.008155   Batch Acc: 76.56
[Train] Epoch: 3 [360704/620022]    Loss: 0.010250   Batch Acc: 76.56
[Train] Epoch: 3 [360768/620022]    Loss: 0.010629   Batch Acc: 70.31
[Train] Epoch: 3 [360832/620022]    Loss: 0.006284   Batch Acc: 87.50
[Train] Epoch: 3 [360896/620022]    Loss: 0.007821   Batch Acc: 76.56
[Train] Epoch: 3 [360960/620022]    Loss: 0.009484   Batch Acc: 73.44
[Train] Epoch: 3 [361024/620022]    Loss: 0.008706   Batch Acc: 76.56
[Train] Epoch: 3 [361088/620022]    Loss: 0.007641   Batch Acc: 79.69
[Train] Epoch: 3 [361152/620022]    Loss: 0.007117   Batch Acc: 84.38
[Train] Epoch: 3 [361216/620022]    Loss: 0.008371   Batch Acc: 73.44
[Train] Epoch: 3 [361280/620022]    Loss: 0.008359   Batch Acc: 81.25
[Train] Epoch: 3 [361344/620022]    Loss: 0.009372   Batch Acc: 75.00
[Train] Epoch: 3 [361408/620022]    Loss: 0.008677   Batch Acc: 75.00
[Train] Epoch: 3 [361472/620022]    Loss: 0.010921   Batch Acc: 73.44
[Train] Epoch: 3 [361536/620022]    Loss: 0.009619   Batch Acc: 76.56
[Train] Epoch: 3 [361600/620022]    Loss: 0.012609   Batch Acc: 70.31
[Train] Epoch: 3 [361664/620022]    Loss: 0.009280   Batch Acc: 71.88
[Train] Epoch: 3 [361728/620022]    Loss: 0.008934   Batch Acc: 79.69
[Train] Epoch: 3 [361792/620022]    Loss: 0.012836   Batch Acc: 64.06
[Train] Epoch: 3 [361856/620022]    Loss: 0.010330   Batch Acc: 68.75
[Train] Epoch: 3 [361920/620022]    Loss: 0.008301   Batch Acc: 79.69
[Train] Epoch: 3 [361984/620022]    Loss: 0.011323   Batch Acc: 68.75
[Train] Epoch: 3 [362048/620022]    Loss: 0.012482   Batch Acc: 67.19
[Train] Epoch: 3 [362112/620022]    Loss: 0.008553   Batch Acc: 78.12
[Train] Epoch: 3 [362176/620022]    Loss: 0.009038   Batch Acc: 75.00
[Train] Epoch: 3 [362240/620022]    Loss: 0.006285   Batch Acc: 85.94
[Train] Epoch: 3 [362304/620022]    Loss: 0.008201   Batch Acc: 81.25
[Train] Epoch: 3 [362368/620022]    Loss: 0.008328   Batch Acc: 76.56
[Train] Epoch: 3 [362432/620022]    Loss: 0.007690   Batch Acc: 82.81
[Train] Epoch: 3 [362496/620022]    Loss: 0.008511   Batch Acc: 82.81
[Train] Epoch: 3 [362560/620022]    Loss: 0.011245   Batch Acc: 76.56
[Train] Epoch: 3 [362624/620022]    Loss: 0.007981   Batch Acc: 76.56
[Train] Epoch: 3 [362688/620022]    Loss: 0.008045   Batch Acc: 79.69
[Train] Epoch: 3 [362752/620022]    Loss: 0.007067   Batch Acc: 81.25
[Train] Epoch: 3 [362816/620022]    Loss: 0.010501   Batch Acc: 79.69
[Train] Epoch: 3 [362880/620022]    Loss: 0.008986   Batch Acc: 73.44
[Train] Epoch: 3 [362944/620022]    Loss: 0.009015   Batch Acc: 79.69
[Train] Epoch: 3 [363008/620022]    Loss: 0.006870   Batch Acc: 84.38
[Train] Epoch: 3 [363072/620022]    Loss: 0.005604   Batch Acc: 84.38
[Train] Epoch: 3 [363136/620022]    Loss: 0.007479   Batch Acc: 82.81
[Train] Epoch: 3 [363200/620022]    Loss: 0.007731   Batch Acc: 75.00
[Train] Epoch: 3 [363264/620022]    Loss: 0.010281   Batch Acc: 68.75
[Train] Epoch: 3 [363328/620022]    Loss: 0.006282   Batch Acc: 89.06
[Train] Epoch: 3 [363392/620022]    Loss: 0.006653   Batch Acc: 79.69
[Train] Epoch: 3 [363456/620022]    Loss: 0.008071   Batch Acc: 84.38
[Train] Epoch: 3 [363520/620022]    Loss: 0.008560   Batch Acc: 78.12
[Train] Epoch: 3 [363584/620022]    Loss: 0.007696   Batch Acc: 78.12
[Train] Epoch: 3 [363648/620022]    Loss: 0.009046   Batch Acc: 71.88
[Train] Epoch: 3 [363712/620022]    Loss: 0.008842   Batch Acc: 76.56
[Train] Epoch: 3 [363776/620022]    Loss: 0.010165   Batch Acc: 73.44
[Train] Epoch: 3 [363840/620022]    Loss: 0.006754   Batch Acc: 84.38
[Train] Epoch: 3 [363904/620022]    Loss: 0.009396   Batch Acc: 67.19
[Train] Epoch: 3 [363968/620022]    Loss: 0.011417   Batch Acc: 71.88
[Train] Epoch: 3 [364032/620022]    Loss: 0.007342   Batch Acc: 84.38
[Train] Epoch: 3 [364096/620022]    Loss: 0.008403   Batch Acc: 78.12
[Train] Epoch: 3 [364160/620022]    Loss: 0.007662   Batch Acc: 81.25
[Train] Epoch: 3 [364224/620022]    Loss: 0.010387   Batch Acc: 73.44
[Train] Epoch: 3 [364288/620022]    Loss: 0.006479   Batch Acc: 84.38
[Train] Epoch: 3 [364352/620022]    Loss: 0.008405   Batch Acc: 73.44
[Train] Epoch: 3 [364416/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 3 [364480/620022]    Loss: 0.007309   Batch Acc: 82.81
[Train] Epoch: 3 [364544/620022]    Loss: 0.008927   Batch Acc: 76.56
[Train] Epoch: 3 [364608/620022]    Loss: 0.008920   Batch Acc: 76.56
[Train] Epoch: 3 [364672/620022]    Loss: 0.007176   Batch Acc: 84.38
[Train] Epoch: 3 [364736/620022]    Loss: 0.009262   Batch Acc: 75.00
[Train] Epoch: 3 [364800/620022]    Loss: 0.005387   Batch Acc: 87.50
[Train] Epoch: 3 [364864/620022]    Loss: 0.009850   Batch Acc: 73.44
[Train] Epoch: 3 [364928/620022]    Loss: 0.008893   Batch Acc: 78.12
[Train] Epoch: 3 [364992/620022]    Loss: 0.007008   Batch Acc: 84.38
[Train] Epoch: 3 [365056/620022]    Loss: 0.008402   Batch Acc: 73.44
[Train] Epoch: 3 [365120/620022]    Loss: 0.008848   Batch Acc: 82.81
[Train] Epoch: 3 [365184/620022]    Loss: 0.011112   Batch Acc: 70.31
[Train] Epoch: 3 [365248/620022]    Loss: 0.006785   Batch Acc: 82.81
[Train] Epoch: 3 [365312/620022]    Loss: 0.009685   Batch Acc: 71.88
[Train] Epoch: 3 [365376/620022]    Loss: 0.007813   Batch Acc: 76.56
[Train] Epoch: 3 [365440/620022]    Loss: 0.010162   Batch Acc: 76.56
[Train] Epoch: 3 [365504/620022]    Loss: 0.009366   Batch Acc: 78.12
[Train] Epoch: 3 [365568/620022]    Loss: 0.008857   Batch Acc: 79.69
[Train] Epoch: 3 [365632/620022]    Loss: 0.008492   Batch Acc: 78.12
[Train] Epoch: 3 [365696/620022]    Loss: 0.008280   Batch Acc: 81.25
[Train] Epoch: 3 [365760/620022]    Loss: 0.007533   Batch Acc: 78.12
[Train] Epoch: 3 [365824/620022]    Loss: 0.011453   Batch Acc: 68.75
[Train] Epoch: 3 [365888/620022]    Loss: 0.008768   Batch Acc: 79.69
[Train] Epoch: 3 [365952/620022]    Loss: 0.009797   Batch Acc: 84.38
[Train] Epoch: 3 [366016/620022]    Loss: 0.008200   Batch Acc: 76.56
[Train] Epoch: 3 [366080/620022]    Loss: 0.008480   Batch Acc: 79.69
[Train] Epoch: 3 [366144/620022]    Loss: 0.010510   Batch Acc: 71.88
[Train] Epoch: 3 [366208/620022]    Loss: 0.007331   Batch Acc: 82.81
[Train] Epoch: 3 [366272/620022]    Loss: 0.008895   Batch Acc: 75.00
[Train] Epoch: 3 [366336/620022]    Loss: 0.006547   Batch Acc: 84.38
[Train] Epoch: 3 [366400/620022]    Loss: 0.007955   Batch Acc: 78.12
[Train] Epoch: 3 [366464/620022]    Loss: 0.008659   Batch Acc: 73.44
[Train] Epoch: 3 [366528/620022]    Loss: 0.009374   Batch Acc: 78.12
[Train] Epoch: 3 [366592/620022]    Loss: 0.009390   Batch Acc: 79.69
[Train] Epoch: 3 [366656/620022]    Loss: 0.008766   Batch Acc: 78.12
[Train] Epoch: 3 [366720/620022]    Loss: 0.008163   Batch Acc: 75.00
[Train] Epoch: 3 [366784/620022]    Loss: 0.008465   Batch Acc: 79.69
[Train] Epoch: 3 [366848/620022]    Loss: 0.008364   Batch Acc: 78.12
[Train] Epoch: 3 [366912/620022]    Loss: 0.007262   Batch Acc: 82.81
[Train] Epoch: 3 [366976/620022]    Loss: 0.008419   Batch Acc: 81.25
[Train] Epoch: 3 [367040/620022]    Loss: 0.007784   Batch Acc: 76.56
[Train] Epoch: 3 [367104/620022]    Loss: 0.008024   Batch Acc: 87.50
[Train] Epoch: 3 [367168/620022]    Loss: 0.008997   Batch Acc: 78.12
[Train] Epoch: 3 [367232/620022]    Loss: 0.009099   Batch Acc: 71.88
[Train] Epoch: 3 [367296/620022]    Loss: 0.009582   Batch Acc: 79.69
[Train] Epoch: 3 [367360/620022]    Loss: 0.009892   Batch Acc: 71.88
[Train] Epoch: 3 [367424/620022]    Loss: 0.010217   Batch Acc: 73.44
[Train] Epoch: 3 [367488/620022]    Loss: 0.006192   Batch Acc: 92.19
[Train] Epoch: 3 [367552/620022]    Loss: 0.006681   Batch Acc: 82.81
[Train] Epoch: 3 [367616/620022]    Loss: 0.009511   Batch Acc: 75.00
[Train] Epoch: 3 [367680/620022]    Loss: 0.008249   Batch Acc: 79.69
[Train] Epoch: 3 [367744/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 3 [367808/620022]    Loss: 0.008198   Batch Acc: 79.69
[Train] Epoch: 3 [367872/620022]    Loss: 0.007630   Batch Acc: 81.25
[Train] Epoch: 3 [367936/620022]    Loss: 0.009845   Batch Acc: 78.12
[Train] Epoch: 3 [368000/620022]    Loss: 0.006990   Batch Acc: 85.94
[Train] Epoch: 3 [368064/620022]    Loss: 0.010534   Batch Acc: 70.31
[Train] Epoch: 3 [368128/620022]    Loss: 0.008648   Batch Acc: 76.56
[Train] Epoch: 3 [368192/620022]    Loss: 0.008848   Batch Acc: 76.56
[Train] Epoch: 3 [368256/620022]    Loss: 0.013424   Batch Acc: 62.50
[Train] Epoch: 3 [368320/620022]    Loss: 0.010205   Batch Acc: 73.44
[Train] Epoch: 3 [368384/620022]    Loss: 0.008418   Batch Acc: 81.25
[Train] Epoch: 3 [368448/620022]    Loss: 0.008321   Batch Acc: 79.69
[Train] Epoch: 3 [368512/620022]    Loss: 0.007645   Batch Acc: 81.25
[Train] Epoch: 3 [368576/620022]    Loss: 0.008437   Batch Acc: 75.00
[Train] Epoch: 3 [368640/620022]    Loss: 0.009867   Batch Acc: 70.31
[Train] Epoch: 3 [368704/620022]    Loss: 0.010950   Batch Acc: 60.94
[Train] Epoch: 3 [368768/620022]    Loss: 0.009011   Batch Acc: 76.56
[Train] Epoch: 3 [368832/620022]    Loss: 0.007489   Batch Acc: 84.38
[Train] Epoch: 3 [368896/620022]    Loss: 0.010371   Batch Acc: 64.06
[Train] Epoch: 3 [368960/620022]    Loss: 0.009032   Batch Acc: 71.88
[Train] Epoch: 3 [369024/620022]    Loss: 0.006497   Batch Acc: 85.94
[Train] Epoch: 3 [369088/620022]    Loss: 0.008098   Batch Acc: 81.25
[Train] Epoch: 3 [369152/620022]    Loss: 0.007734   Batch Acc: 81.25
[Train] Epoch: 3 [369216/620022]    Loss: 0.008726   Batch Acc: 75.00
[Train] Epoch: 3 [369280/620022]    Loss: 0.009973   Batch Acc: 78.12
[Train] Epoch: 3 [369344/620022]    Loss: 0.011186   Batch Acc: 65.62
[Train] Epoch: 3 [369408/620022]    Loss: 0.008552   Batch Acc: 73.44
[Train] Epoch: 3 [369472/620022]    Loss: 0.008030   Batch Acc: 84.38
[Train] Epoch: 3 [369536/620022]    Loss: 0.008030   Batch Acc: 81.25
[Train] Epoch: 3 [369600/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 3 [369664/620022]    Loss: 0.008032   Batch Acc: 79.69
[Train] Epoch: 3 [369728/620022]    Loss: 0.011259   Batch Acc: 68.75
[Train] Epoch: 3 [369792/620022]    Loss: 0.007749   Batch Acc: 82.81
[Train] Epoch: 3 [369856/620022]    Loss: 0.008885   Batch Acc: 81.25
[Train] Epoch: 3 [369920/620022]    Loss: 0.008549   Batch Acc: 79.69
[Train] Epoch: 3 [369984/620022]    Loss: 0.011018   Batch Acc: 75.00
[Train] Epoch: 3 [370048/620022]    Loss: 0.007627   Batch Acc: 78.12
[Train] Epoch: 3 [370112/620022]    Loss: 0.007984   Batch Acc: 85.94
[Train] Epoch: 3 [370176/620022]    Loss: 0.008543   Batch Acc: 76.56
[Train] Epoch: 3 [370240/620022]    Loss: 0.008868   Batch Acc: 78.12
[Train] Epoch: 3 [370304/620022]    Loss: 0.008781   Batch Acc: 81.25
[Train] Epoch: 3 [370368/620022]    Loss: 0.008497   Batch Acc: 78.12
[Train] Epoch: 3 [370432/620022]    Loss: 0.009059   Batch Acc: 81.25
[Train] Epoch: 3 [370496/620022]    Loss: 0.008822   Batch Acc: 76.56
[Train] Epoch: 3 [370560/620022]    Loss: 0.008952   Batch Acc: 70.31
[Train] Epoch: 3 [370624/620022]    Loss: 0.006191   Batch Acc: 85.94
[Train] Epoch: 3 [370688/620022]    Loss: 0.008643   Batch Acc: 79.69
[Train] Epoch: 3 [370752/620022]    Loss: 0.007930   Batch Acc: 85.94
[Train] Epoch: 3 [370816/620022]    Loss: 0.008098   Batch Acc: 82.81
[Train] Epoch: 3 [370880/620022]    Loss: 0.007960   Batch Acc: 85.94
[Train] Epoch: 3 [370944/620022]    Loss: 0.008630   Batch Acc: 76.56
[Train] Epoch: 3 [371008/620022]    Loss: 0.008551   Batch Acc: 75.00
[Train] Epoch: 3 [371072/620022]    Loss: 0.012173   Batch Acc: 67.19
[Train] Epoch: 3 [371136/620022]    Loss: 0.008597   Batch Acc: 79.69
[Train] Epoch: 3 [371200/620022]    Loss: 0.009765   Batch Acc: 75.00
[Train] Epoch: 3 [371264/620022]    Loss: 0.012011   Batch Acc: 65.62
[Train] Epoch: 3 [371328/620022]    Loss: 0.007132   Batch Acc: 84.38
[Train] Epoch: 3 [371392/620022]    Loss: 0.006757   Batch Acc: 89.06
[Train] Epoch: 3 [371456/620022]    Loss: 0.010213   Batch Acc: 73.44
[Train] Epoch: 3 [371520/620022]    Loss: 0.007277   Batch Acc: 82.81
[Train] Epoch: 3 [371584/620022]    Loss: 0.008788   Batch Acc: 76.56
[Train] Epoch: 3 [371648/620022]    Loss: 0.009247   Batch Acc: 76.56
[Train] Epoch: 3 [371712/620022]    Loss: 0.010177   Batch Acc: 75.00
[Train] Epoch: 3 [371776/620022]    Loss: 0.009076   Batch Acc: 70.31
[Train] Epoch: 3 [371840/620022]    Loss: 0.009531   Batch Acc: 79.69
[Train] Epoch: 3 [371904/620022]    Loss: 0.008417   Batch Acc: 79.69
[Train] Epoch: 3 [371968/620022]    Loss: 0.006918   Batch Acc: 82.81
[Train] Epoch: 3 [372032/620022]    Loss: 0.009813   Batch Acc: 68.75
[Train] Epoch: 3 [372096/620022]    Loss: 0.008785   Batch Acc: 75.00
[Train] Epoch: 3 [372160/620022]    Loss: 0.009315   Batch Acc: 75.00
[Train] Epoch: 3 [372224/620022]    Loss: 0.011031   Batch Acc: 68.75
[Train] Epoch: 3 [372288/620022]    Loss: 0.006568   Batch Acc: 84.38
[Train] Epoch: 3 [372352/620022]    Loss: 0.008859   Batch Acc: 76.56
[Train] Epoch: 3 [372416/620022]    Loss: 0.008689   Batch Acc: 85.94
[Train] Epoch: 3 [372480/620022]    Loss: 0.007307   Batch Acc: 76.56
[Train] Epoch: 3 [372544/620022]    Loss: 0.008811   Batch Acc: 82.81
[Train] Epoch: 3 [372608/620022]    Loss: 0.007951   Batch Acc: 81.25
[Train] Epoch: 3 [372672/620022]    Loss: 0.009351   Batch Acc: 71.88
[Train] Epoch: 3 [372736/620022]    Loss: 0.006364   Batch Acc: 84.38
[Train] Epoch: 3 [372800/620022]    Loss: 0.008190   Batch Acc: 76.56
[Train] Epoch: 3 [372864/620022]    Loss: 0.010186   Batch Acc: 71.88
[Train] Epoch: 3 [372928/620022]    Loss: 0.009908   Batch Acc: 76.56
[Train] Epoch: 3 [372992/620022]    Loss: 0.006126   Batch Acc: 85.94
[Train] Epoch: 3 [373056/620022]    Loss: 0.007152   Batch Acc: 79.69
[Train] Epoch: 3 [373120/620022]    Loss: 0.008398   Batch Acc: 76.56
[Train] Epoch: 3 [373184/620022]    Loss: 0.008910   Batch Acc: 79.69
[Train] Epoch: 3 [373248/620022]    Loss: 0.007765   Batch Acc: 82.81
[Train] Epoch: 3 [373312/620022]    Loss: 0.011617   Batch Acc: 73.44
[Train] Epoch: 3 [373376/620022]    Loss: 0.008046   Batch Acc: 79.69
[Train] Epoch: 3 [373440/620022]    Loss: 0.010240   Batch Acc: 75.00
[Train] Epoch: 3 [373504/620022]    Loss: 0.008537   Batch Acc: 81.25
[Train] Epoch: 3 [373568/620022]    Loss: 0.010079   Batch Acc: 68.75
[Train] Epoch: 3 [373632/620022]    Loss: 0.010314   Batch Acc: 71.88
[Train] Epoch: 3 [373696/620022]    Loss: 0.008138   Batch Acc: 79.69
[Train] Epoch: 3 [373760/620022]    Loss: 0.006584   Batch Acc: 84.38
[Train] Epoch: 3 [373824/620022]    Loss: 0.007486   Batch Acc: 84.38
[Train] Epoch: 3 [373888/620022]    Loss: 0.007621   Batch Acc: 81.25
[Train] Epoch: 3 [373952/620022]    Loss: 0.008554   Batch Acc: 81.25
[Train] Epoch: 3 [374016/620022]    Loss: 0.009235   Batch Acc: 70.31
[Train] Epoch: 3 [374080/620022]    Loss: 0.006718   Batch Acc: 82.81
[Train] Epoch: 3 [374144/620022]    Loss: 0.007622   Batch Acc: 79.69
[Train] Epoch: 3 [374208/620022]    Loss: 0.010997   Batch Acc: 73.44
[Train] Epoch: 3 [374272/620022]    Loss: 0.009347   Batch Acc: 73.44
[Train] Epoch: 3 [374336/620022]    Loss: 0.008501   Batch Acc: 73.44
[Train] Epoch: 3 [374400/620022]    Loss: 0.009845   Batch Acc: 78.12
[Train] Epoch: 3 [374464/620022]    Loss: 0.008664   Batch Acc: 70.31
[Train] Epoch: 3 [374528/620022]    Loss: 0.007845   Batch Acc: 79.69
[Train] Epoch: 3 [374592/620022]    Loss: 0.008906   Batch Acc: 76.56
[Train] Epoch: 3 [374656/620022]    Loss: 0.010601   Batch Acc: 71.88
[Train] Epoch: 3 [374720/620022]    Loss: 0.009278   Batch Acc: 75.00
[Train] Epoch: 3 [374784/620022]    Loss: 0.009584   Batch Acc: 71.88
[Train] Epoch: 3 [374848/620022]    Loss: 0.007130   Batch Acc: 84.38
[Train] Epoch: 3 [374912/620022]    Loss: 0.010513   Batch Acc: 78.12
[Train] Epoch: 3 [374976/620022]    Loss: 0.007764   Batch Acc: 81.25
[Train] Epoch: 3 [375040/620022]    Loss: 0.007841   Batch Acc: 79.69
[Train] Epoch: 3 [375104/620022]    Loss: 0.010422   Batch Acc: 79.69
[Train] Epoch: 3 [375168/620022]    Loss: 0.007483   Batch Acc: 84.38
[Train] Epoch: 3 [375232/620022]    Loss: 0.009505   Batch Acc: 73.44
[Train] Epoch: 3 [375296/620022]    Loss: 0.008564   Batch Acc: 81.25
[Train] Epoch: 3 [375360/620022]    Loss: 0.007967   Batch Acc: 87.50
[Train] Epoch: 3 [375424/620022]    Loss: 0.009402   Batch Acc: 75.00
[Train] Epoch: 3 [375488/620022]    Loss: 0.008669   Batch Acc: 78.12
[Train] Epoch: 3 [375552/620022]    Loss: 0.008108   Batch Acc: 73.44
[Train] Epoch: 3 [375616/620022]    Loss: 0.010539   Batch Acc: 65.62
[Train] Epoch: 3 [375680/620022]    Loss: 0.008978   Batch Acc: 76.56
[Train] Epoch: 3 [375744/620022]    Loss: 0.007304   Batch Acc: 76.56
[Train] Epoch: 3 [375808/620022]    Loss: 0.010098   Batch Acc: 78.12
[Train] Epoch: 3 [375872/620022]    Loss: 0.009003   Batch Acc: 78.12
[Train] Epoch: 3 [375936/620022]    Loss: 0.007694   Batch Acc: 79.69
[Train] Epoch: 3 [376000/620022]    Loss: 0.010231   Batch Acc: 75.00
[Train] Epoch: 3 [376064/620022]    Loss: 0.007648   Batch Acc: 79.69
[Train] Epoch: 3 [376128/620022]    Loss: 0.010213   Batch Acc: 73.44
[Train] Epoch: 3 [376192/620022]    Loss: 0.008387   Batch Acc: 79.69
[Train] Epoch: 3 [376256/620022]    Loss: 0.006940   Batch Acc: 84.38
[Train] Epoch: 3 [376320/620022]    Loss: 0.010877   Batch Acc: 75.00
[Train] Epoch: 3 [376384/620022]    Loss: 0.007066   Batch Acc: 85.94
[Train] Epoch: 3 [376448/620022]    Loss: 0.009260   Batch Acc: 75.00
[Train] Epoch: 3 [376512/620022]    Loss: 0.006501   Batch Acc: 84.38
[Train] Epoch: 3 [376576/620022]    Loss: 0.010334   Batch Acc: 75.00
[Train] Epoch: 3 [376640/620022]    Loss: 0.010980   Batch Acc: 67.19
[Train] Epoch: 3 [376704/620022]    Loss: 0.007126   Batch Acc: 85.94
[Train] Epoch: 3 [376768/620022]    Loss: 0.008966   Batch Acc: 73.44
[Train] Epoch: 3 [376832/620022]    Loss: 0.009844   Batch Acc: 79.69
[Train] Epoch: 3 [376896/620022]    Loss: 0.009434   Batch Acc: 70.31
[Train] Epoch: 3 [376960/620022]    Loss: 0.006580   Batch Acc: 89.06
[Train] Epoch: 3 [377024/620022]    Loss: 0.007151   Batch Acc: 79.69
[Train] Epoch: 3 [377088/620022]    Loss: 0.010211   Batch Acc: 75.00
[Train] Epoch: 3 [377152/620022]    Loss: 0.007916   Batch Acc: 75.00
[Train] Epoch: 3 [377216/620022]    Loss: 0.007326   Batch Acc: 84.38
[Train] Epoch: 3 [377280/620022]    Loss: 0.007434   Batch Acc: 79.69
[Train] Epoch: 3 [377344/620022]    Loss: 0.008830   Batch Acc: 76.56
[Train] Epoch: 3 [377408/620022]    Loss: 0.007879   Batch Acc: 84.38
[Train] Epoch: 3 [377472/620022]    Loss: 0.010372   Batch Acc: 71.88
[Train] Epoch: 3 [377536/620022]    Loss: 0.007345   Batch Acc: 79.69
[Train] Epoch: 3 [377600/620022]    Loss: 0.008680   Batch Acc: 71.88
[Train] Epoch: 3 [377664/620022]    Loss: 0.008486   Batch Acc: 79.69
[Train] Epoch: 3 [377728/620022]    Loss: 0.008248   Batch Acc: 79.69
[Train] Epoch: 3 [377792/620022]    Loss: 0.007856   Batch Acc: 76.56
[Train] Epoch: 3 [377856/620022]    Loss: 0.006134   Batch Acc: 85.94
[Train] Epoch: 3 [377920/620022]    Loss: 0.010865   Batch Acc: 71.88
[Train] Epoch: 3 [377984/620022]    Loss: 0.010252   Batch Acc: 70.31
[Train] Epoch: 3 [378048/620022]    Loss: 0.009537   Batch Acc: 70.31
[Train] Epoch: 3 [378112/620022]    Loss: 0.009315   Batch Acc: 79.69
[Train] Epoch: 3 [378176/620022]    Loss: 0.009218   Batch Acc: 71.88
[Train] Epoch: 3 [378240/620022]    Loss: 0.011773   Batch Acc: 73.44
[Train] Epoch: 3 [378304/620022]    Loss: 0.006821   Batch Acc: 81.25
[Train] Epoch: 3 [378368/620022]    Loss: 0.008898   Batch Acc: 73.44
[Train] Epoch: 3 [378432/620022]    Loss: 0.009881   Batch Acc: 71.88
[Train] Epoch: 3 [378496/620022]    Loss: 0.006559   Batch Acc: 81.25
[Train] Epoch: 3 [378560/620022]    Loss: 0.007622   Batch Acc: 84.38
[Train] Epoch: 3 [378624/620022]    Loss: 0.009201   Batch Acc: 75.00
[Train] Epoch: 3 [378688/620022]    Loss: 0.009268   Batch Acc: 75.00
[Train] Epoch: 3 [378752/620022]    Loss: 0.008990   Batch Acc: 75.00
[Train] Epoch: 3 [378816/620022]    Loss: 0.009971   Batch Acc: 76.56
[Train] Epoch: 3 [378880/620022]    Loss: 0.007680   Batch Acc: 84.38
[Train] Epoch: 3 [378944/620022]    Loss: 0.008461   Batch Acc: 81.25
[Train] Epoch: 3 [379008/620022]    Loss: 0.008268   Batch Acc: 75.00
[Train] Epoch: 3 [379072/620022]    Loss: 0.008067   Batch Acc: 81.25
[Train] Epoch: 3 [379136/620022]    Loss: 0.009812   Batch Acc: 73.44
[Train] Epoch: 3 [379200/620022]    Loss: 0.010299   Batch Acc: 73.44
[Train] Epoch: 3 [379264/620022]    Loss: 0.009162   Batch Acc: 73.44
[Train] Epoch: 3 [379328/620022]    Loss: 0.007400   Batch Acc: 79.69
[Train] Epoch: 3 [379392/620022]    Loss: 0.009528   Batch Acc: 79.69
[Train] Epoch: 3 [379456/620022]    Loss: 0.007334   Batch Acc: 81.25
[Train] Epoch: 3 [379520/620022]    Loss: 0.009173   Batch Acc: 75.00
[Train] Epoch: 3 [379584/620022]    Loss: 0.010037   Batch Acc: 73.44
[Train] Epoch: 3 [379648/620022]    Loss: 0.007828   Batch Acc: 79.69
[Train] Epoch: 3 [379712/620022]    Loss: 0.011021   Batch Acc: 75.00
[Train] Epoch: 3 [379776/620022]    Loss: 0.009735   Batch Acc: 75.00
[Train] Epoch: 3 [379840/620022]    Loss: 0.007561   Batch Acc: 78.12
[Train] Epoch: 3 [379904/620022]    Loss: 0.009769   Batch Acc: 76.56
[Train] Epoch: 3 [379968/620022]    Loss: 0.012490   Batch Acc: 65.62
[Train] Epoch: 3 [380032/620022]    Loss: 0.007022   Batch Acc: 84.38
[Train] Epoch: 3 [380096/620022]    Loss: 0.008988   Batch Acc: 76.56
[Train] Epoch: 3 [380160/620022]    Loss: 0.010193   Batch Acc: 70.31
[Train] Epoch: 3 [380224/620022]    Loss: 0.009455   Batch Acc: 73.44
[Train] Epoch: 3 [380288/620022]    Loss: 0.009898   Batch Acc: 73.44
[Train] Epoch: 3 [380352/620022]    Loss: 0.009554   Batch Acc: 71.88
[Train] Epoch: 3 [380416/620022]    Loss: 0.008346   Batch Acc: 79.69
[Train] Epoch: 3 [380480/620022]    Loss: 0.006908   Batch Acc: 87.50
[Train] Epoch: 3 [380544/620022]    Loss: 0.008412   Batch Acc: 78.12
[Train] Epoch: 3 [380608/620022]    Loss: 0.005963   Batch Acc: 85.94
[Train] Epoch: 3 [380672/620022]    Loss: 0.010646   Batch Acc: 73.44
[Train] Epoch: 3 [380736/620022]    Loss: 0.009622   Batch Acc: 75.00
[Train] Epoch: 3 [380800/620022]    Loss: 0.008337   Batch Acc: 78.12
[Train] Epoch: 3 [380864/620022]    Loss: 0.009508   Batch Acc: 76.56
[Train] Epoch: 3 [380928/620022]    Loss: 0.009782   Batch Acc: 76.56
[Train] Epoch: 3 [380992/620022]    Loss: 0.009325   Batch Acc: 79.69
[Train] Epoch: 3 [381056/620022]    Loss: 0.007664   Batch Acc: 82.81
[Train] Epoch: 3 [381120/620022]    Loss: 0.009126   Batch Acc: 73.44
[Train] Epoch: 3 [381184/620022]    Loss: 0.008079   Batch Acc: 75.00
[Train] Epoch: 3 [381248/620022]    Loss: 0.007890   Batch Acc: 82.81
[Train] Epoch: 3 [381312/620022]    Loss: 0.007061   Batch Acc: 87.50
[Train] Epoch: 3 [381376/620022]    Loss: 0.010165   Batch Acc: 70.31
[Train] Epoch: 3 [381440/620022]    Loss: 0.007942   Batch Acc: 87.50
[Train] Epoch: 3 [381504/620022]    Loss: 0.008776   Batch Acc: 79.69
[Train] Epoch: 3 [381568/620022]    Loss: 0.008819   Batch Acc: 70.31
[Train] Epoch: 3 [381632/620022]    Loss: 0.008476   Batch Acc: 79.69
[Train] Epoch: 3 [381696/620022]    Loss: 0.008012   Batch Acc: 79.69
[Train] Epoch: 3 [381760/620022]    Loss: 0.007178   Batch Acc: 79.69
[Train] Epoch: 3 [381824/620022]    Loss: 0.008570   Batch Acc: 76.56
[Train] Epoch: 3 [381888/620022]    Loss: 0.009736   Batch Acc: 78.12
[Train] Epoch: 3 [381952/620022]    Loss: 0.011470   Batch Acc: 71.88
[Train] Epoch: 3 [382016/620022]    Loss: 0.009139   Batch Acc: 76.56
[Train] Epoch: 3 [382080/620022]    Loss: 0.009854   Batch Acc: 70.31
[Train] Epoch: 3 [382144/620022]    Loss: 0.007955   Batch Acc: 78.12
[Train] Epoch: 3 [382208/620022]    Loss: 0.007920   Batch Acc: 79.69
[Train] Epoch: 3 [382272/620022]    Loss: 0.007495   Batch Acc: 82.81
[Train] Epoch: 3 [382336/620022]    Loss: 0.010171   Batch Acc: 68.75
[Train] Epoch: 3 [382400/620022]    Loss: 0.008459   Batch Acc: 84.38
[Train] Epoch: 3 [382464/620022]    Loss: 0.011078   Batch Acc: 64.06
[Train] Epoch: 3 [382528/620022]    Loss: 0.011679   Batch Acc: 71.88
[Train] Epoch: 3 [382592/620022]    Loss: 0.009259   Batch Acc: 71.88
[Train] Epoch: 3 [382656/620022]    Loss: 0.007835   Batch Acc: 78.12
[Train] Epoch: 3 [382720/620022]    Loss: 0.009753   Batch Acc: 71.88
[Train] Epoch: 3 [382784/620022]    Loss: 0.008002   Batch Acc: 81.25
[Train] Epoch: 3 [382848/620022]    Loss: 0.007826   Batch Acc: 79.69
[Train] Epoch: 3 [382912/620022]    Loss: 0.007292   Batch Acc: 85.94
[Train] Epoch: 3 [382976/620022]    Loss: 0.008034   Batch Acc: 85.94
[Train] Epoch: 3 [383040/620022]    Loss: 0.010171   Batch Acc: 73.44
[Train] Epoch: 3 [383104/620022]    Loss: 0.007004   Batch Acc: 82.81
[Train] Epoch: 3 [383168/620022]    Loss: 0.010759   Batch Acc: 71.88
[Train] Epoch: 3 [383232/620022]    Loss: 0.010868   Batch Acc: 73.44
[Train] Epoch: 3 [383296/620022]    Loss: 0.007387   Batch Acc: 82.81
[Train] Epoch: 3 [383360/620022]    Loss: 0.008862   Batch Acc: 73.44
[Train] Epoch: 3 [383424/620022]    Loss: 0.008596   Batch Acc: 76.56
[Train] Epoch: 3 [383488/620022]    Loss: 0.007157   Batch Acc: 84.38
[Train] Epoch: 3 [383552/620022]    Loss: 0.006430   Batch Acc: 85.94
[Train] Epoch: 3 [383616/620022]    Loss: 0.010542   Batch Acc: 75.00
[Train] Epoch: 3 [383680/620022]    Loss: 0.009291   Batch Acc: 73.44
[Train] Epoch: 3 [383744/620022]    Loss: 0.006486   Batch Acc: 84.38
[Train] Epoch: 3 [383808/620022]    Loss: 0.007373   Batch Acc: 79.69
[Train] Epoch: 3 [383872/620022]    Loss: 0.010095   Batch Acc: 73.44
[Train] Epoch: 3 [383936/620022]    Loss: 0.008526   Batch Acc: 75.00
[Train] Epoch: 3 [384000/620022]    Loss: 0.008572   Batch Acc: 75.00
[Train] Epoch: 3 [384064/620022]    Loss: 0.009193   Batch Acc: 78.12
[Train] Epoch: 3 [384128/620022]    Loss: 0.006877   Batch Acc: 85.94
[Train] Epoch: 3 [384192/620022]    Loss: 0.008812   Batch Acc: 79.69
[Train] Epoch: 3 [384256/620022]    Loss: 0.008127   Batch Acc: 79.69
[Train] Epoch: 3 [384320/620022]    Loss: 0.006771   Batch Acc: 85.94
[Train] Epoch: 3 [384384/620022]    Loss: 0.009117   Batch Acc: 73.44
[Train] Epoch: 3 [384448/620022]    Loss: 0.006864   Batch Acc: 79.69
[Train] Epoch: 3 [384512/620022]    Loss: 0.007005   Batch Acc: 82.81
[Train] Epoch: 3 [384576/620022]    Loss: 0.006658   Batch Acc: 84.38
[Train] Epoch: 3 [384640/620022]    Loss: 0.007624   Batch Acc: 78.12
[Train] Epoch: 3 [384704/620022]    Loss: 0.008967   Batch Acc: 78.12
[Train] Epoch: 3 [384768/620022]    Loss: 0.005784   Batch Acc: 89.06
[Train] Epoch: 3 [384832/620022]    Loss: 0.010341   Batch Acc: 67.19
[Train] Epoch: 3 [384896/620022]    Loss: 0.008815   Batch Acc: 71.88
[Train] Epoch: 3 [384960/620022]    Loss: 0.011267   Batch Acc: 71.88
[Train] Epoch: 3 [385024/620022]    Loss: 0.008588   Batch Acc: 75.00
[Train] Epoch: 3 [385088/620022]    Loss: 0.012061   Batch Acc: 68.75
[Train] Epoch: 3 [385152/620022]    Loss: 0.010343   Batch Acc: 75.00
[Train] Epoch: 3 [385216/620022]    Loss: 0.010874   Batch Acc: 68.75
[Train] Epoch: 3 [385280/620022]    Loss: 0.007978   Batch Acc: 82.81
[Train] Epoch: 3 [385344/620022]    Loss: 0.007058   Batch Acc: 76.56
[Train] Epoch: 3 [385408/620022]    Loss: 0.008089   Batch Acc: 71.88
[Train] Epoch: 3 [385472/620022]    Loss: 0.007090   Batch Acc: 82.81
[Train] Epoch: 3 [385536/620022]    Loss: 0.010118   Batch Acc: 71.88
[Train] Epoch: 3 [385600/620022]    Loss: 0.009212   Batch Acc: 78.12
[Train] Epoch: 3 [385664/620022]    Loss: 0.007954   Batch Acc: 82.81
[Train] Epoch: 3 [385728/620022]    Loss: 0.008896   Batch Acc: 75.00
[Train] Epoch: 3 [385792/620022]    Loss: 0.011448   Batch Acc: 68.75
[Train] Epoch: 3 [385856/620022]    Loss: 0.008438   Batch Acc: 79.69
[Train] Epoch: 3 [385920/620022]    Loss: 0.007562   Batch Acc: 84.38
[Train] Epoch: 3 [385984/620022]    Loss: 0.009054   Batch Acc: 71.88
[Train] Epoch: 3 [386048/620022]    Loss: 0.007422   Batch Acc: 82.81
[Train] Epoch: 3 [386112/620022]    Loss: 0.010370   Batch Acc: 71.88
[Train] Epoch: 3 [386176/620022]    Loss: 0.010896   Batch Acc: 70.31
[Train] Epoch: 3 [386240/620022]    Loss: 0.008591   Batch Acc: 79.69
[Train] Epoch: 3 [386304/620022]    Loss: 0.007853   Batch Acc: 79.69
[Train] Epoch: 3 [386368/620022]    Loss: 0.009604   Batch Acc: 73.44
[Train] Epoch: 3 [386432/620022]    Loss: 0.008628   Batch Acc: 78.12
[Train] Epoch: 3 [386496/620022]    Loss: 0.008037   Batch Acc: 79.69
[Train] Epoch: 3 [386560/620022]    Loss: 0.006759   Batch Acc: 84.38
[Train] Epoch: 3 [386624/620022]    Loss: 0.007495   Batch Acc: 84.38
[Train] Epoch: 3 [386688/620022]    Loss: 0.010121   Batch Acc: 71.88
[Train] Epoch: 3 [386752/620022]    Loss: 0.008451   Batch Acc: 73.44
[Train] Epoch: 3 [386816/620022]    Loss: 0.006545   Batch Acc: 85.94
[Train] Epoch: 3 [386880/620022]    Loss: 0.009574   Batch Acc: 76.56
[Train] Epoch: 3 [386944/620022]    Loss: 0.008631   Batch Acc: 75.00
[Train] Epoch: 3 [387008/620022]    Loss: 0.007236   Batch Acc: 79.69
[Train] Epoch: 3 [387072/620022]    Loss: 0.008617   Batch Acc: 81.25
[Train] Epoch: 3 [387136/620022]    Loss: 0.008548   Batch Acc: 76.56
[Train] Epoch: 3 [387200/620022]    Loss: 0.008598   Batch Acc: 79.69
[Train] Epoch: 3 [387264/620022]    Loss: 0.009350   Batch Acc: 81.25
[Train] Epoch: 3 [387328/620022]    Loss: 0.008220   Batch Acc: 81.25
[Train] Epoch: 3 [387392/620022]    Loss: 0.008784   Batch Acc: 79.69
[Train] Epoch: 3 [387456/620022]    Loss: 0.009830   Batch Acc: 71.88
[Train] Epoch: 3 [387520/620022]    Loss: 0.008809   Batch Acc: 81.25
[Train] Epoch: 3 [387584/620022]    Loss: 0.007265   Batch Acc: 84.38
[Train] Epoch: 3 [387648/620022]    Loss: 0.006064   Batch Acc: 90.62
[Train] Epoch: 3 [387712/620022]    Loss: 0.007231   Batch Acc: 82.81
[Train] Epoch: 3 [387776/620022]    Loss: 0.009908   Batch Acc: 70.31
[Train] Epoch: 3 [387840/620022]    Loss: 0.009526   Batch Acc: 70.31
[Train] Epoch: 3 [387904/620022]    Loss: 0.010808   Batch Acc: 75.00
[Train] Epoch: 3 [387968/620022]    Loss: 0.008061   Batch Acc: 78.12
[Train] Epoch: 3 [388032/620022]    Loss: 0.009864   Batch Acc: 70.31
[Train] Epoch: 3 [388096/620022]    Loss: 0.008626   Batch Acc: 78.12
[Train] Epoch: 3 [388160/620022]    Loss: 0.007374   Batch Acc: 84.38
[Train] Epoch: 3 [388224/620022]    Loss: 0.007179   Batch Acc: 82.81
[Train] Epoch: 3 [388288/620022]    Loss: 0.008262   Batch Acc: 81.25
[Train] Epoch: 3 [388352/620022]    Loss: 0.008518   Batch Acc: 75.00
[Train] Epoch: 3 [388416/620022]    Loss: 0.009060   Batch Acc: 81.25
[Train] Epoch: 3 [388480/620022]    Loss: 0.008100   Batch Acc: 79.69
[Train] Epoch: 3 [388544/620022]    Loss: 0.007004   Batch Acc: 85.94
[Train] Epoch: 3 [388608/620022]    Loss: 0.009553   Batch Acc: 71.88
[Train] Epoch: 3 [388672/620022]    Loss: 0.009240   Batch Acc: 75.00
[Train] Epoch: 3 [388736/620022]    Loss: 0.008708   Batch Acc: 75.00
[Train] Epoch: 3 [388800/620022]    Loss: 0.006608   Batch Acc: 87.50
[Train] Epoch: 3 [388864/620022]    Loss: 0.007651   Batch Acc: 81.25
[Train] Epoch: 3 [388928/620022]    Loss: 0.009645   Batch Acc: 76.56
[Train] Epoch: 3 [388992/620022]    Loss: 0.009355   Batch Acc: 71.88
[Train] Epoch: 3 [389056/620022]    Loss: 0.007639   Batch Acc: 82.81
[Train] Epoch: 3 [389120/620022]    Loss: 0.010216   Batch Acc: 71.88
[Train] Epoch: 3 [389184/620022]    Loss: 0.008597   Batch Acc: 75.00
[Train] Epoch: 3 [389248/620022]    Loss: 0.007418   Batch Acc: 79.69
[Train] Epoch: 3 [389312/620022]    Loss: 0.009884   Batch Acc: 78.12
[Train] Epoch: 3 [389376/620022]    Loss: 0.010472   Batch Acc: 71.88
[Train] Epoch: 3 [389440/620022]    Loss: 0.008800   Batch Acc: 82.81
[Train] Epoch: 3 [389504/620022]    Loss: 0.008648   Batch Acc: 78.12
[Train] Epoch: 3 [389568/620022]    Loss: 0.007287   Batch Acc: 78.12
[Train] Epoch: 3 [389632/620022]    Loss: 0.005846   Batch Acc: 87.50
[Train] Epoch: 3 [389696/620022]    Loss: 0.008153   Batch Acc: 78.12
[Train] Epoch: 3 [389760/620022]    Loss: 0.008115   Batch Acc: 78.12
[Train] Epoch: 3 [389824/620022]    Loss: 0.008215   Batch Acc: 81.25
[Train] Epoch: 3 [389888/620022]    Loss: 0.009419   Batch Acc: 70.31
[Train] Epoch: 3 [389952/620022]    Loss: 0.010421   Batch Acc: 75.00
[Train] Epoch: 3 [390016/620022]    Loss: 0.012967   Batch Acc: 65.62
[Train] Epoch: 3 [390080/620022]    Loss: 0.007571   Batch Acc: 81.25
[Train] Epoch: 3 [390144/620022]    Loss: 0.009014   Batch Acc: 76.56
[Train] Epoch: 3 [390208/620022]    Loss: 0.009347   Batch Acc: 75.00
[Train] Epoch: 3 [390272/620022]    Loss: 0.008443   Batch Acc: 79.69
[Train] Epoch: 3 [390336/620022]    Loss: 0.008606   Batch Acc: 79.69
[Train] Epoch: 3 [390400/620022]    Loss: 0.010485   Batch Acc: 76.56
[Train] Epoch: 3 [390464/620022]    Loss: 0.008288   Batch Acc: 84.38
[Train] Epoch: 3 [390528/620022]    Loss: 0.007558   Batch Acc: 81.25
[Train] Epoch: 3 [390592/620022]    Loss: 0.010221   Batch Acc: 81.25
[Train] Epoch: 3 [390656/620022]    Loss: 0.008788   Batch Acc: 82.81
[Train] Epoch: 3 [390720/620022]    Loss: 0.009869   Batch Acc: 75.00
[Train] Epoch: 3 [390784/620022]    Loss: 0.007101   Batch Acc: 87.50
[Train] Epoch: 3 [390848/620022]    Loss: 0.007680   Batch Acc: 82.81
[Train] Epoch: 3 [390912/620022]    Loss: 0.011940   Batch Acc: 65.62
[Train] Epoch: 3 [390976/620022]    Loss: 0.006813   Batch Acc: 85.94
[Train] Epoch: 3 [391040/620022]    Loss: 0.007015   Batch Acc: 84.38
[Train] Epoch: 3 [391104/620022]    Loss: 0.006770   Batch Acc: 85.94
[Train] Epoch: 3 [391168/620022]    Loss: 0.011486   Batch Acc: 65.62
[Train] Epoch: 3 [391232/620022]    Loss: 0.007506   Batch Acc: 84.38
[Train] Epoch: 3 [391296/620022]    Loss: 0.009556   Batch Acc: 68.75
[Train] Epoch: 3 [391360/620022]    Loss: 0.008555   Batch Acc: 78.12
[Train] Epoch: 3 [391424/620022]    Loss: 0.006761   Batch Acc: 82.81
[Train] Epoch: 3 [391488/620022]    Loss: 0.008428   Batch Acc: 81.25
[Train] Epoch: 3 [391552/620022]    Loss: 0.009029   Batch Acc: 79.69
[Train] Epoch: 3 [391616/620022]    Loss: 0.009819   Batch Acc: 79.69
[Train] Epoch: 3 [391680/620022]    Loss: 0.006607   Batch Acc: 84.38
[Train] Epoch: 3 [391744/620022]    Loss: 0.005856   Batch Acc: 89.06
[Train] Epoch: 3 [391808/620022]    Loss: 0.008940   Batch Acc: 75.00
[Train] Epoch: 3 [391872/620022]    Loss: 0.011130   Batch Acc: 70.31
[Train] Epoch: 3 [391936/620022]    Loss: 0.010422   Batch Acc: 71.88
[Train] Epoch: 3 [392000/620022]    Loss: 0.007758   Batch Acc: 78.12
[Train] Epoch: 3 [392064/620022]    Loss: 0.007448   Batch Acc: 81.25
[Train] Epoch: 3 [392128/620022]    Loss: 0.007501   Batch Acc: 84.38
[Train] Epoch: 3 [392192/620022]    Loss: 0.009105   Batch Acc: 78.12
[Train] Epoch: 3 [392256/620022]    Loss: 0.008256   Batch Acc: 78.12
[Train] Epoch: 3 [392320/620022]    Loss: 0.007873   Batch Acc: 78.12
[Train] Epoch: 3 [392384/620022]    Loss: 0.009313   Batch Acc: 81.25
[Train] Epoch: 3 [392448/620022]    Loss: 0.009525   Batch Acc: 76.56
[Train] Epoch: 3 [392512/620022]    Loss: 0.007907   Batch Acc: 81.25
[Train] Epoch: 3 [392576/620022]    Loss: 0.008506   Batch Acc: 76.56
[Train] Epoch: 3 [392640/620022]    Loss: 0.008832   Batch Acc: 75.00
[Train] Epoch: 3 [392704/620022]    Loss: 0.008429   Batch Acc: 79.69
[Train] Epoch: 3 [392768/620022]    Loss: 0.009416   Batch Acc: 75.00
[Train] Epoch: 3 [392832/620022]    Loss: 0.010642   Batch Acc: 73.44
[Train] Epoch: 3 [392896/620022]    Loss: 0.007865   Batch Acc: 78.12
[Train] Epoch: 3 [392960/620022]    Loss: 0.007770   Batch Acc: 84.38
[Train] Epoch: 3 [393024/620022]    Loss: 0.008091   Batch Acc: 78.12
[Train] Epoch: 3 [393088/620022]    Loss: 0.008737   Batch Acc: 78.12
[Train] Epoch: 3 [393152/620022]    Loss: 0.007798   Batch Acc: 82.81
[Train] Epoch: 3 [393216/620022]    Loss: 0.010077   Batch Acc: 75.00
[Train] Epoch: 3 [393280/620022]    Loss: 0.008626   Batch Acc: 76.56
[Train] Epoch: 3 [393344/620022]    Loss: 0.007434   Batch Acc: 84.38
[Train] Epoch: 3 [393408/620022]    Loss: 0.008218   Batch Acc: 75.00
[Train] Epoch: 3 [393472/620022]    Loss: 0.009485   Batch Acc: 71.88
[Train] Epoch: 3 [393536/620022]    Loss: 0.009901   Batch Acc: 81.25
[Train] Epoch: 3 [393600/620022]    Loss: 0.006385   Batch Acc: 81.25
[Train] Epoch: 3 [393664/620022]    Loss: 0.009008   Batch Acc: 76.56
[Train] Epoch: 3 [393728/620022]    Loss: 0.008207   Batch Acc: 78.12
[Train] Epoch: 3 [393792/620022]    Loss: 0.009738   Batch Acc: 76.56
[Train] Epoch: 3 [393856/620022]    Loss: 0.005822   Batch Acc: 89.06
[Train] Epoch: 3 [393920/620022]    Loss: 0.006063   Batch Acc: 84.38
[Train] Epoch: 3 [393984/620022]    Loss: 0.006638   Batch Acc: 85.94
[Train] Epoch: 3 [394048/620022]    Loss: 0.008436   Batch Acc: 76.56
[Train] Epoch: 3 [394112/620022]    Loss: 0.008868   Batch Acc: 75.00
[Train] Epoch: 3 [394176/620022]    Loss: 0.005704   Batch Acc: 84.38
[Train] Epoch: 3 [394240/620022]    Loss: 0.006141   Batch Acc: 85.94
[Train] Epoch: 3 [394304/620022]    Loss: 0.007997   Batch Acc: 79.69
[Train] Epoch: 3 [394368/620022]    Loss: 0.011863   Batch Acc: 65.62
[Train] Epoch: 3 [394432/620022]    Loss: 0.005131   Batch Acc: 89.06
[Train] Epoch: 3 [394496/620022]    Loss: 0.009030   Batch Acc: 73.44
[Train] Epoch: 3 [394560/620022]    Loss: 0.007106   Batch Acc: 90.62
[Train] Epoch: 3 [394624/620022]    Loss: 0.006350   Batch Acc: 82.81
[Train] Epoch: 3 [394688/620022]    Loss: 0.008893   Batch Acc: 76.56
[Train] Epoch: 3 [394752/620022]    Loss: 0.007573   Batch Acc: 76.56
[Train] Epoch: 3 [394816/620022]    Loss: 0.006822   Batch Acc: 85.94
[Train] Epoch: 3 [394880/620022]    Loss: 0.008631   Batch Acc: 71.88
[Train] Epoch: 3 [394944/620022]    Loss: 0.008197   Batch Acc: 81.25
[Train] Epoch: 3 [395008/620022]    Loss: 0.009480   Batch Acc: 76.56
[Train] Epoch: 3 [395072/620022]    Loss: 0.008243   Batch Acc: 78.12
[Train] Epoch: 3 [395136/620022]    Loss: 0.008407   Batch Acc: 71.88
[Train] Epoch: 3 [395200/620022]    Loss: 0.009283   Batch Acc: 76.56
[Train] Epoch: 3 [395264/620022]    Loss: 0.008038   Batch Acc: 81.25
[Train] Epoch: 3 [395328/620022]    Loss: 0.008072   Batch Acc: 78.12
[Train] Epoch: 3 [395392/620022]    Loss: 0.009750   Batch Acc: 75.00
[Train] Epoch: 3 [395456/620022]    Loss: 0.009332   Batch Acc: 73.44
[Train] Epoch: 3 [395520/620022]    Loss: 0.007529   Batch Acc: 81.25
[Train] Epoch: 3 [395584/620022]    Loss: 0.006418   Batch Acc: 87.50
[Train] Epoch: 3 [395648/620022]    Loss: 0.006270   Batch Acc: 87.50
[Train] Epoch: 3 [395712/620022]    Loss: 0.010713   Batch Acc: 71.88
[Train] Epoch: 3 [395776/620022]    Loss: 0.007496   Batch Acc: 81.25
[Train] Epoch: 3 [395840/620022]    Loss: 0.008220   Batch Acc: 79.69
[Train] Epoch: 3 [395904/620022]    Loss: 0.008944   Batch Acc: 76.56
[Train] Epoch: 3 [395968/620022]    Loss: 0.010025   Batch Acc: 78.12
[Train] Epoch: 3 [396032/620022]    Loss: 0.009144   Batch Acc: 76.56
[Train] Epoch: 3 [396096/620022]    Loss: 0.007543   Batch Acc: 81.25
[Train] Epoch: 3 [396160/620022]    Loss: 0.011893   Batch Acc: 67.19
[Train] Epoch: 3 [396224/620022]    Loss: 0.008484   Batch Acc: 75.00
[Train] Epoch: 3 [396288/620022]    Loss: 0.009133   Batch Acc: 78.12
[Train] Epoch: 3 [396352/620022]    Loss: 0.010738   Batch Acc: 73.44
[Train] Epoch: 3 [396416/620022]    Loss: 0.009461   Batch Acc: 70.31
[Train] Epoch: 3 [396480/620022]    Loss: 0.008071   Batch Acc: 79.69
[Train] Epoch: 3 [396544/620022]    Loss: 0.006517   Batch Acc: 85.94
[Train] Epoch: 3 [396608/620022]    Loss: 0.007882   Batch Acc: 76.56
[Train] Epoch: 3 [396672/620022]    Loss: 0.009012   Batch Acc: 75.00
[Train] Epoch: 3 [396736/620022]    Loss: 0.007000   Batch Acc: 90.62
[Train] Epoch: 3 [396800/620022]    Loss: 0.009606   Batch Acc: 71.88
[Train] Epoch: 3 [396864/620022]    Loss: 0.009953   Batch Acc: 70.31
[Train] Epoch: 3 [396928/620022]    Loss: 0.008913   Batch Acc: 81.25
[Train] Epoch: 3 [396992/620022]    Loss: 0.007596   Batch Acc: 76.56
[Train] Epoch: 3 [397056/620022]    Loss: 0.009266   Batch Acc: 78.12
[Train] Epoch: 3 [397120/620022]    Loss: 0.007389   Batch Acc: 79.69
[Train] Epoch: 3 [397184/620022]    Loss: 0.009124   Batch Acc: 71.88
[Train] Epoch: 3 [397248/620022]    Loss: 0.008775   Batch Acc: 78.12
[Train] Epoch: 3 [397312/620022]    Loss: 0.008029   Batch Acc: 79.69
[Train] Epoch: 3 [397376/620022]    Loss: 0.006892   Batch Acc: 84.38
[Train] Epoch: 3 [397440/620022]    Loss: 0.008703   Batch Acc: 73.44
[Train] Epoch: 3 [397504/620022]    Loss: 0.006073   Batch Acc: 87.50
[Train] Epoch: 3 [397568/620022]    Loss: 0.007079   Batch Acc: 81.25
[Train] Epoch: 3 [397632/620022]    Loss: 0.009828   Batch Acc: 78.12
[Train] Epoch: 3 [397696/620022]    Loss: 0.007114   Batch Acc: 82.81
[Train] Epoch: 3 [397760/620022]    Loss: 0.010395   Batch Acc: 75.00
[Train] Epoch: 3 [397824/620022]    Loss: 0.008306   Batch Acc: 78.12
[Train] Epoch: 3 [397888/620022]    Loss: 0.009218   Batch Acc: 76.56
[Train] Epoch: 3 [397952/620022]    Loss: 0.008164   Batch Acc: 78.12
[Train] Epoch: 3 [398016/620022]    Loss: 0.009563   Batch Acc: 70.31
[Train] Epoch: 3 [398080/620022]    Loss: 0.008210   Batch Acc: 76.56
[Train] Epoch: 3 [398144/620022]    Loss: 0.008230   Batch Acc: 78.12
[Train] Epoch: 3 [398208/620022]    Loss: 0.007772   Batch Acc: 81.25
[Train] Epoch: 3 [398272/620022]    Loss: 0.008953   Batch Acc: 79.69
[Train] Epoch: 3 [398336/620022]    Loss: 0.007150   Batch Acc: 82.81
[Train] Epoch: 3 [398400/620022]    Loss: 0.009003   Batch Acc: 79.69
[Train] Epoch: 3 [398464/620022]    Loss: 0.007878   Batch Acc: 76.56
[Train] Epoch: 3 [398528/620022]    Loss: 0.007546   Batch Acc: 82.81
[Train] Epoch: 3 [398592/620022]    Loss: 0.010839   Batch Acc: 76.56
[Train] Epoch: 3 [398656/620022]    Loss: 0.009645   Batch Acc: 73.44
[Train] Epoch: 3 [398720/620022]    Loss: 0.007610   Batch Acc: 79.69
[Train] Epoch: 3 [398784/620022]    Loss: 0.008462   Batch Acc: 84.38
[Train] Epoch: 3 [398848/620022]    Loss: 0.006199   Batch Acc: 85.94
[Train] Epoch: 3 [398912/620022]    Loss: 0.011801   Batch Acc: 65.62
[Train] Epoch: 3 [398976/620022]    Loss: 0.008340   Batch Acc: 79.69
[Train] Epoch: 3 [399040/620022]    Loss: 0.009124   Batch Acc: 78.12
[Train] Epoch: 3 [399104/620022]    Loss: 0.007240   Batch Acc: 87.50
[Train] Epoch: 3 [399168/620022]    Loss: 0.008521   Batch Acc: 79.69
[Train] Epoch: 3 [399232/620022]    Loss: 0.010619   Batch Acc: 78.12
[Train] Epoch: 3 [399296/620022]    Loss: 0.007236   Batch Acc: 79.69
[Train] Epoch: 3 [399360/620022]    Loss: 0.009452   Batch Acc: 79.69
[Train] Epoch: 3 [399424/620022]    Loss: 0.006198   Batch Acc: 85.94
[Train] Epoch: 3 [399488/620022]    Loss: 0.007827   Batch Acc: 81.25
[Train] Epoch: 3 [399552/620022]    Loss: 0.009882   Batch Acc: 76.56
[Train] Epoch: 3 [399616/620022]    Loss: 0.006512   Batch Acc: 87.50
[Train] Epoch: 3 [399680/620022]    Loss: 0.007442   Batch Acc: 81.25
[Train] Epoch: 3 [399744/620022]    Loss: 0.011069   Batch Acc: 73.44
[Train] Epoch: 3 [399808/620022]    Loss: 0.009589   Batch Acc: 76.56
[Train] Epoch: 3 [399872/620022]    Loss: 0.009294   Batch Acc: 71.88
[Train] Epoch: 3 [399936/620022]    Loss: 0.008777   Batch Acc: 73.44
[Train] Epoch: 3 [400000/620022]    Loss: 0.009972   Batch Acc: 70.31
[Train] Epoch: 3 [400064/620022]    Loss: 0.008787   Batch Acc: 70.31
[Train] Epoch: 3 [400128/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 3 [400192/620022]    Loss: 0.011218   Batch Acc: 67.19
[Train] Epoch: 3 [400256/620022]    Loss: 0.008677   Batch Acc: 81.25
[Train] Epoch: 3 [400320/620022]    Loss: 0.008717   Batch Acc: 79.69
[Train] Epoch: 3 [400384/620022]    Loss: 0.008410   Batch Acc: 73.44
[Train] Epoch: 3 [400448/620022]    Loss: 0.010764   Batch Acc: 65.62
[Train] Epoch: 3 [400512/620022]    Loss: 0.010266   Batch Acc: 76.56
[Train] Epoch: 3 [400576/620022]    Loss: 0.007612   Batch Acc: 81.25
[Train] Epoch: 3 [400640/620022]    Loss: 0.010767   Batch Acc: 68.75
[Train] Epoch: 3 [400704/620022]    Loss: 0.008012   Batch Acc: 78.12
[Train] Epoch: 3 [400768/620022]    Loss: 0.009365   Batch Acc: 71.88
[Train] Epoch: 3 [400832/620022]    Loss: 0.008200   Batch Acc: 81.25
[Train] Epoch: 3 [400896/620022]    Loss: 0.006760   Batch Acc: 84.38
[Train] Epoch: 3 [400960/620022]    Loss: 0.006075   Batch Acc: 82.81
[Train] Epoch: 3 [401024/620022]    Loss: 0.007302   Batch Acc: 85.94
[Train] Epoch: 3 [401088/620022]    Loss: 0.007824   Batch Acc: 78.12
[Train] Epoch: 3 [401152/620022]    Loss: 0.008913   Batch Acc: 81.25
[Train] Epoch: 3 [401216/620022]    Loss: 0.009032   Batch Acc: 82.81
[Train] Epoch: 3 [401280/620022]    Loss: 0.008515   Batch Acc: 79.69
[Train] Epoch: 3 [401344/620022]    Loss: 0.009059   Batch Acc: 75.00
[Train] Epoch: 3 [401408/620022]    Loss: 0.006287   Batch Acc: 84.38
[Train] Epoch: 3 [401472/620022]    Loss: 0.009665   Batch Acc: 76.56
[Train] Epoch: 3 [401536/620022]    Loss: 0.007395   Batch Acc: 81.25
[Train] Epoch: 3 [401600/620022]    Loss: 0.008282   Batch Acc: 81.25
[Train] Epoch: 3 [401664/620022]    Loss: 0.007682   Batch Acc: 81.25
[Train] Epoch: 3 [401728/620022]    Loss: 0.007551   Batch Acc: 78.12
[Train] Epoch: 3 [401792/620022]    Loss: 0.007062   Batch Acc: 82.81
[Train] Epoch: 3 [401856/620022]    Loss: 0.009486   Batch Acc: 78.12
[Train] Epoch: 3 [401920/620022]    Loss: 0.008017   Batch Acc: 78.12
[Train] Epoch: 3 [401984/620022]    Loss: 0.009790   Batch Acc: 71.88
[Train] Epoch: 3 [402048/620022]    Loss: 0.011103   Batch Acc: 70.31
[Train] Epoch: 3 [402112/620022]    Loss: 0.007790   Batch Acc: 85.94
[Train] Epoch: 3 [402176/620022]    Loss: 0.007016   Batch Acc: 85.94
[Train] Epoch: 3 [402240/620022]    Loss: 0.011886   Batch Acc: 70.31
[Train] Epoch: 3 [402304/620022]    Loss: 0.009677   Batch Acc: 75.00
[Train] Epoch: 3 [402368/620022]    Loss: 0.010123   Batch Acc: 71.88
[Train] Epoch: 3 [402432/620022]    Loss: 0.005995   Batch Acc: 85.94
[Train] Epoch: 3 [402496/620022]    Loss: 0.007551   Batch Acc: 75.00
[Train] Epoch: 3 [402560/620022]    Loss: 0.006526   Batch Acc: 85.94
[Train] Epoch: 3 [402624/620022]    Loss: 0.007006   Batch Acc: 85.94
[Train] Epoch: 3 [402688/620022]    Loss: 0.008000   Batch Acc: 84.38
[Train] Epoch: 3 [402752/620022]    Loss: 0.008910   Batch Acc: 81.25
[Train] Epoch: 3 [402816/620022]    Loss: 0.008549   Batch Acc: 73.44
[Train] Epoch: 3 [402880/620022]    Loss: 0.008709   Batch Acc: 75.00
[Train] Epoch: 3 [402944/620022]    Loss: 0.007072   Batch Acc: 84.38
[Train] Epoch: 3 [403008/620022]    Loss: 0.007481   Batch Acc: 78.12
[Train] Epoch: 3 [403072/620022]    Loss: 0.011248   Batch Acc: 70.31
[Train] Epoch: 3 [403136/620022]    Loss: 0.009351   Batch Acc: 79.69
[Train] Epoch: 3 [403200/620022]    Loss: 0.009099   Batch Acc: 75.00
[Train] Epoch: 3 [403264/620022]    Loss: 0.008536   Batch Acc: 75.00
[Train] Epoch: 3 [403328/620022]    Loss: 0.007668   Batch Acc: 79.69
[Train] Epoch: 3 [403392/620022]    Loss: 0.010225   Batch Acc: 70.31
[Train] Epoch: 3 [403456/620022]    Loss: 0.008033   Batch Acc: 76.56
[Train] Epoch: 3 [403520/620022]    Loss: 0.011727   Batch Acc: 65.62
[Train] Epoch: 3 [403584/620022]    Loss: 0.009133   Batch Acc: 79.69
[Train] Epoch: 3 [403648/620022]    Loss: 0.008621   Batch Acc: 79.69
[Train] Epoch: 3 [403712/620022]    Loss: 0.008143   Batch Acc: 76.56
[Train] Epoch: 3 [403776/620022]    Loss: 0.008825   Batch Acc: 76.56
[Train] Epoch: 3 [403840/620022]    Loss: 0.007584   Batch Acc: 82.81
[Train] Epoch: 3 [403904/620022]    Loss: 0.008318   Batch Acc: 79.69
[Train] Epoch: 3 [403968/620022]    Loss: 0.009099   Batch Acc: 79.69
[Train] Epoch: 3 [404032/620022]    Loss: 0.008291   Batch Acc: 78.12
[Train] Epoch: 3 [404096/620022]    Loss: 0.008229   Batch Acc: 76.56
[Train] Epoch: 3 [404160/620022]    Loss: 0.008077   Batch Acc: 79.69
[Train] Epoch: 3 [404224/620022]    Loss: 0.006903   Batch Acc: 82.81
[Train] Epoch: 3 [404288/620022]    Loss: 0.009265   Batch Acc: 78.12
[Train] Epoch: 3 [404352/620022]    Loss: 0.007818   Batch Acc: 81.25
[Train] Epoch: 3 [404416/620022]    Loss: 0.009937   Batch Acc: 71.88
[Train] Epoch: 3 [404480/620022]    Loss: 0.008533   Batch Acc: 76.56
[Train] Epoch: 3 [404544/620022]    Loss: 0.007552   Batch Acc: 76.56
[Train] Epoch: 3 [404608/620022]    Loss: 0.009939   Batch Acc: 71.88
[Train] Epoch: 3 [404672/620022]    Loss: 0.008893   Batch Acc: 78.12
[Train] Epoch: 3 [404736/620022]    Loss: 0.008970   Batch Acc: 78.12
[Train] Epoch: 3 [404800/620022]    Loss: 0.007386   Batch Acc: 84.38
[Train] Epoch: 3 [404864/620022]    Loss: 0.011239   Batch Acc: 68.75
[Train] Epoch: 3 [404928/620022]    Loss: 0.006990   Batch Acc: 81.25
[Train] Epoch: 3 [404992/620022]    Loss: 0.008658   Batch Acc: 78.12
[Train] Epoch: 3 [405056/620022]    Loss: 0.009535   Batch Acc: 76.56
[Train] Epoch: 3 [405120/620022]    Loss: 0.008373   Batch Acc: 79.69
[Train] Epoch: 3 [405184/620022]    Loss: 0.007564   Batch Acc: 79.69
[Train] Epoch: 3 [405248/620022]    Loss: 0.007429   Batch Acc: 81.25
[Train] Epoch: 3 [405312/620022]    Loss: 0.007187   Batch Acc: 84.38
[Train] Epoch: 3 [405376/620022]    Loss: 0.008462   Batch Acc: 78.12
[Train] Epoch: 3 [405440/620022]    Loss: 0.011782   Batch Acc: 78.12
[Train] Epoch: 3 [405504/620022]    Loss: 0.009120   Batch Acc: 81.25
[Train] Epoch: 3 [405568/620022]    Loss: 0.009185   Batch Acc: 75.00
[Train] Epoch: 3 [405632/620022]    Loss: 0.006576   Batch Acc: 90.62
[Train] Epoch: 3 [405696/620022]    Loss: 0.007711   Batch Acc: 81.25
[Train] Epoch: 3 [405760/620022]    Loss: 0.007754   Batch Acc: 82.81
[Train] Epoch: 3 [405824/620022]    Loss: 0.006166   Batch Acc: 85.94
[Train] Epoch: 3 [405888/620022]    Loss: 0.010132   Batch Acc: 70.31
[Train] Epoch: 3 [405952/620022]    Loss: 0.008967   Batch Acc: 78.12
[Train] Epoch: 3 [406016/620022]    Loss: 0.008425   Batch Acc: 73.44
[Train] Epoch: 3 [406080/620022]    Loss: 0.010039   Batch Acc: 68.75
[Train] Epoch: 3 [406144/620022]    Loss: 0.008544   Batch Acc: 78.12
[Train] Epoch: 3 [406208/620022]    Loss: 0.008336   Batch Acc: 81.25
[Train] Epoch: 3 [406272/620022]    Loss: 0.008173   Batch Acc: 81.25
[Train] Epoch: 3 [406336/620022]    Loss: 0.010326   Batch Acc: 75.00
[Train] Epoch: 3 [406400/620022]    Loss: 0.007826   Batch Acc: 78.12
[Train] Epoch: 3 [406464/620022]    Loss: 0.010589   Batch Acc: 73.44
[Train] Epoch: 3 [406528/620022]    Loss: 0.009171   Batch Acc: 75.00
[Train] Epoch: 3 [406592/620022]    Loss: 0.007234   Batch Acc: 81.25
[Train] Epoch: 3 [406656/620022]    Loss: 0.007959   Batch Acc: 76.56
[Train] Epoch: 3 [406720/620022]    Loss: 0.008185   Batch Acc: 78.12
[Train] Epoch: 3 [406784/620022]    Loss: 0.008184   Batch Acc: 79.69
[Train] Epoch: 3 [406848/620022]    Loss: 0.007677   Batch Acc: 79.69
[Train] Epoch: 3 [406912/620022]    Loss: 0.009344   Batch Acc: 71.88
[Train] Epoch: 3 [406976/620022]    Loss: 0.011803   Batch Acc: 68.75
[Train] Epoch: 3 [407040/620022]    Loss: 0.008968   Batch Acc: 73.44
[Train] Epoch: 3 [407104/620022]    Loss: 0.008654   Batch Acc: 78.12
[Train] Epoch: 3 [407168/620022]    Loss: 0.009177   Batch Acc: 75.00
[Train] Epoch: 3 [407232/620022]    Loss: 0.007575   Batch Acc: 78.12
[Train] Epoch: 3 [407296/620022]    Loss: 0.011627   Batch Acc: 71.88
[Train] Epoch: 3 [407360/620022]    Loss: 0.007322   Batch Acc: 84.38
[Train] Epoch: 3 [407424/620022]    Loss: 0.009985   Batch Acc: 70.31
[Train] Epoch: 3 [407488/620022]    Loss: 0.008659   Batch Acc: 85.94
[Train] Epoch: 3 [407552/620022]    Loss: 0.007323   Batch Acc: 81.25
[Train] Epoch: 3 [407616/620022]    Loss: 0.008475   Batch Acc: 78.12
[Train] Epoch: 3 [407680/620022]    Loss: 0.009599   Batch Acc: 73.44
[Train] Epoch: 3 [407744/620022]    Loss: 0.006824   Batch Acc: 84.38
[Train] Epoch: 3 [407808/620022]    Loss: 0.007385   Batch Acc: 82.81
[Train] Epoch: 3 [407872/620022]    Loss: 0.008545   Batch Acc: 84.38
[Train] Epoch: 3 [407936/620022]    Loss: 0.006089   Batch Acc: 87.50
[Train] Epoch: 3 [408000/620022]    Loss: 0.010347   Batch Acc: 71.88
[Train] Epoch: 3 [408064/620022]    Loss: 0.007325   Batch Acc: 79.69
[Train] Epoch: 3 [408128/620022]    Loss: 0.012339   Batch Acc: 67.19
[Train] Epoch: 3 [408192/620022]    Loss: 0.005317   Batch Acc: 85.94
[Train] Epoch: 3 [408256/620022]    Loss: 0.009777   Batch Acc: 76.56
[Train] Epoch: 3 [408320/620022]    Loss: 0.009585   Batch Acc: 73.44
[Train] Epoch: 3 [408384/620022]    Loss: 0.007624   Batch Acc: 84.38
[Train] Epoch: 3 [408448/620022]    Loss: 0.009946   Batch Acc: 70.31
[Train] Epoch: 3 [408512/620022]    Loss: 0.008446   Batch Acc: 78.12
[Train] Epoch: 3 [408576/620022]    Loss: 0.010740   Batch Acc: 70.31
[Train] Epoch: 3 [408640/620022]    Loss: 0.007468   Batch Acc: 81.25
[Train] Epoch: 3 [408704/620022]    Loss: 0.009195   Batch Acc: 76.56
[Train] Epoch: 3 [408768/620022]    Loss: 0.010007   Batch Acc: 79.69
[Train] Epoch: 3 [408832/620022]    Loss: 0.007441   Batch Acc: 75.00
[Train] Epoch: 3 [408896/620022]    Loss: 0.008444   Batch Acc: 79.69
[Train] Epoch: 3 [408960/620022]    Loss: 0.008685   Batch Acc: 78.12
[Train] Epoch: 3 [409024/620022]    Loss: 0.009935   Batch Acc: 78.12
[Train] Epoch: 3 [409088/620022]    Loss: 0.007623   Batch Acc: 81.25
[Train] Epoch: 3 [409152/620022]    Loss: 0.008923   Batch Acc: 76.56
[Train] Epoch: 3 [409216/620022]    Loss: 0.009275   Batch Acc: 73.44
[Train] Epoch: 3 [409280/620022]    Loss: 0.009139   Batch Acc: 79.69
[Train] Epoch: 3 [409344/620022]    Loss: 0.009372   Batch Acc: 78.12
[Train] Epoch: 3 [409408/620022]    Loss: 0.011581   Batch Acc: 67.19
[Train] Epoch: 3 [409472/620022]    Loss: 0.008341   Batch Acc: 79.69
[Train] Epoch: 3 [409536/620022]    Loss: 0.008386   Batch Acc: 78.12
[Train] Epoch: 3 [409600/620022]    Loss: 0.009065   Batch Acc: 82.81
[Train] Epoch: 3 [409664/620022]    Loss: 0.008579   Batch Acc: 78.12
[Train] Epoch: 3 [409728/620022]    Loss: 0.007706   Batch Acc: 85.94
[Train] Epoch: 3 [409792/620022]    Loss: 0.006976   Batch Acc: 84.38
[Train] Epoch: 3 [409856/620022]    Loss: 0.008075   Batch Acc: 78.12
[Train] Epoch: 3 [409920/620022]    Loss: 0.008081   Batch Acc: 71.88
[Train] Epoch: 3 [409984/620022]    Loss: 0.008349   Batch Acc: 78.12
[Train] Epoch: 3 [410048/620022]    Loss: 0.007942   Batch Acc: 82.81
[Train] Epoch: 3 [410112/620022]    Loss: 0.008691   Batch Acc: 71.88
[Train] Epoch: 3 [410176/620022]    Loss: 0.009534   Batch Acc: 76.56
[Train] Epoch: 3 [410240/620022]    Loss: 0.008063   Batch Acc: 84.38
[Train] Epoch: 3 [410304/620022]    Loss: 0.008515   Batch Acc: 78.12
[Train] Epoch: 3 [410368/620022]    Loss: 0.009721   Batch Acc: 70.31
[Train] Epoch: 3 [410432/620022]    Loss: 0.007526   Batch Acc: 76.56
[Train] Epoch: 3 [410496/620022]    Loss: 0.006551   Batch Acc: 85.94
[Train] Epoch: 3 [410560/620022]    Loss: 0.008692   Batch Acc: 84.38
[Train] Epoch: 3 [410624/620022]    Loss: 0.009801   Batch Acc: 71.88
[Train] Epoch: 3 [410688/620022]    Loss: 0.008368   Batch Acc: 84.38
[Train] Epoch: 3 [410752/620022]    Loss: 0.011467   Batch Acc: 70.31
[Train] Epoch: 3 [410816/620022]    Loss: 0.007460   Batch Acc: 85.94
[Train] Epoch: 3 [410880/620022]    Loss: 0.008477   Batch Acc: 73.44
[Train] Epoch: 3 [410944/620022]    Loss: 0.008784   Batch Acc: 71.88
[Train] Epoch: 3 [411008/620022]    Loss: 0.009461   Batch Acc: 79.69
[Train] Epoch: 3 [411072/620022]    Loss: 0.008956   Batch Acc: 73.44
[Train] Epoch: 3 [411136/620022]    Loss: 0.008231   Batch Acc: 82.81
[Train] Epoch: 3 [411200/620022]    Loss: 0.009278   Batch Acc: 76.56
[Train] Epoch: 3 [411264/620022]    Loss: 0.008453   Batch Acc: 76.56
[Train] Epoch: 3 [411328/620022]    Loss: 0.008625   Batch Acc: 79.69
[Train] Epoch: 3 [411392/620022]    Loss: 0.008557   Batch Acc: 79.69
[Train] Epoch: 3 [411456/620022]    Loss: 0.008803   Batch Acc: 76.56
[Train] Epoch: 3 [411520/620022]    Loss: 0.008183   Batch Acc: 76.56
[Train] Epoch: 3 [411584/620022]    Loss: 0.009986   Batch Acc: 68.75
[Train] Epoch: 3 [411648/620022]    Loss: 0.007509   Batch Acc: 81.25
[Train] Epoch: 3 [411712/620022]    Loss: 0.006823   Batch Acc: 82.81
[Train] Epoch: 3 [411776/620022]    Loss: 0.008390   Batch Acc: 79.69
[Train] Epoch: 3 [411840/620022]    Loss: 0.010716   Batch Acc: 65.62
[Train] Epoch: 3 [411904/620022]    Loss: 0.008617   Batch Acc: 73.44
[Train] Epoch: 3 [411968/620022]    Loss: 0.007982   Batch Acc: 85.94
[Train] Epoch: 3 [412032/620022]    Loss: 0.008314   Batch Acc: 81.25
[Train] Epoch: 3 [412096/620022]    Loss: 0.007667   Batch Acc: 79.69
[Train] Epoch: 3 [412160/620022]    Loss: 0.008807   Batch Acc: 75.00
[Train] Epoch: 3 [412224/620022]    Loss: 0.009921   Batch Acc: 75.00
[Train] Epoch: 3 [412288/620022]    Loss: 0.005746   Batch Acc: 85.94
[Train] Epoch: 3 [412352/620022]    Loss: 0.008650   Batch Acc: 73.44
[Train] Epoch: 3 [412416/620022]    Loss: 0.009226   Batch Acc: 76.56
[Train] Epoch: 3 [412480/620022]    Loss: 0.008897   Batch Acc: 71.88
[Train] Epoch: 3 [412544/620022]    Loss: 0.008672   Batch Acc: 76.56
[Train] Epoch: 3 [412608/620022]    Loss: 0.006492   Batch Acc: 82.81
[Train] Epoch: 3 [412672/620022]    Loss: 0.006917   Batch Acc: 81.25
[Train] Epoch: 3 [412736/620022]    Loss: 0.008406   Batch Acc: 79.69
[Train] Epoch: 3 [412800/620022]    Loss: 0.006202   Batch Acc: 84.38
[Train] Epoch: 3 [412864/620022]    Loss: 0.007529   Batch Acc: 78.12
[Train] Epoch: 3 [412928/620022]    Loss: 0.007470   Batch Acc: 84.38
[Train] Epoch: 3 [412992/620022]    Loss: 0.008722   Batch Acc: 79.69
[Train] Epoch: 3 [413056/620022]    Loss: 0.006651   Batch Acc: 87.50
[Train] Epoch: 3 [413120/620022]    Loss: 0.008085   Batch Acc: 71.88
[Train] Epoch: 3 [413184/620022]    Loss: 0.009076   Batch Acc: 81.25
[Train] Epoch: 3 [413248/620022]    Loss: 0.007293   Batch Acc: 79.69
[Train] Epoch: 3 [413312/620022]    Loss: 0.007554   Batch Acc: 90.62
[Train] Epoch: 3 [413376/620022]    Loss: 0.007503   Batch Acc: 81.25
[Train] Epoch: 3 [413440/620022]    Loss: 0.009445   Batch Acc: 78.12
[Train] Epoch: 3 [413504/620022]    Loss: 0.008196   Batch Acc: 78.12
[Train] Epoch: 3 [413568/620022]    Loss: 0.009027   Batch Acc: 76.56
[Train] Epoch: 3 [413632/620022]    Loss: 0.008335   Batch Acc: 75.00
[Train] Epoch: 3 [413696/620022]    Loss: 0.010183   Batch Acc: 76.56
[Train] Epoch: 3 [413760/620022]    Loss: 0.011099   Batch Acc: 71.88
[Train] Epoch: 3 [413824/620022]    Loss: 0.007238   Batch Acc: 84.38
[Train] Epoch: 3 [413888/620022]    Loss: 0.008231   Batch Acc: 79.69
[Train] Epoch: 3 [413952/620022]    Loss: 0.009289   Batch Acc: 75.00
[Train] Epoch: 3 [414016/620022]    Loss: 0.009815   Batch Acc: 76.56
[Train] Epoch: 3 [414080/620022]    Loss: 0.009321   Batch Acc: 75.00
[Train] Epoch: 3 [414144/620022]    Loss: 0.007592   Batch Acc: 81.25
[Train] Epoch: 3 [414208/620022]    Loss: 0.007780   Batch Acc: 75.00
[Train] Epoch: 3 [414272/620022]    Loss: 0.009786   Batch Acc: 82.81
[Train] Epoch: 3 [414336/620022]    Loss: 0.006477   Batch Acc: 87.50
[Train] Epoch: 3 [414400/620022]    Loss: 0.007699   Batch Acc: 79.69
[Train] Epoch: 3 [414464/620022]    Loss: 0.009266   Batch Acc: 68.75
[Train] Epoch: 3 [414528/620022]    Loss: 0.007740   Batch Acc: 84.38
[Train] Epoch: 3 [414592/620022]    Loss: 0.009488   Batch Acc: 76.56
[Train] Epoch: 3 [414656/620022]    Loss: 0.007128   Batch Acc: 82.81
[Train] Epoch: 3 [414720/620022]    Loss: 0.006553   Batch Acc: 81.25
[Train] Epoch: 3 [414784/620022]    Loss: 0.006009   Batch Acc: 85.94
[Train] Epoch: 3 [414848/620022]    Loss: 0.010111   Batch Acc: 68.75
[Train] Epoch: 3 [414912/620022]    Loss: 0.008794   Batch Acc: 76.56
[Train] Epoch: 3 [414976/620022]    Loss: 0.007129   Batch Acc: 84.38
[Train] Epoch: 3 [415040/620022]    Loss: 0.007691   Batch Acc: 82.81
[Train] Epoch: 3 [415104/620022]    Loss: 0.008646   Batch Acc: 78.12
[Train] Epoch: 3 [415168/620022]    Loss: 0.009131   Batch Acc: 81.25
[Train] Epoch: 3 [415232/620022]    Loss: 0.011062   Batch Acc: 73.44
[Train] Epoch: 3 [415296/620022]    Loss: 0.008610   Batch Acc: 78.12
[Train] Epoch: 3 [415360/620022]    Loss: 0.008890   Batch Acc: 73.44
[Train] Epoch: 3 [415424/620022]    Loss: 0.010661   Batch Acc: 65.62
[Train] Epoch: 3 [415488/620022]    Loss: 0.009526   Batch Acc: 70.31
[Train] Epoch: 3 [415552/620022]    Loss: 0.008832   Batch Acc: 73.44
[Train] Epoch: 3 [415616/620022]    Loss: 0.011624   Batch Acc: 64.06
[Train] Epoch: 3 [415680/620022]    Loss: 0.006939   Batch Acc: 82.81
[Train] Epoch: 3 [415744/620022]    Loss: 0.010447   Batch Acc: 73.44
[Train] Epoch: 3 [415808/620022]    Loss: 0.009968   Batch Acc: 70.31
[Train] Epoch: 3 [415872/620022]    Loss: 0.008325   Batch Acc: 79.69
[Train] Epoch: 3 [415936/620022]    Loss: 0.010392   Batch Acc: 65.62
[Train] Epoch: 3 [416000/620022]    Loss: 0.008502   Batch Acc: 78.12
[Train] Epoch: 3 [416064/620022]    Loss: 0.008481   Batch Acc: 75.00
[Train] Epoch: 3 [416128/620022]    Loss: 0.007116   Batch Acc: 82.81
[Train] Epoch: 3 [416192/620022]    Loss: 0.010119   Batch Acc: 70.31
[Train] Epoch: 3 [416256/620022]    Loss: 0.008127   Batch Acc: 78.12
[Train] Epoch: 3 [416320/620022]    Loss: 0.007716   Batch Acc: 82.81
[Train] Epoch: 3 [416384/620022]    Loss: 0.010363   Batch Acc: 79.69
[Train] Epoch: 3 [416448/620022]    Loss: 0.006632   Batch Acc: 82.81
[Train] Epoch: 3 [416512/620022]    Loss: 0.012456   Batch Acc: 70.31
[Train] Epoch: 3 [416576/620022]    Loss: 0.008725   Batch Acc: 76.56
[Train] Epoch: 3 [416640/620022]    Loss: 0.009674   Batch Acc: 71.88
[Train] Epoch: 3 [416704/620022]    Loss: 0.005549   Batch Acc: 89.06
[Train] Epoch: 3 [416768/620022]    Loss: 0.008524   Batch Acc: 78.12
[Train] Epoch: 3 [416832/620022]    Loss: 0.006284   Batch Acc: 84.38
[Train] Epoch: 3 [416896/620022]    Loss: 0.009037   Batch Acc: 79.69
[Train] Epoch: 3 [416960/620022]    Loss: 0.010351   Batch Acc: 76.56
[Train] Epoch: 3 [417024/620022]    Loss: 0.008762   Batch Acc: 81.25
[Train] Epoch: 3 [417088/620022]    Loss: 0.007784   Batch Acc: 82.81
[Train] Epoch: 3 [417152/620022]    Loss: 0.008556   Batch Acc: 76.56
[Train] Epoch: 3 [417216/620022]    Loss: 0.007698   Batch Acc: 78.12
[Train] Epoch: 3 [417280/620022]    Loss: 0.010789   Batch Acc: 71.88
[Train] Epoch: 3 [417344/620022]    Loss: 0.007177   Batch Acc: 76.56
[Train] Epoch: 3 [417408/620022]    Loss: 0.008148   Batch Acc: 79.69
[Train] Epoch: 3 [417472/620022]    Loss: 0.006667   Batch Acc: 85.94
[Train] Epoch: 3 [417536/620022]    Loss: 0.008098   Batch Acc: 79.69
[Train] Epoch: 3 [417600/620022]    Loss: 0.007565   Batch Acc: 82.81
[Train] Epoch: 3 [417664/620022]    Loss: 0.008447   Batch Acc: 79.69
[Train] Epoch: 3 [417728/620022]    Loss: 0.008615   Batch Acc: 71.88
[Train] Epoch: 3 [417792/620022]    Loss: 0.010028   Batch Acc: 71.88
[Train] Epoch: 3 [417856/620022]    Loss: 0.007937   Batch Acc: 76.56
[Train] Epoch: 3 [417920/620022]    Loss: 0.008763   Batch Acc: 78.12
[Train] Epoch: 3 [417984/620022]    Loss: 0.009389   Batch Acc: 73.44
[Train] Epoch: 3 [418048/620022]    Loss: 0.008961   Batch Acc: 81.25
[Train] Epoch: 3 [418112/620022]    Loss: 0.009659   Batch Acc: 73.44
[Train] Epoch: 3 [418176/620022]    Loss: 0.008202   Batch Acc: 75.00
[Train] Epoch: 3 [418240/620022]    Loss: 0.008157   Batch Acc: 76.56
[Train] Epoch: 3 [418304/620022]    Loss: 0.006968   Batch Acc: 84.38
[Train] Epoch: 3 [418368/620022]    Loss: 0.010436   Batch Acc: 65.62
[Train] Epoch: 3 [418432/620022]    Loss: 0.008220   Batch Acc: 71.88
[Train] Epoch: 3 [418496/620022]    Loss: 0.009549   Batch Acc: 78.12
[Train] Epoch: 3 [418560/620022]    Loss: 0.009290   Batch Acc: 71.88
[Train] Epoch: 3 [418624/620022]    Loss: 0.012413   Batch Acc: 68.75
[Train] Epoch: 3 [418688/620022]    Loss: 0.007438   Batch Acc: 87.50
[Train] Epoch: 3 [418752/620022]    Loss: 0.009552   Batch Acc: 73.44
[Train] Epoch: 3 [418816/620022]    Loss: 0.009957   Batch Acc: 71.88
[Train] Epoch: 3 [418880/620022]    Loss: 0.007610   Batch Acc: 85.94
[Train] Epoch: 3 [418944/620022]    Loss: 0.008961   Batch Acc: 79.69
[Train] Epoch: 3 [419008/620022]    Loss: 0.009230   Batch Acc: 78.12
[Train] Epoch: 3 [419072/620022]    Loss: 0.009202   Batch Acc: 76.56
[Train] Epoch: 3 [419136/620022]    Loss: 0.009659   Batch Acc: 76.56
[Train] Epoch: 3 [419200/620022]    Loss: 0.007456   Batch Acc: 84.38
[Train] Epoch: 3 [419264/620022]    Loss: 0.008602   Batch Acc: 78.12
[Train] Epoch: 3 [419328/620022]    Loss: 0.010113   Batch Acc: 71.88
[Train] Epoch: 3 [419392/620022]    Loss: 0.005677   Batch Acc: 90.62
[Train] Epoch: 3 [419456/620022]    Loss: 0.006976   Batch Acc: 82.81
[Train] Epoch: 3 [419520/620022]    Loss: 0.007689   Batch Acc: 85.94
[Train] Epoch: 3 [419584/620022]    Loss: 0.007535   Batch Acc: 81.25
[Train] Epoch: 3 [419648/620022]    Loss: 0.008976   Batch Acc: 79.69
[Train] Epoch: 3 [419712/620022]    Loss: 0.007030   Batch Acc: 85.94
[Train] Epoch: 3 [419776/620022]    Loss: 0.009871   Batch Acc: 73.44
[Train] Epoch: 3 [419840/620022]    Loss: 0.008465   Batch Acc: 79.69
[Train] Epoch: 3 [419904/620022]    Loss: 0.006675   Batch Acc: 84.38
[Train] Epoch: 3 [419968/620022]    Loss: 0.007257   Batch Acc: 85.94
[Train] Epoch: 3 [420032/620022]    Loss: 0.009439   Batch Acc: 71.88
[Train] Epoch: 3 [420096/620022]    Loss: 0.009532   Batch Acc: 78.12
[Train] Epoch: 3 [420160/620022]    Loss: 0.009537   Batch Acc: 71.88
[Train] Epoch: 3 [420224/620022]    Loss: 0.006895   Batch Acc: 81.25
[Train] Epoch: 3 [420288/620022]    Loss: 0.008937   Batch Acc: 76.56
[Train] Epoch: 3 [420352/620022]    Loss: 0.010758   Batch Acc: 68.75
[Train] Epoch: 3 [420416/620022]    Loss: 0.009923   Batch Acc: 78.12
[Train] Epoch: 3 [420480/620022]    Loss: 0.008825   Batch Acc: 75.00
[Train] Epoch: 3 [420544/620022]    Loss: 0.008511   Batch Acc: 81.25
[Train] Epoch: 3 [420608/620022]    Loss: 0.010304   Batch Acc: 73.44
[Train] Epoch: 3 [420672/620022]    Loss: 0.010023   Batch Acc: 68.75
[Train] Epoch: 3 [420736/620022]    Loss: 0.009593   Batch Acc: 76.56
[Train] Epoch: 3 [420800/620022]    Loss: 0.007473   Batch Acc: 75.00
[Train] Epoch: 3 [420864/620022]    Loss: 0.006273   Batch Acc: 90.62
[Train] Epoch: 3 [420928/620022]    Loss: 0.007979   Batch Acc: 84.38
[Train] Epoch: 3 [420992/620022]    Loss: 0.007576   Batch Acc: 82.81
[Train] Epoch: 3 [421056/620022]    Loss: 0.009890   Batch Acc: 70.31
[Train] Epoch: 3 [421120/620022]    Loss: 0.010202   Batch Acc: 70.31
[Train] Epoch: 3 [421184/620022]    Loss: 0.007550   Batch Acc: 81.25
[Train] Epoch: 3 [421248/620022]    Loss: 0.009135   Batch Acc: 75.00
[Train] Epoch: 3 [421312/620022]    Loss: 0.007143   Batch Acc: 79.69
[Train] Epoch: 3 [421376/620022]    Loss: 0.008655   Batch Acc: 79.69
[Train] Epoch: 3 [421440/620022]    Loss: 0.011176   Batch Acc: 73.44
[Train] Epoch: 3 [421504/620022]    Loss: 0.008008   Batch Acc: 81.25
[Train] Epoch: 3 [421568/620022]    Loss: 0.007189   Batch Acc: 81.25
[Train] Epoch: 3 [421632/620022]    Loss: 0.010073   Batch Acc: 71.88
[Train] Epoch: 3 [421696/620022]    Loss: 0.007732   Batch Acc: 81.25
[Train] Epoch: 3 [421760/620022]    Loss: 0.007825   Batch Acc: 82.81
[Train] Epoch: 3 [421824/620022]    Loss: 0.006058   Batch Acc: 84.38
[Train] Epoch: 3 [421888/620022]    Loss: 0.008059   Batch Acc: 81.25
[Train] Epoch: 3 [421952/620022]    Loss: 0.007660   Batch Acc: 82.81
[Train] Epoch: 3 [422016/620022]    Loss: 0.008576   Batch Acc: 73.44
[Train] Epoch: 3 [422080/620022]    Loss: 0.010116   Batch Acc: 70.31
[Train] Epoch: 3 [422144/620022]    Loss: 0.008830   Batch Acc: 78.12
[Train] Epoch: 3 [422208/620022]    Loss: 0.006830   Batch Acc: 84.38
[Train] Epoch: 3 [422272/620022]    Loss: 0.005702   Batch Acc: 87.50
[Train] Epoch: 3 [422336/620022]    Loss: 0.008880   Batch Acc: 76.56
[Train] Epoch: 3 [422400/620022]    Loss: 0.007506   Batch Acc: 81.25
[Train] Epoch: 3 [422464/620022]    Loss: 0.008395   Batch Acc: 78.12
[Train] Epoch: 3 [422528/620022]    Loss: 0.007040   Batch Acc: 85.94
[Train] Epoch: 3 [422592/620022]    Loss: 0.006397   Batch Acc: 85.94
[Train] Epoch: 3 [422656/620022]    Loss: 0.008059   Batch Acc: 78.12
[Train] Epoch: 3 [422720/620022]    Loss: 0.008979   Batch Acc: 76.56
[Train] Epoch: 3 [422784/620022]    Loss: 0.008907   Batch Acc: 75.00
[Train] Epoch: 3 [422848/620022]    Loss: 0.008645   Batch Acc: 76.56
[Train] Epoch: 3 [422912/620022]    Loss: 0.010272   Batch Acc: 71.88
[Train] Epoch: 3 [422976/620022]    Loss: 0.006187   Batch Acc: 85.94
[Train] Epoch: 3 [423040/620022]    Loss: 0.007659   Batch Acc: 81.25
[Train] Epoch: 3 [423104/620022]    Loss: 0.006728   Batch Acc: 84.38
[Train] Epoch: 3 [423168/620022]    Loss: 0.009134   Batch Acc: 73.44
[Train] Epoch: 3 [423232/620022]    Loss: 0.007156   Batch Acc: 82.81
[Train] Epoch: 3 [423296/620022]    Loss: 0.006941   Batch Acc: 81.25
[Train] Epoch: 3 [423360/620022]    Loss: 0.008872   Batch Acc: 76.56
[Train] Epoch: 3 [423424/620022]    Loss: 0.007699   Batch Acc: 82.81
[Train] Epoch: 3 [423488/620022]    Loss: 0.009238   Batch Acc: 75.00
[Train] Epoch: 3 [423552/620022]    Loss: 0.007267   Batch Acc: 84.38
[Train] Epoch: 3 [423616/620022]    Loss: 0.007591   Batch Acc: 78.12
[Train] Epoch: 3 [423680/620022]    Loss: 0.008151   Batch Acc: 78.12
[Train] Epoch: 3 [423744/620022]    Loss: 0.007458   Batch Acc: 78.12
[Train] Epoch: 3 [423808/620022]    Loss: 0.008996   Batch Acc: 75.00
[Train] Epoch: 3 [423872/620022]    Loss: 0.008237   Batch Acc: 82.81
[Train] Epoch: 3 [423936/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 3 [424000/620022]    Loss: 0.011255   Batch Acc: 68.75
[Train] Epoch: 3 [424064/620022]    Loss: 0.008532   Batch Acc: 75.00
[Train] Epoch: 3 [424128/620022]    Loss: 0.007944   Batch Acc: 78.12
[Train] Epoch: 3 [424192/620022]    Loss: 0.007122   Batch Acc: 82.81
[Train] Epoch: 3 [424256/620022]    Loss: 0.008016   Batch Acc: 79.69
[Train] Epoch: 3 [424320/620022]    Loss: 0.008147   Batch Acc: 82.81
[Train] Epoch: 3 [424384/620022]    Loss: 0.009420   Batch Acc: 70.31
[Train] Epoch: 3 [424448/620022]    Loss: 0.008632   Batch Acc: 76.56
[Train] Epoch: 3 [424512/620022]    Loss: 0.006627   Batch Acc: 85.94
[Train] Epoch: 3 [424576/620022]    Loss: 0.010002   Batch Acc: 76.56
[Train] Epoch: 3 [424640/620022]    Loss: 0.009975   Batch Acc: 75.00
[Train] Epoch: 3 [424704/620022]    Loss: 0.007833   Batch Acc: 81.25
[Train] Epoch: 3 [424768/620022]    Loss: 0.008612   Batch Acc: 79.69
[Train] Epoch: 3 [424832/620022]    Loss: 0.008326   Batch Acc: 84.38
[Train] Epoch: 3 [424896/620022]    Loss: 0.008877   Batch Acc: 78.12
[Train] Epoch: 3 [424960/620022]    Loss: 0.007823   Batch Acc: 78.12
[Train] Epoch: 3 [425024/620022]    Loss: 0.008205   Batch Acc: 84.38
[Train] Epoch: 3 [425088/620022]    Loss: 0.007455   Batch Acc: 82.81
[Train] Epoch: 3 [425152/620022]    Loss: 0.009398   Batch Acc: 76.56
[Train] Epoch: 3 [425216/620022]    Loss: 0.007149   Batch Acc: 82.81
[Train] Epoch: 3 [425280/620022]    Loss: 0.010254   Batch Acc: 71.88
[Train] Epoch: 3 [425344/620022]    Loss: 0.007224   Batch Acc: 85.94
[Train] Epoch: 3 [425408/620022]    Loss: 0.009132   Batch Acc: 73.44
[Train] Epoch: 3 [425472/620022]    Loss: 0.008162   Batch Acc: 84.38
[Train] Epoch: 3 [425536/620022]    Loss: 0.008205   Batch Acc: 78.12
[Train] Epoch: 3 [425600/620022]    Loss: 0.009269   Batch Acc: 76.56
[Train] Epoch: 3 [425664/620022]    Loss: 0.009874   Batch Acc: 73.44
[Train] Epoch: 3 [425728/620022]    Loss: 0.009160   Batch Acc: 79.69
[Train] Epoch: 3 [425792/620022]    Loss: 0.009216   Batch Acc: 79.69
[Train] Epoch: 3 [425856/620022]    Loss: 0.009928   Batch Acc: 71.88
[Train] Epoch: 3 [425920/620022]    Loss: 0.007466   Batch Acc: 81.25
[Train] Epoch: 3 [425984/620022]    Loss: 0.007251   Batch Acc: 84.38
[Train] Epoch: 3 [426048/620022]    Loss: 0.007777   Batch Acc: 85.94
[Train] Epoch: 3 [426112/620022]    Loss: 0.008551   Batch Acc: 81.25
[Train] Epoch: 3 [426176/620022]    Loss: 0.006035   Batch Acc: 85.94
[Train] Epoch: 3 [426240/620022]    Loss: 0.009445   Batch Acc: 71.88
[Train] Epoch: 3 [426304/620022]    Loss: 0.007911   Batch Acc: 75.00
[Train] Epoch: 3 [426368/620022]    Loss: 0.009899   Batch Acc: 71.88
[Train] Epoch: 3 [426432/620022]    Loss: 0.009814   Batch Acc: 70.31
[Train] Epoch: 3 [426496/620022]    Loss: 0.008491   Batch Acc: 84.38
[Train] Epoch: 3 [426560/620022]    Loss: 0.008884   Batch Acc: 82.81
[Train] Epoch: 3 [426624/620022]    Loss: 0.012670   Batch Acc: 67.19
[Train] Epoch: 3 [426688/620022]    Loss: 0.007437   Batch Acc: 81.25
[Train] Epoch: 3 [426752/620022]    Loss: 0.006848   Batch Acc: 81.25
[Train] Epoch: 3 [426816/620022]    Loss: 0.010724   Batch Acc: 71.88
[Train] Epoch: 3 [426880/620022]    Loss: 0.011378   Batch Acc: 67.19
[Train] Epoch: 3 [426944/620022]    Loss: 0.009398   Batch Acc: 76.56
[Train] Epoch: 3 [427008/620022]    Loss: 0.009529   Batch Acc: 73.44
[Train] Epoch: 3 [427072/620022]    Loss: 0.008440   Batch Acc: 81.25
[Train] Epoch: 3 [427136/620022]    Loss: 0.008305   Batch Acc: 78.12
[Train] Epoch: 3 [427200/620022]    Loss: 0.008414   Batch Acc: 85.94
[Train] Epoch: 3 [427264/620022]    Loss: 0.007802   Batch Acc: 79.69
[Train] Epoch: 3 [427328/620022]    Loss: 0.008681   Batch Acc: 71.88
[Train] Epoch: 3 [427392/620022]    Loss: 0.008045   Batch Acc: 76.56
[Train] Epoch: 3 [427456/620022]    Loss: 0.007088   Batch Acc: 81.25
[Train] Epoch: 3 [427520/620022]    Loss: 0.007725   Batch Acc: 78.12
[Train] Epoch: 3 [427584/620022]    Loss: 0.008461   Batch Acc: 75.00
[Train] Epoch: 3 [427648/620022]    Loss: 0.005548   Batch Acc: 92.19
[Train] Epoch: 3 [427712/620022]    Loss: 0.009472   Batch Acc: 75.00
[Train] Epoch: 3 [427776/620022]    Loss: 0.008861   Batch Acc: 76.56
[Train] Epoch: 3 [427840/620022]    Loss: 0.011131   Batch Acc: 71.88
[Train] Epoch: 3 [427904/620022]    Loss: 0.007946   Batch Acc: 79.69
[Train] Epoch: 3 [427968/620022]    Loss: 0.008711   Batch Acc: 79.69
[Train] Epoch: 3 [428032/620022]    Loss: 0.010040   Batch Acc: 79.69
[Train] Epoch: 3 [428096/620022]    Loss: 0.008190   Batch Acc: 85.94
[Train] Epoch: 3 [428160/620022]    Loss: 0.007008   Batch Acc: 81.25
[Train] Epoch: 3 [428224/620022]    Loss: 0.007953   Batch Acc: 81.25
[Train] Epoch: 3 [428288/620022]    Loss: 0.009168   Batch Acc: 75.00
[Train] Epoch: 3 [428352/620022]    Loss: 0.009278   Batch Acc: 78.12
[Train] Epoch: 3 [428416/620022]    Loss: 0.007034   Batch Acc: 85.94
[Train] Epoch: 3 [428480/620022]    Loss: 0.009816   Batch Acc: 70.31
[Train] Epoch: 3 [428544/620022]    Loss: 0.009669   Batch Acc: 73.44
[Train] Epoch: 3 [428608/620022]    Loss: 0.007884   Batch Acc: 82.81
[Train] Epoch: 3 [428672/620022]    Loss: 0.008682   Batch Acc: 76.56
[Train] Epoch: 3 [428736/620022]    Loss: 0.008379   Batch Acc: 82.81
[Train] Epoch: 3 [428800/620022]    Loss: 0.007674   Batch Acc: 82.81
[Train] Epoch: 3 [428864/620022]    Loss: 0.006041   Batch Acc: 89.06
[Train] Epoch: 3 [428928/620022]    Loss: 0.009223   Batch Acc: 78.12
[Train] Epoch: 3 [428992/620022]    Loss: 0.009038   Batch Acc: 78.12
[Train] Epoch: 3 [429056/620022]    Loss: 0.009079   Batch Acc: 76.56
[Train] Epoch: 3 [429120/620022]    Loss: 0.009319   Batch Acc: 81.25
[Train] Epoch: 3 [429184/620022]    Loss: 0.008015   Batch Acc: 81.25
[Train] Epoch: 3 [429248/620022]    Loss: 0.007367   Batch Acc: 81.25
[Train] Epoch: 3 [429312/620022]    Loss: 0.010069   Batch Acc: 68.75
[Train] Epoch: 3 [429376/620022]    Loss: 0.010717   Batch Acc: 71.88
[Train] Epoch: 3 [429440/620022]    Loss: 0.012472   Batch Acc: 60.94
[Train] Epoch: 3 [429504/620022]    Loss: 0.007134   Batch Acc: 82.81
[Train] Epoch: 3 [429568/620022]    Loss: 0.010117   Batch Acc: 75.00
[Train] Epoch: 3 [429632/620022]    Loss: 0.008858   Batch Acc: 76.56
[Train] Epoch: 3 [429696/620022]    Loss: 0.008876   Batch Acc: 79.69
[Train] Epoch: 3 [429760/620022]    Loss: 0.008627   Batch Acc: 82.81
[Train] Epoch: 3 [429824/620022]    Loss: 0.008242   Batch Acc: 79.69
[Train] Epoch: 3 [429888/620022]    Loss: 0.008125   Batch Acc: 79.69
[Train] Epoch: 3 [429952/620022]    Loss: 0.008538   Batch Acc: 73.44
[Train] Epoch: 3 [430016/620022]    Loss: 0.009353   Batch Acc: 76.56
[Train] Epoch: 3 [430080/620022]    Loss: 0.007861   Batch Acc: 82.81
[Train] Epoch: 3 [430144/620022]    Loss: 0.006873   Batch Acc: 85.94
[Train] Epoch: 3 [430208/620022]    Loss: 0.009712   Batch Acc: 75.00
[Train] Epoch: 3 [430272/620022]    Loss: 0.008418   Batch Acc: 75.00
[Train] Epoch: 3 [430336/620022]    Loss: 0.010315   Batch Acc: 76.56
[Train] Epoch: 3 [430400/620022]    Loss: 0.011098   Batch Acc: 68.75
[Train] Epoch: 3 [430464/620022]    Loss: 0.008503   Batch Acc: 78.12
[Train] Epoch: 3 [430528/620022]    Loss: 0.011617   Batch Acc: 70.31
[Train] Epoch: 3 [430592/620022]    Loss: 0.009737   Batch Acc: 78.12
[Train] Epoch: 3 [430656/620022]    Loss: 0.007468   Batch Acc: 84.38
[Train] Epoch: 3 [430720/620022]    Loss: 0.010207   Batch Acc: 68.75
[Train] Epoch: 3 [430784/620022]    Loss: 0.007226   Batch Acc: 76.56
[Train] Epoch: 3 [430848/620022]    Loss: 0.006394   Batch Acc: 87.50
[Train] Epoch: 3 [430912/620022]    Loss: 0.007215   Batch Acc: 85.94
[Train] Epoch: 3 [430976/620022]    Loss: 0.009351   Batch Acc: 79.69
[Train] Epoch: 3 [431040/620022]    Loss: 0.009545   Batch Acc: 64.06
[Train] Epoch: 3 [431104/620022]    Loss: 0.007790   Batch Acc: 78.12
[Train] Epoch: 3 [431168/620022]    Loss: 0.009527   Batch Acc: 73.44
[Train] Epoch: 3 [431232/620022]    Loss: 0.009206   Batch Acc: 76.56
[Train] Epoch: 3 [431296/620022]    Loss: 0.009660   Batch Acc: 71.88
[Train] Epoch: 3 [431360/620022]    Loss: 0.010109   Batch Acc: 78.12
[Train] Epoch: 3 [431424/620022]    Loss: 0.009488   Batch Acc: 78.12
[Train] Epoch: 3 [431488/620022]    Loss: 0.007773   Batch Acc: 84.38
[Train] Epoch: 3 [431552/620022]    Loss: 0.007960   Batch Acc: 79.69
[Train] Epoch: 3 [431616/620022]    Loss: 0.010487   Batch Acc: 71.88
[Train] Epoch: 3 [431680/620022]    Loss: 0.009524   Batch Acc: 73.44
[Train] Epoch: 3 [431744/620022]    Loss: 0.008695   Batch Acc: 79.69
[Train] Epoch: 3 [431808/620022]    Loss: 0.008315   Batch Acc: 82.81
[Train] Epoch: 3 [431872/620022]    Loss: 0.009911   Batch Acc: 75.00
[Train] Epoch: 3 [431936/620022]    Loss: 0.008807   Batch Acc: 81.25
[Train] Epoch: 3 [432000/620022]    Loss: 0.008636   Batch Acc: 73.44
[Train] Epoch: 3 [432064/620022]    Loss: 0.008996   Batch Acc: 78.12
[Train] Epoch: 3 [432128/620022]    Loss: 0.008823   Batch Acc: 76.56
[Train] Epoch: 3 [432192/620022]    Loss: 0.009453   Batch Acc: 81.25
[Train] Epoch: 3 [432256/620022]    Loss: 0.007885   Batch Acc: 76.56
[Train] Epoch: 3 [432320/620022]    Loss: 0.006317   Batch Acc: 90.62
[Train] Epoch: 3 [432384/620022]    Loss: 0.007998   Batch Acc: 75.00
[Train] Epoch: 3 [432448/620022]    Loss: 0.009886   Batch Acc: 75.00
[Train] Epoch: 3 [432512/620022]    Loss: 0.007312   Batch Acc: 79.69
[Train] Epoch: 3 [432576/620022]    Loss: 0.008091   Batch Acc: 82.81
[Train] Epoch: 3 [432640/620022]    Loss: 0.006079   Batch Acc: 87.50
[Train] Epoch: 3 [432704/620022]    Loss: 0.010398   Batch Acc: 70.31
[Train] Epoch: 3 [432768/620022]    Loss: 0.009108   Batch Acc: 79.69
[Train] Epoch: 3 [432832/620022]    Loss: 0.007633   Batch Acc: 79.69
[Train] Epoch: 3 [432896/620022]    Loss: 0.009016   Batch Acc: 73.44
[Train] Epoch: 3 [432960/620022]    Loss: 0.009217   Batch Acc: 76.56
[Train] Epoch: 3 [433024/620022]    Loss: 0.009473   Batch Acc: 75.00
[Train] Epoch: 3 [433088/620022]    Loss: 0.009862   Batch Acc: 75.00
[Train] Epoch: 3 [433152/620022]    Loss: 0.008295   Batch Acc: 82.81
[Train] Epoch: 3 [433216/620022]    Loss: 0.006971   Batch Acc: 84.38
[Train] Epoch: 3 [433280/620022]    Loss: 0.007476   Batch Acc: 81.25
[Train] Epoch: 3 [433344/620022]    Loss: 0.009578   Batch Acc: 78.12
[Train] Epoch: 3 [433408/620022]    Loss: 0.010681   Batch Acc: 67.19
[Train] Epoch: 3 [433472/620022]    Loss: 0.007702   Batch Acc: 78.12
[Train] Epoch: 3 [433536/620022]    Loss: 0.005673   Batch Acc: 85.94
[Train] Epoch: 3 [433600/620022]    Loss: 0.007418   Batch Acc: 82.81
[Train] Epoch: 3 [433664/620022]    Loss: 0.008581   Batch Acc: 81.25
[Train] Epoch: 3 [433728/620022]    Loss: 0.007277   Batch Acc: 79.69
[Train] Epoch: 3 [433792/620022]    Loss: 0.009031   Batch Acc: 70.31
[Train] Epoch: 3 [433856/620022]    Loss: 0.009495   Batch Acc: 76.56
[Train] Epoch: 3 [433920/620022]    Loss: 0.008233   Batch Acc: 79.69
[Train] Epoch: 3 [433984/620022]    Loss: 0.011808   Batch Acc: 67.19
[Train] Epoch: 3 [434048/620022]    Loss: 0.007163   Batch Acc: 76.56
[Train] Epoch: 3 [434112/620022]    Loss: 0.006821   Batch Acc: 89.06
[Train] Epoch: 3 [434176/620022]    Loss: 0.009358   Batch Acc: 81.25
[Train] Epoch: 3 [434240/620022]    Loss: 0.008620   Batch Acc: 73.44
[Train] Epoch: 3 [434304/620022]    Loss: 0.009817   Batch Acc: 71.88
[Train] Epoch: 3 [434368/620022]    Loss: 0.007754   Batch Acc: 82.81
[Train] Epoch: 3 [434432/620022]    Loss: 0.009473   Batch Acc: 73.44
[Train] Epoch: 3 [434496/620022]    Loss: 0.009386   Batch Acc: 70.31
[Train] Epoch: 3 [434560/620022]    Loss: 0.009927   Batch Acc: 68.75
[Train] Epoch: 3 [434624/620022]    Loss: 0.007799   Batch Acc: 79.69
[Train] Epoch: 3 [434688/620022]    Loss: 0.008623   Batch Acc: 79.69
[Train] Epoch: 3 [434752/620022]    Loss: 0.009234   Batch Acc: 76.56
[Train] Epoch: 3 [434816/620022]    Loss: 0.008219   Batch Acc: 79.69
[Train] Epoch: 3 [434880/620022]    Loss: 0.007914   Batch Acc: 84.38
[Train] Epoch: 3 [434944/620022]    Loss: 0.008414   Batch Acc: 76.56
[Train] Epoch: 3 [435008/620022]    Loss: 0.007683   Batch Acc: 81.25
[Train] Epoch: 3 [435072/620022]    Loss: 0.007841   Batch Acc: 81.25
[Train] Epoch: 3 [435136/620022]    Loss: 0.007356   Batch Acc: 79.69
[Train] Epoch: 3 [435200/620022]    Loss: 0.007300   Batch Acc: 79.69
[Train] Epoch: 3 [435264/620022]    Loss: 0.007710   Batch Acc: 81.25
[Train] Epoch: 3 [435328/620022]    Loss: 0.007855   Batch Acc: 79.69
[Train] Epoch: 3 [435392/620022]    Loss: 0.008077   Batch Acc: 79.69
[Train] Epoch: 3 [435456/620022]    Loss: 0.007750   Batch Acc: 78.12
[Train] Epoch: 3 [435520/620022]    Loss: 0.010226   Batch Acc: 67.19
[Train] Epoch: 3 [435584/620022]    Loss: 0.009235   Batch Acc: 75.00
[Train] Epoch: 3 [435648/620022]    Loss: 0.008807   Batch Acc: 78.12
[Train] Epoch: 3 [435712/620022]    Loss: 0.010760   Batch Acc: 68.75
[Train] Epoch: 3 [435776/620022]    Loss: 0.007445   Batch Acc: 87.50
[Train] Epoch: 3 [435840/620022]    Loss: 0.009426   Batch Acc: 73.44
[Train] Epoch: 3 [435904/620022]    Loss: 0.009492   Batch Acc: 76.56
[Train] Epoch: 3 [435968/620022]    Loss: 0.008744   Batch Acc: 79.69
[Train] Epoch: 3 [436032/620022]    Loss: 0.008654   Batch Acc: 75.00
[Train] Epoch: 3 [436096/620022]    Loss: 0.007660   Batch Acc: 79.69
[Train] Epoch: 3 [436160/620022]    Loss: 0.006268   Batch Acc: 82.81
[Train] Epoch: 3 [436224/620022]    Loss: 0.009180   Batch Acc: 73.44
[Train] Epoch: 3 [436288/620022]    Loss: 0.006457   Batch Acc: 87.50
[Train] Epoch: 3 [436352/620022]    Loss: 0.010457   Batch Acc: 65.62
[Train] Epoch: 3 [436416/620022]    Loss: 0.008059   Batch Acc: 82.81
[Train] Epoch: 3 [436480/620022]    Loss: 0.008630   Batch Acc: 78.12
[Train] Epoch: 3 [436544/620022]    Loss: 0.009993   Batch Acc: 75.00
[Train] Epoch: 3 [436608/620022]    Loss: 0.009061   Batch Acc: 75.00
[Train] Epoch: 3 [436672/620022]    Loss: 0.008965   Batch Acc: 78.12
[Train] Epoch: 3 [436736/620022]    Loss: 0.007205   Batch Acc: 85.94
[Train] Epoch: 3 [436800/620022]    Loss: 0.008818   Batch Acc: 78.12
[Train] Epoch: 3 [436864/620022]    Loss: 0.005998   Batch Acc: 90.62
[Train] Epoch: 3 [436928/620022]    Loss: 0.006085   Batch Acc: 90.62
[Train] Epoch: 3 [436992/620022]    Loss: 0.008456   Batch Acc: 75.00
[Train] Epoch: 3 [437056/620022]    Loss: 0.010144   Batch Acc: 73.44
[Train] Epoch: 3 [437120/620022]    Loss: 0.008422   Batch Acc: 78.12
[Train] Epoch: 3 [437184/620022]    Loss: 0.006818   Batch Acc: 82.81
[Train] Epoch: 3 [437248/620022]    Loss: 0.009687   Batch Acc: 78.12
[Train] Epoch: 3 [437312/620022]    Loss: 0.009219   Batch Acc: 76.56
[Train] Epoch: 3 [437376/620022]    Loss: 0.008273   Batch Acc: 79.69
[Train] Epoch: 3 [437440/620022]    Loss: 0.010074   Batch Acc: 70.31
[Train] Epoch: 3 [437504/620022]    Loss: 0.007965   Batch Acc: 84.38
[Train] Epoch: 3 [437568/620022]    Loss: 0.009649   Batch Acc: 73.44
[Train] Epoch: 3 [437632/620022]    Loss: 0.008194   Batch Acc: 78.12
[Train] Epoch: 3 [437696/620022]    Loss: 0.008988   Batch Acc: 76.56
[Train] Epoch: 3 [437760/620022]    Loss: 0.009838   Batch Acc: 70.31
[Train] Epoch: 3 [437824/620022]    Loss: 0.007763   Batch Acc: 76.56
[Train] Epoch: 3 [437888/620022]    Loss: 0.006015   Batch Acc: 87.50
[Train] Epoch: 3 [437952/620022]    Loss: 0.009394   Batch Acc: 75.00
[Train] Epoch: 3 [438016/620022]    Loss: 0.009203   Batch Acc: 78.12
[Train] Epoch: 3 [438080/620022]    Loss: 0.008608   Batch Acc: 75.00
[Train] Epoch: 3 [438144/620022]    Loss: 0.008223   Batch Acc: 78.12
[Train] Epoch: 3 [438208/620022]    Loss: 0.008903   Batch Acc: 82.81
[Train] Epoch: 3 [438272/620022]    Loss: 0.010034   Batch Acc: 71.88
[Train] Epoch: 3 [438336/620022]    Loss: 0.010518   Batch Acc: 71.88
[Train] Epoch: 3 [438400/620022]    Loss: 0.007984   Batch Acc: 85.94
[Train] Epoch: 3 [438464/620022]    Loss: 0.006071   Batch Acc: 89.06
[Train] Epoch: 3 [438528/620022]    Loss: 0.010025   Batch Acc: 78.12
[Train] Epoch: 3 [438592/620022]    Loss: 0.008539   Batch Acc: 78.12
[Train] Epoch: 3 [438656/620022]    Loss: 0.007262   Batch Acc: 81.25
[Train] Epoch: 3 [438720/620022]    Loss: 0.009032   Batch Acc: 79.69
[Train] Epoch: 3 [438784/620022]    Loss: 0.007552   Batch Acc: 76.56
[Train] Epoch: 3 [438848/620022]    Loss: 0.005967   Batch Acc: 85.94
[Train] Epoch: 3 [438912/620022]    Loss: 0.009615   Batch Acc: 71.88
[Train] Epoch: 3 [438976/620022]    Loss: 0.007773   Batch Acc: 79.69
[Train] Epoch: 3 [439040/620022]    Loss: 0.009583   Batch Acc: 73.44
[Train] Epoch: 3 [439104/620022]    Loss: 0.009009   Batch Acc: 78.12
[Train] Epoch: 3 [439168/620022]    Loss: 0.006926   Batch Acc: 85.94
[Train] Epoch: 3 [439232/620022]    Loss: 0.008368   Batch Acc: 75.00
[Train] Epoch: 3 [439296/620022]    Loss: 0.011317   Batch Acc: 67.19
[Train] Epoch: 3 [439360/620022]    Loss: 0.008668   Batch Acc: 78.12
[Train] Epoch: 3 [439424/620022]    Loss: 0.008428   Batch Acc: 79.69
[Train] Epoch: 3 [439488/620022]    Loss: 0.010466   Batch Acc: 78.12
[Train] Epoch: 3 [439552/620022]    Loss: 0.008119   Batch Acc: 81.25
[Train] Epoch: 3 [439616/620022]    Loss: 0.009721   Batch Acc: 81.25
[Train] Epoch: 3 [439680/620022]    Loss: 0.007947   Batch Acc: 75.00
[Train] Epoch: 3 [439744/620022]    Loss: 0.007866   Batch Acc: 78.12
[Train] Epoch: 3 [439808/620022]    Loss: 0.009260   Batch Acc: 73.44
[Train] Epoch: 3 [439872/620022]    Loss: 0.008798   Batch Acc: 81.25
[Train] Epoch: 3 [439936/620022]    Loss: 0.007756   Batch Acc: 75.00
[Train] Epoch: 3 [440000/620022]    Loss: 0.007008   Batch Acc: 78.12
[Train] Epoch: 3 [440064/620022]    Loss: 0.009468   Batch Acc: 76.56
[Train] Epoch: 3 [440128/620022]    Loss: 0.006662   Batch Acc: 79.69
[Train] Epoch: 3 [440192/620022]    Loss: 0.011295   Batch Acc: 67.19
[Train] Epoch: 3 [440256/620022]    Loss: 0.008729   Batch Acc: 76.56
[Train] Epoch: 3 [440320/620022]    Loss: 0.012513   Batch Acc: 68.75
[Train] Epoch: 3 [440384/620022]    Loss: 0.009854   Batch Acc: 70.31
[Train] Epoch: 3 [440448/620022]    Loss: 0.007258   Batch Acc: 84.38
[Train] Epoch: 3 [440512/620022]    Loss: 0.009488   Batch Acc: 76.56
[Train] Epoch: 3 [440576/620022]    Loss: 0.009793   Batch Acc: 67.19
[Train] Epoch: 3 [440640/620022]    Loss: 0.008376   Batch Acc: 71.88
[Train] Epoch: 3 [440704/620022]    Loss: 0.007795   Batch Acc: 76.56
[Train] Epoch: 3 [440768/620022]    Loss: 0.008841   Batch Acc: 82.81
[Train] Epoch: 3 [440832/620022]    Loss: 0.009390   Batch Acc: 73.44
[Train] Epoch: 3 [440896/620022]    Loss: 0.007698   Batch Acc: 81.25
[Train] Epoch: 3 [440960/620022]    Loss: 0.007535   Batch Acc: 84.38
[Train] Epoch: 3 [441024/620022]    Loss: 0.008303   Batch Acc: 73.44
[Train] Epoch: 3 [441088/620022]    Loss: 0.010243   Batch Acc: 73.44
[Train] Epoch: 3 [441152/620022]    Loss: 0.008438   Batch Acc: 79.69
[Train] Epoch: 3 [441216/620022]    Loss: 0.009966   Batch Acc: 78.12
[Train] Epoch: 3 [441280/620022]    Loss: 0.009402   Batch Acc: 70.31
[Train] Epoch: 3 [441344/620022]    Loss: 0.008509   Batch Acc: 82.81
[Train] Epoch: 3 [441408/620022]    Loss: 0.010258   Batch Acc: 71.88
[Train] Epoch: 3 [441472/620022]    Loss: 0.006822   Batch Acc: 84.38
[Train] Epoch: 3 [441536/620022]    Loss: 0.006469   Batch Acc: 87.50
[Train] Epoch: 3 [441600/620022]    Loss: 0.009860   Batch Acc: 70.31
[Train] Epoch: 3 [441664/620022]    Loss: 0.010290   Batch Acc: 70.31
[Train] Epoch: 3 [441728/620022]    Loss: 0.008018   Batch Acc: 84.38
[Train] Epoch: 3 [441792/620022]    Loss: 0.006364   Batch Acc: 89.06
[Train] Epoch: 3 [441856/620022]    Loss: 0.008023   Batch Acc: 78.12
[Train] Epoch: 3 [441920/620022]    Loss: 0.010704   Batch Acc: 68.75
[Train] Epoch: 3 [441984/620022]    Loss: 0.008886   Batch Acc: 71.88
[Train] Epoch: 3 [442048/620022]    Loss: 0.008651   Batch Acc: 78.12
[Train] Epoch: 3 [442112/620022]    Loss: 0.010716   Batch Acc: 73.44
[Train] Epoch: 3 [442176/620022]    Loss: 0.006092   Batch Acc: 92.19
[Train] Epoch: 3 [442240/620022]    Loss: 0.007660   Batch Acc: 78.12
[Train] Epoch: 3 [442304/620022]    Loss: 0.008779   Batch Acc: 76.56
[Train] Epoch: 3 [442368/620022]    Loss: 0.006643   Batch Acc: 87.50
[Train] Epoch: 3 [442432/620022]    Loss: 0.009764   Batch Acc: 71.88
[Train] Epoch: 3 [442496/620022]    Loss: 0.010558   Batch Acc: 75.00
[Train] Epoch: 3 [442560/620022]    Loss: 0.007249   Batch Acc: 82.81
[Train] Epoch: 3 [442624/620022]    Loss: 0.007447   Batch Acc: 84.38
[Train] Epoch: 3 [442688/620022]    Loss: 0.008963   Batch Acc: 81.25
[Train] Epoch: 3 [442752/620022]    Loss: 0.008396   Batch Acc: 76.56
[Train] Epoch: 3 [442816/620022]    Loss: 0.008306   Batch Acc: 73.44
[Train] Epoch: 3 [442880/620022]    Loss: 0.007900   Batch Acc: 81.25
[Train] Epoch: 3 [442944/620022]    Loss: 0.010480   Batch Acc: 73.44
[Train] Epoch: 3 [443008/620022]    Loss: 0.008693   Batch Acc: 76.56
[Train] Epoch: 3 [443072/620022]    Loss: 0.011137   Batch Acc: 60.94
[Train] Epoch: 3 [443136/620022]    Loss: 0.010935   Batch Acc: 68.75
[Train] Epoch: 3 [443200/620022]    Loss: 0.009095   Batch Acc: 73.44
[Train] Epoch: 3 [443264/620022]    Loss: 0.006906   Batch Acc: 81.25
[Train] Epoch: 3 [443328/620022]    Loss: 0.009362   Batch Acc: 73.44
[Train] Epoch: 3 [443392/620022]    Loss: 0.009734   Batch Acc: 73.44
[Train] Epoch: 3 [443456/620022]    Loss: 0.007978   Batch Acc: 76.56
[Train] Epoch: 3 [443520/620022]    Loss: 0.007716   Batch Acc: 75.00
[Train] Epoch: 3 [443584/620022]    Loss: 0.006600   Batch Acc: 82.81
[Train] Epoch: 3 [443648/620022]    Loss: 0.010143   Batch Acc: 65.62
[Train] Epoch: 3 [443712/620022]    Loss: 0.008967   Batch Acc: 73.44
[Train] Epoch: 3 [443776/620022]    Loss: 0.008727   Batch Acc: 81.25
[Train] Epoch: 3 [443840/620022]    Loss: 0.009847   Batch Acc: 76.56
[Train] Epoch: 3 [443904/620022]    Loss: 0.009805   Batch Acc: 73.44
[Train] Epoch: 3 [443968/620022]    Loss: 0.009947   Batch Acc: 75.00
[Train] Epoch: 3 [444032/620022]    Loss: 0.008327   Batch Acc: 76.56
[Train] Epoch: 3 [444096/620022]    Loss: 0.009892   Batch Acc: 73.44
[Train] Epoch: 3 [444160/620022]    Loss: 0.011901   Batch Acc: 68.75
[Train] Epoch: 3 [444224/620022]    Loss: 0.010231   Batch Acc: 75.00
[Train] Epoch: 3 [444288/620022]    Loss: 0.008463   Batch Acc: 75.00
[Train] Epoch: 3 [444352/620022]    Loss: 0.008760   Batch Acc: 78.12
[Train] Epoch: 3 [444416/620022]    Loss: 0.007293   Batch Acc: 84.38
[Train] Epoch: 3 [444480/620022]    Loss: 0.007792   Batch Acc: 82.81
[Train] Epoch: 3 [444544/620022]    Loss: 0.012138   Batch Acc: 64.06
[Train] Epoch: 3 [444608/620022]    Loss: 0.008640   Batch Acc: 76.56
[Train] Epoch: 3 [444672/620022]    Loss: 0.010580   Batch Acc: 73.44
[Train] Epoch: 3 [444736/620022]    Loss: 0.007292   Batch Acc: 82.81
[Train] Epoch: 3 [444800/620022]    Loss: 0.009805   Batch Acc: 76.56
[Train] Epoch: 3 [444864/620022]    Loss: 0.011182   Batch Acc: 78.12
[Train] Epoch: 3 [444928/620022]    Loss: 0.008872   Batch Acc: 78.12
[Train] Epoch: 3 [444992/620022]    Loss: 0.008460   Batch Acc: 76.56
[Train] Epoch: 3 [445056/620022]    Loss: 0.007965   Batch Acc: 85.94
[Train] Epoch: 3 [445120/620022]    Loss: 0.008969   Batch Acc: 75.00
[Train] Epoch: 3 [445184/620022]    Loss: 0.010321   Batch Acc: 68.75
[Train] Epoch: 3 [445248/620022]    Loss: 0.008066   Batch Acc: 81.25
[Train] Epoch: 3 [445312/620022]    Loss: 0.008169   Batch Acc: 76.56
[Train] Epoch: 3 [445376/620022]    Loss: 0.006218   Batch Acc: 85.94
[Train] Epoch: 3 [445440/620022]    Loss: 0.009918   Batch Acc: 78.12
[Train] Epoch: 3 [445504/620022]    Loss: 0.009374   Batch Acc: 76.56
[Train] Epoch: 3 [445568/620022]    Loss: 0.010355   Batch Acc: 64.06
[Train] Epoch: 3 [445632/620022]    Loss: 0.009376   Batch Acc: 73.44
[Train] Epoch: 3 [445696/620022]    Loss: 0.007707   Batch Acc: 82.81
[Train] Epoch: 3 [445760/620022]    Loss: 0.008408   Batch Acc: 78.12
[Train] Epoch: 3 [445824/620022]    Loss: 0.009943   Batch Acc: 79.69
[Train] Epoch: 3 [445888/620022]    Loss: 0.010000   Batch Acc: 76.56
[Train] Epoch: 3 [445952/620022]    Loss: 0.007524   Batch Acc: 79.69
[Train] Epoch: 3 [446016/620022]    Loss: 0.008787   Batch Acc: 76.56
[Train] Epoch: 3 [446080/620022]    Loss: 0.010371   Batch Acc: 71.88
[Train] Epoch: 3 [446144/620022]    Loss: 0.006840   Batch Acc: 82.81
[Train] Epoch: 3 [446208/620022]    Loss: 0.008586   Batch Acc: 79.69
[Train] Epoch: 3 [446272/620022]    Loss: 0.011866   Batch Acc: 67.19
[Train] Epoch: 3 [446336/620022]    Loss: 0.009761   Batch Acc: 70.31
[Train] Epoch: 3 [446400/620022]    Loss: 0.008872   Batch Acc: 73.44
[Train] Epoch: 3 [446464/620022]    Loss: 0.009315   Batch Acc: 76.56
[Train] Epoch: 3 [446528/620022]    Loss: 0.009771   Batch Acc: 76.56
[Train] Epoch: 3 [446592/620022]    Loss: 0.010141   Batch Acc: 76.56
[Train] Epoch: 3 [446656/620022]    Loss: 0.007713   Batch Acc: 81.25
[Train] Epoch: 3 [446720/620022]    Loss: 0.009989   Batch Acc: 75.00
[Train] Epoch: 3 [446784/620022]    Loss: 0.009571   Batch Acc: 76.56
[Train] Epoch: 3 [446848/620022]    Loss: 0.009724   Batch Acc: 78.12
[Train] Epoch: 3 [446912/620022]    Loss: 0.007026   Batch Acc: 87.50
[Train] Epoch: 3 [446976/620022]    Loss: 0.010698   Batch Acc: 73.44
[Train] Epoch: 3 [447040/620022]    Loss: 0.006323   Batch Acc: 85.94
[Train] Epoch: 3 [447104/620022]    Loss: 0.008404   Batch Acc: 73.44
[Train] Epoch: 3 [447168/620022]    Loss: 0.011434   Batch Acc: 67.19
[Train] Epoch: 3 [447232/620022]    Loss: 0.010827   Batch Acc: 68.75
[Train] Epoch: 3 [447296/620022]    Loss: 0.010418   Batch Acc: 73.44
[Train] Epoch: 3 [447360/620022]    Loss: 0.009053   Batch Acc: 78.12
[Train] Epoch: 3 [447424/620022]    Loss: 0.008972   Batch Acc: 78.12
[Train] Epoch: 3 [447488/620022]    Loss: 0.006408   Batch Acc: 87.50
[Train] Epoch: 3 [447552/620022]    Loss: 0.010320   Batch Acc: 68.75
[Train] Epoch: 3 [447616/620022]    Loss: 0.008224   Batch Acc: 76.56
[Train] Epoch: 3 [447680/620022]    Loss: 0.009575   Batch Acc: 75.00
[Train] Epoch: 3 [447744/620022]    Loss: 0.009644   Batch Acc: 68.75
[Train] Epoch: 3 [447808/620022]    Loss: 0.007434   Batch Acc: 84.38
[Train] Epoch: 3 [447872/620022]    Loss: 0.008449   Batch Acc: 75.00
[Train] Epoch: 3 [447936/620022]    Loss: 0.010814   Batch Acc: 76.56
[Train] Epoch: 3 [448000/620022]    Loss: 0.009391   Batch Acc: 78.12
[Train] Epoch: 3 [448064/620022]    Loss: 0.004725   Batch Acc: 92.19
[Train] Epoch: 3 [448128/620022]    Loss: 0.011339   Batch Acc: 70.31
[Train] Epoch: 3 [448192/620022]    Loss: 0.009519   Batch Acc: 73.44
[Train] Epoch: 3 [448256/620022]    Loss: 0.009340   Batch Acc: 78.12
[Train] Epoch: 3 [448320/620022]    Loss: 0.006601   Batch Acc: 84.38
[Train] Epoch: 3 [448384/620022]    Loss: 0.008624   Batch Acc: 79.69
[Train] Epoch: 3 [448448/620022]    Loss: 0.008191   Batch Acc: 79.69
[Train] Epoch: 3 [448512/620022]    Loss: 0.007617   Batch Acc: 78.12
[Train] Epoch: 3 [448576/620022]    Loss: 0.008250   Batch Acc: 73.44
[Train] Epoch: 3 [448640/620022]    Loss: 0.011334   Batch Acc: 71.88
[Train] Epoch: 3 [448704/620022]    Loss: 0.008789   Batch Acc: 78.12
[Train] Epoch: 3 [448768/620022]    Loss: 0.008581   Batch Acc: 81.25
[Train] Epoch: 3 [448832/620022]    Loss: 0.010181   Batch Acc: 73.44
[Train] Epoch: 3 [448896/620022]    Loss: 0.009608   Batch Acc: 78.12
[Train] Epoch: 3 [448960/620022]    Loss: 0.008755   Batch Acc: 76.56
[Train] Epoch: 3 [449024/620022]    Loss: 0.009035   Batch Acc: 79.69
[Train] Epoch: 3 [449088/620022]    Loss: 0.010890   Batch Acc: 68.75
[Train] Epoch: 3 [449152/620022]    Loss: 0.008562   Batch Acc: 70.31
[Train] Epoch: 3 [449216/620022]    Loss: 0.009812   Batch Acc: 76.56
[Train] Epoch: 3 [449280/620022]    Loss: 0.009866   Batch Acc: 76.56
[Train] Epoch: 3 [449344/620022]    Loss: 0.008857   Batch Acc: 81.25
[Train] Epoch: 3 [449408/620022]    Loss: 0.009751   Batch Acc: 71.88
[Train] Epoch: 3 [449472/620022]    Loss: 0.007212   Batch Acc: 82.81
[Train] Epoch: 3 [449536/620022]    Loss: 0.008321   Batch Acc: 75.00
[Train] Epoch: 3 [449600/620022]    Loss: 0.010452   Batch Acc: 71.88
[Train] Epoch: 3 [449664/620022]    Loss: 0.009335   Batch Acc: 73.44
[Train] Epoch: 3 [449728/620022]    Loss: 0.009784   Batch Acc: 75.00
[Train] Epoch: 3 [449792/620022]    Loss: 0.009354   Batch Acc: 73.44
[Train] Epoch: 3 [449856/620022]    Loss: 0.007075   Batch Acc: 87.50
[Train] Epoch: 3 [449920/620022]    Loss: 0.010366   Batch Acc: 67.19
[Train] Epoch: 3 [449984/620022]    Loss: 0.007507   Batch Acc: 81.25
[Train] Epoch: 3 [450048/620022]    Loss: 0.008215   Batch Acc: 79.69
[Train] Epoch: 3 [450112/620022]    Loss: 0.008258   Batch Acc: 81.25
[Train] Epoch: 3 [450176/620022]    Loss: 0.009875   Batch Acc: 73.44
[Train] Epoch: 3 [450240/620022]    Loss: 0.008773   Batch Acc: 76.56
[Train] Epoch: 3 [450304/620022]    Loss: 0.008126   Batch Acc: 73.44
[Train] Epoch: 3 [450368/620022]    Loss: 0.010993   Batch Acc: 70.31
[Train] Epoch: 3 [450432/620022]    Loss: 0.010460   Batch Acc: 65.62
[Train] Epoch: 3 [450496/620022]    Loss: 0.008668   Batch Acc: 78.12
[Train] Epoch: 3 [450560/620022]    Loss: 0.009346   Batch Acc: 78.12
[Train] Epoch: 3 [450624/620022]    Loss: 0.008993   Batch Acc: 67.19
[Train] Epoch: 3 [450688/620022]    Loss: 0.008565   Batch Acc: 82.81
[Train] Epoch: 3 [450752/620022]    Loss: 0.008369   Batch Acc: 84.38
[Train] Epoch: 3 [450816/620022]    Loss: 0.008775   Batch Acc: 79.69
[Train] Epoch: 3 [450880/620022]    Loss: 0.010586   Batch Acc: 70.31
[Train] Epoch: 3 [450944/620022]    Loss: 0.007017   Batch Acc: 87.50
[Train] Epoch: 3 [451008/620022]    Loss: 0.008377   Batch Acc: 79.69
[Train] Epoch: 3 [451072/620022]    Loss: 0.011676   Batch Acc: 71.88
[Train] Epoch: 3 [451136/620022]    Loss: 0.007381   Batch Acc: 78.12
[Train] Epoch: 3 [451200/620022]    Loss: 0.008488   Batch Acc: 75.00
[Train] Epoch: 3 [451264/620022]    Loss: 0.009164   Batch Acc: 76.56
[Train] Epoch: 3 [451328/620022]    Loss: 0.007430   Batch Acc: 81.25
[Train] Epoch: 3 [451392/620022]    Loss: 0.007944   Batch Acc: 79.69
[Train] Epoch: 3 [451456/620022]    Loss: 0.007245   Batch Acc: 82.81
[Train] Epoch: 3 [451520/620022]    Loss: 0.007493   Batch Acc: 84.38
[Train] Epoch: 3 [451584/620022]    Loss: 0.007413   Batch Acc: 79.69
[Train] Epoch: 3 [451648/620022]    Loss: 0.008367   Batch Acc: 76.56
[Train] Epoch: 3 [451712/620022]    Loss: 0.008059   Batch Acc: 81.25
[Train] Epoch: 3 [451776/620022]    Loss: 0.005650   Batch Acc: 85.94
[Train] Epoch: 3 [451840/620022]    Loss: 0.008619   Batch Acc: 79.69
[Train] Epoch: 3 [451904/620022]    Loss: 0.008342   Batch Acc: 82.81
[Train] Epoch: 3 [451968/620022]    Loss: 0.008021   Batch Acc: 78.12
[Train] Epoch: 3 [452032/620022]    Loss: 0.007010   Batch Acc: 84.38
[Train] Epoch: 3 [452096/620022]    Loss: 0.007936   Batch Acc: 79.69
[Train] Epoch: 3 [452160/620022]    Loss: 0.007817   Batch Acc: 82.81
[Train] Epoch: 3 [452224/620022]    Loss: 0.007993   Batch Acc: 75.00
[Train] Epoch: 3 [452288/620022]    Loss: 0.010697   Batch Acc: 70.31
[Train] Epoch: 3 [452352/620022]    Loss: 0.008911   Batch Acc: 78.12
[Train] Epoch: 3 [452416/620022]    Loss: 0.010379   Batch Acc: 75.00
[Train] Epoch: 3 [452480/620022]    Loss: 0.010330   Batch Acc: 75.00
[Train] Epoch: 3 [452544/620022]    Loss: 0.008490   Batch Acc: 82.81
[Train] Epoch: 3 [452608/620022]    Loss: 0.011805   Batch Acc: 73.44
[Train] Epoch: 3 [452672/620022]    Loss: 0.008909   Batch Acc: 79.69
[Train] Epoch: 3 [452736/620022]    Loss: 0.008823   Batch Acc: 76.56
[Train] Epoch: 3 [452800/620022]    Loss: 0.008263   Batch Acc: 79.69
[Train] Epoch: 3 [452864/620022]    Loss: 0.009533   Batch Acc: 70.31
[Train] Epoch: 3 [452928/620022]    Loss: 0.006997   Batch Acc: 84.38
[Train] Epoch: 3 [452992/620022]    Loss: 0.009424   Batch Acc: 76.56
[Train] Epoch: 3 [453056/620022]    Loss: 0.007154   Batch Acc: 79.69
[Train] Epoch: 3 [453120/620022]    Loss: 0.008439   Batch Acc: 79.69
[Train] Epoch: 3 [453184/620022]    Loss: 0.009724   Batch Acc: 76.56
[Train] Epoch: 3 [453248/620022]    Loss: 0.008996   Batch Acc: 76.56
[Train] Epoch: 3 [453312/620022]    Loss: 0.010657   Batch Acc: 67.19
[Train] Epoch: 3 [453376/620022]    Loss: 0.007912   Batch Acc: 73.44
[Train] Epoch: 3 [453440/620022]    Loss: 0.006321   Batch Acc: 84.38
[Train] Epoch: 3 [453504/620022]    Loss: 0.009754   Batch Acc: 73.44
[Train] Epoch: 3 [453568/620022]    Loss: 0.008756   Batch Acc: 79.69
[Train] Epoch: 3 [453632/620022]    Loss: 0.006575   Batch Acc: 84.38
[Train] Epoch: 3 [453696/620022]    Loss: 0.007118   Batch Acc: 84.38
[Train] Epoch: 3 [453760/620022]    Loss: 0.008350   Batch Acc: 79.69
[Train] Epoch: 3 [453824/620022]    Loss: 0.007487   Batch Acc: 85.94
[Train] Epoch: 3 [453888/620022]    Loss: 0.008812   Batch Acc: 76.56
[Train] Epoch: 3 [453952/620022]    Loss: 0.005670   Batch Acc: 87.50
[Train] Epoch: 3 [454016/620022]    Loss: 0.009806   Batch Acc: 78.12
[Train] Epoch: 3 [454080/620022]    Loss: 0.005896   Batch Acc: 89.06
[Train] Epoch: 3 [454144/620022]    Loss: 0.009033   Batch Acc: 79.69
[Train] Epoch: 3 [454208/620022]    Loss: 0.008187   Batch Acc: 81.25
[Train] Epoch: 3 [454272/620022]    Loss: 0.008603   Batch Acc: 76.56
[Train] Epoch: 3 [454336/620022]    Loss: 0.008459   Batch Acc: 81.25
[Train] Epoch: 3 [454400/620022]    Loss: 0.011300   Batch Acc: 70.31
[Train] Epoch: 3 [454464/620022]    Loss: 0.008538   Batch Acc: 79.69
[Train] Epoch: 3 [454528/620022]    Loss: 0.010196   Batch Acc: 75.00
[Train] Epoch: 3 [454592/620022]    Loss: 0.007971   Batch Acc: 81.25
[Train] Epoch: 3 [454656/620022]    Loss: 0.007058   Batch Acc: 82.81
[Train] Epoch: 3 [454720/620022]    Loss: 0.007167   Batch Acc: 82.81
[Train] Epoch: 3 [454784/620022]    Loss: 0.009218   Batch Acc: 76.56
[Train] Epoch: 3 [454848/620022]    Loss: 0.008481   Batch Acc: 78.12
[Train] Epoch: 3 [454912/620022]    Loss: 0.007447   Batch Acc: 82.81
[Train] Epoch: 3 [454976/620022]    Loss: 0.008942   Batch Acc: 79.69
[Train] Epoch: 3 [455040/620022]    Loss: 0.007155   Batch Acc: 85.94
[Train] Epoch: 3 [455104/620022]    Loss: 0.009217   Batch Acc: 81.25
[Train] Epoch: 3 [455168/620022]    Loss: 0.009267   Batch Acc: 75.00
[Train] Epoch: 3 [455232/620022]    Loss: 0.010516   Batch Acc: 65.62
[Train] Epoch: 3 [455296/620022]    Loss: 0.009979   Batch Acc: 75.00
[Train] Epoch: 3 [455360/620022]    Loss: 0.008081   Batch Acc: 79.69
[Train] Epoch: 3 [455424/620022]    Loss: 0.007029   Batch Acc: 84.38
[Train] Epoch: 3 [455488/620022]    Loss: 0.008482   Batch Acc: 79.69
[Train] Epoch: 3 [455552/620022]    Loss: 0.009986   Batch Acc: 71.88
[Train] Epoch: 3 [455616/620022]    Loss: 0.011578   Batch Acc: 67.19
[Train] Epoch: 3 [455680/620022]    Loss: 0.008755   Batch Acc: 76.56
[Train] Epoch: 3 [455744/620022]    Loss: 0.009242   Batch Acc: 78.12
[Train] Epoch: 3 [455808/620022]    Loss: 0.007753   Batch Acc: 81.25
[Train] Epoch: 3 [455872/620022]    Loss: 0.007371   Batch Acc: 82.81
[Train] Epoch: 3 [455936/620022]    Loss: 0.007190   Batch Acc: 85.94
[Train] Epoch: 3 [456000/620022]    Loss: 0.010520   Batch Acc: 78.12
[Train] Epoch: 3 [456064/620022]    Loss: 0.009298   Batch Acc: 81.25
[Train] Epoch: 3 [456128/620022]    Loss: 0.010883   Batch Acc: 65.62
[Train] Epoch: 3 [456192/620022]    Loss: 0.007324   Batch Acc: 82.81
[Train] Epoch: 3 [456256/620022]    Loss: 0.009933   Batch Acc: 76.56
[Train] Epoch: 3 [456320/620022]    Loss: 0.007876   Batch Acc: 82.81
[Train] Epoch: 3 [456384/620022]    Loss: 0.010321   Batch Acc: 70.31
[Train] Epoch: 3 [456448/620022]    Loss: 0.006843   Batch Acc: 84.38
[Train] Epoch: 3 [456512/620022]    Loss: 0.010722   Batch Acc: 71.88
[Train] Epoch: 3 [456576/620022]    Loss: 0.009133   Batch Acc: 76.56
[Train] Epoch: 3 [456640/620022]    Loss: 0.008788   Batch Acc: 78.12
[Train] Epoch: 3 [456704/620022]    Loss: 0.007675   Batch Acc: 84.38
[Train] Epoch: 3 [456768/620022]    Loss: 0.007934   Batch Acc: 81.25
[Train] Epoch: 3 [456832/620022]    Loss: 0.009777   Batch Acc: 71.88
[Train] Epoch: 3 [456896/620022]    Loss: 0.008306   Batch Acc: 78.12
[Train] Epoch: 3 [456960/620022]    Loss: 0.009946   Batch Acc: 71.88
[Train] Epoch: 3 [457024/620022]    Loss: 0.006488   Batch Acc: 85.94
[Train] Epoch: 3 [457088/620022]    Loss: 0.008439   Batch Acc: 70.31
[Train] Epoch: 3 [457152/620022]    Loss: 0.007058   Batch Acc: 85.94
[Train] Epoch: 3 [457216/620022]    Loss: 0.006856   Batch Acc: 81.25
[Train] Epoch: 3 [457280/620022]    Loss: 0.007537   Batch Acc: 84.38
[Train] Epoch: 3 [457344/620022]    Loss: 0.010095   Batch Acc: 71.88
[Train] Epoch: 3 [457408/620022]    Loss: 0.009563   Batch Acc: 76.56
[Train] Epoch: 3 [457472/620022]    Loss: 0.008422   Batch Acc: 78.12
[Train] Epoch: 3 [457536/620022]    Loss: 0.010124   Batch Acc: 70.31
[Train] Epoch: 3 [457600/620022]    Loss: 0.009022   Batch Acc: 76.56
[Train] Epoch: 3 [457664/620022]    Loss: 0.008876   Batch Acc: 75.00
[Train] Epoch: 3 [457728/620022]    Loss: 0.009141   Batch Acc: 70.31
[Train] Epoch: 3 [457792/620022]    Loss: 0.009799   Batch Acc: 76.56
[Train] Epoch: 3 [457856/620022]    Loss: 0.009284   Batch Acc: 76.56
[Train] Epoch: 3 [457920/620022]    Loss: 0.009095   Batch Acc: 76.56
[Train] Epoch: 3 [457984/620022]    Loss: 0.009692   Batch Acc: 73.44
[Train] Epoch: 3 [458048/620022]    Loss: 0.008193   Batch Acc: 78.12
[Train] Epoch: 3 [458112/620022]    Loss: 0.010204   Batch Acc: 73.44
[Train] Epoch: 3 [458176/620022]    Loss: 0.009003   Batch Acc: 70.31
[Train] Epoch: 3 [458240/620022]    Loss: 0.011143   Batch Acc: 68.75
[Train] Epoch: 3 [458304/620022]    Loss: 0.006305   Batch Acc: 81.25
[Train] Epoch: 3 [458368/620022]    Loss: 0.008122   Batch Acc: 75.00
[Train] Epoch: 3 [458432/620022]    Loss: 0.007347   Batch Acc: 85.94
[Train] Epoch: 3 [458496/620022]    Loss: 0.007539   Batch Acc: 85.94
[Train] Epoch: 3 [458560/620022]    Loss: 0.006661   Batch Acc: 85.94
[Train] Epoch: 3 [458624/620022]    Loss: 0.008695   Batch Acc: 81.25
[Train] Epoch: 3 [458688/620022]    Loss: 0.009111   Batch Acc: 78.12
[Train] Epoch: 3 [458752/620022]    Loss: 0.008213   Batch Acc: 85.94
[Train] Epoch: 3 [458816/620022]    Loss: 0.007737   Batch Acc: 73.44
[Train] Epoch: 3 [458880/620022]    Loss: 0.010994   Batch Acc: 68.75
[Train] Epoch: 3 [458944/620022]    Loss: 0.010296   Batch Acc: 68.75
[Train] Epoch: 3 [459008/620022]    Loss: 0.008887   Batch Acc: 81.25
[Train] Epoch: 3 [459072/620022]    Loss: 0.007510   Batch Acc: 79.69
[Train] Epoch: 3 [459136/620022]    Loss: 0.011077   Batch Acc: 79.69
[Train] Epoch: 3 [459200/620022]    Loss: 0.009408   Batch Acc: 71.88
[Train] Epoch: 3 [459264/620022]    Loss: 0.008083   Batch Acc: 76.56
[Train] Epoch: 3 [459328/620022]    Loss: 0.009180   Batch Acc: 76.56
[Train] Epoch: 3 [459392/620022]    Loss: 0.007129   Batch Acc: 87.50
[Train] Epoch: 3 [459456/620022]    Loss: 0.007543   Batch Acc: 85.94
[Train] Epoch: 3 [459520/620022]    Loss: 0.011225   Batch Acc: 73.44
[Train] Epoch: 3 [459584/620022]    Loss: 0.009701   Batch Acc: 75.00
[Train] Epoch: 3 [459648/620022]    Loss: 0.005256   Batch Acc: 90.62
[Train] Epoch: 3 [459712/620022]    Loss: 0.009421   Batch Acc: 71.88
[Train] Epoch: 3 [459776/620022]    Loss: 0.009488   Batch Acc: 67.19
[Train] Epoch: 3 [459840/620022]    Loss: 0.009239   Batch Acc: 76.56
[Train] Epoch: 3 [459904/620022]    Loss: 0.009960   Batch Acc: 76.56
[Train] Epoch: 3 [459968/620022]    Loss: 0.008882   Batch Acc: 73.44
[Train] Epoch: 3 [460032/620022]    Loss: 0.010486   Batch Acc: 78.12
[Train] Epoch: 3 [460096/620022]    Loss: 0.007820   Batch Acc: 82.81
[Train] Epoch: 3 [460160/620022]    Loss: 0.011067   Batch Acc: 71.88
[Train] Epoch: 3 [460224/620022]    Loss: 0.009407   Batch Acc: 81.25
[Train] Epoch: 3 [460288/620022]    Loss: 0.009892   Batch Acc: 70.31
[Train] Epoch: 3 [460352/620022]    Loss: 0.009530   Batch Acc: 78.12
[Train] Epoch: 3 [460416/620022]    Loss: 0.007907   Batch Acc: 81.25
[Train] Epoch: 3 [460480/620022]    Loss: 0.010115   Batch Acc: 73.44
[Train] Epoch: 3 [460544/620022]    Loss: 0.009788   Batch Acc: 75.00
[Train] Epoch: 3 [460608/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 3 [460672/620022]    Loss: 0.008887   Batch Acc: 71.88
[Train] Epoch: 3 [460736/620022]    Loss: 0.008470   Batch Acc: 75.00
[Train] Epoch: 3 [460800/620022]    Loss: 0.007726   Batch Acc: 78.12
[Train] Epoch: 3 [460864/620022]    Loss: 0.007810   Batch Acc: 79.69
[Train] Epoch: 3 [460928/620022]    Loss: 0.007501   Batch Acc: 78.12
[Train] Epoch: 3 [460992/620022]    Loss: 0.009379   Batch Acc: 78.12
[Train] Epoch: 3 [461056/620022]    Loss: 0.005953   Batch Acc: 85.94
[Train] Epoch: 3 [461120/620022]    Loss: 0.009028   Batch Acc: 75.00
[Train] Epoch: 3 [461184/620022]    Loss: 0.008304   Batch Acc: 79.69
[Train] Epoch: 3 [461248/620022]    Loss: 0.008148   Batch Acc: 73.44
[Train] Epoch: 3 [461312/620022]    Loss: 0.009896   Batch Acc: 71.88
[Train] Epoch: 3 [461376/620022]    Loss: 0.007488   Batch Acc: 81.25
[Train] Epoch: 3 [461440/620022]    Loss: 0.008376   Batch Acc: 78.12
[Train] Epoch: 3 [461504/620022]    Loss: 0.006960   Batch Acc: 85.94
[Train] Epoch: 3 [461568/620022]    Loss: 0.007503   Batch Acc: 82.81
[Train] Epoch: 3 [461632/620022]    Loss: 0.007467   Batch Acc: 81.25
[Train] Epoch: 3 [461696/620022]    Loss: 0.007721   Batch Acc: 79.69
[Train] Epoch: 3 [461760/620022]    Loss: 0.009717   Batch Acc: 73.44
[Train] Epoch: 3 [461824/620022]    Loss: 0.006884   Batch Acc: 82.81
[Train] Epoch: 3 [461888/620022]    Loss: 0.008065   Batch Acc: 82.81
[Train] Epoch: 3 [461952/620022]    Loss: 0.006925   Batch Acc: 84.38
[Train] Epoch: 3 [462016/620022]    Loss: 0.007786   Batch Acc: 71.88
[Train] Epoch: 3 [462080/620022]    Loss: 0.011115   Batch Acc: 71.88
[Train] Epoch: 3 [462144/620022]    Loss: 0.008814   Batch Acc: 79.69
[Train] Epoch: 3 [462208/620022]    Loss: 0.004547   Batch Acc: 90.62
[Train] Epoch: 3 [462272/620022]    Loss: 0.008891   Batch Acc: 79.69
[Train] Epoch: 3 [462336/620022]    Loss: 0.006589   Batch Acc: 84.38
[Train] Epoch: 3 [462400/620022]    Loss: 0.009298   Batch Acc: 73.44
[Train] Epoch: 3 [462464/620022]    Loss: 0.006973   Batch Acc: 81.25
[Train] Epoch: 3 [462528/620022]    Loss: 0.008980   Batch Acc: 73.44
[Train] Epoch: 3 [462592/620022]    Loss: 0.007063   Batch Acc: 87.50
[Train] Epoch: 3 [462656/620022]    Loss: 0.007720   Batch Acc: 82.81
[Train] Epoch: 3 [462720/620022]    Loss: 0.007461   Batch Acc: 78.12
[Train] Epoch: 3 [462784/620022]    Loss: 0.009653   Batch Acc: 71.88
[Train] Epoch: 3 [462848/620022]    Loss: 0.011976   Batch Acc: 71.88
[Train] Epoch: 3 [462912/620022]    Loss: 0.007700   Batch Acc: 84.38
[Train] Epoch: 3 [462976/620022]    Loss: 0.010355   Batch Acc: 70.31
[Train] Epoch: 3 [463040/620022]    Loss: 0.006609   Batch Acc: 85.94
[Train] Epoch: 3 [463104/620022]    Loss: 0.009448   Batch Acc: 79.69
[Train] Epoch: 3 [463168/620022]    Loss: 0.007914   Batch Acc: 82.81
[Train] Epoch: 3 [463232/620022]    Loss: 0.007677   Batch Acc: 82.81
[Train] Epoch: 3 [463296/620022]    Loss: 0.008727   Batch Acc: 73.44
[Train] Epoch: 3 [463360/620022]    Loss: 0.006123   Batch Acc: 87.50
[Train] Epoch: 3 [463424/620022]    Loss: 0.010242   Batch Acc: 78.12
[Train] Epoch: 3 [463488/620022]    Loss: 0.010855   Batch Acc: 68.75
[Train] Epoch: 3 [463552/620022]    Loss: 0.008937   Batch Acc: 75.00
[Train] Epoch: 3 [463616/620022]    Loss: 0.008538   Batch Acc: 79.69
[Train] Epoch: 3 [463680/620022]    Loss: 0.010544   Batch Acc: 75.00
[Train] Epoch: 3 [463744/620022]    Loss: 0.007230   Batch Acc: 84.38
[Train] Epoch: 3 [463808/620022]    Loss: 0.007224   Batch Acc: 84.38
[Train] Epoch: 3 [463872/620022]    Loss: 0.007480   Batch Acc: 84.38
[Train] Epoch: 3 [463936/620022]    Loss: 0.007783   Batch Acc: 78.12
[Train] Epoch: 3 [464000/620022]    Loss: 0.008550   Batch Acc: 82.81
[Train] Epoch: 3 [464064/620022]    Loss: 0.007609   Batch Acc: 81.25
[Train] Epoch: 3 [464128/620022]    Loss: 0.006572   Batch Acc: 87.50
[Train] Epoch: 3 [464192/620022]    Loss: 0.009493   Batch Acc: 70.31
[Train] Epoch: 3 [464256/620022]    Loss: 0.008872   Batch Acc: 76.56
[Train] Epoch: 3 [464320/620022]    Loss: 0.008199   Batch Acc: 78.12
[Train] Epoch: 3 [464384/620022]    Loss: 0.008150   Batch Acc: 82.81
[Train] Epoch: 3 [464448/620022]    Loss: 0.010534   Batch Acc: 73.44
[Train] Epoch: 3 [464512/620022]    Loss: 0.010959   Batch Acc: 81.25
[Train] Epoch: 3 [464576/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 3 [464640/620022]    Loss: 0.011712   Batch Acc: 64.06
[Train] Epoch: 3 [464704/620022]    Loss: 0.008829   Batch Acc: 75.00
[Train] Epoch: 3 [464768/620022]    Loss: 0.008933   Batch Acc: 71.88
[Train] Epoch: 3 [464832/620022]    Loss: 0.009422   Batch Acc: 75.00
[Train] Epoch: 3 [464896/620022]    Loss: 0.006886   Batch Acc: 84.38
[Train] Epoch: 3 [464960/620022]    Loss: 0.007297   Batch Acc: 85.94
[Train] Epoch: 3 [465024/620022]    Loss: 0.010627   Batch Acc: 73.44
[Train] Epoch: 3 [465088/620022]    Loss: 0.010800   Batch Acc: 73.44
[Train] Epoch: 3 [465152/620022]    Loss: 0.009573   Batch Acc: 76.56
[Train] Epoch: 3 [465216/620022]    Loss: 0.007959   Batch Acc: 78.12
[Train] Epoch: 3 [465280/620022]    Loss: 0.009395   Batch Acc: 75.00
[Train] Epoch: 3 [465344/620022]    Loss: 0.008220   Batch Acc: 76.56
[Train] Epoch: 3 [465408/620022]    Loss: 0.008425   Batch Acc: 73.44
[Train] Epoch: 3 [465472/620022]    Loss: 0.008318   Batch Acc: 78.12
[Train] Epoch: 3 [465536/620022]    Loss: 0.007891   Batch Acc: 81.25
[Train] Epoch: 3 [465600/620022]    Loss: 0.008611   Batch Acc: 78.12
[Train] Epoch: 3 [465664/620022]    Loss: 0.008091   Batch Acc: 81.25
[Train] Epoch: 3 [465728/620022]    Loss: 0.007124   Batch Acc: 82.81
[Train] Epoch: 3 [465792/620022]    Loss: 0.012003   Batch Acc: 65.62
[Train] Epoch: 3 [465856/620022]    Loss: 0.008417   Batch Acc: 73.44
[Train] Epoch: 3 [465920/620022]    Loss: 0.008673   Batch Acc: 78.12
[Train] Epoch: 3 [465984/620022]    Loss: 0.008962   Batch Acc: 78.12
[Train] Epoch: 3 [466048/620022]    Loss: 0.006554   Batch Acc: 87.50
[Train] Epoch: 3 [466112/620022]    Loss: 0.009027   Batch Acc: 78.12
[Train] Epoch: 3 [466176/620022]    Loss: 0.007752   Batch Acc: 82.81
[Train] Epoch: 3 [466240/620022]    Loss: 0.009301   Batch Acc: 78.12
[Train] Epoch: 3 [466304/620022]    Loss: 0.009227   Batch Acc: 73.44
[Train] Epoch: 3 [466368/620022]    Loss: 0.008705   Batch Acc: 81.25
[Train] Epoch: 3 [466432/620022]    Loss: 0.007795   Batch Acc: 82.81
[Train] Epoch: 3 [466496/620022]    Loss: 0.007710   Batch Acc: 79.69
[Train] Epoch: 3 [466560/620022]    Loss: 0.010583   Batch Acc: 71.88
[Train] Epoch: 3 [466624/620022]    Loss: 0.008648   Batch Acc: 82.81
[Train] Epoch: 3 [466688/620022]    Loss: 0.009377   Batch Acc: 75.00
[Train] Epoch: 3 [466752/620022]    Loss: 0.011191   Batch Acc: 67.19
[Train] Epoch: 3 [466816/620022]    Loss: 0.008584   Batch Acc: 76.56
[Train] Epoch: 3 [466880/620022]    Loss: 0.007982   Batch Acc: 82.81
[Train] Epoch: 3 [466944/620022]    Loss: 0.007973   Batch Acc: 73.44
[Train] Epoch: 3 [467008/620022]    Loss: 0.008159   Batch Acc: 79.69
[Train] Epoch: 3 [467072/620022]    Loss: 0.006928   Batch Acc: 78.12
[Train] Epoch: 3 [467136/620022]    Loss: 0.008157   Batch Acc: 73.44
[Train] Epoch: 3 [467200/620022]    Loss: 0.008726   Batch Acc: 76.56
[Train] Epoch: 3 [467264/620022]    Loss: 0.009098   Batch Acc: 78.12
[Train] Epoch: 3 [467328/620022]    Loss: 0.008125   Batch Acc: 78.12
[Train] Epoch: 3 [467392/620022]    Loss: 0.008786   Batch Acc: 73.44
[Train] Epoch: 3 [467456/620022]    Loss: 0.008992   Batch Acc: 76.56
[Train] Epoch: 3 [467520/620022]    Loss: 0.007694   Batch Acc: 79.69
[Train] Epoch: 3 [467584/620022]    Loss: 0.010769   Batch Acc: 75.00
[Train] Epoch: 3 [467648/620022]    Loss: 0.009366   Batch Acc: 75.00
[Train] Epoch: 3 [467712/620022]    Loss: 0.008943   Batch Acc: 76.56
[Train] Epoch: 3 [467776/620022]    Loss: 0.010034   Batch Acc: 68.75
[Train] Epoch: 3 [467840/620022]    Loss: 0.009279   Batch Acc: 73.44
[Train] Epoch: 3 [467904/620022]    Loss: 0.009783   Batch Acc: 75.00
[Train] Epoch: 3 [467968/620022]    Loss: 0.010368   Batch Acc: 70.31
[Train] Epoch: 3 [468032/620022]    Loss: 0.012139   Batch Acc: 65.62
[Train] Epoch: 3 [468096/620022]    Loss: 0.010564   Batch Acc: 67.19
[Train] Epoch: 3 [468160/620022]    Loss: 0.010152   Batch Acc: 81.25
[Train] Epoch: 3 [468224/620022]    Loss: 0.008094   Batch Acc: 79.69
[Train] Epoch: 3 [468288/620022]    Loss: 0.008317   Batch Acc: 73.44
[Train] Epoch: 3 [468352/620022]    Loss: 0.007273   Batch Acc: 85.94
[Train] Epoch: 3 [468416/620022]    Loss: 0.010498   Batch Acc: 73.44
[Train] Epoch: 3 [468480/620022]    Loss: 0.011409   Batch Acc: 70.31
[Train] Epoch: 3 [468544/620022]    Loss: 0.009054   Batch Acc: 73.44
[Train] Epoch: 3 [468608/620022]    Loss: 0.008777   Batch Acc: 71.88
[Train] Epoch: 3 [468672/620022]    Loss: 0.010014   Batch Acc: 71.88
[Train] Epoch: 3 [468736/620022]    Loss: 0.011076   Batch Acc: 71.88
[Train] Epoch: 3 [468800/620022]    Loss: 0.008628   Batch Acc: 78.12
[Train] Epoch: 3 [468864/620022]    Loss: 0.009935   Batch Acc: 78.12
[Train] Epoch: 3 [468928/620022]    Loss: 0.009512   Batch Acc: 73.44
[Train] Epoch: 3 [468992/620022]    Loss: 0.010151   Batch Acc: 67.19
[Train] Epoch: 3 [469056/620022]    Loss: 0.007377   Batch Acc: 78.12
[Train] Epoch: 3 [469120/620022]    Loss: 0.008640   Batch Acc: 71.88
[Train] Epoch: 3 [469184/620022]    Loss: 0.008755   Batch Acc: 78.12
[Train] Epoch: 3 [469248/620022]    Loss: 0.008756   Batch Acc: 73.44
[Train] Epoch: 3 [469312/620022]    Loss: 0.007952   Batch Acc: 79.69
[Train] Epoch: 3 [469376/620022]    Loss: 0.008666   Batch Acc: 76.56
[Train] Epoch: 3 [469440/620022]    Loss: 0.009834   Batch Acc: 73.44
[Train] Epoch: 3 [469504/620022]    Loss: 0.009894   Batch Acc: 73.44
[Train] Epoch: 3 [469568/620022]    Loss: 0.005529   Batch Acc: 85.94
[Train] Epoch: 3 [469632/620022]    Loss: 0.008612   Batch Acc: 78.12
[Train] Epoch: 3 [469696/620022]    Loss: 0.007471   Batch Acc: 81.25
[Train] Epoch: 3 [469760/620022]    Loss: 0.008957   Batch Acc: 75.00
[Train] Epoch: 3 [469824/620022]    Loss: 0.008876   Batch Acc: 81.25
[Train] Epoch: 3 [469888/620022]    Loss: 0.006705   Batch Acc: 84.38
[Train] Epoch: 3 [469952/620022]    Loss: 0.007826   Batch Acc: 75.00
[Train] Epoch: 3 [470016/620022]    Loss: 0.007192   Batch Acc: 81.25
[Train] Epoch: 3 [470080/620022]    Loss: 0.009926   Batch Acc: 75.00
[Train] Epoch: 3 [470144/620022]    Loss: 0.008882   Batch Acc: 73.44
[Train] Epoch: 3 [470208/620022]    Loss: 0.009424   Batch Acc: 79.69
[Train] Epoch: 3 [470272/620022]    Loss: 0.008714   Batch Acc: 82.81
[Train] Epoch: 3 [470336/620022]    Loss: 0.010819   Batch Acc: 71.88
[Train] Epoch: 3 [470400/620022]    Loss: 0.007924   Batch Acc: 81.25
[Train] Epoch: 3 [470464/620022]    Loss: 0.009329   Batch Acc: 71.88
[Train] Epoch: 3 [470528/620022]    Loss: 0.006749   Batch Acc: 85.94
[Train] Epoch: 3 [470592/620022]    Loss: 0.008320   Batch Acc: 81.25
[Train] Epoch: 3 [470656/620022]    Loss: 0.009820   Batch Acc: 73.44
[Train] Epoch: 3 [470720/620022]    Loss: 0.008285   Batch Acc: 75.00
[Train] Epoch: 3 [470784/620022]    Loss: 0.006859   Batch Acc: 85.94
[Train] Epoch: 3 [470848/620022]    Loss: 0.008222   Batch Acc: 82.81
[Train] Epoch: 3 [470912/620022]    Loss: 0.007236   Batch Acc: 84.38
[Train] Epoch: 3 [470976/620022]    Loss: 0.008712   Batch Acc: 75.00
[Train] Epoch: 3 [471040/620022]    Loss: 0.008907   Batch Acc: 76.56
[Train] Epoch: 3 [471104/620022]    Loss: 0.010684   Batch Acc: 75.00
[Train] Epoch: 3 [471168/620022]    Loss: 0.009417   Batch Acc: 73.44
[Train] Epoch: 3 [471232/620022]    Loss: 0.007434   Batch Acc: 79.69
[Train] Epoch: 3 [471296/620022]    Loss: 0.008610   Batch Acc: 73.44
[Train] Epoch: 3 [471360/620022]    Loss: 0.009554   Batch Acc: 65.62
[Train] Epoch: 3 [471424/620022]    Loss: 0.009112   Batch Acc: 71.88
[Train] Epoch: 3 [471488/620022]    Loss: 0.006611   Batch Acc: 84.38
[Train] Epoch: 3 [471552/620022]    Loss: 0.009857   Batch Acc: 73.44
[Train] Epoch: 3 [471616/620022]    Loss: 0.008068   Batch Acc: 85.94
[Train] Epoch: 3 [471680/620022]    Loss: 0.009679   Batch Acc: 75.00
[Train] Epoch: 3 [471744/620022]    Loss: 0.009497   Batch Acc: 78.12
[Train] Epoch: 3 [471808/620022]    Loss: 0.006662   Batch Acc: 78.12
[Train] Epoch: 3 [471872/620022]    Loss: 0.009030   Batch Acc: 73.44
[Train] Epoch: 3 [471936/620022]    Loss: 0.009581   Batch Acc: 70.31
[Train] Epoch: 3 [472000/620022]    Loss: 0.008374   Batch Acc: 76.56
[Train] Epoch: 3 [472064/620022]    Loss: 0.007127   Batch Acc: 89.06
[Train] Epoch: 3 [472128/620022]    Loss: 0.007995   Batch Acc: 81.25
[Train] Epoch: 3 [472192/620022]    Loss: 0.008017   Batch Acc: 81.25
[Train] Epoch: 3 [472256/620022]    Loss: 0.009929   Batch Acc: 71.88
[Train] Epoch: 3 [472320/620022]    Loss: 0.008402   Batch Acc: 79.69
[Train] Epoch: 3 [472384/620022]    Loss: 0.008017   Batch Acc: 78.12
[Train] Epoch: 3 [472448/620022]    Loss: 0.010049   Batch Acc: 71.88
[Train] Epoch: 3 [472512/620022]    Loss: 0.010192   Batch Acc: 68.75
[Train] Epoch: 3 [472576/620022]    Loss: 0.009274   Batch Acc: 73.44
[Train] Epoch: 3 [472640/620022]    Loss: 0.009519   Batch Acc: 76.56
[Train] Epoch: 3 [472704/620022]    Loss: 0.009025   Batch Acc: 73.44
[Train] Epoch: 3 [472768/620022]    Loss: 0.008670   Batch Acc: 75.00
[Train] Epoch: 3 [472832/620022]    Loss: 0.009015   Batch Acc: 78.12
[Train] Epoch: 3 [472896/620022]    Loss: 0.008274   Batch Acc: 78.12
[Train] Epoch: 3 [472960/620022]    Loss: 0.008044   Batch Acc: 76.56
[Train] Epoch: 3 [473024/620022]    Loss: 0.010232   Batch Acc: 71.88
[Train] Epoch: 3 [473088/620022]    Loss: 0.007715   Batch Acc: 84.38
[Train] Epoch: 3 [473152/620022]    Loss: 0.006813   Batch Acc: 79.69
[Train] Epoch: 3 [473216/620022]    Loss: 0.009631   Batch Acc: 76.56
[Train] Epoch: 3 [473280/620022]    Loss: 0.008268   Batch Acc: 87.50
[Train] Epoch: 3 [473344/620022]    Loss: 0.009897   Batch Acc: 70.31
[Train] Epoch: 3 [473408/620022]    Loss: 0.009188   Batch Acc: 73.44
[Train] Epoch: 3 [473472/620022]    Loss: 0.008914   Batch Acc: 81.25
[Train] Epoch: 3 [473536/620022]    Loss: 0.009161   Batch Acc: 78.12
[Train] Epoch: 3 [473600/620022]    Loss: 0.008392   Batch Acc: 78.12
[Train] Epoch: 3 [473664/620022]    Loss: 0.007899   Batch Acc: 81.25
[Train] Epoch: 3 [473728/620022]    Loss: 0.007482   Batch Acc: 81.25
[Train] Epoch: 3 [473792/620022]    Loss: 0.010130   Batch Acc: 70.31
[Train] Epoch: 3 [473856/620022]    Loss: 0.012096   Batch Acc: 71.88
[Train] Epoch: 3 [473920/620022]    Loss: 0.007740   Batch Acc: 81.25
[Train] Epoch: 3 [473984/620022]    Loss: 0.008359   Batch Acc: 82.81
[Train] Epoch: 3 [474048/620022]    Loss: 0.008768   Batch Acc: 70.31
[Train] Epoch: 3 [474112/620022]    Loss: 0.007237   Batch Acc: 85.94
[Train] Epoch: 3 [474176/620022]    Loss: 0.007673   Batch Acc: 82.81
[Train] Epoch: 3 [474240/620022]    Loss: 0.008170   Batch Acc: 81.25
[Train] Epoch: 3 [474304/620022]    Loss: 0.009669   Batch Acc: 76.56
[Train] Epoch: 3 [474368/620022]    Loss: 0.010337   Batch Acc: 70.31
[Train] Epoch: 3 [474432/620022]    Loss: 0.009539   Batch Acc: 73.44
[Train] Epoch: 3 [474496/620022]    Loss: 0.011358   Batch Acc: 65.62
[Train] Epoch: 3 [474560/620022]    Loss: 0.009278   Batch Acc: 76.56
[Train] Epoch: 3 [474624/620022]    Loss: 0.009935   Batch Acc: 73.44
[Train] Epoch: 3 [474688/620022]    Loss: 0.007866   Batch Acc: 81.25
[Train] Epoch: 3 [474752/620022]    Loss: 0.007845   Batch Acc: 85.94
[Train] Epoch: 3 [474816/620022]    Loss: 0.008855   Batch Acc: 84.38
[Train] Epoch: 3 [474880/620022]    Loss: 0.010599   Batch Acc: 67.19
[Train] Epoch: 3 [474944/620022]    Loss: 0.008448   Batch Acc: 73.44
[Train] Epoch: 3 [475008/620022]    Loss: 0.008199   Batch Acc: 78.12
[Train] Epoch: 3 [475072/620022]    Loss: 0.006699   Batch Acc: 82.81
[Train] Epoch: 3 [475136/620022]    Loss: 0.008208   Batch Acc: 82.81
[Train] Epoch: 3 [475200/620022]    Loss: 0.006920   Batch Acc: 81.25
[Train] Epoch: 3 [475264/620022]    Loss: 0.007922   Batch Acc: 78.12
[Train] Epoch: 3 [475328/620022]    Loss: 0.010013   Batch Acc: 73.44
[Train] Epoch: 3 [475392/620022]    Loss: 0.008377   Batch Acc: 81.25
[Train] Epoch: 3 [475456/620022]    Loss: 0.008226   Batch Acc: 84.38
[Train] Epoch: 3 [475520/620022]    Loss: 0.009444   Batch Acc: 65.62
[Train] Epoch: 3 [475584/620022]    Loss: 0.010394   Batch Acc: 71.88
[Train] Epoch: 3 [475648/620022]    Loss: 0.009259   Batch Acc: 78.12
[Train] Epoch: 3 [475712/620022]    Loss: 0.008665   Batch Acc: 78.12
[Train] Epoch: 3 [475776/620022]    Loss: 0.008722   Batch Acc: 78.12
[Train] Epoch: 3 [475840/620022]    Loss: 0.009270   Batch Acc: 75.00
[Train] Epoch: 3 [475904/620022]    Loss: 0.009336   Batch Acc: 75.00
[Train] Epoch: 3 [475968/620022]    Loss: 0.010200   Batch Acc: 68.75
[Train] Epoch: 3 [476032/620022]    Loss: 0.007659   Batch Acc: 79.69
[Train] Epoch: 3 [476096/620022]    Loss: 0.009843   Batch Acc: 71.88
[Train] Epoch: 3 [476160/620022]    Loss: 0.008159   Batch Acc: 84.38
[Train] Epoch: 3 [476224/620022]    Loss: 0.010407   Batch Acc: 70.31
[Train] Epoch: 3 [476288/620022]    Loss: 0.007776   Batch Acc: 82.81
[Train] Epoch: 3 [476352/620022]    Loss: 0.007559   Batch Acc: 84.38
[Train] Epoch: 3 [476416/620022]    Loss: 0.006857   Batch Acc: 82.81
[Train] Epoch: 3 [476480/620022]    Loss: 0.011369   Batch Acc: 65.62
[Train] Epoch: 3 [476544/620022]    Loss: 0.006737   Batch Acc: 85.94
[Train] Epoch: 3 [476608/620022]    Loss: 0.006810   Batch Acc: 84.38
[Train] Epoch: 3 [476672/620022]    Loss: 0.008192   Batch Acc: 81.25
[Train] Epoch: 3 [476736/620022]    Loss: 0.008200   Batch Acc: 81.25
[Train] Epoch: 3 [476800/620022]    Loss: 0.007984   Batch Acc: 81.25
[Train] Epoch: 3 [476864/620022]    Loss: 0.007060   Batch Acc: 82.81
[Train] Epoch: 3 [476928/620022]    Loss: 0.008075   Batch Acc: 79.69
[Train] Epoch: 3 [476992/620022]    Loss: 0.005869   Batch Acc: 89.06
[Train] Epoch: 3 [477056/620022]    Loss: 0.009402   Batch Acc: 78.12
[Train] Epoch: 3 [477120/620022]    Loss: 0.007739   Batch Acc: 81.25
[Train] Epoch: 3 [477184/620022]    Loss: 0.010033   Batch Acc: 65.62
[Train] Epoch: 3 [477248/620022]    Loss: 0.009148   Batch Acc: 75.00
[Train] Epoch: 3 [477312/620022]    Loss: 0.009336   Batch Acc: 76.56
[Train] Epoch: 3 [477376/620022]    Loss: 0.007242   Batch Acc: 85.94
[Train] Epoch: 3 [477440/620022]    Loss: 0.007521   Batch Acc: 82.81
[Train] Epoch: 3 [477504/620022]    Loss: 0.009476   Batch Acc: 75.00
[Train] Epoch: 3 [477568/620022]    Loss: 0.006474   Batch Acc: 82.81
[Train] Epoch: 3 [477632/620022]    Loss: 0.009649   Batch Acc: 78.12
[Train] Epoch: 3 [477696/620022]    Loss: 0.009274   Batch Acc: 84.38
[Train] Epoch: 3 [477760/620022]    Loss: 0.010568   Batch Acc: 70.31
[Train] Epoch: 3 [477824/620022]    Loss: 0.010106   Batch Acc: 81.25
[Train] Epoch: 3 [477888/620022]    Loss: 0.009460   Batch Acc: 76.56
[Train] Epoch: 3 [477952/620022]    Loss: 0.010295   Batch Acc: 70.31
[Train] Epoch: 3 [478016/620022]    Loss: 0.011236   Batch Acc: 71.88
[Train] Epoch: 3 [478080/620022]    Loss: 0.007980   Batch Acc: 78.12
[Train] Epoch: 3 [478144/620022]    Loss: 0.007144   Batch Acc: 81.25
[Train] Epoch: 3 [478208/620022]    Loss: 0.008066   Batch Acc: 75.00
[Train] Epoch: 3 [478272/620022]    Loss: 0.008096   Batch Acc: 76.56
[Train] Epoch: 3 [478336/620022]    Loss: 0.007043   Batch Acc: 82.81
[Train] Epoch: 3 [478400/620022]    Loss: 0.009318   Batch Acc: 73.44
[Train] Epoch: 3 [478464/620022]    Loss: 0.006867   Batch Acc: 85.94
[Train] Epoch: 3 [478528/620022]    Loss: 0.006397   Batch Acc: 79.69
[Train] Epoch: 3 [478592/620022]    Loss: 0.008883   Batch Acc: 76.56
[Train] Epoch: 3 [478656/620022]    Loss: 0.011987   Batch Acc: 67.19
[Train] Epoch: 3 [478720/620022]    Loss: 0.009773   Batch Acc: 76.56
[Train] Epoch: 3 [478784/620022]    Loss: 0.008554   Batch Acc: 76.56
[Train] Epoch: 3 [478848/620022]    Loss: 0.009335   Batch Acc: 71.88
[Train] Epoch: 3 [478912/620022]    Loss: 0.007432   Batch Acc: 84.38
[Train] Epoch: 3 [478976/620022]    Loss: 0.008370   Batch Acc: 85.94
[Train] Epoch: 3 [479040/620022]    Loss: 0.009836   Batch Acc: 81.25
[Train] Epoch: 3 [479104/620022]    Loss: 0.007635   Batch Acc: 81.25
[Train] Epoch: 3 [479168/620022]    Loss: 0.009981   Batch Acc: 71.88
[Train] Epoch: 3 [479232/620022]    Loss: 0.011055   Batch Acc: 73.44
[Train] Epoch: 3 [479296/620022]    Loss: 0.008180   Batch Acc: 84.38
[Train] Epoch: 3 [479360/620022]    Loss: 0.007357   Batch Acc: 87.50
[Train] Epoch: 3 [479424/620022]    Loss: 0.008915   Batch Acc: 78.12
[Train] Epoch: 3 [479488/620022]    Loss: 0.008555   Batch Acc: 75.00
[Train] Epoch: 3 [479552/620022]    Loss: 0.005981   Batch Acc: 84.38
[Train] Epoch: 3 [479616/620022]    Loss: 0.008097   Batch Acc: 79.69
[Train] Epoch: 3 [479680/620022]    Loss: 0.007758   Batch Acc: 81.25
[Train] Epoch: 3 [479744/620022]    Loss: 0.010737   Batch Acc: 76.56
[Train] Epoch: 3 [479808/620022]    Loss: 0.010548   Batch Acc: 70.31
[Train] Epoch: 3 [479872/620022]    Loss: 0.008150   Batch Acc: 79.69
[Train] Epoch: 3 [479936/620022]    Loss: 0.007558   Batch Acc: 81.25
[Train] Epoch: 3 [480000/620022]    Loss: 0.007442   Batch Acc: 79.69
[Train] Epoch: 3 [480064/620022]    Loss: 0.008161   Batch Acc: 81.25
[Train] Epoch: 3 [480128/620022]    Loss: 0.006083   Batch Acc: 85.94
[Train] Epoch: 3 [480192/620022]    Loss: 0.007812   Batch Acc: 73.44
[Train] Epoch: 3 [480256/620022]    Loss: 0.007446   Batch Acc: 79.69
[Train] Epoch: 3 [480320/620022]    Loss: 0.008802   Batch Acc: 82.81
[Train] Epoch: 3 [480384/620022]    Loss: 0.007949   Batch Acc: 79.69
[Train] Epoch: 3 [480448/620022]    Loss: 0.009677   Batch Acc: 78.12
[Train] Epoch: 3 [480512/620022]    Loss: 0.009093   Batch Acc: 82.81
[Train] Epoch: 3 [480576/620022]    Loss: 0.009484   Batch Acc: 76.56
[Train] Epoch: 3 [480640/620022]    Loss: 0.010684   Batch Acc: 70.31
[Train] Epoch: 3 [480704/620022]    Loss: 0.011678   Batch Acc: 73.44
[Train] Epoch: 3 [480768/620022]    Loss: 0.010186   Batch Acc: 75.00
[Train] Epoch: 3 [480832/620022]    Loss: 0.006933   Batch Acc: 82.81
[Train] Epoch: 3 [480896/620022]    Loss: 0.007726   Batch Acc: 76.56
[Train] Epoch: 3 [480960/620022]    Loss: 0.009003   Batch Acc: 78.12
[Train] Epoch: 3 [481024/620022]    Loss: 0.010512   Batch Acc: 67.19
[Train] Epoch: 3 [481088/620022]    Loss: 0.007577   Batch Acc: 79.69
[Train] Epoch: 3 [481152/620022]    Loss: 0.011464   Batch Acc: 62.50
[Train] Epoch: 3 [481216/620022]    Loss: 0.008416   Batch Acc: 76.56
[Train] Epoch: 3 [481280/620022]    Loss: 0.011438   Batch Acc: 70.31
[Train] Epoch: 3 [481344/620022]    Loss: 0.007070   Batch Acc: 81.25
[Train] Epoch: 3 [481408/620022]    Loss: 0.007736   Batch Acc: 84.38
[Train] Epoch: 3 [481472/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 3 [481536/620022]    Loss: 0.008204   Batch Acc: 84.38
[Train] Epoch: 3 [481600/620022]    Loss: 0.007650   Batch Acc: 82.81
[Train] Epoch: 3 [481664/620022]    Loss: 0.009176   Batch Acc: 75.00
[Train] Epoch: 3 [481728/620022]    Loss: 0.008553   Batch Acc: 78.12
[Train] Epoch: 3 [481792/620022]    Loss: 0.009245   Batch Acc: 78.12
[Train] Epoch: 3 [481856/620022]    Loss: 0.006410   Batch Acc: 87.50
[Train] Epoch: 3 [481920/620022]    Loss: 0.007940   Batch Acc: 79.69
[Train] Epoch: 3 [481984/620022]    Loss: 0.009985   Batch Acc: 73.44
[Train] Epoch: 3 [482048/620022]    Loss: 0.008549   Batch Acc: 78.12
[Train] Epoch: 3 [482112/620022]    Loss: 0.008147   Batch Acc: 78.12
[Train] Epoch: 3 [482176/620022]    Loss: 0.010175   Batch Acc: 75.00
[Train] Epoch: 3 [482240/620022]    Loss: 0.011015   Batch Acc: 71.88
[Train] Epoch: 3 [482304/620022]    Loss: 0.008767   Batch Acc: 81.25
[Train] Epoch: 3 [482368/620022]    Loss: 0.008311   Batch Acc: 78.12
[Train] Epoch: 3 [482432/620022]    Loss: 0.008517   Batch Acc: 75.00
[Train] Epoch: 3 [482496/620022]    Loss: 0.008659   Batch Acc: 79.69
[Train] Epoch: 3 [482560/620022]    Loss: 0.007565   Batch Acc: 84.38
[Train] Epoch: 3 [482624/620022]    Loss: 0.008280   Batch Acc: 78.12
[Train] Epoch: 3 [482688/620022]    Loss: 0.011239   Batch Acc: 76.56
[Train] Epoch: 3 [482752/620022]    Loss: 0.005849   Batch Acc: 85.94
[Train] Epoch: 3 [482816/620022]    Loss: 0.008390   Batch Acc: 76.56
[Train] Epoch: 3 [482880/620022]    Loss: 0.008779   Batch Acc: 73.44
[Train] Epoch: 3 [482944/620022]    Loss: 0.008231   Batch Acc: 79.69
[Train] Epoch: 3 [483008/620022]    Loss: 0.006313   Batch Acc: 84.38
[Train] Epoch: 3 [483072/620022]    Loss: 0.007083   Batch Acc: 82.81
[Train] Epoch: 3 [483136/620022]    Loss: 0.007873   Batch Acc: 78.12
[Train] Epoch: 3 [483200/620022]    Loss: 0.008971   Batch Acc: 75.00
[Train] Epoch: 3 [483264/620022]    Loss: 0.009344   Batch Acc: 76.56
[Train] Epoch: 3 [483328/620022]    Loss: 0.008932   Batch Acc: 75.00
[Train] Epoch: 3 [483392/620022]    Loss: 0.008145   Batch Acc: 82.81
[Train] Epoch: 3 [483456/620022]    Loss: 0.009265   Batch Acc: 75.00
[Train] Epoch: 3 [483520/620022]    Loss: 0.009001   Batch Acc: 71.88
[Train] Epoch: 3 [483584/620022]    Loss: 0.010293   Batch Acc: 75.00
[Train] Epoch: 3 [483648/620022]    Loss: 0.012085   Batch Acc: 65.62
[Train] Epoch: 3 [483712/620022]    Loss: 0.010445   Batch Acc: 76.56
[Train] Epoch: 3 [483776/620022]    Loss: 0.007916   Batch Acc: 75.00
[Train] Epoch: 3 [483840/620022]    Loss: 0.008376   Batch Acc: 78.12
[Train] Epoch: 3 [483904/620022]    Loss: 0.009536   Batch Acc: 73.44
[Train] Epoch: 3 [483968/620022]    Loss: 0.008694   Batch Acc: 78.12
[Train] Epoch: 3 [484032/620022]    Loss: 0.009948   Batch Acc: 75.00
[Train] Epoch: 3 [484096/620022]    Loss: 0.006361   Batch Acc: 89.06
[Train] Epoch: 3 [484160/620022]    Loss: 0.012416   Batch Acc: 70.31
[Train] Epoch: 3 [484224/620022]    Loss: 0.007361   Batch Acc: 84.38
[Train] Epoch: 3 [484288/620022]    Loss: 0.007784   Batch Acc: 79.69
[Train] Epoch: 3 [484352/620022]    Loss: 0.007139   Batch Acc: 87.50
[Train] Epoch: 3 [484416/620022]    Loss: 0.009894   Batch Acc: 70.31
[Train] Epoch: 3 [484480/620022]    Loss: 0.006465   Batch Acc: 82.81
[Train] Epoch: 3 [484544/620022]    Loss: 0.007785   Batch Acc: 87.50
[Train] Epoch: 3 [484608/620022]    Loss: 0.007845   Batch Acc: 76.56
[Train] Epoch: 3 [484672/620022]    Loss: 0.010762   Batch Acc: 71.88
[Train] Epoch: 3 [484736/620022]    Loss: 0.008922   Batch Acc: 75.00
[Train] Epoch: 3 [484800/620022]    Loss: 0.009255   Batch Acc: 78.12
[Train] Epoch: 3 [484864/620022]    Loss: 0.009551   Batch Acc: 73.44
[Train] Epoch: 3 [484928/620022]    Loss: 0.010366   Batch Acc: 73.44
[Train] Epoch: 3 [484992/620022]    Loss: 0.007407   Batch Acc: 84.38
[Train] Epoch: 3 [485056/620022]    Loss: 0.007431   Batch Acc: 79.69
[Train] Epoch: 3 [485120/620022]    Loss: 0.009763   Batch Acc: 78.12
[Train] Epoch: 3 [485184/620022]    Loss: 0.006933   Batch Acc: 82.81
[Train] Epoch: 3 [485248/620022]    Loss: 0.009283   Batch Acc: 76.56
[Train] Epoch: 3 [485312/620022]    Loss: 0.008783   Batch Acc: 76.56
[Train] Epoch: 3 [485376/620022]    Loss: 0.010806   Batch Acc: 70.31
[Train] Epoch: 3 [485440/620022]    Loss: 0.006829   Batch Acc: 82.81
[Train] Epoch: 3 [485504/620022]    Loss: 0.009951   Batch Acc: 76.56
[Train] Epoch: 3 [485568/620022]    Loss: 0.007366   Batch Acc: 84.38
[Train] Epoch: 3 [485632/620022]    Loss: 0.009765   Batch Acc: 73.44
[Train] Epoch: 3 [485696/620022]    Loss: 0.007466   Batch Acc: 82.81
[Train] Epoch: 3 [485760/620022]    Loss: 0.007964   Batch Acc: 79.69
[Train] Epoch: 3 [485824/620022]    Loss: 0.009551   Batch Acc: 79.69
[Train] Epoch: 3 [485888/620022]    Loss: 0.006987   Batch Acc: 87.50
[Train] Epoch: 3 [485952/620022]    Loss: 0.006766   Batch Acc: 82.81
[Train] Epoch: 3 [486016/620022]    Loss: 0.010644   Batch Acc: 70.31
[Train] Epoch: 3 [486080/620022]    Loss: 0.010475   Batch Acc: 73.44
[Train] Epoch: 3 [486144/620022]    Loss: 0.007088   Batch Acc: 82.81
[Train] Epoch: 3 [486208/620022]    Loss: 0.008554   Batch Acc: 79.69
[Train] Epoch: 3 [486272/620022]    Loss: 0.008640   Batch Acc: 82.81
[Train] Epoch: 3 [486336/620022]    Loss: 0.008855   Batch Acc: 76.56
[Train] Epoch: 3 [486400/620022]    Loss: 0.007657   Batch Acc: 78.12
[Train] Epoch: 3 [486464/620022]    Loss: 0.009468   Batch Acc: 73.44
[Train] Epoch: 3 [486528/620022]    Loss: 0.007850   Batch Acc: 82.81
[Train] Epoch: 3 [486592/620022]    Loss: 0.009641   Batch Acc: 71.88
[Train] Epoch: 3 [486656/620022]    Loss: 0.007153   Batch Acc: 82.81
[Train] Epoch: 3 [486720/620022]    Loss: 0.009946   Batch Acc: 76.56
[Train] Epoch: 3 [486784/620022]    Loss: 0.008270   Batch Acc: 82.81
[Train] Epoch: 3 [486848/620022]    Loss: 0.007724   Batch Acc: 82.81
[Train] Epoch: 3 [486912/620022]    Loss: 0.007290   Batch Acc: 78.12
[Train] Epoch: 3 [486976/620022]    Loss: 0.007500   Batch Acc: 81.25
[Train] Epoch: 3 [487040/620022]    Loss: 0.006493   Batch Acc: 85.94
[Train] Epoch: 3 [487104/620022]    Loss: 0.007143   Batch Acc: 84.38
[Train] Epoch: 3 [487168/620022]    Loss: 0.008307   Batch Acc: 78.12
[Train] Epoch: 3 [487232/620022]    Loss: 0.009308   Batch Acc: 68.75
[Train] Epoch: 3 [487296/620022]    Loss: 0.007835   Batch Acc: 79.69
[Train] Epoch: 3 [487360/620022]    Loss: 0.005317   Batch Acc: 90.62
[Train] Epoch: 3 [487424/620022]    Loss: 0.009467   Batch Acc: 73.44
[Train] Epoch: 3 [487488/620022]    Loss: 0.009376   Batch Acc: 76.56
[Train] Epoch: 3 [487552/620022]    Loss: 0.009685   Batch Acc: 76.56
[Train] Epoch: 3 [487616/620022]    Loss: 0.009237   Batch Acc: 76.56
[Train] Epoch: 3 [487680/620022]    Loss: 0.008918   Batch Acc: 79.69
[Train] Epoch: 3 [487744/620022]    Loss: 0.008288   Batch Acc: 81.25
[Train] Epoch: 3 [487808/620022]    Loss: 0.010609   Batch Acc: 71.88
[Train] Epoch: 3 [487872/620022]    Loss: 0.010688   Batch Acc: 75.00
[Train] Epoch: 3 [487936/620022]    Loss: 0.009688   Batch Acc: 76.56
[Train] Epoch: 3 [488000/620022]    Loss: 0.009388   Batch Acc: 75.00
[Train] Epoch: 3 [488064/620022]    Loss: 0.009232   Batch Acc: 73.44
[Train] Epoch: 3 [488128/620022]    Loss: 0.009300   Batch Acc: 71.88
[Train] Epoch: 3 [488192/620022]    Loss: 0.007996   Batch Acc: 81.25
[Train] Epoch: 3 [488256/620022]    Loss: 0.011640   Batch Acc: 68.75
[Train] Epoch: 3 [488320/620022]    Loss: 0.007258   Batch Acc: 84.38
[Train] Epoch: 3 [488384/620022]    Loss: 0.007537   Batch Acc: 81.25
[Train] Epoch: 3 [488448/620022]    Loss: 0.008294   Batch Acc: 78.12
[Train] Epoch: 3 [488512/620022]    Loss: 0.007743   Batch Acc: 81.25
[Train] Epoch: 3 [488576/620022]    Loss: 0.006434   Batch Acc: 85.94
[Train] Epoch: 3 [488640/620022]    Loss: 0.009071   Batch Acc: 71.88
[Train] Epoch: 3 [488704/620022]    Loss: 0.008580   Batch Acc: 75.00
[Train] Epoch: 3 [488768/620022]    Loss: 0.009368   Batch Acc: 76.56
[Train] Epoch: 3 [488832/620022]    Loss: 0.007954   Batch Acc: 84.38
[Train] Epoch: 3 [488896/620022]    Loss: 0.009033   Batch Acc: 68.75
[Train] Epoch: 3 [488960/620022]    Loss: 0.007420   Batch Acc: 81.25
[Train] Epoch: 3 [489024/620022]    Loss: 0.009164   Batch Acc: 78.12
[Train] Epoch: 3 [489088/620022]    Loss: 0.008294   Batch Acc: 81.25
[Train] Epoch: 3 [489152/620022]    Loss: 0.008800   Batch Acc: 73.44
[Train] Epoch: 3 [489216/620022]    Loss: 0.008810   Batch Acc: 78.12
[Train] Epoch: 3 [489280/620022]    Loss: 0.007081   Batch Acc: 84.38
[Train] Epoch: 3 [489344/620022]    Loss: 0.008609   Batch Acc: 78.12
[Train] Epoch: 3 [489408/620022]    Loss: 0.009339   Batch Acc: 70.31
[Train] Epoch: 3 [489472/620022]    Loss: 0.010179   Batch Acc: 73.44
[Train] Epoch: 3 [489536/620022]    Loss: 0.008961   Batch Acc: 75.00
[Train] Epoch: 3 [489600/620022]    Loss: 0.010074   Batch Acc: 71.88
[Train] Epoch: 3 [489664/620022]    Loss: 0.007889   Batch Acc: 82.81
[Train] Epoch: 3 [489728/620022]    Loss: 0.006919   Batch Acc: 84.38
[Train] Epoch: 3 [489792/620022]    Loss: 0.009310   Batch Acc: 73.44
[Train] Epoch: 3 [489856/620022]    Loss: 0.011110   Batch Acc: 68.75
[Train] Epoch: 3 [489920/620022]    Loss: 0.008122   Batch Acc: 78.12
[Train] Epoch: 3 [489984/620022]    Loss: 0.009634   Batch Acc: 79.69
[Train] Epoch: 3 [490048/620022]    Loss: 0.008554   Batch Acc: 73.44
[Train] Epoch: 3 [490112/620022]    Loss: 0.009323   Batch Acc: 73.44
[Train] Epoch: 3 [490176/620022]    Loss: 0.010049   Batch Acc: 76.56
[Train] Epoch: 3 [490240/620022]    Loss: 0.006513   Batch Acc: 89.06
[Train] Epoch: 3 [490304/620022]    Loss: 0.008805   Batch Acc: 78.12
[Train] Epoch: 3 [490368/620022]    Loss: 0.007218   Batch Acc: 81.25
[Train] Epoch: 3 [490432/620022]    Loss: 0.008803   Batch Acc: 76.56
[Train] Epoch: 3 [490496/620022]    Loss: 0.010612   Batch Acc: 68.75
[Train] Epoch: 3 [490560/620022]    Loss: 0.007419   Batch Acc: 79.69
[Train] Epoch: 3 [490624/620022]    Loss: 0.008545   Batch Acc: 75.00
[Train] Epoch: 3 [490688/620022]    Loss: 0.008540   Batch Acc: 73.44
[Train] Epoch: 3 [490752/620022]    Loss: 0.010669   Batch Acc: 73.44
[Train] Epoch: 3 [490816/620022]    Loss: 0.007720   Batch Acc: 79.69
[Train] Epoch: 3 [490880/620022]    Loss: 0.009325   Batch Acc: 75.00
[Train] Epoch: 3 [490944/620022]    Loss: 0.009412   Batch Acc: 79.69
[Train] Epoch: 3 [491008/620022]    Loss: 0.008350   Batch Acc: 76.56
[Train] Epoch: 3 [491072/620022]    Loss: 0.009473   Batch Acc: 71.88
[Train] Epoch: 3 [491136/620022]    Loss: 0.007181   Batch Acc: 81.25
[Train] Epoch: 3 [491200/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 3 [491264/620022]    Loss: 0.008312   Batch Acc: 78.12
[Train] Epoch: 3 [491328/620022]    Loss: 0.010340   Batch Acc: 65.62
[Train] Epoch: 3 [491392/620022]    Loss: 0.007221   Batch Acc: 81.25
[Train] Epoch: 3 [491456/620022]    Loss: 0.010205   Batch Acc: 75.00
[Train] Epoch: 3 [491520/620022]    Loss: 0.010632   Batch Acc: 68.75
[Train] Epoch: 3 [491584/620022]    Loss: 0.006501   Batch Acc: 84.38
[Train] Epoch: 3 [491648/620022]    Loss: 0.008831   Batch Acc: 73.44
[Train] Epoch: 3 [491712/620022]    Loss: 0.007154   Batch Acc: 81.25
[Train] Epoch: 3 [491776/620022]    Loss: 0.007750   Batch Acc: 84.38
[Train] Epoch: 3 [491840/620022]    Loss: 0.009821   Batch Acc: 75.00
[Train] Epoch: 3 [491904/620022]    Loss: 0.009962   Batch Acc: 70.31
[Train] Epoch: 3 [491968/620022]    Loss: 0.009009   Batch Acc: 81.25
[Train] Epoch: 3 [492032/620022]    Loss: 0.010605   Batch Acc: 76.56
[Train] Epoch: 3 [492096/620022]    Loss: 0.011347   Batch Acc: 67.19
[Train] Epoch: 3 [492160/620022]    Loss: 0.009103   Batch Acc: 76.56
[Train] Epoch: 3 [492224/620022]    Loss: 0.009194   Batch Acc: 76.56
[Train] Epoch: 3 [492288/620022]    Loss: 0.009707   Batch Acc: 73.44
[Train] Epoch: 3 [492352/620022]    Loss: 0.010317   Batch Acc: 75.00
[Train] Epoch: 3 [492416/620022]    Loss: 0.009258   Batch Acc: 78.12
[Train] Epoch: 3 [492480/620022]    Loss: 0.008526   Batch Acc: 81.25
[Train] Epoch: 3 [492544/620022]    Loss: 0.010742   Batch Acc: 71.88
[Train] Epoch: 3 [492608/620022]    Loss: 0.009839   Batch Acc: 75.00
[Train] Epoch: 3 [492672/620022]    Loss: 0.009475   Batch Acc: 75.00
[Train] Epoch: 3 [492736/620022]    Loss: 0.008756   Batch Acc: 78.12
[Train] Epoch: 3 [492800/620022]    Loss: 0.012068   Batch Acc: 73.44
[Train] Epoch: 3 [492864/620022]    Loss: 0.009355   Batch Acc: 71.88
[Train] Epoch: 3 [492928/620022]    Loss: 0.009300   Batch Acc: 71.88
[Train] Epoch: 3 [492992/620022]    Loss: 0.007362   Batch Acc: 85.94
[Train] Epoch: 3 [493056/620022]    Loss: 0.008103   Batch Acc: 82.81
[Train] Epoch: 3 [493120/620022]    Loss: 0.009858   Batch Acc: 78.12
[Train] Epoch: 3 [493184/620022]    Loss: 0.008656   Batch Acc: 79.69
[Train] Epoch: 3 [493248/620022]    Loss: 0.006451   Batch Acc: 81.25
[Train] Epoch: 3 [493312/620022]    Loss: 0.009614   Batch Acc: 79.69
[Train] Epoch: 3 [493376/620022]    Loss: 0.007994   Batch Acc: 78.12
[Train] Epoch: 3 [493440/620022]    Loss: 0.007287   Batch Acc: 79.69
[Train] Epoch: 3 [493504/620022]    Loss: 0.008480   Batch Acc: 81.25
[Train] Epoch: 3 [493568/620022]    Loss: 0.007391   Batch Acc: 78.12
[Train] Epoch: 3 [493632/620022]    Loss: 0.008494   Batch Acc: 75.00
[Train] Epoch: 3 [493696/620022]    Loss: 0.009703   Batch Acc: 75.00
[Train] Epoch: 3 [493760/620022]    Loss: 0.007131   Batch Acc: 81.25
[Train] Epoch: 3 [493824/620022]    Loss: 0.008091   Batch Acc: 81.25
[Train] Epoch: 3 [493888/620022]    Loss: 0.009841   Batch Acc: 75.00
[Train] Epoch: 3 [493952/620022]    Loss: 0.007188   Batch Acc: 85.94
[Train] Epoch: 3 [494016/620022]    Loss: 0.013028   Batch Acc: 62.50
[Train] Epoch: 3 [494080/620022]    Loss: 0.010143   Batch Acc: 75.00
[Train] Epoch: 3 [494144/620022]    Loss: 0.007304   Batch Acc: 82.81
[Train] Epoch: 3 [494208/620022]    Loss: 0.006807   Batch Acc: 84.38
[Train] Epoch: 3 [494272/620022]    Loss: 0.009353   Batch Acc: 78.12
[Train] Epoch: 3 [494336/620022]    Loss: 0.007031   Batch Acc: 85.94
[Train] Epoch: 3 [494400/620022]    Loss: 0.008968   Batch Acc: 81.25
[Train] Epoch: 3 [494464/620022]    Loss: 0.008097   Batch Acc: 76.56
[Train] Epoch: 3 [494528/620022]    Loss: 0.009368   Batch Acc: 75.00
[Train] Epoch: 3 [494592/620022]    Loss: 0.006290   Batch Acc: 85.94
[Train] Epoch: 3 [494656/620022]    Loss: 0.010283   Batch Acc: 73.44
[Train] Epoch: 3 [494720/620022]    Loss: 0.009424   Batch Acc: 73.44
[Train] Epoch: 3 [494784/620022]    Loss: 0.009815   Batch Acc: 70.31
[Train] Epoch: 3 [494848/620022]    Loss: 0.008313   Batch Acc: 81.25
[Train] Epoch: 3 [494912/620022]    Loss: 0.008826   Batch Acc: 82.81
[Train] Epoch: 3 [494976/620022]    Loss: 0.008877   Batch Acc: 75.00
[Train] Epoch: 3 [495040/620022]    Loss: 0.009118   Batch Acc: 79.69
[Train] Epoch: 3 [495104/620022]    Loss: 0.007332   Batch Acc: 79.69
[Train] Epoch: 3 [495168/620022]    Loss: 0.008550   Batch Acc: 81.25
[Train] Epoch: 3 [495232/620022]    Loss: 0.009315   Batch Acc: 76.56
[Train] Epoch: 3 [495296/620022]    Loss: 0.005996   Batch Acc: 90.62
[Train] Epoch: 3 [495360/620022]    Loss: 0.007428   Batch Acc: 81.25
[Train] Epoch: 3 [495424/620022]    Loss: 0.008368   Batch Acc: 73.44
[Train] Epoch: 3 [495488/620022]    Loss: 0.007382   Batch Acc: 81.25
[Train] Epoch: 3 [495552/620022]    Loss: 0.008959   Batch Acc: 85.94
[Train] Epoch: 3 [495616/620022]    Loss: 0.010675   Batch Acc: 73.44
[Train] Epoch: 3 [495680/620022]    Loss: 0.011547   Batch Acc: 65.62
[Train] Epoch: 3 [495744/620022]    Loss: 0.008141   Batch Acc: 71.88
[Train] Epoch: 3 [495808/620022]    Loss: 0.009333   Batch Acc: 76.56
[Train] Epoch: 3 [495872/620022]    Loss: 0.009461   Batch Acc: 73.44
[Train] Epoch: 3 [495936/620022]    Loss: 0.005249   Batch Acc: 92.19
[Train] Epoch: 3 [496000/620022]    Loss: 0.008900   Batch Acc: 79.69
[Train] Epoch: 3 [496064/620022]    Loss: 0.007598   Batch Acc: 82.81
[Train] Epoch: 3 [496128/620022]    Loss: 0.010483   Batch Acc: 70.31
[Train] Epoch: 3 [496192/620022]    Loss: 0.008888   Batch Acc: 76.56
[Train] Epoch: 3 [496256/620022]    Loss: 0.008005   Batch Acc: 76.56
[Train] Epoch: 3 [496320/620022]    Loss: 0.008781   Batch Acc: 78.12
[Train] Epoch: 3 [496384/620022]    Loss: 0.010131   Batch Acc: 73.44
[Train] Epoch: 3 [496448/620022]    Loss: 0.009326   Batch Acc: 71.88
[Train] Epoch: 3 [496512/620022]    Loss: 0.007857   Batch Acc: 82.81
[Train] Epoch: 3 [496576/620022]    Loss: 0.007143   Batch Acc: 87.50
[Train] Epoch: 3 [496640/620022]    Loss: 0.008356   Batch Acc: 82.81
[Train] Epoch: 3 [496704/620022]    Loss: 0.009922   Batch Acc: 68.75
[Train] Epoch: 3 [496768/620022]    Loss: 0.008746   Batch Acc: 81.25
[Train] Epoch: 3 [496832/620022]    Loss: 0.009699   Batch Acc: 71.88
[Train] Epoch: 3 [496896/620022]    Loss: 0.010478   Batch Acc: 76.56
[Train] Epoch: 3 [496960/620022]    Loss: 0.008187   Batch Acc: 75.00
[Train] Epoch: 3 [497024/620022]    Loss: 0.007384   Batch Acc: 84.38
[Train] Epoch: 3 [497088/620022]    Loss: 0.008287   Batch Acc: 76.56
[Train] Epoch: 3 [497152/620022]    Loss: 0.009784   Batch Acc: 73.44
[Train] Epoch: 3 [497216/620022]    Loss: 0.010207   Batch Acc: 68.75
[Train] Epoch: 3 [497280/620022]    Loss: 0.006942   Batch Acc: 85.94
[Train] Epoch: 3 [497344/620022]    Loss: 0.008130   Batch Acc: 85.94
[Train] Epoch: 3 [497408/620022]    Loss: 0.009241   Batch Acc: 76.56
[Train] Epoch: 3 [497472/620022]    Loss: 0.010057   Batch Acc: 64.06
[Train] Epoch: 3 [497536/620022]    Loss: 0.009688   Batch Acc: 70.31
[Train] Epoch: 3 [497600/620022]    Loss: 0.006935   Batch Acc: 79.69
[Train] Epoch: 3 [497664/620022]    Loss: 0.009573   Batch Acc: 73.44
[Train] Epoch: 3 [497728/620022]    Loss: 0.008323   Batch Acc: 78.12
[Train] Epoch: 3 [497792/620022]    Loss: 0.007816   Batch Acc: 79.69
[Train] Epoch: 3 [497856/620022]    Loss: 0.011278   Batch Acc: 62.50
[Train] Epoch: 3 [497920/620022]    Loss: 0.008125   Batch Acc: 81.25
[Train] Epoch: 3 [497984/620022]    Loss: 0.010563   Batch Acc: 70.31
[Train] Epoch: 3 [498048/620022]    Loss: 0.006682   Batch Acc: 89.06
[Train] Epoch: 3 [498112/620022]    Loss: 0.008488   Batch Acc: 78.12
[Train] Epoch: 3 [498176/620022]    Loss: 0.008669   Batch Acc: 78.12
[Train] Epoch: 3 [498240/620022]    Loss: 0.005743   Batch Acc: 92.19
[Train] Epoch: 3 [498304/620022]    Loss: 0.009578   Batch Acc: 75.00
[Train] Epoch: 3 [498368/620022]    Loss: 0.009325   Batch Acc: 76.56
[Train] Epoch: 3 [498432/620022]    Loss: 0.008297   Batch Acc: 81.25
[Train] Epoch: 3 [498496/620022]    Loss: 0.009382   Batch Acc: 75.00
[Train] Epoch: 3 [498560/620022]    Loss: 0.009461   Batch Acc: 70.31
[Train] Epoch: 3 [498624/620022]    Loss: 0.005845   Batch Acc: 85.94
[Train] Epoch: 3 [498688/620022]    Loss: 0.007553   Batch Acc: 81.25
[Train] Epoch: 3 [498752/620022]    Loss: 0.006644   Batch Acc: 87.50
[Train] Epoch: 3 [498816/620022]    Loss: 0.009031   Batch Acc: 76.56
[Train] Epoch: 3 [498880/620022]    Loss: 0.009164   Batch Acc: 73.44
[Train] Epoch: 3 [498944/620022]    Loss: 0.007365   Batch Acc: 79.69
[Train] Epoch: 3 [499008/620022]    Loss: 0.008504   Batch Acc: 76.56
[Train] Epoch: 3 [499072/620022]    Loss: 0.007948   Batch Acc: 78.12
[Train] Epoch: 3 [499136/620022]    Loss: 0.009197   Batch Acc: 78.12
[Train] Epoch: 3 [499200/620022]    Loss: 0.007454   Batch Acc: 85.94
[Train] Epoch: 3 [499264/620022]    Loss: 0.008507   Batch Acc: 76.56
[Train] Epoch: 3 [499328/620022]    Loss: 0.006979   Batch Acc: 82.81
[Train] Epoch: 3 [499392/620022]    Loss: 0.010220   Batch Acc: 78.12
[Train] Epoch: 3 [499456/620022]    Loss: 0.010430   Batch Acc: 71.88
[Train] Epoch: 3 [499520/620022]    Loss: 0.006835   Batch Acc: 84.38
[Train] Epoch: 3 [499584/620022]    Loss: 0.009700   Batch Acc: 75.00
[Train] Epoch: 3 [499648/620022]    Loss: 0.007367   Batch Acc: 82.81
[Train] Epoch: 3 [499712/620022]    Loss: 0.008691   Batch Acc: 75.00
[Train] Epoch: 3 [499776/620022]    Loss: 0.008484   Batch Acc: 79.69
[Train] Epoch: 3 [499840/620022]    Loss: 0.007052   Batch Acc: 82.81
[Train] Epoch: 3 [499904/620022]    Loss: 0.008269   Batch Acc: 78.12
[Train] Epoch: 3 [499968/620022]    Loss: 0.008241   Batch Acc: 78.12
[Train] Epoch: 3 [500032/620022]    Loss: 0.006500   Batch Acc: 81.25
[Train] Epoch: 3 [500096/620022]    Loss: 0.007725   Batch Acc: 84.38
[Train] Epoch: 3 [500160/620022]    Loss: 0.008353   Batch Acc: 76.56
[Train] Epoch: 3 [500224/620022]    Loss: 0.008260   Batch Acc: 78.12
[Train] Epoch: 3 [500288/620022]    Loss: 0.008674   Batch Acc: 81.25
[Train] Epoch: 3 [500352/620022]    Loss: 0.006425   Batch Acc: 84.38
[Train] Epoch: 3 [500416/620022]    Loss: 0.005589   Batch Acc: 84.38
[Train] Epoch: 3 [500480/620022]    Loss: 0.010933   Batch Acc: 70.31
[Train] Epoch: 3 [500544/620022]    Loss: 0.008505   Batch Acc: 75.00
[Train] Epoch: 3 [500608/620022]    Loss: 0.007205   Batch Acc: 84.38
[Train] Epoch: 3 [500672/620022]    Loss: 0.008020   Batch Acc: 81.25
[Train] Epoch: 3 [500736/620022]    Loss: 0.008724   Batch Acc: 79.69
[Train] Epoch: 3 [500800/620022]    Loss: 0.008054   Batch Acc: 81.25
[Train] Epoch: 3 [500864/620022]    Loss: 0.009461   Batch Acc: 75.00
[Train] Epoch: 3 [500928/620022]    Loss: 0.010807   Batch Acc: 62.50
[Train] Epoch: 3 [500992/620022]    Loss: 0.008298   Batch Acc: 75.00
[Train] Epoch: 3 [501056/620022]    Loss: 0.007951   Batch Acc: 79.69
[Train] Epoch: 3 [501120/620022]    Loss: 0.009951   Batch Acc: 73.44
[Train] Epoch: 3 [501184/620022]    Loss: 0.009155   Batch Acc: 71.88
[Train] Epoch: 3 [501248/620022]    Loss: 0.007694   Batch Acc: 78.12
[Train] Epoch: 3 [501312/620022]    Loss: 0.009027   Batch Acc: 71.88
[Train] Epoch: 3 [501376/620022]    Loss: 0.008978   Batch Acc: 71.88
[Train] Epoch: 3 [501440/620022]    Loss: 0.009885   Batch Acc: 70.31
[Train] Epoch: 3 [501504/620022]    Loss: 0.006856   Batch Acc: 79.69
[Train] Epoch: 3 [501568/620022]    Loss: 0.009644   Batch Acc: 73.44
[Train] Epoch: 3 [501632/620022]    Loss: 0.007765   Batch Acc: 76.56
[Train] Epoch: 3 [501696/620022]    Loss: 0.007944   Batch Acc: 79.69
[Train] Epoch: 3 [501760/620022]    Loss: 0.009484   Batch Acc: 79.69
[Train] Epoch: 3 [501824/620022]    Loss: 0.008830   Batch Acc: 75.00
[Train] Epoch: 3 [501888/620022]    Loss: 0.008591   Batch Acc: 79.69
[Train] Epoch: 3 [501952/620022]    Loss: 0.005377   Batch Acc: 89.06
[Train] Epoch: 3 [502016/620022]    Loss: 0.007340   Batch Acc: 78.12
[Train] Epoch: 3 [502080/620022]    Loss: 0.010252   Batch Acc: 68.75
[Train] Epoch: 3 [502144/620022]    Loss: 0.011704   Batch Acc: 65.62
[Train] Epoch: 3 [502208/620022]    Loss: 0.006850   Batch Acc: 82.81
[Train] Epoch: 3 [502272/620022]    Loss: 0.007557   Batch Acc: 78.12
[Train] Epoch: 3 [502336/620022]    Loss: 0.008539   Batch Acc: 73.44
[Train] Epoch: 3 [502400/620022]    Loss: 0.009737   Batch Acc: 79.69
[Train] Epoch: 3 [502464/620022]    Loss: 0.009417   Batch Acc: 71.88
[Train] Epoch: 3 [502528/620022]    Loss: 0.008638   Batch Acc: 75.00
[Train] Epoch: 3 [502592/620022]    Loss: 0.009766   Batch Acc: 70.31
[Train] Epoch: 3 [502656/620022]    Loss: 0.008489   Batch Acc: 78.12
[Train] Epoch: 3 [502720/620022]    Loss: 0.007390   Batch Acc: 75.00
[Train] Epoch: 3 [502784/620022]    Loss: 0.008369   Batch Acc: 78.12
[Train] Epoch: 3 [502848/620022]    Loss: 0.007403   Batch Acc: 82.81
[Train] Epoch: 3 [502912/620022]    Loss: 0.007961   Batch Acc: 81.25
[Train] Epoch: 3 [502976/620022]    Loss: 0.008691   Batch Acc: 79.69
[Train] Epoch: 3 [503040/620022]    Loss: 0.011145   Batch Acc: 65.62
[Train] Epoch: 3 [503104/620022]    Loss: 0.009102   Batch Acc: 73.44
[Train] Epoch: 3 [503168/620022]    Loss: 0.008411   Batch Acc: 79.69
[Train] Epoch: 3 [503232/620022]    Loss: 0.009506   Batch Acc: 78.12
[Train] Epoch: 3 [503296/620022]    Loss: 0.010282   Batch Acc: 70.31
[Train] Epoch: 3 [503360/620022]    Loss: 0.008008   Batch Acc: 81.25
[Train] Epoch: 3 [503424/620022]    Loss: 0.009033   Batch Acc: 76.56
[Train] Epoch: 3 [503488/620022]    Loss: 0.008339   Batch Acc: 76.56
[Train] Epoch: 3 [503552/620022]    Loss: 0.007809   Batch Acc: 79.69
[Train] Epoch: 3 [503616/620022]    Loss: 0.008278   Batch Acc: 71.88
[Train] Epoch: 3 [503680/620022]    Loss: 0.007099   Batch Acc: 78.12
[Train] Epoch: 3 [503744/620022]    Loss: 0.009044   Batch Acc: 79.69
[Train] Epoch: 3 [503808/620022]    Loss: 0.009725   Batch Acc: 75.00
[Train] Epoch: 3 [503872/620022]    Loss: 0.009158   Batch Acc: 75.00
[Train] Epoch: 3 [503936/620022]    Loss: 0.007806   Batch Acc: 81.25
[Train] Epoch: 3 [504000/620022]    Loss: 0.008419   Batch Acc: 84.38
[Train] Epoch: 3 [504064/620022]    Loss: 0.009340   Batch Acc: 76.56
[Train] Epoch: 3 [504128/620022]    Loss: 0.010284   Batch Acc: 71.88
[Train] Epoch: 3 [504192/620022]    Loss: 0.008637   Batch Acc: 78.12
[Train] Epoch: 3 [504256/620022]    Loss: 0.009983   Batch Acc: 73.44
[Train] Epoch: 3 [504320/620022]    Loss: 0.006554   Batch Acc: 84.38
[Train] Epoch: 3 [504384/620022]    Loss: 0.010665   Batch Acc: 75.00
[Train] Epoch: 3 [504448/620022]    Loss: 0.009011   Batch Acc: 79.69
[Train] Epoch: 3 [504512/620022]    Loss: 0.010058   Batch Acc: 75.00
[Train] Epoch: 3 [504576/620022]    Loss: 0.008225   Batch Acc: 78.12
[Train] Epoch: 3 [504640/620022]    Loss: 0.010696   Batch Acc: 71.88
[Train] Epoch: 3 [504704/620022]    Loss: 0.006834   Batch Acc: 85.94
[Train] Epoch: 3 [504768/620022]    Loss: 0.008077   Batch Acc: 85.94
[Train] Epoch: 3 [504832/620022]    Loss: 0.009554   Batch Acc: 75.00
[Train] Epoch: 3 [504896/620022]    Loss: 0.007582   Batch Acc: 81.25
[Train] Epoch: 3 [504960/620022]    Loss: 0.009444   Batch Acc: 73.44
[Train] Epoch: 3 [505024/620022]    Loss: 0.011171   Batch Acc: 62.50
[Train] Epoch: 3 [505088/620022]    Loss: 0.007172   Batch Acc: 76.56
[Train] Epoch: 3 [505152/620022]    Loss: 0.007284   Batch Acc: 87.50
[Train] Epoch: 3 [505216/620022]    Loss: 0.008209   Batch Acc: 82.81
[Train] Epoch: 3 [505280/620022]    Loss: 0.006822   Batch Acc: 79.69
[Train] Epoch: 3 [505344/620022]    Loss: 0.009957   Batch Acc: 70.31
[Train] Epoch: 3 [505408/620022]    Loss: 0.006710   Batch Acc: 87.50
[Train] Epoch: 3 [505472/620022]    Loss: 0.009460   Batch Acc: 76.56
[Train] Epoch: 3 [505536/620022]    Loss: 0.010045   Batch Acc: 71.88
[Train] Epoch: 3 [505600/620022]    Loss: 0.008784   Batch Acc: 73.44
[Train] Epoch: 3 [505664/620022]    Loss: 0.010693   Batch Acc: 71.88
[Train] Epoch: 3 [505728/620022]    Loss: 0.008334   Batch Acc: 84.38
[Train] Epoch: 3 [505792/620022]    Loss: 0.007247   Batch Acc: 78.12
[Train] Epoch: 3 [505856/620022]    Loss: 0.008057   Batch Acc: 81.25
[Train] Epoch: 3 [505920/620022]    Loss: 0.009540   Batch Acc: 79.69
[Train] Epoch: 3 [505984/620022]    Loss: 0.009043   Batch Acc: 70.31
[Train] Epoch: 3 [506048/620022]    Loss: 0.008092   Batch Acc: 82.81
[Train] Epoch: 3 [506112/620022]    Loss: 0.008098   Batch Acc: 81.25
[Train] Epoch: 3 [506176/620022]    Loss: 0.010332   Batch Acc: 71.88
[Train] Epoch: 3 [506240/620022]    Loss: 0.008252   Batch Acc: 81.25
[Train] Epoch: 3 [506304/620022]    Loss: 0.007900   Batch Acc: 82.81
[Train] Epoch: 3 [506368/620022]    Loss: 0.008316   Batch Acc: 79.69
[Train] Epoch: 3 [506432/620022]    Loss: 0.007155   Batch Acc: 84.38
[Train] Epoch: 3 [506496/620022]    Loss: 0.007678   Batch Acc: 85.94
[Train] Epoch: 3 [506560/620022]    Loss: 0.008743   Batch Acc: 76.56
[Train] Epoch: 3 [506624/620022]    Loss: 0.007067   Batch Acc: 87.50
[Train] Epoch: 3 [506688/620022]    Loss: 0.009449   Batch Acc: 75.00
[Train] Epoch: 3 [506752/620022]    Loss: 0.005944   Batch Acc: 89.06
[Train] Epoch: 3 [506816/620022]    Loss: 0.008088   Batch Acc: 78.12
[Train] Epoch: 3 [506880/620022]    Loss: 0.010602   Batch Acc: 70.31
[Train] Epoch: 3 [506944/620022]    Loss: 0.006845   Batch Acc: 87.50
[Train] Epoch: 3 [507008/620022]    Loss: 0.009242   Batch Acc: 71.88
[Train] Epoch: 3 [507072/620022]    Loss: 0.008890   Batch Acc: 75.00
[Train] Epoch: 3 [507136/620022]    Loss: 0.007412   Batch Acc: 81.25
[Train] Epoch: 3 [507200/620022]    Loss: 0.009347   Batch Acc: 82.81
[Train] Epoch: 3 [507264/620022]    Loss: 0.006906   Batch Acc: 89.06
[Train] Epoch: 3 [507328/620022]    Loss: 0.010065   Batch Acc: 75.00
[Train] Epoch: 3 [507392/620022]    Loss: 0.009005   Batch Acc: 76.56
[Train] Epoch: 3 [507456/620022]    Loss: 0.008471   Batch Acc: 75.00
[Train] Epoch: 3 [507520/620022]    Loss: 0.008550   Batch Acc: 79.69
[Train] Epoch: 3 [507584/620022]    Loss: 0.009017   Batch Acc: 78.12
[Train] Epoch: 3 [507648/620022]    Loss: 0.007251   Batch Acc: 81.25
[Train] Epoch: 3 [507712/620022]    Loss: 0.010118   Batch Acc: 75.00
[Train] Epoch: 3 [507776/620022]    Loss: 0.007895   Batch Acc: 79.69
[Train] Epoch: 3 [507840/620022]    Loss: 0.007001   Batch Acc: 84.38
[Train] Epoch: 3 [507904/620022]    Loss: 0.007653   Batch Acc: 82.81
[Train] Epoch: 3 [507968/620022]    Loss: 0.006997   Batch Acc: 76.56
[Train] Epoch: 3 [508032/620022]    Loss: 0.006986   Batch Acc: 85.94
[Train] Epoch: 3 [508096/620022]    Loss: 0.008386   Batch Acc: 81.25
[Train] Epoch: 3 [508160/620022]    Loss: 0.006778   Batch Acc: 85.94
[Train] Epoch: 3 [508224/620022]    Loss: 0.007494   Batch Acc: 82.81
[Train] Epoch: 3 [508288/620022]    Loss: 0.011534   Batch Acc: 68.75
[Train] Epoch: 3 [508352/620022]    Loss: 0.008842   Batch Acc: 82.81
[Train] Epoch: 3 [508416/620022]    Loss: 0.008994   Batch Acc: 79.69
[Train] Epoch: 3 [508480/620022]    Loss: 0.009101   Batch Acc: 75.00
[Train] Epoch: 3 [508544/620022]    Loss: 0.007289   Batch Acc: 76.56
[Train] Epoch: 3 [508608/620022]    Loss: 0.008134   Batch Acc: 82.81
[Train] Epoch: 3 [508672/620022]    Loss: 0.009367   Batch Acc: 70.31
[Train] Epoch: 3 [508736/620022]    Loss: 0.008532   Batch Acc: 81.25
[Train] Epoch: 3 [508800/620022]    Loss: 0.010109   Batch Acc: 75.00
[Train] Epoch: 3 [508864/620022]    Loss: 0.008592   Batch Acc: 76.56
[Train] Epoch: 3 [508928/620022]    Loss: 0.010988   Batch Acc: 70.31
[Train] Epoch: 3 [508992/620022]    Loss: 0.009057   Batch Acc: 70.31
[Train] Epoch: 3 [509056/620022]    Loss: 0.006380   Batch Acc: 81.25
[Train] Epoch: 3 [509120/620022]    Loss: 0.007923   Batch Acc: 78.12
[Train] Epoch: 3 [509184/620022]    Loss: 0.009460   Batch Acc: 75.00
[Train] Epoch: 3 [509248/620022]    Loss: 0.005946   Batch Acc: 89.06
[Train] Epoch: 3 [509312/620022]    Loss: 0.006364   Batch Acc: 87.50
[Train] Epoch: 3 [509376/620022]    Loss: 0.007837   Batch Acc: 81.25
[Train] Epoch: 3 [509440/620022]    Loss: 0.007684   Batch Acc: 84.38
[Train] Epoch: 3 [509504/620022]    Loss: 0.007011   Batch Acc: 81.25
[Train] Epoch: 3 [509568/620022]    Loss: 0.009834   Batch Acc: 81.25
[Train] Epoch: 3 [509632/620022]    Loss: 0.008783   Batch Acc: 76.56
[Train] Epoch: 3 [509696/620022]    Loss: 0.009238   Batch Acc: 76.56
[Train] Epoch: 3 [509760/620022]    Loss: 0.011174   Batch Acc: 79.69
[Train] Epoch: 3 [509824/620022]    Loss: 0.005552   Batch Acc: 92.19
[Train] Epoch: 3 [509888/620022]    Loss: 0.010942   Batch Acc: 65.62
[Train] Epoch: 3 [509952/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 3 [510016/620022]    Loss: 0.009945   Batch Acc: 78.12
[Train] Epoch: 3 [510080/620022]    Loss: 0.008034   Batch Acc: 79.69
[Train] Epoch: 3 [510144/620022]    Loss: 0.012814   Batch Acc: 64.06
[Train] Epoch: 3 [510208/620022]    Loss: 0.006560   Batch Acc: 87.50
[Train] Epoch: 3 [510272/620022]    Loss: 0.008290   Batch Acc: 78.12
[Train] Epoch: 3 [510336/620022]    Loss: 0.009487   Batch Acc: 70.31
[Train] Epoch: 3 [510400/620022]    Loss: 0.007552   Batch Acc: 79.69
[Train] Epoch: 3 [510464/620022]    Loss: 0.008781   Batch Acc: 78.12
[Train] Epoch: 3 [510528/620022]    Loss: 0.008122   Batch Acc: 78.12
[Train] Epoch: 3 [510592/620022]    Loss: 0.010194   Batch Acc: 75.00
[Train] Epoch: 3 [510656/620022]    Loss: 0.008730   Batch Acc: 78.12
[Train] Epoch: 3 [510720/620022]    Loss: 0.008253   Batch Acc: 75.00
[Train] Epoch: 3 [510784/620022]    Loss: 0.009443   Batch Acc: 73.44
[Train] Epoch: 3 [510848/620022]    Loss: 0.009800   Batch Acc: 70.31
[Train] Epoch: 3 [510912/620022]    Loss: 0.009393   Batch Acc: 76.56
[Train] Epoch: 3 [510976/620022]    Loss: 0.007262   Batch Acc: 82.81
[Train] Epoch: 3 [511040/620022]    Loss: 0.009232   Batch Acc: 70.31
[Train] Epoch: 3 [511104/620022]    Loss: 0.008603   Batch Acc: 76.56
[Train] Epoch: 3 [511168/620022]    Loss: 0.010738   Batch Acc: 70.31
[Train] Epoch: 3 [511232/620022]    Loss: 0.010974   Batch Acc: 67.19
[Train] Epoch: 3 [511296/620022]    Loss: 0.007037   Batch Acc: 81.25
[Train] Epoch: 3 [511360/620022]    Loss: 0.007816   Batch Acc: 79.69
[Train] Epoch: 3 [511424/620022]    Loss: 0.009975   Batch Acc: 75.00
[Train] Epoch: 3 [511488/620022]    Loss: 0.007540   Batch Acc: 82.81
[Train] Epoch: 3 [511552/620022]    Loss: 0.008198   Batch Acc: 76.56
[Train] Epoch: 3 [511616/620022]    Loss: 0.008839   Batch Acc: 75.00
[Train] Epoch: 3 [511680/620022]    Loss: 0.008281   Batch Acc: 76.56
[Train] Epoch: 3 [511744/620022]    Loss: 0.010412   Batch Acc: 78.12
[Train] Epoch: 3 [511808/620022]    Loss: 0.006441   Batch Acc: 87.50
[Train] Epoch: 3 [511872/620022]    Loss: 0.009306   Batch Acc: 75.00
[Train] Epoch: 3 [511936/620022]    Loss: 0.009047   Batch Acc: 75.00
[Train] Epoch: 3 [512000/620022]    Loss: 0.009152   Batch Acc: 73.44
[Train] Epoch: 3 [512064/620022]    Loss: 0.008877   Batch Acc: 78.12
[Train] Epoch: 3 [512128/620022]    Loss: 0.006966   Batch Acc: 84.38
[Train] Epoch: 3 [512192/620022]    Loss: 0.010541   Batch Acc: 73.44
[Train] Epoch: 3 [512256/620022]    Loss: 0.008870   Batch Acc: 79.69
[Train] Epoch: 3 [512320/620022]    Loss: 0.009595   Batch Acc: 75.00
[Train] Epoch: 3 [512384/620022]    Loss: 0.008747   Batch Acc: 75.00
[Train] Epoch: 3 [512448/620022]    Loss: 0.009377   Batch Acc: 75.00
[Train] Epoch: 3 [512512/620022]    Loss: 0.008097   Batch Acc: 81.25
[Train] Epoch: 3 [512576/620022]    Loss: 0.008022   Batch Acc: 84.38
[Train] Epoch: 3 [512640/620022]    Loss: 0.009362   Batch Acc: 79.69
[Train] Epoch: 3 [512704/620022]    Loss: 0.007891   Batch Acc: 82.81
[Train] Epoch: 3 [512768/620022]    Loss: 0.007976   Batch Acc: 81.25
[Train] Epoch: 3 [512832/620022]    Loss: 0.007385   Batch Acc: 81.25
[Train] Epoch: 3 [512896/620022]    Loss: 0.010113   Batch Acc: 75.00
[Train] Epoch: 3 [512960/620022]    Loss: 0.010809   Batch Acc: 68.75
[Train] Epoch: 3 [513024/620022]    Loss: 0.008560   Batch Acc: 81.25
[Train] Epoch: 3 [513088/620022]    Loss: 0.007898   Batch Acc: 85.94
[Train] Epoch: 3 [513152/620022]    Loss: 0.010101   Batch Acc: 76.56
[Train] Epoch: 3 [513216/620022]    Loss: 0.008800   Batch Acc: 81.25
[Train] Epoch: 3 [513280/620022]    Loss: 0.009494   Batch Acc: 73.44
[Train] Epoch: 3 [513344/620022]    Loss: 0.007192   Batch Acc: 79.69
[Train] Epoch: 3 [513408/620022]    Loss: 0.007975   Batch Acc: 78.12
[Train] Epoch: 3 [513472/620022]    Loss: 0.008183   Batch Acc: 81.25
[Train] Epoch: 3 [513536/620022]    Loss: 0.008417   Batch Acc: 76.56
[Train] Epoch: 3 [513600/620022]    Loss: 0.009977   Batch Acc: 78.12
[Train] Epoch: 3 [513664/620022]    Loss: 0.006919   Batch Acc: 85.94
[Train] Epoch: 3 [513728/620022]    Loss: 0.007606   Batch Acc: 78.12
[Train] Epoch: 3 [513792/620022]    Loss: 0.007992   Batch Acc: 78.12
[Train] Epoch: 3 [513856/620022]    Loss: 0.009294   Batch Acc: 78.12
[Train] Epoch: 3 [513920/620022]    Loss: 0.007639   Batch Acc: 79.69
[Train] Epoch: 3 [513984/620022]    Loss: 0.012035   Batch Acc: 68.75
[Train] Epoch: 3 [514048/620022]    Loss: 0.009271   Batch Acc: 76.56
[Train] Epoch: 3 [514112/620022]    Loss: 0.009046   Batch Acc: 71.88
[Train] Epoch: 3 [514176/620022]    Loss: 0.009150   Batch Acc: 81.25
[Train] Epoch: 3 [514240/620022]    Loss: 0.009320   Batch Acc: 75.00
[Train] Epoch: 3 [514304/620022]    Loss: 0.007622   Batch Acc: 85.94
[Train] Epoch: 3 [514368/620022]    Loss: 0.010141   Batch Acc: 75.00
[Train] Epoch: 3 [514432/620022]    Loss: 0.007353   Batch Acc: 84.38
[Train] Epoch: 3 [514496/620022]    Loss: 0.010203   Batch Acc: 71.88
[Train] Epoch: 3 [514560/620022]    Loss: 0.009393   Batch Acc: 71.88
[Train] Epoch: 3 [514624/620022]    Loss: 0.008646   Batch Acc: 75.00
[Train] Epoch: 3 [514688/620022]    Loss: 0.012240   Batch Acc: 67.19
[Train] Epoch: 3 [514752/620022]    Loss: 0.011330   Batch Acc: 70.31
[Train] Epoch: 3 [514816/620022]    Loss: 0.007016   Batch Acc: 90.62
[Train] Epoch: 3 [514880/620022]    Loss: 0.007137   Batch Acc: 79.69
[Train] Epoch: 3 [514944/620022]    Loss: 0.006585   Batch Acc: 85.94
[Train] Epoch: 3 [515008/620022]    Loss: 0.007847   Batch Acc: 84.38
[Train] Epoch: 3 [515072/620022]    Loss: 0.006714   Batch Acc: 84.38
[Train] Epoch: 3 [515136/620022]    Loss: 0.008552   Batch Acc: 76.56
[Train] Epoch: 3 [515200/620022]    Loss: 0.008046   Batch Acc: 81.25
[Train] Epoch: 3 [515264/620022]    Loss: 0.008489   Batch Acc: 81.25
[Train] Epoch: 3 [515328/620022]    Loss: 0.007862   Batch Acc: 82.81
[Train] Epoch: 3 [515392/620022]    Loss: 0.007195   Batch Acc: 81.25
[Train] Epoch: 3 [515456/620022]    Loss: 0.007406   Batch Acc: 81.25
[Train] Epoch: 3 [515520/620022]    Loss: 0.007948   Batch Acc: 84.38
[Train] Epoch: 3 [515584/620022]    Loss: 0.007685   Batch Acc: 78.12
[Train] Epoch: 3 [515648/620022]    Loss: 0.008827   Batch Acc: 73.44
[Train] Epoch: 3 [515712/620022]    Loss: 0.007468   Batch Acc: 79.69
[Train] Epoch: 3 [515776/620022]    Loss: 0.009212   Batch Acc: 70.31
[Train] Epoch: 3 [515840/620022]    Loss: 0.009233   Batch Acc: 73.44
[Train] Epoch: 3 [515904/620022]    Loss: 0.006450   Batch Acc: 82.81
[Train] Epoch: 3 [515968/620022]    Loss: 0.008285   Batch Acc: 82.81
[Train] Epoch: 3 [516032/620022]    Loss: 0.008364   Batch Acc: 78.12
[Train] Epoch: 3 [516096/620022]    Loss: 0.006462   Batch Acc: 85.94
[Train] Epoch: 3 [516160/620022]    Loss: 0.008124   Batch Acc: 78.12
[Train] Epoch: 3 [516224/620022]    Loss: 0.009633   Batch Acc: 70.31
[Train] Epoch: 3 [516288/620022]    Loss: 0.006755   Batch Acc: 85.94
[Train] Epoch: 3 [516352/620022]    Loss: 0.006539   Batch Acc: 84.38
[Train] Epoch: 3 [516416/620022]    Loss: 0.009591   Batch Acc: 75.00
[Train] Epoch: 3 [516480/620022]    Loss: 0.009055   Batch Acc: 78.12
[Train] Epoch: 3 [516544/620022]    Loss: 0.007261   Batch Acc: 79.69
[Train] Epoch: 3 [516608/620022]    Loss: 0.007103   Batch Acc: 81.25
[Train] Epoch: 3 [516672/620022]    Loss: 0.009568   Batch Acc: 73.44
[Train] Epoch: 3 [516736/620022]    Loss: 0.008672   Batch Acc: 79.69
[Train] Epoch: 3 [516800/620022]    Loss: 0.009193   Batch Acc: 73.44
[Train] Epoch: 3 [516864/620022]    Loss: 0.008253   Batch Acc: 78.12
[Train] Epoch: 3 [516928/620022]    Loss: 0.009280   Batch Acc: 76.56
[Train] Epoch: 3 [516992/620022]    Loss: 0.008761   Batch Acc: 75.00
[Train] Epoch: 3 [517056/620022]    Loss: 0.008409   Batch Acc: 78.12
[Train] Epoch: 3 [517120/620022]    Loss: 0.008389   Batch Acc: 82.81
[Train] Epoch: 3 [517184/620022]    Loss: 0.006442   Batch Acc: 82.81
[Train] Epoch: 3 [517248/620022]    Loss: 0.009747   Batch Acc: 70.31
[Train] Epoch: 3 [517312/620022]    Loss: 0.007982   Batch Acc: 81.25
[Train] Epoch: 3 [517376/620022]    Loss: 0.009475   Batch Acc: 76.56
[Train] Epoch: 3 [517440/620022]    Loss: 0.009701   Batch Acc: 73.44
[Train] Epoch: 3 [517504/620022]    Loss: 0.009454   Batch Acc: 78.12
[Train] Epoch: 3 [517568/620022]    Loss: 0.009377   Batch Acc: 75.00
[Train] Epoch: 3 [517632/620022]    Loss: 0.008504   Batch Acc: 75.00
[Train] Epoch: 3 [517696/620022]    Loss: 0.007243   Batch Acc: 81.25
[Train] Epoch: 3 [517760/620022]    Loss: 0.009309   Batch Acc: 78.12
[Train] Epoch: 3 [517824/620022]    Loss: 0.007868   Batch Acc: 82.81
[Train] Epoch: 3 [517888/620022]    Loss: 0.007864   Batch Acc: 81.25
[Train] Epoch: 3 [517952/620022]    Loss: 0.007903   Batch Acc: 81.25
[Train] Epoch: 3 [518016/620022]    Loss: 0.008567   Batch Acc: 79.69
[Train] Epoch: 3 [518080/620022]    Loss: 0.008824   Batch Acc: 76.56
[Train] Epoch: 3 [518144/620022]    Loss: 0.008165   Batch Acc: 82.81
[Train] Epoch: 3 [518208/620022]    Loss: 0.009217   Batch Acc: 71.88
[Train] Epoch: 3 [518272/620022]    Loss: 0.007030   Batch Acc: 82.81
[Train] Epoch: 3 [518336/620022]    Loss: 0.008429   Batch Acc: 75.00
[Train] Epoch: 3 [518400/620022]    Loss: 0.007839   Batch Acc: 81.25
[Train] Epoch: 3 [518464/620022]    Loss: 0.010235   Batch Acc: 73.44
[Train] Epoch: 3 [518528/620022]    Loss: 0.008951   Batch Acc: 75.00
[Train] Epoch: 3 [518592/620022]    Loss: 0.007724   Batch Acc: 79.69
[Train] Epoch: 3 [518656/620022]    Loss: 0.009168   Batch Acc: 82.81
[Train] Epoch: 3 [518720/620022]    Loss: 0.007191   Batch Acc: 85.94
[Train] Epoch: 3 [518784/620022]    Loss: 0.010816   Batch Acc: 68.75
[Train] Epoch: 3 [518848/620022]    Loss: 0.007641   Batch Acc: 75.00
[Train] Epoch: 3 [518912/620022]    Loss: 0.009164   Batch Acc: 82.81
[Train] Epoch: 3 [518976/620022]    Loss: 0.009604   Batch Acc: 73.44
[Train] Epoch: 3 [519040/620022]    Loss: 0.008845   Batch Acc: 79.69
[Train] Epoch: 3 [519104/620022]    Loss: 0.011350   Batch Acc: 71.88
[Train] Epoch: 3 [519168/620022]    Loss: 0.008859   Batch Acc: 78.12
[Train] Epoch: 3 [519232/620022]    Loss: 0.007959   Batch Acc: 82.81
[Train] Epoch: 3 [519296/620022]    Loss: 0.010798   Batch Acc: 71.88
[Train] Epoch: 3 [519360/620022]    Loss: 0.006120   Batch Acc: 82.81
[Train] Epoch: 3 [519424/620022]    Loss: 0.008383   Batch Acc: 78.12
[Train] Epoch: 3 [519488/620022]    Loss: 0.007561   Batch Acc: 82.81
[Train] Epoch: 3 [519552/620022]    Loss: 0.006668   Batch Acc: 84.38
[Train] Epoch: 3 [519616/620022]    Loss: 0.007662   Batch Acc: 81.25
[Train] Epoch: 3 [519680/620022]    Loss: 0.010691   Batch Acc: 70.31
[Train] Epoch: 3 [519744/620022]    Loss: 0.010862   Batch Acc: 64.06
[Train] Epoch: 3 [519808/620022]    Loss: 0.009360   Batch Acc: 75.00
[Train] Epoch: 3 [519872/620022]    Loss: 0.008024   Batch Acc: 82.81
[Train] Epoch: 3 [519936/620022]    Loss: 0.009429   Batch Acc: 70.31
[Train] Epoch: 3 [520000/620022]    Loss: 0.010488   Batch Acc: 71.88
[Train] Epoch: 3 [520064/620022]    Loss: 0.009059   Batch Acc: 71.88
[Train] Epoch: 3 [520128/620022]    Loss: 0.007395   Batch Acc: 81.25
[Train] Epoch: 3 [520192/620022]    Loss: 0.007894   Batch Acc: 78.12
[Train] Epoch: 3 [520256/620022]    Loss: 0.006704   Batch Acc: 89.06
[Train] Epoch: 3 [520320/620022]    Loss: 0.008446   Batch Acc: 75.00
[Train] Epoch: 3 [520384/620022]    Loss: 0.011653   Batch Acc: 62.50
[Train] Epoch: 3 [520448/620022]    Loss: 0.008761   Batch Acc: 76.56
[Train] Epoch: 3 [520512/620022]    Loss: 0.008025   Batch Acc: 81.25
[Train] Epoch: 3 [520576/620022]    Loss: 0.009685   Batch Acc: 75.00
[Train] Epoch: 3 [520640/620022]    Loss: 0.008684   Batch Acc: 78.12
[Train] Epoch: 3 [520704/620022]    Loss: 0.009999   Batch Acc: 73.44
[Train] Epoch: 3 [520768/620022]    Loss: 0.008779   Batch Acc: 75.00
[Train] Epoch: 3 [520832/620022]    Loss: 0.008757   Batch Acc: 78.12
[Train] Epoch: 3 [520896/620022]    Loss: 0.006431   Batch Acc: 85.94
[Train] Epoch: 3 [520960/620022]    Loss: 0.011453   Batch Acc: 71.88
[Train] Epoch: 3 [521024/620022]    Loss: 0.008128   Batch Acc: 82.81
[Train] Epoch: 3 [521088/620022]    Loss: 0.008656   Batch Acc: 79.69
[Train] Epoch: 3 [521152/620022]    Loss: 0.006694   Batch Acc: 85.94
[Train] Epoch: 3 [521216/620022]    Loss: 0.006841   Batch Acc: 79.69
[Train] Epoch: 3 [521280/620022]    Loss: 0.010773   Batch Acc: 70.31
[Train] Epoch: 3 [521344/620022]    Loss: 0.010514   Batch Acc: 70.31
[Train] Epoch: 3 [521408/620022]    Loss: 0.006900   Batch Acc: 82.81
[Train] Epoch: 3 [521472/620022]    Loss: 0.007581   Batch Acc: 82.81
[Train] Epoch: 3 [521536/620022]    Loss: 0.008835   Batch Acc: 73.44
[Train] Epoch: 3 [521600/620022]    Loss: 0.009781   Batch Acc: 75.00
[Train] Epoch: 3 [521664/620022]    Loss: 0.008977   Batch Acc: 76.56
[Train] Epoch: 3 [521728/620022]    Loss: 0.008002   Batch Acc: 81.25
[Train] Epoch: 3 [521792/620022]    Loss: 0.006789   Batch Acc: 87.50
[Train] Epoch: 3 [521856/620022]    Loss: 0.008056   Batch Acc: 82.81
[Train] Epoch: 3 [521920/620022]    Loss: 0.008576   Batch Acc: 78.12
[Train] Epoch: 3 [521984/620022]    Loss: 0.010190   Batch Acc: 73.44
[Train] Epoch: 3 [522048/620022]    Loss: 0.008416   Batch Acc: 82.81
[Train] Epoch: 3 [522112/620022]    Loss: 0.006261   Batch Acc: 82.81
[Train] Epoch: 3 [522176/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 3 [522240/620022]    Loss: 0.008138   Batch Acc: 79.69
[Train] Epoch: 3 [522304/620022]    Loss: 0.010044   Batch Acc: 71.88
[Train] Epoch: 3 [522368/620022]    Loss: 0.007208   Batch Acc: 76.56
[Train] Epoch: 3 [522432/620022]    Loss: 0.006645   Batch Acc: 79.69
[Train] Epoch: 3 [522496/620022]    Loss: 0.010653   Batch Acc: 73.44
[Train] Epoch: 3 [522560/620022]    Loss: 0.007612   Batch Acc: 79.69
[Train] Epoch: 3 [522624/620022]    Loss: 0.011418   Batch Acc: 65.62
[Train] Epoch: 3 [522688/620022]    Loss: 0.007916   Batch Acc: 81.25
[Train] Epoch: 3 [522752/620022]    Loss: 0.005900   Batch Acc: 87.50
[Train] Epoch: 3 [522816/620022]    Loss: 0.009350   Batch Acc: 75.00
[Train] Epoch: 3 [522880/620022]    Loss: 0.009313   Batch Acc: 71.88
[Train] Epoch: 3 [522944/620022]    Loss: 0.006081   Batch Acc: 87.50
[Train] Epoch: 3 [523008/620022]    Loss: 0.009304   Batch Acc: 78.12
[Train] Epoch: 3 [523072/620022]    Loss: 0.008621   Batch Acc: 78.12
[Train] Epoch: 3 [523136/620022]    Loss: 0.009451   Batch Acc: 79.69
[Train] Epoch: 3 [523200/620022]    Loss: 0.008490   Batch Acc: 75.00
[Train] Epoch: 3 [523264/620022]    Loss: 0.009771   Batch Acc: 75.00
[Train] Epoch: 3 [523328/620022]    Loss: 0.009642   Batch Acc: 73.44
[Train] Epoch: 3 [523392/620022]    Loss: 0.007214   Batch Acc: 82.81
[Train] Epoch: 3 [523456/620022]    Loss: 0.008375   Batch Acc: 78.12
[Train] Epoch: 3 [523520/620022]    Loss: 0.009637   Batch Acc: 78.12
[Train] Epoch: 3 [523584/620022]    Loss: 0.008002   Batch Acc: 73.44
[Train] Epoch: 3 [523648/620022]    Loss: 0.011573   Batch Acc: 68.75
[Train] Epoch: 3 [523712/620022]    Loss: 0.010015   Batch Acc: 71.88
[Train] Epoch: 3 [523776/620022]    Loss: 0.009203   Batch Acc: 76.56
[Train] Epoch: 3 [523840/620022]    Loss: 0.007711   Batch Acc: 79.69
[Train] Epoch: 3 [523904/620022]    Loss: 0.008898   Batch Acc: 78.12
[Train] Epoch: 3 [523968/620022]    Loss: 0.008911   Batch Acc: 75.00
[Train] Epoch: 3 [524032/620022]    Loss: 0.007223   Batch Acc: 82.81
[Train] Epoch: 3 [524096/620022]    Loss: 0.007612   Batch Acc: 79.69
[Train] Epoch: 3 [524160/620022]    Loss: 0.009265   Batch Acc: 73.44
[Train] Epoch: 3 [524224/620022]    Loss: 0.010357   Batch Acc: 78.12
[Train] Epoch: 3 [524288/620022]    Loss: 0.006750   Batch Acc: 87.50
[Train] Epoch: 3 [524352/620022]    Loss: 0.008069   Batch Acc: 81.25
[Train] Epoch: 3 [524416/620022]    Loss: 0.009903   Batch Acc: 78.12
[Train] Epoch: 3 [524480/620022]    Loss: 0.008549   Batch Acc: 76.56
[Train] Epoch: 3 [524544/620022]    Loss: 0.008677   Batch Acc: 78.12
[Train] Epoch: 3 [524608/620022]    Loss: 0.010117   Batch Acc: 65.62
[Train] Epoch: 3 [524672/620022]    Loss: 0.009266   Batch Acc: 78.12
[Train] Epoch: 3 [524736/620022]    Loss: 0.006265   Batch Acc: 89.06
[Train] Epoch: 3 [524800/620022]    Loss: 0.009612   Batch Acc: 70.31
[Train] Epoch: 3 [524864/620022]    Loss: 0.009467   Batch Acc: 73.44
[Train] Epoch: 3 [524928/620022]    Loss: 0.010805   Batch Acc: 70.31
[Train] Epoch: 3 [524992/620022]    Loss: 0.009871   Batch Acc: 76.56
[Train] Epoch: 3 [525056/620022]    Loss: 0.009467   Batch Acc: 73.44
[Train] Epoch: 3 [525120/620022]    Loss: 0.009431   Batch Acc: 78.12
[Train] Epoch: 3 [525184/620022]    Loss: 0.008378   Batch Acc: 79.69
[Train] Epoch: 3 [525248/620022]    Loss: 0.010738   Batch Acc: 68.75
[Train] Epoch: 3 [525312/620022]    Loss: 0.007943   Batch Acc: 78.12
[Train] Epoch: 3 [525376/620022]    Loss: 0.008798   Batch Acc: 79.69
[Train] Epoch: 3 [525440/620022]    Loss: 0.008050   Batch Acc: 71.88
[Train] Epoch: 3 [525504/620022]    Loss: 0.007027   Batch Acc: 81.25
[Train] Epoch: 3 [525568/620022]    Loss: 0.008431   Batch Acc: 73.44
[Train] Epoch: 3 [525632/620022]    Loss: 0.008253   Batch Acc: 81.25
[Train] Epoch: 3 [525696/620022]    Loss: 0.009641   Batch Acc: 75.00
[Train] Epoch: 3 [525760/620022]    Loss: 0.008148   Batch Acc: 79.69
[Train] Epoch: 3 [525824/620022]    Loss: 0.009438   Batch Acc: 75.00
[Train] Epoch: 3 [525888/620022]    Loss: 0.009149   Batch Acc: 78.12
[Train] Epoch: 3 [525952/620022]    Loss: 0.009639   Batch Acc: 75.00
[Train] Epoch: 3 [526016/620022]    Loss: 0.007877   Batch Acc: 85.94
[Train] Epoch: 3 [526080/620022]    Loss: 0.007770   Batch Acc: 79.69
[Train] Epoch: 3 [526144/620022]    Loss: 0.009497   Batch Acc: 78.12
[Train] Epoch: 3 [526208/620022]    Loss: 0.010026   Batch Acc: 73.44
[Train] Epoch: 3 [526272/620022]    Loss: 0.008355   Batch Acc: 85.94
[Train] Epoch: 3 [526336/620022]    Loss: 0.010303   Batch Acc: 76.56
[Train] Epoch: 3 [526400/620022]    Loss: 0.010086   Batch Acc: 76.56
[Train] Epoch: 3 [526464/620022]    Loss: 0.009301   Batch Acc: 75.00
[Train] Epoch: 3 [526528/620022]    Loss: 0.006315   Batch Acc: 82.81
[Train] Epoch: 3 [526592/620022]    Loss: 0.007670   Batch Acc: 78.12
[Train] Epoch: 3 [526656/620022]    Loss: 0.007685   Batch Acc: 87.50
[Train] Epoch: 3 [526720/620022]    Loss: 0.006752   Batch Acc: 87.50
[Train] Epoch: 3 [526784/620022]    Loss: 0.006569   Batch Acc: 87.50
[Train] Epoch: 3 [526848/620022]    Loss: 0.007075   Batch Acc: 81.25
[Train] Epoch: 3 [526912/620022]    Loss: 0.008158   Batch Acc: 79.69
[Train] Epoch: 3 [526976/620022]    Loss: 0.007968   Batch Acc: 81.25
[Train] Epoch: 3 [527040/620022]    Loss: 0.009004   Batch Acc: 73.44
[Train] Epoch: 3 [527104/620022]    Loss: 0.010817   Batch Acc: 73.44
[Train] Epoch: 3 [527168/620022]    Loss: 0.009135   Batch Acc: 73.44
[Train] Epoch: 3 [527232/620022]    Loss: 0.009072   Batch Acc: 76.56
[Train] Epoch: 3 [527296/620022]    Loss: 0.008122   Batch Acc: 81.25
[Train] Epoch: 3 [527360/620022]    Loss: 0.009937   Batch Acc: 71.88
[Train] Epoch: 3 [527424/620022]    Loss: 0.009078   Batch Acc: 76.56
[Train] Epoch: 3 [527488/620022]    Loss: 0.007084   Batch Acc: 89.06
[Train] Epoch: 3 [527552/620022]    Loss: 0.007818   Batch Acc: 82.81
[Train] Epoch: 3 [527616/620022]    Loss: 0.007438   Batch Acc: 82.81
[Train] Epoch: 3 [527680/620022]    Loss: 0.008881   Batch Acc: 78.12
[Train] Epoch: 3 [527744/620022]    Loss: 0.008911   Batch Acc: 76.56
[Train] Epoch: 3 [527808/620022]    Loss: 0.009173   Batch Acc: 73.44
[Train] Epoch: 3 [527872/620022]    Loss: 0.008428   Batch Acc: 79.69
[Train] Epoch: 3 [527936/620022]    Loss: 0.006161   Batch Acc: 82.81
[Train] Epoch: 3 [528000/620022]    Loss: 0.006708   Batch Acc: 84.38
[Train] Epoch: 3 [528064/620022]    Loss: 0.008051   Batch Acc: 84.38
[Train] Epoch: 3 [528128/620022]    Loss: 0.009677   Batch Acc: 76.56
[Train] Epoch: 3 [528192/620022]    Loss: 0.008234   Batch Acc: 76.56
[Train] Epoch: 3 [528256/620022]    Loss: 0.009163   Batch Acc: 76.56
[Train] Epoch: 3 [528320/620022]    Loss: 0.009287   Batch Acc: 76.56
[Train] Epoch: 3 [528384/620022]    Loss: 0.008558   Batch Acc: 81.25
[Train] Epoch: 3 [528448/620022]    Loss: 0.008243   Batch Acc: 75.00
[Train] Epoch: 3 [528512/620022]    Loss: 0.006217   Batch Acc: 87.50
[Train] Epoch: 3 [528576/620022]    Loss: 0.011001   Batch Acc: 67.19
[Train] Epoch: 3 [528640/620022]    Loss: 0.009424   Batch Acc: 78.12
[Train] Epoch: 3 [528704/620022]    Loss: 0.007243   Batch Acc: 82.81
[Train] Epoch: 3 [528768/620022]    Loss: 0.010489   Batch Acc: 73.44
[Train] Epoch: 3 [528832/620022]    Loss: 0.009990   Batch Acc: 68.75
[Train] Epoch: 3 [528896/620022]    Loss: 0.008001   Batch Acc: 82.81
[Train] Epoch: 3 [528960/620022]    Loss: 0.006952   Batch Acc: 85.94
[Train] Epoch: 3 [529024/620022]    Loss: 0.010260   Batch Acc: 78.12
[Train] Epoch: 3 [529088/620022]    Loss: 0.008016   Batch Acc: 73.44
[Train] Epoch: 3 [529152/620022]    Loss: 0.008076   Batch Acc: 71.88
[Train] Epoch: 3 [529216/620022]    Loss: 0.010680   Batch Acc: 71.88
[Train] Epoch: 3 [529280/620022]    Loss: 0.011113   Batch Acc: 73.44
[Train] Epoch: 3 [529344/620022]    Loss: 0.011533   Batch Acc: 75.00
[Train] Epoch: 3 [529408/620022]    Loss: 0.008056   Batch Acc: 79.69
[Train] Epoch: 3 [529472/620022]    Loss: 0.008811   Batch Acc: 70.31
[Train] Epoch: 3 [529536/620022]    Loss: 0.006246   Batch Acc: 82.81
[Train] Epoch: 3 [529600/620022]    Loss: 0.008208   Batch Acc: 75.00
[Train] Epoch: 3 [529664/620022]    Loss: 0.006229   Batch Acc: 84.38
[Train] Epoch: 3 [529728/620022]    Loss: 0.008094   Batch Acc: 82.81
[Train] Epoch: 3 [529792/620022]    Loss: 0.007482   Batch Acc: 82.81
[Train] Epoch: 3 [529856/620022]    Loss: 0.011048   Batch Acc: 71.88
[Train] Epoch: 3 [529920/620022]    Loss: 0.007872   Batch Acc: 82.81
[Train] Epoch: 3 [529984/620022]    Loss: 0.008399   Batch Acc: 76.56
[Train] Epoch: 3 [530048/620022]    Loss: 0.009691   Batch Acc: 75.00
[Train] Epoch: 3 [530112/620022]    Loss: 0.008759   Batch Acc: 75.00
[Train] Epoch: 3 [530176/620022]    Loss: 0.011264   Batch Acc: 68.75
[Train] Epoch: 3 [530240/620022]    Loss: 0.009206   Batch Acc: 73.44
[Train] Epoch: 3 [530304/620022]    Loss: 0.010714   Batch Acc: 75.00
[Train] Epoch: 3 [530368/620022]    Loss: 0.008053   Batch Acc: 82.81
[Train] Epoch: 3 [530432/620022]    Loss: 0.011800   Batch Acc: 65.62
[Train] Epoch: 3 [530496/620022]    Loss: 0.008991   Batch Acc: 79.69
[Train] Epoch: 3 [530560/620022]    Loss: 0.008994   Batch Acc: 78.12
[Train] Epoch: 3 [530624/620022]    Loss: 0.005474   Batch Acc: 90.62
[Train] Epoch: 3 [530688/620022]    Loss: 0.006767   Batch Acc: 84.38
[Train] Epoch: 3 [530752/620022]    Loss: 0.007193   Batch Acc: 85.94
[Train] Epoch: 3 [530816/620022]    Loss: 0.007955   Batch Acc: 84.38
[Train] Epoch: 3 [530880/620022]    Loss: 0.009163   Batch Acc: 73.44
[Train] Epoch: 3 [530944/620022]    Loss: 0.009380   Batch Acc: 76.56
[Train] Epoch: 3 [531008/620022]    Loss: 0.009553   Batch Acc: 78.12
[Train] Epoch: 3 [531072/620022]    Loss: 0.006018   Batch Acc: 90.62
[Train] Epoch: 3 [531136/620022]    Loss: 0.007490   Batch Acc: 78.12
[Train] Epoch: 3 [531200/620022]    Loss: 0.009598   Batch Acc: 68.75
[Train] Epoch: 3 [531264/620022]    Loss: 0.008931   Batch Acc: 76.56
[Train] Epoch: 3 [531328/620022]    Loss: 0.008271   Batch Acc: 73.44
[Train] Epoch: 3 [531392/620022]    Loss: 0.007684   Batch Acc: 82.81
[Train] Epoch: 3 [531456/620022]    Loss: 0.008102   Batch Acc: 79.69
[Train] Epoch: 3 [531520/620022]    Loss: 0.010193   Batch Acc: 71.88
[Train] Epoch: 3 [531584/620022]    Loss: 0.009407   Batch Acc: 75.00
[Train] Epoch: 3 [531648/620022]    Loss: 0.008957   Batch Acc: 76.56
[Train] Epoch: 3 [531712/620022]    Loss: 0.008470   Batch Acc: 84.38
[Train] Epoch: 3 [531776/620022]    Loss: 0.006092   Batch Acc: 87.50
[Train] Epoch: 3 [531840/620022]    Loss: 0.008715   Batch Acc: 78.12
[Train] Epoch: 3 [531904/620022]    Loss: 0.008471   Batch Acc: 84.38
[Train] Epoch: 3 [531968/620022]    Loss: 0.008118   Batch Acc: 79.69
[Train] Epoch: 3 [532032/620022]    Loss: 0.009886   Batch Acc: 71.88
[Train] Epoch: 3 [532096/620022]    Loss: 0.007500   Batch Acc: 82.81
[Train] Epoch: 3 [532160/620022]    Loss: 0.007583   Batch Acc: 76.56
[Train] Epoch: 3 [532224/620022]    Loss: 0.011383   Batch Acc: 71.88
[Train] Epoch: 3 [532288/620022]    Loss: 0.008307   Batch Acc: 78.12
[Train] Epoch: 3 [532352/620022]    Loss: 0.010878   Batch Acc: 68.75
[Train] Epoch: 3 [532416/620022]    Loss: 0.009074   Batch Acc: 76.56
[Train] Epoch: 3 [532480/620022]    Loss: 0.008284   Batch Acc: 73.44
[Train] Epoch: 3 [532544/620022]    Loss: 0.007981   Batch Acc: 81.25
[Train] Epoch: 3 [532608/620022]    Loss: 0.010866   Batch Acc: 68.75
[Train] Epoch: 3 [532672/620022]    Loss: 0.006735   Batch Acc: 85.94
[Train] Epoch: 3 [532736/620022]    Loss: 0.013291   Batch Acc: 68.75
[Train] Epoch: 3 [532800/620022]    Loss: 0.009429   Batch Acc: 64.06
[Train] Epoch: 3 [532864/620022]    Loss: 0.008710   Batch Acc: 76.56
[Train] Epoch: 3 [532928/620022]    Loss: 0.007407   Batch Acc: 79.69
[Train] Epoch: 3 [532992/620022]    Loss: 0.008586   Batch Acc: 78.12
[Train] Epoch: 3 [533056/620022]    Loss: 0.009533   Batch Acc: 73.44
[Train] Epoch: 3 [533120/620022]    Loss: 0.009220   Batch Acc: 73.44
[Train] Epoch: 3 [533184/620022]    Loss: 0.007314   Batch Acc: 84.38
[Train] Epoch: 3 [533248/620022]    Loss: 0.009554   Batch Acc: 76.56
[Train] Epoch: 3 [533312/620022]    Loss: 0.009336   Batch Acc: 81.25
[Train] Epoch: 3 [533376/620022]    Loss: 0.008249   Batch Acc: 82.81
[Train] Epoch: 3 [533440/620022]    Loss: 0.009938   Batch Acc: 67.19
[Train] Epoch: 3 [533504/620022]    Loss: 0.009890   Batch Acc: 71.88
[Train] Epoch: 3 [533568/620022]    Loss: 0.007081   Batch Acc: 82.81
[Train] Epoch: 3 [533632/620022]    Loss: 0.009327   Batch Acc: 70.31
[Train] Epoch: 3 [533696/620022]    Loss: 0.008075   Batch Acc: 79.69
[Train] Epoch: 3 [533760/620022]    Loss: 0.006866   Batch Acc: 85.94
[Train] Epoch: 3 [533824/620022]    Loss: 0.010458   Batch Acc: 78.12
[Train] Epoch: 3 [533888/620022]    Loss: 0.009144   Batch Acc: 81.25
[Train] Epoch: 3 [533952/620022]    Loss: 0.008105   Batch Acc: 78.12
[Train] Epoch: 3 [534016/620022]    Loss: 0.010137   Batch Acc: 76.56
[Train] Epoch: 3 [534080/620022]    Loss: 0.010325   Batch Acc: 70.31
[Train] Epoch: 3 [534144/620022]    Loss: 0.008489   Batch Acc: 76.56
[Train] Epoch: 3 [534208/620022]    Loss: 0.009806   Batch Acc: 75.00
[Train] Epoch: 3 [534272/620022]    Loss: 0.008490   Batch Acc: 75.00
[Train] Epoch: 3 [534336/620022]    Loss: 0.009427   Batch Acc: 73.44
[Train] Epoch: 3 [534400/620022]    Loss: 0.007873   Batch Acc: 85.94
[Train] Epoch: 3 [534464/620022]    Loss: 0.008661   Batch Acc: 78.12
[Train] Epoch: 3 [534528/620022]    Loss: 0.008761   Batch Acc: 76.56
[Train] Epoch: 3 [534592/620022]    Loss: 0.007763   Batch Acc: 78.12
[Train] Epoch: 3 [534656/620022]    Loss: 0.007896   Batch Acc: 82.81
[Train] Epoch: 3 [534720/620022]    Loss: 0.009096   Batch Acc: 71.88
[Train] Epoch: 3 [534784/620022]    Loss: 0.008627   Batch Acc: 78.12
[Train] Epoch: 3 [534848/620022]    Loss: 0.007285   Batch Acc: 79.69
[Train] Epoch: 3 [534912/620022]    Loss: 0.008026   Batch Acc: 79.69
[Train] Epoch: 3 [534976/620022]    Loss: 0.008025   Batch Acc: 81.25
[Train] Epoch: 3 [535040/620022]    Loss: 0.008072   Batch Acc: 82.81
[Train] Epoch: 3 [535104/620022]    Loss: 0.011235   Batch Acc: 62.50
[Train] Epoch: 3 [535168/620022]    Loss: 0.008355   Batch Acc: 78.12
[Train] Epoch: 3 [535232/620022]    Loss: 0.007362   Batch Acc: 81.25
[Train] Epoch: 3 [535296/620022]    Loss: 0.009136   Batch Acc: 76.56
[Train] Epoch: 3 [535360/620022]    Loss: 0.007019   Batch Acc: 85.94
[Train] Epoch: 3 [535424/620022]    Loss: 0.009993   Batch Acc: 78.12
[Train] Epoch: 3 [535488/620022]    Loss: 0.012200   Batch Acc: 67.19
[Train] Epoch: 3 [535552/620022]    Loss: 0.006719   Batch Acc: 87.50
[Train] Epoch: 3 [535616/620022]    Loss: 0.008869   Batch Acc: 79.69
[Train] Epoch: 3 [535680/620022]    Loss: 0.007746   Batch Acc: 79.69
[Train] Epoch: 3 [535744/620022]    Loss: 0.009100   Batch Acc: 76.56
[Train] Epoch: 3 [535808/620022]    Loss: 0.007343   Batch Acc: 81.25
[Train] Epoch: 3 [535872/620022]    Loss: 0.008292   Batch Acc: 79.69
[Train] Epoch: 3 [535936/620022]    Loss: 0.009307   Batch Acc: 75.00
[Train] Epoch: 3 [536000/620022]    Loss: 0.010332   Batch Acc: 71.88
[Train] Epoch: 3 [536064/620022]    Loss: 0.008580   Batch Acc: 76.56
[Train] Epoch: 3 [536128/620022]    Loss: 0.008029   Batch Acc: 84.38
[Train] Epoch: 3 [536192/620022]    Loss: 0.010047   Batch Acc: 73.44
[Train] Epoch: 3 [536256/620022]    Loss: 0.009501   Batch Acc: 76.56
[Train] Epoch: 3 [536320/620022]    Loss: 0.007597   Batch Acc: 81.25
[Train] Epoch: 3 [536384/620022]    Loss: 0.007417   Batch Acc: 85.94
[Train] Epoch: 3 [536448/620022]    Loss: 0.008786   Batch Acc: 75.00
[Train] Epoch: 3 [536512/620022]    Loss: 0.010139   Batch Acc: 75.00
[Train] Epoch: 3 [536576/620022]    Loss: 0.010516   Batch Acc: 67.19
[Train] Epoch: 3 [536640/620022]    Loss: 0.010059   Batch Acc: 73.44
[Train] Epoch: 3 [536704/620022]    Loss: 0.010420   Batch Acc: 75.00
[Train] Epoch: 3 [536768/620022]    Loss: 0.008257   Batch Acc: 81.25
[Train] Epoch: 3 [536832/620022]    Loss: 0.007402   Batch Acc: 81.25
[Train] Epoch: 3 [536896/620022]    Loss: 0.008125   Batch Acc: 81.25
[Train] Epoch: 3 [536960/620022]    Loss: 0.008353   Batch Acc: 76.56
[Train] Epoch: 3 [537024/620022]    Loss: 0.008688   Batch Acc: 79.69
[Train] Epoch: 3 [537088/620022]    Loss: 0.009739   Batch Acc: 70.31
[Train] Epoch: 3 [537152/620022]    Loss: 0.008460   Batch Acc: 73.44
[Train] Epoch: 3 [537216/620022]    Loss: 0.008174   Batch Acc: 79.69
[Train] Epoch: 3 [537280/620022]    Loss: 0.009331   Batch Acc: 73.44
[Train] Epoch: 3 [537344/620022]    Loss: 0.011552   Batch Acc: 68.75
[Train] Epoch: 3 [537408/620022]    Loss: 0.006214   Batch Acc: 85.94
[Train] Epoch: 3 [537472/620022]    Loss: 0.006377   Batch Acc: 90.62
[Train] Epoch: 3 [537536/620022]    Loss: 0.009313   Batch Acc: 73.44
[Train] Epoch: 3 [537600/620022]    Loss: 0.006735   Batch Acc: 84.38
[Train] Epoch: 3 [537664/620022]    Loss: 0.008618   Batch Acc: 79.69
[Train] Epoch: 3 [537728/620022]    Loss: 0.009302   Batch Acc: 71.88
[Train] Epoch: 3 [537792/620022]    Loss: 0.009551   Batch Acc: 81.25
[Train] Epoch: 3 [537856/620022]    Loss: 0.008951   Batch Acc: 81.25
[Train] Epoch: 3 [537920/620022]    Loss: 0.009184   Batch Acc: 76.56
[Train] Epoch: 3 [537984/620022]    Loss: 0.009478   Batch Acc: 73.44
[Train] Epoch: 3 [538048/620022]    Loss: 0.009921   Batch Acc: 71.88
[Train] Epoch: 3 [538112/620022]    Loss: 0.008430   Batch Acc: 75.00
[Train] Epoch: 3 [538176/620022]    Loss: 0.010526   Batch Acc: 81.25
[Train] Epoch: 3 [538240/620022]    Loss: 0.010023   Batch Acc: 68.75
[Train] Epoch: 3 [538304/620022]    Loss: 0.008232   Batch Acc: 79.69
[Train] Epoch: 3 [538368/620022]    Loss: 0.008247   Batch Acc: 76.56
[Train] Epoch: 3 [538432/620022]    Loss: 0.009561   Batch Acc: 76.56
[Train] Epoch: 3 [538496/620022]    Loss: 0.010757   Batch Acc: 73.44
[Train] Epoch: 3 [538560/620022]    Loss: 0.010074   Batch Acc: 70.31
[Train] Epoch: 3 [538624/620022]    Loss: 0.008307   Batch Acc: 78.12
[Train] Epoch: 3 [538688/620022]    Loss: 0.007955   Batch Acc: 81.25
[Train] Epoch: 3 [538752/620022]    Loss: 0.006501   Batch Acc: 85.94
[Train] Epoch: 3 [538816/620022]    Loss: 0.010524   Batch Acc: 67.19
[Train] Epoch: 3 [538880/620022]    Loss: 0.009377   Batch Acc: 78.12
[Train] Epoch: 3 [538944/620022]    Loss: 0.009424   Batch Acc: 78.12
[Train] Epoch: 3 [539008/620022]    Loss: 0.009664   Batch Acc: 75.00
[Train] Epoch: 3 [539072/620022]    Loss: 0.008811   Batch Acc: 79.69
[Train] Epoch: 3 [539136/620022]    Loss: 0.007183   Batch Acc: 79.69
[Train] Epoch: 3 [539200/620022]    Loss: 0.008560   Batch Acc: 78.12
[Train] Epoch: 3 [539264/620022]    Loss: 0.010796   Batch Acc: 79.69
[Train] Epoch: 3 [539328/620022]    Loss: 0.009235   Batch Acc: 75.00
[Train] Epoch: 3 [539392/620022]    Loss: 0.007233   Batch Acc: 84.38
[Train] Epoch: 3 [539456/620022]    Loss: 0.008475   Batch Acc: 79.69
[Train] Epoch: 3 [539520/620022]    Loss: 0.008157   Batch Acc: 79.69
[Train] Epoch: 3 [539584/620022]    Loss: 0.011524   Batch Acc: 65.62
[Train] Epoch: 3 [539648/620022]    Loss: 0.007745   Batch Acc: 78.12
[Train] Epoch: 3 [539712/620022]    Loss: 0.007768   Batch Acc: 81.25
[Train] Epoch: 3 [539776/620022]    Loss: 0.009389   Batch Acc: 71.88
[Train] Epoch: 3 [539840/620022]    Loss: 0.009803   Batch Acc: 79.69
[Train] Epoch: 3 [539904/620022]    Loss: 0.009978   Batch Acc: 68.75
[Train] Epoch: 3 [539968/620022]    Loss: 0.009323   Batch Acc: 79.69
[Train] Epoch: 3 [540032/620022]    Loss: 0.007166   Batch Acc: 75.00
[Train] Epoch: 3 [540096/620022]    Loss: 0.009200   Batch Acc: 76.56
[Train] Epoch: 3 [540160/620022]    Loss: 0.009043   Batch Acc: 79.69
[Train] Epoch: 3 [540224/620022]    Loss: 0.008745   Batch Acc: 71.88
[Train] Epoch: 3 [540288/620022]    Loss: 0.009639   Batch Acc: 75.00
[Train] Epoch: 3 [540352/620022]    Loss: 0.009610   Batch Acc: 76.56
[Train] Epoch: 3 [540416/620022]    Loss: 0.006668   Batch Acc: 84.38
[Train] Epoch: 3 [540480/620022]    Loss: 0.007723   Batch Acc: 79.69
[Train] Epoch: 3 [540544/620022]    Loss: 0.008996   Batch Acc: 73.44
[Train] Epoch: 3 [540608/620022]    Loss: 0.009992   Batch Acc: 79.69
[Train] Epoch: 3 [540672/620022]    Loss: 0.006635   Batch Acc: 85.94
[Train] Epoch: 3 [540736/620022]    Loss: 0.006570   Batch Acc: 84.38
[Train] Epoch: 3 [540800/620022]    Loss: 0.007715   Batch Acc: 82.81
[Train] Epoch: 3 [540864/620022]    Loss: 0.006984   Batch Acc: 73.44
[Train] Epoch: 3 [540928/620022]    Loss: 0.009279   Batch Acc: 76.56
[Train] Epoch: 3 [540992/620022]    Loss: 0.010235   Batch Acc: 75.00
[Train] Epoch: 3 [541056/620022]    Loss: 0.008461   Batch Acc: 81.25
[Train] Epoch: 3 [541120/620022]    Loss: 0.005701   Batch Acc: 82.81
[Train] Epoch: 3 [541184/620022]    Loss: 0.006898   Batch Acc: 79.69
[Train] Epoch: 3 [541248/620022]    Loss: 0.006204   Batch Acc: 84.38
[Train] Epoch: 3 [541312/620022]    Loss: 0.008084   Batch Acc: 79.69
[Train] Epoch: 3 [541376/620022]    Loss: 0.006954   Batch Acc: 84.38
[Train] Epoch: 3 [541440/620022]    Loss: 0.007872   Batch Acc: 81.25
[Train] Epoch: 3 [541504/620022]    Loss: 0.010700   Batch Acc: 75.00
[Train] Epoch: 3 [541568/620022]    Loss: 0.009792   Batch Acc: 73.44
[Train] Epoch: 3 [541632/620022]    Loss: 0.006579   Batch Acc: 81.25
[Train] Epoch: 3 [541696/620022]    Loss: 0.007085   Batch Acc: 81.25
[Train] Epoch: 3 [541760/620022]    Loss: 0.009329   Batch Acc: 75.00
[Train] Epoch: 3 [541824/620022]    Loss: 0.009130   Batch Acc: 78.12
[Train] Epoch: 3 [541888/620022]    Loss: 0.007221   Batch Acc: 81.25
[Train] Epoch: 3 [541952/620022]    Loss: 0.006928   Batch Acc: 82.81
[Train] Epoch: 3 [542016/620022]    Loss: 0.008411   Batch Acc: 75.00
[Train] Epoch: 3 [542080/620022]    Loss: 0.010039   Batch Acc: 73.44
[Train] Epoch: 3 [542144/620022]    Loss: 0.008627   Batch Acc: 79.69
[Train] Epoch: 3 [542208/620022]    Loss: 0.007571   Batch Acc: 79.69
[Train] Epoch: 3 [542272/620022]    Loss: 0.010498   Batch Acc: 75.00
[Train] Epoch: 3 [542336/620022]    Loss: 0.009004   Batch Acc: 70.31
[Train] Epoch: 3 [542400/620022]    Loss: 0.009721   Batch Acc: 75.00
[Train] Epoch: 3 [542464/620022]    Loss: 0.011552   Batch Acc: 76.56
[Train] Epoch: 3 [542528/620022]    Loss: 0.011697   Batch Acc: 64.06
[Train] Epoch: 3 [542592/620022]    Loss: 0.009292   Batch Acc: 79.69
[Train] Epoch: 3 [542656/620022]    Loss: 0.008526   Batch Acc: 81.25
[Train] Epoch: 3 [542720/620022]    Loss: 0.008710   Batch Acc: 79.69
[Train] Epoch: 3 [542784/620022]    Loss: 0.008019   Batch Acc: 81.25
[Train] Epoch: 3 [542848/620022]    Loss: 0.009775   Batch Acc: 73.44
[Train] Epoch: 3 [542912/620022]    Loss: 0.005541   Batch Acc: 89.06
[Train] Epoch: 3 [542976/620022]    Loss: 0.006713   Batch Acc: 85.94
[Train] Epoch: 3 [543040/620022]    Loss: 0.007679   Batch Acc: 76.56
[Train] Epoch: 3 [543104/620022]    Loss: 0.010115   Batch Acc: 75.00
[Train] Epoch: 3 [543168/620022]    Loss: 0.008783   Batch Acc: 73.44
[Train] Epoch: 3 [543232/620022]    Loss: 0.008023   Batch Acc: 85.94
[Train] Epoch: 3 [543296/620022]    Loss: 0.006546   Batch Acc: 90.62
[Train] Epoch: 3 [543360/620022]    Loss: 0.006424   Batch Acc: 89.06
[Train] Epoch: 3 [543424/620022]    Loss: 0.008591   Batch Acc: 82.81
[Train] Epoch: 3 [543488/620022]    Loss: 0.006858   Batch Acc: 81.25
[Train] Epoch: 3 [543552/620022]    Loss: 0.006297   Batch Acc: 84.38
[Train] Epoch: 3 [543616/620022]    Loss: 0.008947   Batch Acc: 82.81
[Train] Epoch: 3 [543680/620022]    Loss: 0.008801   Batch Acc: 71.88
[Train] Epoch: 3 [543744/620022]    Loss: 0.009519   Batch Acc: 73.44
[Train] Epoch: 3 [543808/620022]    Loss: 0.009051   Batch Acc: 78.12
[Train] Epoch: 3 [543872/620022]    Loss: 0.008885   Batch Acc: 76.56
[Train] Epoch: 3 [543936/620022]    Loss: 0.007438   Batch Acc: 78.12
[Train] Epoch: 3 [544000/620022]    Loss: 0.007591   Batch Acc: 79.69
[Train] Epoch: 3 [544064/620022]    Loss: 0.006255   Batch Acc: 84.38
[Train] Epoch: 3 [544128/620022]    Loss: 0.009873   Batch Acc: 73.44
[Train] Epoch: 3 [544192/620022]    Loss: 0.011943   Batch Acc: 68.75
[Train] Epoch: 3 [544256/620022]    Loss: 0.008988   Batch Acc: 70.31
[Train] Epoch: 3 [544320/620022]    Loss: 0.009149   Batch Acc: 76.56
[Train] Epoch: 3 [544384/620022]    Loss: 0.006364   Batch Acc: 89.06
[Train] Epoch: 3 [544448/620022]    Loss: 0.007734   Batch Acc: 84.38
[Train] Epoch: 3 [544512/620022]    Loss: 0.009271   Batch Acc: 76.56
[Train] Epoch: 3 [544576/620022]    Loss: 0.010036   Batch Acc: 79.69
[Train] Epoch: 3 [544640/620022]    Loss: 0.010029   Batch Acc: 71.88
[Train] Epoch: 3 [544704/620022]    Loss: 0.007958   Batch Acc: 82.81
[Train] Epoch: 3 [544768/620022]    Loss: 0.007779   Batch Acc: 75.00
[Train] Epoch: 3 [544832/620022]    Loss: 0.008524   Batch Acc: 78.12
[Train] Epoch: 3 [544896/620022]    Loss: 0.006564   Batch Acc: 84.38
[Train] Epoch: 3 [544960/620022]    Loss: 0.009276   Batch Acc: 68.75
[Train] Epoch: 3 [545024/620022]    Loss: 0.006838   Batch Acc: 81.25
[Train] Epoch: 3 [545088/620022]    Loss: 0.008762   Batch Acc: 81.25
[Train] Epoch: 3 [545152/620022]    Loss: 0.008697   Batch Acc: 75.00
[Train] Epoch: 3 [545216/620022]    Loss: 0.006784   Batch Acc: 82.81
[Train] Epoch: 3 [545280/620022]    Loss: 0.009047   Batch Acc: 79.69
[Train] Epoch: 3 [545344/620022]    Loss: 0.007852   Batch Acc: 84.38
[Train] Epoch: 3 [545408/620022]    Loss: 0.007493   Batch Acc: 82.81
[Train] Epoch: 3 [545472/620022]    Loss: 0.007652   Batch Acc: 76.56
[Train] Epoch: 3 [545536/620022]    Loss: 0.008304   Batch Acc: 82.81
[Train] Epoch: 3 [545600/620022]    Loss: 0.008425   Batch Acc: 82.81
[Train] Epoch: 3 [545664/620022]    Loss: 0.007860   Batch Acc: 82.81
[Train] Epoch: 3 [545728/620022]    Loss: 0.009569   Batch Acc: 78.12
[Train] Epoch: 3 [545792/620022]    Loss: 0.009445   Batch Acc: 75.00
[Train] Epoch: 3 [545856/620022]    Loss: 0.008410   Batch Acc: 81.25
[Train] Epoch: 3 [545920/620022]    Loss: 0.007318   Batch Acc: 85.94
[Train] Epoch: 3 [545984/620022]    Loss: 0.008803   Batch Acc: 76.56
[Train] Epoch: 3 [546048/620022]    Loss: 0.008556   Batch Acc: 82.81
[Train] Epoch: 3 [546112/620022]    Loss: 0.007498   Batch Acc: 78.12
[Train] Epoch: 3 [546176/620022]    Loss: 0.010180   Batch Acc: 70.31
[Train] Epoch: 3 [546240/620022]    Loss: 0.008885   Batch Acc: 81.25
[Train] Epoch: 3 [546304/620022]    Loss: 0.007579   Batch Acc: 76.56
[Train] Epoch: 3 [546368/620022]    Loss: 0.007519   Batch Acc: 84.38
[Train] Epoch: 3 [546432/620022]    Loss: 0.008007   Batch Acc: 79.69
[Train] Epoch: 3 [546496/620022]    Loss: 0.009504   Batch Acc: 71.88
[Train] Epoch: 3 [546560/620022]    Loss: 0.008308   Batch Acc: 79.69
[Train] Epoch: 3 [546624/620022]    Loss: 0.007315   Batch Acc: 82.81
[Train] Epoch: 3 [546688/620022]    Loss: 0.009182   Batch Acc: 78.12
[Train] Epoch: 3 [546752/620022]    Loss: 0.008783   Batch Acc: 78.12
[Train] Epoch: 3 [546816/620022]    Loss: 0.008667   Batch Acc: 76.56
[Train] Epoch: 3 [546880/620022]    Loss: 0.008431   Batch Acc: 79.69
[Train] Epoch: 3 [546944/620022]    Loss: 0.007678   Batch Acc: 79.69
[Train] Epoch: 3 [547008/620022]    Loss: 0.008644   Batch Acc: 82.81
[Train] Epoch: 3 [547072/620022]    Loss: 0.010168   Batch Acc: 73.44
[Train] Epoch: 3 [547136/620022]    Loss: 0.006780   Batch Acc: 79.69
[Train] Epoch: 3 [547200/620022]    Loss: 0.008961   Batch Acc: 76.56
[Train] Epoch: 3 [547264/620022]    Loss: 0.008866   Batch Acc: 75.00
[Train] Epoch: 3 [547328/620022]    Loss: 0.008234   Batch Acc: 78.12
[Train] Epoch: 3 [547392/620022]    Loss: 0.007271   Batch Acc: 85.94
[Train] Epoch: 3 [547456/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 3 [547520/620022]    Loss: 0.007696   Batch Acc: 76.56
[Train] Epoch: 3 [547584/620022]    Loss: 0.008778   Batch Acc: 76.56
[Train] Epoch: 3 [547648/620022]    Loss: 0.009254   Batch Acc: 78.12
[Train] Epoch: 3 [547712/620022]    Loss: 0.007810   Batch Acc: 82.81
[Train] Epoch: 3 [547776/620022]    Loss: 0.007933   Batch Acc: 84.38
[Train] Epoch: 3 [547840/620022]    Loss: 0.007155   Batch Acc: 81.25
[Train] Epoch: 3 [547904/620022]    Loss: 0.009524   Batch Acc: 73.44
[Train] Epoch: 3 [547968/620022]    Loss: 0.008688   Batch Acc: 81.25
[Train] Epoch: 3 [548032/620022]    Loss: 0.009739   Batch Acc: 76.56
[Train] Epoch: 3 [548096/620022]    Loss: 0.007507   Batch Acc: 82.81
[Train] Epoch: 3 [548160/620022]    Loss: 0.011203   Batch Acc: 73.44
[Train] Epoch: 3 [548224/620022]    Loss: 0.007390   Batch Acc: 84.38
[Train] Epoch: 3 [548288/620022]    Loss: 0.008472   Batch Acc: 85.94
[Train] Epoch: 3 [548352/620022]    Loss: 0.009588   Batch Acc: 76.56
[Train] Epoch: 3 [548416/620022]    Loss: 0.008941   Batch Acc: 76.56
[Train] Epoch: 3 [548480/620022]    Loss: 0.007136   Batch Acc: 84.38
[Train] Epoch: 3 [548544/620022]    Loss: 0.006166   Batch Acc: 89.06
[Train] Epoch: 3 [548608/620022]    Loss: 0.009326   Batch Acc: 75.00
[Train] Epoch: 3 [548672/620022]    Loss: 0.009227   Batch Acc: 78.12
[Train] Epoch: 3 [548736/620022]    Loss: 0.008753   Batch Acc: 75.00
[Train] Epoch: 3 [548800/620022]    Loss: 0.006767   Batch Acc: 84.38
[Train] Epoch: 3 [548864/620022]    Loss: 0.010652   Batch Acc: 73.44
[Train] Epoch: 3 [548928/620022]    Loss: 0.008227   Batch Acc: 76.56
[Train] Epoch: 3 [548992/620022]    Loss: 0.008885   Batch Acc: 75.00
[Train] Epoch: 3 [549056/620022]    Loss: 0.007176   Batch Acc: 82.81
[Train] Epoch: 3 [549120/620022]    Loss: 0.006691   Batch Acc: 85.94
[Train] Epoch: 3 [549184/620022]    Loss: 0.009700   Batch Acc: 73.44
[Train] Epoch: 3 [549248/620022]    Loss: 0.008762   Batch Acc: 76.56
[Train] Epoch: 3 [549312/620022]    Loss: 0.010956   Batch Acc: 67.19
[Train] Epoch: 3 [549376/620022]    Loss: 0.007800   Batch Acc: 82.81
[Train] Epoch: 3 [549440/620022]    Loss: 0.008612   Batch Acc: 73.44
[Train] Epoch: 3 [549504/620022]    Loss: 0.009370   Batch Acc: 79.69
[Train] Epoch: 3 [549568/620022]    Loss: 0.007024   Batch Acc: 81.25
[Train] Epoch: 3 [549632/620022]    Loss: 0.007675   Batch Acc: 81.25
[Train] Epoch: 3 [549696/620022]    Loss: 0.009586   Batch Acc: 76.56
[Train] Epoch: 3 [549760/620022]    Loss: 0.008167   Batch Acc: 82.81
[Train] Epoch: 3 [549824/620022]    Loss: 0.011334   Batch Acc: 65.62
[Train] Epoch: 3 [549888/620022]    Loss: 0.006091   Batch Acc: 84.38
[Train] Epoch: 3 [549952/620022]    Loss: 0.008960   Batch Acc: 84.38
[Train] Epoch: 3 [550016/620022]    Loss: 0.009396   Batch Acc: 76.56
[Train] Epoch: 3 [550080/620022]    Loss: 0.008754   Batch Acc: 81.25
[Train] Epoch: 3 [550144/620022]    Loss: 0.007920   Batch Acc: 85.94
[Train] Epoch: 3 [550208/620022]    Loss: 0.007885   Batch Acc: 78.12
[Train] Epoch: 3 [550272/620022]    Loss: 0.011371   Batch Acc: 75.00
[Train] Epoch: 3 [550336/620022]    Loss: 0.009226   Batch Acc: 73.44
[Train] Epoch: 3 [550400/620022]    Loss: 0.009868   Batch Acc: 76.56
[Train] Epoch: 3 [550464/620022]    Loss: 0.007996   Batch Acc: 78.12
[Train] Epoch: 3 [550528/620022]    Loss: 0.009928   Batch Acc: 73.44
[Train] Epoch: 3 [550592/620022]    Loss: 0.005706   Batch Acc: 87.50
[Train] Epoch: 3 [550656/620022]    Loss: 0.009452   Batch Acc: 76.56
[Train] Epoch: 3 [550720/620022]    Loss: 0.008656   Batch Acc: 82.81
[Train] Epoch: 3 [550784/620022]    Loss: 0.008229   Batch Acc: 81.25
[Train] Epoch: 3 [550848/620022]    Loss: 0.009529   Batch Acc: 81.25
[Train] Epoch: 3 [550912/620022]    Loss: 0.010508   Batch Acc: 71.88
[Train] Epoch: 3 [550976/620022]    Loss: 0.008139   Batch Acc: 82.81
[Train] Epoch: 3 [551040/620022]    Loss: 0.010071   Batch Acc: 78.12
[Train] Epoch: 3 [551104/620022]    Loss: 0.007494   Batch Acc: 79.69
[Train] Epoch: 3 [551168/620022]    Loss: 0.008038   Batch Acc: 78.12
[Train] Epoch: 3 [551232/620022]    Loss: 0.011499   Batch Acc: 70.31
[Train] Epoch: 3 [551296/620022]    Loss: 0.009344   Batch Acc: 73.44
[Train] Epoch: 3 [551360/620022]    Loss: 0.009019   Batch Acc: 76.56
[Train] Epoch: 3 [551424/620022]    Loss: 0.010514   Batch Acc: 68.75
[Train] Epoch: 3 [551488/620022]    Loss: 0.008572   Batch Acc: 78.12
[Train] Epoch: 3 [551552/620022]    Loss: 0.008591   Batch Acc: 76.56
[Train] Epoch: 3 [551616/620022]    Loss: 0.010872   Batch Acc: 78.12
[Train] Epoch: 3 [551680/620022]    Loss: 0.008812   Batch Acc: 73.44
[Train] Epoch: 3 [551744/620022]    Loss: 0.008319   Batch Acc: 84.38
[Train] Epoch: 3 [551808/620022]    Loss: 0.008141   Batch Acc: 81.25
[Train] Epoch: 3 [551872/620022]    Loss: 0.008487   Batch Acc: 76.56
[Train] Epoch: 3 [551936/620022]    Loss: 0.007812   Batch Acc: 81.25
[Train] Epoch: 3 [552000/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 3 [552064/620022]    Loss: 0.012054   Batch Acc: 71.88
[Train] Epoch: 3 [552128/620022]    Loss: 0.007740   Batch Acc: 79.69
[Train] Epoch: 3 [552192/620022]    Loss: 0.008026   Batch Acc: 81.25
[Train] Epoch: 3 [552256/620022]    Loss: 0.008127   Batch Acc: 78.12
[Train] Epoch: 3 [552320/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 3 [552384/620022]    Loss: 0.007501   Batch Acc: 79.69
[Train] Epoch: 3 [552448/620022]    Loss: 0.009930   Batch Acc: 73.44
[Train] Epoch: 3 [552512/620022]    Loss: 0.010868   Batch Acc: 67.19
[Train] Epoch: 3 [552576/620022]    Loss: 0.007960   Batch Acc: 76.56
[Train] Epoch: 3 [552640/620022]    Loss: 0.008655   Batch Acc: 78.12
[Train] Epoch: 3 [552704/620022]    Loss: 0.009473   Batch Acc: 78.12
[Train] Epoch: 3 [552768/620022]    Loss: 0.009486   Batch Acc: 76.56
[Train] Epoch: 3 [552832/620022]    Loss: 0.012827   Batch Acc: 67.19
[Train] Epoch: 3 [552896/620022]    Loss: 0.007954   Batch Acc: 81.25
[Train] Epoch: 3 [552960/620022]    Loss: 0.008610   Batch Acc: 75.00
[Train] Epoch: 3 [553024/620022]    Loss: 0.006527   Batch Acc: 81.25
[Train] Epoch: 3 [553088/620022]    Loss: 0.008337   Batch Acc: 81.25
[Train] Epoch: 3 [553152/620022]    Loss: 0.007445   Batch Acc: 78.12
[Train] Epoch: 3 [553216/620022]    Loss: 0.007772   Batch Acc: 81.25
[Train] Epoch: 3 [553280/620022]    Loss: 0.007089   Batch Acc: 81.25
[Train] Epoch: 3 [553344/620022]    Loss: 0.008788   Batch Acc: 82.81
[Train] Epoch: 3 [553408/620022]    Loss: 0.008536   Batch Acc: 81.25
[Train] Epoch: 3 [553472/620022]    Loss: 0.008248   Batch Acc: 79.69
[Train] Epoch: 3 [553536/620022]    Loss: 0.009446   Batch Acc: 76.56
[Train] Epoch: 3 [553600/620022]    Loss: 0.007469   Batch Acc: 85.94
[Train] Epoch: 3 [553664/620022]    Loss: 0.010013   Batch Acc: 70.31
[Train] Epoch: 3 [553728/620022]    Loss: 0.008005   Batch Acc: 81.25
[Train] Epoch: 3 [553792/620022]    Loss: 0.010288   Batch Acc: 71.88
[Train] Epoch: 3 [553856/620022]    Loss: 0.010908   Batch Acc: 70.31
[Train] Epoch: 3 [553920/620022]    Loss: 0.008705   Batch Acc: 79.69
[Train] Epoch: 3 [553984/620022]    Loss: 0.008489   Batch Acc: 81.25
[Train] Epoch: 3 [554048/620022]    Loss: 0.008117   Batch Acc: 71.88
[Train] Epoch: 3 [554112/620022]    Loss: 0.008218   Batch Acc: 71.88
[Train] Epoch: 3 [554176/620022]    Loss: 0.007085   Batch Acc: 81.25
[Train] Epoch: 3 [554240/620022]    Loss: 0.010240   Batch Acc: 70.31
[Train] Epoch: 3 [554304/620022]    Loss: 0.008746   Batch Acc: 76.56
[Train] Epoch: 3 [554368/620022]    Loss: 0.007604   Batch Acc: 79.69
[Train] Epoch: 3 [554432/620022]    Loss: 0.008287   Batch Acc: 82.81
[Train] Epoch: 3 [554496/620022]    Loss: 0.009697   Batch Acc: 79.69
[Train] Epoch: 3 [554560/620022]    Loss: 0.007009   Batch Acc: 84.38
[Train] Epoch: 3 [554624/620022]    Loss: 0.006427   Batch Acc: 82.81
[Train] Epoch: 3 [554688/620022]    Loss: 0.009343   Batch Acc: 73.44
[Train] Epoch: 3 [554752/620022]    Loss: 0.008991   Batch Acc: 71.88
[Train] Epoch: 3 [554816/620022]    Loss: 0.007204   Batch Acc: 82.81
[Train] Epoch: 3 [554880/620022]    Loss: 0.009313   Batch Acc: 78.12
[Train] Epoch: 3 [554944/620022]    Loss: 0.010022   Batch Acc: 67.19
[Train] Epoch: 3 [555008/620022]    Loss: 0.009176   Batch Acc: 71.88
[Train] Epoch: 3 [555072/620022]    Loss: 0.009158   Batch Acc: 79.69
[Train] Epoch: 3 [555136/620022]    Loss: 0.010290   Batch Acc: 76.56
[Train] Epoch: 3 [555200/620022]    Loss: 0.008711   Batch Acc: 81.25
[Train] Epoch: 3 [555264/620022]    Loss: 0.009491   Batch Acc: 73.44
[Train] Epoch: 3 [555328/620022]    Loss: 0.007095   Batch Acc: 82.81
[Train] Epoch: 3 [555392/620022]    Loss: 0.006270   Batch Acc: 84.38
[Train] Epoch: 3 [555456/620022]    Loss: 0.008538   Batch Acc: 79.69
[Train] Epoch: 3 [555520/620022]    Loss: 0.006531   Batch Acc: 84.38
[Train] Epoch: 3 [555584/620022]    Loss: 0.010351   Batch Acc: 68.75
[Train] Epoch: 3 [555648/620022]    Loss: 0.008774   Batch Acc: 76.56
[Train] Epoch: 3 [555712/620022]    Loss: 0.009497   Batch Acc: 78.12
[Train] Epoch: 3 [555776/620022]    Loss: 0.008005   Batch Acc: 84.38
[Train] Epoch: 3 [555840/620022]    Loss: 0.009045   Batch Acc: 78.12
[Train] Epoch: 3 [555904/620022]    Loss: 0.008576   Batch Acc: 75.00
[Train] Epoch: 3 [555968/620022]    Loss: 0.008068   Batch Acc: 75.00
[Train] Epoch: 3 [556032/620022]    Loss: 0.009534   Batch Acc: 78.12
[Train] Epoch: 3 [556096/620022]    Loss: 0.008077   Batch Acc: 78.12
[Train] Epoch: 3 [556160/620022]    Loss: 0.005776   Batch Acc: 90.62
[Train] Epoch: 3 [556224/620022]    Loss: 0.007728   Batch Acc: 79.69
[Train] Epoch: 3 [556288/620022]    Loss: 0.009108   Batch Acc: 75.00
[Train] Epoch: 3 [556352/620022]    Loss: 0.010891   Batch Acc: 68.75
[Train] Epoch: 3 [556416/620022]    Loss: 0.010251   Batch Acc: 70.31
[Train] Epoch: 3 [556480/620022]    Loss: 0.008931   Batch Acc: 78.12
[Train] Epoch: 3 [556544/620022]    Loss: 0.007042   Batch Acc: 81.25
[Train] Epoch: 3 [556608/620022]    Loss: 0.007206   Batch Acc: 84.38
[Train] Epoch: 3 [556672/620022]    Loss: 0.005165   Batch Acc: 89.06
[Train] Epoch: 3 [556736/620022]    Loss: 0.007485   Batch Acc: 82.81
[Train] Epoch: 3 [556800/620022]    Loss: 0.008144   Batch Acc: 84.38
[Train] Epoch: 3 [556864/620022]    Loss: 0.010326   Batch Acc: 71.88
[Train] Epoch: 3 [556928/620022]    Loss: 0.010486   Batch Acc: 75.00
[Train] Epoch: 3 [556992/620022]    Loss: 0.009755   Batch Acc: 73.44
[Train] Epoch: 3 [557056/620022]    Loss: 0.007070   Batch Acc: 82.81
[Train] Epoch: 3 [557120/620022]    Loss: 0.009680   Batch Acc: 75.00
[Train] Epoch: 3 [557184/620022]    Loss: 0.009327   Batch Acc: 79.69
[Train] Epoch: 3 [557248/620022]    Loss: 0.009545   Batch Acc: 78.12
[Train] Epoch: 3 [557312/620022]    Loss: 0.008004   Batch Acc: 81.25
[Train] Epoch: 3 [557376/620022]    Loss: 0.006559   Batch Acc: 87.50
[Train] Epoch: 3 [557440/620022]    Loss: 0.009039   Batch Acc: 79.69
[Train] Epoch: 3 [557504/620022]    Loss: 0.008539   Batch Acc: 79.69
[Train] Epoch: 3 [557568/620022]    Loss: 0.007311   Batch Acc: 79.69
[Train] Epoch: 3 [557632/620022]    Loss: 0.009430   Batch Acc: 76.56
[Train] Epoch: 3 [557696/620022]    Loss: 0.009646   Batch Acc: 71.88
[Train] Epoch: 3 [557760/620022]    Loss: 0.008270   Batch Acc: 73.44
[Train] Epoch: 3 [557824/620022]    Loss: 0.008312   Batch Acc: 78.12
[Train] Epoch: 3 [557888/620022]    Loss: 0.009777   Batch Acc: 76.56
[Train] Epoch: 3 [557952/620022]    Loss: 0.010378   Batch Acc: 70.31
[Train] Epoch: 3 [558016/620022]    Loss: 0.007071   Batch Acc: 81.25
[Train] Epoch: 3 [558080/620022]    Loss: 0.007021   Batch Acc: 82.81
[Train] Epoch: 3 [558144/620022]    Loss: 0.007766   Batch Acc: 76.56
[Train] Epoch: 3 [558208/620022]    Loss: 0.009511   Batch Acc: 76.56
[Train] Epoch: 3 [558272/620022]    Loss: 0.008006   Batch Acc: 81.25
[Train] Epoch: 3 [558336/620022]    Loss: 0.009526   Batch Acc: 71.88
[Train] Epoch: 3 [558400/620022]    Loss: 0.008559   Batch Acc: 82.81
[Train] Epoch: 3 [558464/620022]    Loss: 0.008226   Batch Acc: 76.56
[Train] Epoch: 3 [558528/620022]    Loss: 0.007805   Batch Acc: 87.50
[Train] Epoch: 3 [558592/620022]    Loss: 0.007398   Batch Acc: 82.81
[Train] Epoch: 3 [558656/620022]    Loss: 0.008445   Batch Acc: 78.12
[Train] Epoch: 3 [558720/620022]    Loss: 0.009776   Batch Acc: 76.56
[Train] Epoch: 3 [558784/620022]    Loss: 0.009750   Batch Acc: 78.12
[Train] Epoch: 3 [558848/620022]    Loss: 0.008993   Batch Acc: 76.56
[Train] Epoch: 3 [558912/620022]    Loss: 0.010504   Batch Acc: 70.31
[Train] Epoch: 3 [558976/620022]    Loss: 0.008210   Batch Acc: 81.25
[Train] Epoch: 3 [559040/620022]    Loss: 0.010353   Batch Acc: 70.31
[Train] Epoch: 3 [559104/620022]    Loss: 0.007658   Batch Acc: 79.69
[Train] Epoch: 3 [559168/620022]    Loss: 0.009144   Batch Acc: 73.44
[Train] Epoch: 3 [559232/620022]    Loss: 0.010376   Batch Acc: 78.12
[Train] Epoch: 3 [559296/620022]    Loss: 0.009042   Batch Acc: 78.12
[Train] Epoch: 3 [559360/620022]    Loss: 0.007069   Batch Acc: 85.94
[Train] Epoch: 3 [559424/620022]    Loss: 0.008161   Batch Acc: 84.38
[Train] Epoch: 3 [559488/620022]    Loss: 0.009981   Batch Acc: 78.12
[Train] Epoch: 3 [559552/620022]    Loss: 0.010744   Batch Acc: 76.56
[Train] Epoch: 3 [559616/620022]    Loss: 0.007248   Batch Acc: 82.81
[Train] Epoch: 3 [559680/620022]    Loss: 0.009021   Batch Acc: 75.00
[Train] Epoch: 3 [559744/620022]    Loss: 0.007877   Batch Acc: 81.25
[Train] Epoch: 3 [559808/620022]    Loss: 0.007361   Batch Acc: 84.38
[Train] Epoch: 3 [559872/620022]    Loss: 0.009378   Batch Acc: 73.44
[Train] Epoch: 3 [559936/620022]    Loss: 0.009160   Batch Acc: 79.69
[Train] Epoch: 3 [560000/620022]    Loss: 0.010867   Batch Acc: 76.56
[Train] Epoch: 3 [560064/620022]    Loss: 0.010259   Batch Acc: 70.31
[Train] Epoch: 3 [560128/620022]    Loss: 0.008920   Batch Acc: 79.69
[Train] Epoch: 3 [560192/620022]    Loss: 0.010216   Batch Acc: 73.44
[Train] Epoch: 3 [560256/620022]    Loss: 0.009205   Batch Acc: 70.31
[Train] Epoch: 3 [560320/620022]    Loss: 0.009303   Batch Acc: 73.44
[Train] Epoch: 3 [560384/620022]    Loss: 0.009165   Batch Acc: 68.75
[Train] Epoch: 3 [560448/620022]    Loss: 0.007953   Batch Acc: 75.00
[Train] Epoch: 3 [560512/620022]    Loss: 0.008065   Batch Acc: 76.56
[Train] Epoch: 3 [560576/620022]    Loss: 0.009748   Batch Acc: 71.88
[Train] Epoch: 3 [560640/620022]    Loss: 0.006459   Batch Acc: 87.50
[Train] Epoch: 3 [560704/620022]    Loss: 0.009096   Batch Acc: 71.88
[Train] Epoch: 3 [560768/620022]    Loss: 0.009543   Batch Acc: 78.12
[Train] Epoch: 3 [560832/620022]    Loss: 0.009660   Batch Acc: 78.12
[Train] Epoch: 3 [560896/620022]    Loss: 0.008780   Batch Acc: 71.88
[Train] Epoch: 3 [560960/620022]    Loss: 0.012431   Batch Acc: 68.75
[Train] Epoch: 3 [561024/620022]    Loss: 0.008574   Batch Acc: 79.69
[Train] Epoch: 3 [561088/620022]    Loss: 0.007586   Batch Acc: 76.56
[Train] Epoch: 3 [561152/620022]    Loss: 0.009451   Batch Acc: 78.12
[Train] Epoch: 3 [561216/620022]    Loss: 0.009745   Batch Acc: 71.88
[Train] Epoch: 3 [561280/620022]    Loss: 0.008214   Batch Acc: 78.12
[Train] Epoch: 3 [561344/620022]    Loss: 0.007140   Batch Acc: 82.81
[Train] Epoch: 3 [561408/620022]    Loss: 0.006436   Batch Acc: 85.94
[Train] Epoch: 3 [561472/620022]    Loss: 0.007455   Batch Acc: 76.56
[Train] Epoch: 3 [561536/620022]    Loss: 0.007949   Batch Acc: 79.69
[Train] Epoch: 3 [561600/620022]    Loss: 0.007514   Batch Acc: 82.81
[Train] Epoch: 3 [561664/620022]    Loss: 0.005946   Batch Acc: 85.94
[Train] Epoch: 3 [561728/620022]    Loss: 0.009419   Batch Acc: 73.44
[Train] Epoch: 3 [561792/620022]    Loss: 0.008614   Batch Acc: 78.12
[Train] Epoch: 3 [561856/620022]    Loss: 0.009906   Batch Acc: 78.12
[Train] Epoch: 3 [561920/620022]    Loss: 0.008938   Batch Acc: 79.69
[Train] Epoch: 3 [561984/620022]    Loss: 0.008698   Batch Acc: 79.69
[Train] Epoch: 3 [562048/620022]    Loss: 0.006518   Batch Acc: 85.94
[Train] Epoch: 3 [562112/620022]    Loss: 0.007006   Batch Acc: 84.38
[Train] Epoch: 3 [562176/620022]    Loss: 0.009018   Batch Acc: 76.56
[Train] Epoch: 3 [562240/620022]    Loss: 0.008744   Batch Acc: 73.44
[Train] Epoch: 3 [562304/620022]    Loss: 0.010622   Batch Acc: 71.88
[Train] Epoch: 3 [562368/620022]    Loss: 0.009638   Batch Acc: 67.19
[Train] Epoch: 3 [562432/620022]    Loss: 0.009084   Batch Acc: 76.56
[Train] Epoch: 3 [562496/620022]    Loss: 0.010067   Batch Acc: 79.69
[Train] Epoch: 3 [562560/620022]    Loss: 0.007390   Batch Acc: 85.94
[Train] Epoch: 3 [562624/620022]    Loss: 0.008717   Batch Acc: 81.25
[Train] Epoch: 3 [562688/620022]    Loss: 0.005944   Batch Acc: 89.06
[Train] Epoch: 3 [562752/620022]    Loss: 0.007232   Batch Acc: 81.25
[Train] Epoch: 3 [562816/620022]    Loss: 0.006938   Batch Acc: 84.38
[Train] Epoch: 3 [562880/620022]    Loss: 0.008957   Batch Acc: 78.12
[Train] Epoch: 3 [562944/620022]    Loss: 0.006633   Batch Acc: 85.94
[Train] Epoch: 3 [563008/620022]    Loss: 0.009854   Batch Acc: 70.31
[Train] Epoch: 3 [563072/620022]    Loss: 0.008660   Batch Acc: 79.69
[Train] Epoch: 3 [563136/620022]    Loss: 0.010716   Batch Acc: 75.00
[Train] Epoch: 3 [563200/620022]    Loss: 0.007877   Batch Acc: 76.56
[Train] Epoch: 3 [563264/620022]    Loss: 0.010179   Batch Acc: 79.69
[Train] Epoch: 3 [563328/620022]    Loss: 0.006910   Batch Acc: 81.25
[Train] Epoch: 3 [563392/620022]    Loss: 0.006896   Batch Acc: 84.38
[Train] Epoch: 3 [563456/620022]    Loss: 0.007310   Batch Acc: 84.38
[Train] Epoch: 3 [563520/620022]    Loss: 0.009042   Batch Acc: 78.12
[Train] Epoch: 3 [563584/620022]    Loss: 0.009042   Batch Acc: 79.69
[Train] Epoch: 3 [563648/620022]    Loss: 0.007273   Batch Acc: 81.25
[Train] Epoch: 3 [563712/620022]    Loss: 0.010099   Batch Acc: 67.19
[Train] Epoch: 3 [563776/620022]    Loss: 0.008529   Batch Acc: 79.69
[Train] Epoch: 3 [563840/620022]    Loss: 0.006494   Batch Acc: 89.06
[Train] Epoch: 3 [563904/620022]    Loss: 0.008271   Batch Acc: 85.94
[Train] Epoch: 3 [563968/620022]    Loss: 0.006863   Batch Acc: 81.25
[Train] Epoch: 3 [564032/620022]    Loss: 0.010132   Batch Acc: 71.88
[Train] Epoch: 3 [564096/620022]    Loss: 0.008995   Batch Acc: 81.25
[Train] Epoch: 3 [564160/620022]    Loss: 0.007990   Batch Acc: 82.81
[Train] Epoch: 3 [564224/620022]    Loss: 0.009273   Batch Acc: 76.56
[Train] Epoch: 3 [564288/620022]    Loss: 0.007338   Batch Acc: 82.81
[Train] Epoch: 3 [564352/620022]    Loss: 0.010173   Batch Acc: 71.88
[Train] Epoch: 3 [564416/620022]    Loss: 0.007610   Batch Acc: 81.25
[Train] Epoch: 3 [564480/620022]    Loss: 0.009991   Batch Acc: 75.00
[Train] Epoch: 3 [564544/620022]    Loss: 0.010471   Batch Acc: 75.00
[Train] Epoch: 3 [564608/620022]    Loss: 0.007197   Batch Acc: 84.38
[Train] Epoch: 3 [564672/620022]    Loss: 0.007950   Batch Acc: 81.25
[Train] Epoch: 3 [564736/620022]    Loss: 0.006181   Batch Acc: 84.38
[Train] Epoch: 3 [564800/620022]    Loss: 0.007426   Batch Acc: 82.81
[Train] Epoch: 3 [564864/620022]    Loss: 0.010849   Batch Acc: 70.31
[Train] Epoch: 3 [564928/620022]    Loss: 0.008464   Batch Acc: 79.69
[Train] Epoch: 3 [564992/620022]    Loss: 0.009488   Batch Acc: 78.12
[Train] Epoch: 3 [565056/620022]    Loss: 0.007452   Batch Acc: 82.81
[Train] Epoch: 3 [565120/620022]    Loss: 0.009360   Batch Acc: 73.44
[Train] Epoch: 3 [565184/620022]    Loss: 0.012020   Batch Acc: 67.19
[Train] Epoch: 3 [565248/620022]    Loss: 0.006720   Batch Acc: 81.25
[Train] Epoch: 3 [565312/620022]    Loss: 0.010172   Batch Acc: 73.44
[Train] Epoch: 3 [565376/620022]    Loss: 0.010554   Batch Acc: 68.75
[Train] Epoch: 3 [565440/620022]    Loss: 0.006468   Batch Acc: 85.94
[Train] Epoch: 3 [565504/620022]    Loss: 0.009449   Batch Acc: 78.12
[Train] Epoch: 3 [565568/620022]    Loss: 0.009134   Batch Acc: 73.44
[Train] Epoch: 3 [565632/620022]    Loss: 0.007489   Batch Acc: 85.94
[Train] Epoch: 3 [565696/620022]    Loss: 0.008104   Batch Acc: 76.56
[Train] Epoch: 3 [565760/620022]    Loss: 0.009423   Batch Acc: 73.44
[Train] Epoch: 3 [565824/620022]    Loss: 0.009221   Batch Acc: 78.12
[Train] Epoch: 3 [565888/620022]    Loss: 0.007936   Batch Acc: 81.25
[Train] Epoch: 3 [565952/620022]    Loss: 0.008250   Batch Acc: 73.44
[Train] Epoch: 3 [566016/620022]    Loss: 0.007469   Batch Acc: 76.56
[Train] Epoch: 3 [566080/620022]    Loss: 0.007348   Batch Acc: 82.81
[Train] Epoch: 3 [566144/620022]    Loss: 0.007528   Batch Acc: 84.38
[Train] Epoch: 3 [566208/620022]    Loss: 0.006936   Batch Acc: 84.38
[Train] Epoch: 3 [566272/620022]    Loss: 0.007319   Batch Acc: 82.81
[Train] Epoch: 3 [566336/620022]    Loss: 0.009782   Batch Acc: 78.12
[Train] Epoch: 3 [566400/620022]    Loss: 0.007804   Batch Acc: 84.38
[Train] Epoch: 3 [566464/620022]    Loss: 0.008819   Batch Acc: 81.25
[Train] Epoch: 3 [566528/620022]    Loss: 0.007860   Batch Acc: 82.81
[Train] Epoch: 3 [566592/620022]    Loss: 0.006349   Batch Acc: 85.94
[Train] Epoch: 3 [566656/620022]    Loss: 0.008780   Batch Acc: 75.00
[Train] Epoch: 3 [566720/620022]    Loss: 0.007821   Batch Acc: 84.38
[Train] Epoch: 3 [566784/620022]    Loss: 0.007627   Batch Acc: 79.69
[Train] Epoch: 3 [566848/620022]    Loss: 0.008107   Batch Acc: 78.12
[Train] Epoch: 3 [566912/620022]    Loss: 0.007640   Batch Acc: 84.38
[Train] Epoch: 3 [566976/620022]    Loss: 0.008558   Batch Acc: 81.25
[Train] Epoch: 3 [567040/620022]    Loss: 0.009630   Batch Acc: 73.44
[Train] Epoch: 3 [567104/620022]    Loss: 0.007779   Batch Acc: 79.69
[Train] Epoch: 3 [567168/620022]    Loss: 0.008797   Batch Acc: 79.69
[Train] Epoch: 3 [567232/620022]    Loss: 0.008438   Batch Acc: 76.56
[Train] Epoch: 3 [567296/620022]    Loss: 0.009245   Batch Acc: 71.88
[Train] Epoch: 3 [567360/620022]    Loss: 0.005427   Batch Acc: 89.06
[Train] Epoch: 3 [567424/620022]    Loss: 0.011954   Batch Acc: 60.94
[Train] Epoch: 3 [567488/620022]    Loss: 0.007741   Batch Acc: 79.69
[Train] Epoch: 3 [567552/620022]    Loss: 0.005688   Batch Acc: 89.06
[Train] Epoch: 3 [567616/620022]    Loss: 0.008706   Batch Acc: 76.56
[Train] Epoch: 3 [567680/620022]    Loss: 0.008372   Batch Acc: 73.44
[Train] Epoch: 3 [567744/620022]    Loss: 0.005851   Batch Acc: 85.94
[Train] Epoch: 3 [567808/620022]    Loss: 0.006969   Batch Acc: 84.38
[Train] Epoch: 3 [567872/620022]    Loss: 0.009042   Batch Acc: 71.88
[Train] Epoch: 3 [567936/620022]    Loss: 0.007305   Batch Acc: 82.81
[Train] Epoch: 3 [568000/620022]    Loss: 0.009092   Batch Acc: 68.75
[Train] Epoch: 3 [568064/620022]    Loss: 0.009672   Batch Acc: 78.12
[Train] Epoch: 3 [568128/620022]    Loss: 0.008505   Batch Acc: 78.12
[Train] Epoch: 3 [568192/620022]    Loss: 0.009325   Batch Acc: 81.25
[Train] Epoch: 3 [568256/620022]    Loss: 0.008320   Batch Acc: 82.81
[Train] Epoch: 3 [568320/620022]    Loss: 0.008313   Batch Acc: 81.25
[Train] Epoch: 3 [568384/620022]    Loss: 0.007466   Batch Acc: 79.69
[Train] Epoch: 3 [568448/620022]    Loss: 0.010671   Batch Acc: 75.00
[Train] Epoch: 3 [568512/620022]    Loss: 0.007860   Batch Acc: 81.25
[Train] Epoch: 3 [568576/620022]    Loss: 0.007604   Batch Acc: 84.38
[Train] Epoch: 3 [568640/620022]    Loss: 0.009655   Batch Acc: 70.31
[Train] Epoch: 3 [568704/620022]    Loss: 0.005216   Batch Acc: 92.19
[Train] Epoch: 3 [568768/620022]    Loss: 0.007142   Batch Acc: 82.81
[Train] Epoch: 3 [568832/620022]    Loss: 0.008613   Batch Acc: 78.12
[Train] Epoch: 3 [568896/620022]    Loss: 0.009391   Batch Acc: 75.00
[Train] Epoch: 3 [568960/620022]    Loss: 0.008645   Batch Acc: 76.56
[Train] Epoch: 3 [569024/620022]    Loss: 0.008465   Batch Acc: 76.56
[Train] Epoch: 3 [569088/620022]    Loss: 0.009544   Batch Acc: 71.88
[Train] Epoch: 3 [569152/620022]    Loss: 0.010757   Batch Acc: 76.56
[Train] Epoch: 3 [569216/620022]    Loss: 0.009798   Batch Acc: 75.00
[Train] Epoch: 3 [569280/620022]    Loss: 0.009624   Batch Acc: 70.31
[Train] Epoch: 3 [569344/620022]    Loss: 0.007838   Batch Acc: 76.56
[Train] Epoch: 3 [569408/620022]    Loss: 0.006690   Batch Acc: 81.25
[Train] Epoch: 3 [569472/620022]    Loss: 0.007973   Batch Acc: 78.12
[Train] Epoch: 3 [569536/620022]    Loss: 0.009044   Batch Acc: 81.25
[Train] Epoch: 3 [569600/620022]    Loss: 0.009692   Batch Acc: 76.56
[Train] Epoch: 3 [569664/620022]    Loss: 0.009568   Batch Acc: 76.56
[Train] Epoch: 3 [569728/620022]    Loss: 0.008148   Batch Acc: 79.69
[Train] Epoch: 3 [569792/620022]    Loss: 0.008559   Batch Acc: 76.56
[Train] Epoch: 3 [569856/620022]    Loss: 0.008250   Batch Acc: 78.12
[Train] Epoch: 3 [569920/620022]    Loss: 0.008422   Batch Acc: 73.44
[Train] Epoch: 3 [569984/620022]    Loss: 0.007154   Batch Acc: 84.38
[Train] Epoch: 3 [570048/620022]    Loss: 0.008274   Batch Acc: 78.12
[Train] Epoch: 3 [570112/620022]    Loss: 0.009242   Batch Acc: 79.69
[Train] Epoch: 3 [570176/620022]    Loss: 0.010695   Batch Acc: 68.75
[Train] Epoch: 3 [570240/620022]    Loss: 0.007193   Batch Acc: 82.81
[Train] Epoch: 3 [570304/620022]    Loss: 0.010192   Batch Acc: 78.12
[Train] Epoch: 3 [570368/620022]    Loss: 0.007078   Batch Acc: 79.69
[Train] Epoch: 3 [570432/620022]    Loss: 0.008397   Batch Acc: 75.00
[Train] Epoch: 3 [570496/620022]    Loss: 0.010898   Batch Acc: 71.88
[Train] Epoch: 3 [570560/620022]    Loss: 0.009994   Batch Acc: 71.88
[Train] Epoch: 3 [570624/620022]    Loss: 0.007854   Batch Acc: 78.12
[Train] Epoch: 3 [570688/620022]    Loss: 0.010723   Batch Acc: 70.31
[Train] Epoch: 3 [570752/620022]    Loss: 0.007978   Batch Acc: 78.12
[Train] Epoch: 3 [570816/620022]    Loss: 0.008823   Batch Acc: 75.00
[Train] Epoch: 3 [570880/620022]    Loss: 0.010485   Batch Acc: 73.44
[Train] Epoch: 3 [570944/620022]    Loss: 0.007755   Batch Acc: 81.25
[Train] Epoch: 3 [571008/620022]    Loss: 0.008088   Batch Acc: 87.50
[Train] Epoch: 3 [571072/620022]    Loss: 0.006272   Batch Acc: 87.50
[Train] Epoch: 3 [571136/620022]    Loss: 0.006333   Batch Acc: 84.38
[Train] Epoch: 3 [571200/620022]    Loss: 0.010923   Batch Acc: 78.12
[Train] Epoch: 3 [571264/620022]    Loss: 0.008424   Batch Acc: 79.69
[Train] Epoch: 3 [571328/620022]    Loss: 0.008818   Batch Acc: 75.00
[Train] Epoch: 3 [571392/620022]    Loss: 0.009441   Batch Acc: 73.44
[Train] Epoch: 3 [571456/620022]    Loss: 0.008428   Batch Acc: 81.25
[Train] Epoch: 3 [571520/620022]    Loss: 0.006769   Batch Acc: 81.25
[Train] Epoch: 3 [571584/620022]    Loss: 0.008062   Batch Acc: 84.38
[Train] Epoch: 3 [571648/620022]    Loss: 0.008902   Batch Acc: 75.00
[Train] Epoch: 3 [571712/620022]    Loss: 0.009545   Batch Acc: 82.81
[Train] Epoch: 3 [571776/620022]    Loss: 0.009829   Batch Acc: 75.00
[Train] Epoch: 3 [571840/620022]    Loss: 0.010734   Batch Acc: 73.44
[Train] Epoch: 3 [571904/620022]    Loss: 0.008350   Batch Acc: 81.25
[Train] Epoch: 3 [571968/620022]    Loss: 0.009880   Batch Acc: 78.12
[Train] Epoch: 3 [572032/620022]    Loss: 0.007772   Batch Acc: 78.12
[Train] Epoch: 3 [572096/620022]    Loss: 0.007581   Batch Acc: 76.56
[Train] Epoch: 3 [572160/620022]    Loss: 0.007523   Batch Acc: 82.81
[Train] Epoch: 3 [572224/620022]    Loss: 0.007790   Batch Acc: 84.38
[Train] Epoch: 3 [572288/620022]    Loss: 0.007517   Batch Acc: 78.12
[Train] Epoch: 3 [572352/620022]    Loss: 0.007433   Batch Acc: 81.25
[Train] Epoch: 3 [572416/620022]    Loss: 0.009079   Batch Acc: 76.56
[Train] Epoch: 3 [572480/620022]    Loss: 0.009440   Batch Acc: 70.31
[Train] Epoch: 3 [572544/620022]    Loss: 0.009414   Batch Acc: 73.44
[Train] Epoch: 3 [572608/620022]    Loss: 0.008419   Batch Acc: 75.00
[Train] Epoch: 3 [572672/620022]    Loss: 0.010143   Batch Acc: 73.44
[Train] Epoch: 3 [572736/620022]    Loss: 0.009209   Batch Acc: 68.75
[Train] Epoch: 3 [572800/620022]    Loss: 0.010517   Batch Acc: 73.44
[Train] Epoch: 3 [572864/620022]    Loss: 0.010601   Batch Acc: 76.56
[Train] Epoch: 3 [572928/620022]    Loss: 0.008572   Batch Acc: 82.81
[Train] Epoch: 3 [572992/620022]    Loss: 0.008185   Batch Acc: 79.69
[Train] Epoch: 3 [573056/620022]    Loss: 0.007766   Batch Acc: 82.81
[Train] Epoch: 3 [573120/620022]    Loss: 0.009865   Batch Acc: 76.56
[Train] Epoch: 3 [573184/620022]    Loss: 0.006039   Batch Acc: 85.94
[Train] Epoch: 3 [573248/620022]    Loss: 0.009340   Batch Acc: 75.00
[Train] Epoch: 3 [573312/620022]    Loss: 0.010150   Batch Acc: 76.56
[Train] Epoch: 3 [573376/620022]    Loss: 0.009626   Batch Acc: 79.69
[Train] Epoch: 3 [573440/620022]    Loss: 0.009624   Batch Acc: 71.88
[Train] Epoch: 3 [573504/620022]    Loss: 0.009322   Batch Acc: 78.12
[Train] Epoch: 3 [573568/620022]    Loss: 0.006583   Batch Acc: 87.50
[Train] Epoch: 3 [573632/620022]    Loss: 0.009516   Batch Acc: 76.56
[Train] Epoch: 3 [573696/620022]    Loss: 0.009028   Batch Acc: 71.88
[Train] Epoch: 3 [573760/620022]    Loss: 0.009632   Batch Acc: 75.00
[Train] Epoch: 3 [573824/620022]    Loss: 0.006971   Batch Acc: 84.38
[Train] Epoch: 3 [573888/620022]    Loss: 0.010313   Batch Acc: 78.12
[Train] Epoch: 3 [573952/620022]    Loss: 0.010297   Batch Acc: 70.31
[Train] Epoch: 3 [574016/620022]    Loss: 0.009614   Batch Acc: 76.56
[Train] Epoch: 3 [574080/620022]    Loss: 0.008685   Batch Acc: 79.69
[Train] Epoch: 3 [574144/620022]    Loss: 0.010073   Batch Acc: 73.44
[Train] Epoch: 3 [574208/620022]    Loss: 0.008861   Batch Acc: 76.56
[Train] Epoch: 3 [574272/620022]    Loss: 0.007122   Batch Acc: 78.12
[Train] Epoch: 3 [574336/620022]    Loss: 0.011259   Batch Acc: 71.88
[Train] Epoch: 3 [574400/620022]    Loss: 0.009284   Batch Acc: 79.69
[Train] Epoch: 3 [574464/620022]    Loss: 0.008196   Batch Acc: 78.12
[Train] Epoch: 3 [574528/620022]    Loss: 0.008614   Batch Acc: 75.00
[Train] Epoch: 3 [574592/620022]    Loss: 0.007980   Batch Acc: 81.25
[Train] Epoch: 3 [574656/620022]    Loss: 0.009922   Batch Acc: 78.12
[Train] Epoch: 3 [574720/620022]    Loss: 0.008715   Batch Acc: 75.00
[Train] Epoch: 3 [574784/620022]    Loss: 0.007882   Batch Acc: 79.69
[Train] Epoch: 3 [574848/620022]    Loss: 0.008028   Batch Acc: 82.81
[Train] Epoch: 3 [574912/620022]    Loss: 0.008167   Batch Acc: 78.12
[Train] Epoch: 3 [574976/620022]    Loss: 0.008587   Batch Acc: 73.44
[Train] Epoch: 3 [575040/620022]    Loss: 0.008175   Batch Acc: 78.12
[Train] Epoch: 3 [575104/620022]    Loss: 0.007599   Batch Acc: 85.94
[Train] Epoch: 3 [575168/620022]    Loss: 0.010772   Batch Acc: 68.75
[Train] Epoch: 3 [575232/620022]    Loss: 0.008274   Batch Acc: 79.69
[Train] Epoch: 3 [575296/620022]    Loss: 0.007645   Batch Acc: 79.69
[Train] Epoch: 3 [575360/620022]    Loss: 0.007168   Batch Acc: 82.81
[Train] Epoch: 3 [575424/620022]    Loss: 0.009497   Batch Acc: 79.69
[Train] Epoch: 3 [575488/620022]    Loss: 0.009022   Batch Acc: 79.69
[Train] Epoch: 3 [575552/620022]    Loss: 0.009150   Batch Acc: 73.44
[Train] Epoch: 3 [575616/620022]    Loss: 0.009504   Batch Acc: 70.31
[Train] Epoch: 3 [575680/620022]    Loss: 0.007789   Batch Acc: 78.12
[Train] Epoch: 3 [575744/620022]    Loss: 0.007348   Batch Acc: 79.69
[Train] Epoch: 3 [575808/620022]    Loss: 0.007385   Batch Acc: 85.94
[Train] Epoch: 3 [575872/620022]    Loss: 0.007169   Batch Acc: 87.50
[Train] Epoch: 3 [575936/620022]    Loss: 0.009966   Batch Acc: 65.62
[Train] Epoch: 3 [576000/620022]    Loss: 0.006611   Batch Acc: 89.06
[Train] Epoch: 3 [576064/620022]    Loss: 0.010414   Batch Acc: 78.12
[Train] Epoch: 3 [576128/620022]    Loss: 0.010307   Batch Acc: 70.31
[Train] Epoch: 3 [576192/620022]    Loss: 0.007987   Batch Acc: 82.81
[Train] Epoch: 3 [576256/620022]    Loss: 0.009460   Batch Acc: 73.44
[Train] Epoch: 3 [576320/620022]    Loss: 0.009083   Batch Acc: 75.00
[Train] Epoch: 3 [576384/620022]    Loss: 0.007400   Batch Acc: 85.94
[Train] Epoch: 3 [576448/620022]    Loss: 0.007725   Batch Acc: 75.00
[Train] Epoch: 3 [576512/620022]    Loss: 0.008572   Batch Acc: 79.69
[Train] Epoch: 3 [576576/620022]    Loss: 0.008328   Batch Acc: 85.94
[Train] Epoch: 3 [576640/620022]    Loss: 0.010371   Batch Acc: 68.75
[Train] Epoch: 3 [576704/620022]    Loss: 0.007749   Batch Acc: 85.94
[Train] Epoch: 3 [576768/620022]    Loss: 0.009508   Batch Acc: 71.88
[Train] Epoch: 3 [576832/620022]    Loss: 0.006046   Batch Acc: 87.50
[Train] Epoch: 3 [576896/620022]    Loss: 0.008775   Batch Acc: 75.00
[Train] Epoch: 3 [576960/620022]    Loss: 0.011749   Batch Acc: 64.06
[Train] Epoch: 3 [577024/620022]    Loss: 0.010429   Batch Acc: 67.19
[Train] Epoch: 3 [577088/620022]    Loss: 0.007177   Batch Acc: 84.38
[Train] Epoch: 3 [577152/620022]    Loss: 0.010234   Batch Acc: 70.31
[Train] Epoch: 3 [577216/620022]    Loss: 0.008608   Batch Acc: 76.56
[Train] Epoch: 3 [577280/620022]    Loss: 0.007054   Batch Acc: 79.69
[Train] Epoch: 3 [577344/620022]    Loss: 0.009426   Batch Acc: 76.56
[Train] Epoch: 3 [577408/620022]    Loss: 0.009175   Batch Acc: 71.88
[Train] Epoch: 3 [577472/620022]    Loss: 0.008242   Batch Acc: 79.69
[Train] Epoch: 3 [577536/620022]    Loss: 0.009150   Batch Acc: 75.00
[Train] Epoch: 3 [577600/620022]    Loss: 0.007001   Batch Acc: 82.81
[Train] Epoch: 3 [577664/620022]    Loss: 0.007257   Batch Acc: 79.69
[Train] Epoch: 3 [577728/620022]    Loss: 0.009015   Batch Acc: 76.56
[Train] Epoch: 3 [577792/620022]    Loss: 0.007492   Batch Acc: 79.69
[Train] Epoch: 3 [577856/620022]    Loss: 0.008294   Batch Acc: 76.56
[Train] Epoch: 3 [577920/620022]    Loss: 0.008865   Batch Acc: 73.44
[Train] Epoch: 3 [577984/620022]    Loss: 0.008100   Batch Acc: 78.12
[Train] Epoch: 3 [578048/620022]    Loss: 0.009028   Batch Acc: 79.69
[Train] Epoch: 3 [578112/620022]    Loss: 0.008337   Batch Acc: 81.25
[Train] Epoch: 3 [578176/620022]    Loss: 0.008205   Batch Acc: 78.12
[Train] Epoch: 3 [578240/620022]    Loss: 0.005710   Batch Acc: 89.06
[Train] Epoch: 3 [578304/620022]    Loss: 0.009858   Batch Acc: 73.44
[Train] Epoch: 3 [578368/620022]    Loss: 0.007488   Batch Acc: 81.25
[Train] Epoch: 3 [578432/620022]    Loss: 0.010628   Batch Acc: 79.69
[Train] Epoch: 3 [578496/620022]    Loss: 0.007688   Batch Acc: 82.81
[Train] Epoch: 3 [578560/620022]    Loss: 0.011928   Batch Acc: 67.19
[Train] Epoch: 3 [578624/620022]    Loss: 0.007724   Batch Acc: 81.25
[Train] Epoch: 3 [578688/620022]    Loss: 0.008735   Batch Acc: 75.00
[Train] Epoch: 3 [578752/620022]    Loss: 0.010270   Batch Acc: 76.56
[Train] Epoch: 3 [578816/620022]    Loss: 0.007120   Batch Acc: 84.38
[Train] Epoch: 3 [578880/620022]    Loss: 0.007750   Batch Acc: 76.56
[Train] Epoch: 3 [578944/620022]    Loss: 0.008250   Batch Acc: 76.56
[Train] Epoch: 3 [579008/620022]    Loss: 0.010181   Batch Acc: 71.88
[Train] Epoch: 3 [579072/620022]    Loss: 0.006642   Batch Acc: 84.38
[Train] Epoch: 3 [579136/620022]    Loss: 0.010371   Batch Acc: 71.88
[Train] Epoch: 3 [579200/620022]    Loss: 0.008544   Batch Acc: 76.56
[Train] Epoch: 3 [579264/620022]    Loss: 0.009049   Batch Acc: 78.12
[Train] Epoch: 3 [579328/620022]    Loss: 0.008504   Batch Acc: 79.69
[Train] Epoch: 3 [579392/620022]    Loss: 0.011050   Batch Acc: 64.06
[Train] Epoch: 3 [579456/620022]    Loss: 0.008980   Batch Acc: 78.12
[Train] Epoch: 3 [579520/620022]    Loss: 0.008830   Batch Acc: 75.00
[Train] Epoch: 3 [579584/620022]    Loss: 0.007155   Batch Acc: 85.94
[Train] Epoch: 3 [579648/620022]    Loss: 0.006971   Batch Acc: 84.38
[Train] Epoch: 3 [579712/620022]    Loss: 0.007801   Batch Acc: 81.25
[Train] Epoch: 3 [579776/620022]    Loss: 0.010206   Batch Acc: 71.88
[Train] Epoch: 3 [579840/620022]    Loss: 0.009328   Batch Acc: 73.44
[Train] Epoch: 3 [579904/620022]    Loss: 0.008267   Batch Acc: 79.69
[Train] Epoch: 3 [579968/620022]    Loss: 0.008825   Batch Acc: 76.56
[Train] Epoch: 3 [580032/620022]    Loss: 0.006878   Batch Acc: 82.81
[Train] Epoch: 3 [580096/620022]    Loss: 0.006176   Batch Acc: 85.94
[Train] Epoch: 3 [580160/620022]    Loss: 0.005937   Batch Acc: 82.81
[Train] Epoch: 3 [580224/620022]    Loss: 0.010398   Batch Acc: 75.00
[Train] Epoch: 3 [580288/620022]    Loss: 0.008506   Batch Acc: 78.12
[Train] Epoch: 3 [580352/620022]    Loss: 0.010772   Batch Acc: 68.75
[Train] Epoch: 3 [580416/620022]    Loss: 0.008566   Batch Acc: 76.56
[Train] Epoch: 3 [580480/620022]    Loss: 0.008797   Batch Acc: 76.56
[Train] Epoch: 3 [580544/620022]    Loss: 0.005766   Batch Acc: 87.50
[Train] Epoch: 3 [580608/620022]    Loss: 0.009009   Batch Acc: 76.56
[Train] Epoch: 3 [580672/620022]    Loss: 0.012213   Batch Acc: 68.75
[Train] Epoch: 3 [580736/620022]    Loss: 0.009519   Batch Acc: 76.56
[Train] Epoch: 3 [580800/620022]    Loss: 0.008606   Batch Acc: 81.25
[Train] Epoch: 3 [580864/620022]    Loss: 0.007206   Batch Acc: 82.81
[Train] Epoch: 3 [580928/620022]    Loss: 0.007947   Batch Acc: 81.25
[Train] Epoch: 3 [580992/620022]    Loss: 0.007555   Batch Acc: 79.69
[Train] Epoch: 3 [581056/620022]    Loss: 0.007335   Batch Acc: 81.25
[Train] Epoch: 3 [581120/620022]    Loss: 0.007461   Batch Acc: 79.69
[Train] Epoch: 3 [581184/620022]    Loss: 0.010321   Batch Acc: 73.44
[Train] Epoch: 3 [581248/620022]    Loss: 0.008617   Batch Acc: 73.44
[Train] Epoch: 3 [581312/620022]    Loss: 0.007738   Batch Acc: 79.69
[Train] Epoch: 3 [581376/620022]    Loss: 0.008877   Batch Acc: 81.25
[Train] Epoch: 3 [581440/620022]    Loss: 0.008330   Batch Acc: 73.44
[Train] Epoch: 3 [581504/620022]    Loss: 0.008125   Batch Acc: 73.44
[Train] Epoch: 3 [581568/620022]    Loss: 0.007293   Batch Acc: 87.50
[Train] Epoch: 3 [581632/620022]    Loss: 0.008020   Batch Acc: 82.81
[Train] Epoch: 3 [581696/620022]    Loss: 0.009181   Batch Acc: 67.19
[Train] Epoch: 3 [581760/620022]    Loss: 0.007644   Batch Acc: 78.12
[Train] Epoch: 3 [581824/620022]    Loss: 0.007263   Batch Acc: 81.25
[Train] Epoch: 3 [581888/620022]    Loss: 0.011735   Batch Acc: 73.44
[Train] Epoch: 3 [581952/620022]    Loss: 0.007771   Batch Acc: 81.25
[Train] Epoch: 3 [582016/620022]    Loss: 0.009712   Batch Acc: 71.88
[Train] Epoch: 3 [582080/620022]    Loss: 0.007446   Batch Acc: 84.38
[Train] Epoch: 3 [582144/620022]    Loss: 0.009862   Batch Acc: 71.88
[Train] Epoch: 3 [582208/620022]    Loss: 0.008512   Batch Acc: 79.69
[Train] Epoch: 3 [582272/620022]    Loss: 0.006627   Batch Acc: 84.38
[Train] Epoch: 3 [582336/620022]    Loss: 0.009640   Batch Acc: 78.12
[Train] Epoch: 3 [582400/620022]    Loss: 0.008529   Batch Acc: 79.69
[Train] Epoch: 3 [582464/620022]    Loss: 0.007236   Batch Acc: 81.25
[Train] Epoch: 3 [582528/620022]    Loss: 0.007419   Batch Acc: 79.69
[Train] Epoch: 3 [582592/620022]    Loss: 0.007300   Batch Acc: 81.25
[Train] Epoch: 3 [582656/620022]    Loss: 0.007657   Batch Acc: 79.69
[Train] Epoch: 3 [582720/620022]    Loss: 0.009609   Batch Acc: 73.44
[Train] Epoch: 3 [582784/620022]    Loss: 0.009245   Batch Acc: 76.56
[Train] Epoch: 3 [582848/620022]    Loss: 0.008761   Batch Acc: 79.69
[Train] Epoch: 3 [582912/620022]    Loss: 0.008238   Batch Acc: 82.81
[Train] Epoch: 3 [582976/620022]    Loss: 0.007902   Batch Acc: 82.81
[Train] Epoch: 3 [583040/620022]    Loss: 0.007502   Batch Acc: 81.25
[Train] Epoch: 3 [583104/620022]    Loss: 0.009510   Batch Acc: 70.31
[Train] Epoch: 3 [583168/620022]    Loss: 0.008118   Batch Acc: 78.12
[Train] Epoch: 3 [583232/620022]    Loss: 0.007784   Batch Acc: 78.12
[Train] Epoch: 3 [583296/620022]    Loss: 0.010893   Batch Acc: 68.75
[Train] Epoch: 3 [583360/620022]    Loss: 0.009519   Batch Acc: 79.69
[Train] Epoch: 3 [583424/620022]    Loss: 0.008022   Batch Acc: 76.56
[Train] Epoch: 3 [583488/620022]    Loss: 0.010331   Batch Acc: 71.88
[Train] Epoch: 3 [583552/620022]    Loss: 0.006675   Batch Acc: 87.50
[Train] Epoch: 3 [583616/620022]    Loss: 0.006181   Batch Acc: 85.94
[Train] Epoch: 3 [583680/620022]    Loss: 0.011150   Batch Acc: 73.44
[Train] Epoch: 3 [583744/620022]    Loss: 0.007077   Batch Acc: 87.50
[Train] Epoch: 3 [583808/620022]    Loss: 0.007277   Batch Acc: 84.38
[Train] Epoch: 3 [583872/620022]    Loss: 0.009146   Batch Acc: 76.56
[Train] Epoch: 3 [583936/620022]    Loss: 0.008445   Batch Acc: 75.00
[Train] Epoch: 3 [584000/620022]    Loss: 0.010178   Batch Acc: 70.31
[Train] Epoch: 3 [584064/620022]    Loss: 0.008552   Batch Acc: 75.00
[Train] Epoch: 3 [584128/620022]    Loss: 0.008148   Batch Acc: 82.81
[Train] Epoch: 3 [584192/620022]    Loss: 0.010812   Batch Acc: 67.19
[Train] Epoch: 3 [584256/620022]    Loss: 0.007880   Batch Acc: 76.56
[Train] Epoch: 3 [584320/620022]    Loss: 0.009273   Batch Acc: 79.69
[Train] Epoch: 3 [584384/620022]    Loss: 0.007956   Batch Acc: 82.81
[Train] Epoch: 3 [584448/620022]    Loss: 0.010961   Batch Acc: 70.31
[Train] Epoch: 3 [584512/620022]    Loss: 0.009596   Batch Acc: 78.12
[Train] Epoch: 3 [584576/620022]    Loss: 0.008718   Batch Acc: 78.12
[Train] Epoch: 3 [584640/620022]    Loss: 0.010096   Batch Acc: 67.19
[Train] Epoch: 3 [584704/620022]    Loss: 0.007091   Batch Acc: 82.81
[Train] Epoch: 3 [584768/620022]    Loss: 0.008328   Batch Acc: 81.25
[Train] Epoch: 3 [584832/620022]    Loss: 0.008167   Batch Acc: 81.25
[Train] Epoch: 3 [584896/620022]    Loss: 0.007460   Batch Acc: 82.81
[Train] Epoch: 3 [584960/620022]    Loss: 0.008893   Batch Acc: 75.00
[Train] Epoch: 3 [585024/620022]    Loss: 0.010533   Batch Acc: 70.31
[Train] Epoch: 3 [585088/620022]    Loss: 0.008860   Batch Acc: 68.75
[Train] Epoch: 3 [585152/620022]    Loss: 0.009816   Batch Acc: 71.88
[Train] Epoch: 3 [585216/620022]    Loss: 0.006399   Batch Acc: 85.94
[Train] Epoch: 3 [585280/620022]    Loss: 0.008547   Batch Acc: 78.12
[Train] Epoch: 3 [585344/620022]    Loss: 0.009772   Batch Acc: 73.44
[Train] Epoch: 3 [585408/620022]    Loss: 0.008283   Batch Acc: 81.25
[Train] Epoch: 3 [585472/620022]    Loss: 0.006172   Batch Acc: 90.62
[Train] Epoch: 3 [585536/620022]    Loss: 0.010619   Batch Acc: 76.56
[Train] Epoch: 3 [585600/620022]    Loss: 0.008440   Batch Acc: 79.69
[Train] Epoch: 3 [585664/620022]    Loss: 0.009548   Batch Acc: 75.00
[Train] Epoch: 3 [585728/620022]    Loss: 0.007616   Batch Acc: 78.12
[Train] Epoch: 3 [585792/620022]    Loss: 0.008317   Batch Acc: 78.12
[Train] Epoch: 3 [585856/620022]    Loss: 0.008039   Batch Acc: 78.12
[Train] Epoch: 3 [585920/620022]    Loss: 0.007124   Batch Acc: 84.38
[Train] Epoch: 3 [585984/620022]    Loss: 0.007122   Batch Acc: 81.25
[Train] Epoch: 3 [586048/620022]    Loss: 0.008257   Batch Acc: 81.25
[Train] Epoch: 3 [586112/620022]    Loss: 0.008952   Batch Acc: 75.00
[Train] Epoch: 3 [586176/620022]    Loss: 0.010430   Batch Acc: 71.88
[Train] Epoch: 3 [586240/620022]    Loss: 0.008432   Batch Acc: 78.12
[Train] Epoch: 3 [586304/620022]    Loss: 0.010706   Batch Acc: 68.75
[Train] Epoch: 3 [586368/620022]    Loss: 0.010882   Batch Acc: 76.56
[Train] Epoch: 3 [586432/620022]    Loss: 0.008350   Batch Acc: 79.69
[Train] Epoch: 3 [586496/620022]    Loss: 0.007719   Batch Acc: 85.94
[Train] Epoch: 3 [586560/620022]    Loss: 0.007775   Batch Acc: 79.69
[Train] Epoch: 3 [586624/620022]    Loss: 0.008972   Batch Acc: 75.00
[Train] Epoch: 3 [586688/620022]    Loss: 0.009348   Batch Acc: 68.75
[Train] Epoch: 3 [586752/620022]    Loss: 0.009946   Batch Acc: 75.00
[Train] Epoch: 3 [586816/620022]    Loss: 0.006670   Batch Acc: 85.94
[Train] Epoch: 3 [586880/620022]    Loss: 0.011269   Batch Acc: 68.75
[Train] Epoch: 3 [586944/620022]    Loss: 0.008620   Batch Acc: 73.44
[Train] Epoch: 3 [587008/620022]    Loss: 0.008475   Batch Acc: 79.69
[Train] Epoch: 3 [587072/620022]    Loss: 0.007902   Batch Acc: 84.38
[Train] Epoch: 3 [587136/620022]    Loss: 0.008089   Batch Acc: 78.12
[Train] Epoch: 3 [587200/620022]    Loss: 0.005740   Batch Acc: 89.06
[Train] Epoch: 3 [587264/620022]    Loss: 0.006551   Batch Acc: 85.94
[Train] Epoch: 3 [587328/620022]    Loss: 0.011044   Batch Acc: 67.19
[Train] Epoch: 3 [587392/620022]    Loss: 0.007010   Batch Acc: 84.38
[Train] Epoch: 3 [587456/620022]    Loss: 0.010222   Batch Acc: 67.19
[Train] Epoch: 3 [587520/620022]    Loss: 0.007691   Batch Acc: 85.94
[Train] Epoch: 3 [587584/620022]    Loss: 0.008933   Batch Acc: 76.56
[Train] Epoch: 3 [587648/620022]    Loss: 0.007480   Batch Acc: 82.81
[Train] Epoch: 3 [587712/620022]    Loss: 0.010774   Batch Acc: 70.31
[Train] Epoch: 3 [587776/620022]    Loss: 0.006547   Batch Acc: 82.81
[Train] Epoch: 3 [587840/620022]    Loss: 0.009776   Batch Acc: 71.88
[Train] Epoch: 3 [587904/620022]    Loss: 0.006927   Batch Acc: 79.69
[Train] Epoch: 3 [587968/620022]    Loss: 0.009800   Batch Acc: 65.62
[Train] Epoch: 3 [588032/620022]    Loss: 0.010420   Batch Acc: 70.31
[Train] Epoch: 3 [588096/620022]    Loss: 0.007435   Batch Acc: 89.06
[Train] Epoch: 3 [588160/620022]    Loss: 0.007557   Batch Acc: 76.56
[Train] Epoch: 3 [588224/620022]    Loss: 0.007761   Batch Acc: 81.25
[Train] Epoch: 3 [588288/620022]    Loss: 0.009247   Batch Acc: 79.69
[Train] Epoch: 3 [588352/620022]    Loss: 0.008825   Batch Acc: 76.56
[Train] Epoch: 3 [588416/620022]    Loss: 0.007250   Batch Acc: 84.38
[Train] Epoch: 3 [588480/620022]    Loss: 0.006733   Batch Acc: 84.38
[Train] Epoch: 3 [588544/620022]    Loss: 0.008829   Batch Acc: 75.00
[Train] Epoch: 3 [588608/620022]    Loss: 0.009238   Batch Acc: 71.88
[Train] Epoch: 3 [588672/620022]    Loss: 0.008748   Batch Acc: 75.00
[Train] Epoch: 3 [588736/620022]    Loss: 0.009057   Batch Acc: 71.88
[Train] Epoch: 3 [588800/620022]    Loss: 0.009131   Batch Acc: 71.88
[Train] Epoch: 3 [588864/620022]    Loss: 0.009582   Batch Acc: 76.56
[Train] Epoch: 3 [588928/620022]    Loss: 0.009702   Batch Acc: 68.75
[Train] Epoch: 3 [588992/620022]    Loss: 0.007228   Batch Acc: 82.81
[Train] Epoch: 3 [589056/620022]    Loss: 0.010129   Batch Acc: 73.44
[Train] Epoch: 3 [589120/620022]    Loss: 0.008851   Batch Acc: 79.69
[Train] Epoch: 3 [589184/620022]    Loss: 0.008262   Batch Acc: 76.56
[Train] Epoch: 3 [589248/620022]    Loss: 0.009199   Batch Acc: 75.00
[Train] Epoch: 3 [589312/620022]    Loss: 0.009488   Batch Acc: 75.00
[Train] Epoch: 3 [589376/620022]    Loss: 0.009162   Batch Acc: 78.12
[Train] Epoch: 3 [589440/620022]    Loss: 0.007388   Batch Acc: 84.38
[Train] Epoch: 3 [589504/620022]    Loss: 0.009081   Batch Acc: 75.00
[Train] Epoch: 3 [589568/620022]    Loss: 0.009586   Batch Acc: 71.88
[Train] Epoch: 3 [589632/620022]    Loss: 0.007745   Batch Acc: 73.44
[Train] Epoch: 3 [589696/620022]    Loss: 0.007205   Batch Acc: 78.12
[Train] Epoch: 3 [589760/620022]    Loss: 0.010147   Batch Acc: 71.88
[Train] Epoch: 3 [589824/620022]    Loss: 0.008273   Batch Acc: 75.00
[Train] Epoch: 3 [589888/620022]    Loss: 0.008825   Batch Acc: 76.56
[Train] Epoch: 3 [589952/620022]    Loss: 0.008254   Batch Acc: 75.00
[Train] Epoch: 3 [590016/620022]    Loss: 0.009918   Batch Acc: 73.44
[Train] Epoch: 3 [590080/620022]    Loss: 0.008842   Batch Acc: 75.00
[Train] Epoch: 3 [590144/620022]    Loss: 0.007956   Batch Acc: 81.25
[Train] Epoch: 3 [590208/620022]    Loss: 0.010052   Batch Acc: 71.88
[Train] Epoch: 3 [590272/620022]    Loss: 0.008599   Batch Acc: 81.25
[Train] Epoch: 3 [590336/620022]    Loss: 0.010274   Batch Acc: 70.31
[Train] Epoch: 3 [590400/620022]    Loss: 0.008094   Batch Acc: 76.56
[Train] Epoch: 3 [590464/620022]    Loss: 0.009179   Batch Acc: 79.69
[Train] Epoch: 3 [590528/620022]    Loss: 0.009991   Batch Acc: 70.31
[Train] Epoch: 3 [590592/620022]    Loss: 0.008840   Batch Acc: 76.56
[Train] Epoch: 3 [590656/620022]    Loss: 0.006366   Batch Acc: 89.06
[Train] Epoch: 3 [590720/620022]    Loss: 0.010663   Batch Acc: 65.62
[Train] Epoch: 3 [590784/620022]    Loss: 0.007597   Batch Acc: 81.25
[Train] Epoch: 3 [590848/620022]    Loss: 0.008440   Batch Acc: 78.12
[Train] Epoch: 3 [590912/620022]    Loss: 0.008476   Batch Acc: 75.00
[Train] Epoch: 3 [590976/620022]    Loss: 0.007170   Batch Acc: 78.12
[Train] Epoch: 3 [591040/620022]    Loss: 0.010453   Batch Acc: 75.00
[Train] Epoch: 3 [591104/620022]    Loss: 0.009660   Batch Acc: 71.88
[Train] Epoch: 3 [591168/620022]    Loss: 0.010235   Batch Acc: 75.00
[Train] Epoch: 3 [591232/620022]    Loss: 0.010146   Batch Acc: 79.69
[Train] Epoch: 3 [591296/620022]    Loss: 0.008387   Batch Acc: 78.12
[Train] Epoch: 3 [591360/620022]    Loss: 0.011174   Batch Acc: 68.75
[Train] Epoch: 3 [591424/620022]    Loss: 0.007685   Batch Acc: 85.94
[Train] Epoch: 3 [591488/620022]    Loss: 0.010274   Batch Acc: 78.12
[Train] Epoch: 3 [591552/620022]    Loss: 0.008910   Batch Acc: 75.00
[Train] Epoch: 3 [591616/620022]    Loss: 0.007821   Batch Acc: 84.38
[Train] Epoch: 3 [591680/620022]    Loss: 0.005877   Batch Acc: 85.94
[Train] Epoch: 3 [591744/620022]    Loss: 0.007557   Batch Acc: 76.56
[Train] Epoch: 3 [591808/620022]    Loss: 0.010436   Batch Acc: 75.00
[Train] Epoch: 3 [591872/620022]    Loss: 0.009600   Batch Acc: 70.31
[Train] Epoch: 3 [591936/620022]    Loss: 0.008288   Batch Acc: 76.56
[Train] Epoch: 3 [592000/620022]    Loss: 0.011318   Batch Acc: 75.00
[Train] Epoch: 3 [592064/620022]    Loss: 0.007756   Batch Acc: 81.25
[Train] Epoch: 3 [592128/620022]    Loss: 0.008808   Batch Acc: 75.00
[Train] Epoch: 3 [592192/620022]    Loss: 0.008556   Batch Acc: 79.69
[Train] Epoch: 3 [592256/620022]    Loss: 0.008480   Batch Acc: 78.12
[Train] Epoch: 3 [592320/620022]    Loss: 0.009725   Batch Acc: 73.44
[Train] Epoch: 3 [592384/620022]    Loss: 0.009652   Batch Acc: 75.00
[Train] Epoch: 3 [592448/620022]    Loss: 0.006836   Batch Acc: 85.94
[Train] Epoch: 3 [592512/620022]    Loss: 0.009094   Batch Acc: 79.69
[Train] Epoch: 3 [592576/620022]    Loss: 0.006108   Batch Acc: 82.81
[Train] Epoch: 3 [592640/620022]    Loss: 0.007025   Batch Acc: 85.94
[Train] Epoch: 3 [592704/620022]    Loss: 0.007894   Batch Acc: 81.25
[Train] Epoch: 3 [592768/620022]    Loss: 0.007949   Batch Acc: 81.25
[Train] Epoch: 3 [592832/620022]    Loss: 0.008481   Batch Acc: 76.56
[Train] Epoch: 3 [592896/620022]    Loss: 0.012267   Batch Acc: 59.38
[Train] Epoch: 3 [592960/620022]    Loss: 0.006616   Batch Acc: 82.81
[Train] Epoch: 3 [593024/620022]    Loss: 0.011001   Batch Acc: 67.19
[Train] Epoch: 3 [593088/620022]    Loss: 0.006884   Batch Acc: 85.94
[Train] Epoch: 3 [593152/620022]    Loss: 0.007612   Batch Acc: 76.56
[Train] Epoch: 3 [593216/620022]    Loss: 0.010969   Batch Acc: 70.31
[Train] Epoch: 3 [593280/620022]    Loss: 0.011149   Batch Acc: 67.19
[Train] Epoch: 3 [593344/620022]    Loss: 0.009365   Batch Acc: 75.00
[Train] Epoch: 3 [593408/620022]    Loss: 0.007420   Batch Acc: 87.50
[Train] Epoch: 3 [593472/620022]    Loss: 0.009406   Batch Acc: 78.12
[Train] Epoch: 3 [593536/620022]    Loss: 0.009732   Batch Acc: 73.44
[Train] Epoch: 3 [593600/620022]    Loss: 0.007226   Batch Acc: 82.81
[Train] Epoch: 3 [593664/620022]    Loss: 0.006643   Batch Acc: 85.94
[Train] Epoch: 3 [593728/620022]    Loss: 0.007340   Batch Acc: 82.81
[Train] Epoch: 3 [593792/620022]    Loss: 0.010907   Batch Acc: 71.88
[Train] Epoch: 3 [593856/620022]    Loss: 0.008320   Batch Acc: 79.69
[Train] Epoch: 3 [593920/620022]    Loss: 0.006848   Batch Acc: 79.69
[Train] Epoch: 3 [593984/620022]    Loss: 0.008391   Batch Acc: 79.69
[Train] Epoch: 3 [594048/620022]    Loss: 0.008214   Batch Acc: 79.69
[Train] Epoch: 3 [594112/620022]    Loss: 0.009446   Batch Acc: 75.00
[Train] Epoch: 3 [594176/620022]    Loss: 0.009406   Batch Acc: 71.88
[Train] Epoch: 3 [594240/620022]    Loss: 0.009223   Batch Acc: 78.12
[Train] Epoch: 3 [594304/620022]    Loss: 0.007473   Batch Acc: 79.69
[Train] Epoch: 3 [594368/620022]    Loss: 0.007293   Batch Acc: 76.56
[Train] Epoch: 3 [594432/620022]    Loss: 0.008574   Batch Acc: 75.00
[Train] Epoch: 3 [594496/620022]    Loss: 0.007981   Batch Acc: 79.69
[Train] Epoch: 3 [594560/620022]    Loss: 0.010093   Batch Acc: 70.31
[Train] Epoch: 3 [594624/620022]    Loss: 0.009001   Batch Acc: 70.31
[Train] Epoch: 3 [594688/620022]    Loss: 0.009161   Batch Acc: 78.12
[Train] Epoch: 3 [594752/620022]    Loss: 0.008767   Batch Acc: 71.88
[Train] Epoch: 3 [594816/620022]    Loss: 0.008340   Batch Acc: 78.12
[Train] Epoch: 3 [594880/620022]    Loss: 0.007271   Batch Acc: 82.81
[Train] Epoch: 3 [594944/620022]    Loss: 0.009269   Batch Acc: 75.00
[Train] Epoch: 3 [595008/620022]    Loss: 0.008198   Batch Acc: 79.69
[Train] Epoch: 3 [595072/620022]    Loss: 0.010405   Batch Acc: 70.31
[Train] Epoch: 3 [595136/620022]    Loss: 0.008105   Batch Acc: 79.69
[Train] Epoch: 3 [595200/620022]    Loss: 0.009065   Batch Acc: 70.31
[Train] Epoch: 3 [595264/620022]    Loss: 0.009981   Batch Acc: 70.31
[Train] Epoch: 3 [595328/620022]    Loss: 0.008524   Batch Acc: 78.12
[Train] Epoch: 3 [595392/620022]    Loss: 0.005904   Batch Acc: 89.06
[Train] Epoch: 3 [595456/620022]    Loss: 0.009399   Batch Acc: 70.31
[Train] Epoch: 3 [595520/620022]    Loss: 0.008303   Batch Acc: 78.12
[Train] Epoch: 3 [595584/620022]    Loss: 0.010567   Batch Acc: 70.31
[Train] Epoch: 3 [595648/620022]    Loss: 0.009036   Batch Acc: 81.25
[Train] Epoch: 3 [595712/620022]    Loss: 0.007628   Batch Acc: 76.56
[Train] Epoch: 3 [595776/620022]    Loss: 0.007098   Batch Acc: 76.56
[Train] Epoch: 3 [595840/620022]    Loss: 0.007893   Batch Acc: 78.12
[Train] Epoch: 3 [595904/620022]    Loss: 0.007803   Batch Acc: 78.12
[Train] Epoch: 3 [595968/620022]    Loss: 0.010269   Batch Acc: 70.31
[Train] Epoch: 3 [596032/620022]    Loss: 0.006758   Batch Acc: 85.94
[Train] Epoch: 3 [596096/620022]    Loss: 0.008933   Batch Acc: 75.00
[Train] Epoch: 3 [596160/620022]    Loss: 0.008003   Batch Acc: 79.69
[Train] Epoch: 3 [596224/620022]    Loss: 0.007119   Batch Acc: 82.81
[Train] Epoch: 3 [596288/620022]    Loss: 0.007270   Batch Acc: 84.38
[Train] Epoch: 3 [596352/620022]    Loss: 0.009332   Batch Acc: 70.31
[Train] Epoch: 3 [596416/620022]    Loss: 0.010783   Batch Acc: 71.88
[Train] Epoch: 3 [596480/620022]    Loss: 0.008883   Batch Acc: 78.12
[Train] Epoch: 3 [596544/620022]    Loss: 0.008431   Batch Acc: 79.69
[Train] Epoch: 3 [596608/620022]    Loss: 0.010066   Batch Acc: 70.31
[Train] Epoch: 3 [596672/620022]    Loss: 0.007791   Batch Acc: 82.81
[Train] Epoch: 3 [596736/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 3 [596800/620022]    Loss: 0.007253   Batch Acc: 84.38
[Train] Epoch: 3 [596864/620022]    Loss: 0.010158   Batch Acc: 76.56
[Train] Epoch: 3 [596928/620022]    Loss: 0.011496   Batch Acc: 71.88
[Train] Epoch: 3 [596992/620022]    Loss: 0.009467   Batch Acc: 73.44
[Train] Epoch: 3 [597056/620022]    Loss: 0.006597   Batch Acc: 89.06
[Train] Epoch: 3 [597120/620022]    Loss: 0.010160   Batch Acc: 75.00
[Train] Epoch: 3 [597184/620022]    Loss: 0.008769   Batch Acc: 79.69
[Train] Epoch: 3 [597248/620022]    Loss: 0.007341   Batch Acc: 82.81
[Train] Epoch: 3 [597312/620022]    Loss: 0.010450   Batch Acc: 70.31
[Train] Epoch: 3 [597376/620022]    Loss: 0.011119   Batch Acc: 67.19
[Train] Epoch: 3 [597440/620022]    Loss: 0.006610   Batch Acc: 78.12
[Train] Epoch: 3 [597504/620022]    Loss: 0.008648   Batch Acc: 78.12
[Train] Epoch: 3 [597568/620022]    Loss: 0.010187   Batch Acc: 76.56
[Train] Epoch: 3 [597632/620022]    Loss: 0.008610   Batch Acc: 79.69
[Train] Epoch: 3 [597696/620022]    Loss: 0.006841   Batch Acc: 81.25
[Train] Epoch: 3 [597760/620022]    Loss: 0.008655   Batch Acc: 71.88
[Train] Epoch: 3 [597824/620022]    Loss: 0.010366   Batch Acc: 70.31
[Train] Epoch: 3 [597888/620022]    Loss: 0.008900   Batch Acc: 79.69
[Train] Epoch: 3 [597952/620022]    Loss: 0.008695   Batch Acc: 75.00
[Train] Epoch: 3 [598016/620022]    Loss: 0.007037   Batch Acc: 82.81
[Train] Epoch: 3 [598080/620022]    Loss: 0.007018   Batch Acc: 82.81
[Train] Epoch: 3 [598144/620022]    Loss: 0.007924   Batch Acc: 79.69
[Train] Epoch: 3 [598208/620022]    Loss: 0.009268   Batch Acc: 76.56
[Train] Epoch: 3 [598272/620022]    Loss: 0.008477   Batch Acc: 76.56
[Train] Epoch: 3 [598336/620022]    Loss: 0.008440   Batch Acc: 82.81
[Train] Epoch: 3 [598400/620022]    Loss: 0.007537   Batch Acc: 84.38
[Train] Epoch: 3 [598464/620022]    Loss: 0.008661   Batch Acc: 76.56
[Train] Epoch: 3 [598528/620022]    Loss: 0.008805   Batch Acc: 75.00
[Train] Epoch: 3 [598592/620022]    Loss: 0.009024   Batch Acc: 79.69
[Train] Epoch: 3 [598656/620022]    Loss: 0.007310   Batch Acc: 78.12
[Train] Epoch: 3 [598720/620022]    Loss: 0.009051   Batch Acc: 71.88
[Train] Epoch: 3 [598784/620022]    Loss: 0.008755   Batch Acc: 79.69
[Train] Epoch: 3 [598848/620022]    Loss: 0.010051   Batch Acc: 70.31
[Train] Epoch: 3 [598912/620022]    Loss: 0.011257   Batch Acc: 70.31
[Train] Epoch: 3 [598976/620022]    Loss: 0.008988   Batch Acc: 79.69
[Train] Epoch: 3 [599040/620022]    Loss: 0.009417   Batch Acc: 75.00
[Train] Epoch: 3 [599104/620022]    Loss: 0.008620   Batch Acc: 79.69
[Train] Epoch: 3 [599168/620022]    Loss: 0.008728   Batch Acc: 76.56
[Train] Epoch: 3 [599232/620022]    Loss: 0.010572   Batch Acc: 75.00
[Train] Epoch: 3 [599296/620022]    Loss: 0.008490   Batch Acc: 75.00
[Train] Epoch: 3 [599360/620022]    Loss: 0.010087   Batch Acc: 73.44
[Train] Epoch: 3 [599424/620022]    Loss: 0.009168   Batch Acc: 76.56
[Train] Epoch: 3 [599488/620022]    Loss: 0.008686   Batch Acc: 78.12
[Train] Epoch: 3 [599552/620022]    Loss: 0.011372   Batch Acc: 67.19
[Train] Epoch: 3 [599616/620022]    Loss: 0.008937   Batch Acc: 82.81
[Train] Epoch: 3 [599680/620022]    Loss: 0.006349   Batch Acc: 82.81
[Train] Epoch: 3 [599744/620022]    Loss: 0.008780   Batch Acc: 81.25
[Train] Epoch: 3 [599808/620022]    Loss: 0.010104   Batch Acc: 76.56
[Train] Epoch: 3 [599872/620022]    Loss: 0.008464   Batch Acc: 81.25
[Train] Epoch: 3 [599936/620022]    Loss: 0.008114   Batch Acc: 84.38
[Train] Epoch: 3 [600000/620022]    Loss: 0.006526   Batch Acc: 81.25
[Train] Epoch: 3 [600064/620022]    Loss: 0.007809   Batch Acc: 82.81
[Train] Epoch: 3 [600128/620022]    Loss: 0.007925   Batch Acc: 78.12
[Train] Epoch: 3 [600192/620022]    Loss: 0.009776   Batch Acc: 68.75
[Train] Epoch: 3 [600256/620022]    Loss: 0.010035   Batch Acc: 70.31
[Train] Epoch: 3 [600320/620022]    Loss: 0.007160   Batch Acc: 82.81
[Train] Epoch: 3 [600384/620022]    Loss: 0.006832   Batch Acc: 82.81
[Train] Epoch: 3 [600448/620022]    Loss: 0.006067   Batch Acc: 82.81
[Train] Epoch: 3 [600512/620022]    Loss: 0.010420   Batch Acc: 78.12
[Train] Epoch: 3 [600576/620022]    Loss: 0.009263   Batch Acc: 81.25
[Train] Epoch: 3 [600640/620022]    Loss: 0.008528   Batch Acc: 75.00
[Train] Epoch: 3 [600704/620022]    Loss: 0.006846   Batch Acc: 78.12
[Train] Epoch: 3 [600768/620022]    Loss: 0.011905   Batch Acc: 71.88
[Train] Epoch: 3 [600832/620022]    Loss: 0.009889   Batch Acc: 73.44
[Train] Epoch: 3 [600896/620022]    Loss: 0.010124   Batch Acc: 68.75
[Train] Epoch: 3 [600960/620022]    Loss: 0.008141   Batch Acc: 81.25
[Train] Epoch: 3 [601024/620022]    Loss: 0.008356   Batch Acc: 78.12
[Train] Epoch: 3 [601088/620022]    Loss: 0.007441   Batch Acc: 75.00
[Train] Epoch: 3 [601152/620022]    Loss: 0.008503   Batch Acc: 73.44
[Train] Epoch: 3 [601216/620022]    Loss: 0.008421   Batch Acc: 75.00
[Train] Epoch: 3 [601280/620022]    Loss: 0.007853   Batch Acc: 81.25
[Train] Epoch: 3 [601344/620022]    Loss: 0.009144   Batch Acc: 84.38
[Train] Epoch: 3 [601408/620022]    Loss: 0.007728   Batch Acc: 82.81
[Train] Epoch: 3 [601472/620022]    Loss: 0.007260   Batch Acc: 82.81
[Train] Epoch: 3 [601536/620022]    Loss: 0.009012   Batch Acc: 67.19
[Train] Epoch: 3 [601600/620022]    Loss: 0.011818   Batch Acc: 68.75
[Train] Epoch: 3 [601664/620022]    Loss: 0.008495   Batch Acc: 76.56
[Train] Epoch: 3 [601728/620022]    Loss: 0.010479   Batch Acc: 71.88
[Train] Epoch: 3 [601792/620022]    Loss: 0.010390   Batch Acc: 70.31
[Train] Epoch: 3 [601856/620022]    Loss: 0.007863   Batch Acc: 81.25
[Train] Epoch: 3 [601920/620022]    Loss: 0.009387   Batch Acc: 73.44
[Train] Epoch: 3 [601984/620022]    Loss: 0.007264   Batch Acc: 84.38
[Train] Epoch: 3 [602048/620022]    Loss: 0.007141   Batch Acc: 81.25
[Train] Epoch: 3 [602112/620022]    Loss: 0.008468   Batch Acc: 76.56
[Train] Epoch: 3 [602176/620022]    Loss: 0.009276   Batch Acc: 79.69
[Train] Epoch: 3 [602240/620022]    Loss: 0.008329   Batch Acc: 79.69
[Train] Epoch: 3 [602304/620022]    Loss: 0.008065   Batch Acc: 81.25
[Train] Epoch: 3 [602368/620022]    Loss: 0.008158   Batch Acc: 81.25
[Train] Epoch: 3 [602432/620022]    Loss: 0.008723   Batch Acc: 82.81
[Train] Epoch: 3 [602496/620022]    Loss: 0.007868   Batch Acc: 76.56
[Train] Epoch: 3 [602560/620022]    Loss: 0.009742   Batch Acc: 75.00
[Train] Epoch: 3 [602624/620022]    Loss: 0.008149   Batch Acc: 78.12
[Train] Epoch: 3 [602688/620022]    Loss: 0.009318   Batch Acc: 79.69
[Train] Epoch: 3 [602752/620022]    Loss: 0.008107   Batch Acc: 79.69
[Train] Epoch: 3 [602816/620022]    Loss: 0.010250   Batch Acc: 68.75
[Train] Epoch: 3 [602880/620022]    Loss: 0.005434   Batch Acc: 85.94
[Train] Epoch: 3 [602944/620022]    Loss: 0.008925   Batch Acc: 76.56
[Train] Epoch: 3 [603008/620022]    Loss: 0.007908   Batch Acc: 81.25
[Train] Epoch: 3 [603072/620022]    Loss: 0.007619   Batch Acc: 76.56
[Train] Epoch: 3 [603136/620022]    Loss: 0.007736   Batch Acc: 82.81
[Train] Epoch: 3 [603200/620022]    Loss: 0.009665   Batch Acc: 73.44
[Train] Epoch: 3 [603264/620022]    Loss: 0.010046   Batch Acc: 76.56
[Train] Epoch: 3 [603328/620022]    Loss: 0.007481   Batch Acc: 82.81
[Train] Epoch: 3 [603392/620022]    Loss: 0.009856   Batch Acc: 78.12
[Train] Epoch: 3 [603456/620022]    Loss: 0.010120   Batch Acc: 78.12
[Train] Epoch: 3 [603520/620022]    Loss: 0.008821   Batch Acc: 76.56
[Train] Epoch: 3 [603584/620022]    Loss: 0.009866   Batch Acc: 79.69
[Train] Epoch: 3 [603648/620022]    Loss: 0.009215   Batch Acc: 71.88
[Train] Epoch: 3 [603712/620022]    Loss: 0.008726   Batch Acc: 76.56
[Train] Epoch: 3 [603776/620022]    Loss: 0.007528   Batch Acc: 78.12
[Train] Epoch: 3 [603840/620022]    Loss: 0.006637   Batch Acc: 82.81
[Train] Epoch: 3 [603904/620022]    Loss: 0.009965   Batch Acc: 70.31
[Train] Epoch: 3 [603968/620022]    Loss: 0.007748   Batch Acc: 82.81
[Train] Epoch: 3 [604032/620022]    Loss: 0.009740   Batch Acc: 73.44
[Train] Epoch: 3 [604096/620022]    Loss: 0.007765   Batch Acc: 79.69
[Train] Epoch: 3 [604160/620022]    Loss: 0.007222   Batch Acc: 79.69
[Train] Epoch: 3 [604224/620022]    Loss: 0.008636   Batch Acc: 76.56
[Train] Epoch: 3 [604288/620022]    Loss: 0.009679   Batch Acc: 76.56
[Train] Epoch: 3 [604352/620022]    Loss: 0.008167   Batch Acc: 78.12
[Train] Epoch: 3 [604416/620022]    Loss: 0.008921   Batch Acc: 78.12
[Train] Epoch: 3 [604480/620022]    Loss: 0.008493   Batch Acc: 81.25
[Train] Epoch: 3 [604544/620022]    Loss: 0.009517   Batch Acc: 75.00
[Train] Epoch: 3 [604608/620022]    Loss: 0.007411   Batch Acc: 85.94
[Train] Epoch: 3 [604672/620022]    Loss: 0.007391   Batch Acc: 82.81
[Train] Epoch: 3 [604736/620022]    Loss: 0.008651   Batch Acc: 81.25
[Train] Epoch: 3 [604800/620022]    Loss: 0.008521   Batch Acc: 71.88
[Train] Epoch: 3 [604864/620022]    Loss: 0.009609   Batch Acc: 70.31
[Train] Epoch: 3 [604928/620022]    Loss: 0.011660   Batch Acc: 68.75
[Train] Epoch: 3 [604992/620022]    Loss: 0.009632   Batch Acc: 73.44
[Train] Epoch: 3 [605056/620022]    Loss: 0.009916   Batch Acc: 75.00
[Train] Epoch: 3 [605120/620022]    Loss: 0.009607   Batch Acc: 73.44
[Train] Epoch: 3 [605184/620022]    Loss: 0.010834   Batch Acc: 70.31
[Train] Epoch: 3 [605248/620022]    Loss: 0.007690   Batch Acc: 85.94
[Train] Epoch: 3 [605312/620022]    Loss: 0.007516   Batch Acc: 84.38
[Train] Epoch: 3 [605376/620022]    Loss: 0.006897   Batch Acc: 85.94
[Train] Epoch: 3 [605440/620022]    Loss: 0.009173   Batch Acc: 78.12
[Train] Epoch: 3 [605504/620022]    Loss: 0.009499   Batch Acc: 71.88
[Train] Epoch: 3 [605568/620022]    Loss: 0.011173   Batch Acc: 76.56
[Train] Epoch: 3 [605632/620022]    Loss: 0.006262   Batch Acc: 81.25
[Train] Epoch: 3 [605696/620022]    Loss: 0.007803   Batch Acc: 81.25
[Train] Epoch: 3 [605760/620022]    Loss: 0.009925   Batch Acc: 75.00
[Train] Epoch: 3 [605824/620022]    Loss: 0.008837   Batch Acc: 71.88
[Train] Epoch: 3 [605888/620022]    Loss: 0.007504   Batch Acc: 75.00
[Train] Epoch: 3 [605952/620022]    Loss: 0.007029   Batch Acc: 81.25
[Train] Epoch: 3 [606016/620022]    Loss: 0.009006   Batch Acc: 78.12
[Train] Epoch: 3 [606080/620022]    Loss: 0.009119   Batch Acc: 78.12
[Train] Epoch: 3 [606144/620022]    Loss: 0.008075   Batch Acc: 85.94
[Train] Epoch: 3 [606208/620022]    Loss: 0.007641   Batch Acc: 81.25
[Train] Epoch: 3 [606272/620022]    Loss: 0.007873   Batch Acc: 76.56
[Train] Epoch: 3 [606336/620022]    Loss: 0.007080   Batch Acc: 85.94
[Train] Epoch: 3 [606400/620022]    Loss: 0.006822   Batch Acc: 81.25
[Train] Epoch: 3 [606464/620022]    Loss: 0.007834   Batch Acc: 76.56
[Train] Epoch: 3 [606528/620022]    Loss: 0.007661   Batch Acc: 81.25
[Train] Epoch: 3 [606592/620022]    Loss: 0.006867   Batch Acc: 84.38
[Train] Epoch: 3 [606656/620022]    Loss: 0.006406   Batch Acc: 89.06
[Train] Epoch: 3 [606720/620022]    Loss: 0.010903   Batch Acc: 73.44
[Train] Epoch: 3 [606784/620022]    Loss: 0.011829   Batch Acc: 75.00
[Train] Epoch: 3 [606848/620022]    Loss: 0.008060   Batch Acc: 82.81
[Train] Epoch: 3 [606912/620022]    Loss: 0.012252   Batch Acc: 65.62
[Train] Epoch: 3 [606976/620022]    Loss: 0.009944   Batch Acc: 76.56
[Train] Epoch: 3 [607040/620022]    Loss: 0.008754   Batch Acc: 78.12
[Train] Epoch: 3 [607104/620022]    Loss: 0.008870   Batch Acc: 75.00
[Train] Epoch: 3 [607168/620022]    Loss: 0.010190   Batch Acc: 71.88
[Train] Epoch: 3 [607232/620022]    Loss: 0.006855   Batch Acc: 85.94
[Train] Epoch: 3 [607296/620022]    Loss: 0.009622   Batch Acc: 73.44
[Train] Epoch: 3 [607360/620022]    Loss: 0.007399   Batch Acc: 76.56
[Train] Epoch: 3 [607424/620022]    Loss: 0.009192   Batch Acc: 75.00
[Train] Epoch: 3 [607488/620022]    Loss: 0.008518   Batch Acc: 79.69
[Train] Epoch: 3 [607552/620022]    Loss: 0.007609   Batch Acc: 81.25
[Train] Epoch: 3 [607616/620022]    Loss: 0.008940   Batch Acc: 75.00
[Train] Epoch: 3 [607680/620022]    Loss: 0.009648   Batch Acc: 79.69
[Train] Epoch: 3 [607744/620022]    Loss: 0.010537   Batch Acc: 76.56
[Train] Epoch: 3 [607808/620022]    Loss: 0.008971   Batch Acc: 76.56
[Train] Epoch: 3 [607872/620022]    Loss: 0.007254   Batch Acc: 79.69
[Train] Epoch: 3 [607936/620022]    Loss: 0.008132   Batch Acc: 75.00
[Train] Epoch: 3 [608000/620022]    Loss: 0.006418   Batch Acc: 84.38
[Train] Epoch: 3 [608064/620022]    Loss: 0.011819   Batch Acc: 67.19
[Train] Epoch: 3 [608128/620022]    Loss: 0.007761   Batch Acc: 79.69
[Train] Epoch: 3 [608192/620022]    Loss: 0.008082   Batch Acc: 85.94
[Train] Epoch: 3 [608256/620022]    Loss: 0.008369   Batch Acc: 73.44
[Train] Epoch: 3 [608320/620022]    Loss: 0.008057   Batch Acc: 81.25
[Train] Epoch: 3 [608384/620022]    Loss: 0.007426   Batch Acc: 84.38
[Train] Epoch: 3 [608448/620022]    Loss: 0.007979   Batch Acc: 75.00
[Train] Epoch: 3 [608512/620022]    Loss: 0.007152   Batch Acc: 79.69
[Train] Epoch: 3 [608576/620022]    Loss: 0.009568   Batch Acc: 71.88
[Train] Epoch: 3 [608640/620022]    Loss: 0.010386   Batch Acc: 70.31
[Train] Epoch: 3 [608704/620022]    Loss: 0.009706   Batch Acc: 75.00
[Train] Epoch: 3 [608768/620022]    Loss: 0.008989   Batch Acc: 78.12
[Train] Epoch: 3 [608832/620022]    Loss: 0.010599   Batch Acc: 68.75
[Train] Epoch: 3 [608896/620022]    Loss: 0.007741   Batch Acc: 81.25
[Train] Epoch: 3 [608960/620022]    Loss: 0.009408   Batch Acc: 75.00
[Train] Epoch: 3 [609024/620022]    Loss: 0.008508   Batch Acc: 78.12
[Train] Epoch: 3 [609088/620022]    Loss: 0.007163   Batch Acc: 82.81
[Train] Epoch: 3 [609152/620022]    Loss: 0.009406   Batch Acc: 79.69
[Train] Epoch: 3 [609216/620022]    Loss: 0.010898   Batch Acc: 73.44
[Train] Epoch: 3 [609280/620022]    Loss: 0.009024   Batch Acc: 79.69
[Train] Epoch: 3 [609344/620022]    Loss: 0.010130   Batch Acc: 68.75
[Train] Epoch: 3 [609408/620022]    Loss: 0.008220   Batch Acc: 76.56
[Train] Epoch: 3 [609472/620022]    Loss: 0.008800   Batch Acc: 79.69
[Train] Epoch: 3 [609536/620022]    Loss: 0.007924   Batch Acc: 78.12
[Train] Epoch: 3 [609600/620022]    Loss: 0.006271   Batch Acc: 82.81
[Train] Epoch: 3 [609664/620022]    Loss: 0.007671   Batch Acc: 82.81
[Train] Epoch: 3 [609728/620022]    Loss: 0.008178   Batch Acc: 79.69
[Train] Epoch: 3 [609792/620022]    Loss: 0.006712   Batch Acc: 87.50
[Train] Epoch: 3 [609856/620022]    Loss: 0.008481   Batch Acc: 76.56
[Train] Epoch: 3 [609920/620022]    Loss: 0.008431   Batch Acc: 81.25
[Train] Epoch: 3 [609984/620022]    Loss: 0.007981   Batch Acc: 81.25
[Train] Epoch: 3 [610048/620022]    Loss: 0.008634   Batch Acc: 79.69
[Train] Epoch: 3 [610112/620022]    Loss: 0.007598   Batch Acc: 81.25
[Train] Epoch: 3 [610176/620022]    Loss: 0.008518   Batch Acc: 71.88
[Train] Epoch: 3 [610240/620022]    Loss: 0.007645   Batch Acc: 79.69
[Train] Epoch: 3 [610304/620022]    Loss: 0.009064   Batch Acc: 76.56
[Train] Epoch: 3 [610368/620022]    Loss: 0.009934   Batch Acc: 75.00
[Train] Epoch: 3 [610432/620022]    Loss: 0.008654   Batch Acc: 76.56
[Train] Epoch: 3 [610496/620022]    Loss: 0.008076   Batch Acc: 81.25
[Train] Epoch: 3 [610560/620022]    Loss: 0.009631   Batch Acc: 71.88
[Train] Epoch: 3 [610624/620022]    Loss: 0.007877   Batch Acc: 79.69
[Train] Epoch: 3 [610688/620022]    Loss: 0.011828   Batch Acc: 68.75
[Train] Epoch: 3 [610752/620022]    Loss: 0.008155   Batch Acc: 75.00
[Train] Epoch: 3 [610816/620022]    Loss: 0.009607   Batch Acc: 70.31
[Train] Epoch: 3 [610880/620022]    Loss: 0.008173   Batch Acc: 81.25
[Train] Epoch: 3 [610944/620022]    Loss: 0.009325   Batch Acc: 78.12
[Train] Epoch: 3 [611008/620022]    Loss: 0.009914   Batch Acc: 75.00
[Train] Epoch: 3 [611072/620022]    Loss: 0.006258   Batch Acc: 87.50
[Train] Epoch: 3 [611136/620022]    Loss: 0.009346   Batch Acc: 70.31
[Train] Epoch: 3 [611200/620022]    Loss: 0.010427   Batch Acc: 71.88
[Train] Epoch: 3 [611264/620022]    Loss: 0.008701   Batch Acc: 79.69
[Train] Epoch: 3 [611328/620022]    Loss: 0.008934   Batch Acc: 75.00
[Train] Epoch: 3 [611392/620022]    Loss: 0.010671   Batch Acc: 70.31
[Train] Epoch: 3 [611456/620022]    Loss: 0.008065   Batch Acc: 82.81
[Train] Epoch: 3 [611520/620022]    Loss: 0.007429   Batch Acc: 79.69
[Train] Epoch: 3 [611584/620022]    Loss: 0.007210   Batch Acc: 82.81
[Train] Epoch: 3 [611648/620022]    Loss: 0.006573   Batch Acc: 82.81
[Train] Epoch: 3 [611712/620022]    Loss: 0.008351   Batch Acc: 75.00
[Train] Epoch: 3 [611776/620022]    Loss: 0.009625   Batch Acc: 73.44
[Train] Epoch: 3 [611840/620022]    Loss: 0.006793   Batch Acc: 84.38
[Train] Epoch: 3 [611904/620022]    Loss: 0.007697   Batch Acc: 81.25
[Train] Epoch: 3 [611968/620022]    Loss: 0.010641   Batch Acc: 70.31
[Train] Epoch: 3 [612032/620022]    Loss: 0.009598   Batch Acc: 76.56
[Train] Epoch: 3 [612096/620022]    Loss: 0.008580   Batch Acc: 76.56
[Train] Epoch: 3 [612160/620022]    Loss: 0.009672   Batch Acc: 75.00
[Train] Epoch: 3 [612224/620022]    Loss: 0.011249   Batch Acc: 65.62
[Train] Epoch: 3 [612288/620022]    Loss: 0.007450   Batch Acc: 84.38
[Train] Epoch: 3 [612352/620022]    Loss: 0.008201   Batch Acc: 76.56
[Train] Epoch: 3 [612416/620022]    Loss: 0.010903   Batch Acc: 70.31
[Train] Epoch: 3 [612480/620022]    Loss: 0.007855   Batch Acc: 73.44
[Train] Epoch: 3 [612544/620022]    Loss: 0.007122   Batch Acc: 84.38
[Train] Epoch: 3 [612608/620022]    Loss: 0.010360   Batch Acc: 70.31
[Train] Epoch: 3 [612672/620022]    Loss: 0.007015   Batch Acc: 84.38
[Train] Epoch: 3 [612736/620022]    Loss: 0.007323   Batch Acc: 81.25
[Train] Epoch: 3 [612800/620022]    Loss: 0.009684   Batch Acc: 73.44
[Train] Epoch: 3 [612864/620022]    Loss: 0.010366   Batch Acc: 73.44
[Train] Epoch: 3 [612928/620022]    Loss: 0.010337   Batch Acc: 75.00
[Train] Epoch: 3 [612992/620022]    Loss: 0.008096   Batch Acc: 76.56
[Train] Epoch: 3 [613056/620022]    Loss: 0.010041   Batch Acc: 71.88
[Train] Epoch: 3 [613120/620022]    Loss: 0.007682   Batch Acc: 78.12
[Train] Epoch: 3 [613184/620022]    Loss: 0.007997   Batch Acc: 81.25
[Train] Epoch: 3 [613248/620022]    Loss: 0.008346   Batch Acc: 75.00
[Train] Epoch: 3 [613312/620022]    Loss: 0.008745   Batch Acc: 84.38
[Train] Epoch: 3 [613376/620022]    Loss: 0.010405   Batch Acc: 68.75
[Train] Epoch: 3 [613440/620022]    Loss: 0.008427   Batch Acc: 75.00
[Train] Epoch: 3 [613504/620022]    Loss: 0.008319   Batch Acc: 81.25
[Train] Epoch: 3 [613568/620022]    Loss: 0.010035   Batch Acc: 73.44
[Train] Epoch: 3 [613632/620022]    Loss: 0.008883   Batch Acc: 78.12
[Train] Epoch: 3 [613696/620022]    Loss: 0.012196   Batch Acc: 59.38
[Train] Epoch: 3 [613760/620022]    Loss: 0.008392   Batch Acc: 76.56
[Train] Epoch: 3 [613824/620022]    Loss: 0.009229   Batch Acc: 71.88
[Train] Epoch: 3 [613888/620022]    Loss: 0.008034   Batch Acc: 82.81
[Train] Epoch: 3 [613952/620022]    Loss: 0.007669   Batch Acc: 81.25
[Train] Epoch: 3 [614016/620022]    Loss: 0.009935   Batch Acc: 79.69
[Train] Epoch: 3 [614080/620022]    Loss: 0.006786   Batch Acc: 82.81
[Train] Epoch: 3 [614144/620022]    Loss: 0.008907   Batch Acc: 75.00
[Train] Epoch: 3 [614208/620022]    Loss: 0.009202   Batch Acc: 78.12
[Train] Epoch: 3 [614272/620022]    Loss: 0.008330   Batch Acc: 75.00
[Train] Epoch: 3 [614336/620022]    Loss: 0.011454   Batch Acc: 67.19
[Train] Epoch: 3 [614400/620022]    Loss: 0.009067   Batch Acc: 78.12
[Train] Epoch: 3 [614464/620022]    Loss: 0.010177   Batch Acc: 67.19
[Train] Epoch: 3 [614528/620022]    Loss: 0.007089   Batch Acc: 82.81
[Train] Epoch: 3 [614592/620022]    Loss: 0.010073   Batch Acc: 70.31
[Train] Epoch: 3 [614656/620022]    Loss: 0.008954   Batch Acc: 78.12
[Train] Epoch: 3 [614720/620022]    Loss: 0.008551   Batch Acc: 81.25
[Train] Epoch: 3 [614784/620022]    Loss: 0.008604   Batch Acc: 81.25
[Train] Epoch: 3 [614848/620022]    Loss: 0.007255   Batch Acc: 84.38
[Train] Epoch: 3 [614912/620022]    Loss: 0.009270   Batch Acc: 78.12
[Train] Epoch: 3 [614976/620022]    Loss: 0.009148   Batch Acc: 73.44
[Train] Epoch: 3 [615040/620022]    Loss: 0.008791   Batch Acc: 81.25
[Train] Epoch: 3 [615104/620022]    Loss: 0.007528   Batch Acc: 84.38
[Train] Epoch: 3 [615168/620022]    Loss: 0.007771   Batch Acc: 84.38
[Train] Epoch: 3 [615232/620022]    Loss: 0.007824   Batch Acc: 82.81
[Train] Epoch: 3 [615296/620022]    Loss: 0.007920   Batch Acc: 82.81
[Train] Epoch: 3 [615360/620022]    Loss: 0.009195   Batch Acc: 78.12
[Train] Epoch: 3 [615424/620022]    Loss: 0.007487   Batch Acc: 82.81
[Train] Epoch: 3 [615488/620022]    Loss: 0.007324   Batch Acc: 82.81
[Train] Epoch: 3 [615552/620022]    Loss: 0.006918   Batch Acc: 87.50
[Train] Epoch: 3 [615616/620022]    Loss: 0.007076   Batch Acc: 78.12
[Train] Epoch: 3 [615680/620022]    Loss: 0.008279   Batch Acc: 78.12
[Train] Epoch: 3 [615744/620022]    Loss: 0.009928   Batch Acc: 79.69
[Train] Epoch: 3 [615808/620022]    Loss: 0.009421   Batch Acc: 81.25
[Train] Epoch: 3 [615872/620022]    Loss: 0.008249   Batch Acc: 79.69
[Train] Epoch: 3 [615936/620022]    Loss: 0.008796   Batch Acc: 84.38
[Train] Epoch: 3 [616000/620022]    Loss: 0.009864   Batch Acc: 76.56
[Train] Epoch: 3 [616064/620022]    Loss: 0.009773   Batch Acc: 76.56
[Train] Epoch: 3 [616128/620022]    Loss: 0.009016   Batch Acc: 78.12
[Train] Epoch: 3 [616192/620022]    Loss: 0.008209   Batch Acc: 79.69
[Train] Epoch: 3 [616256/620022]    Loss: 0.007970   Batch Acc: 84.38
[Train] Epoch: 3 [616320/620022]    Loss: 0.009785   Batch Acc: 71.88
[Train] Epoch: 3 [616384/620022]    Loss: 0.011303   Batch Acc: 67.19
[Train] Epoch: 3 [616448/620022]    Loss: 0.009775   Batch Acc: 71.88
[Train] Epoch: 3 [616512/620022]    Loss: 0.007559   Batch Acc: 82.81
[Train] Epoch: 3 [616576/620022]    Loss: 0.010220   Batch Acc: 73.44
[Train] Epoch: 3 [616640/620022]    Loss: 0.008672   Batch Acc: 71.88
[Train] Epoch: 3 [616704/620022]    Loss: 0.006599   Batch Acc: 85.94
[Train] Epoch: 3 [616768/620022]    Loss: 0.009564   Batch Acc: 76.56
[Train] Epoch: 3 [616832/620022]    Loss: 0.008327   Batch Acc: 75.00
[Train] Epoch: 3 [616896/620022]    Loss: 0.012257   Batch Acc: 68.75
[Train] Epoch: 3 [616960/620022]    Loss: 0.008163   Batch Acc: 81.25
[Train] Epoch: 3 [617024/620022]    Loss: 0.007191   Batch Acc: 82.81
[Train] Epoch: 3 [617088/620022]    Loss: 0.009861   Batch Acc: 79.69
[Train] Epoch: 3 [617152/620022]    Loss: 0.007774   Batch Acc: 81.25
[Train] Epoch: 3 [617216/620022]    Loss: 0.009124   Batch Acc: 78.12
[Train] Epoch: 3 [617280/620022]    Loss: 0.007199   Batch Acc: 85.94
[Train] Epoch: 3 [617344/620022]    Loss: 0.005841   Batch Acc: 84.38
[Train] Epoch: 3 [617408/620022]    Loss: 0.008477   Batch Acc: 71.88
[Train] Epoch: 3 [617472/620022]    Loss: 0.010102   Batch Acc: 75.00
[Train] Epoch: 3 [617536/620022]    Loss: 0.009133   Batch Acc: 70.31
[Train] Epoch: 3 [617600/620022]    Loss: 0.008375   Batch Acc: 78.12
[Train] Epoch: 3 [617664/620022]    Loss: 0.006173   Batch Acc: 87.50
[Train] Epoch: 3 [617728/620022]    Loss: 0.009521   Batch Acc: 79.69
[Train] Epoch: 3 [617792/620022]    Loss: 0.006685   Batch Acc: 85.94
[Train] Epoch: 3 [617856/620022]    Loss: 0.007634   Batch Acc: 82.81
[Train] Epoch: 3 [617920/620022]    Loss: 0.008096   Batch Acc: 81.25
[Train] Epoch: 3 [617984/620022]    Loss: 0.008802   Batch Acc: 78.12
[Train] Epoch: 3 [618048/620022]    Loss: 0.006564   Batch Acc: 89.06
[Train] Epoch: 3 [618112/620022]    Loss: 0.009759   Batch Acc: 71.88
[Train] Epoch: 3 [618176/620022]    Loss: 0.010823   Batch Acc: 76.56
[Train] Epoch: 3 [618240/620022]    Loss: 0.009668   Batch Acc: 75.00
[Train] Epoch: 3 [618304/620022]    Loss: 0.009145   Batch Acc: 73.44
[Train] Epoch: 3 [618368/620022]    Loss: 0.009438   Batch Acc: 75.00
[Train] Epoch: 3 [618432/620022]    Loss: 0.009388   Batch Acc: 82.81
[Train] Epoch: 3 [618496/620022]    Loss: 0.012100   Batch Acc: 73.44
[Train] Epoch: 3 [618560/620022]    Loss: 0.008511   Batch Acc: 76.56
[Train] Epoch: 3 [618624/620022]    Loss: 0.008028   Batch Acc: 82.81
[Train] Epoch: 3 [618688/620022]    Loss: 0.009189   Batch Acc: 79.69
[Train] Epoch: 3 [618752/620022]    Loss: 0.005825   Batch Acc: 82.81
[Train] Epoch: 3 [618816/620022]    Loss: 0.009045   Batch Acc: 75.00
[Train] Epoch: 3 [618880/620022]    Loss: 0.009533   Batch Acc: 79.69
[Train] Epoch: 3 [618944/620022]    Loss: 0.011048   Batch Acc: 71.88
[Train] Epoch: 3 [619008/620022]    Loss: 0.007936   Batch Acc: 82.81
[Train] Epoch: 3 [619072/620022]    Loss: 0.007657   Batch Acc: 79.69
[Train] Epoch: 3 [619136/620022]    Loss: 0.008886   Batch Acc: 73.44
[Train] Epoch: 3 [619200/620022]    Loss: 0.007891   Batch Acc: 75.00
[Train] Epoch: 3 [619264/620022]    Loss: 0.009580   Batch Acc: 75.00
[Train] Epoch: 3 [619328/620022]    Loss: 0.007970   Batch Acc: 81.25
[Train] Epoch: 3 [619392/620022]    Loss: 0.007030   Batch Acc: 84.38
[Train] Epoch: 3 [619456/620022]    Loss: 0.007967   Batch Acc: 81.25
[Train] Epoch: 3 [619520/620022]    Loss: 0.010712   Batch Acc: 70.31
[Train] Epoch: 3 [619584/620022]    Loss: 0.009454   Batch Acc: 73.44
[Train] Epoch: 3 [619648/620022]    Loss: 0.011602   Batch Acc: 71.88
[Train] Epoch: 3 [619712/620022]    Loss: 0.008358   Batch Acc: 75.00
[Train] Epoch: 3 [619776/620022]    Loss: 0.007651   Batch Acc: 78.12
[Train] Epoch: 3 [619840/620022]    Loss: 0.008973   Batch Acc: 76.56
[Train] Epoch: 3 [619904/620022]    Loss: 0.009997   Batch Acc: 70.31
[Train] Epoch: 3 [619968/620022]    Loss: 0.010199   Batch Acc: 75.00
[Train] Epoch: 3 [523152/620022]    Loss: 0.011539   Batch Acc: 83.33
Validation Done: [64/154214]
Validation Done: [128/154214]
Validation Done: [192/154214]
Validation Done: [256/154214]
Validation Done: [320/154214]
Validation Done: [384/154214]
Validation Done: [448/154214]
Validation Done: [512/154214]
Validation Done: [576/154214]
Validation Done: [640/154214]
Validation Done: [704/154214]
Validation Done: [768/154214]
Validation Done: [832/154214]
Validation Done: [896/154214]
Validation Done: [960/154214]
Validation Done: [1024/154214]
Validation Done: [1088/154214]
Validation Done: [1152/154214]
Validation Done: [1216/154214]
Validation Done: [1280/154214]
Validation Done: [1344/154214]
Validation Done: [1408/154214]
Validation Done: [1472/154214]
Validation Done: [1536/154214]
Validation Done: [1600/154214]
Validation Done: [1664/154214]
Validation Done: [1728/154214]
Validation Done: [1792/154214]
Validation Done: [1856/154214]
Validation Done: [1920/154214]
Validation Done: [1984/154214]
Validation Done: [2048/154214]
Validation Done: [2112/154214]
Validation Done: [2176/154214]
Validation Done: [2240/154214]
Validation Done: [2304/154214]
Validation Done: [2368/154214]
Validation Done: [2432/154214]
Validation Done: [2496/154214]
Validation Done: [2560/154214]
Validation Done: [2624/154214]
Validation Done: [2688/154214]
Validation Done: [2752/154214]
Validation Done: [2816/154214]
Validation Done: [2880/154214]
Validation Done: [2944/154214]
Validation Done: [3008/154214]
Validation Done: [3072/154214]
Validation Done: [3136/154214]
Validation Done: [3200/154214]
Validation Done: [3264/154214]
Validation Done: [3328/154214]
Validation Done: [3392/154214]
Validation Done: [3456/154214]
Validation Done: [3520/154214]
Validation Done: [3584/154214]
Validation Done: [3648/154214]
Validation Done: [3712/154214]
Validation Done: [3776/154214]
Validation Done: [3840/154214]
Validation Done: [3904/154214]
Validation Done: [3968/154214]
Validation Done: [4032/154214]
Validation Done: [4096/154214]
Validation Done: [4160/154214]
Validation Done: [4224/154214]
Validation Done: [4288/154214]
Validation Done: [4352/154214]
Validation Done: [4416/154214]
Validation Done: [4480/154214]
Validation Done: [4544/154214]
Validation Done: [4608/154214]
Validation Done: [4672/154214]
Validation Done: [4736/154214]
Validation Done: [4800/154214]
Validation Done: [4864/154214]
Validation Done: [4928/154214]
Validation Done: [4992/154214]
Validation Done: [5056/154214]
Validation Done: [5120/154214]
Validation Done: [5184/154214]
Validation Done: [5248/154214]
Validation Done: [5312/154214]
Validation Done: [5376/154214]
Validation Done: [5440/154214]
Validation Done: [5504/154214]
Validation Done: [5568/154214]
Validation Done: [5632/154214]
Validation Done: [5696/154214]
Validation Done: [5760/154214]
Validation Done: [5824/154214]
Validation Done: [5888/154214]
Validation Done: [5952/154214]
Validation Done: [6016/154214]
Validation Done: [6080/154214]
Validation Done: [6144/154214]
Validation Done: [6208/154214]
Validation Done: [6272/154214]
Validation Done: [6336/154214]
Validation Done: [6400/154214]
Validation Done: [6464/154214]
Validation Done: [6528/154214]
Validation Done: [6592/154214]
Validation Done: [6656/154214]
Validation Done: [6720/154214]
Validation Done: [6784/154214]
Validation Done: [6848/154214]
Validation Done: [6912/154214]
Validation Done: [6976/154214]
Validation Done: [7040/154214]
Validation Done: [7104/154214]
Validation Done: [7168/154214]
Validation Done: [7232/154214]
Validation Done: [7296/154214]
Validation Done: [7360/154214]
Validation Done: [7424/154214]
Validation Done: [7488/154214]
Validation Done: [7552/154214]
Validation Done: [7616/154214]
Validation Done: [7680/154214]
Validation Done: [7744/154214]
Validation Done: [7808/154214]
Validation Done: [7872/154214]
Validation Done: [7936/154214]
Validation Done: [8000/154214]
Validation Done: [8064/154214]
Validation Done: [8128/154214]
Validation Done: [8192/154214]
Validation Done: [8256/154214]
Validation Done: [8320/154214]
Validation Done: [8384/154214]
Validation Done: [8448/154214]
Validation Done: [8512/154214]
Validation Done: [8576/154214]
Validation Done: [8640/154214]
Validation Done: [8704/154214]
Validation Done: [8768/154214]
Validation Done: [8832/154214]
Validation Done: [8896/154214]
Validation Done: [8960/154214]
Validation Done: [9024/154214]
Validation Done: [9088/154214]
Validation Done: [9152/154214]
Validation Done: [9216/154214]
Validation Done: [9280/154214]
Validation Done: [9344/154214]
Validation Done: [9408/154214]
Validation Done: [9472/154214]
Validation Done: [9536/154214]
Validation Done: [9600/154214]
Validation Done: [9664/154214]
Validation Done: [9728/154214]
Validation Done: [9792/154214]
Validation Done: [9856/154214]
Validation Done: [9920/154214]
Validation Done: [9984/154214]
Validation Done: [10048/154214]
Validation Done: [10112/154214]
Validation Done: [10176/154214]
Validation Done: [10240/154214]
Validation Done: [10304/154214]
Validation Done: [10368/154214]
Validation Done: [10432/154214]
Validation Done: [10496/154214]
Validation Done: [10560/154214]
Validation Done: [10624/154214]
Validation Done: [10688/154214]
Validation Done: [10752/154214]
Validation Done: [10816/154214]
Validation Done: [10880/154214]
Validation Done: [10944/154214]
Validation Done: [11008/154214]
Validation Done: [11072/154214]
Validation Done: [11136/154214]
Validation Done: [11200/154214]
Validation Done: [11264/154214]
Validation Done: [11328/154214]
Validation Done: [11392/154214]
Validation Done: [11456/154214]
Validation Done: [11520/154214]
Validation Done: [11584/154214]
Validation Done: [11648/154214]
Validation Done: [11712/154214]
Validation Done: [11776/154214]
Validation Done: [11840/154214]
Validation Done: [11904/154214]
Validation Done: [11968/154214]
Validation Done: [12032/154214]
Validation Done: [12096/154214]
Validation Done: [12160/154214]
Validation Done: [12224/154214]
Validation Done: [12288/154214]
Validation Done: [12352/154214]
Validation Done: [12416/154214]
Validation Done: [12480/154214]
Validation Done: [12544/154214]
Validation Done: [12608/154214]
Validation Done: [12672/154214]
Validation Done: [12736/154214]
Validation Done: [12800/154214]
Validation Done: [12864/154214]
Validation Done: [12928/154214]
Validation Done: [12992/154214]
Validation Done: [13056/154214]
Validation Done: [13120/154214]
Validation Done: [13184/154214]
Validation Done: [13248/154214]
Validation Done: [13312/154214]
Validation Done: [13376/154214]
Validation Done: [13440/154214]
Validation Done: [13504/154214]
Validation Done: [13568/154214]
Validation Done: [13632/154214]
Validation Done: [13696/154214]
Validation Done: [13760/154214]
Validation Done: [13824/154214]
Validation Done: [13888/154214]
Validation Done: [13952/154214]
Validation Done: [14016/154214]
Validation Done: [14080/154214]
Validation Done: [14144/154214]
Validation Done: [14208/154214]
Validation Done: [14272/154214]
Validation Done: [14336/154214]
Validation Done: [14400/154214]
Validation Done: [14464/154214]
Validation Done: [14528/154214]
Validation Done: [14592/154214]
Validation Done: [14656/154214]
Validation Done: [14720/154214]
Validation Done: [14784/154214]
Validation Done: [14848/154214]
Validation Done: [14912/154214]
Validation Done: [14976/154214]
Validation Done: [15040/154214]
Validation Done: [15104/154214]
Validation Done: [15168/154214]
Validation Done: [15232/154214]
Validation Done: [15296/154214]
Validation Done: [15360/154214]
Validation Done: [15424/154214]
Validation Done: [15488/154214]
Validation Done: [15552/154214]
Validation Done: [15616/154214]
Validation Done: [15680/154214]
Validation Done: [15744/154214]
Validation Done: [15808/154214]
Validation Done: [15872/154214]
Validation Done: [15936/154214]
Validation Done: [16000/154214]
Validation Done: [16064/154214]
Validation Done: [16128/154214]
Validation Done: [16192/154214]
Validation Done: [16256/154214]
Validation Done: [16320/154214]
Validation Done: [16384/154214]
Validation Done: [16448/154214]
Validation Done: [16512/154214]
Validation Done: [16576/154214]
Validation Done: [16640/154214]
Validation Done: [16704/154214]
Validation Done: [16768/154214]
Validation Done: [16832/154214]
Validation Done: [16896/154214]
Validation Done: [16960/154214]
Validation Done: [17024/154214]
Validation Done: [17088/154214]
Validation Done: [17152/154214]
Validation Done: [17216/154214]
Validation Done: [17280/154214]
Validation Done: [17344/154214]
Validation Done: [17408/154214]
Validation Done: [17472/154214]
Validation Done: [17536/154214]
Validation Done: [17600/154214]
Validation Done: [17664/154214]
Validation Done: [17728/154214]
Validation Done: [17792/154214]
Validation Done: [17856/154214]
Validation Done: [17920/154214]
Validation Done: [17984/154214]
Validation Done: [18048/154214]
Validation Done: [18112/154214]
Validation Done: [18176/154214]
Validation Done: [18240/154214]
Validation Done: [18304/154214]
Validation Done: [18368/154214]
Validation Done: [18432/154214]
Validation Done: [18496/154214]
Validation Done: [18560/154214]
Validation Done: [18624/154214]
Validation Done: [18688/154214]
Validation Done: [18752/154214]
Validation Done: [18816/154214]
Validation Done: [18880/154214]
Validation Done: [18944/154214]
Validation Done: [19008/154214]
Validation Done: [19072/154214]
Validation Done: [19136/154214]
Validation Done: [19200/154214]
Validation Done: [19264/154214]
Validation Done: [19328/154214]
Validation Done: [19392/154214]
Validation Done: [19456/154214]
Validation Done: [19520/154214]
Validation Done: [19584/154214]
Validation Done: [19648/154214]
Validation Done: [19712/154214]
Validation Done: [19776/154214]
Validation Done: [19840/154214]
Validation Done: [19904/154214]
Validation Done: [19968/154214]
Validation Done: [20032/154214]
Validation Done: [20096/154214]
Validation Done: [20160/154214]
Validation Done: [20224/154214]
Validation Done: [20288/154214]
Validation Done: [20352/154214]
Validation Done: [20416/154214]
Validation Done: [20480/154214]
Validation Done: [20544/154214]
Validation Done: [20608/154214]
Validation Done: [20672/154214]
Validation Done: [20736/154214]
Validation Done: [20800/154214]
Validation Done: [20864/154214]
Validation Done: [20928/154214]
Validation Done: [20992/154214]
Validation Done: [21056/154214]
Validation Done: [21120/154214]
Validation Done: [21184/154214]
Validation Done: [21248/154214]
Validation Done: [21312/154214]
Validation Done: [21376/154214]
Validation Done: [21440/154214]
Validation Done: [21504/154214]
Validation Done: [21568/154214]
Validation Done: [21632/154214]
Validation Done: [21696/154214]
Validation Done: [21760/154214]
Validation Done: [21824/154214]
Validation Done: [21888/154214]
Validation Done: [21952/154214]
Validation Done: [22016/154214]
Validation Done: [22080/154214]
Validation Done: [22144/154214]
Validation Done: [22208/154214]
Validation Done: [22272/154214]
Validation Done: [22336/154214]
Validation Done: [22400/154214]
Validation Done: [22464/154214]
Validation Done: [22528/154214]
Validation Done: [22592/154214]
Validation Done: [22656/154214]
Validation Done: [22720/154214]
Validation Done: [22784/154214]
Validation Done: [22848/154214]
Validation Done: [22912/154214]
Validation Done: [22976/154214]
Validation Done: [23040/154214]
Validation Done: [23104/154214]
Validation Done: [23168/154214]
Validation Done: [23232/154214]
Validation Done: [23296/154214]
Validation Done: [23360/154214]
Validation Done: [23424/154214]
Validation Done: [23488/154214]
Validation Done: [23552/154214]
Validation Done: [23616/154214]
Validation Done: [23680/154214]
Validation Done: [23744/154214]
Validation Done: [23808/154214]
Validation Done: [23872/154214]
Validation Done: [23936/154214]
Validation Done: [24000/154214]
Validation Done: [24064/154214]
Validation Done: [24128/154214]
Validation Done: [24192/154214]
Validation Done: [24256/154214]
Validation Done: [24320/154214]
Validation Done: [24384/154214]
Validation Done: [24448/154214]
Validation Done: [24512/154214]
Validation Done: [24576/154214]
Validation Done: [24640/154214]
Validation Done: [24704/154214]
Validation Done: [24768/154214]
Validation Done: [24832/154214]
Validation Done: [24896/154214]
Validation Done: [24960/154214]
Validation Done: [25024/154214]
Validation Done: [25088/154214]
Validation Done: [25152/154214]
Validation Done: [25216/154214]
Validation Done: [25280/154214]
Validation Done: [25344/154214]
Validation Done: [25408/154214]
Validation Done: [25472/154214]
Validation Done: [25536/154214]
Validation Done: [25600/154214]
Validation Done: [25664/154214]
Validation Done: [25728/154214]
Validation Done: [25792/154214]
Validation Done: [25856/154214]
Validation Done: [25920/154214]
Validation Done: [25984/154214]
Validation Done: [26048/154214]
Validation Done: [26112/154214]
Validation Done: [26176/154214]
Validation Done: [26240/154214]
Validation Done: [26304/154214]
Validation Done: [26368/154214]
Validation Done: [26432/154214]
Validation Done: [26496/154214]
Validation Done: [26560/154214]
Validation Done: [26624/154214]
Validation Done: [26688/154214]
Validation Done: [26752/154214]
Validation Done: [26816/154214]
Validation Done: [26880/154214]
Validation Done: [26944/154214]
Validation Done: [27008/154214]
Validation Done: [27072/154214]
Validation Done: [27136/154214]
Validation Done: [27200/154214]
Validation Done: [27264/154214]
Validation Done: [27328/154214]
Validation Done: [27392/154214]
Validation Done: [27456/154214]
Validation Done: [27520/154214]
Validation Done: [27584/154214]
Validation Done: [27648/154214]
Validation Done: [27712/154214]
Validation Done: [27776/154214]
Validation Done: [27840/154214]
Validation Done: [27904/154214]
Validation Done: [27968/154214]
Validation Done: [28032/154214]
Validation Done: [28096/154214]
Validation Done: [28160/154214]
Validation Done: [28224/154214]
Validation Done: [28288/154214]
Validation Done: [28352/154214]
Validation Done: [28416/154214]
Validation Done: [28480/154214]
Validation Done: [28544/154214]
Validation Done: [28608/154214]
Validation Done: [28672/154214]
Validation Done: [28736/154214]
Validation Done: [28800/154214]
Validation Done: [28864/154214]
Validation Done: [28928/154214]
Validation Done: [28992/154214]
Validation Done: [29056/154214]
Validation Done: [29120/154214]
Validation Done: [29184/154214]
Validation Done: [29248/154214]
Validation Done: [29312/154214]
Validation Done: [29376/154214]
Validation Done: [29440/154214]
Validation Done: [29504/154214]
Validation Done: [29568/154214]
Validation Done: [29632/154214]
Validation Done: [29696/154214]
Validation Done: [29760/154214]
Validation Done: [29824/154214]
Validation Done: [29888/154214]
Validation Done: [29952/154214]
Validation Done: [30016/154214]
Validation Done: [30080/154214]
Validation Done: [30144/154214]
Validation Done: [30208/154214]
Validation Done: [30272/154214]
Validation Done: [30336/154214]
Validation Done: [30400/154214]
Validation Done: [30464/154214]
Validation Done: [30528/154214]
Validation Done: [30592/154214]
Validation Done: [30656/154214]
Validation Done: [30720/154214]
Validation Done: [30784/154214]
Validation Done: [30848/154214]
Validation Done: [30912/154214]
Validation Done: [30976/154214]
Validation Done: [31040/154214]
Validation Done: [31104/154214]
Validation Done: [31168/154214]
Validation Done: [31232/154214]
Validation Done: [31296/154214]
Validation Done: [31360/154214]
Validation Done: [31424/154214]
Validation Done: [31488/154214]
Validation Done: [31552/154214]
Validation Done: [31616/154214]
Validation Done: [31680/154214]
Validation Done: [31744/154214]
Validation Done: [31808/154214]
Validation Done: [31872/154214]
Validation Done: [31936/154214]
Validation Done: [32000/154214]
Validation Done: [32064/154214]
Validation Done: [32128/154214]
Validation Done: [32192/154214]
Validation Done: [32256/154214]
Validation Done: [32320/154214]
Validation Done: [32384/154214]
Validation Done: [32448/154214]
Validation Done: [32512/154214]
Validation Done: [32576/154214]
Validation Done: [32640/154214]
Validation Done: [32704/154214]
Validation Done: [32768/154214]
Validation Done: [32832/154214]
Validation Done: [32896/154214]
Validation Done: [32960/154214]
Validation Done: [33024/154214]
Validation Done: [33088/154214]
Validation Done: [33152/154214]
Validation Done: [33216/154214]
Validation Done: [33280/154214]
Validation Done: [33344/154214]
Validation Done: [33408/154214]
Validation Done: [33472/154214]
Validation Done: [33536/154214]
Validation Done: [33600/154214]
Validation Done: [33664/154214]
Validation Done: [33728/154214]
Validation Done: [33792/154214]
Validation Done: [33856/154214]
Validation Done: [33920/154214]
Validation Done: [33984/154214]
Validation Done: [34048/154214]
Validation Done: [34112/154214]
Validation Done: [34176/154214]
Validation Done: [34240/154214]
Validation Done: [34304/154214]
Validation Done: [34368/154214]
Validation Done: [34432/154214]
Validation Done: [34496/154214]
Validation Done: [34560/154214]
Validation Done: [34624/154214]
Validation Done: [34688/154214]
Validation Done: [34752/154214]
Validation Done: [34816/154214]
Validation Done: [34880/154214]
Validation Done: [34944/154214]
Validation Done: [35008/154214]
Validation Done: [35072/154214]
Validation Done: [35136/154214]
Validation Done: [35200/154214]
Validation Done: [35264/154214]
Validation Done: [35328/154214]
Validation Done: [35392/154214]
Validation Done: [35456/154214]
Validation Done: [35520/154214]
Validation Done: [35584/154214]
Validation Done: [35648/154214]
Validation Done: [35712/154214]
Validation Done: [35776/154214]
Validation Done: [35840/154214]
Validation Done: [35904/154214]
Validation Done: [35968/154214]
Validation Done: [36032/154214]
Validation Done: [36096/154214]
Validation Done: [36160/154214]
Validation Done: [36224/154214]
Validation Done: [36288/154214]
Validation Done: [36352/154214]
Validation Done: [36416/154214]
Validation Done: [36480/154214]
Validation Done: [36544/154214]
Validation Done: [36608/154214]
Validation Done: [36672/154214]
Validation Done: [36736/154214]
Validation Done: [36800/154214]
Validation Done: [36864/154214]
Validation Done: [36928/154214]
Validation Done: [36992/154214]
Validation Done: [37056/154214]
Validation Done: [37120/154214]
Validation Done: [37184/154214]
Validation Done: [37248/154214]
Validation Done: [37312/154214]
Validation Done: [37376/154214]
Validation Done: [37440/154214]
Validation Done: [37504/154214]
Validation Done: [37568/154214]
Validation Done: [37632/154214]
Validation Done: [37696/154214]
Validation Done: [37760/154214]
Validation Done: [37824/154214]
Validation Done: [37888/154214]
Validation Done: [37952/154214]
Validation Done: [38016/154214]
Validation Done: [38080/154214]
Validation Done: [38144/154214]
Validation Done: [38208/154214]
Validation Done: [38272/154214]
Validation Done: [38336/154214]
Validation Done: [38400/154214]
Validation Done: [38464/154214]
Validation Done: [38528/154214]
Validation Done: [38592/154214]
Validation Done: [38656/154214]
Validation Done: [38720/154214]
Validation Done: [38784/154214]
Validation Done: [38848/154214]
Validation Done: [38912/154214]
Validation Done: [38976/154214]
Validation Done: [39040/154214]
Validation Done: [39104/154214]
Validation Done: [39168/154214]
Validation Done: [39232/154214]
Validation Done: [39296/154214]
Validation Done: [39360/154214]
Validation Done: [39424/154214]
Validation Done: [39488/154214]
Validation Done: [39552/154214]
Validation Done: [39616/154214]
Validation Done: [39680/154214]
Validation Done: [39744/154214]
Validation Done: [39808/154214]
Validation Done: [39872/154214]
Validation Done: [39936/154214]
Validation Done: [40000/154214]
Validation Done: [40064/154214]
Validation Done: [40128/154214]
Validation Done: [40192/154214]
Validation Done: [40256/154214]
Validation Done: [40320/154214]
Validation Done: [40384/154214]
Validation Done: [40448/154214]
Validation Done: [40512/154214]
Validation Done: [40576/154214]
Validation Done: [40640/154214]
Validation Done: [40704/154214]
Validation Done: [40768/154214]
Validation Done: [40832/154214]
Validation Done: [40896/154214]
Validation Done: [40960/154214]
Validation Done: [41024/154214]
Validation Done: [41088/154214]
Validation Done: [41152/154214]
Validation Done: [41216/154214]
Validation Done: [41280/154214]
Validation Done: [41344/154214]
Validation Done: [41408/154214]
Validation Done: [41472/154214]
Validation Done: [41536/154214]
Validation Done: [41600/154214]
Validation Done: [41664/154214]
Validation Done: [41728/154214]
Validation Done: [41792/154214]
Validation Done: [41856/154214]
Validation Done: [41920/154214]
Validation Done: [41984/154214]
Validation Done: [42048/154214]
Validation Done: [42112/154214]
Validation Done: [42176/154214]
Validation Done: [42240/154214]
Validation Done: [42304/154214]
Validation Done: [42368/154214]
Validation Done: [42432/154214]
Validation Done: [42496/154214]
Validation Done: [42560/154214]
Validation Done: [42624/154214]
Validation Done: [42688/154214]
Validation Done: [42752/154214]
Validation Done: [42816/154214]
Validation Done: [42880/154214]
Validation Done: [42944/154214]
Validation Done: [43008/154214]
Validation Done: [43072/154214]
Validation Done: [43136/154214]
Validation Done: [43200/154214]
Validation Done: [43264/154214]
Validation Done: [43328/154214]
Validation Done: [43392/154214]
Validation Done: [43456/154214]
Validation Done: [43520/154214]
Validation Done: [43584/154214]
Validation Done: [43648/154214]
Validation Done: [43712/154214]
Validation Done: [43776/154214]
Validation Done: [43840/154214]
Validation Done: [43904/154214]
Validation Done: [43968/154214]
Validation Done: [44032/154214]
Validation Done: [44096/154214]
Validation Done: [44160/154214]
Validation Done: [44224/154214]
Validation Done: [44288/154214]
Validation Done: [44352/154214]
Validation Done: [44416/154214]
Validation Done: [44480/154214]
Validation Done: [44544/154214]
Validation Done: [44608/154214]
Validation Done: [44672/154214]
Validation Done: [44736/154214]
Validation Done: [44800/154214]
Validation Done: [44864/154214]
Validation Done: [44928/154214]
Validation Done: [44992/154214]
Validation Done: [45056/154214]
Validation Done: [45120/154214]
Validation Done: [45184/154214]
Validation Done: [45248/154214]
Validation Done: [45312/154214]
Validation Done: [45376/154214]
Validation Done: [45440/154214]
Validation Done: [45504/154214]
Validation Done: [45568/154214]
Validation Done: [45632/154214]
Validation Done: [45696/154214]
Validation Done: [45760/154214]
Validation Done: [45824/154214]
Validation Done: [45888/154214]
Validation Done: [45952/154214]
Validation Done: [46016/154214]
Validation Done: [46080/154214]
Validation Done: [46144/154214]
Validation Done: [46208/154214]
Validation Done: [46272/154214]
Validation Done: [46336/154214]
Validation Done: [46400/154214]
Validation Done: [46464/154214]
Validation Done: [46528/154214]
Validation Done: [46592/154214]
Validation Done: [46656/154214]
Validation Done: [46720/154214]
Validation Done: [46784/154214]
Validation Done: [46848/154214]
Validation Done: [46912/154214]
Validation Done: [46976/154214]
Validation Done: [47040/154214]
Validation Done: [47104/154214]
Validation Done: [47168/154214]
Validation Done: [47232/154214]
Validation Done: [47296/154214]
Validation Done: [47360/154214]
Validation Done: [47424/154214]
Validation Done: [47488/154214]
Validation Done: [47552/154214]
Validation Done: [47616/154214]
Validation Done: [47680/154214]
Validation Done: [47744/154214]
Validation Done: [47808/154214]
Validation Done: [47872/154214]
Validation Done: [47936/154214]
Validation Done: [48000/154214]
Validation Done: [48064/154214]
Validation Done: [48128/154214]
Validation Done: [48192/154214]
Validation Done: [48256/154214]
Validation Done: [48320/154214]
Validation Done: [48384/154214]
Validation Done: [48448/154214]
Validation Done: [48512/154214]
Validation Done: [48576/154214]
Validation Done: [48640/154214]
Validation Done: [48704/154214]
Validation Done: [48768/154214]
Validation Done: [48832/154214]
Validation Done: [48896/154214]
Validation Done: [48960/154214]
Validation Done: [49024/154214]
Validation Done: [49088/154214]
Validation Done: [49152/154214]
Validation Done: [49216/154214]
Validation Done: [49280/154214]
Validation Done: [49344/154214]
Validation Done: [49408/154214]
Validation Done: [49472/154214]
Validation Done: [49536/154214]
Validation Done: [49600/154214]
Validation Done: [49664/154214]
Validation Done: [49728/154214]
Validation Done: [49792/154214]
Validation Done: [49856/154214]
Validation Done: [49920/154214]
Validation Done: [49984/154214]
Validation Done: [50048/154214]
Validation Done: [50112/154214]
Validation Done: [50176/154214]
Validation Done: [50240/154214]
Validation Done: [50304/154214]
Validation Done: [50368/154214]
Validation Done: [50432/154214]
Validation Done: [50496/154214]
Validation Done: [50560/154214]
Validation Done: [50624/154214]
Validation Done: [50688/154214]
Validation Done: [50752/154214]
Validation Done: [50816/154214]
Validation Done: [50880/154214]
Validation Done: [50944/154214]
Validation Done: [51008/154214]
Validation Done: [51072/154214]
Validation Done: [51136/154214]
Validation Done: [51200/154214]
Validation Done: [51264/154214]
Validation Done: [51328/154214]
Validation Done: [51392/154214]
Validation Done: [51456/154214]
Validation Done: [51520/154214]
Validation Done: [51584/154214]
Validation Done: [51648/154214]
Validation Done: [51712/154214]
Validation Done: [51776/154214]
Validation Done: [51840/154214]
Validation Done: [51904/154214]
Validation Done: [51968/154214]
Validation Done: [52032/154214]
Validation Done: [52096/154214]
Validation Done: [52160/154214]
Validation Done: [52224/154214]
Validation Done: [52288/154214]
Validation Done: [52352/154214]
Validation Done: [52416/154214]
Validation Done: [52480/154214]
Validation Done: [52544/154214]
Validation Done: [52608/154214]
Validation Done: [52672/154214]
Validation Done: [52736/154214]
Validation Done: [52800/154214]
Validation Done: [52864/154214]
Validation Done: [52928/154214]
Validation Done: [52992/154214]
Validation Done: [53056/154214]
Validation Done: [53120/154214]
Validation Done: [53184/154214]
Validation Done: [53248/154214]
Validation Done: [53312/154214]
Validation Done: [53376/154214]
Validation Done: [53440/154214]
Validation Done: [53504/154214]
Validation Done: [53568/154214]
Validation Done: [53632/154214]
Validation Done: [53696/154214]
Validation Done: [53760/154214]
Validation Done: [53824/154214]
Validation Done: [53888/154214]
Validation Done: [53952/154214]
Validation Done: [54016/154214]
Validation Done: [54080/154214]
Validation Done: [54144/154214]
Validation Done: [54208/154214]
Validation Done: [54272/154214]
Validation Done: [54336/154214]
Validation Done: [54400/154214]
Validation Done: [54464/154214]
Validation Done: [54528/154214]
Validation Done: [54592/154214]
Validation Done: [54656/154214]
Validation Done: [54720/154214]
Validation Done: [54784/154214]
Validation Done: [54848/154214]
Validation Done: [54912/154214]
Validation Done: [54976/154214]
Validation Done: [55040/154214]
Validation Done: [55104/154214]
Validation Done: [55168/154214]
Validation Done: [55232/154214]
Validation Done: [55296/154214]
Validation Done: [55360/154214]
Validation Done: [55424/154214]
Validation Done: [55488/154214]
Validation Done: [55552/154214]
Validation Done: [55616/154214]
Validation Done: [55680/154214]
Validation Done: [55744/154214]
Validation Done: [55808/154214]
Validation Done: [55872/154214]
Validation Done: [55936/154214]
Validation Done: [56000/154214]
Validation Done: [56064/154214]
Validation Done: [56128/154214]
Validation Done: [56192/154214]
Validation Done: [56256/154214]
Validation Done: [56320/154214]
Validation Done: [56384/154214]
Validation Done: [56448/154214]
Validation Done: [56512/154214]
Validation Done: [56576/154214]
Validation Done: [56640/154214]
Validation Done: [56704/154214]
Validation Done: [56768/154214]
Validation Done: [56832/154214]
Validation Done: [56896/154214]
Validation Done: [56960/154214]
Validation Done: [57024/154214]
Validation Done: [57088/154214]
Validation Done: [57152/154214]
Validation Done: [57216/154214]
Validation Done: [57280/154214]
Validation Done: [57344/154214]
Validation Done: [57408/154214]
Validation Done: [57472/154214]
Validation Done: [57536/154214]
Validation Done: [57600/154214]
Validation Done: [57664/154214]
Validation Done: [57728/154214]
Validation Done: [57792/154214]
Validation Done: [57856/154214]
Validation Done: [57920/154214]
Validation Done: [57984/154214]
Validation Done: [58048/154214]
Validation Done: [58112/154214]
Validation Done: [58176/154214]
Validation Done: [58240/154214]
Validation Done: [58304/154214]
Validation Done: [58368/154214]
Validation Done: [58432/154214]
Validation Done: [58496/154214]
Validation Done: [58560/154214]
Validation Done: [58624/154214]
Validation Done: [58688/154214]
Validation Done: [58752/154214]
Validation Done: [58816/154214]
Validation Done: [58880/154214]
Validation Done: [58944/154214]
Validation Done: [59008/154214]
Validation Done: [59072/154214]
Validation Done: [59136/154214]
Validation Done: [59200/154214]
Validation Done: [59264/154214]
Validation Done: [59328/154214]
Validation Done: [59392/154214]
Validation Done: [59456/154214]
Validation Done: [59520/154214]
Validation Done: [59584/154214]
Validation Done: [59648/154214]
Validation Done: [59712/154214]
Validation Done: [59776/154214]
Validation Done: [59840/154214]
Validation Done: [59904/154214]
Validation Done: [59968/154214]
Validation Done: [60032/154214]
Validation Done: [60096/154214]
Validation Done: [60160/154214]
Validation Done: [60224/154214]
Validation Done: [60288/154214]
Validation Done: [60352/154214]
Validation Done: [60416/154214]
Validation Done: [60480/154214]
Validation Done: [60544/154214]
Validation Done: [60608/154214]
Validation Done: [60672/154214]
Validation Done: [60736/154214]
Validation Done: [60800/154214]
Validation Done: [60864/154214]
Validation Done: [60928/154214]
Validation Done: [60992/154214]
Validation Done: [61056/154214]
Validation Done: [61120/154214]
Validation Done: [61184/154214]
Validation Done: [61248/154214]
Validation Done: [61312/154214]
Validation Done: [61376/154214]
Validation Done: [61440/154214]
Validation Done: [61504/154214]
Validation Done: [61568/154214]
Validation Done: [61632/154214]
Validation Done: [61696/154214]
Validation Done: [61760/154214]
Validation Done: [61824/154214]
Validation Done: [61888/154214]
Validation Done: [61952/154214]
Validation Done: [62016/154214]
Validation Done: [62080/154214]
Validation Done: [62144/154214]
Validation Done: [62208/154214]
Validation Done: [62272/154214]
Validation Done: [62336/154214]
Validation Done: [62400/154214]
Validation Done: [62464/154214]
Validation Done: [62528/154214]
Validation Done: [62592/154214]
Validation Done: [62656/154214]
Validation Done: [62720/154214]
Validation Done: [62784/154214]
Validation Done: [62848/154214]
Validation Done: [62912/154214]
Validation Done: [62976/154214]
Validation Done: [63040/154214]
Validation Done: [63104/154214]
Validation Done: [63168/154214]
Validation Done: [63232/154214]
Validation Done: [63296/154214]
Validation Done: [63360/154214]
Validation Done: [63424/154214]
Validation Done: [63488/154214]
Validation Done: [63552/154214]
Validation Done: [63616/154214]
Validation Done: [63680/154214]
Validation Done: [63744/154214]
Validation Done: [63808/154214]
Validation Done: [63872/154214]
Validation Done: [63936/154214]
Validation Done: [64000/154214]
Validation Done: [64064/154214]
Validation Done: [64128/154214]
Validation Done: [64192/154214]
Validation Done: [64256/154214]
Validation Done: [64320/154214]
Validation Done: [64384/154214]
Validation Done: [64448/154214]
Validation Done: [64512/154214]
Validation Done: [64576/154214]
Validation Done: [64640/154214]
Validation Done: [64704/154214]
Validation Done: [64768/154214]
Validation Done: [64832/154214]
Validation Done: [64896/154214]
Validation Done: [64960/154214]
Validation Done: [65024/154214]
Validation Done: [65088/154214]
Validation Done: [65152/154214]
Validation Done: [65216/154214]
Validation Done: [65280/154214]
Validation Done: [65344/154214]
Validation Done: [65408/154214]
Validation Done: [65472/154214]
Validation Done: [65536/154214]
Validation Done: [65600/154214]
Validation Done: [65664/154214]
Validation Done: [65728/154214]
Validation Done: [65792/154214]
Validation Done: [65856/154214]
Validation Done: [65920/154214]
Validation Done: [65984/154214]
Validation Done: [66048/154214]
Validation Done: [66112/154214]
Validation Done: [66176/154214]
Validation Done: [66240/154214]
Validation Done: [66304/154214]
Validation Done: [66368/154214]
Validation Done: [66432/154214]
Validation Done: [66496/154214]
Validation Done: [66560/154214]
Validation Done: [66624/154214]
Validation Done: [66688/154214]
Validation Done: [66752/154214]
Validation Done: [66816/154214]
Validation Done: [66880/154214]
Validation Done: [66944/154214]
Validation Done: [67008/154214]
Validation Done: [67072/154214]
Validation Done: [67136/154214]
Validation Done: [67200/154214]
Validation Done: [67264/154214]
Validation Done: [67328/154214]
Validation Done: [67392/154214]
Validation Done: [67456/154214]
Validation Done: [67520/154214]
Validation Done: [67584/154214]
Validation Done: [67648/154214]
Validation Done: [67712/154214]
Validation Done: [67776/154214]
Validation Done: [67840/154214]
Validation Done: [67904/154214]
Validation Done: [67968/154214]
Validation Done: [68032/154214]
Validation Done: [68096/154214]
Validation Done: [68160/154214]
Validation Done: [68224/154214]
Validation Done: [68288/154214]
Validation Done: [68352/154214]
Validation Done: [68416/154214]
Validation Done: [68480/154214]
Validation Done: [68544/154214]
Validation Done: [68608/154214]
Validation Done: [68672/154214]
Validation Done: [68736/154214]
Validation Done: [68800/154214]
Validation Done: [68864/154214]
Validation Done: [68928/154214]
Validation Done: [68992/154214]
Validation Done: [69056/154214]
Validation Done: [69120/154214]
Validation Done: [69184/154214]
Validation Done: [69248/154214]
Validation Done: [69312/154214]
Validation Done: [69376/154214]
Validation Done: [69440/154214]
Validation Done: [69504/154214]
Validation Done: [69568/154214]
Validation Done: [69632/154214]
Validation Done: [69696/154214]
Validation Done: [69760/154214]
Validation Done: [69824/154214]
Validation Done: [69888/154214]
Validation Done: [69952/154214]
Validation Done: [70016/154214]
Validation Done: [70080/154214]
Validation Done: [70144/154214]
Validation Done: [70208/154214]
Validation Done: [70272/154214]
Validation Done: [70336/154214]
Validation Done: [70400/154214]
Validation Done: [70464/154214]
Validation Done: [70528/154214]
Validation Done: [70592/154214]
Validation Done: [70656/154214]
Validation Done: [70720/154214]
Validation Done: [70784/154214]
Validation Done: [70848/154214]
Validation Done: [70912/154214]
Validation Done: [70976/154214]
Validation Done: [71040/154214]
Validation Done: [71104/154214]
Validation Done: [71168/154214]
Validation Done: [71232/154214]
Validation Done: [71296/154214]
Validation Done: [71360/154214]
Validation Done: [71424/154214]
Validation Done: [71488/154214]
Validation Done: [71552/154214]
Validation Done: [71616/154214]
Validation Done: [71680/154214]
Validation Done: [71744/154214]
Validation Done: [71808/154214]
Validation Done: [71872/154214]
Validation Done: [71936/154214]
Validation Done: [72000/154214]
Validation Done: [72064/154214]
Validation Done: [72128/154214]
Validation Done: [72192/154214]
Validation Done: [72256/154214]
Validation Done: [72320/154214]
Validation Done: [72384/154214]
Validation Done: [72448/154214]
Validation Done: [72512/154214]
Validation Done: [72576/154214]
Validation Done: [72640/154214]
Validation Done: [72704/154214]
Validation Done: [72768/154214]
Validation Done: [72832/154214]
Validation Done: [72896/154214]
Validation Done: [72960/154214]
Validation Done: [73024/154214]
Validation Done: [73088/154214]
Validation Done: [73152/154214]
Validation Done: [73216/154214]
Validation Done: [73280/154214]
Validation Done: [73344/154214]
Validation Done: [73408/154214]
Validation Done: [73472/154214]
Validation Done: [73536/154214]
Validation Done: [73600/154214]
Validation Done: [73664/154214]
Validation Done: [73728/154214]
Validation Done: [73792/154214]
Validation Done: [73856/154214]
Validation Done: [73920/154214]
Validation Done: [73984/154214]
Validation Done: [74048/154214]
Validation Done: [74112/154214]
Validation Done: [74176/154214]
Validation Done: [74240/154214]
Validation Done: [74304/154214]
Validation Done: [74368/154214]
Validation Done: [74432/154214]
Validation Done: [74496/154214]
Validation Done: [74560/154214]
Validation Done: [74624/154214]
Validation Done: [74688/154214]
Validation Done: [74752/154214]
Validation Done: [74816/154214]
Validation Done: [74880/154214]
Validation Done: [74944/154214]
Validation Done: [75008/154214]
Validation Done: [75072/154214]
Validation Done: [75136/154214]
Validation Done: [75200/154214]
Validation Done: [75264/154214]
Validation Done: [75328/154214]
Validation Done: [75392/154214]
Validation Done: [75456/154214]
Validation Done: [75520/154214]
Validation Done: [75584/154214]
Validation Done: [75648/154214]
Validation Done: [75712/154214]
Validation Done: [75776/154214]
Validation Done: [75840/154214]
Validation Done: [75904/154214]
Validation Done: [75968/154214]
Validation Done: [76032/154214]
Validation Done: [76096/154214]
Validation Done: [76160/154214]
Validation Done: [76224/154214]
Validation Done: [76288/154214]
Validation Done: [76352/154214]
Validation Done: [76416/154214]
Validation Done: [76480/154214]
Validation Done: [76544/154214]
Validation Done: [76608/154214]
Validation Done: [76672/154214]
Validation Done: [76736/154214]
Validation Done: [76800/154214]
Validation Done: [76864/154214]
Validation Done: [76928/154214]
Validation Done: [76992/154214]
Validation Done: [77056/154214]
Validation Done: [77120/154214]
Validation Done: [77184/154214]
Validation Done: [77248/154214]
Validation Done: [77312/154214]
Validation Done: [77376/154214]
Validation Done: [77440/154214]
Validation Done: [77504/154214]
Validation Done: [77568/154214]
Validation Done: [77632/154214]
Validation Done: [77696/154214]
Validation Done: [77760/154214]
Validation Done: [77824/154214]
Validation Done: [77888/154214]
Validation Done: [77952/154214]
Validation Done: [78016/154214]
Validation Done: [78080/154214]
Validation Done: [78144/154214]
Validation Done: [78208/154214]
Validation Done: [78272/154214]
Validation Done: [78336/154214]
Validation Done: [78400/154214]
Validation Done: [78464/154214]
Validation Done: [78528/154214]
Validation Done: [78592/154214]
Validation Done: [78656/154214]
Validation Done: [78720/154214]
Validation Done: [78784/154214]
Validation Done: [78848/154214]
Validation Done: [78912/154214]
Validation Done: [78976/154214]
Validation Done: [79040/154214]
Validation Done: [79104/154214]
Validation Done: [79168/154214]
Validation Done: [79232/154214]
Validation Done: [79296/154214]
Validation Done: [79360/154214]
Validation Done: [79424/154214]
Validation Done: [79488/154214]
Validation Done: [79552/154214]
Validation Done: [79616/154214]
Validation Done: [79680/154214]
Validation Done: [79744/154214]
Validation Done: [79808/154214]
Validation Done: [79872/154214]
Validation Done: [79936/154214]
Validation Done: [80000/154214]
Validation Done: [80064/154214]
Validation Done: [80128/154214]
Validation Done: [80192/154214]
Validation Done: [80256/154214]
Validation Done: [80320/154214]
Validation Done: [80384/154214]
Validation Done: [80448/154214]
Validation Done: [80512/154214]
Validation Done: [80576/154214]
Validation Done: [80640/154214]
Validation Done: [80704/154214]
Validation Done: [80768/154214]
Validation Done: [80832/154214]
Validation Done: [80896/154214]
Validation Done: [80960/154214]
Validation Done: [81024/154214]
Validation Done: [81088/154214]
Validation Done: [81152/154214]
Validation Done: [81216/154214]
Validation Done: [81280/154214]
Validation Done: [81344/154214]
Validation Done: [81408/154214]
Validation Done: [81472/154214]
Validation Done: [81536/154214]
Validation Done: [81600/154214]
Validation Done: [81664/154214]
Validation Done: [81728/154214]
Validation Done: [81792/154214]
Validation Done: [81856/154214]
Validation Done: [81920/154214]
Validation Done: [81984/154214]
Validation Done: [82048/154214]
Validation Done: [82112/154214]
Validation Done: [82176/154214]
Validation Done: [82240/154214]
Validation Done: [82304/154214]
Validation Done: [82368/154214]
Validation Done: [82432/154214]
Validation Done: [82496/154214]
Validation Done: [82560/154214]
Validation Done: [82624/154214]
Validation Done: [82688/154214]
Validation Done: [82752/154214]
Validation Done: [82816/154214]
Validation Done: [82880/154214]
Validation Done: [82944/154214]
Validation Done: [83008/154214]
Validation Done: [83072/154214]
Validation Done: [83136/154214]
Validation Done: [83200/154214]
Validation Done: [83264/154214]
Validation Done: [83328/154214]
Validation Done: [83392/154214]
Validation Done: [83456/154214]
Validation Done: [83520/154214]
Validation Done: [83584/154214]
Validation Done: [83648/154214]
Validation Done: [83712/154214]
Validation Done: [83776/154214]
Validation Done: [83840/154214]
Validation Done: [83904/154214]
Validation Done: [83968/154214]
Validation Done: [84032/154214]
Validation Done: [84096/154214]
Validation Done: [84160/154214]
Validation Done: [84224/154214]
Validation Done: [84288/154214]
Validation Done: [84352/154214]
Validation Done: [84416/154214]
Validation Done: [84480/154214]
Validation Done: [84544/154214]
Validation Done: [84608/154214]
Validation Done: [84672/154214]
Validation Done: [84736/154214]
Validation Done: [84800/154214]
Validation Done: [84864/154214]
Validation Done: [84928/154214]
Validation Done: [84992/154214]
Validation Done: [85056/154214]
Validation Done: [85120/154214]
Validation Done: [85184/154214]
Validation Done: [85248/154214]
Validation Done: [85312/154214]
Validation Done: [85376/154214]
Validation Done: [85440/154214]
Validation Done: [85504/154214]
Validation Done: [85568/154214]
Validation Done: [85632/154214]
Validation Done: [85696/154214]
Validation Done: [85760/154214]
Validation Done: [85824/154214]
Validation Done: [85888/154214]
Validation Done: [85952/154214]
Validation Done: [86016/154214]
Validation Done: [86080/154214]
Validation Done: [86144/154214]
Validation Done: [86208/154214]
Validation Done: [86272/154214]
Validation Done: [86336/154214]
Validation Done: [86400/154214]
Validation Done: [86464/154214]
Validation Done: [86528/154214]
Validation Done: [86592/154214]
Validation Done: [86656/154214]
Validation Done: [86720/154214]
Validation Done: [86784/154214]
Validation Done: [86848/154214]
Validation Done: [86912/154214]
Validation Done: [86976/154214]
Validation Done: [87040/154214]
Validation Done: [87104/154214]
Validation Done: [87168/154214]
Validation Done: [87232/154214]
Validation Done: [87296/154214]
Validation Done: [87360/154214]
Validation Done: [87424/154214]
Validation Done: [87488/154214]
Validation Done: [87552/154214]
Validation Done: [87616/154214]
Validation Done: [87680/154214]
Validation Done: [87744/154214]
Validation Done: [87808/154214]
Validation Done: [87872/154214]
Validation Done: [87936/154214]
Validation Done: [88000/154214]
Validation Done: [88064/154214]
Validation Done: [88128/154214]
Validation Done: [88192/154214]
Validation Done: [88256/154214]
Validation Done: [88320/154214]
Validation Done: [88384/154214]
Validation Done: [88448/154214]
Validation Done: [88512/154214]
Validation Done: [88576/154214]
Validation Done: [88640/154214]
Validation Done: [88704/154214]
Validation Done: [88768/154214]
Validation Done: [88832/154214]
Validation Done: [88896/154214]
Validation Done: [88960/154214]
Validation Done: [89024/154214]
Validation Done: [89088/154214]
Validation Done: [89152/154214]
Validation Done: [89216/154214]
Validation Done: [89280/154214]
Validation Done: [89344/154214]
Validation Done: [89408/154214]
Validation Done: [89472/154214]
Validation Done: [89536/154214]
Validation Done: [89600/154214]
Validation Done: [89664/154214]
Validation Done: [89728/154214]
Validation Done: [89792/154214]
Validation Done: [89856/154214]
Validation Done: [89920/154214]
Validation Done: [89984/154214]
Validation Done: [90048/154214]
Validation Done: [90112/154214]
Validation Done: [90176/154214]
Validation Done: [90240/154214]
Validation Done: [90304/154214]
Validation Done: [90368/154214]
Validation Done: [90432/154214]
Validation Done: [90496/154214]
Validation Done: [90560/154214]
Validation Done: [90624/154214]
Validation Done: [90688/154214]
Validation Done: [90752/154214]
Validation Done: [90816/154214]
Validation Done: [90880/154214]
Validation Done: [90944/154214]
Validation Done: [91008/154214]
Validation Done: [91072/154214]
Validation Done: [91136/154214]
Validation Done: [91200/154214]
Validation Done: [91264/154214]
Validation Done: [91328/154214]
Validation Done: [91392/154214]
Validation Done: [91456/154214]
Validation Done: [91520/154214]
Validation Done: [91584/154214]
Validation Done: [91648/154214]
Validation Done: [91712/154214]
Validation Done: [91776/154214]
Validation Done: [91840/154214]
Validation Done: [91904/154214]
Validation Done: [91968/154214]
Validation Done: [92032/154214]
Validation Done: [92096/154214]
Validation Done: [92160/154214]
Validation Done: [92224/154214]
Validation Done: [92288/154214]
Validation Done: [92352/154214]
Validation Done: [92416/154214]
Validation Done: [92480/154214]
Validation Done: [92544/154214]
Validation Done: [92608/154214]
Validation Done: [92672/154214]
Validation Done: [92736/154214]
Validation Done: [92800/154214]
Validation Done: [92864/154214]
Validation Done: [92928/154214]
Validation Done: [92992/154214]
Validation Done: [93056/154214]
Validation Done: [93120/154214]
Validation Done: [93184/154214]
Validation Done: [93248/154214]
Validation Done: [93312/154214]
Validation Done: [93376/154214]
Validation Done: [93440/154214]
Validation Done: [93504/154214]
Validation Done: [93568/154214]
Validation Done: [93632/154214]
Validation Done: [93696/154214]
Validation Done: [93760/154214]
Validation Done: [93824/154214]
Validation Done: [93888/154214]
Validation Done: [93952/154214]
Validation Done: [94016/154214]
Validation Done: [94080/154214]
Validation Done: [94144/154214]
Validation Done: [94208/154214]
Validation Done: [94272/154214]
Validation Done: [94336/154214]
Validation Done: [94400/154214]
Validation Done: [94464/154214]
Validation Done: [94528/154214]
Validation Done: [94592/154214]
Validation Done: [94656/154214]
Validation Done: [94720/154214]
Validation Done: [94784/154214]
Validation Done: [94848/154214]
Validation Done: [94912/154214]
Validation Done: [94976/154214]
Validation Done: [95040/154214]
Validation Done: [95104/154214]
Validation Done: [95168/154214]
Validation Done: [95232/154214]
Validation Done: [95296/154214]
Validation Done: [95360/154214]
Validation Done: [95424/154214]
Validation Done: [95488/154214]
Validation Done: [95552/154214]
Validation Done: [95616/154214]
Validation Done: [95680/154214]
Validation Done: [95744/154214]
Validation Done: [95808/154214]
Validation Done: [95872/154214]
Validation Done: [95936/154214]
Validation Done: [96000/154214]
Validation Done: [96064/154214]
Validation Done: [96128/154214]
Validation Done: [96192/154214]
Validation Done: [96256/154214]
Validation Done: [96320/154214]
Validation Done: [96384/154214]
Validation Done: [96448/154214]
Validation Done: [96512/154214]
Validation Done: [96576/154214]
Validation Done: [96640/154214]
Validation Done: [96704/154214]
Validation Done: [96768/154214]
Validation Done: [96832/154214]
Validation Done: [96896/154214]
Validation Done: [96960/154214]
Validation Done: [97024/154214]
Validation Done: [97088/154214]
Validation Done: [97152/154214]
Validation Done: [97216/154214]
Validation Done: [97280/154214]
Validation Done: [97344/154214]
Validation Done: [97408/154214]
Validation Done: [97472/154214]
Validation Done: [97536/154214]
Validation Done: [97600/154214]
Validation Done: [97664/154214]
Validation Done: [97728/154214]
Validation Done: [97792/154214]
Validation Done: [97856/154214]
Validation Done: [97920/154214]
Validation Done: [97984/154214]
Validation Done: [98048/154214]
Validation Done: [98112/154214]
Validation Done: [98176/154214]
Validation Done: [98240/154214]
Validation Done: [98304/154214]
Validation Done: [98368/154214]
Validation Done: [98432/154214]
Validation Done: [98496/154214]
Validation Done: [98560/154214]
Validation Done: [98624/154214]
Validation Done: [98688/154214]
Validation Done: [98752/154214]
Validation Done: [98816/154214]
Validation Done: [98880/154214]
Validation Done: [98944/154214]
Validation Done: [99008/154214]
Validation Done: [99072/154214]
Validation Done: [99136/154214]
Validation Done: [99200/154214]
Validation Done: [99264/154214]
Validation Done: [99328/154214]
Validation Done: [99392/154214]
Validation Done: [99456/154214]
Validation Done: [99520/154214]
Validation Done: [99584/154214]
Validation Done: [99648/154214]
Validation Done: [99712/154214]
Validation Done: [99776/154214]
Validation Done: [99840/154214]
Validation Done: [99904/154214]
Validation Done: [99968/154214]
Validation Done: [100032/154214]
Validation Done: [100096/154214]
Validation Done: [100160/154214]
Validation Done: [100224/154214]
Validation Done: [100288/154214]
Validation Done: [100352/154214]
Validation Done: [100416/154214]
Validation Done: [100480/154214]
Validation Done: [100544/154214]
Validation Done: [100608/154214]
Validation Done: [100672/154214]
Validation Done: [100736/154214]
Validation Done: [100800/154214]
Validation Done: [100864/154214]
Validation Done: [100928/154214]
Validation Done: [100992/154214]
Validation Done: [101056/154214]
Validation Done: [101120/154214]
Validation Done: [101184/154214]
Validation Done: [101248/154214]
Validation Done: [101312/154214]
Validation Done: [101376/154214]
Validation Done: [101440/154214]
Validation Done: [101504/154214]
Validation Done: [101568/154214]
Validation Done: [101632/154214]
Validation Done: [101696/154214]
Validation Done: [101760/154214]
Validation Done: [101824/154214]
Validation Done: [101888/154214]
Validation Done: [101952/154214]
Validation Done: [102016/154214]
Validation Done: [102080/154214]
Validation Done: [102144/154214]
Validation Done: [102208/154214]
Validation Done: [102272/154214]
Validation Done: [102336/154214]
Validation Done: [102400/154214]
Validation Done: [102464/154214]
Validation Done: [102528/154214]
Validation Done: [102592/154214]
Validation Done: [102656/154214]
Validation Done: [102720/154214]
Validation Done: [102784/154214]
Validation Done: [102848/154214]
Validation Done: [102912/154214]
Validation Done: [102976/154214]
Validation Done: [103040/154214]
Validation Done: [103104/154214]
Validation Done: [103168/154214]
Validation Done: [103232/154214]
Validation Done: [103296/154214]
Validation Done: [103360/154214]
Validation Done: [103424/154214]
Validation Done: [103488/154214]
Validation Done: [103552/154214]
Validation Done: [103616/154214]
Validation Done: [103680/154214]
Validation Done: [103744/154214]
Validation Done: [103808/154214]
Validation Done: [103872/154214]
Validation Done: [103936/154214]
Validation Done: [104000/154214]
Validation Done: [104064/154214]
Validation Done: [104128/154214]
Validation Done: [104192/154214]
Validation Done: [104256/154214]
Validation Done: [104320/154214]
Validation Done: [104384/154214]
Validation Done: [104448/154214]
Validation Done: [104512/154214]
Validation Done: [104576/154214]
Validation Done: [104640/154214]
Validation Done: [104704/154214]
Validation Done: [104768/154214]
Validation Done: [104832/154214]
Validation Done: [104896/154214]
Validation Done: [104960/154214]
Validation Done: [105024/154214]
Validation Done: [105088/154214]
Validation Done: [105152/154214]
Validation Done: [105216/154214]
Validation Done: [105280/154214]
Validation Done: [105344/154214]
Validation Done: [105408/154214]
Validation Done: [105472/154214]
Validation Done: [105536/154214]
Validation Done: [105600/154214]
Validation Done: [105664/154214]
Validation Done: [105728/154214]
Validation Done: [105792/154214]
Validation Done: [105856/154214]
Validation Done: [105920/154214]
Validation Done: [105984/154214]
Validation Done: [106048/154214]
Validation Done: [106112/154214]
Validation Done: [106176/154214]
Validation Done: [106240/154214]
Validation Done: [106304/154214]
Validation Done: [106368/154214]
Validation Done: [106432/154214]
Validation Done: [106496/154214]
Validation Done: [106560/154214]
Validation Done: [106624/154214]
Validation Done: [106688/154214]
Validation Done: [106752/154214]
Validation Done: [106816/154214]
Validation Done: [106880/154214]
Validation Done: [106944/154214]
Validation Done: [107008/154214]
Validation Done: [107072/154214]
Validation Done: [107136/154214]
Validation Done: [107200/154214]
Validation Done: [107264/154214]
Validation Done: [107328/154214]
Validation Done: [107392/154214]
Validation Done: [107456/154214]
Validation Done: [107520/154214]
Validation Done: [107584/154214]
Validation Done: [107648/154214]
Validation Done: [107712/154214]
Validation Done: [107776/154214]
Validation Done: [107840/154214]
Validation Done: [107904/154214]
Validation Done: [107968/154214]
Validation Done: [108032/154214]
Validation Done: [108096/154214]
Validation Done: [108160/154214]
Validation Done: [108224/154214]
Validation Done: [108288/154214]
Validation Done: [108352/154214]
Validation Done: [108416/154214]
Validation Done: [108480/154214]
Validation Done: [108544/154214]
Validation Done: [108608/154214]
Validation Done: [108672/154214]
Validation Done: [108736/154214]
Validation Done: [108800/154214]
Validation Done: [108864/154214]
Validation Done: [108928/154214]
Validation Done: [108992/154214]
Validation Done: [109056/154214]
Validation Done: [109120/154214]
Validation Done: [109184/154214]
Validation Done: [109248/154214]
Validation Done: [109312/154214]
Validation Done: [109376/154214]
Validation Done: [109440/154214]
Validation Done: [109504/154214]
Validation Done: [109568/154214]
Validation Done: [109632/154214]
Validation Done: [109696/154214]
Validation Done: [109760/154214]
Validation Done: [109824/154214]
Validation Done: [109888/154214]
Validation Done: [109952/154214]
Validation Done: [110016/154214]
Validation Done: [110080/154214]
Validation Done: [110144/154214]
Validation Done: [110208/154214]
Validation Done: [110272/154214]
Validation Done: [110336/154214]
Validation Done: [110400/154214]
Validation Done: [110464/154214]
Validation Done: [110528/154214]
Validation Done: [110592/154214]
Validation Done: [110656/154214]
Validation Done: [110720/154214]
Validation Done: [110784/154214]
Validation Done: [110848/154214]
Validation Done: [110912/154214]
Validation Done: [110976/154214]
Validation Done: [111040/154214]
Validation Done: [111104/154214]
Validation Done: [111168/154214]
Validation Done: [111232/154214]
Validation Done: [111296/154214]
Validation Done: [111360/154214]
Validation Done: [111424/154214]
Validation Done: [111488/154214]
Validation Done: [111552/154214]
Validation Done: [111616/154214]
Validation Done: [111680/154214]
Validation Done: [111744/154214]
Validation Done: [111808/154214]
Validation Done: [111872/154214]
Validation Done: [111936/154214]
Validation Done: [112000/154214]
Validation Done: [112064/154214]
Validation Done: [112128/154214]
Validation Done: [112192/154214]
Validation Done: [112256/154214]
Validation Done: [112320/154214]
Validation Done: [112384/154214]
Validation Done: [112448/154214]
Validation Done: [112512/154214]
Validation Done: [112576/154214]
Validation Done: [112640/154214]
Validation Done: [112704/154214]
Validation Done: [112768/154214]
Validation Done: [112832/154214]
Validation Done: [112896/154214]
Validation Done: [112960/154214]
Validation Done: [113024/154214]
Validation Done: [113088/154214]
Validation Done: [113152/154214]
Validation Done: [113216/154214]
Validation Done: [113280/154214]
Validation Done: [113344/154214]
Validation Done: [113408/154214]
Validation Done: [113472/154214]
Validation Done: [113536/154214]
Validation Done: [113600/154214]
Validation Done: [113664/154214]
Validation Done: [113728/154214]
Validation Done: [113792/154214]
Validation Done: [113856/154214]
Validation Done: [113920/154214]
Validation Done: [113984/154214]
Validation Done: [114048/154214]
Validation Done: [114112/154214]
Validation Done: [114176/154214]
Validation Done: [114240/154214]
Validation Done: [114304/154214]
Validation Done: [114368/154214]
Validation Done: [114432/154214]
Validation Done: [114496/154214]
Validation Done: [114560/154214]
Validation Done: [114624/154214]
Validation Done: [114688/154214]
Validation Done: [114752/154214]
Validation Done: [114816/154214]
Validation Done: [114880/154214]
Validation Done: [114944/154214]
Validation Done: [115008/154214]
Validation Done: [115072/154214]
Validation Done: [115136/154214]
Validation Done: [115200/154214]
Validation Done: [115264/154214]
Validation Done: [115328/154214]
Validation Done: [115392/154214]
Validation Done: [115456/154214]
Validation Done: [115520/154214]
Validation Done: [115584/154214]
Validation Done: [115648/154214]
Validation Done: [115712/154214]
Validation Done: [115776/154214]
Validation Done: [115840/154214]
Validation Done: [115904/154214]
Validation Done: [115968/154214]
Validation Done: [116032/154214]
Validation Done: [116096/154214]
Validation Done: [116160/154214]
Validation Done: [116224/154214]
Validation Done: [116288/154214]
Validation Done: [116352/154214]
Validation Done: [116416/154214]
Validation Done: [116480/154214]
Validation Done: [116544/154214]
Validation Done: [116608/154214]
Validation Done: [116672/154214]
Validation Done: [116736/154214]
Validation Done: [116800/154214]
Validation Done: [116864/154214]
Validation Done: [116928/154214]
Validation Done: [116992/154214]
Validation Done: [117056/154214]
Validation Done: [117120/154214]
Validation Done: [117184/154214]
Validation Done: [117248/154214]
Validation Done: [117312/154214]
Validation Done: [117376/154214]
Validation Done: [117440/154214]
Validation Done: [117504/154214]
Validation Done: [117568/154214]
Validation Done: [117632/154214]
Validation Done: [117696/154214]
Validation Done: [117760/154214]
Validation Done: [117824/154214]
Validation Done: [117888/154214]
Validation Done: [117952/154214]
Validation Done: [118016/154214]
Validation Done: [118080/154214]
Validation Done: [118144/154214]
Validation Done: [118208/154214]
Validation Done: [118272/154214]
Validation Done: [118336/154214]
Validation Done: [118400/154214]
Validation Done: [118464/154214]
Validation Done: [118528/154214]
Validation Done: [118592/154214]
Validation Done: [118656/154214]
Validation Done: [118720/154214]
Validation Done: [118784/154214]
Validation Done: [118848/154214]
Validation Done: [118912/154214]
Validation Done: [118976/154214]
Validation Done: [119040/154214]
Validation Done: [119104/154214]
Validation Done: [119168/154214]
Validation Done: [119232/154214]
Validation Done: [119296/154214]
Validation Done: [119360/154214]
Validation Done: [119424/154214]
Validation Done: [119488/154214]
Validation Done: [119552/154214]
Validation Done: [119616/154214]
Validation Done: [119680/154214]
Validation Done: [119744/154214]
Validation Done: [119808/154214]
Validation Done: [119872/154214]
Validation Done: [119936/154214]
Validation Done: [120000/154214]
Validation Done: [120064/154214]
Validation Done: [120128/154214]
Validation Done: [120192/154214]
Validation Done: [120256/154214]
Validation Done: [120320/154214]
Validation Done: [120384/154214]
Validation Done: [120448/154214]
Validation Done: [120512/154214]
Validation Done: [120576/154214]
Validation Done: [120640/154214]
Validation Done: [120704/154214]
Validation Done: [120768/154214]
Validation Done: [120832/154214]
Validation Done: [120896/154214]
Validation Done: [120960/154214]
Validation Done: [121024/154214]
Validation Done: [121088/154214]
Validation Done: [121152/154214]
Validation Done: [121216/154214]
Validation Done: [121280/154214]
Validation Done: [121344/154214]
Validation Done: [121408/154214]
Validation Done: [121472/154214]
Validation Done: [121536/154214]
Validation Done: [121600/154214]
Validation Done: [121664/154214]
Validation Done: [121728/154214]
Validation Done: [121792/154214]
Validation Done: [121856/154214]
Validation Done: [121920/154214]
Validation Done: [121984/154214]
Validation Done: [122048/154214]
Validation Done: [122112/154214]
Validation Done: [122176/154214]
Validation Done: [122240/154214]
Validation Done: [122304/154214]
Validation Done: [122368/154214]
Validation Done: [122432/154214]
Validation Done: [122496/154214]
Validation Done: [122560/154214]
Validation Done: [122624/154214]
Validation Done: [122688/154214]
Validation Done: [122752/154214]
Validation Done: [122816/154214]
Validation Done: [122880/154214]
Validation Done: [122944/154214]
Validation Done: [123008/154214]
Validation Done: [123072/154214]
Validation Done: [123136/154214]
Validation Done: [123200/154214]
Validation Done: [123264/154214]
Validation Done: [123328/154214]
Validation Done: [123392/154214]
Validation Done: [123456/154214]
Validation Done: [123520/154214]
Validation Done: [123584/154214]
Validation Done: [123648/154214]
Validation Done: [123712/154214]
Validation Done: [123776/154214]
Validation Done: [123840/154214]
Validation Done: [123904/154214]
Validation Done: [123968/154214]
Validation Done: [124032/154214]
Validation Done: [124096/154214]
Validation Done: [124160/154214]
Validation Done: [124224/154214]
Validation Done: [124288/154214]
Validation Done: [124352/154214]
Validation Done: [124416/154214]
Validation Done: [124480/154214]
Validation Done: [124544/154214]
Validation Done: [124608/154214]
Validation Done: [124672/154214]
Validation Done: [124736/154214]
Validation Done: [124800/154214]
Validation Done: [124864/154214]
Validation Done: [124928/154214]
Validation Done: [124992/154214]
Validation Done: [125056/154214]
Validation Done: [125120/154214]
Validation Done: [125184/154214]
Validation Done: [125248/154214]
Validation Done: [125312/154214]
Validation Done: [125376/154214]
Validation Done: [125440/154214]
Validation Done: [125504/154214]
Validation Done: [125568/154214]
Validation Done: [125632/154214]
Validation Done: [125696/154214]
Validation Done: [125760/154214]
Validation Done: [125824/154214]
Validation Done: [125888/154214]
Validation Done: [125952/154214]
Validation Done: [126016/154214]
Validation Done: [126080/154214]
Validation Done: [126144/154214]
Validation Done: [126208/154214]
Validation Done: [126272/154214]
Validation Done: [126336/154214]
Validation Done: [126400/154214]
Validation Done: [126464/154214]
Validation Done: [126528/154214]
Validation Done: [126592/154214]
Validation Done: [126656/154214]
Validation Done: [126720/154214]
Validation Done: [126784/154214]
Validation Done: [126848/154214]
Validation Done: [126912/154214]
Validation Done: [126976/154214]
Validation Done: [127040/154214]
Validation Done: [127104/154214]
Validation Done: [127168/154214]
Validation Done: [127232/154214]
Validation Done: [127296/154214]
Validation Done: [127360/154214]
Validation Done: [127424/154214]
Validation Done: [127488/154214]
Validation Done: [127552/154214]
Validation Done: [127616/154214]
Validation Done: [127680/154214]
Validation Done: [127744/154214]
Validation Done: [127808/154214]
Validation Done: [127872/154214]
Validation Done: [127936/154214]
Validation Done: [128000/154214]
Validation Done: [128064/154214]
Validation Done: [128128/154214]
Validation Done: [128192/154214]
Validation Done: [128256/154214]
Validation Done: [128320/154214]
Validation Done: [128384/154214]
Validation Done: [128448/154214]
Validation Done: [128512/154214]
Validation Done: [128576/154214]
Validation Done: [128640/154214]
Validation Done: [128704/154214]
Validation Done: [128768/154214]
Validation Done: [128832/154214]
Validation Done: [128896/154214]
Validation Done: [128960/154214]
Validation Done: [129024/154214]
Validation Done: [129088/154214]
Validation Done: [129152/154214]
Validation Done: [129216/154214]
Validation Done: [129280/154214]
Validation Done: [129344/154214]
Validation Done: [129408/154214]
Validation Done: [129472/154214]
Validation Done: [129536/154214]
Validation Done: [129600/154214]
Validation Done: [129664/154214]
Validation Done: [129728/154214]
Validation Done: [129792/154214]
Validation Done: [129856/154214]
Validation Done: [129920/154214]
Validation Done: [129984/154214]
Validation Done: [130048/154214]
Validation Done: [130112/154214]
Validation Done: [130176/154214]
Validation Done: [130240/154214]
Validation Done: [130304/154214]
Validation Done: [130368/154214]
Validation Done: [130432/154214]
Validation Done: [130496/154214]
Validation Done: [130560/154214]
Validation Done: [130624/154214]
Validation Done: [130688/154214]
Validation Done: [130752/154214]
Validation Done: [130816/154214]
Validation Done: [130880/154214]
Validation Done: [130944/154214]
Validation Done: [131008/154214]
Validation Done: [131072/154214]
Validation Done: [131136/154214]
Validation Done: [131200/154214]
Validation Done: [131264/154214]
Validation Done: [131328/154214]
Validation Done: [131392/154214]
Validation Done: [131456/154214]
Validation Done: [131520/154214]
Validation Done: [131584/154214]
Validation Done: [131648/154214]
Validation Done: [131712/154214]
Validation Done: [131776/154214]
Validation Done: [131840/154214]
Validation Done: [131904/154214]
Validation Done: [131968/154214]
Validation Done: [132032/154214]
Validation Done: [132096/154214]
Validation Done: [132160/154214]
Validation Done: [132224/154214]
Validation Done: [132288/154214]
Validation Done: [132352/154214]
Validation Done: [132416/154214]
Validation Done: [132480/154214]
Validation Done: [132544/154214]
Validation Done: [132608/154214]
Validation Done: [132672/154214]
Validation Done: [132736/154214]
Validation Done: [132800/154214]
Validation Done: [132864/154214]
Validation Done: [132928/154214]
Validation Done: [132992/154214]
Validation Done: [133056/154214]
Validation Done: [133120/154214]
Validation Done: [133184/154214]
Validation Done: [133248/154214]
Validation Done: [133312/154214]
Validation Done: [133376/154214]
Validation Done: [133440/154214]
Validation Done: [133504/154214]
Validation Done: [133568/154214]
Validation Done: [133632/154214]
Validation Done: [133696/154214]
Validation Done: [133760/154214]
Validation Done: [133824/154214]
Validation Done: [133888/154214]
Validation Done: [133952/154214]
Validation Done: [134016/154214]
Validation Done: [134080/154214]
Validation Done: [134144/154214]
Validation Done: [134208/154214]
Validation Done: [134272/154214]
Validation Done: [134336/154214]
Validation Done: [134400/154214]
Validation Done: [134464/154214]
Validation Done: [134528/154214]
Validation Done: [134592/154214]
Validation Done: [134656/154214]
Validation Done: [134720/154214]
Validation Done: [134784/154214]
Validation Done: [134848/154214]
Validation Done: [134912/154214]
Validation Done: [134976/154214]
Validation Done: [135040/154214]
Validation Done: [135104/154214]
Validation Done: [135168/154214]
Validation Done: [135232/154214]
Validation Done: [135296/154214]
Validation Done: [135360/154214]
Validation Done: [135424/154214]
Validation Done: [135488/154214]
Validation Done: [135552/154214]
Validation Done: [135616/154214]
Validation Done: [135680/154214]
Validation Done: [135744/154214]
Validation Done: [135808/154214]
Validation Done: [135872/154214]
Validation Done: [135936/154214]
Validation Done: [136000/154214]
Validation Done: [136064/154214]
Validation Done: [136128/154214]
Validation Done: [136192/154214]
Validation Done: [136256/154214]
Validation Done: [136320/154214]
Validation Done: [136384/154214]
Validation Done: [136448/154214]
Validation Done: [136512/154214]
Validation Done: [136576/154214]
Validation Done: [136640/154214]
Validation Done: [136704/154214]
Validation Done: [136768/154214]
Validation Done: [136832/154214]
Validation Done: [136896/154214]
Validation Done: [136960/154214]
Validation Done: [137024/154214]
Validation Done: [137088/154214]
Validation Done: [137152/154214]
Validation Done: [137216/154214]
Validation Done: [137280/154214]
Validation Done: [137344/154214]
Validation Done: [137408/154214]
Validation Done: [137472/154214]
Validation Done: [137536/154214]
Validation Done: [137600/154214]
Validation Done: [137664/154214]
Validation Done: [137728/154214]
Validation Done: [137792/154214]
Validation Done: [137856/154214]
Validation Done: [137920/154214]
Validation Done: [137984/154214]
Validation Done: [138048/154214]
Validation Done: [138112/154214]
Validation Done: [138176/154214]
Validation Done: [138240/154214]
Validation Done: [138304/154214]
Validation Done: [138368/154214]
Validation Done: [138432/154214]
Validation Done: [138496/154214]
Validation Done: [138560/154214]
Validation Done: [138624/154214]
Validation Done: [138688/154214]
Validation Done: [138752/154214]
Validation Done: [138816/154214]
Validation Done: [138880/154214]
Validation Done: [138944/154214]
Validation Done: [139008/154214]
Validation Done: [139072/154214]
Validation Done: [139136/154214]
Validation Done: [139200/154214]
Validation Done: [139264/154214]
Validation Done: [139328/154214]
Validation Done: [139392/154214]
Validation Done: [139456/154214]
Validation Done: [139520/154214]
Validation Done: [139584/154214]
Validation Done: [139648/154214]
Validation Done: [139712/154214]
Validation Done: [139776/154214]
Validation Done: [139840/154214]
Validation Done: [139904/154214]
Validation Done: [139968/154214]
Validation Done: [140032/154214]
Validation Done: [140096/154214]
Validation Done: [140160/154214]
Validation Done: [140224/154214]
Validation Done: [140288/154214]
Validation Done: [140352/154214]
Validation Done: [140416/154214]
Validation Done: [140480/154214]
Validation Done: [140544/154214]
Validation Done: [140608/154214]
Validation Done: [140672/154214]
Validation Done: [140736/154214]
Validation Done: [140800/154214]
Validation Done: [140864/154214]
Validation Done: [140928/154214]
Validation Done: [140992/154214]
Validation Done: [141056/154214]
Validation Done: [141120/154214]
Validation Done: [141184/154214]
Validation Done: [141248/154214]
Validation Done: [141312/154214]
Validation Done: [141376/154214]
Validation Done: [141440/154214]
Validation Done: [141504/154214]
Validation Done: [141568/154214]
Validation Done: [141632/154214]
Validation Done: [141696/154214]
Validation Done: [141760/154214]
Validation Done: [141824/154214]
Validation Done: [141888/154214]
Validation Done: [141952/154214]
Validation Done: [142016/154214]
Validation Done: [142080/154214]
Validation Done: [142144/154214]
Validation Done: [142208/154214]
Validation Done: [142272/154214]
Validation Done: [142336/154214]
Validation Done: [142400/154214]
Validation Done: [142464/154214]
Validation Done: [142528/154214]
Validation Done: [142592/154214]
Validation Done: [142656/154214]
Validation Done: [142720/154214]
Validation Done: [142784/154214]
Validation Done: [142848/154214]
Validation Done: [142912/154214]
Validation Done: [142976/154214]
Validation Done: [143040/154214]
Validation Done: [143104/154214]
Validation Done: [143168/154214]
Validation Done: [143232/154214]
Validation Done: [143296/154214]
Validation Done: [143360/154214]
Validation Done: [143424/154214]
Validation Done: [143488/154214]
Validation Done: [143552/154214]
Validation Done: [143616/154214]
Validation Done: [143680/154214]
Validation Done: [143744/154214]
Validation Done: [143808/154214]
Validation Done: [143872/154214]
Validation Done: [143936/154214]
Validation Done: [144000/154214]
Validation Done: [144064/154214]
Validation Done: [144128/154214]
Validation Done: [144192/154214]
Validation Done: [144256/154214]
Validation Done: [144320/154214]
Validation Done: [144384/154214]
Validation Done: [144448/154214]
Validation Done: [144512/154214]
Validation Done: [144576/154214]
Validation Done: [144640/154214]
Validation Done: [144704/154214]
Validation Done: [144768/154214]
Validation Done: [144832/154214]
Validation Done: [144896/154214]
Validation Done: [144960/154214]
Validation Done: [145024/154214]
Validation Done: [145088/154214]
Validation Done: [145152/154214]
Validation Done: [145216/154214]
Validation Done: [145280/154214]
Validation Done: [145344/154214]
Validation Done: [145408/154214]
Validation Done: [145472/154214]
Validation Done: [145536/154214]
Validation Done: [145600/154214]
Validation Done: [145664/154214]
Validation Done: [145728/154214]
Validation Done: [145792/154214]
Validation Done: [145856/154214]
Validation Done: [145920/154214]
Validation Done: [145984/154214]
Validation Done: [146048/154214]
Validation Done: [146112/154214]
Validation Done: [146176/154214]
Validation Done: [146240/154214]
Validation Done: [146304/154214]
Validation Done: [146368/154214]
Validation Done: [146432/154214]
Validation Done: [146496/154214]
Validation Done: [146560/154214]
Validation Done: [146624/154214]
Validation Done: [146688/154214]
Validation Done: [146752/154214]
Validation Done: [146816/154214]
Validation Done: [146880/154214]
Validation Done: [146944/154214]
Validation Done: [147008/154214]
Validation Done: [147072/154214]
Validation Done: [147136/154214]
Validation Done: [147200/154214]
Validation Done: [147264/154214]
Validation Done: [147328/154214]
Validation Done: [147392/154214]
Validation Done: [147456/154214]
Validation Done: [147520/154214]
Validation Done: [147584/154214]
Validation Done: [147648/154214]
Validation Done: [147712/154214]
Validation Done: [147776/154214]
Validation Done: [147840/154214]
Validation Done: [147904/154214]
Validation Done: [147968/154214]
Validation Done: [148032/154214]
Validation Done: [148096/154214]
Validation Done: [148160/154214]
Validation Done: [148224/154214]
Validation Done: [148288/154214]
Validation Done: [148352/154214]
Validation Done: [148416/154214]
Validation Done: [148480/154214]
Validation Done: [148544/154214]
Validation Done: [148608/154214]
Validation Done: [148672/154214]
Validation Done: [148736/154214]
Validation Done: [148800/154214]
Validation Done: [148864/154214]
Validation Done: [148928/154214]
Validation Done: [148992/154214]
Validation Done: [149056/154214]
Validation Done: [149120/154214]
Validation Done: [149184/154214]
Validation Done: [149248/154214]
Validation Done: [149312/154214]
Validation Done: [149376/154214]
Validation Done: [149440/154214]
Validation Done: [149504/154214]
Validation Done: [149568/154214]
Validation Done: [149632/154214]
Validation Done: [149696/154214]
Validation Done: [149760/154214]
Validation Done: [149824/154214]
Validation Done: [149888/154214]
Validation Done: [149952/154214]
Validation Done: [150016/154214]
Validation Done: [150080/154214]
Validation Done: [150144/154214]
Validation Done: [150208/154214]
Validation Done: [150272/154214]
Validation Done: [150336/154214]
Validation Done: [150400/154214]
Validation Done: [150464/154214]
Validation Done: [150528/154214]
Validation Done: [150592/154214]
Validation Done: [150656/154214]
Validation Done: [150720/154214]
Validation Done: [150784/154214]
Validation Done: [150848/154214]
Validation Done: [150912/154214]
Validation Done: [150976/154214]
Validation Done: [151040/154214]
Validation Done: [151104/154214]
Validation Done: [151168/154214]
Validation Done: [151232/154214]
Validation Done: [151296/154214]
Validation Done: [151360/154214]
Validation Done: [151424/154214]
Validation Done: [151488/154214]
Validation Done: [151552/154214]
Validation Done: [151616/154214]
Validation Done: [151680/154214]
Validation Done: [151744/154214]
Validation Done: [151808/154214]
Validation Done: [151872/154214]
Validation Done: [151936/154214]
Validation Done: [152000/154214]
Validation Done: [152064/154214]
Validation Done: [152128/154214]
Validation Done: [152192/154214]
Validation Done: [152256/154214]
Validation Done: [152320/154214]
Validation Done: [152384/154214]
Validation Done: [152448/154214]
Validation Done: [152512/154214]
Validation Done: [152576/154214]
Validation Done: [152640/154214]
Validation Done: [152704/154214]
Validation Done: [152768/154214]
Validation Done: [152832/154214]
Validation Done: [152896/154214]
Validation Done: [152960/154214]
Validation Done: [153024/154214]
Validation Done: [153088/154214]
Validation Done: [153152/154214]
Validation Done: [153216/154214]
Validation Done: [153280/154214]
Validation Done: [153344/154214]
Validation Done: [153408/154214]
Validation Done: [153472/154214]
Validation Done: [153536/154214]
Validation Done: [153600/154214]
Validation Done: [153664/154214]
Validation Done: [153728/154214]
Validation Done: [153792/154214]
Validation Done: [153856/154214]
Validation Done: [153920/154214]
Validation Done: [153984/154214]
Validation Done: [154048/154214]
Validation Done: [154112/154214]
Validation Done: [154176/154214]
Validation Done: [91580/154214]
[Test] Epoch: 3 Test set: Average loss: 0.0083, Accuracy: 121743/154214 (78.94%)
{'KIRC': {'recall': 0.8635803020824023, 'support': 55945, 'precision': 0.7582672839990583, 'f1-score': 0.807504596356343}, 'weighted avg': {'recall': 0.789441944311152, 'support': 154214, 'precision': 0.7961183731176745, 'f1-score': 0.789321604672304}, 'KICH': {'recall': 0.7336766220391349, 'support': 58260, 'precision': 0.8692751972667372, 'f1-score': 0.7957405614714423}, 'accuracy': 0.789441944311152, 'macro avg': {'recall': 0.7880781180665899, 'support': 154214, 'precision': 0.7900198266127191, 'f1-score': 0.785931396335697}, 'KIRP': {'recall': 0.7669774300782324, 'support': 40009, 'precision': 0.7425169985723619, 'f1-score': 0.7545490311793056}}
[Train] Epoch: 4 [64/620022]    Loss: 0.009145   Batch Acc: 79.69
[Train] Epoch: 4 [128/620022]    Loss: 0.009382   Batch Acc: 84.38
[Train] Epoch: 4 [192/620022]    Loss: 0.009636   Batch Acc: 67.19
[Train] Epoch: 4 [256/620022]    Loss: 0.007050   Batch Acc: 87.50
[Train] Epoch: 4 [320/620022]    Loss: 0.007763   Batch Acc: 79.69
[Train] Epoch: 4 [384/620022]    Loss: 0.010441   Batch Acc: 67.19
[Train] Epoch: 4 [448/620022]    Loss: 0.008592   Batch Acc: 79.69
[Train] Epoch: 4 [512/620022]    Loss: 0.009572   Batch Acc: 76.56
[Train] Epoch: 4 [576/620022]    Loss: 0.007769   Batch Acc: 84.38
[Train] Epoch: 4 [640/620022]    Loss: 0.007151   Batch Acc: 85.94
[Train] Epoch: 4 [704/620022]    Loss: 0.007325   Batch Acc: 79.69
[Train] Epoch: 4 [768/620022]    Loss: 0.009728   Batch Acc: 67.19
[Train] Epoch: 4 [832/620022]    Loss: 0.006927   Batch Acc: 84.38
[Train] Epoch: 4 [896/620022]    Loss: 0.008724   Batch Acc: 76.56
[Train] Epoch: 4 [960/620022]    Loss: 0.010123   Batch Acc: 70.31
[Train] Epoch: 4 [1024/620022]    Loss: 0.008792   Batch Acc: 79.69
[Train] Epoch: 4 [1088/620022]    Loss: 0.008666   Batch Acc: 70.31
[Train] Epoch: 4 [1152/620022]    Loss: 0.009703   Batch Acc: 78.12
[Train] Epoch: 4 [1216/620022]    Loss: 0.007385   Batch Acc: 81.25
[Train] Epoch: 4 [1280/620022]    Loss: 0.009541   Batch Acc: 71.88
[Train] Epoch: 4 [1344/620022]    Loss: 0.010740   Batch Acc: 68.75
[Train] Epoch: 4 [1408/620022]    Loss: 0.007795   Batch Acc: 81.25
[Train] Epoch: 4 [1472/620022]    Loss: 0.008154   Batch Acc: 79.69
[Train] Epoch: 4 [1536/620022]    Loss: 0.007346   Batch Acc: 82.81
[Train] Epoch: 4 [1600/620022]    Loss: 0.007215   Batch Acc: 79.69
[Train] Epoch: 4 [1664/620022]    Loss: 0.011269   Batch Acc: 71.88
[Train] Epoch: 4 [1728/620022]    Loss: 0.007835   Batch Acc: 78.12
[Train] Epoch: 4 [1792/620022]    Loss: 0.008675   Batch Acc: 73.44
[Train] Epoch: 4 [1856/620022]    Loss: 0.011967   Batch Acc: 67.19
[Train] Epoch: 4 [1920/620022]    Loss: 0.007305   Batch Acc: 85.94
[Train] Epoch: 4 [1984/620022]    Loss: 0.006219   Batch Acc: 87.50
[Train] Epoch: 4 [2048/620022]    Loss: 0.007880   Batch Acc: 79.69
[Train] Epoch: 4 [2112/620022]    Loss: 0.010410   Batch Acc: 73.44
[Train] Epoch: 4 [2176/620022]    Loss: 0.009426   Batch Acc: 76.56
[Train] Epoch: 4 [2240/620022]    Loss: 0.008546   Batch Acc: 81.25
[Train] Epoch: 4 [2304/620022]    Loss: 0.009065   Batch Acc: 76.56
[Train] Epoch: 4 [2368/620022]    Loss: 0.007150   Batch Acc: 81.25
[Train] Epoch: 4 [2432/620022]    Loss: 0.009955   Batch Acc: 68.75
[Train] Epoch: 4 [2496/620022]    Loss: 0.009199   Batch Acc: 75.00
[Train] Epoch: 4 [2560/620022]    Loss: 0.007127   Batch Acc: 82.81
[Train] Epoch: 4 [2624/620022]    Loss: 0.008649   Batch Acc: 79.69
[Train] Epoch: 4 [2688/620022]    Loss: 0.008533   Batch Acc: 81.25
[Train] Epoch: 4 [2752/620022]    Loss: 0.008973   Batch Acc: 78.12
[Train] Epoch: 4 [2816/620022]    Loss: 0.007988   Batch Acc: 82.81
[Train] Epoch: 4 [2880/620022]    Loss: 0.009521   Batch Acc: 75.00
[Train] Epoch: 4 [2944/620022]    Loss: 0.010017   Batch Acc: 75.00
[Train] Epoch: 4 [3008/620022]    Loss: 0.009195   Batch Acc: 75.00
[Train] Epoch: 4 [3072/620022]    Loss: 0.009307   Batch Acc: 76.56
[Train] Epoch: 4 [3136/620022]    Loss: 0.006421   Batch Acc: 84.38
[Train] Epoch: 4 [3200/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 4 [3264/620022]    Loss: 0.009301   Batch Acc: 79.69
[Train] Epoch: 4 [3328/620022]    Loss: 0.007842   Batch Acc: 78.12
[Train] Epoch: 4 [3392/620022]    Loss: 0.008223   Batch Acc: 78.12
[Train] Epoch: 4 [3456/620022]    Loss: 0.009923   Batch Acc: 76.56
[Train] Epoch: 4 [3520/620022]    Loss: 0.006708   Batch Acc: 85.94
[Train] Epoch: 4 [3584/620022]    Loss: 0.007817   Batch Acc: 81.25
[Train] Epoch: 4 [3648/620022]    Loss: 0.008137   Batch Acc: 82.81
[Train] Epoch: 4 [3712/620022]    Loss: 0.010348   Batch Acc: 70.31
[Train] Epoch: 4 [3776/620022]    Loss: 0.007261   Batch Acc: 82.81
[Train] Epoch: 4 [3840/620022]    Loss: 0.008319   Batch Acc: 78.12
[Train] Epoch: 4 [3904/620022]    Loss: 0.007714   Batch Acc: 81.25
[Train] Epoch: 4 [3968/620022]    Loss: 0.007912   Batch Acc: 79.69
[Train] Epoch: 4 [4032/620022]    Loss: 0.009661   Batch Acc: 76.56
[Train] Epoch: 4 [4096/620022]    Loss: 0.008075   Batch Acc: 84.38
[Train] Epoch: 4 [4160/620022]    Loss: 0.008852   Batch Acc: 78.12
[Train] Epoch: 4 [4224/620022]    Loss: 0.009304   Batch Acc: 79.69
[Train] Epoch: 4 [4288/620022]    Loss: 0.009208   Batch Acc: 78.12
[Train] Epoch: 4 [4352/620022]    Loss: 0.008494   Batch Acc: 78.12
[Train] Epoch: 4 [4416/620022]    Loss: 0.009242   Batch Acc: 78.12
[Train] Epoch: 4 [4480/620022]    Loss: 0.007985   Batch Acc: 84.38
[Train] Epoch: 4 [4544/620022]    Loss: 0.007794   Batch Acc: 82.81
[Train] Epoch: 4 [4608/620022]    Loss: 0.007729   Batch Acc: 76.56
[Train] Epoch: 4 [4672/620022]    Loss: 0.007989   Batch Acc: 78.12
[Train] Epoch: 4 [4736/620022]    Loss: 0.007515   Batch Acc: 81.25
[Train] Epoch: 4 [4800/620022]    Loss: 0.010349   Batch Acc: 67.19
[Train] Epoch: 4 [4864/620022]    Loss: 0.007303   Batch Acc: 82.81
[Train] Epoch: 4 [4928/620022]    Loss: 0.008808   Batch Acc: 73.44
[Train] Epoch: 4 [4992/620022]    Loss: 0.009136   Batch Acc: 67.19
[Train] Epoch: 4 [5056/620022]    Loss: 0.009040   Batch Acc: 79.69
[Train] Epoch: 4 [5120/620022]    Loss: 0.007758   Batch Acc: 84.38
[Train] Epoch: 4 [5184/620022]    Loss: 0.010807   Batch Acc: 65.62
[Train] Epoch: 4 [5248/620022]    Loss: 0.008974   Batch Acc: 78.12
[Train] Epoch: 4 [5312/620022]    Loss: 0.009334   Batch Acc: 73.44
[Train] Epoch: 4 [5376/620022]    Loss: 0.008468   Batch Acc: 75.00
[Train] Epoch: 4 [5440/620022]    Loss: 0.009304   Batch Acc: 75.00
[Train] Epoch: 4 [5504/620022]    Loss: 0.008771   Batch Acc: 76.56
[Train] Epoch: 4 [5568/620022]    Loss: 0.007690   Batch Acc: 79.69
[Train] Epoch: 4 [5632/620022]    Loss: 0.006814   Batch Acc: 87.50
[Train] Epoch: 4 [5696/620022]    Loss: 0.008094   Batch Acc: 73.44
[Train] Epoch: 4 [5760/620022]    Loss: 0.008585   Batch Acc: 79.69
[Train] Epoch: 4 [5824/620022]    Loss: 0.009358   Batch Acc: 78.12
[Train] Epoch: 4 [5888/620022]    Loss: 0.008965   Batch Acc: 82.81
[Train] Epoch: 4 [5952/620022]    Loss: 0.007063   Batch Acc: 82.81
[Train] Epoch: 4 [6016/620022]    Loss: 0.008501   Batch Acc: 78.12
[Train] Epoch: 4 [6080/620022]    Loss: 0.006049   Batch Acc: 90.62
[Train] Epoch: 4 [6144/620022]    Loss: 0.007161   Batch Acc: 82.81
[Train] Epoch: 4 [6208/620022]    Loss: 0.010361   Batch Acc: 71.88
[Train] Epoch: 4 [6272/620022]    Loss: 0.008440   Batch Acc: 75.00
[Train] Epoch: 4 [6336/620022]    Loss: 0.009187   Batch Acc: 78.12
[Train] Epoch: 4 [6400/620022]    Loss: 0.007529   Batch Acc: 81.25
[Train] Epoch: 4 [6464/620022]    Loss: 0.010009   Batch Acc: 73.44
[Train] Epoch: 4 [6528/620022]    Loss: 0.008700   Batch Acc: 76.56
[Train] Epoch: 4 [6592/620022]    Loss: 0.008566   Batch Acc: 78.12
[Train] Epoch: 4 [6656/620022]    Loss: 0.010230   Batch Acc: 73.44
[Train] Epoch: 4 [6720/620022]    Loss: 0.009683   Batch Acc: 78.12
[Train] Epoch: 4 [6784/620022]    Loss: 0.008827   Batch Acc: 76.56
[Train] Epoch: 4 [6848/620022]    Loss: 0.009139   Batch Acc: 73.44
[Train] Epoch: 4 [6912/620022]    Loss: 0.006163   Batch Acc: 92.19
[Train] Epoch: 4 [6976/620022]    Loss: 0.010690   Batch Acc: 65.62
[Train] Epoch: 4 [7040/620022]    Loss: 0.009340   Batch Acc: 75.00
[Train] Epoch: 4 [7104/620022]    Loss: 0.008616   Batch Acc: 76.56
[Train] Epoch: 4 [7168/620022]    Loss: 0.007649   Batch Acc: 73.44
[Train] Epoch: 4 [7232/620022]    Loss: 0.007788   Batch Acc: 81.25
[Train] Epoch: 4 [7296/620022]    Loss: 0.006840   Batch Acc: 84.38
[Train] Epoch: 4 [7360/620022]    Loss: 0.008499   Batch Acc: 78.12
[Train] Epoch: 4 [7424/620022]    Loss: 0.007531   Batch Acc: 85.94
[Train] Epoch: 4 [7488/620022]    Loss: 0.010253   Batch Acc: 70.31
[Train] Epoch: 4 [7552/620022]    Loss: 0.009280   Batch Acc: 76.56
[Train] Epoch: 4 [7616/620022]    Loss: 0.008931   Batch Acc: 78.12
[Train] Epoch: 4 [7680/620022]    Loss: 0.011239   Batch Acc: 59.38
[Train] Epoch: 4 [7744/620022]    Loss: 0.006295   Batch Acc: 85.94
[Train] Epoch: 4 [7808/620022]    Loss: 0.008708   Batch Acc: 81.25
[Train] Epoch: 4 [7872/620022]    Loss: 0.008608   Batch Acc: 73.44
[Train] Epoch: 4 [7936/620022]    Loss: 0.010293   Batch Acc: 76.56
[Train] Epoch: 4 [8000/620022]    Loss: 0.007043   Batch Acc: 79.69
[Train] Epoch: 4 [8064/620022]    Loss: 0.007854   Batch Acc: 73.44
[Train] Epoch: 4 [8128/620022]    Loss: 0.007495   Batch Acc: 84.38
[Train] Epoch: 4 [8192/620022]    Loss: 0.008780   Batch Acc: 76.56
[Train] Epoch: 4 [8256/620022]    Loss: 0.008546   Batch Acc: 78.12
[Train] Epoch: 4 [8320/620022]    Loss: 0.009423   Batch Acc: 76.56
[Train] Epoch: 4 [8384/620022]    Loss: 0.009967   Batch Acc: 68.75
[Train] Epoch: 4 [8448/620022]    Loss: 0.008109   Batch Acc: 78.12
[Train] Epoch: 4 [8512/620022]    Loss: 0.009793   Batch Acc: 76.56
[Train] Epoch: 4 [8576/620022]    Loss: 0.008083   Batch Acc: 79.69
[Train] Epoch: 4 [8640/620022]    Loss: 0.009781   Batch Acc: 76.56
[Train] Epoch: 4 [8704/620022]    Loss: 0.010807   Batch Acc: 73.44
[Train] Epoch: 4 [8768/620022]    Loss: 0.008181   Batch Acc: 79.69
[Train] Epoch: 4 [8832/620022]    Loss: 0.010858   Batch Acc: 76.56
[Train] Epoch: 4 [8896/620022]    Loss: 0.006814   Batch Acc: 84.38
[Train] Epoch: 4 [8960/620022]    Loss: 0.008141   Batch Acc: 78.12
[Train] Epoch: 4 [9024/620022]    Loss: 0.009453   Batch Acc: 75.00
[Train] Epoch: 4 [9088/620022]    Loss: 0.010346   Batch Acc: 68.75
[Train] Epoch: 4 [9152/620022]    Loss: 0.007515   Batch Acc: 81.25
[Train] Epoch: 4 [9216/620022]    Loss: 0.008968   Batch Acc: 78.12
[Train] Epoch: 4 [9280/620022]    Loss: 0.009564   Batch Acc: 71.88
[Train] Epoch: 4 [9344/620022]    Loss: 0.008180   Batch Acc: 82.81
[Train] Epoch: 4 [9408/620022]    Loss: 0.008277   Batch Acc: 81.25
[Train] Epoch: 4 [9472/620022]    Loss: 0.008163   Batch Acc: 82.81
[Train] Epoch: 4 [9536/620022]    Loss: 0.005886   Batch Acc: 90.62
[Train] Epoch: 4 [9600/620022]    Loss: 0.009269   Batch Acc: 75.00
[Train] Epoch: 4 [9664/620022]    Loss: 0.008332   Batch Acc: 79.69
[Train] Epoch: 4 [9728/620022]    Loss: 0.007246   Batch Acc: 82.81
[Train] Epoch: 4 [9792/620022]    Loss: 0.009209   Batch Acc: 78.12
[Train] Epoch: 4 [9856/620022]    Loss: 0.010112   Batch Acc: 67.19
[Train] Epoch: 4 [9920/620022]    Loss: 0.009350   Batch Acc: 76.56
[Train] Epoch: 4 [9984/620022]    Loss: 0.008211   Batch Acc: 81.25
[Train] Epoch: 4 [10048/620022]    Loss: 0.009469   Batch Acc: 76.56
[Train] Epoch: 4 [10112/620022]    Loss: 0.007624   Batch Acc: 84.38
[Train] Epoch: 4 [10176/620022]    Loss: 0.009744   Batch Acc: 76.56
[Train] Epoch: 4 [10240/620022]    Loss: 0.007394   Batch Acc: 85.94
[Train] Epoch: 4 [10304/620022]    Loss: 0.009971   Batch Acc: 73.44
[Train] Epoch: 4 [10368/620022]    Loss: 0.009639   Batch Acc: 70.31
[Train] Epoch: 4 [10432/620022]    Loss: 0.009269   Batch Acc: 73.44
[Train] Epoch: 4 [10496/620022]    Loss: 0.007533   Batch Acc: 75.00
[Train] Epoch: 4 [10560/620022]    Loss: 0.006871   Batch Acc: 85.94
[Train] Epoch: 4 [10624/620022]    Loss: 0.007813   Batch Acc: 73.44
[Train] Epoch: 4 [10688/620022]    Loss: 0.008127   Batch Acc: 84.38
[Train] Epoch: 4 [10752/620022]    Loss: 0.008980   Batch Acc: 79.69
[Train] Epoch: 4 [10816/620022]    Loss: 0.008130   Batch Acc: 82.81
[Train] Epoch: 4 [10880/620022]    Loss: 0.010384   Batch Acc: 70.31
[Train] Epoch: 4 [10944/620022]    Loss: 0.008027   Batch Acc: 76.56
[Train] Epoch: 4 [11008/620022]    Loss: 0.008691   Batch Acc: 79.69
[Train] Epoch: 4 [11072/620022]    Loss: 0.008938   Batch Acc: 78.12
[Train] Epoch: 4 [11136/620022]    Loss: 0.011203   Batch Acc: 73.44
[Train] Epoch: 4 [11200/620022]    Loss: 0.007280   Batch Acc: 81.25
[Train] Epoch: 4 [11264/620022]    Loss: 0.008209   Batch Acc: 81.25
[Train] Epoch: 4 [11328/620022]    Loss: 0.008681   Batch Acc: 78.12
[Train] Epoch: 4 [11392/620022]    Loss: 0.006086   Batch Acc: 84.38
[Train] Epoch: 4 [11456/620022]    Loss: 0.011366   Batch Acc: 73.44
[Train] Epoch: 4 [11520/620022]    Loss: 0.009043   Batch Acc: 75.00
[Train] Epoch: 4 [11584/620022]    Loss: 0.009631   Batch Acc: 76.56
[Train] Epoch: 4 [11648/620022]    Loss: 0.006783   Batch Acc: 84.38
[Train] Epoch: 4 [11712/620022]    Loss: 0.009418   Batch Acc: 73.44
[Train] Epoch: 4 [11776/620022]    Loss: 0.008514   Batch Acc: 81.25
[Train] Epoch: 4 [11840/620022]    Loss: 0.008178   Batch Acc: 76.56
[Train] Epoch: 4 [11904/620022]    Loss: 0.008847   Batch Acc: 75.00
[Train] Epoch: 4 [11968/620022]    Loss: 0.008665   Batch Acc: 79.69
[Train] Epoch: 4 [12032/620022]    Loss: 0.009664   Batch Acc: 71.88
[Train] Epoch: 4 [12096/620022]    Loss: 0.008973   Batch Acc: 71.88
[Train] Epoch: 4 [12160/620022]    Loss: 0.007398   Batch Acc: 82.81
[Train] Epoch: 4 [12224/620022]    Loss: 0.008168   Batch Acc: 79.69
[Train] Epoch: 4 [12288/620022]    Loss: 0.009731   Batch Acc: 81.25
[Train] Epoch: 4 [12352/620022]    Loss: 0.007955   Batch Acc: 76.56
[Train] Epoch: 4 [12416/620022]    Loss: 0.008059   Batch Acc: 82.81
[Train] Epoch: 4 [12480/620022]    Loss: 0.009965   Batch Acc: 71.88
[Train] Epoch: 4 [12544/620022]    Loss: 0.007866   Batch Acc: 81.25
[Train] Epoch: 4 [12608/620022]    Loss: 0.008381   Batch Acc: 79.69
[Train] Epoch: 4 [12672/620022]    Loss: 0.005083   Batch Acc: 92.19
[Train] Epoch: 4 [12736/620022]    Loss: 0.008447   Batch Acc: 78.12
[Train] Epoch: 4 [12800/620022]    Loss: 0.005605   Batch Acc: 90.62
[Train] Epoch: 4 [12864/620022]    Loss: 0.007326   Batch Acc: 85.94
[Train] Epoch: 4 [12928/620022]    Loss: 0.008941   Batch Acc: 79.69
[Train] Epoch: 4 [12992/620022]    Loss: 0.009314   Batch Acc: 79.69
[Train] Epoch: 4 [13056/620022]    Loss: 0.008650   Batch Acc: 81.25
[Train] Epoch: 4 [13120/620022]    Loss: 0.010856   Batch Acc: 76.56
[Train] Epoch: 4 [13184/620022]    Loss: 0.008270   Batch Acc: 81.25
[Train] Epoch: 4 [13248/620022]    Loss: 0.007446   Batch Acc: 81.25
[Train] Epoch: 4 [13312/620022]    Loss: 0.010457   Batch Acc: 73.44
[Train] Epoch: 4 [13376/620022]    Loss: 0.006534   Batch Acc: 87.50
[Train] Epoch: 4 [13440/620022]    Loss: 0.007503   Batch Acc: 84.38
[Train] Epoch: 4 [13504/620022]    Loss: 0.007345   Batch Acc: 82.81
[Train] Epoch: 4 [13568/620022]    Loss: 0.008367   Batch Acc: 76.56
[Train] Epoch: 4 [13632/620022]    Loss: 0.007904   Batch Acc: 87.50
[Train] Epoch: 4 [13696/620022]    Loss: 0.009884   Batch Acc: 75.00
[Train] Epoch: 4 [13760/620022]    Loss: 0.008118   Batch Acc: 79.69
[Train] Epoch: 4 [13824/620022]    Loss: 0.006403   Batch Acc: 89.06
[Train] Epoch: 4 [13888/620022]    Loss: 0.006448   Batch Acc: 87.50
[Train] Epoch: 4 [13952/620022]    Loss: 0.008974   Batch Acc: 78.12
[Train] Epoch: 4 [14016/620022]    Loss: 0.008588   Batch Acc: 82.81
[Train] Epoch: 4 [14080/620022]    Loss: 0.010870   Batch Acc: 67.19
[Train] Epoch: 4 [14144/620022]    Loss: 0.011003   Batch Acc: 73.44
[Train] Epoch: 4 [14208/620022]    Loss: 0.007578   Batch Acc: 82.81
[Train] Epoch: 4 [14272/620022]    Loss: 0.007970   Batch Acc: 78.12
[Train] Epoch: 4 [14336/620022]    Loss: 0.009232   Batch Acc: 78.12
[Train] Epoch: 4 [14400/620022]    Loss: 0.008733   Batch Acc: 78.12
[Train] Epoch: 4 [14464/620022]    Loss: 0.008311   Batch Acc: 79.69
[Train] Epoch: 4 [14528/620022]    Loss: 0.006231   Batch Acc: 84.38
[Train] Epoch: 4 [14592/620022]    Loss: 0.010653   Batch Acc: 71.88
[Train] Epoch: 4 [14656/620022]    Loss: 0.009912   Batch Acc: 73.44
[Train] Epoch: 4 [14720/620022]    Loss: 0.009885   Batch Acc: 73.44
[Train] Epoch: 4 [14784/620022]    Loss: 0.012715   Batch Acc: 67.19
[Train] Epoch: 4 [14848/620022]    Loss: 0.009650   Batch Acc: 68.75
[Train] Epoch: 4 [14912/620022]    Loss: 0.008731   Batch Acc: 76.56
[Train] Epoch: 4 [14976/620022]    Loss: 0.010510   Batch Acc: 70.31
[Train] Epoch: 4 [15040/620022]    Loss: 0.009963   Batch Acc: 73.44
[Train] Epoch: 4 [15104/620022]    Loss: 0.007664   Batch Acc: 76.56
[Train] Epoch: 4 [15168/620022]    Loss: 0.007991   Batch Acc: 79.69
[Train] Epoch: 4 [15232/620022]    Loss: 0.007561   Batch Acc: 84.38
[Train] Epoch: 4 [15296/620022]    Loss: 0.008998   Batch Acc: 78.12
[Train] Epoch: 4 [15360/620022]    Loss: 0.008537   Batch Acc: 75.00
[Train] Epoch: 4 [15424/620022]    Loss: 0.008350   Batch Acc: 79.69
[Train] Epoch: 4 [15488/620022]    Loss: 0.006858   Batch Acc: 82.81
[Train] Epoch: 4 [15552/620022]    Loss: 0.008711   Batch Acc: 78.12
[Train] Epoch: 4 [15616/620022]    Loss: 0.006421   Batch Acc: 87.50
[Train] Epoch: 4 [15680/620022]    Loss: 0.010933   Batch Acc: 78.12
[Train] Epoch: 4 [15744/620022]    Loss: 0.007696   Batch Acc: 81.25
[Train] Epoch: 4 [15808/620022]    Loss: 0.007108   Batch Acc: 82.81
[Train] Epoch: 4 [15872/620022]    Loss: 0.008756   Batch Acc: 81.25
[Train] Epoch: 4 [15936/620022]    Loss: 0.005695   Batch Acc: 90.62
[Train] Epoch: 4 [16000/620022]    Loss: 0.007567   Batch Acc: 84.38
[Train] Epoch: 4 [16064/620022]    Loss: 0.009349   Batch Acc: 75.00
[Train] Epoch: 4 [16128/620022]    Loss: 0.009614   Batch Acc: 75.00
[Train] Epoch: 4 [16192/620022]    Loss: 0.008938   Batch Acc: 76.56
[Train] Epoch: 4 [16256/620022]    Loss: 0.009661   Batch Acc: 78.12
[Train] Epoch: 4 [16320/620022]    Loss: 0.008509   Batch Acc: 82.81
[Train] Epoch: 4 [16384/620022]    Loss: 0.007388   Batch Acc: 82.81
[Train] Epoch: 4 [16448/620022]    Loss: 0.008614   Batch Acc: 76.56
[Train] Epoch: 4 [16512/620022]    Loss: 0.010008   Batch Acc: 65.62
[Train] Epoch: 4 [16576/620022]    Loss: 0.008339   Batch Acc: 84.38
[Train] Epoch: 4 [16640/620022]    Loss: 0.010257   Batch Acc: 73.44
[Train] Epoch: 4 [16704/620022]    Loss: 0.008841   Batch Acc: 76.56
[Train] Epoch: 4 [16768/620022]    Loss: 0.007346   Batch Acc: 87.50
[Train] Epoch: 4 [16832/620022]    Loss: 0.008604   Batch Acc: 73.44
[Train] Epoch: 4 [16896/620022]    Loss: 0.008074   Batch Acc: 78.12
[Train] Epoch: 4 [16960/620022]    Loss: 0.008608   Batch Acc: 81.25
[Train] Epoch: 4 [17024/620022]    Loss: 0.008001   Batch Acc: 78.12
[Train] Epoch: 4 [17088/620022]    Loss: 0.008099   Batch Acc: 81.25
[Train] Epoch: 4 [17152/620022]    Loss: 0.007952   Batch Acc: 78.12
[Train] Epoch: 4 [17216/620022]    Loss: 0.006442   Batch Acc: 81.25
[Train] Epoch: 4 [17280/620022]    Loss: 0.006592   Batch Acc: 85.94
[Train] Epoch: 4 [17344/620022]    Loss: 0.011944   Batch Acc: 70.31
[Train] Epoch: 4 [17408/620022]    Loss: 0.007717   Batch Acc: 73.44
[Train] Epoch: 4 [17472/620022]    Loss: 0.009225   Batch Acc: 76.56
[Train] Epoch: 4 [17536/620022]    Loss: 0.008299   Batch Acc: 82.81
[Train] Epoch: 4 [17600/620022]    Loss: 0.006057   Batch Acc: 87.50
[Train] Epoch: 4 [17664/620022]    Loss: 0.008504   Batch Acc: 76.56
[Train] Epoch: 4 [17728/620022]    Loss: 0.009392   Batch Acc: 71.88
[Train] Epoch: 4 [17792/620022]    Loss: 0.006585   Batch Acc: 81.25
[Train] Epoch: 4 [17856/620022]    Loss: 0.007304   Batch Acc: 87.50
[Train] Epoch: 4 [17920/620022]    Loss: 0.007059   Batch Acc: 85.94
[Train] Epoch: 4 [17984/620022]    Loss: 0.008759   Batch Acc: 78.12
[Train] Epoch: 4 [18048/620022]    Loss: 0.009951   Batch Acc: 76.56
[Train] Epoch: 4 [18112/620022]    Loss: 0.008173   Batch Acc: 81.25
[Train] Epoch: 4 [18176/620022]    Loss: 0.010619   Batch Acc: 71.88
[Train] Epoch: 4 [18240/620022]    Loss: 0.008752   Batch Acc: 78.12
[Train] Epoch: 4 [18304/620022]    Loss: 0.009643   Batch Acc: 76.56
[Train] Epoch: 4 [18368/620022]    Loss: 0.008225   Batch Acc: 81.25
[Train] Epoch: 4 [18432/620022]    Loss: 0.010479   Batch Acc: 68.75
[Train] Epoch: 4 [18496/620022]    Loss: 0.006982   Batch Acc: 85.94
[Train] Epoch: 4 [18560/620022]    Loss: 0.010030   Batch Acc: 78.12
[Train] Epoch: 4 [18624/620022]    Loss: 0.007334   Batch Acc: 84.38
[Train] Epoch: 4 [18688/620022]    Loss: 0.007946   Batch Acc: 78.12
[Train] Epoch: 4 [18752/620022]    Loss: 0.008572   Batch Acc: 81.25
[Train] Epoch: 4 [18816/620022]    Loss: 0.012030   Batch Acc: 67.19
[Train] Epoch: 4 [18880/620022]    Loss: 0.008019   Batch Acc: 82.81
[Train] Epoch: 4 [18944/620022]    Loss: 0.008841   Batch Acc: 76.56
[Train] Epoch: 4 [19008/620022]    Loss: 0.008451   Batch Acc: 75.00
[Train] Epoch: 4 [19072/620022]    Loss: 0.007203   Batch Acc: 84.38
[Train] Epoch: 4 [19136/620022]    Loss: 0.006729   Batch Acc: 84.38
[Train] Epoch: 4 [19200/620022]    Loss: 0.009588   Batch Acc: 75.00
[Train] Epoch: 4 [19264/620022]    Loss: 0.009852   Batch Acc: 73.44
[Train] Epoch: 4 [19328/620022]    Loss: 0.011230   Batch Acc: 68.75
[Train] Epoch: 4 [19392/620022]    Loss: 0.012003   Batch Acc: 68.75
[Train] Epoch: 4 [19456/620022]    Loss: 0.008996   Batch Acc: 73.44
[Train] Epoch: 4 [19520/620022]    Loss: 0.006513   Batch Acc: 82.81
[Train] Epoch: 4 [19584/620022]    Loss: 0.008704   Batch Acc: 76.56
[Train] Epoch: 4 [19648/620022]    Loss: 0.005714   Batch Acc: 89.06
[Train] Epoch: 4 [19712/620022]    Loss: 0.008339   Batch Acc: 73.44
[Train] Epoch: 4 [19776/620022]    Loss: 0.008931   Batch Acc: 79.69
[Train] Epoch: 4 [19840/620022]    Loss: 0.008103   Batch Acc: 84.38
[Train] Epoch: 4 [19904/620022]    Loss: 0.009486   Batch Acc: 73.44
[Train] Epoch: 4 [19968/620022]    Loss: 0.009122   Batch Acc: 76.56
[Train] Epoch: 4 [20032/620022]    Loss: 0.006840   Batch Acc: 81.25
[Train] Epoch: 4 [20096/620022]    Loss: 0.009454   Batch Acc: 81.25
[Train] Epoch: 4 [20160/620022]    Loss: 0.008216   Batch Acc: 73.44
[Train] Epoch: 4 [20224/620022]    Loss: 0.009260   Batch Acc: 76.56
[Train] Epoch: 4 [20288/620022]    Loss: 0.008743   Batch Acc: 78.12
[Train] Epoch: 4 [20352/620022]    Loss: 0.009511   Batch Acc: 70.31
[Train] Epoch: 4 [20416/620022]    Loss: 0.009450   Batch Acc: 78.12
[Train] Epoch: 4 [20480/620022]    Loss: 0.011454   Batch Acc: 68.75
[Train] Epoch: 4 [20544/620022]    Loss: 0.007201   Batch Acc: 81.25
[Train] Epoch: 4 [20608/620022]    Loss: 0.008806   Batch Acc: 70.31
[Train] Epoch: 4 [20672/620022]    Loss: 0.005952   Batch Acc: 89.06
[Train] Epoch: 4 [20736/620022]    Loss: 0.009772   Batch Acc: 81.25
[Train] Epoch: 4 [20800/620022]    Loss: 0.007139   Batch Acc: 84.38
[Train] Epoch: 4 [20864/620022]    Loss: 0.010723   Batch Acc: 71.88
[Train] Epoch: 4 [20928/620022]    Loss: 0.008387   Batch Acc: 84.38
[Train] Epoch: 4 [20992/620022]    Loss: 0.008303   Batch Acc: 78.12
[Train] Epoch: 4 [21056/620022]    Loss: 0.008022   Batch Acc: 79.69
[Train] Epoch: 4 [21120/620022]    Loss: 0.009469   Batch Acc: 73.44
[Train] Epoch: 4 [21184/620022]    Loss: 0.007522   Batch Acc: 81.25
[Train] Epoch: 4 [21248/620022]    Loss: 0.009564   Batch Acc: 76.56
[Train] Epoch: 4 [21312/620022]    Loss: 0.007910   Batch Acc: 78.12
[Train] Epoch: 4 [21376/620022]    Loss: 0.006959   Batch Acc: 84.38
[Train] Epoch: 4 [21440/620022]    Loss: 0.006565   Batch Acc: 89.06
[Train] Epoch: 4 [21504/620022]    Loss: 0.007807   Batch Acc: 79.69
[Train] Epoch: 4 [21568/620022]    Loss: 0.007098   Batch Acc: 84.38
[Train] Epoch: 4 [21632/620022]    Loss: 0.010098   Batch Acc: 76.56
[Train] Epoch: 4 [21696/620022]    Loss: 0.009697   Batch Acc: 75.00
[Train] Epoch: 4 [21760/620022]    Loss: 0.010669   Batch Acc: 73.44
[Train] Epoch: 4 [21824/620022]    Loss: 0.008505   Batch Acc: 73.44
[Train] Epoch: 4 [21888/620022]    Loss: 0.009212   Batch Acc: 71.88
[Train] Epoch: 4 [21952/620022]    Loss: 0.010106   Batch Acc: 73.44
[Train] Epoch: 4 [22016/620022]    Loss: 0.009040   Batch Acc: 84.38
[Train] Epoch: 4 [22080/620022]    Loss: 0.009184   Batch Acc: 71.88
[Train] Epoch: 4 [22144/620022]    Loss: 0.006968   Batch Acc: 84.38
[Train] Epoch: 4 [22208/620022]    Loss: 0.007810   Batch Acc: 81.25
[Train] Epoch: 4 [22272/620022]    Loss: 0.009315   Batch Acc: 79.69
[Train] Epoch: 4 [22336/620022]    Loss: 0.006864   Batch Acc: 84.38
[Train] Epoch: 4 [22400/620022]    Loss: 0.009495   Batch Acc: 75.00
[Train] Epoch: 4 [22464/620022]    Loss: 0.009526   Batch Acc: 78.12
[Train] Epoch: 4 [22528/620022]    Loss: 0.007070   Batch Acc: 85.94
[Train] Epoch: 4 [22592/620022]    Loss: 0.007932   Batch Acc: 84.38
[Train] Epoch: 4 [22656/620022]    Loss: 0.008365   Batch Acc: 78.12
[Train] Epoch: 4 [22720/620022]    Loss: 0.008342   Batch Acc: 81.25
[Train] Epoch: 4 [22784/620022]    Loss: 0.009266   Batch Acc: 79.69
[Train] Epoch: 4 [22848/620022]    Loss: 0.007284   Batch Acc: 84.38
[Train] Epoch: 4 [22912/620022]    Loss: 0.009425   Batch Acc: 73.44
[Train] Epoch: 4 [22976/620022]    Loss: 0.008506   Batch Acc: 78.12
[Train] Epoch: 4 [23040/620022]    Loss: 0.009272   Batch Acc: 73.44
[Train] Epoch: 4 [23104/620022]    Loss: 0.007425   Batch Acc: 84.38
[Train] Epoch: 4 [23168/620022]    Loss: 0.008299   Batch Acc: 75.00
[Train] Epoch: 4 [23232/620022]    Loss: 0.008743   Batch Acc: 78.12
[Train] Epoch: 4 [23296/620022]    Loss: 0.008556   Batch Acc: 78.12
[Train] Epoch: 4 [23360/620022]    Loss: 0.009652   Batch Acc: 70.31
[Train] Epoch: 4 [23424/620022]    Loss: 0.011218   Batch Acc: 75.00
[Train] Epoch: 4 [23488/620022]    Loss: 0.009459   Batch Acc: 78.12
[Train] Epoch: 4 [23552/620022]    Loss: 0.008285   Batch Acc: 82.81
[Train] Epoch: 4 [23616/620022]    Loss: 0.007643   Batch Acc: 81.25
[Train] Epoch: 4 [23680/620022]    Loss: 0.007497   Batch Acc: 76.56
[Train] Epoch: 4 [23744/620022]    Loss: 0.010971   Batch Acc: 75.00
[Train] Epoch: 4 [23808/620022]    Loss: 0.008284   Batch Acc: 76.56
[Train] Epoch: 4 [23872/620022]    Loss: 0.009079   Batch Acc: 75.00
[Train] Epoch: 4 [23936/620022]    Loss: 0.010061   Batch Acc: 71.88
[Train] Epoch: 4 [24000/620022]    Loss: 0.007248   Batch Acc: 79.69
[Train] Epoch: 4 [24064/620022]    Loss: 0.009321   Batch Acc: 75.00
[Train] Epoch: 4 [24128/620022]    Loss: 0.008839   Batch Acc: 71.88
[Train] Epoch: 4 [24192/620022]    Loss: 0.007808   Batch Acc: 81.25
[Train] Epoch: 4 [24256/620022]    Loss: 0.008647   Batch Acc: 78.12
[Train] Epoch: 4 [24320/620022]    Loss: 0.008955   Batch Acc: 76.56
[Train] Epoch: 4 [24384/620022]    Loss: 0.008079   Batch Acc: 81.25
[Train] Epoch: 4 [24448/620022]    Loss: 0.008866   Batch Acc: 73.44
[Train] Epoch: 4 [24512/620022]    Loss: 0.007245   Batch Acc: 79.69
[Train] Epoch: 4 [24576/620022]    Loss: 0.008803   Batch Acc: 84.38
[Train] Epoch: 4 [24640/620022]    Loss: 0.007816   Batch Acc: 85.94
[Train] Epoch: 4 [24704/620022]    Loss: 0.009799   Batch Acc: 73.44
[Train] Epoch: 4 [24768/620022]    Loss: 0.011130   Batch Acc: 70.31
[Train] Epoch: 4 [24832/620022]    Loss: 0.010043   Batch Acc: 75.00
[Train] Epoch: 4 [24896/620022]    Loss: 0.010474   Batch Acc: 67.19
[Train] Epoch: 4 [24960/620022]    Loss: 0.009302   Batch Acc: 73.44
[Train] Epoch: 4 [25024/620022]    Loss: 0.010244   Batch Acc: 71.88
[Train] Epoch: 4 [25088/620022]    Loss: 0.007393   Batch Acc: 81.25
[Train] Epoch: 4 [25152/620022]    Loss: 0.007757   Batch Acc: 78.12
[Train] Epoch: 4 [25216/620022]    Loss: 0.009573   Batch Acc: 78.12
[Train] Epoch: 4 [25280/620022]    Loss: 0.009603   Batch Acc: 76.56
[Train] Epoch: 4 [25344/620022]    Loss: 0.008897   Batch Acc: 76.56
[Train] Epoch: 4 [25408/620022]    Loss: 0.008959   Batch Acc: 76.56
[Train] Epoch: 4 [25472/620022]    Loss: 0.010188   Batch Acc: 75.00
[Train] Epoch: 4 [25536/620022]    Loss: 0.006865   Batch Acc: 79.69
[Train] Epoch: 4 [25600/620022]    Loss: 0.009866   Batch Acc: 75.00
[Train] Epoch: 4 [25664/620022]    Loss: 0.008676   Batch Acc: 75.00
[Train] Epoch: 4 [25728/620022]    Loss: 0.009996   Batch Acc: 76.56
[Train] Epoch: 4 [25792/620022]    Loss: 0.009231   Batch Acc: 79.69
[Train] Epoch: 4 [25856/620022]    Loss: 0.008385   Batch Acc: 79.69
[Train] Epoch: 4 [25920/620022]    Loss: 0.008236   Batch Acc: 81.25
[Train] Epoch: 4 [25984/620022]    Loss: 0.008576   Batch Acc: 75.00
[Train] Epoch: 4 [26048/620022]    Loss: 0.008585   Batch Acc: 79.69
[Train] Epoch: 4 [26112/620022]    Loss: 0.006860   Batch Acc: 84.38
[Train] Epoch: 4 [26176/620022]    Loss: 0.008387   Batch Acc: 81.25
[Train] Epoch: 4 [26240/620022]    Loss: 0.008557   Batch Acc: 78.12
[Train] Epoch: 4 [26304/620022]    Loss: 0.006861   Batch Acc: 82.81
[Train] Epoch: 4 [26368/620022]    Loss: 0.010206   Batch Acc: 73.44
[Train] Epoch: 4 [26432/620022]    Loss: 0.008429   Batch Acc: 81.25
[Train] Epoch: 4 [26496/620022]    Loss: 0.009264   Batch Acc: 71.88
[Train] Epoch: 4 [26560/620022]    Loss: 0.008215   Batch Acc: 81.25
[Train] Epoch: 4 [26624/620022]    Loss: 0.009085   Batch Acc: 75.00
[Train] Epoch: 4 [26688/620022]    Loss: 0.009008   Batch Acc: 75.00
[Train] Epoch: 4 [26752/620022]    Loss: 0.008544   Batch Acc: 81.25
[Train] Epoch: 4 [26816/620022]    Loss: 0.009171   Batch Acc: 76.56
[Train] Epoch: 4 [26880/620022]    Loss: 0.010435   Batch Acc: 68.75
[Train] Epoch: 4 [26944/620022]    Loss: 0.007516   Batch Acc: 81.25
[Train] Epoch: 4 [27008/620022]    Loss: 0.009048   Batch Acc: 78.12
[Train] Epoch: 4 [27072/620022]    Loss: 0.007869   Batch Acc: 79.69
[Train] Epoch: 4 [27136/620022]    Loss: 0.006360   Batch Acc: 85.94
[Train] Epoch: 4 [27200/620022]    Loss: 0.008822   Batch Acc: 79.69
[Train] Epoch: 4 [27264/620022]    Loss: 0.009406   Batch Acc: 76.56
[Train] Epoch: 4 [27328/620022]    Loss: 0.007653   Batch Acc: 76.56
[Train] Epoch: 4 [27392/620022]    Loss: 0.009409   Batch Acc: 73.44
[Train] Epoch: 4 [27456/620022]    Loss: 0.007938   Batch Acc: 79.69
[Train] Epoch: 4 [27520/620022]    Loss: 0.009569   Batch Acc: 78.12
[Train] Epoch: 4 [27584/620022]    Loss: 0.007822   Batch Acc: 81.25
[Train] Epoch: 4 [27648/620022]    Loss: 0.009561   Batch Acc: 75.00
[Train] Epoch: 4 [27712/620022]    Loss: 0.009033   Batch Acc: 78.12
[Train] Epoch: 4 [27776/620022]    Loss: 0.007820   Batch Acc: 82.81
[Train] Epoch: 4 [27840/620022]    Loss: 0.007634   Batch Acc: 79.69
[Train] Epoch: 4 [27904/620022]    Loss: 0.009090   Batch Acc: 75.00
[Train] Epoch: 4 [27968/620022]    Loss: 0.009199   Batch Acc: 81.25
[Train] Epoch: 4 [28032/620022]    Loss: 0.009101   Batch Acc: 75.00
[Train] Epoch: 4 [28096/620022]    Loss: 0.008190   Batch Acc: 78.12
[Train] Epoch: 4 [28160/620022]    Loss: 0.009666   Batch Acc: 76.56
[Train] Epoch: 4 [28224/620022]    Loss: 0.009765   Batch Acc: 76.56
[Train] Epoch: 4 [28288/620022]    Loss: 0.008031   Batch Acc: 75.00
[Train] Epoch: 4 [28352/620022]    Loss: 0.007608   Batch Acc: 84.38
[Train] Epoch: 4 [28416/620022]    Loss: 0.007852   Batch Acc: 78.12
[Train] Epoch: 4 [28480/620022]    Loss: 0.010190   Batch Acc: 75.00
[Train] Epoch: 4 [28544/620022]    Loss: 0.007738   Batch Acc: 87.50
[Train] Epoch: 4 [28608/620022]    Loss: 0.009082   Batch Acc: 78.12
[Train] Epoch: 4 [28672/620022]    Loss: 0.008785   Batch Acc: 81.25
[Train] Epoch: 4 [28736/620022]    Loss: 0.010124   Batch Acc: 68.75
[Train] Epoch: 4 [28800/620022]    Loss: 0.012347   Batch Acc: 59.38
[Train] Epoch: 4 [28864/620022]    Loss: 0.006910   Batch Acc: 87.50
[Train] Epoch: 4 [28928/620022]    Loss: 0.009413   Batch Acc: 76.56
[Train] Epoch: 4 [28992/620022]    Loss: 0.008494   Batch Acc: 70.31
[Train] Epoch: 4 [29056/620022]    Loss: 0.010536   Batch Acc: 71.88
[Train] Epoch: 4 [29120/620022]    Loss: 0.007108   Batch Acc: 81.25
[Train] Epoch: 4 [29184/620022]    Loss: 0.010273   Batch Acc: 78.12
[Train] Epoch: 4 [29248/620022]    Loss: 0.008868   Batch Acc: 79.69
[Train] Epoch: 4 [29312/620022]    Loss: 0.007775   Batch Acc: 78.12
[Train] Epoch: 4 [29376/620022]    Loss: 0.007440   Batch Acc: 78.12
[Train] Epoch: 4 [29440/620022]    Loss: 0.008794   Batch Acc: 75.00
[Train] Epoch: 4 [29504/620022]    Loss: 0.007665   Batch Acc: 82.81
[Train] Epoch: 4 [29568/620022]    Loss: 0.007537   Batch Acc: 79.69
[Train] Epoch: 4 [29632/620022]    Loss: 0.008042   Batch Acc: 82.81
[Train] Epoch: 4 [29696/620022]    Loss: 0.010179   Batch Acc: 71.88
[Train] Epoch: 4 [29760/620022]    Loss: 0.009748   Batch Acc: 76.56
[Train] Epoch: 4 [29824/620022]    Loss: 0.009626   Batch Acc: 78.12
[Train] Epoch: 4 [29888/620022]    Loss: 0.006936   Batch Acc: 84.38
[Train] Epoch: 4 [29952/620022]    Loss: 0.006822   Batch Acc: 84.38
[Train] Epoch: 4 [30016/620022]    Loss: 0.008853   Batch Acc: 78.12
[Train] Epoch: 4 [30080/620022]    Loss: 0.006695   Batch Acc: 82.81
[Train] Epoch: 4 [30144/620022]    Loss: 0.008251   Batch Acc: 76.56
[Train] Epoch: 4 [30208/620022]    Loss: 0.009548   Batch Acc: 78.12
[Train] Epoch: 4 [30272/620022]    Loss: 0.010654   Batch Acc: 68.75
[Train] Epoch: 4 [30336/620022]    Loss: 0.007839   Batch Acc: 82.81
[Train] Epoch: 4 [30400/620022]    Loss: 0.009268   Batch Acc: 73.44
[Train] Epoch: 4 [30464/620022]    Loss: 0.005788   Batch Acc: 89.06
[Train] Epoch: 4 [30528/620022]    Loss: 0.010762   Batch Acc: 67.19
[Train] Epoch: 4 [30592/620022]    Loss: 0.007404   Batch Acc: 79.69
[Train] Epoch: 4 [30656/620022]    Loss: 0.010409   Batch Acc: 76.56
[Train] Epoch: 4 [30720/620022]    Loss: 0.010823   Batch Acc: 75.00
[Train] Epoch: 4 [30784/620022]    Loss: 0.007621   Batch Acc: 79.69
[Train] Epoch: 4 [30848/620022]    Loss: 0.009104   Batch Acc: 79.69
[Train] Epoch: 4 [30912/620022]    Loss: 0.007731   Batch Acc: 79.69
[Train] Epoch: 4 [30976/620022]    Loss: 0.008819   Batch Acc: 75.00
[Train] Epoch: 4 [31040/620022]    Loss: 0.008592   Batch Acc: 84.38
[Train] Epoch: 4 [31104/620022]    Loss: 0.009620   Batch Acc: 71.88
[Train] Epoch: 4 [31168/620022]    Loss: 0.008311   Batch Acc: 76.56
[Train] Epoch: 4 [31232/620022]    Loss: 0.009782   Batch Acc: 76.56
[Train] Epoch: 4 [31296/620022]    Loss: 0.008262   Batch Acc: 81.25
[Train] Epoch: 4 [31360/620022]    Loss: 0.010141   Batch Acc: 73.44
[Train] Epoch: 4 [31424/620022]    Loss: 0.005999   Batch Acc: 87.50
[Train] Epoch: 4 [31488/620022]    Loss: 0.006130   Batch Acc: 89.06
[Train] Epoch: 4 [31552/620022]    Loss: 0.010318   Batch Acc: 73.44
[Train] Epoch: 4 [31616/620022]    Loss: 0.010000   Batch Acc: 68.75
[Train] Epoch: 4 [31680/620022]    Loss: 0.009267   Batch Acc: 70.31
[Train] Epoch: 4 [31744/620022]    Loss: 0.009266   Batch Acc: 78.12
[Train] Epoch: 4 [31808/620022]    Loss: 0.010343   Batch Acc: 73.44
[Train] Epoch: 4 [31872/620022]    Loss: 0.009524   Batch Acc: 81.25
[Train] Epoch: 4 [31936/620022]    Loss: 0.011227   Batch Acc: 71.88
[Train] Epoch: 4 [32000/620022]    Loss: 0.009582   Batch Acc: 73.44
[Train] Epoch: 4 [32064/620022]    Loss: 0.009009   Batch Acc: 71.88
[Train] Epoch: 4 [32128/620022]    Loss: 0.008525   Batch Acc: 81.25
[Train] Epoch: 4 [32192/620022]    Loss: 0.007778   Batch Acc: 85.94
[Train] Epoch: 4 [32256/620022]    Loss: 0.010727   Batch Acc: 71.88
[Train] Epoch: 4 [32320/620022]    Loss: 0.008801   Batch Acc: 79.69
[Train] Epoch: 4 [32384/620022]    Loss: 0.008159   Batch Acc: 79.69
[Train] Epoch: 4 [32448/620022]    Loss: 0.006682   Batch Acc: 82.81
[Train] Epoch: 4 [32512/620022]    Loss: 0.008022   Batch Acc: 79.69
[Train] Epoch: 4 [32576/620022]    Loss: 0.009260   Batch Acc: 75.00
[Train] Epoch: 4 [32640/620022]    Loss: 0.008933   Batch Acc: 76.56
[Train] Epoch: 4 [32704/620022]    Loss: 0.009070   Batch Acc: 73.44
[Train] Epoch: 4 [32768/620022]    Loss: 0.006867   Batch Acc: 92.19
[Train] Epoch: 4 [32832/620022]    Loss: 0.006579   Batch Acc: 87.50
[Train] Epoch: 4 [32896/620022]    Loss: 0.010319   Batch Acc: 70.31
[Train] Epoch: 4 [32960/620022]    Loss: 0.009014   Batch Acc: 73.44
[Train] Epoch: 4 [33024/620022]    Loss: 0.007259   Batch Acc: 78.12
[Train] Epoch: 4 [33088/620022]    Loss: 0.009125   Batch Acc: 78.12
[Train] Epoch: 4 [33152/620022]    Loss: 0.008457   Batch Acc: 76.56
[Train] Epoch: 4 [33216/620022]    Loss: 0.008972   Batch Acc: 78.12
[Train] Epoch: 4 [33280/620022]    Loss: 0.009479   Batch Acc: 81.25
[Train] Epoch: 4 [33344/620022]    Loss: 0.010483   Batch Acc: 67.19
[Train] Epoch: 4 [33408/620022]    Loss: 0.010017   Batch Acc: 71.88
[Train] Epoch: 4 [33472/620022]    Loss: 0.009832   Batch Acc: 78.12
[Train] Epoch: 4 [33536/620022]    Loss: 0.012454   Batch Acc: 60.94
[Train] Epoch: 4 [33600/620022]    Loss: 0.006889   Batch Acc: 84.38
[Train] Epoch: 4 [33664/620022]    Loss: 0.008001   Batch Acc: 81.25
[Train] Epoch: 4 [33728/620022]    Loss: 0.009358   Batch Acc: 81.25
[Train] Epoch: 4 [33792/620022]    Loss: 0.009613   Batch Acc: 75.00
[Train] Epoch: 4 [33856/620022]    Loss: 0.008051   Batch Acc: 76.56
[Train] Epoch: 4 [33920/620022]    Loss: 0.007909   Batch Acc: 79.69
[Train] Epoch: 4 [33984/620022]    Loss: 0.008193   Batch Acc: 79.69
[Train] Epoch: 4 [34048/620022]    Loss: 0.006983   Batch Acc: 82.81
[Train] Epoch: 4 [34112/620022]    Loss: 0.007091   Batch Acc: 79.69
[Train] Epoch: 4 [34176/620022]    Loss: 0.007251   Batch Acc: 82.81
[Train] Epoch: 4 [34240/620022]    Loss: 0.009368   Batch Acc: 75.00
[Train] Epoch: 4 [34304/620022]    Loss: 0.009676   Batch Acc: 71.88
[Train] Epoch: 4 [34368/620022]    Loss: 0.010665   Batch Acc: 75.00
[Train] Epoch: 4 [34432/620022]    Loss: 0.009184   Batch Acc: 70.31
[Train] Epoch: 4 [34496/620022]    Loss: 0.007836   Batch Acc: 79.69
[Train] Epoch: 4 [34560/620022]    Loss: 0.008174   Batch Acc: 70.31
[Train] Epoch: 4 [34624/620022]    Loss: 0.007001   Batch Acc: 87.50
[Train] Epoch: 4 [34688/620022]    Loss: 0.008317   Batch Acc: 71.88
[Train] Epoch: 4 [34752/620022]    Loss: 0.009233   Batch Acc: 73.44
[Train] Epoch: 4 [34816/620022]    Loss: 0.008516   Batch Acc: 84.38
[Train] Epoch: 4 [34880/620022]    Loss: 0.009265   Batch Acc: 70.31
[Train] Epoch: 4 [34944/620022]    Loss: 0.010353   Batch Acc: 71.88
[Train] Epoch: 4 [35008/620022]    Loss: 0.009416   Batch Acc: 78.12
[Train] Epoch: 4 [35072/620022]    Loss: 0.009309   Batch Acc: 78.12
[Train] Epoch: 4 [35136/620022]    Loss: 0.009304   Batch Acc: 78.12
[Train] Epoch: 4 [35200/620022]    Loss: 0.009446   Batch Acc: 75.00
[Train] Epoch: 4 [35264/620022]    Loss: 0.007922   Batch Acc: 82.81
[Train] Epoch: 4 [35328/620022]    Loss: 0.010525   Batch Acc: 71.88
[Train] Epoch: 4 [35392/620022]    Loss: 0.006414   Batch Acc: 84.38
[Train] Epoch: 4 [35456/620022]    Loss: 0.008236   Batch Acc: 79.69
[Train] Epoch: 4 [35520/620022]    Loss: 0.008667   Batch Acc: 70.31
[Train] Epoch: 4 [35584/620022]    Loss: 0.006812   Batch Acc: 85.94
[Train] Epoch: 4 [35648/620022]    Loss: 0.009371   Batch Acc: 78.12
[Train] Epoch: 4 [35712/620022]    Loss: 0.007345   Batch Acc: 82.81
[Train] Epoch: 4 [35776/620022]    Loss: 0.007297   Batch Acc: 85.94
[Train] Epoch: 4 [35840/620022]    Loss: 0.008136   Batch Acc: 84.38
[Train] Epoch: 4 [35904/620022]    Loss: 0.008076   Batch Acc: 79.69
[Train] Epoch: 4 [35968/620022]    Loss: 0.007364   Batch Acc: 82.81
[Train] Epoch: 4 [36032/620022]    Loss: 0.006089   Batch Acc: 90.62
[Train] Epoch: 4 [36096/620022]    Loss: 0.009455   Batch Acc: 73.44
[Train] Epoch: 4 [36160/620022]    Loss: 0.008897   Batch Acc: 78.12
[Train] Epoch: 4 [36224/620022]    Loss: 0.007475   Batch Acc: 85.94
[Train] Epoch: 4 [36288/620022]    Loss: 0.007567   Batch Acc: 78.12
[Train] Epoch: 4 [36352/620022]    Loss: 0.008999   Batch Acc: 75.00
[Train] Epoch: 4 [36416/620022]    Loss: 0.009748   Batch Acc: 78.12
[Train] Epoch: 4 [36480/620022]    Loss: 0.008539   Batch Acc: 78.12
[Train] Epoch: 4 [36544/620022]    Loss: 0.009722   Batch Acc: 75.00
[Train] Epoch: 4 [36608/620022]    Loss: 0.006939   Batch Acc: 84.38
[Train] Epoch: 4 [36672/620022]    Loss: 0.009174   Batch Acc: 76.56
[Train] Epoch: 4 [36736/620022]    Loss: 0.011197   Batch Acc: 73.44
[Train] Epoch: 4 [36800/620022]    Loss: 0.007155   Batch Acc: 87.50
[Train] Epoch: 4 [36864/620022]    Loss: 0.007060   Batch Acc: 81.25
[Train] Epoch: 4 [36928/620022]    Loss: 0.009259   Batch Acc: 76.56
[Train] Epoch: 4 [36992/620022]    Loss: 0.010870   Batch Acc: 68.75
[Train] Epoch: 4 [37056/620022]    Loss: 0.009060   Batch Acc: 75.00
[Train] Epoch: 4 [37120/620022]    Loss: 0.007767   Batch Acc: 81.25
[Train] Epoch: 4 [37184/620022]    Loss: 0.008291   Batch Acc: 81.25
[Train] Epoch: 4 [37248/620022]    Loss: 0.010104   Batch Acc: 75.00
[Train] Epoch: 4 [37312/620022]    Loss: 0.009314   Batch Acc: 79.69
[Train] Epoch: 4 [37376/620022]    Loss: 0.008574   Batch Acc: 79.69
[Train] Epoch: 4 [37440/620022]    Loss: 0.008893   Batch Acc: 75.00
[Train] Epoch: 4 [37504/620022]    Loss: 0.009104   Batch Acc: 75.00
[Train] Epoch: 4 [37568/620022]    Loss: 0.008598   Batch Acc: 76.56
[Train] Epoch: 4 [37632/620022]    Loss: 0.007857   Batch Acc: 81.25
[Train] Epoch: 4 [37696/620022]    Loss: 0.010800   Batch Acc: 70.31
[Train] Epoch: 4 [37760/620022]    Loss: 0.008322   Batch Acc: 78.12
[Train] Epoch: 4 [37824/620022]    Loss: 0.007543   Batch Acc: 79.69
[Train] Epoch: 4 [37888/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 4 [37952/620022]    Loss: 0.008264   Batch Acc: 78.12
[Train] Epoch: 4 [38016/620022]    Loss: 0.007777   Batch Acc: 85.94
[Train] Epoch: 4 [38080/620022]    Loss: 0.009901   Batch Acc: 76.56
[Train] Epoch: 4 [38144/620022]    Loss: 0.009863   Batch Acc: 76.56
[Train] Epoch: 4 [38208/620022]    Loss: 0.010441   Batch Acc: 70.31
[Train] Epoch: 4 [38272/620022]    Loss: 0.007275   Batch Acc: 85.94
[Train] Epoch: 4 [38336/620022]    Loss: 0.007664   Batch Acc: 79.69
[Train] Epoch: 4 [38400/620022]    Loss: 0.007668   Batch Acc: 85.94
[Train] Epoch: 4 [38464/620022]    Loss: 0.008675   Batch Acc: 75.00
[Train] Epoch: 4 [38528/620022]    Loss: 0.008014   Batch Acc: 79.69
[Train] Epoch: 4 [38592/620022]    Loss: 0.011261   Batch Acc: 67.19
[Train] Epoch: 4 [38656/620022]    Loss: 0.007468   Batch Acc: 78.12
[Train] Epoch: 4 [38720/620022]    Loss: 0.009698   Batch Acc: 71.88
[Train] Epoch: 4 [38784/620022]    Loss: 0.008736   Batch Acc: 78.12
[Train] Epoch: 4 [38848/620022]    Loss: 0.008396   Batch Acc: 81.25
[Train] Epoch: 4 [38912/620022]    Loss: 0.008353   Batch Acc: 78.12
[Train] Epoch: 4 [38976/620022]    Loss: 0.010255   Batch Acc: 68.75
[Train] Epoch: 4 [39040/620022]    Loss: 0.009142   Batch Acc: 76.56
[Train] Epoch: 4 [39104/620022]    Loss: 0.010716   Batch Acc: 68.75
[Train] Epoch: 4 [39168/620022]    Loss: 0.009950   Batch Acc: 79.69
[Train] Epoch: 4 [39232/620022]    Loss: 0.008181   Batch Acc: 75.00
[Train] Epoch: 4 [39296/620022]    Loss: 0.008637   Batch Acc: 78.12
[Train] Epoch: 4 [39360/620022]    Loss: 0.009352   Batch Acc: 75.00
[Train] Epoch: 4 [39424/620022]    Loss: 0.010060   Batch Acc: 70.31
[Train] Epoch: 4 [39488/620022]    Loss: 0.008413   Batch Acc: 75.00
[Train] Epoch: 4 [39552/620022]    Loss: 0.008550   Batch Acc: 79.69
[Train] Epoch: 4 [39616/620022]    Loss: 0.009250   Batch Acc: 78.12
[Train] Epoch: 4 [39680/620022]    Loss: 0.010599   Batch Acc: 71.88
[Train] Epoch: 4 [39744/620022]    Loss: 0.009171   Batch Acc: 76.56
[Train] Epoch: 4 [39808/620022]    Loss: 0.009362   Batch Acc: 76.56
[Train] Epoch: 4 [39872/620022]    Loss: 0.010571   Batch Acc: 76.56
[Train] Epoch: 4 [39936/620022]    Loss: 0.007699   Batch Acc: 84.38
[Train] Epoch: 4 [40000/620022]    Loss: 0.010577   Batch Acc: 68.75
[Train] Epoch: 4 [40064/620022]    Loss: 0.008511   Batch Acc: 81.25
[Train] Epoch: 4 [40128/620022]    Loss: 0.008147   Batch Acc: 79.69
[Train] Epoch: 4 [40192/620022]    Loss: 0.009039   Batch Acc: 76.56
[Train] Epoch: 4 [40256/620022]    Loss: 0.007951   Batch Acc: 81.25
[Train] Epoch: 4 [40320/620022]    Loss: 0.008037   Batch Acc: 82.81
[Train] Epoch: 4 [40384/620022]    Loss: 0.009270   Batch Acc: 75.00
[Train] Epoch: 4 [40448/620022]    Loss: 0.007935   Batch Acc: 78.12
[Train] Epoch: 4 [40512/620022]    Loss: 0.010204   Batch Acc: 73.44
[Train] Epoch: 4 [40576/620022]    Loss: 0.006010   Batch Acc: 85.94
[Train] Epoch: 4 [40640/620022]    Loss: 0.007347   Batch Acc: 82.81
[Train] Epoch: 4 [40704/620022]    Loss: 0.011483   Batch Acc: 76.56
[Train] Epoch: 4 [40768/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 4 [40832/620022]    Loss: 0.009089   Batch Acc: 78.12
[Train] Epoch: 4 [40896/620022]    Loss: 0.007682   Batch Acc: 79.69
[Train] Epoch: 4 [40960/620022]    Loss: 0.006136   Batch Acc: 84.38
[Train] Epoch: 4 [41024/620022]    Loss: 0.008753   Batch Acc: 78.12
[Train] Epoch: 4 [41088/620022]    Loss: 0.007236   Batch Acc: 79.69
[Train] Epoch: 4 [41152/620022]    Loss: 0.007115   Batch Acc: 84.38
[Train] Epoch: 4 [41216/620022]    Loss: 0.008644   Batch Acc: 79.69
[Train] Epoch: 4 [41280/620022]    Loss: 0.008187   Batch Acc: 76.56
[Train] Epoch: 4 [41344/620022]    Loss: 0.005524   Batch Acc: 90.62
[Train] Epoch: 4 [41408/620022]    Loss: 0.008345   Batch Acc: 76.56
[Train] Epoch: 4 [41472/620022]    Loss: 0.006971   Batch Acc: 84.38
[Train] Epoch: 4 [41536/620022]    Loss: 0.009015   Batch Acc: 78.12
[Train] Epoch: 4 [41600/620022]    Loss: 0.009623   Batch Acc: 79.69
[Train] Epoch: 4 [41664/620022]    Loss: 0.007176   Batch Acc: 89.06
[Train] Epoch: 4 [41728/620022]    Loss: 0.008720   Batch Acc: 75.00
[Train] Epoch: 4 [41792/620022]    Loss: 0.008058   Batch Acc: 81.25
[Train] Epoch: 4 [41856/620022]    Loss: 0.007796   Batch Acc: 82.81
[Train] Epoch: 4 [41920/620022]    Loss: 0.008953   Batch Acc: 76.56
[Train] Epoch: 4 [41984/620022]    Loss: 0.009668   Batch Acc: 73.44
[Train] Epoch: 4 [42048/620022]    Loss: 0.009664   Batch Acc: 71.88
[Train] Epoch: 4 [42112/620022]    Loss: 0.005880   Batch Acc: 89.06
[Train] Epoch: 4 [42176/620022]    Loss: 0.013624   Batch Acc: 64.06
[Train] Epoch: 4 [42240/620022]    Loss: 0.006551   Batch Acc: 84.38
[Train] Epoch: 4 [42304/620022]    Loss: 0.009367   Batch Acc: 70.31
[Train] Epoch: 4 [42368/620022]    Loss: 0.008763   Batch Acc: 78.12
[Train] Epoch: 4 [42432/620022]    Loss: 0.008020   Batch Acc: 82.81
[Train] Epoch: 4 [42496/620022]    Loss: 0.010685   Batch Acc: 62.50
[Train] Epoch: 4 [42560/620022]    Loss: 0.007531   Batch Acc: 79.69
[Train] Epoch: 4 [42624/620022]    Loss: 0.008746   Batch Acc: 76.56
[Train] Epoch: 4 [42688/620022]    Loss: 0.009291   Batch Acc: 73.44
[Train] Epoch: 4 [42752/620022]    Loss: 0.008630   Batch Acc: 76.56
[Train] Epoch: 4 [42816/620022]    Loss: 0.011184   Batch Acc: 70.31
[Train] Epoch: 4 [42880/620022]    Loss: 0.007741   Batch Acc: 79.69
[Train] Epoch: 4 [42944/620022]    Loss: 0.009413   Batch Acc: 79.69
[Train] Epoch: 4 [43008/620022]    Loss: 0.008815   Batch Acc: 79.69
[Train] Epoch: 4 [43072/620022]    Loss: 0.008992   Batch Acc: 79.69
[Train] Epoch: 4 [43136/620022]    Loss: 0.006902   Batch Acc: 90.62
[Train] Epoch: 4 [43200/620022]    Loss: 0.009643   Batch Acc: 76.56
[Train] Epoch: 4 [43264/620022]    Loss: 0.007572   Batch Acc: 84.38
[Train] Epoch: 4 [43328/620022]    Loss: 0.010108   Batch Acc: 67.19
[Train] Epoch: 4 [43392/620022]    Loss: 0.009767   Batch Acc: 79.69
[Train] Epoch: 4 [43456/620022]    Loss: 0.007738   Batch Acc: 81.25
[Train] Epoch: 4 [43520/620022]    Loss: 0.009516   Batch Acc: 81.25
[Train] Epoch: 4 [43584/620022]    Loss: 0.010922   Batch Acc: 73.44
[Train] Epoch: 4 [43648/620022]    Loss: 0.008328   Batch Acc: 81.25
[Train] Epoch: 4 [43712/620022]    Loss: 0.008304   Batch Acc: 79.69
[Train] Epoch: 4 [43776/620022]    Loss: 0.008714   Batch Acc: 79.69
[Train] Epoch: 4 [43840/620022]    Loss: 0.007709   Batch Acc: 84.38
[Train] Epoch: 4 [43904/620022]    Loss: 0.007646   Batch Acc: 85.94
[Train] Epoch: 4 [43968/620022]    Loss: 0.009841   Batch Acc: 71.88
[Train] Epoch: 4 [44032/620022]    Loss: 0.012377   Batch Acc: 67.19
[Train] Epoch: 4 [44096/620022]    Loss: 0.009363   Batch Acc: 79.69
[Train] Epoch: 4 [44160/620022]    Loss: 0.008691   Batch Acc: 79.69
[Train] Epoch: 4 [44224/620022]    Loss: 0.013405   Batch Acc: 65.62
[Train] Epoch: 4 [44288/620022]    Loss: 0.009716   Batch Acc: 79.69
[Train] Epoch: 4 [44352/620022]    Loss: 0.009319   Batch Acc: 79.69
[Train] Epoch: 4 [44416/620022]    Loss: 0.009219   Batch Acc: 76.56
[Train] Epoch: 4 [44480/620022]    Loss: 0.007506   Batch Acc: 81.25
[Train] Epoch: 4 [44544/620022]    Loss: 0.009862   Batch Acc: 73.44
[Train] Epoch: 4 [44608/620022]    Loss: 0.009415   Batch Acc: 79.69
[Train] Epoch: 4 [44672/620022]    Loss: 0.009308   Batch Acc: 71.88
[Train] Epoch: 4 [44736/620022]    Loss: 0.008964   Batch Acc: 76.56
[Train] Epoch: 4 [44800/620022]    Loss: 0.005168   Batch Acc: 93.75
[Train] Epoch: 4 [44864/620022]    Loss: 0.006672   Batch Acc: 89.06
[Train] Epoch: 4 [44928/620022]    Loss: 0.009792   Batch Acc: 73.44
[Train] Epoch: 4 [44992/620022]    Loss: 0.008779   Batch Acc: 78.12
[Train] Epoch: 4 [45056/620022]    Loss: 0.008218   Batch Acc: 85.94
[Train] Epoch: 4 [45120/620022]    Loss: 0.009446   Batch Acc: 76.56
[Train] Epoch: 4 [45184/620022]    Loss: 0.009833   Batch Acc: 78.12
[Train] Epoch: 4 [45248/620022]    Loss: 0.010533   Batch Acc: 67.19
[Train] Epoch: 4 [45312/620022]    Loss: 0.008037   Batch Acc: 79.69
[Train] Epoch: 4 [45376/620022]    Loss: 0.010379   Batch Acc: 76.56
[Train] Epoch: 4 [45440/620022]    Loss: 0.009012   Batch Acc: 78.12
[Train] Epoch: 4 [45504/620022]    Loss: 0.006901   Batch Acc: 82.81
[Train] Epoch: 4 [45568/620022]    Loss: 0.009238   Batch Acc: 68.75
[Train] Epoch: 4 [45632/620022]    Loss: 0.010645   Batch Acc: 67.19
[Train] Epoch: 4 [45696/620022]    Loss: 0.008951   Batch Acc: 71.88
[Train] Epoch: 4 [45760/620022]    Loss: 0.006069   Batch Acc: 87.50
[Train] Epoch: 4 [45824/620022]    Loss: 0.009657   Batch Acc: 71.88
[Train] Epoch: 4 [45888/620022]    Loss: 0.009867   Batch Acc: 75.00
[Train] Epoch: 4 [45952/620022]    Loss: 0.009716   Batch Acc: 75.00
[Train] Epoch: 4 [46016/620022]    Loss: 0.008445   Batch Acc: 78.12
[Train] Epoch: 4 [46080/620022]    Loss: 0.006909   Batch Acc: 79.69
[Train] Epoch: 4 [46144/620022]    Loss: 0.007775   Batch Acc: 79.69
[Train] Epoch: 4 [46208/620022]    Loss: 0.008641   Batch Acc: 78.12
[Train] Epoch: 4 [46272/620022]    Loss: 0.008618   Batch Acc: 75.00
[Train] Epoch: 4 [46336/620022]    Loss: 0.007705   Batch Acc: 78.12
[Train] Epoch: 4 [46400/620022]    Loss: 0.011421   Batch Acc: 76.56
[Train] Epoch: 4 [46464/620022]    Loss: 0.008720   Batch Acc: 78.12
[Train] Epoch: 4 [46528/620022]    Loss: 0.006262   Batch Acc: 89.06
[Train] Epoch: 4 [46592/620022]    Loss: 0.008395   Batch Acc: 81.25
[Train] Epoch: 4 [46656/620022]    Loss: 0.006222   Batch Acc: 89.06
[Train] Epoch: 4 [46720/620022]    Loss: 0.009457   Batch Acc: 71.88
[Train] Epoch: 4 [46784/620022]    Loss: 0.008180   Batch Acc: 78.12
[Train] Epoch: 4 [46848/620022]    Loss: 0.008621   Batch Acc: 78.12
[Train] Epoch: 4 [46912/620022]    Loss: 0.008668   Batch Acc: 78.12
[Train] Epoch: 4 [46976/620022]    Loss: 0.009327   Batch Acc: 75.00
[Train] Epoch: 4 [47040/620022]    Loss: 0.009099   Batch Acc: 75.00
[Train] Epoch: 4 [47104/620022]    Loss: 0.008287   Batch Acc: 79.69
[Train] Epoch: 4 [47168/620022]    Loss: 0.009226   Batch Acc: 73.44
[Train] Epoch: 4 [47232/620022]    Loss: 0.007673   Batch Acc: 81.25
[Train] Epoch: 4 [47296/620022]    Loss: 0.008741   Batch Acc: 81.25
[Train] Epoch: 4 [47360/620022]    Loss: 0.006897   Batch Acc: 79.69
[Train] Epoch: 4 [47424/620022]    Loss: 0.009498   Batch Acc: 73.44
[Train] Epoch: 4 [47488/620022]    Loss: 0.008585   Batch Acc: 75.00
[Train] Epoch: 4 [47552/620022]    Loss: 0.007857   Batch Acc: 76.56
[Train] Epoch: 4 [47616/620022]    Loss: 0.008885   Batch Acc: 82.81
[Train] Epoch: 4 [47680/620022]    Loss: 0.007040   Batch Acc: 87.50
[Train] Epoch: 4 [47744/620022]    Loss: 0.008507   Batch Acc: 78.12
[Train] Epoch: 4 [47808/620022]    Loss: 0.008996   Batch Acc: 79.69
[Train] Epoch: 4 [47872/620022]    Loss: 0.007817   Batch Acc: 81.25
[Train] Epoch: 4 [47936/620022]    Loss: 0.008475   Batch Acc: 73.44
[Train] Epoch: 4 [48000/620022]    Loss: 0.005794   Batch Acc: 85.94
[Train] Epoch: 4 [48064/620022]    Loss: 0.007577   Batch Acc: 84.38
[Train] Epoch: 4 [48128/620022]    Loss: 0.009837   Batch Acc: 71.88
[Train] Epoch: 4 [48192/620022]    Loss: 0.007771   Batch Acc: 84.38
[Train] Epoch: 4 [48256/620022]    Loss: 0.008972   Batch Acc: 76.56
[Train] Epoch: 4 [48320/620022]    Loss: 0.011804   Batch Acc: 64.06
[Train] Epoch: 4 [48384/620022]    Loss: 0.008192   Batch Acc: 79.69
[Train] Epoch: 4 [48448/620022]    Loss: 0.009491   Batch Acc: 78.12
[Train] Epoch: 4 [48512/620022]    Loss: 0.009174   Batch Acc: 76.56
[Train] Epoch: 4 [48576/620022]    Loss: 0.008101   Batch Acc: 76.56
[Train] Epoch: 4 [48640/620022]    Loss: 0.008886   Batch Acc: 81.25
[Train] Epoch: 4 [48704/620022]    Loss: 0.009699   Batch Acc: 70.31
[Train] Epoch: 4 [48768/620022]    Loss: 0.007896   Batch Acc: 78.12
[Train] Epoch: 4 [48832/620022]    Loss: 0.008389   Batch Acc: 76.56
[Train] Epoch: 4 [48896/620022]    Loss: 0.007942   Batch Acc: 76.56
[Train] Epoch: 4 [48960/620022]    Loss: 0.008070   Batch Acc: 76.56
[Train] Epoch: 4 [49024/620022]    Loss: 0.007612   Batch Acc: 82.81
[Train] Epoch: 4 [49088/620022]    Loss: 0.008218   Batch Acc: 81.25
[Train] Epoch: 4 [49152/620022]    Loss: 0.007728   Batch Acc: 81.25
[Train] Epoch: 4 [49216/620022]    Loss: 0.007681   Batch Acc: 81.25
[Train] Epoch: 4 [49280/620022]    Loss: 0.009283   Batch Acc: 78.12
[Train] Epoch: 4 [49344/620022]    Loss: 0.009693   Batch Acc: 73.44
[Train] Epoch: 4 [49408/620022]    Loss: 0.006913   Batch Acc: 81.25
[Train] Epoch: 4 [49472/620022]    Loss: 0.007539   Batch Acc: 85.94
[Train] Epoch: 4 [49536/620022]    Loss: 0.010573   Batch Acc: 76.56
[Train] Epoch: 4 [49600/620022]    Loss: 0.006849   Batch Acc: 84.38
[Train] Epoch: 4 [49664/620022]    Loss: 0.008247   Batch Acc: 78.12
[Train] Epoch: 4 [49728/620022]    Loss: 0.009016   Batch Acc: 75.00
[Train] Epoch: 4 [49792/620022]    Loss: 0.009228   Batch Acc: 71.88
[Train] Epoch: 4 [49856/620022]    Loss: 0.006476   Batch Acc: 85.94
[Train] Epoch: 4 [49920/620022]    Loss: 0.006945   Batch Acc: 84.38
[Train] Epoch: 4 [49984/620022]    Loss: 0.011859   Batch Acc: 67.19
[Train] Epoch: 4 [50048/620022]    Loss: 0.009899   Batch Acc: 75.00
[Train] Epoch: 4 [50112/620022]    Loss: 0.010282   Batch Acc: 70.31
[Train] Epoch: 4 [50176/620022]    Loss: 0.007503   Batch Acc: 84.38
[Train] Epoch: 4 [50240/620022]    Loss: 0.009960   Batch Acc: 73.44
[Train] Epoch: 4 [50304/620022]    Loss: 0.008732   Batch Acc: 75.00
[Train] Epoch: 4 [50368/620022]    Loss: 0.007311   Batch Acc: 82.81
[Train] Epoch: 4 [50432/620022]    Loss: 0.007349   Batch Acc: 82.81
[Train] Epoch: 4 [50496/620022]    Loss: 0.007880   Batch Acc: 75.00
[Train] Epoch: 4 [50560/620022]    Loss: 0.010260   Batch Acc: 75.00
[Train] Epoch: 4 [50624/620022]    Loss: 0.008672   Batch Acc: 78.12
[Train] Epoch: 4 [50688/620022]    Loss: 0.008976   Batch Acc: 76.56
[Train] Epoch: 4 [50752/620022]    Loss: 0.006814   Batch Acc: 84.38
[Train] Epoch: 4 [50816/620022]    Loss: 0.008692   Batch Acc: 76.56
[Train] Epoch: 4 [50880/620022]    Loss: 0.007984   Batch Acc: 76.56
[Train] Epoch: 4 [50944/620022]    Loss: 0.008831   Batch Acc: 75.00
[Train] Epoch: 4 [51008/620022]    Loss: 0.005814   Batch Acc: 89.06
[Train] Epoch: 4 [51072/620022]    Loss: 0.009398   Batch Acc: 75.00
[Train] Epoch: 4 [51136/620022]    Loss: 0.010558   Batch Acc: 70.31
[Train] Epoch: 4 [51200/620022]    Loss: 0.008012   Batch Acc: 79.69
[Train] Epoch: 4 [51264/620022]    Loss: 0.009111   Batch Acc: 75.00
[Train] Epoch: 4 [51328/620022]    Loss: 0.009325   Batch Acc: 75.00
[Train] Epoch: 4 [51392/620022]    Loss: 0.007436   Batch Acc: 78.12
[Train] Epoch: 4 [51456/620022]    Loss: 0.009763   Batch Acc: 75.00
[Train] Epoch: 4 [51520/620022]    Loss: 0.008004   Batch Acc: 79.69
[Train] Epoch: 4 [51584/620022]    Loss: 0.010080   Batch Acc: 68.75
[Train] Epoch: 4 [51648/620022]    Loss: 0.011301   Batch Acc: 71.88
[Train] Epoch: 4 [51712/620022]    Loss: 0.008594   Batch Acc: 79.69
[Train] Epoch: 4 [51776/620022]    Loss: 0.009409   Batch Acc: 78.12
[Train] Epoch: 4 [51840/620022]    Loss: 0.009491   Batch Acc: 73.44
[Train] Epoch: 4 [51904/620022]    Loss: 0.010231   Batch Acc: 71.88
[Train] Epoch: 4 [51968/620022]    Loss: 0.006537   Batch Acc: 81.25
[Train] Epoch: 4 [52032/620022]    Loss: 0.008393   Batch Acc: 75.00
[Train] Epoch: 4 [52096/620022]    Loss: 0.011404   Batch Acc: 71.88
[Train] Epoch: 4 [52160/620022]    Loss: 0.008383   Batch Acc: 73.44
[Train] Epoch: 4 [52224/620022]    Loss: 0.008073   Batch Acc: 81.25
[Train] Epoch: 4 [52288/620022]    Loss: 0.005973   Batch Acc: 87.50
[Train] Epoch: 4 [52352/620022]    Loss: 0.009998   Batch Acc: 73.44
[Train] Epoch: 4 [52416/620022]    Loss: 0.007841   Batch Acc: 79.69
[Train] Epoch: 4 [52480/620022]    Loss: 0.008071   Batch Acc: 78.12
[Train] Epoch: 4 [52544/620022]    Loss: 0.009941   Batch Acc: 75.00
[Train] Epoch: 4 [52608/620022]    Loss: 0.007668   Batch Acc: 76.56
[Train] Epoch: 4 [52672/620022]    Loss: 0.011079   Batch Acc: 65.62
[Train] Epoch: 4 [52736/620022]    Loss: 0.008847   Batch Acc: 76.56
[Train] Epoch: 4 [52800/620022]    Loss: 0.012574   Batch Acc: 65.62
[Train] Epoch: 4 [52864/620022]    Loss: 0.008838   Batch Acc: 75.00
[Train] Epoch: 4 [52928/620022]    Loss: 0.008343   Batch Acc: 78.12
[Train] Epoch: 4 [52992/620022]    Loss: 0.010418   Batch Acc: 73.44
[Train] Epoch: 4 [53056/620022]    Loss: 0.009117   Batch Acc: 76.56
[Train] Epoch: 4 [53120/620022]    Loss: 0.007727   Batch Acc: 76.56
[Train] Epoch: 4 [53184/620022]    Loss: 0.008618   Batch Acc: 79.69
[Train] Epoch: 4 [53248/620022]    Loss: 0.009409   Batch Acc: 73.44
[Train] Epoch: 4 [53312/620022]    Loss: 0.007443   Batch Acc: 79.69
[Train] Epoch: 4 [53376/620022]    Loss: 0.008639   Batch Acc: 78.12
[Train] Epoch: 4 [53440/620022]    Loss: 0.006595   Batch Acc: 85.94
[Train] Epoch: 4 [53504/620022]    Loss: 0.011600   Batch Acc: 71.88
[Train] Epoch: 4 [53568/620022]    Loss: 0.010556   Batch Acc: 71.88
[Train] Epoch: 4 [53632/620022]    Loss: 0.010955   Batch Acc: 71.88
[Train] Epoch: 4 [53696/620022]    Loss: 0.007398   Batch Acc: 79.69
[Train] Epoch: 4 [53760/620022]    Loss: 0.008607   Batch Acc: 79.69
[Train] Epoch: 4 [53824/620022]    Loss: 0.008544   Batch Acc: 82.81
[Train] Epoch: 4 [53888/620022]    Loss: 0.006462   Batch Acc: 82.81
[Train] Epoch: 4 [53952/620022]    Loss: 0.009379   Batch Acc: 79.69
[Train] Epoch: 4 [54016/620022]    Loss: 0.009316   Batch Acc: 76.56
[Train] Epoch: 4 [54080/620022]    Loss: 0.009271   Batch Acc: 70.31
[Train] Epoch: 4 [54144/620022]    Loss: 0.008710   Batch Acc: 73.44
[Train] Epoch: 4 [54208/620022]    Loss: 0.006694   Batch Acc: 85.94
[Train] Epoch: 4 [54272/620022]    Loss: 0.009484   Batch Acc: 75.00
[Train] Epoch: 4 [54336/620022]    Loss: 0.006951   Batch Acc: 85.94
[Train] Epoch: 4 [54400/620022]    Loss: 0.008166   Batch Acc: 76.56
[Train] Epoch: 4 [54464/620022]    Loss: 0.009700   Batch Acc: 70.31
[Train] Epoch: 4 [54528/620022]    Loss: 0.009883   Batch Acc: 73.44
[Train] Epoch: 4 [54592/620022]    Loss: 0.007188   Batch Acc: 90.62
[Train] Epoch: 4 [54656/620022]    Loss: 0.009425   Batch Acc: 73.44
[Train] Epoch: 4 [54720/620022]    Loss: 0.007001   Batch Acc: 79.69
[Train] Epoch: 4 [54784/620022]    Loss: 0.009848   Batch Acc: 75.00
[Train] Epoch: 4 [54848/620022]    Loss: 0.008121   Batch Acc: 81.25
[Train] Epoch: 4 [54912/620022]    Loss: 0.009358   Batch Acc: 73.44
[Train] Epoch: 4 [54976/620022]    Loss: 0.011166   Batch Acc: 71.88
[Train] Epoch: 4 [55040/620022]    Loss: 0.009918   Batch Acc: 76.56
[Train] Epoch: 4 [55104/620022]    Loss: 0.008537   Batch Acc: 82.81
[Train] Epoch: 4 [55168/620022]    Loss: 0.010727   Batch Acc: 67.19
[Train] Epoch: 4 [55232/620022]    Loss: 0.006307   Batch Acc: 92.19
[Train] Epoch: 4 [55296/620022]    Loss: 0.008135   Batch Acc: 75.00
[Train] Epoch: 4 [55360/620022]    Loss: 0.007796   Batch Acc: 76.56
[Train] Epoch: 4 [55424/620022]    Loss: 0.012706   Batch Acc: 62.50
[Train] Epoch: 4 [55488/620022]    Loss: 0.009743   Batch Acc: 71.88
[Train] Epoch: 4 [55552/620022]    Loss: 0.006565   Batch Acc: 82.81
[Train] Epoch: 4 [55616/620022]    Loss: 0.007211   Batch Acc: 85.94
[Train] Epoch: 4 [55680/620022]    Loss: 0.008848   Batch Acc: 76.56
[Train] Epoch: 4 [55744/620022]    Loss: 0.006023   Batch Acc: 82.81
[Train] Epoch: 4 [55808/620022]    Loss: 0.006791   Batch Acc: 85.94
[Train] Epoch: 4 [55872/620022]    Loss: 0.008182   Batch Acc: 78.12
[Train] Epoch: 4 [55936/620022]    Loss: 0.007945   Batch Acc: 78.12
[Train] Epoch: 4 [56000/620022]    Loss: 0.010771   Batch Acc: 67.19
[Train] Epoch: 4 [56064/620022]    Loss: 0.012499   Batch Acc: 67.19
[Train] Epoch: 4 [56128/620022]    Loss: 0.009130   Batch Acc: 78.12
[Train] Epoch: 4 [56192/620022]    Loss: 0.007753   Batch Acc: 79.69
[Train] Epoch: 4 [56256/620022]    Loss: 0.010261   Batch Acc: 65.62
[Train] Epoch: 4 [56320/620022]    Loss: 0.008106   Batch Acc: 81.25
[Train] Epoch: 4 [56384/620022]    Loss: 0.007850   Batch Acc: 79.69
[Train] Epoch: 4 [56448/620022]    Loss: 0.009674   Batch Acc: 71.88
[Train] Epoch: 4 [56512/620022]    Loss: 0.008202   Batch Acc: 76.56
[Train] Epoch: 4 [56576/620022]    Loss: 0.007877   Batch Acc: 79.69
[Train] Epoch: 4 [56640/620022]    Loss: 0.009105   Batch Acc: 78.12
[Train] Epoch: 4 [56704/620022]    Loss: 0.008283   Batch Acc: 78.12
[Train] Epoch: 4 [56768/620022]    Loss: 0.009285   Batch Acc: 75.00
[Train] Epoch: 4 [56832/620022]    Loss: 0.011059   Batch Acc: 73.44
[Train] Epoch: 4 [56896/620022]    Loss: 0.009242   Batch Acc: 71.88
[Train] Epoch: 4 [56960/620022]    Loss: 0.008799   Batch Acc: 79.69
[Train] Epoch: 4 [57024/620022]    Loss: 0.009686   Batch Acc: 70.31
[Train] Epoch: 4 [57088/620022]    Loss: 0.007742   Batch Acc: 82.81
[Train] Epoch: 4 [57152/620022]    Loss: 0.007459   Batch Acc: 78.12
[Train] Epoch: 4 [57216/620022]    Loss: 0.011526   Batch Acc: 68.75
[Train] Epoch: 4 [57280/620022]    Loss: 0.007216   Batch Acc: 85.94
[Train] Epoch: 4 [57344/620022]    Loss: 0.008088   Batch Acc: 76.56
[Train] Epoch: 4 [57408/620022]    Loss: 0.006647   Batch Acc: 79.69
[Train] Epoch: 4 [57472/620022]    Loss: 0.009592   Batch Acc: 75.00
[Train] Epoch: 4 [57536/620022]    Loss: 0.007807   Batch Acc: 81.25
[Train] Epoch: 4 [57600/620022]    Loss: 0.007625   Batch Acc: 79.69
[Train] Epoch: 4 [57664/620022]    Loss: 0.010416   Batch Acc: 68.75
[Train] Epoch: 4 [57728/620022]    Loss: 0.009643   Batch Acc: 73.44
[Train] Epoch: 4 [57792/620022]    Loss: 0.010743   Batch Acc: 70.31
[Train] Epoch: 4 [57856/620022]    Loss: 0.009986   Batch Acc: 68.75
[Train] Epoch: 4 [57920/620022]    Loss: 0.008503   Batch Acc: 70.31
[Train] Epoch: 4 [57984/620022]    Loss: 0.007865   Batch Acc: 81.25
[Train] Epoch: 4 [58048/620022]    Loss: 0.006812   Batch Acc: 84.38
[Train] Epoch: 4 [58112/620022]    Loss: 0.006036   Batch Acc: 87.50
[Train] Epoch: 4 [58176/620022]    Loss: 0.011569   Batch Acc: 71.88
[Train] Epoch: 4 [58240/620022]    Loss: 0.010067   Batch Acc: 71.88
[Train] Epoch: 4 [58304/620022]    Loss: 0.010716   Batch Acc: 75.00
[Train] Epoch: 4 [58368/620022]    Loss: 0.011259   Batch Acc: 68.75
[Train] Epoch: 4 [58432/620022]    Loss: 0.008735   Batch Acc: 81.25
[Train] Epoch: 4 [58496/620022]    Loss: 0.008097   Batch Acc: 79.69
[Train] Epoch: 4 [58560/620022]    Loss: 0.009381   Batch Acc: 76.56
[Train] Epoch: 4 [58624/620022]    Loss: 0.008819   Batch Acc: 78.12
[Train] Epoch: 4 [58688/620022]    Loss: 0.009537   Batch Acc: 78.12
[Train] Epoch: 4 [58752/620022]    Loss: 0.008667   Batch Acc: 75.00
[Train] Epoch: 4 [58816/620022]    Loss: 0.009465   Batch Acc: 79.69
[Train] Epoch: 4 [58880/620022]    Loss: 0.010561   Batch Acc: 68.75
[Train] Epoch: 4 [58944/620022]    Loss: 0.012118   Batch Acc: 75.00
[Train] Epoch: 4 [59008/620022]    Loss: 0.008885   Batch Acc: 79.69
[Train] Epoch: 4 [59072/620022]    Loss: 0.008874   Batch Acc: 82.81
[Train] Epoch: 4 [59136/620022]    Loss: 0.006003   Batch Acc: 87.50
[Train] Epoch: 4 [59200/620022]    Loss: 0.009477   Batch Acc: 71.88
[Train] Epoch: 4 [59264/620022]    Loss: 0.008123   Batch Acc: 78.12
[Train] Epoch: 4 [59328/620022]    Loss: 0.007161   Batch Acc: 84.38
[Train] Epoch: 4 [59392/620022]    Loss: 0.008811   Batch Acc: 78.12
[Train] Epoch: 4 [59456/620022]    Loss: 0.007631   Batch Acc: 81.25
[Train] Epoch: 4 [59520/620022]    Loss: 0.008662   Batch Acc: 70.31
[Train] Epoch: 4 [59584/620022]    Loss: 0.008151   Batch Acc: 78.12
[Train] Epoch: 4 [59648/620022]    Loss: 0.008758   Batch Acc: 79.69
[Train] Epoch: 4 [59712/620022]    Loss: 0.007935   Batch Acc: 75.00
[Train] Epoch: 4 [59776/620022]    Loss: 0.008674   Batch Acc: 76.56
[Train] Epoch: 4 [59840/620022]    Loss: 0.008535   Batch Acc: 78.12
[Train] Epoch: 4 [59904/620022]    Loss: 0.010748   Batch Acc: 73.44
[Train] Epoch: 4 [59968/620022]    Loss: 0.007861   Batch Acc: 79.69
[Train] Epoch: 4 [60032/620022]    Loss: 0.007707   Batch Acc: 76.56
[Train] Epoch: 4 [60096/620022]    Loss: 0.009931   Batch Acc: 70.31
[Train] Epoch: 4 [60160/620022]    Loss: 0.009580   Batch Acc: 76.56
[Train] Epoch: 4 [60224/620022]    Loss: 0.007338   Batch Acc: 82.81
[Train] Epoch: 4 [60288/620022]    Loss: 0.007986   Batch Acc: 81.25
[Train] Epoch: 4 [60352/620022]    Loss: 0.009241   Batch Acc: 71.88
[Train] Epoch: 4 [60416/620022]    Loss: 0.008273   Batch Acc: 78.12
[Train] Epoch: 4 [60480/620022]    Loss: 0.009970   Batch Acc: 71.88
[Train] Epoch: 4 [60544/620022]    Loss: 0.009826   Batch Acc: 76.56
[Train] Epoch: 4 [60608/620022]    Loss: 0.007603   Batch Acc: 79.69
[Train] Epoch: 4 [60672/620022]    Loss: 0.007756   Batch Acc: 85.94
[Train] Epoch: 4 [60736/620022]    Loss: 0.007991   Batch Acc: 78.12
[Train] Epoch: 4 [60800/620022]    Loss: 0.009519   Batch Acc: 71.88
[Train] Epoch: 4 [60864/620022]    Loss: 0.008925   Batch Acc: 71.88
[Train] Epoch: 4 [60928/620022]    Loss: 0.008630   Batch Acc: 81.25
[Train] Epoch: 4 [60992/620022]    Loss: 0.008152   Batch Acc: 79.69
[Train] Epoch: 4 [61056/620022]    Loss: 0.010022   Batch Acc: 73.44
[Train] Epoch: 4 [61120/620022]    Loss: 0.009462   Batch Acc: 73.44
[Train] Epoch: 4 [61184/620022]    Loss: 0.009796   Batch Acc: 75.00
[Train] Epoch: 4 [61248/620022]    Loss: 0.006214   Batch Acc: 89.06
[Train] Epoch: 4 [61312/620022]    Loss: 0.011348   Batch Acc: 67.19
[Train] Epoch: 4 [61376/620022]    Loss: 0.007946   Batch Acc: 81.25
[Train] Epoch: 4 [61440/620022]    Loss: 0.007350   Batch Acc: 79.69
[Train] Epoch: 4 [61504/620022]    Loss: 0.008069   Batch Acc: 78.12
[Train] Epoch: 4 [61568/620022]    Loss: 0.006625   Batch Acc: 84.38
[Train] Epoch: 4 [61632/620022]    Loss: 0.009949   Batch Acc: 70.31
[Train] Epoch: 4 [61696/620022]    Loss: 0.008878   Batch Acc: 73.44
[Train] Epoch: 4 [61760/620022]    Loss: 0.006518   Batch Acc: 87.50
[Train] Epoch: 4 [61824/620022]    Loss: 0.008833   Batch Acc: 75.00
[Train] Epoch: 4 [61888/620022]    Loss: 0.006790   Batch Acc: 87.50
[Train] Epoch: 4 [61952/620022]    Loss: 0.009307   Batch Acc: 70.31
[Train] Epoch: 4 [62016/620022]    Loss: 0.006579   Batch Acc: 87.50
[Train] Epoch: 4 [62080/620022]    Loss: 0.012239   Batch Acc: 68.75
[Train] Epoch: 4 [62144/620022]    Loss: 0.007497   Batch Acc: 78.12
[Train] Epoch: 4 [62208/620022]    Loss: 0.011015   Batch Acc: 65.62
[Train] Epoch: 4 [62272/620022]    Loss: 0.008113   Batch Acc: 79.69
[Train] Epoch: 4 [62336/620022]    Loss: 0.011564   Batch Acc: 67.19
[Train] Epoch: 4 [62400/620022]    Loss: 0.007080   Batch Acc: 84.38
[Train] Epoch: 4 [62464/620022]    Loss: 0.007735   Batch Acc: 84.38
[Train] Epoch: 4 [62528/620022]    Loss: 0.008838   Batch Acc: 75.00
[Train] Epoch: 4 [62592/620022]    Loss: 0.010670   Batch Acc: 73.44
[Train] Epoch: 4 [62656/620022]    Loss: 0.009021   Batch Acc: 75.00
[Train] Epoch: 4 [62720/620022]    Loss: 0.007073   Batch Acc: 89.06
[Train] Epoch: 4 [62784/620022]    Loss: 0.005326   Batch Acc: 93.75
[Train] Epoch: 4 [62848/620022]    Loss: 0.007328   Batch Acc: 81.25
[Train] Epoch: 4 [62912/620022]    Loss: 0.007201   Batch Acc: 84.38
[Train] Epoch: 4 [62976/620022]    Loss: 0.008879   Batch Acc: 76.56
[Train] Epoch: 4 [63040/620022]    Loss: 0.007230   Batch Acc: 79.69
[Train] Epoch: 4 [63104/620022]    Loss: 0.009458   Batch Acc: 75.00
[Train] Epoch: 4 [63168/620022]    Loss: 0.009138   Batch Acc: 75.00
[Train] Epoch: 4 [63232/620022]    Loss: 0.007416   Batch Acc: 79.69
[Train] Epoch: 4 [63296/620022]    Loss: 0.008750   Batch Acc: 76.56
[Train] Epoch: 4 [63360/620022]    Loss: 0.007575   Batch Acc: 78.12
[Train] Epoch: 4 [63424/620022]    Loss: 0.008194   Batch Acc: 78.12
[Train] Epoch: 4 [63488/620022]    Loss: 0.010054   Batch Acc: 81.25
[Train] Epoch: 4 [63552/620022]    Loss: 0.007669   Batch Acc: 76.56
[Train] Epoch: 4 [63616/620022]    Loss: 0.009792   Batch Acc: 71.88
[Train] Epoch: 4 [63680/620022]    Loss: 0.008196   Batch Acc: 82.81
[Train] Epoch: 4 [63744/620022]    Loss: 0.009526   Batch Acc: 73.44
[Train] Epoch: 4 [63808/620022]    Loss: 0.009210   Batch Acc: 76.56
[Train] Epoch: 4 [63872/620022]    Loss: 0.008684   Batch Acc: 75.00
[Train] Epoch: 4 [63936/620022]    Loss: 0.008419   Batch Acc: 81.25
[Train] Epoch: 4 [64000/620022]    Loss: 0.008263   Batch Acc: 75.00
[Train] Epoch: 4 [64064/620022]    Loss: 0.009730   Batch Acc: 73.44
[Train] Epoch: 4 [64128/620022]    Loss: 0.009214   Batch Acc: 75.00
[Train] Epoch: 4 [64192/620022]    Loss: 0.009280   Batch Acc: 78.12
[Train] Epoch: 4 [64256/620022]    Loss: 0.006881   Batch Acc: 85.94
[Train] Epoch: 4 [64320/620022]    Loss: 0.009612   Batch Acc: 76.56
[Train] Epoch: 4 [64384/620022]    Loss: 0.008089   Batch Acc: 79.69
[Train] Epoch: 4 [64448/620022]    Loss: 0.006272   Batch Acc: 82.81
[Train] Epoch: 4 [64512/620022]    Loss: 0.009708   Batch Acc: 75.00
[Train] Epoch: 4 [64576/620022]    Loss: 0.007666   Batch Acc: 85.94
[Train] Epoch: 4 [64640/620022]    Loss: 0.008390   Batch Acc: 75.00
[Train] Epoch: 4 [64704/620022]    Loss: 0.009150   Batch Acc: 71.88
[Train] Epoch: 4 [64768/620022]    Loss: 0.008090   Batch Acc: 82.81
[Train] Epoch: 4 [64832/620022]    Loss: 0.007908   Batch Acc: 78.12
[Train] Epoch: 4 [64896/620022]    Loss: 0.010439   Batch Acc: 73.44
[Train] Epoch: 4 [64960/620022]    Loss: 0.009865   Batch Acc: 73.44
[Train] Epoch: 4 [65024/620022]    Loss: 0.008123   Batch Acc: 78.12
[Train] Epoch: 4 [65088/620022]    Loss: 0.008302   Batch Acc: 81.25
[Train] Epoch: 4 [65152/620022]    Loss: 0.008011   Batch Acc: 81.25
[Train] Epoch: 4 [65216/620022]    Loss: 0.006999   Batch Acc: 79.69
[Train] Epoch: 4 [65280/620022]    Loss: 0.006533   Batch Acc: 84.38
[Train] Epoch: 4 [65344/620022]    Loss: 0.008579   Batch Acc: 71.88
[Train] Epoch: 4 [65408/620022]    Loss: 0.009465   Batch Acc: 71.88
[Train] Epoch: 4 [65472/620022]    Loss: 0.007674   Batch Acc: 82.81
[Train] Epoch: 4 [65536/620022]    Loss: 0.007932   Batch Acc: 78.12
[Train] Epoch: 4 [65600/620022]    Loss: 0.009051   Batch Acc: 75.00
[Train] Epoch: 4 [65664/620022]    Loss: 0.007042   Batch Acc: 81.25
[Train] Epoch: 4 [65728/620022]    Loss: 0.007625   Batch Acc: 82.81
[Train] Epoch: 4 [65792/620022]    Loss: 0.006792   Batch Acc: 84.38
[Train] Epoch: 4 [65856/620022]    Loss: 0.007927   Batch Acc: 84.38
[Train] Epoch: 4 [65920/620022]    Loss: 0.007345   Batch Acc: 79.69
[Train] Epoch: 4 [65984/620022]    Loss: 0.009018   Batch Acc: 71.88
[Train] Epoch: 4 [66048/620022]    Loss: 0.009980   Batch Acc: 68.75
[Train] Epoch: 4 [66112/620022]    Loss: 0.011379   Batch Acc: 68.75
[Train] Epoch: 4 [66176/620022]    Loss: 0.009043   Batch Acc: 76.56
[Train] Epoch: 4 [66240/620022]    Loss: 0.006712   Batch Acc: 84.38
[Train] Epoch: 4 [66304/620022]    Loss: 0.008529   Batch Acc: 73.44
[Train] Epoch: 4 [66368/620022]    Loss: 0.008457   Batch Acc: 78.12
[Train] Epoch: 4 [66432/620022]    Loss: 0.009069   Batch Acc: 71.88
[Train] Epoch: 4 [66496/620022]    Loss: 0.007624   Batch Acc: 76.56
[Train] Epoch: 4 [66560/620022]    Loss: 0.008606   Batch Acc: 79.69
[Train] Epoch: 4 [66624/620022]    Loss: 0.008395   Batch Acc: 79.69
[Train] Epoch: 4 [66688/620022]    Loss: 0.007863   Batch Acc: 84.38
[Train] Epoch: 4 [66752/620022]    Loss: 0.008000   Batch Acc: 84.38
[Train] Epoch: 4 [66816/620022]    Loss: 0.007651   Batch Acc: 79.69
[Train] Epoch: 4 [66880/620022]    Loss: 0.011478   Batch Acc: 71.88
[Train] Epoch: 4 [66944/620022]    Loss: 0.007162   Batch Acc: 84.38
[Train] Epoch: 4 [67008/620022]    Loss: 0.008414   Batch Acc: 73.44
[Train] Epoch: 4 [67072/620022]    Loss: 0.011179   Batch Acc: 70.31
[Train] Epoch: 4 [67136/620022]    Loss: 0.009582   Batch Acc: 82.81
[Train] Epoch: 4 [67200/620022]    Loss: 0.007967   Batch Acc: 79.69
[Train] Epoch: 4 [67264/620022]    Loss: 0.007747   Batch Acc: 84.38
[Train] Epoch: 4 [67328/620022]    Loss: 0.008090   Batch Acc: 76.56
[Train] Epoch: 4 [67392/620022]    Loss: 0.010233   Batch Acc: 73.44
[Train] Epoch: 4 [67456/620022]    Loss: 0.007706   Batch Acc: 81.25
[Train] Epoch: 4 [67520/620022]    Loss: 0.008962   Batch Acc: 78.12
[Train] Epoch: 4 [67584/620022]    Loss: 0.008487   Batch Acc: 81.25
[Train] Epoch: 4 [67648/620022]    Loss: 0.008947   Batch Acc: 78.12
[Train] Epoch: 4 [67712/620022]    Loss: 0.009003   Batch Acc: 79.69
[Train] Epoch: 4 [67776/620022]    Loss: 0.010049   Batch Acc: 75.00
[Train] Epoch: 4 [67840/620022]    Loss: 0.007247   Batch Acc: 85.94
[Train] Epoch: 4 [67904/620022]    Loss: 0.007947   Batch Acc: 81.25
[Train] Epoch: 4 [67968/620022]    Loss: 0.007771   Batch Acc: 75.00
[Train] Epoch: 4 [68032/620022]    Loss: 0.007065   Batch Acc: 84.38
[Train] Epoch: 4 [68096/620022]    Loss: 0.009561   Batch Acc: 78.12
[Train] Epoch: 4 [68160/620022]    Loss: 0.008124   Batch Acc: 82.81
[Train] Epoch: 4 [68224/620022]    Loss: 0.009306   Batch Acc: 79.69
[Train] Epoch: 4 [68288/620022]    Loss: 0.010062   Batch Acc: 70.31
[Train] Epoch: 4 [68352/620022]    Loss: 0.012132   Batch Acc: 65.62
[Train] Epoch: 4 [68416/620022]    Loss: 0.011051   Batch Acc: 64.06
[Train] Epoch: 4 [68480/620022]    Loss: 0.007275   Batch Acc: 89.06
[Train] Epoch: 4 [68544/620022]    Loss: 0.007785   Batch Acc: 79.69
[Train] Epoch: 4 [68608/620022]    Loss: 0.007834   Batch Acc: 79.69
[Train] Epoch: 4 [68672/620022]    Loss: 0.007683   Batch Acc: 81.25
[Train] Epoch: 4 [68736/620022]    Loss: 0.009167   Batch Acc: 75.00
[Train] Epoch: 4 [68800/620022]    Loss: 0.009405   Batch Acc: 71.88
[Train] Epoch: 4 [68864/620022]    Loss: 0.008787   Batch Acc: 75.00
[Train] Epoch: 4 [68928/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 4 [68992/620022]    Loss: 0.005741   Batch Acc: 87.50
[Train] Epoch: 4 [69056/620022]    Loss: 0.009064   Batch Acc: 79.69
[Train] Epoch: 4 [69120/620022]    Loss: 0.007433   Batch Acc: 81.25
[Train] Epoch: 4 [69184/620022]    Loss: 0.008769   Batch Acc: 79.69
[Train] Epoch: 4 [69248/620022]    Loss: 0.007772   Batch Acc: 78.12
[Train] Epoch: 4 [69312/620022]    Loss: 0.008606   Batch Acc: 76.56
[Train] Epoch: 4 [69376/620022]    Loss: 0.006947   Batch Acc: 90.62
[Train] Epoch: 4 [69440/620022]    Loss: 0.007423   Batch Acc: 79.69
[Train] Epoch: 4 [69504/620022]    Loss: 0.008637   Batch Acc: 79.69
[Train] Epoch: 4 [69568/620022]    Loss: 0.008340   Batch Acc: 75.00
[Train] Epoch: 4 [69632/620022]    Loss: 0.009171   Batch Acc: 75.00
[Train] Epoch: 4 [69696/620022]    Loss: 0.008690   Batch Acc: 75.00
[Train] Epoch: 4 [69760/620022]    Loss: 0.011873   Batch Acc: 71.88
[Train] Epoch: 4 [69824/620022]    Loss: 0.009361   Batch Acc: 73.44
[Train] Epoch: 4 [69888/620022]    Loss: 0.006656   Batch Acc: 85.94
[Train] Epoch: 4 [69952/620022]    Loss: 0.008737   Batch Acc: 76.56
[Train] Epoch: 4 [70016/620022]    Loss: 0.008933   Batch Acc: 79.69
[Train] Epoch: 4 [70080/620022]    Loss: 0.009300   Batch Acc: 75.00
[Train] Epoch: 4 [70144/620022]    Loss: 0.008342   Batch Acc: 76.56
[Train] Epoch: 4 [70208/620022]    Loss: 0.008617   Batch Acc: 82.81
[Train] Epoch: 4 [70272/620022]    Loss: 0.008323   Batch Acc: 79.69
[Train] Epoch: 4 [70336/620022]    Loss: 0.007799   Batch Acc: 81.25
[Train] Epoch: 4 [70400/620022]    Loss: 0.009653   Batch Acc: 75.00
[Train] Epoch: 4 [70464/620022]    Loss: 0.007581   Batch Acc: 79.69
[Train] Epoch: 4 [70528/620022]    Loss: 0.006315   Batch Acc: 87.50
[Train] Epoch: 4 [70592/620022]    Loss: 0.009434   Batch Acc: 73.44
[Train] Epoch: 4 [70656/620022]    Loss: 0.006486   Batch Acc: 81.25
[Train] Epoch: 4 [70720/620022]    Loss: 0.007098   Batch Acc: 82.81
[Train] Epoch: 4 [70784/620022]    Loss: 0.008452   Batch Acc: 82.81
[Train] Epoch: 4 [70848/620022]    Loss: 0.008857   Batch Acc: 81.25
[Train] Epoch: 4 [70912/620022]    Loss: 0.009111   Batch Acc: 73.44
[Train] Epoch: 4 [70976/620022]    Loss: 0.006668   Batch Acc: 84.38
[Train] Epoch: 4 [71040/620022]    Loss: 0.009709   Batch Acc: 71.88
[Train] Epoch: 4 [71104/620022]    Loss: 0.008850   Batch Acc: 78.12
[Train] Epoch: 4 [71168/620022]    Loss: 0.009055   Batch Acc: 73.44
[Train] Epoch: 4 [71232/620022]    Loss: 0.007728   Batch Acc: 84.38
[Train] Epoch: 4 [71296/620022]    Loss: 0.008316   Batch Acc: 82.81
[Train] Epoch: 4 [71360/620022]    Loss: 0.008490   Batch Acc: 79.69
[Train] Epoch: 4 [71424/620022]    Loss: 0.010077   Batch Acc: 71.88
[Train] Epoch: 4 [71488/620022]    Loss: 0.010748   Batch Acc: 71.88
[Train] Epoch: 4 [71552/620022]    Loss: 0.008572   Batch Acc: 75.00
[Train] Epoch: 4 [71616/620022]    Loss: 0.010997   Batch Acc: 71.88
[Train] Epoch: 4 [71680/620022]    Loss: 0.008389   Batch Acc: 76.56
[Train] Epoch: 4 [71744/620022]    Loss: 0.006480   Batch Acc: 89.06
[Train] Epoch: 4 [71808/620022]    Loss: 0.008316   Batch Acc: 81.25
[Train] Epoch: 4 [71872/620022]    Loss: 0.006035   Batch Acc: 84.38
[Train] Epoch: 4 [71936/620022]    Loss: 0.010370   Batch Acc: 75.00
[Train] Epoch: 4 [72000/620022]    Loss: 0.007486   Batch Acc: 81.25
[Train] Epoch: 4 [72064/620022]    Loss: 0.007790   Batch Acc: 82.81
[Train] Epoch: 4 [72128/620022]    Loss: 0.009828   Batch Acc: 79.69
[Train] Epoch: 4 [72192/620022]    Loss: 0.009117   Batch Acc: 78.12
[Train] Epoch: 4 [72256/620022]    Loss: 0.010791   Batch Acc: 75.00
[Train] Epoch: 4 [72320/620022]    Loss: 0.009191   Batch Acc: 79.69
[Train] Epoch: 4 [72384/620022]    Loss: 0.007601   Batch Acc: 82.81
[Train] Epoch: 4 [72448/620022]    Loss: 0.009878   Batch Acc: 76.56
[Train] Epoch: 4 [72512/620022]    Loss: 0.010345   Batch Acc: 73.44
[Train] Epoch: 4 [72576/620022]    Loss: 0.006995   Batch Acc: 81.25
[Train] Epoch: 4 [72640/620022]    Loss: 0.012801   Batch Acc: 68.75
[Train] Epoch: 4 [72704/620022]    Loss: 0.008377   Batch Acc: 84.38
[Train] Epoch: 4 [72768/620022]    Loss: 0.010437   Batch Acc: 75.00
[Train] Epoch: 4 [72832/620022]    Loss: 0.011730   Batch Acc: 68.75
[Train] Epoch: 4 [72896/620022]    Loss: 0.010627   Batch Acc: 75.00
[Train] Epoch: 4 [72960/620022]    Loss: 0.007569   Batch Acc: 78.12
[Train] Epoch: 4 [73024/620022]    Loss: 0.007556   Batch Acc: 78.12
[Train] Epoch: 4 [73088/620022]    Loss: 0.007238   Batch Acc: 81.25
[Train] Epoch: 4 [73152/620022]    Loss: 0.008929   Batch Acc: 73.44
[Train] Epoch: 4 [73216/620022]    Loss: 0.009121   Batch Acc: 76.56
[Train] Epoch: 4 [73280/620022]    Loss: 0.011014   Batch Acc: 67.19
[Train] Epoch: 4 [73344/620022]    Loss: 0.010196   Batch Acc: 76.56
[Train] Epoch: 4 [73408/620022]    Loss: 0.011333   Batch Acc: 71.88
[Train] Epoch: 4 [73472/620022]    Loss: 0.008620   Batch Acc: 76.56
[Train] Epoch: 4 [73536/620022]    Loss: 0.007808   Batch Acc: 75.00
[Train] Epoch: 4 [73600/620022]    Loss: 0.010811   Batch Acc: 75.00
[Train] Epoch: 4 [73664/620022]    Loss: 0.008354   Batch Acc: 79.69
[Train] Epoch: 4 [73728/620022]    Loss: 0.013468   Batch Acc: 62.50
[Train] Epoch: 4 [73792/620022]    Loss: 0.007314   Batch Acc: 78.12
[Train] Epoch: 4 [73856/620022]    Loss: 0.006987   Batch Acc: 85.94
[Train] Epoch: 4 [73920/620022]    Loss: 0.009107   Batch Acc: 76.56
[Train] Epoch: 4 [73984/620022]    Loss: 0.009407   Batch Acc: 73.44
[Train] Epoch: 4 [74048/620022]    Loss: 0.007273   Batch Acc: 78.12
[Train] Epoch: 4 [74112/620022]    Loss: 0.007406   Batch Acc: 82.81
[Train] Epoch: 4 [74176/620022]    Loss: 0.010982   Batch Acc: 67.19
[Train] Epoch: 4 [74240/620022]    Loss: 0.007448   Batch Acc: 78.12
[Train] Epoch: 4 [74304/620022]    Loss: 0.008485   Batch Acc: 79.69
[Train] Epoch: 4 [74368/620022]    Loss: 0.008469   Batch Acc: 71.88
[Train] Epoch: 4 [74432/620022]    Loss: 0.005740   Batch Acc: 92.19
[Train] Epoch: 4 [74496/620022]    Loss: 0.011224   Batch Acc: 73.44
[Train] Epoch: 4 [74560/620022]    Loss: 0.010748   Batch Acc: 67.19
[Train] Epoch: 4 [74624/620022]    Loss: 0.009740   Batch Acc: 76.56
[Train] Epoch: 4 [74688/620022]    Loss: 0.007438   Batch Acc: 78.12
[Train] Epoch: 4 [74752/620022]    Loss: 0.008104   Batch Acc: 84.38
[Train] Epoch: 4 [74816/620022]    Loss: 0.007198   Batch Acc: 81.25
[Train] Epoch: 4 [74880/620022]    Loss: 0.007555   Batch Acc: 82.81
[Train] Epoch: 4 [74944/620022]    Loss: 0.009742   Batch Acc: 78.12
[Train] Epoch: 4 [75008/620022]    Loss: 0.009482   Batch Acc: 78.12
[Train] Epoch: 4 [75072/620022]    Loss: 0.006764   Batch Acc: 84.38
[Train] Epoch: 4 [75136/620022]    Loss: 0.008390   Batch Acc: 78.12
[Train] Epoch: 4 [75200/620022]    Loss: 0.008989   Batch Acc: 81.25
[Train] Epoch: 4 [75264/620022]    Loss: 0.008674   Batch Acc: 73.44
[Train] Epoch: 4 [75328/620022]    Loss: 0.008867   Batch Acc: 76.56
[Train] Epoch: 4 [75392/620022]    Loss: 0.007719   Batch Acc: 81.25
[Train] Epoch: 4 [75456/620022]    Loss: 0.006855   Batch Acc: 79.69
[Train] Epoch: 4 [75520/620022]    Loss: 0.009123   Batch Acc: 76.56
[Train] Epoch: 4 [75584/620022]    Loss: 0.008677   Batch Acc: 78.12
[Train] Epoch: 4 [75648/620022]    Loss: 0.007744   Batch Acc: 81.25
[Train] Epoch: 4 [75712/620022]    Loss: 0.007768   Batch Acc: 82.81
[Train] Epoch: 4 [75776/620022]    Loss: 0.009113   Batch Acc: 79.69
[Train] Epoch: 4 [75840/620022]    Loss: 0.011169   Batch Acc: 68.75
[Train] Epoch: 4 [75904/620022]    Loss: 0.008835   Batch Acc: 78.12
[Train] Epoch: 4 [75968/620022]    Loss: 0.008291   Batch Acc: 82.81
[Train] Epoch: 4 [76032/620022]    Loss: 0.010204   Batch Acc: 70.31
[Train] Epoch: 4 [76096/620022]    Loss: 0.007333   Batch Acc: 85.94
[Train] Epoch: 4 [76160/620022]    Loss: 0.010661   Batch Acc: 67.19
[Train] Epoch: 4 [76224/620022]    Loss: 0.009501   Batch Acc: 78.12
[Train] Epoch: 4 [76288/620022]    Loss: 0.008729   Batch Acc: 79.69
[Train] Epoch: 4 [76352/620022]    Loss: 0.006607   Batch Acc: 85.94
[Train] Epoch: 4 [76416/620022]    Loss: 0.008528   Batch Acc: 71.88
[Train] Epoch: 4 [76480/620022]    Loss: 0.006476   Batch Acc: 85.94
[Train] Epoch: 4 [76544/620022]    Loss: 0.007914   Batch Acc: 81.25
[Train] Epoch: 4 [76608/620022]    Loss: 0.009240   Batch Acc: 75.00
[Train] Epoch: 4 [76672/620022]    Loss: 0.009704   Batch Acc: 71.88
[Train] Epoch: 4 [76736/620022]    Loss: 0.006547   Batch Acc: 85.94
[Train] Epoch: 4 [76800/620022]    Loss: 0.008079   Batch Acc: 78.12
[Train] Epoch: 4 [76864/620022]    Loss: 0.008581   Batch Acc: 78.12
[Train] Epoch: 4 [76928/620022]    Loss: 0.007558   Batch Acc: 81.25
[Train] Epoch: 4 [76992/620022]    Loss: 0.007905   Batch Acc: 81.25
[Train] Epoch: 4 [77056/620022]    Loss: 0.008734   Batch Acc: 76.56
[Train] Epoch: 4 [77120/620022]    Loss: 0.008912   Batch Acc: 75.00
[Train] Epoch: 4 [77184/620022]    Loss: 0.008978   Batch Acc: 73.44
[Train] Epoch: 4 [77248/620022]    Loss: 0.009746   Batch Acc: 73.44
[Train] Epoch: 4 [77312/620022]    Loss: 0.007738   Batch Acc: 79.69
[Train] Epoch: 4 [77376/620022]    Loss: 0.008496   Batch Acc: 84.38
[Train] Epoch: 4 [77440/620022]    Loss: 0.007007   Batch Acc: 78.12
[Train] Epoch: 4 [77504/620022]    Loss: 0.008934   Batch Acc: 71.88
[Train] Epoch: 4 [77568/620022]    Loss: 0.009217   Batch Acc: 76.56
[Train] Epoch: 4 [77632/620022]    Loss: 0.008865   Batch Acc: 75.00
[Train] Epoch: 4 [77696/620022]    Loss: 0.009086   Batch Acc: 76.56
[Train] Epoch: 4 [77760/620022]    Loss: 0.006898   Batch Acc: 85.94
[Train] Epoch: 4 [77824/620022]    Loss: 0.011927   Batch Acc: 70.31
[Train] Epoch: 4 [77888/620022]    Loss: 0.007098   Batch Acc: 84.38
[Train] Epoch: 4 [77952/620022]    Loss: 0.009327   Batch Acc: 70.31
[Train] Epoch: 4 [78016/620022]    Loss: 0.009719   Batch Acc: 73.44
[Train] Epoch: 4 [78080/620022]    Loss: 0.010897   Batch Acc: 65.62
[Train] Epoch: 4 [78144/620022]    Loss: 0.010840   Batch Acc: 70.31
[Train] Epoch: 4 [78208/620022]    Loss: 0.009271   Batch Acc: 71.88
[Train] Epoch: 4 [78272/620022]    Loss: 0.009025   Batch Acc: 78.12
[Train] Epoch: 4 [78336/620022]    Loss: 0.010458   Batch Acc: 71.88
[Train] Epoch: 4 [78400/620022]    Loss: 0.009347   Batch Acc: 78.12
[Train] Epoch: 4 [78464/620022]    Loss: 0.008455   Batch Acc: 76.56
[Train] Epoch: 4 [78528/620022]    Loss: 0.007861   Batch Acc: 78.12
[Train] Epoch: 4 [78592/620022]    Loss: 0.007072   Batch Acc: 85.94
[Train] Epoch: 4 [78656/620022]    Loss: 0.008122   Batch Acc: 75.00
[Train] Epoch: 4 [78720/620022]    Loss: 0.008641   Batch Acc: 78.12
[Train] Epoch: 4 [78784/620022]    Loss: 0.007354   Batch Acc: 84.38
[Train] Epoch: 4 [78848/620022]    Loss: 0.006965   Batch Acc: 84.38
[Train] Epoch: 4 [78912/620022]    Loss: 0.008934   Batch Acc: 78.12
[Train] Epoch: 4 [78976/620022]    Loss: 0.006768   Batch Acc: 82.81
[Train] Epoch: 4 [79040/620022]    Loss: 0.011021   Batch Acc: 71.88
[Train] Epoch: 4 [79104/620022]    Loss: 0.010204   Batch Acc: 73.44
[Train] Epoch: 4 [79168/620022]    Loss: 0.008070   Batch Acc: 75.00
[Train] Epoch: 4 [79232/620022]    Loss: 0.009911   Batch Acc: 73.44
[Train] Epoch: 4 [79296/620022]    Loss: 0.007654   Batch Acc: 82.81
[Train] Epoch: 4 [79360/620022]    Loss: 0.009424   Batch Acc: 76.56
[Train] Epoch: 4 [79424/620022]    Loss: 0.011951   Batch Acc: 64.06
[Train] Epoch: 4 [79488/620022]    Loss: 0.007136   Batch Acc: 79.69
[Train] Epoch: 4 [79552/620022]    Loss: 0.008376   Batch Acc: 79.69
[Train] Epoch: 4 [79616/620022]    Loss: 0.009495   Batch Acc: 78.12
[Train] Epoch: 4 [79680/620022]    Loss: 0.007895   Batch Acc: 85.94
[Train] Epoch: 4 [79744/620022]    Loss: 0.007693   Batch Acc: 84.38
[Train] Epoch: 4 [79808/620022]    Loss: 0.006943   Batch Acc: 87.50
[Train] Epoch: 4 [79872/620022]    Loss: 0.008265   Batch Acc: 78.12
[Train] Epoch: 4 [79936/620022]    Loss: 0.010082   Batch Acc: 67.19
[Train] Epoch: 4 [80000/620022]    Loss: 0.007409   Batch Acc: 85.94
[Train] Epoch: 4 [80064/620022]    Loss: 0.008776   Batch Acc: 78.12
[Train] Epoch: 4 [80128/620022]    Loss: 0.008987   Batch Acc: 76.56
[Train] Epoch: 4 [80192/620022]    Loss: 0.007311   Batch Acc: 85.94
[Train] Epoch: 4 [80256/620022]    Loss: 0.008892   Batch Acc: 73.44
[Train] Epoch: 4 [80320/620022]    Loss: 0.009053   Batch Acc: 73.44
[Train] Epoch: 4 [80384/620022]    Loss: 0.006584   Batch Acc: 84.38
[Train] Epoch: 4 [80448/620022]    Loss: 0.009712   Batch Acc: 78.12
[Train] Epoch: 4 [80512/620022]    Loss: 0.009816   Batch Acc: 75.00
[Train] Epoch: 4 [80576/620022]    Loss: 0.009971   Batch Acc: 73.44
[Train] Epoch: 4 [80640/620022]    Loss: 0.009528   Batch Acc: 73.44
[Train] Epoch: 4 [80704/620022]    Loss: 0.009752   Batch Acc: 79.69
[Train] Epoch: 4 [80768/620022]    Loss: 0.007830   Batch Acc: 84.38
[Train] Epoch: 4 [80832/620022]    Loss: 0.009489   Batch Acc: 71.88
[Train] Epoch: 4 [80896/620022]    Loss: 0.010086   Batch Acc: 73.44
[Train] Epoch: 4 [80960/620022]    Loss: 0.009958   Batch Acc: 71.88
[Train] Epoch: 4 [81024/620022]    Loss: 0.007500   Batch Acc: 81.25
[Train] Epoch: 4 [81088/620022]    Loss: 0.007558   Batch Acc: 85.94
[Train] Epoch: 4 [81152/620022]    Loss: 0.006862   Batch Acc: 85.94
[Train] Epoch: 4 [81216/620022]    Loss: 0.007582   Batch Acc: 82.81
[Train] Epoch: 4 [81280/620022]    Loss: 0.009080   Batch Acc: 73.44
[Train] Epoch: 4 [81344/620022]    Loss: 0.008821   Batch Acc: 76.56
[Train] Epoch: 4 [81408/620022]    Loss: 0.007835   Batch Acc: 79.69
[Train] Epoch: 4 [81472/620022]    Loss: 0.008418   Batch Acc: 81.25
[Train] Epoch: 4 [81536/620022]    Loss: 0.010947   Batch Acc: 68.75
[Train] Epoch: 4 [81600/620022]    Loss: 0.011402   Batch Acc: 76.56
[Train] Epoch: 4 [81664/620022]    Loss: 0.006853   Batch Acc: 85.94
[Train] Epoch: 4 [81728/620022]    Loss: 0.009917   Batch Acc: 71.88
[Train] Epoch: 4 [81792/620022]    Loss: 0.007004   Batch Acc: 85.94
[Train] Epoch: 4 [81856/620022]    Loss: 0.010573   Batch Acc: 75.00
[Train] Epoch: 4 [81920/620022]    Loss: 0.006961   Batch Acc: 82.81
[Train] Epoch: 4 [81984/620022]    Loss: 0.008014   Batch Acc: 79.69
[Train] Epoch: 4 [82048/620022]    Loss: 0.009480   Batch Acc: 76.56
[Train] Epoch: 4 [82112/620022]    Loss: 0.007225   Batch Acc: 82.81
[Train] Epoch: 4 [82176/620022]    Loss: 0.012044   Batch Acc: 65.62
[Train] Epoch: 4 [82240/620022]    Loss: 0.008616   Batch Acc: 81.25
[Train] Epoch: 4 [82304/620022]    Loss: 0.010683   Batch Acc: 71.88
[Train] Epoch: 4 [82368/620022]    Loss: 0.010351   Batch Acc: 68.75
[Train] Epoch: 4 [82432/620022]    Loss: 0.009890   Batch Acc: 75.00
[Train] Epoch: 4 [82496/620022]    Loss: 0.007677   Batch Acc: 79.69
[Train] Epoch: 4 [82560/620022]    Loss: 0.008364   Batch Acc: 79.69
[Train] Epoch: 4 [82624/620022]    Loss: 0.010166   Batch Acc: 71.88
[Train] Epoch: 4 [82688/620022]    Loss: 0.011388   Batch Acc: 68.75
[Train] Epoch: 4 [82752/620022]    Loss: 0.011059   Batch Acc: 65.62
[Train] Epoch: 4 [82816/620022]    Loss: 0.008714   Batch Acc: 78.12
[Train] Epoch: 4 [82880/620022]    Loss: 0.009767   Batch Acc: 76.56
[Train] Epoch: 4 [82944/620022]    Loss: 0.009069   Batch Acc: 75.00
[Train] Epoch: 4 [83008/620022]    Loss: 0.008698   Batch Acc: 78.12
[Train] Epoch: 4 [83072/620022]    Loss: 0.010409   Batch Acc: 76.56
[Train] Epoch: 4 [83136/620022]    Loss: 0.008690   Batch Acc: 76.56
[Train] Epoch: 4 [83200/620022]    Loss: 0.009293   Batch Acc: 78.12
[Train] Epoch: 4 [83264/620022]    Loss: 0.007987   Batch Acc: 73.44
[Train] Epoch: 4 [83328/620022]    Loss: 0.006607   Batch Acc: 84.38
[Train] Epoch: 4 [83392/620022]    Loss: 0.006539   Batch Acc: 84.38
[Train] Epoch: 4 [83456/620022]    Loss: 0.010792   Batch Acc: 68.75
[Train] Epoch: 4 [83520/620022]    Loss: 0.006638   Batch Acc: 85.94
[Train] Epoch: 4 [83584/620022]    Loss: 0.009129   Batch Acc: 82.81
[Train] Epoch: 4 [83648/620022]    Loss: 0.010290   Batch Acc: 73.44
[Train] Epoch: 4 [83712/620022]    Loss: 0.009417   Batch Acc: 78.12
[Train] Epoch: 4 [83776/620022]    Loss: 0.009289   Batch Acc: 75.00
[Train] Epoch: 4 [83840/620022]    Loss: 0.006646   Batch Acc: 87.50
[Train] Epoch: 4 [83904/620022]    Loss: 0.006440   Batch Acc: 85.94
[Train] Epoch: 4 [83968/620022]    Loss: 0.009380   Batch Acc: 71.88
[Train] Epoch: 4 [84032/620022]    Loss: 0.007393   Batch Acc: 85.94
[Train] Epoch: 4 [84096/620022]    Loss: 0.009383   Batch Acc: 76.56
[Train] Epoch: 4 [84160/620022]    Loss: 0.010057   Batch Acc: 73.44
[Train] Epoch: 4 [84224/620022]    Loss: 0.011885   Batch Acc: 67.19
[Train] Epoch: 4 [84288/620022]    Loss: 0.009934   Batch Acc: 76.56
[Train] Epoch: 4 [84352/620022]    Loss: 0.008677   Batch Acc: 81.25
[Train] Epoch: 4 [84416/620022]    Loss: 0.008995   Batch Acc: 79.69
[Train] Epoch: 4 [84480/620022]    Loss: 0.008789   Batch Acc: 78.12
[Train] Epoch: 4 [84544/620022]    Loss: 0.010895   Batch Acc: 70.31
[Train] Epoch: 4 [84608/620022]    Loss: 0.008102   Batch Acc: 78.12
[Train] Epoch: 4 [84672/620022]    Loss: 0.009019   Batch Acc: 78.12
[Train] Epoch: 4 [84736/620022]    Loss: 0.009667   Batch Acc: 78.12
[Train] Epoch: 4 [84800/620022]    Loss: 0.009266   Batch Acc: 78.12
[Train] Epoch: 4 [84864/620022]    Loss: 0.007343   Batch Acc: 84.38
[Train] Epoch: 4 [84928/620022]    Loss: 0.008209   Batch Acc: 81.25
[Train] Epoch: 4 [84992/620022]    Loss: 0.009771   Batch Acc: 73.44
[Train] Epoch: 4 [85056/620022]    Loss: 0.009434   Batch Acc: 75.00
[Train] Epoch: 4 [85120/620022]    Loss: 0.009250   Batch Acc: 76.56
[Train] Epoch: 4 [85184/620022]    Loss: 0.011901   Batch Acc: 68.75
[Train] Epoch: 4 [85248/620022]    Loss: 0.006894   Batch Acc: 84.38
[Train] Epoch: 4 [85312/620022]    Loss: 0.009283   Batch Acc: 73.44
[Train] Epoch: 4 [85376/620022]    Loss: 0.007412   Batch Acc: 81.25
[Train] Epoch: 4 [85440/620022]    Loss: 0.008472   Batch Acc: 78.12
[Train] Epoch: 4 [85504/620022]    Loss: 0.007235   Batch Acc: 79.69
[Train] Epoch: 4 [85568/620022]    Loss: 0.009390   Batch Acc: 70.31
[Train] Epoch: 4 [85632/620022]    Loss: 0.006350   Batch Acc: 89.06
[Train] Epoch: 4 [85696/620022]    Loss: 0.009664   Batch Acc: 75.00
[Train] Epoch: 4 [85760/620022]    Loss: 0.007531   Batch Acc: 82.81
[Train] Epoch: 4 [85824/620022]    Loss: 0.010741   Batch Acc: 73.44
[Train] Epoch: 4 [85888/620022]    Loss: 0.009776   Batch Acc: 70.31
[Train] Epoch: 4 [85952/620022]    Loss: 0.008668   Batch Acc: 82.81
[Train] Epoch: 4 [86016/620022]    Loss: 0.007290   Batch Acc: 87.50
[Train] Epoch: 4 [86080/620022]    Loss: 0.009959   Batch Acc: 70.31
[Train] Epoch: 4 [86144/620022]    Loss: 0.009700   Batch Acc: 76.56
[Train] Epoch: 4 [86208/620022]    Loss: 0.007214   Batch Acc: 78.12
[Train] Epoch: 4 [86272/620022]    Loss: 0.009233   Batch Acc: 73.44
[Train] Epoch: 4 [86336/620022]    Loss: 0.008114   Batch Acc: 76.56
[Train] Epoch: 4 [86400/620022]    Loss: 0.009001   Batch Acc: 75.00
[Train] Epoch: 4 [86464/620022]    Loss: 0.006774   Batch Acc: 82.81
[Train] Epoch: 4 [86528/620022]    Loss: 0.008660   Batch Acc: 78.12
[Train] Epoch: 4 [86592/620022]    Loss: 0.008337   Batch Acc: 78.12
[Train] Epoch: 4 [86656/620022]    Loss: 0.008301   Batch Acc: 82.81
[Train] Epoch: 4 [86720/620022]    Loss: 0.005935   Batch Acc: 87.50
[Train] Epoch: 4 [86784/620022]    Loss: 0.007201   Batch Acc: 85.94
[Train] Epoch: 4 [86848/620022]    Loss: 0.007988   Batch Acc: 79.69
[Train] Epoch: 4 [86912/620022]    Loss: 0.010030   Batch Acc: 71.88
[Train] Epoch: 4 [86976/620022]    Loss: 0.008558   Batch Acc: 79.69
[Train] Epoch: 4 [87040/620022]    Loss: 0.009874   Batch Acc: 73.44
[Train] Epoch: 4 [87104/620022]    Loss: 0.008615   Batch Acc: 75.00
[Train] Epoch: 4 [87168/620022]    Loss: 0.009061   Batch Acc: 78.12
[Train] Epoch: 4 [87232/620022]    Loss: 0.007774   Batch Acc: 78.12
[Train] Epoch: 4 [87296/620022]    Loss: 0.009676   Batch Acc: 75.00
[Train] Epoch: 4 [87360/620022]    Loss: 0.007742   Batch Acc: 75.00
[Train] Epoch: 4 [87424/620022]    Loss: 0.008940   Batch Acc: 76.56
[Train] Epoch: 4 [87488/620022]    Loss: 0.012727   Batch Acc: 70.31
[Train] Epoch: 4 [87552/620022]    Loss: 0.007337   Batch Acc: 78.12
[Train] Epoch: 4 [87616/620022]    Loss: 0.009996   Batch Acc: 68.75
[Train] Epoch: 4 [87680/620022]    Loss: 0.007550   Batch Acc: 78.12
[Train] Epoch: 4 [87744/620022]    Loss: 0.009176   Batch Acc: 78.12
[Train] Epoch: 4 [87808/620022]    Loss: 0.008434   Batch Acc: 79.69
[Train] Epoch: 4 [87872/620022]    Loss: 0.010953   Batch Acc: 71.88
[Train] Epoch: 4 [87936/620022]    Loss: 0.010952   Batch Acc: 68.75
[Train] Epoch: 4 [88000/620022]    Loss: 0.008255   Batch Acc: 76.56
[Train] Epoch: 4 [88064/620022]    Loss: 0.006917   Batch Acc: 82.81
[Train] Epoch: 4 [88128/620022]    Loss: 0.008352   Batch Acc: 75.00
[Train] Epoch: 4 [88192/620022]    Loss: 0.008345   Batch Acc: 78.12
[Train] Epoch: 4 [88256/620022]    Loss: 0.007105   Batch Acc: 85.94
[Train] Epoch: 4 [88320/620022]    Loss: 0.009329   Batch Acc: 75.00
[Train] Epoch: 4 [88384/620022]    Loss: 0.010169   Batch Acc: 78.12
[Train] Epoch: 4 [88448/620022]    Loss: 0.009700   Batch Acc: 65.62
[Train] Epoch: 4 [88512/620022]    Loss: 0.009199   Batch Acc: 73.44
[Train] Epoch: 4 [88576/620022]    Loss: 0.007472   Batch Acc: 82.81
[Train] Epoch: 4 [88640/620022]    Loss: 0.006914   Batch Acc: 81.25
[Train] Epoch: 4 [88704/620022]    Loss: 0.008338   Batch Acc: 79.69
[Train] Epoch: 4 [88768/620022]    Loss: 0.009170   Batch Acc: 76.56
[Train] Epoch: 4 [88832/620022]    Loss: 0.009198   Batch Acc: 73.44
[Train] Epoch: 4 [88896/620022]    Loss: 0.008597   Batch Acc: 76.56
[Train] Epoch: 4 [88960/620022]    Loss: 0.007525   Batch Acc: 87.50
[Train] Epoch: 4 [89024/620022]    Loss: 0.007757   Batch Acc: 81.25
[Train] Epoch: 4 [89088/620022]    Loss: 0.008635   Batch Acc: 78.12
[Train] Epoch: 4 [89152/620022]    Loss: 0.009733   Batch Acc: 71.88
[Train] Epoch: 4 [89216/620022]    Loss: 0.006399   Batch Acc: 85.94
[Train] Epoch: 4 [89280/620022]    Loss: 0.009837   Batch Acc: 70.31
[Train] Epoch: 4 [89344/620022]    Loss: 0.010387   Batch Acc: 70.31
[Train] Epoch: 4 [89408/620022]    Loss: 0.008034   Batch Acc: 78.12
[Train] Epoch: 4 [89472/620022]    Loss: 0.008102   Batch Acc: 81.25
[Train] Epoch: 4 [89536/620022]    Loss: 0.008441   Batch Acc: 73.44
[Train] Epoch: 4 [89600/620022]    Loss: 0.009248   Batch Acc: 75.00
[Train] Epoch: 4 [89664/620022]    Loss: 0.009688   Batch Acc: 78.12
[Train] Epoch: 4 [89728/620022]    Loss: 0.006411   Batch Acc: 85.94
[Train] Epoch: 4 [89792/620022]    Loss: 0.007287   Batch Acc: 85.94
[Train] Epoch: 4 [89856/620022]    Loss: 0.010155   Batch Acc: 67.19
[Train] Epoch: 4 [89920/620022]    Loss: 0.008665   Batch Acc: 79.69
[Train] Epoch: 4 [89984/620022]    Loss: 0.007292   Batch Acc: 82.81
[Train] Epoch: 4 [90048/620022]    Loss: 0.008038   Batch Acc: 81.25
[Train] Epoch: 4 [90112/620022]    Loss: 0.007392   Batch Acc: 79.69
[Train] Epoch: 4 [90176/620022]    Loss: 0.008514   Batch Acc: 81.25
[Train] Epoch: 4 [90240/620022]    Loss: 0.008676   Batch Acc: 79.69
[Train] Epoch: 4 [90304/620022]    Loss: 0.009413   Batch Acc: 79.69
[Train] Epoch: 4 [90368/620022]    Loss: 0.008585   Batch Acc: 73.44
[Train] Epoch: 4 [90432/620022]    Loss: 0.010501   Batch Acc: 73.44
[Train] Epoch: 4 [90496/620022]    Loss: 0.008289   Batch Acc: 75.00
[Train] Epoch: 4 [90560/620022]    Loss: 0.008289   Batch Acc: 75.00
[Train] Epoch: 4 [90624/620022]    Loss: 0.009429   Batch Acc: 71.88
[Train] Epoch: 4 [90688/620022]    Loss: 0.006846   Batch Acc: 84.38
[Train] Epoch: 4 [90752/620022]    Loss: 0.007085   Batch Acc: 85.94
[Train] Epoch: 4 [90816/620022]    Loss: 0.009694   Batch Acc: 75.00
[Train] Epoch: 4 [90880/620022]    Loss: 0.009044   Batch Acc: 81.25
[Train] Epoch: 4 [90944/620022]    Loss: 0.007574   Batch Acc: 82.81
[Train] Epoch: 4 [91008/620022]    Loss: 0.007234   Batch Acc: 84.38
[Train] Epoch: 4 [91072/620022]    Loss: 0.008321   Batch Acc: 81.25
[Train] Epoch: 4 [91136/620022]    Loss: 0.008535   Batch Acc: 76.56
[Train] Epoch: 4 [91200/620022]    Loss: 0.009528   Batch Acc: 78.12
[Train] Epoch: 4 [91264/620022]    Loss: 0.008635   Batch Acc: 76.56
[Train] Epoch: 4 [91328/620022]    Loss: 0.006855   Batch Acc: 81.25
[Train] Epoch: 4 [91392/620022]    Loss: 0.010036   Batch Acc: 70.31
[Train] Epoch: 4 [91456/620022]    Loss: 0.008881   Batch Acc: 78.12
[Train] Epoch: 4 [91520/620022]    Loss: 0.008288   Batch Acc: 78.12
[Train] Epoch: 4 [91584/620022]    Loss: 0.004991   Batch Acc: 87.50
[Train] Epoch: 4 [91648/620022]    Loss: 0.008240   Batch Acc: 78.12
[Train] Epoch: 4 [91712/620022]    Loss: 0.009161   Batch Acc: 70.31
[Train] Epoch: 4 [91776/620022]    Loss: 0.007987   Batch Acc: 79.69
[Train] Epoch: 4 [91840/620022]    Loss: 0.007254   Batch Acc: 79.69
[Train] Epoch: 4 [91904/620022]    Loss: 0.011869   Batch Acc: 64.06
[Train] Epoch: 4 [91968/620022]    Loss: 0.008230   Batch Acc: 78.12
[Train] Epoch: 4 [92032/620022]    Loss: 0.008566   Batch Acc: 78.12
[Train] Epoch: 4 [92096/620022]    Loss: 0.007995   Batch Acc: 79.69
[Train] Epoch: 4 [92160/620022]    Loss: 0.008846   Batch Acc: 76.56
[Train] Epoch: 4 [92224/620022]    Loss: 0.009095   Batch Acc: 73.44
[Train] Epoch: 4 [92288/620022]    Loss: 0.007034   Batch Acc: 81.25
[Train] Epoch: 4 [92352/620022]    Loss: 0.010625   Batch Acc: 67.19
[Train] Epoch: 4 [92416/620022]    Loss: 0.010046   Batch Acc: 75.00
[Train] Epoch: 4 [92480/620022]    Loss: 0.007330   Batch Acc: 84.38
[Train] Epoch: 4 [92544/620022]    Loss: 0.008248   Batch Acc: 76.56
[Train] Epoch: 4 [92608/620022]    Loss: 0.009826   Batch Acc: 75.00
[Train] Epoch: 4 [92672/620022]    Loss: 0.007090   Batch Acc: 84.38
[Train] Epoch: 4 [92736/620022]    Loss: 0.009792   Batch Acc: 81.25
[Train] Epoch: 4 [92800/620022]    Loss: 0.010149   Batch Acc: 70.31
[Train] Epoch: 4 [92864/620022]    Loss: 0.008545   Batch Acc: 78.12
[Train] Epoch: 4 [92928/620022]    Loss: 0.008374   Batch Acc: 79.69
[Train] Epoch: 4 [92992/620022]    Loss: 0.007453   Batch Acc: 79.69
[Train] Epoch: 4 [93056/620022]    Loss: 0.010714   Batch Acc: 67.19
[Train] Epoch: 4 [93120/620022]    Loss: 0.009592   Batch Acc: 78.12
[Train] Epoch: 4 [93184/620022]    Loss: 0.008758   Batch Acc: 73.44
[Train] Epoch: 4 [93248/620022]    Loss: 0.009502   Batch Acc: 73.44
[Train] Epoch: 4 [93312/620022]    Loss: 0.008614   Batch Acc: 82.81
[Train] Epoch: 4 [93376/620022]    Loss: 0.007331   Batch Acc: 85.94
[Train] Epoch: 4 [93440/620022]    Loss: 0.010192   Batch Acc: 68.75
[Train] Epoch: 4 [93504/620022]    Loss: 0.008172   Batch Acc: 78.12
[Train] Epoch: 4 [93568/620022]    Loss: 0.008294   Batch Acc: 73.44
[Train] Epoch: 4 [93632/620022]    Loss: 0.008365   Batch Acc: 78.12
[Train] Epoch: 4 [93696/620022]    Loss: 0.007143   Batch Acc: 79.69
[Train] Epoch: 4 [93760/620022]    Loss: 0.011075   Batch Acc: 71.88
[Train] Epoch: 4 [93824/620022]    Loss: 0.007767   Batch Acc: 81.25
[Train] Epoch: 4 [93888/620022]    Loss: 0.008308   Batch Acc: 82.81
[Train] Epoch: 4 [93952/620022]    Loss: 0.007367   Batch Acc: 85.94
[Train] Epoch: 4 [94016/620022]    Loss: 0.009475   Batch Acc: 78.12
[Train] Epoch: 4 [94080/620022]    Loss: 0.010628   Batch Acc: 78.12
[Train] Epoch: 4 [94144/620022]    Loss: 0.006420   Batch Acc: 82.81
[Train] Epoch: 4 [94208/620022]    Loss: 0.010107   Batch Acc: 68.75
[Train] Epoch: 4 [94272/620022]    Loss: 0.007366   Batch Acc: 82.81
[Train] Epoch: 4 [94336/620022]    Loss: 0.007794   Batch Acc: 82.81
[Train] Epoch: 4 [94400/620022]    Loss: 0.011277   Batch Acc: 70.31
[Train] Epoch: 4 [94464/620022]    Loss: 0.007377   Batch Acc: 84.38
[Train] Epoch: 4 [94528/620022]    Loss: 0.006817   Batch Acc: 82.81
[Train] Epoch: 4 [94592/620022]    Loss: 0.008265   Batch Acc: 78.12
[Train] Epoch: 4 [94656/620022]    Loss: 0.008540   Batch Acc: 76.56
[Train] Epoch: 4 [94720/620022]    Loss: 0.007041   Batch Acc: 85.94
[Train] Epoch: 4 [94784/620022]    Loss: 0.005670   Batch Acc: 85.94
[Train] Epoch: 4 [94848/620022]    Loss: 0.007774   Batch Acc: 78.12
[Train] Epoch: 4 [94912/620022]    Loss: 0.006079   Batch Acc: 87.50
[Train] Epoch: 4 [94976/620022]    Loss: 0.009246   Batch Acc: 75.00
[Train] Epoch: 4 [95040/620022]    Loss: 0.007420   Batch Acc: 85.94
[Train] Epoch: 4 [95104/620022]    Loss: 0.008613   Batch Acc: 79.69
[Train] Epoch: 4 [95168/620022]    Loss: 0.010236   Batch Acc: 75.00
[Train] Epoch: 4 [95232/620022]    Loss: 0.007693   Batch Acc: 81.25
[Train] Epoch: 4 [95296/620022]    Loss: 0.008842   Batch Acc: 81.25
[Train] Epoch: 4 [95360/620022]    Loss: 0.007131   Batch Acc: 78.12
[Train] Epoch: 4 [95424/620022]    Loss: 0.009815   Batch Acc: 75.00
[Train] Epoch: 4 [95488/620022]    Loss: 0.005712   Batch Acc: 87.50
[Train] Epoch: 4 [95552/620022]    Loss: 0.006981   Batch Acc: 87.50
[Train] Epoch: 4 [95616/620022]    Loss: 0.010030   Batch Acc: 75.00
[Train] Epoch: 4 [95680/620022]    Loss: 0.007919   Batch Acc: 79.69
[Train] Epoch: 4 [95744/620022]    Loss: 0.007844   Batch Acc: 76.56
[Train] Epoch: 4 [95808/620022]    Loss: 0.008572   Batch Acc: 81.25
[Train] Epoch: 4 [95872/620022]    Loss: 0.008720   Batch Acc: 79.69
[Train] Epoch: 4 [95936/620022]    Loss: 0.006902   Batch Acc: 81.25
[Train] Epoch: 4 [96000/620022]    Loss: 0.008359   Batch Acc: 73.44
[Train] Epoch: 4 [96064/620022]    Loss: 0.007204   Batch Acc: 79.69
[Train] Epoch: 4 [96128/620022]    Loss: 0.007153   Batch Acc: 76.56
[Train] Epoch: 4 [96192/620022]    Loss: 0.008661   Batch Acc: 76.56
[Train] Epoch: 4 [96256/620022]    Loss: 0.009006   Batch Acc: 76.56
[Train] Epoch: 4 [96320/620022]    Loss: 0.009960   Batch Acc: 73.44
[Train] Epoch: 4 [96384/620022]    Loss: 0.007066   Batch Acc: 87.50
[Train] Epoch: 4 [96448/620022]    Loss: 0.007141   Batch Acc: 81.25
[Train] Epoch: 4 [96512/620022]    Loss: 0.008711   Batch Acc: 79.69
[Train] Epoch: 4 [96576/620022]    Loss: 0.009380   Batch Acc: 78.12
[Train] Epoch: 4 [96640/620022]    Loss: 0.009402   Batch Acc: 73.44
[Train] Epoch: 4 [96704/620022]    Loss: 0.007293   Batch Acc: 81.25
[Train] Epoch: 4 [96768/620022]    Loss: 0.007319   Batch Acc: 84.38
[Train] Epoch: 4 [96832/620022]    Loss: 0.009887   Batch Acc: 75.00
[Train] Epoch: 4 [96896/620022]    Loss: 0.009500   Batch Acc: 82.81
[Train] Epoch: 4 [96960/620022]    Loss: 0.008448   Batch Acc: 78.12
[Train] Epoch: 4 [97024/620022]    Loss: 0.008414   Batch Acc: 75.00
[Train] Epoch: 4 [97088/620022]    Loss: 0.010127   Batch Acc: 71.88
[Train] Epoch: 4 [97152/620022]    Loss: 0.011504   Batch Acc: 71.88
[Train] Epoch: 4 [97216/620022]    Loss: 0.008851   Batch Acc: 73.44
[Train] Epoch: 4 [97280/620022]    Loss: 0.009001   Batch Acc: 78.12
[Train] Epoch: 4 [97344/620022]    Loss: 0.009837   Batch Acc: 73.44
[Train] Epoch: 4 [97408/620022]    Loss: 0.010340   Batch Acc: 71.88
[Train] Epoch: 4 [97472/620022]    Loss: 0.008463   Batch Acc: 78.12
[Train] Epoch: 4 [97536/620022]    Loss: 0.009098   Batch Acc: 76.56
[Train] Epoch: 4 [97600/620022]    Loss: 0.006611   Batch Acc: 82.81
[Train] Epoch: 4 [97664/620022]    Loss: 0.006739   Batch Acc: 84.38
[Train] Epoch: 4 [97728/620022]    Loss: 0.011928   Batch Acc: 67.19
[Train] Epoch: 4 [97792/620022]    Loss: 0.008019   Batch Acc: 75.00
[Train] Epoch: 4 [97856/620022]    Loss: 0.009590   Batch Acc: 75.00
[Train] Epoch: 4 [97920/620022]    Loss: 0.009748   Batch Acc: 75.00
[Train] Epoch: 4 [97984/620022]    Loss: 0.007751   Batch Acc: 79.69
[Train] Epoch: 4 [98048/620022]    Loss: 0.006560   Batch Acc: 89.06
[Train] Epoch: 4 [98112/620022]    Loss: 0.006675   Batch Acc: 81.25
[Train] Epoch: 4 [98176/620022]    Loss: 0.008935   Batch Acc: 79.69
[Train] Epoch: 4 [98240/620022]    Loss: 0.009727   Batch Acc: 71.88
[Train] Epoch: 4 [98304/620022]    Loss: 0.008219   Batch Acc: 79.69
[Train] Epoch: 4 [98368/620022]    Loss: 0.007837   Batch Acc: 78.12
[Train] Epoch: 4 [98432/620022]    Loss: 0.009020   Batch Acc: 78.12
[Train] Epoch: 4 [98496/620022]    Loss: 0.008510   Batch Acc: 82.81
[Train] Epoch: 4 [98560/620022]    Loss: 0.010387   Batch Acc: 70.31
[Train] Epoch: 4 [98624/620022]    Loss: 0.009989   Batch Acc: 75.00
[Train] Epoch: 4 [98688/620022]    Loss: 0.009230   Batch Acc: 76.56
[Train] Epoch: 4 [98752/620022]    Loss: 0.007955   Batch Acc: 78.12
[Train] Epoch: 4 [98816/620022]    Loss: 0.009401   Batch Acc: 73.44
[Train] Epoch: 4 [98880/620022]    Loss: 0.007271   Batch Acc: 81.25
[Train] Epoch: 4 [98944/620022]    Loss: 0.008125   Batch Acc: 84.38
[Train] Epoch: 4 [99008/620022]    Loss: 0.008290   Batch Acc: 79.69
[Train] Epoch: 4 [99072/620022]    Loss: 0.006923   Batch Acc: 85.94
[Train] Epoch: 4 [99136/620022]    Loss: 0.006723   Batch Acc: 84.38
[Train] Epoch: 4 [99200/620022]    Loss: 0.009226   Batch Acc: 75.00
[Train] Epoch: 4 [99264/620022]    Loss: 0.007655   Batch Acc: 78.12
[Train] Epoch: 4 [99328/620022]    Loss: 0.011356   Batch Acc: 65.62
[Train] Epoch: 4 [99392/620022]    Loss: 0.008491   Batch Acc: 78.12
[Train] Epoch: 4 [99456/620022]    Loss: 0.009489   Batch Acc: 76.56
[Train] Epoch: 4 [99520/620022]    Loss: 0.009066   Batch Acc: 68.75
[Train] Epoch: 4 [99584/620022]    Loss: 0.008906   Batch Acc: 85.94
[Train] Epoch: 4 [99648/620022]    Loss: 0.008449   Batch Acc: 78.12
[Train] Epoch: 4 [99712/620022]    Loss: 0.008072   Batch Acc: 81.25
[Train] Epoch: 4 [99776/620022]    Loss: 0.007036   Batch Acc: 81.25
[Train] Epoch: 4 [99840/620022]    Loss: 0.010301   Batch Acc: 70.31
[Train] Epoch: 4 [99904/620022]    Loss: 0.009464   Batch Acc: 73.44
[Train] Epoch: 4 [99968/620022]    Loss: 0.008959   Batch Acc: 76.56
[Train] Epoch: 4 [100032/620022]    Loss: 0.007858   Batch Acc: 84.38
[Train] Epoch: 4 [100096/620022]    Loss: 0.008316   Batch Acc: 76.56
[Train] Epoch: 4 [100160/620022]    Loss: 0.009005   Batch Acc: 75.00
[Train] Epoch: 4 [100224/620022]    Loss: 0.009866   Batch Acc: 70.31
[Train] Epoch: 4 [100288/620022]    Loss: 0.009420   Batch Acc: 71.88
[Train] Epoch: 4 [100352/620022]    Loss: 0.006514   Batch Acc: 82.81
[Train] Epoch: 4 [100416/620022]    Loss: 0.009522   Batch Acc: 76.56
[Train] Epoch: 4 [100480/620022]    Loss: 0.011184   Batch Acc: 68.75
[Train] Epoch: 4 [100544/620022]    Loss: 0.007815   Batch Acc: 79.69
[Train] Epoch: 4 [100608/620022]    Loss: 0.008971   Batch Acc: 78.12
[Train] Epoch: 4 [100672/620022]    Loss: 0.006923   Batch Acc: 84.38
[Train] Epoch: 4 [100736/620022]    Loss: 0.008635   Batch Acc: 71.88
[Train] Epoch: 4 [100800/620022]    Loss: 0.010734   Batch Acc: 67.19
[Train] Epoch: 4 [100864/620022]    Loss: 0.009727   Batch Acc: 73.44
[Train] Epoch: 4 [100928/620022]    Loss: 0.009042   Batch Acc: 79.69
[Train] Epoch: 4 [100992/620022]    Loss: 0.007236   Batch Acc: 82.81
[Train] Epoch: 4 [101056/620022]    Loss: 0.006385   Batch Acc: 81.25
[Train] Epoch: 4 [101120/620022]    Loss: 0.007276   Batch Acc: 82.81
[Train] Epoch: 4 [101184/620022]    Loss: 0.008965   Batch Acc: 73.44
[Train] Epoch: 4 [101248/620022]    Loss: 0.008552   Batch Acc: 78.12
[Train] Epoch: 4 [101312/620022]    Loss: 0.007964   Batch Acc: 82.81
[Train] Epoch: 4 [101376/620022]    Loss: 0.008234   Batch Acc: 79.69
[Train] Epoch: 4 [101440/620022]    Loss: 0.006388   Batch Acc: 84.38
[Train] Epoch: 4 [101504/620022]    Loss: 0.008667   Batch Acc: 71.88
[Train] Epoch: 4 [101568/620022]    Loss: 0.008388   Batch Acc: 76.56
[Train] Epoch: 4 [101632/620022]    Loss: 0.007740   Batch Acc: 81.25
[Train] Epoch: 4 [101696/620022]    Loss: 0.007099   Batch Acc: 85.94
[Train] Epoch: 4 [101760/620022]    Loss: 0.007979   Batch Acc: 82.81
[Train] Epoch: 4 [101824/620022]    Loss: 0.008914   Batch Acc: 73.44
[Train] Epoch: 4 [101888/620022]    Loss: 0.009371   Batch Acc: 75.00
[Train] Epoch: 4 [101952/620022]    Loss: 0.007530   Batch Acc: 82.81
[Train] Epoch: 4 [102016/620022]    Loss: 0.007079   Batch Acc: 81.25
[Train] Epoch: 4 [102080/620022]    Loss: 0.006104   Batch Acc: 89.06
[Train] Epoch: 4 [102144/620022]    Loss: 0.008625   Batch Acc: 79.69
[Train] Epoch: 4 [102208/620022]    Loss: 0.007082   Batch Acc: 82.81
[Train] Epoch: 4 [102272/620022]    Loss: 0.009191   Batch Acc: 79.69
[Train] Epoch: 4 [102336/620022]    Loss: 0.006640   Batch Acc: 92.19
[Train] Epoch: 4 [102400/620022]    Loss: 0.010047   Batch Acc: 76.56
[Train] Epoch: 4 [102464/620022]    Loss: 0.006993   Batch Acc: 85.94
[Train] Epoch: 4 [102528/620022]    Loss: 0.008079   Batch Acc: 78.12
[Train] Epoch: 4 [102592/620022]    Loss: 0.006821   Batch Acc: 87.50
[Train] Epoch: 4 [102656/620022]    Loss: 0.009097   Batch Acc: 73.44
[Train] Epoch: 4 [102720/620022]    Loss: 0.007069   Batch Acc: 84.38
[Train] Epoch: 4 [102784/620022]    Loss: 0.009365   Batch Acc: 73.44
[Train] Epoch: 4 [102848/620022]    Loss: 0.009879   Batch Acc: 73.44
[Train] Epoch: 4 [102912/620022]    Loss: 0.009925   Batch Acc: 75.00
[Train] Epoch: 4 [102976/620022]    Loss: 0.008797   Batch Acc: 78.12
[Train] Epoch: 4 [103040/620022]    Loss: 0.008163   Batch Acc: 79.69
[Train] Epoch: 4 [103104/620022]    Loss: 0.007068   Batch Acc: 81.25
[Train] Epoch: 4 [103168/620022]    Loss: 0.009655   Batch Acc: 78.12
[Train] Epoch: 4 [103232/620022]    Loss: 0.009394   Batch Acc: 82.81
[Train] Epoch: 4 [103296/620022]    Loss: 0.007636   Batch Acc: 81.25
[Train] Epoch: 4 [103360/620022]    Loss: 0.010583   Batch Acc: 71.88
[Train] Epoch: 4 [103424/620022]    Loss: 0.009355   Batch Acc: 76.56
[Train] Epoch: 4 [103488/620022]    Loss: 0.010433   Batch Acc: 75.00
[Train] Epoch: 4 [103552/620022]    Loss: 0.010853   Batch Acc: 73.44
[Train] Epoch: 4 [103616/620022]    Loss: 0.007299   Batch Acc: 82.81
[Train] Epoch: 4 [103680/620022]    Loss: 0.009028   Batch Acc: 71.88
[Train] Epoch: 4 [103744/620022]    Loss: 0.009226   Batch Acc: 79.69
[Train] Epoch: 4 [103808/620022]    Loss: 0.007394   Batch Acc: 87.50
[Train] Epoch: 4 [103872/620022]    Loss: 0.009618   Batch Acc: 68.75
[Train] Epoch: 4 [103936/620022]    Loss: 0.009477   Batch Acc: 78.12
[Train] Epoch: 4 [104000/620022]    Loss: 0.010311   Batch Acc: 68.75
[Train] Epoch: 4 [104064/620022]    Loss: 0.008628   Batch Acc: 73.44
[Train] Epoch: 4 [104128/620022]    Loss: 0.008172   Batch Acc: 81.25
[Train] Epoch: 4 [104192/620022]    Loss: 0.015412   Batch Acc: 64.06
[Train] Epoch: 4 [104256/620022]    Loss: 0.008655   Batch Acc: 79.69
[Train] Epoch: 4 [104320/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 4 [104384/620022]    Loss: 0.008270   Batch Acc: 82.81
[Train] Epoch: 4 [104448/620022]    Loss: 0.008925   Batch Acc: 81.25
[Train] Epoch: 4 [104512/620022]    Loss: 0.008999   Batch Acc: 68.75
[Train] Epoch: 4 [104576/620022]    Loss: 0.008922   Batch Acc: 76.56
[Train] Epoch: 4 [104640/620022]    Loss: 0.010124   Batch Acc: 73.44
[Train] Epoch: 4 [104704/620022]    Loss: 0.009500   Batch Acc: 78.12
[Train] Epoch: 4 [104768/620022]    Loss: 0.008557   Batch Acc: 78.12
[Train] Epoch: 4 [104832/620022]    Loss: 0.005051   Batch Acc: 92.19
[Train] Epoch: 4 [104896/620022]    Loss: 0.006377   Batch Acc: 84.38
[Train] Epoch: 4 [104960/620022]    Loss: 0.009205   Batch Acc: 78.12
[Train] Epoch: 4 [105024/620022]    Loss: 0.009072   Batch Acc: 76.56
[Train] Epoch: 4 [105088/620022]    Loss: 0.008233   Batch Acc: 84.38
[Train] Epoch: 4 [105152/620022]    Loss: 0.010097   Batch Acc: 68.75
[Train] Epoch: 4 [105216/620022]    Loss: 0.007154   Batch Acc: 76.56
[Train] Epoch: 4 [105280/620022]    Loss: 0.008144   Batch Acc: 76.56
[Train] Epoch: 4 [105344/620022]    Loss: 0.009006   Batch Acc: 75.00
[Train] Epoch: 4 [105408/620022]    Loss: 0.009097   Batch Acc: 76.56
[Train] Epoch: 4 [105472/620022]    Loss: 0.009293   Batch Acc: 71.88
[Train] Epoch: 4 [105536/620022]    Loss: 0.009039   Batch Acc: 73.44
[Train] Epoch: 4 [105600/620022]    Loss: 0.007914   Batch Acc: 81.25
[Train] Epoch: 4 [105664/620022]    Loss: 0.007659   Batch Acc: 79.69
[Train] Epoch: 4 [105728/620022]    Loss: 0.008854   Batch Acc: 76.56
[Train] Epoch: 4 [105792/620022]    Loss: 0.007827   Batch Acc: 79.69
[Train] Epoch: 4 [105856/620022]    Loss: 0.009021   Batch Acc: 75.00
[Train] Epoch: 4 [105920/620022]    Loss: 0.008860   Batch Acc: 76.56
[Train] Epoch: 4 [105984/620022]    Loss: 0.008495   Batch Acc: 78.12
[Train] Epoch: 4 [106048/620022]    Loss: 0.008381   Batch Acc: 78.12
[Train] Epoch: 4 [106112/620022]    Loss: 0.010257   Batch Acc: 70.31
[Train] Epoch: 4 [106176/620022]    Loss: 0.008365   Batch Acc: 84.38
[Train] Epoch: 4 [106240/620022]    Loss: 0.007756   Batch Acc: 79.69
[Train] Epoch: 4 [106304/620022]    Loss: 0.009039   Batch Acc: 81.25
[Train] Epoch: 4 [106368/620022]    Loss: 0.007527   Batch Acc: 84.38
[Train] Epoch: 4 [106432/620022]    Loss: 0.008310   Batch Acc: 79.69
[Train] Epoch: 4 [106496/620022]    Loss: 0.006853   Batch Acc: 84.38
[Train] Epoch: 4 [106560/620022]    Loss: 0.009516   Batch Acc: 76.56
[Train] Epoch: 4 [106624/620022]    Loss: 0.008619   Batch Acc: 82.81
[Train] Epoch: 4 [106688/620022]    Loss: 0.009870   Batch Acc: 73.44
[Train] Epoch: 4 [106752/620022]    Loss: 0.010624   Batch Acc: 71.88
[Train] Epoch: 4 [106816/620022]    Loss: 0.007917   Batch Acc: 79.69
[Train] Epoch: 4 [106880/620022]    Loss: 0.009310   Batch Acc: 76.56
[Train] Epoch: 4 [106944/620022]    Loss: 0.006994   Batch Acc: 81.25
[Train] Epoch: 4 [107008/620022]    Loss: 0.009633   Batch Acc: 75.00
[Train] Epoch: 4 [107072/620022]    Loss: 0.011232   Batch Acc: 65.62
[Train] Epoch: 4 [107136/620022]    Loss: 0.008238   Batch Acc: 81.25
[Train] Epoch: 4 [107200/620022]    Loss: 0.009534   Batch Acc: 76.56
[Train] Epoch: 4 [107264/620022]    Loss: 0.011051   Batch Acc: 68.75
[Train] Epoch: 4 [107328/620022]    Loss: 0.007367   Batch Acc: 82.81
[Train] Epoch: 4 [107392/620022]    Loss: 0.010000   Batch Acc: 70.31
[Train] Epoch: 4 [107456/620022]    Loss: 0.007462   Batch Acc: 82.81
[Train] Epoch: 4 [107520/620022]    Loss: 0.008407   Batch Acc: 82.81
[Train] Epoch: 4 [107584/620022]    Loss: 0.011084   Batch Acc: 70.31
[Train] Epoch: 4 [107648/620022]    Loss: 0.008846   Batch Acc: 75.00
[Train] Epoch: 4 [107712/620022]    Loss: 0.009118   Batch Acc: 79.69
[Train] Epoch: 4 [107776/620022]    Loss: 0.010263   Batch Acc: 75.00
[Train] Epoch: 4 [107840/620022]    Loss: 0.008404   Batch Acc: 78.12
[Train] Epoch: 4 [107904/620022]    Loss: 0.006007   Batch Acc: 85.94
[Train] Epoch: 4 [107968/620022]    Loss: 0.006246   Batch Acc: 81.25
[Train] Epoch: 4 [108032/620022]    Loss: 0.010158   Batch Acc: 71.88
[Train] Epoch: 4 [108096/620022]    Loss: 0.009361   Batch Acc: 73.44
[Train] Epoch: 4 [108160/620022]    Loss: 0.009667   Batch Acc: 71.88
[Train] Epoch: 4 [108224/620022]    Loss: 0.009271   Batch Acc: 76.56
[Train] Epoch: 4 [108288/620022]    Loss: 0.009258   Batch Acc: 73.44
[Train] Epoch: 4 [108352/620022]    Loss: 0.005777   Batch Acc: 84.38
[Train] Epoch: 4 [108416/620022]    Loss: 0.010370   Batch Acc: 75.00
[Train] Epoch: 4 [108480/620022]    Loss: 0.006508   Batch Acc: 82.81
[Train] Epoch: 4 [108544/620022]    Loss: 0.008208   Batch Acc: 73.44
[Train] Epoch: 4 [108608/620022]    Loss: 0.009149   Batch Acc: 79.69
[Train] Epoch: 4 [108672/620022]    Loss: 0.008033   Batch Acc: 79.69
[Train] Epoch: 4 [108736/620022]    Loss: 0.009572   Batch Acc: 76.56
[Train] Epoch: 4 [108800/620022]    Loss: 0.008593   Batch Acc: 76.56
[Train] Epoch: 4 [108864/620022]    Loss: 0.010718   Batch Acc: 68.75
[Train] Epoch: 4 [108928/620022]    Loss: 0.008347   Batch Acc: 82.81
[Train] Epoch: 4 [108992/620022]    Loss: 0.007175   Batch Acc: 78.12
[Train] Epoch: 4 [109056/620022]    Loss: 0.007121   Batch Acc: 87.50
[Train] Epoch: 4 [109120/620022]    Loss: 0.008291   Batch Acc: 73.44
[Train] Epoch: 4 [109184/620022]    Loss: 0.010997   Batch Acc: 70.31
[Train] Epoch: 4 [109248/620022]    Loss: 0.007190   Batch Acc: 84.38
[Train] Epoch: 4 [109312/620022]    Loss: 0.009412   Batch Acc: 76.56
[Train] Epoch: 4 [109376/620022]    Loss: 0.008738   Batch Acc: 75.00
[Train] Epoch: 4 [109440/620022]    Loss: 0.008852   Batch Acc: 76.56
[Train] Epoch: 4 [109504/620022]    Loss: 0.010052   Batch Acc: 75.00
[Train] Epoch: 4 [109568/620022]    Loss: 0.008111   Batch Acc: 82.81
[Train] Epoch: 4 [109632/620022]    Loss: 0.009244   Batch Acc: 76.56
[Train] Epoch: 4 [109696/620022]    Loss: 0.008186   Batch Acc: 81.25
[Train] Epoch: 4 [109760/620022]    Loss: 0.009588   Batch Acc: 73.44
[Train] Epoch: 4 [109824/620022]    Loss: 0.008962   Batch Acc: 85.94
[Train] Epoch: 4 [109888/620022]    Loss: 0.007072   Batch Acc: 84.38
[Train] Epoch: 4 [109952/620022]    Loss: 0.007878   Batch Acc: 84.38
[Train] Epoch: 4 [110016/620022]    Loss: 0.007016   Batch Acc: 84.38
[Train] Epoch: 4 [110080/620022]    Loss: 0.007968   Batch Acc: 82.81
[Train] Epoch: 4 [110144/620022]    Loss: 0.008107   Batch Acc: 81.25
[Train] Epoch: 4 [110208/620022]    Loss: 0.009670   Batch Acc: 73.44
[Train] Epoch: 4 [110272/620022]    Loss: 0.007369   Batch Acc: 84.38
[Train] Epoch: 4 [110336/620022]    Loss: 0.009466   Batch Acc: 75.00
[Train] Epoch: 4 [110400/620022]    Loss: 0.008669   Batch Acc: 79.69
[Train] Epoch: 4 [110464/620022]    Loss: 0.009256   Batch Acc: 79.69
[Train] Epoch: 4 [110528/620022]    Loss: 0.008767   Batch Acc: 76.56
[Train] Epoch: 4 [110592/620022]    Loss: 0.009300   Batch Acc: 73.44
[Train] Epoch: 4 [110656/620022]    Loss: 0.008877   Batch Acc: 78.12
[Train] Epoch: 4 [110720/620022]    Loss: 0.009290   Batch Acc: 71.88
[Train] Epoch: 4 [110784/620022]    Loss: 0.006914   Batch Acc: 87.50
[Train] Epoch: 4 [110848/620022]    Loss: 0.008089   Batch Acc: 79.69
[Train] Epoch: 4 [110912/620022]    Loss: 0.010546   Batch Acc: 71.88
[Train] Epoch: 4 [110976/620022]    Loss: 0.007869   Batch Acc: 81.25
[Train] Epoch: 4 [111040/620022]    Loss: 0.007519   Batch Acc: 78.12
[Train] Epoch: 4 [111104/620022]    Loss: 0.008493   Batch Acc: 81.25
[Train] Epoch: 4 [111168/620022]    Loss: 0.009897   Batch Acc: 76.56
[Train] Epoch: 4 [111232/620022]    Loss: 0.005272   Batch Acc: 92.19
[Train] Epoch: 4 [111296/620022]    Loss: 0.009788   Batch Acc: 73.44
[Train] Epoch: 4 [111360/620022]    Loss: 0.009558   Batch Acc: 73.44
[Train] Epoch: 4 [111424/620022]    Loss: 0.010821   Batch Acc: 75.00
[Train] Epoch: 4 [111488/620022]    Loss: 0.010880   Batch Acc: 70.31
[Train] Epoch: 4 [111552/620022]    Loss: 0.006857   Batch Acc: 89.06
[Train] Epoch: 4 [111616/620022]    Loss: 0.008367   Batch Acc: 79.69
[Train] Epoch: 4 [111680/620022]    Loss: 0.006669   Batch Acc: 82.81
[Train] Epoch: 4 [111744/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 4 [111808/620022]    Loss: 0.010104   Batch Acc: 73.44
[Train] Epoch: 4 [111872/620022]    Loss: 0.006501   Batch Acc: 84.38
[Train] Epoch: 4 [111936/620022]    Loss: 0.009301   Batch Acc: 73.44
[Train] Epoch: 4 [112000/620022]    Loss: 0.008793   Batch Acc: 76.56
[Train] Epoch: 4 [112064/620022]    Loss: 0.007621   Batch Acc: 84.38
[Train] Epoch: 4 [112128/620022]    Loss: 0.008449   Batch Acc: 71.88
[Train] Epoch: 4 [112192/620022]    Loss: 0.008919   Batch Acc: 73.44
[Train] Epoch: 4 [112256/620022]    Loss: 0.007592   Batch Acc: 82.81
[Train] Epoch: 4 [112320/620022]    Loss: 0.009277   Batch Acc: 75.00
[Train] Epoch: 4 [112384/620022]    Loss: 0.006538   Batch Acc: 85.94
[Train] Epoch: 4 [112448/620022]    Loss: 0.007205   Batch Acc: 84.38
[Train] Epoch: 4 [112512/620022]    Loss: 0.007588   Batch Acc: 84.38
[Train] Epoch: 4 [112576/620022]    Loss: 0.008368   Batch Acc: 71.88
[Train] Epoch: 4 [112640/620022]    Loss: 0.009573   Batch Acc: 73.44
[Train] Epoch: 4 [112704/620022]    Loss: 0.006529   Batch Acc: 84.38
[Train] Epoch: 4 [112768/620022]    Loss: 0.009826   Batch Acc: 73.44
[Train] Epoch: 4 [112832/620022]    Loss: 0.007480   Batch Acc: 82.81
[Train] Epoch: 4 [112896/620022]    Loss: 0.006638   Batch Acc: 85.94
[Train] Epoch: 4 [112960/620022]    Loss: 0.009647   Batch Acc: 71.88
[Train] Epoch: 4 [113024/620022]    Loss: 0.007911   Batch Acc: 82.81
[Train] Epoch: 4 [113088/620022]    Loss: 0.012733   Batch Acc: 64.06
[Train] Epoch: 4 [113152/620022]    Loss: 0.009321   Batch Acc: 76.56
[Train] Epoch: 4 [113216/620022]    Loss: 0.009491   Batch Acc: 75.00
[Train] Epoch: 4 [113280/620022]    Loss: 0.008104   Batch Acc: 81.25
[Train] Epoch: 4 [113344/620022]    Loss: 0.008685   Batch Acc: 84.38
[Train] Epoch: 4 [113408/620022]    Loss: 0.010439   Batch Acc: 71.88
[Train] Epoch: 4 [113472/620022]    Loss: 0.008711   Batch Acc: 73.44
[Train] Epoch: 4 [113536/620022]    Loss: 0.008978   Batch Acc: 75.00
[Train] Epoch: 4 [113600/620022]    Loss: 0.007659   Batch Acc: 82.81
[Train] Epoch: 4 [113664/620022]    Loss: 0.009443   Batch Acc: 78.12
[Train] Epoch: 4 [113728/620022]    Loss: 0.009585   Batch Acc: 70.31
[Train] Epoch: 4 [113792/620022]    Loss: 0.008083   Batch Acc: 81.25
[Train] Epoch: 4 [113856/620022]    Loss: 0.010052   Batch Acc: 71.88
[Train] Epoch: 4 [113920/620022]    Loss: 0.009177   Batch Acc: 78.12
[Train] Epoch: 4 [113984/620022]    Loss: 0.007073   Batch Acc: 84.38
[Train] Epoch: 4 [114048/620022]    Loss: 0.008040   Batch Acc: 81.25
[Train] Epoch: 4 [114112/620022]    Loss: 0.007983   Batch Acc: 76.56
[Train] Epoch: 4 [114176/620022]    Loss: 0.010248   Batch Acc: 73.44
[Train] Epoch: 4 [114240/620022]    Loss: 0.009423   Batch Acc: 75.00
[Train] Epoch: 4 [114304/620022]    Loss: 0.007286   Batch Acc: 82.81
[Train] Epoch: 4 [114368/620022]    Loss: 0.009426   Batch Acc: 81.25
[Train] Epoch: 4 [114432/620022]    Loss: 0.009387   Batch Acc: 75.00
[Train] Epoch: 4 [114496/620022]    Loss: 0.008655   Batch Acc: 81.25
[Train] Epoch: 4 [114560/620022]    Loss: 0.009151   Batch Acc: 75.00
[Train] Epoch: 4 [114624/620022]    Loss: 0.008900   Batch Acc: 75.00
[Train] Epoch: 4 [114688/620022]    Loss: 0.009259   Batch Acc: 79.69
[Train] Epoch: 4 [114752/620022]    Loss: 0.006529   Batch Acc: 84.38
[Train] Epoch: 4 [114816/620022]    Loss: 0.008444   Batch Acc: 75.00
[Train] Epoch: 4 [114880/620022]    Loss: 0.007556   Batch Acc: 84.38
[Train] Epoch: 4 [114944/620022]    Loss: 0.008662   Batch Acc: 75.00
[Train] Epoch: 4 [115008/620022]    Loss: 0.007454   Batch Acc: 75.00
[Train] Epoch: 4 [115072/620022]    Loss: 0.008167   Batch Acc: 78.12
[Train] Epoch: 4 [115136/620022]    Loss: 0.009039   Batch Acc: 76.56
[Train] Epoch: 4 [115200/620022]    Loss: 0.008242   Batch Acc: 78.12
[Train] Epoch: 4 [115264/620022]    Loss: 0.007099   Batch Acc: 84.38
[Train] Epoch: 4 [115328/620022]    Loss: 0.009211   Batch Acc: 79.69
[Train] Epoch: 4 [115392/620022]    Loss: 0.007819   Batch Acc: 84.38
[Train] Epoch: 4 [115456/620022]    Loss: 0.007986   Batch Acc: 79.69
[Train] Epoch: 4 [115520/620022]    Loss: 0.006529   Batch Acc: 85.94
[Train] Epoch: 4 [115584/620022]    Loss: 0.006818   Batch Acc: 85.94
[Train] Epoch: 4 [115648/620022]    Loss: 0.010269   Batch Acc: 70.31
[Train] Epoch: 4 [115712/620022]    Loss: 0.008017   Batch Acc: 82.81
[Train] Epoch: 4 [115776/620022]    Loss: 0.006656   Batch Acc: 81.25
[Train] Epoch: 4 [115840/620022]    Loss: 0.010078   Batch Acc: 73.44
[Train] Epoch: 4 [115904/620022]    Loss: 0.008684   Batch Acc: 71.88
[Train] Epoch: 4 [115968/620022]    Loss: 0.007704   Batch Acc: 78.12
[Train] Epoch: 4 [116032/620022]    Loss: 0.009196   Batch Acc: 81.25
[Train] Epoch: 4 [116096/620022]    Loss: 0.010021   Batch Acc: 71.88
[Train] Epoch: 4 [116160/620022]    Loss: 0.009112   Batch Acc: 78.12
[Train] Epoch: 4 [116224/620022]    Loss: 0.009370   Batch Acc: 73.44
[Train] Epoch: 4 [116288/620022]    Loss: 0.010938   Batch Acc: 68.75
[Train] Epoch: 4 [116352/620022]    Loss: 0.009620   Batch Acc: 70.31
[Train] Epoch: 4 [116416/620022]    Loss: 0.007603   Batch Acc: 82.81
[Train] Epoch: 4 [116480/620022]    Loss: 0.008502   Batch Acc: 79.69
[Train] Epoch: 4 [116544/620022]    Loss: 0.007540   Batch Acc: 82.81
[Train] Epoch: 4 [116608/620022]    Loss: 0.009866   Batch Acc: 73.44
[Train] Epoch: 4 [116672/620022]    Loss: 0.007790   Batch Acc: 79.69
[Train] Epoch: 4 [116736/620022]    Loss: 0.008415   Batch Acc: 78.12
[Train] Epoch: 4 [116800/620022]    Loss: 0.006657   Batch Acc: 84.38
[Train] Epoch: 4 [116864/620022]    Loss: 0.006869   Batch Acc: 84.38
[Train] Epoch: 4 [116928/620022]    Loss: 0.008202   Batch Acc: 73.44
[Train] Epoch: 4 [116992/620022]    Loss: 0.007475   Batch Acc: 82.81
[Train] Epoch: 4 [117056/620022]    Loss: 0.009604   Batch Acc: 68.75
[Train] Epoch: 4 [117120/620022]    Loss: 0.006993   Batch Acc: 84.38
[Train] Epoch: 4 [117184/620022]    Loss: 0.007243   Batch Acc: 82.81
[Train] Epoch: 4 [117248/620022]    Loss: 0.006239   Batch Acc: 89.06
[Train] Epoch: 4 [117312/620022]    Loss: 0.012273   Batch Acc: 65.62
[Train] Epoch: 4 [117376/620022]    Loss: 0.008747   Batch Acc: 75.00
[Train] Epoch: 4 [117440/620022]    Loss: 0.007648   Batch Acc: 78.12
[Train] Epoch: 4 [117504/620022]    Loss: 0.009003   Batch Acc: 79.69
[Train] Epoch: 4 [117568/620022]    Loss: 0.009921   Batch Acc: 75.00
[Train] Epoch: 4 [117632/620022]    Loss: 0.007832   Batch Acc: 85.94
[Train] Epoch: 4 [117696/620022]    Loss: 0.008003   Batch Acc: 82.81
[Train] Epoch: 4 [117760/620022]    Loss: 0.008003   Batch Acc: 81.25
[Train] Epoch: 4 [117824/620022]    Loss: 0.008851   Batch Acc: 75.00
[Train] Epoch: 4 [117888/620022]    Loss: 0.008002   Batch Acc: 82.81
[Train] Epoch: 4 [117952/620022]    Loss: 0.007549   Batch Acc: 73.44
[Train] Epoch: 4 [118016/620022]    Loss: 0.007097   Batch Acc: 81.25
[Train] Epoch: 4 [118080/620022]    Loss: 0.008438   Batch Acc: 79.69
[Train] Epoch: 4 [118144/620022]    Loss: 0.009870   Batch Acc: 70.31
[Train] Epoch: 4 [118208/620022]    Loss: 0.008597   Batch Acc: 81.25
[Train] Epoch: 4 [118272/620022]    Loss: 0.010036   Batch Acc: 73.44
[Train] Epoch: 4 [118336/620022]    Loss: 0.011769   Batch Acc: 71.88
[Train] Epoch: 4 [118400/620022]    Loss: 0.010139   Batch Acc: 73.44
[Train] Epoch: 4 [118464/620022]    Loss: 0.009067   Batch Acc: 76.56
[Train] Epoch: 4 [118528/620022]    Loss: 0.009215   Batch Acc: 78.12
[Train] Epoch: 4 [118592/620022]    Loss: 0.010376   Batch Acc: 68.75
[Train] Epoch: 4 [118656/620022]    Loss: 0.007719   Batch Acc: 78.12
[Train] Epoch: 4 [118720/620022]    Loss: 0.007123   Batch Acc: 82.81
[Train] Epoch: 4 [118784/620022]    Loss: 0.007802   Batch Acc: 81.25
[Train] Epoch: 4 [118848/620022]    Loss: 0.010025   Batch Acc: 75.00
[Train] Epoch: 4 [118912/620022]    Loss: 0.010349   Batch Acc: 73.44
[Train] Epoch: 4 [118976/620022]    Loss: 0.008355   Batch Acc: 81.25
[Train] Epoch: 4 [119040/620022]    Loss: 0.009684   Batch Acc: 76.56
[Train] Epoch: 4 [119104/620022]    Loss: 0.008563   Batch Acc: 81.25
[Train] Epoch: 4 [119168/620022]    Loss: 0.011247   Batch Acc: 68.75
[Train] Epoch: 4 [119232/620022]    Loss: 0.009058   Batch Acc: 78.12
[Train] Epoch: 4 [119296/620022]    Loss: 0.006735   Batch Acc: 87.50
[Train] Epoch: 4 [119360/620022]    Loss: 0.006372   Batch Acc: 81.25
[Train] Epoch: 4 [119424/620022]    Loss: 0.008867   Batch Acc: 76.56
[Train] Epoch: 4 [119488/620022]    Loss: 0.010600   Batch Acc: 68.75
[Train] Epoch: 4 [119552/620022]    Loss: 0.007850   Batch Acc: 82.81
[Train] Epoch: 4 [119616/620022]    Loss: 0.010392   Batch Acc: 76.56
[Train] Epoch: 4 [119680/620022]    Loss: 0.009364   Batch Acc: 76.56
[Train] Epoch: 4 [119744/620022]    Loss: 0.005543   Batch Acc: 89.06
[Train] Epoch: 4 [119808/620022]    Loss: 0.008756   Batch Acc: 75.00
[Train] Epoch: 4 [119872/620022]    Loss: 0.008677   Batch Acc: 73.44
[Train] Epoch: 4 [119936/620022]    Loss: 0.009297   Batch Acc: 70.31
[Train] Epoch: 4 [120000/620022]    Loss: 0.010296   Batch Acc: 76.56
[Train] Epoch: 4 [120064/620022]    Loss: 0.007803   Batch Acc: 79.69
[Train] Epoch: 4 [120128/620022]    Loss: 0.009526   Batch Acc: 73.44
[Train] Epoch: 4 [120192/620022]    Loss: 0.007986   Batch Acc: 76.56
[Train] Epoch: 4 [120256/620022]    Loss: 0.009272   Batch Acc: 76.56
[Train] Epoch: 4 [120320/620022]    Loss: 0.011062   Batch Acc: 75.00
[Train] Epoch: 4 [120384/620022]    Loss: 0.011204   Batch Acc: 70.31
[Train] Epoch: 4 [120448/620022]    Loss: 0.009394   Batch Acc: 78.12
[Train] Epoch: 4 [120512/620022]    Loss: 0.007787   Batch Acc: 82.81
[Train] Epoch: 4 [120576/620022]    Loss: 0.007760   Batch Acc: 82.81
[Train] Epoch: 4 [120640/620022]    Loss: 0.007439   Batch Acc: 87.50
[Train] Epoch: 4 [120704/620022]    Loss: 0.007939   Batch Acc: 75.00
[Train] Epoch: 4 [120768/620022]    Loss: 0.007901   Batch Acc: 81.25
[Train] Epoch: 4 [120832/620022]    Loss: 0.011655   Batch Acc: 64.06
[Train] Epoch: 4 [120896/620022]    Loss: 0.008537   Batch Acc: 81.25
[Train] Epoch: 4 [120960/620022]    Loss: 0.008335   Batch Acc: 78.12
[Train] Epoch: 4 [121024/620022]    Loss: 0.008537   Batch Acc: 76.56
[Train] Epoch: 4 [121088/620022]    Loss: 0.008066   Batch Acc: 78.12
[Train] Epoch: 4 [121152/620022]    Loss: 0.007783   Batch Acc: 76.56
[Train] Epoch: 4 [121216/620022]    Loss: 0.007855   Batch Acc: 81.25
[Train] Epoch: 4 [121280/620022]    Loss: 0.011041   Batch Acc: 71.88
[Train] Epoch: 4 [121344/620022]    Loss: 0.006423   Batch Acc: 85.94
[Train] Epoch: 4 [121408/620022]    Loss: 0.008336   Batch Acc: 82.81
[Train] Epoch: 4 [121472/620022]    Loss: 0.011474   Batch Acc: 65.62
[Train] Epoch: 4 [121536/620022]    Loss: 0.009038   Batch Acc: 70.31
[Train] Epoch: 4 [121600/620022]    Loss: 0.008291   Batch Acc: 79.69
[Train] Epoch: 4 [121664/620022]    Loss: 0.008442   Batch Acc: 79.69
[Train] Epoch: 4 [121728/620022]    Loss: 0.009466   Batch Acc: 75.00
[Train] Epoch: 4 [121792/620022]    Loss: 0.009699   Batch Acc: 71.88
[Train] Epoch: 4 [121856/620022]    Loss: 0.007352   Batch Acc: 81.25
[Train] Epoch: 4 [121920/620022]    Loss: 0.009199   Batch Acc: 81.25
[Train] Epoch: 4 [121984/620022]    Loss: 0.009106   Batch Acc: 75.00
[Train] Epoch: 4 [122048/620022]    Loss: 0.007900   Batch Acc: 79.69
[Train] Epoch: 4 [122112/620022]    Loss: 0.008224   Batch Acc: 79.69
[Train] Epoch: 4 [122176/620022]    Loss: 0.006212   Batch Acc: 85.94
[Train] Epoch: 4 [122240/620022]    Loss: 0.006592   Batch Acc: 85.94
[Train] Epoch: 4 [122304/620022]    Loss: 0.006305   Batch Acc: 87.50
[Train] Epoch: 4 [122368/620022]    Loss: 0.007970   Batch Acc: 82.81
[Train] Epoch: 4 [122432/620022]    Loss: 0.007915   Batch Acc: 82.81
[Train] Epoch: 4 [122496/620022]    Loss: 0.010340   Batch Acc: 76.56
[Train] Epoch: 4 [122560/620022]    Loss: 0.009646   Batch Acc: 76.56
[Train] Epoch: 4 [122624/620022]    Loss: 0.007425   Batch Acc: 81.25
[Train] Epoch: 4 [122688/620022]    Loss: 0.007863   Batch Acc: 76.56
[Train] Epoch: 4 [122752/620022]    Loss: 0.007950   Batch Acc: 79.69
[Train] Epoch: 4 [122816/620022]    Loss: 0.008542   Batch Acc: 82.81
[Train] Epoch: 4 [122880/620022]    Loss: 0.010291   Batch Acc: 71.88
[Train] Epoch: 4 [122944/620022]    Loss: 0.008403   Batch Acc: 76.56
[Train] Epoch: 4 [123008/620022]    Loss: 0.011408   Batch Acc: 73.44
[Train] Epoch: 4 [123072/620022]    Loss: 0.007019   Batch Acc: 84.38
[Train] Epoch: 4 [123136/620022]    Loss: 0.008644   Batch Acc: 73.44
[Train] Epoch: 4 [123200/620022]    Loss: 0.007921   Batch Acc: 82.81
[Train] Epoch: 4 [123264/620022]    Loss: 0.007363   Batch Acc: 82.81
[Train] Epoch: 4 [123328/620022]    Loss: 0.007546   Batch Acc: 78.12
[Train] Epoch: 4 [123392/620022]    Loss: 0.009515   Batch Acc: 78.12
[Train] Epoch: 4 [123456/620022]    Loss: 0.007432   Batch Acc: 78.12
[Train] Epoch: 4 [123520/620022]    Loss: 0.008267   Batch Acc: 81.25
[Train] Epoch: 4 [123584/620022]    Loss: 0.009566   Batch Acc: 71.88
[Train] Epoch: 4 [123648/620022]    Loss: 0.008650   Batch Acc: 81.25
[Train] Epoch: 4 [123712/620022]    Loss: 0.007082   Batch Acc: 82.81
[Train] Epoch: 4 [123776/620022]    Loss: 0.008602   Batch Acc: 78.12
[Train] Epoch: 4 [123840/620022]    Loss: 0.009340   Batch Acc: 73.44
[Train] Epoch: 4 [123904/620022]    Loss: 0.009156   Batch Acc: 79.69
[Train] Epoch: 4 [123968/620022]    Loss: 0.007567   Batch Acc: 85.94
[Train] Epoch: 4 [124032/620022]    Loss: 0.007850   Batch Acc: 79.69
[Train] Epoch: 4 [124096/620022]    Loss: 0.007758   Batch Acc: 81.25
[Train] Epoch: 4 [124160/620022]    Loss: 0.009031   Batch Acc: 79.69
[Train] Epoch: 4 [124224/620022]    Loss: 0.007835   Batch Acc: 81.25
[Train] Epoch: 4 [124288/620022]    Loss: 0.009315   Batch Acc: 78.12
[Train] Epoch: 4 [124352/620022]    Loss: 0.007219   Batch Acc: 85.94
[Train] Epoch: 4 [124416/620022]    Loss: 0.006907   Batch Acc: 82.81
[Train] Epoch: 4 [124480/620022]    Loss: 0.009304   Batch Acc: 76.56
[Train] Epoch: 4 [124544/620022]    Loss: 0.008088   Batch Acc: 81.25
[Train] Epoch: 4 [124608/620022]    Loss: 0.008437   Batch Acc: 76.56
[Train] Epoch: 4 [124672/620022]    Loss: 0.007127   Batch Acc: 81.25
[Train] Epoch: 4 [124736/620022]    Loss: 0.008214   Batch Acc: 75.00
[Train] Epoch: 4 [124800/620022]    Loss: 0.011509   Batch Acc: 70.31
[Train] Epoch: 4 [124864/620022]    Loss: 0.010455   Batch Acc: 67.19
[Train] Epoch: 4 [124928/620022]    Loss: 0.007677   Batch Acc: 82.81
[Train] Epoch: 4 [124992/620022]    Loss: 0.005879   Batch Acc: 85.94
[Train] Epoch: 4 [125056/620022]    Loss: 0.008008   Batch Acc: 73.44
[Train] Epoch: 4 [125120/620022]    Loss: 0.009764   Batch Acc: 71.88
[Train] Epoch: 4 [125184/620022]    Loss: 0.011112   Batch Acc: 62.50
[Train] Epoch: 4 [125248/620022]    Loss: 0.007651   Batch Acc: 79.69
[Train] Epoch: 4 [125312/620022]    Loss: 0.009754   Batch Acc: 76.56
[Train] Epoch: 4 [125376/620022]    Loss: 0.007341   Batch Acc: 79.69
[Train] Epoch: 4 [125440/620022]    Loss: 0.009648   Batch Acc: 76.56
[Train] Epoch: 4 [125504/620022]    Loss: 0.006844   Batch Acc: 87.50
[Train] Epoch: 4 [125568/620022]    Loss: 0.008932   Batch Acc: 78.12
[Train] Epoch: 4 [125632/620022]    Loss: 0.008567   Batch Acc: 78.12
[Train] Epoch: 4 [125696/620022]    Loss: 0.010851   Batch Acc: 70.31
[Train] Epoch: 4 [125760/620022]    Loss: 0.010569   Batch Acc: 71.88
[Train] Epoch: 4 [125824/620022]    Loss: 0.008923   Batch Acc: 78.12
[Train] Epoch: 4 [125888/620022]    Loss: 0.011453   Batch Acc: 60.94
[Train] Epoch: 4 [125952/620022]    Loss: 0.006532   Batch Acc: 87.50
[Train] Epoch: 4 [126016/620022]    Loss: 0.008189   Batch Acc: 84.38
[Train] Epoch: 4 [126080/620022]    Loss: 0.006913   Batch Acc: 84.38
[Train] Epoch: 4 [126144/620022]    Loss: 0.007962   Batch Acc: 84.38
[Train] Epoch: 4 [126208/620022]    Loss: 0.007159   Batch Acc: 84.38
[Train] Epoch: 4 [126272/620022]    Loss: 0.009101   Batch Acc: 82.81
[Train] Epoch: 4 [126336/620022]    Loss: 0.010244   Batch Acc: 75.00
[Train] Epoch: 4 [126400/620022]    Loss: 0.008504   Batch Acc: 76.56
[Train] Epoch: 4 [126464/620022]    Loss: 0.007326   Batch Acc: 85.94
[Train] Epoch: 4 [126528/620022]    Loss: 0.007898   Batch Acc: 78.12
[Train] Epoch: 4 [126592/620022]    Loss: 0.008628   Batch Acc: 76.56
[Train] Epoch: 4 [126656/620022]    Loss: 0.007845   Batch Acc: 82.81
[Train] Epoch: 4 [126720/620022]    Loss: 0.009940   Batch Acc: 70.31
[Train] Epoch: 4 [126784/620022]    Loss: 0.009137   Batch Acc: 75.00
[Train] Epoch: 4 [126848/620022]    Loss: 0.008205   Batch Acc: 78.12
[Train] Epoch: 4 [126912/620022]    Loss: 0.008464   Batch Acc: 76.56
[Train] Epoch: 4 [126976/620022]    Loss: 0.012507   Batch Acc: 64.06
[Train] Epoch: 4 [127040/620022]    Loss: 0.006782   Batch Acc: 87.50
[Train] Epoch: 4 [127104/620022]    Loss: 0.007351   Batch Acc: 79.69
[Train] Epoch: 4 [127168/620022]    Loss: 0.009280   Batch Acc: 76.56
[Train] Epoch: 4 [127232/620022]    Loss: 0.011039   Batch Acc: 71.88
[Train] Epoch: 4 [127296/620022]    Loss: 0.008899   Batch Acc: 76.56
[Train] Epoch: 4 [127360/620022]    Loss: 0.012927   Batch Acc: 64.06
[Train] Epoch: 4 [127424/620022]    Loss: 0.008781   Batch Acc: 79.69
[Train] Epoch: 4 [127488/620022]    Loss: 0.008849   Batch Acc: 73.44
[Train] Epoch: 4 [127552/620022]    Loss: 0.009019   Batch Acc: 78.12
[Train] Epoch: 4 [127616/620022]    Loss: 0.006778   Batch Acc: 85.94
[Train] Epoch: 4 [127680/620022]    Loss: 0.009322   Batch Acc: 81.25
[Train] Epoch: 4 [127744/620022]    Loss: 0.008779   Batch Acc: 73.44
[Train] Epoch: 4 [127808/620022]    Loss: 0.010368   Batch Acc: 71.88
[Train] Epoch: 4 [127872/620022]    Loss: 0.006369   Batch Acc: 87.50
[Train] Epoch: 4 [127936/620022]    Loss: 0.007135   Batch Acc: 82.81
[Train] Epoch: 4 [128000/620022]    Loss: 0.008266   Batch Acc: 78.12
[Train] Epoch: 4 [128064/620022]    Loss: 0.007660   Batch Acc: 79.69
[Train] Epoch: 4 [128128/620022]    Loss: 0.008811   Batch Acc: 76.56
[Train] Epoch: 4 [128192/620022]    Loss: 0.009157   Batch Acc: 78.12
[Train] Epoch: 4 [128256/620022]    Loss: 0.009442   Batch Acc: 75.00
[Train] Epoch: 4 [128320/620022]    Loss: 0.006710   Batch Acc: 90.62
[Train] Epoch: 4 [128384/620022]    Loss: 0.009538   Batch Acc: 70.31
[Train] Epoch: 4 [128448/620022]    Loss: 0.009618   Batch Acc: 78.12
[Train] Epoch: 4 [128512/620022]    Loss: 0.008787   Batch Acc: 75.00
[Train] Epoch: 4 [128576/620022]    Loss: 0.007849   Batch Acc: 81.25
[Train] Epoch: 4 [128640/620022]    Loss: 0.006560   Batch Acc: 82.81
[Train] Epoch: 4 [128704/620022]    Loss: 0.006347   Batch Acc: 81.25
[Train] Epoch: 4 [128768/620022]    Loss: 0.006776   Batch Acc: 84.38
[Train] Epoch: 4 [128832/620022]    Loss: 0.008850   Batch Acc: 76.56
[Train] Epoch: 4 [128896/620022]    Loss: 0.008671   Batch Acc: 76.56
[Train] Epoch: 4 [128960/620022]    Loss: 0.009915   Batch Acc: 76.56
[Train] Epoch: 4 [129024/620022]    Loss: 0.007976   Batch Acc: 81.25
[Train] Epoch: 4 [129088/620022]    Loss: 0.006686   Batch Acc: 87.50
[Train] Epoch: 4 [129152/620022]    Loss: 0.010322   Batch Acc: 71.88
[Train] Epoch: 4 [129216/620022]    Loss: 0.008247   Batch Acc: 79.69
[Train] Epoch: 4 [129280/620022]    Loss: 0.006751   Batch Acc: 79.69
[Train] Epoch: 4 [129344/620022]    Loss: 0.009351   Batch Acc: 76.56
[Train] Epoch: 4 [129408/620022]    Loss: 0.010861   Batch Acc: 71.88
[Train] Epoch: 4 [129472/620022]    Loss: 0.009692   Batch Acc: 71.88
[Train] Epoch: 4 [129536/620022]    Loss: 0.007868   Batch Acc: 78.12
[Train] Epoch: 4 [129600/620022]    Loss: 0.006922   Batch Acc: 82.81
[Train] Epoch: 4 [129664/620022]    Loss: 0.007636   Batch Acc: 79.69
[Train] Epoch: 4 [129728/620022]    Loss: 0.007580   Batch Acc: 87.50
[Train] Epoch: 4 [129792/620022]    Loss: 0.008000   Batch Acc: 79.69
[Train] Epoch: 4 [129856/620022]    Loss: 0.008031   Batch Acc: 76.56
[Train] Epoch: 4 [129920/620022]    Loss: 0.006180   Batch Acc: 85.94
[Train] Epoch: 4 [129984/620022]    Loss: 0.008289   Batch Acc: 79.69
[Train] Epoch: 4 [130048/620022]    Loss: 0.007402   Batch Acc: 84.38
[Train] Epoch: 4 [130112/620022]    Loss: 0.010155   Batch Acc: 71.88
[Train] Epoch: 4 [130176/620022]    Loss: 0.009858   Batch Acc: 73.44
[Train] Epoch: 4 [130240/620022]    Loss: 0.007648   Batch Acc: 81.25
[Train] Epoch: 4 [130304/620022]    Loss: 0.011899   Batch Acc: 73.44
[Train] Epoch: 4 [130368/620022]    Loss: 0.009175   Batch Acc: 78.12
[Train] Epoch: 4 [130432/620022]    Loss: 0.007673   Batch Acc: 81.25
[Train] Epoch: 4 [130496/620022]    Loss: 0.008401   Batch Acc: 78.12
[Train] Epoch: 4 [130560/620022]    Loss: 0.007377   Batch Acc: 82.81
[Train] Epoch: 4 [130624/620022]    Loss: 0.008088   Batch Acc: 81.25
[Train] Epoch: 4 [130688/620022]    Loss: 0.008285   Batch Acc: 84.38
[Train] Epoch: 4 [130752/620022]    Loss: 0.008243   Batch Acc: 76.56
[Train] Epoch: 4 [130816/620022]    Loss: 0.008321   Batch Acc: 75.00
[Train] Epoch: 4 [130880/620022]    Loss: 0.008635   Batch Acc: 75.00
[Train] Epoch: 4 [130944/620022]    Loss: 0.009796   Batch Acc: 79.69
[Train] Epoch: 4 [131008/620022]    Loss: 0.007157   Batch Acc: 84.38
[Train] Epoch: 4 [131072/620022]    Loss: 0.009499   Batch Acc: 76.56
[Train] Epoch: 4 [131136/620022]    Loss: 0.008979   Batch Acc: 78.12
[Train] Epoch: 4 [131200/620022]    Loss: 0.006888   Batch Acc: 84.38
[Train] Epoch: 4 [131264/620022]    Loss: 0.008167   Batch Acc: 75.00
[Train] Epoch: 4 [131328/620022]    Loss: 0.009041   Batch Acc: 79.69
[Train] Epoch: 4 [131392/620022]    Loss: 0.008527   Batch Acc: 78.12
[Train] Epoch: 4 [131456/620022]    Loss: 0.006854   Batch Acc: 85.94
[Train] Epoch: 4 [131520/620022]    Loss: 0.009920   Batch Acc: 68.75
[Train] Epoch: 4 [131584/620022]    Loss: 0.008499   Batch Acc: 78.12
[Train] Epoch: 4 [131648/620022]    Loss: 0.010162   Batch Acc: 73.44
[Train] Epoch: 4 [131712/620022]    Loss: 0.008385   Batch Acc: 78.12
[Train] Epoch: 4 [131776/620022]    Loss: 0.007526   Batch Acc: 82.81
[Train] Epoch: 4 [131840/620022]    Loss: 0.012892   Batch Acc: 67.19
[Train] Epoch: 4 [131904/620022]    Loss: 0.006500   Batch Acc: 85.94
[Train] Epoch: 4 [131968/620022]    Loss: 0.009804   Batch Acc: 76.56
[Train] Epoch: 4 [132032/620022]    Loss: 0.006101   Batch Acc: 85.94
[Train] Epoch: 4 [132096/620022]    Loss: 0.007835   Batch Acc: 76.56
[Train] Epoch: 4 [132160/620022]    Loss: 0.007427   Batch Acc: 84.38
[Train] Epoch: 4 [132224/620022]    Loss: 0.009451   Batch Acc: 73.44
[Train] Epoch: 4 [132288/620022]    Loss: 0.009205   Batch Acc: 76.56
[Train] Epoch: 4 [132352/620022]    Loss: 0.008886   Batch Acc: 78.12
[Train] Epoch: 4 [132416/620022]    Loss: 0.009401   Batch Acc: 75.00
[Train] Epoch: 4 [132480/620022]    Loss: 0.007532   Batch Acc: 82.81
[Train] Epoch: 4 [132544/620022]    Loss: 0.008574   Batch Acc: 81.25
[Train] Epoch: 4 [132608/620022]    Loss: 0.010784   Batch Acc: 73.44
[Train] Epoch: 4 [132672/620022]    Loss: 0.008189   Batch Acc: 79.69
[Train] Epoch: 4 [132736/620022]    Loss: 0.006626   Batch Acc: 85.94
[Train] Epoch: 4 [132800/620022]    Loss: 0.008297   Batch Acc: 81.25
[Train] Epoch: 4 [132864/620022]    Loss: 0.010520   Batch Acc: 68.75
[Train] Epoch: 4 [132928/620022]    Loss: 0.008794   Batch Acc: 76.56
[Train] Epoch: 4 [132992/620022]    Loss: 0.007459   Batch Acc: 79.69
[Train] Epoch: 4 [133056/620022]    Loss: 0.008412   Batch Acc: 79.69
[Train] Epoch: 4 [133120/620022]    Loss: 0.006964   Batch Acc: 79.69
[Train] Epoch: 4 [133184/620022]    Loss: 0.008982   Batch Acc: 76.56
[Train] Epoch: 4 [133248/620022]    Loss: 0.008228   Batch Acc: 78.12
[Train] Epoch: 4 [133312/620022]    Loss: 0.006929   Batch Acc: 81.25
[Train] Epoch: 4 [133376/620022]    Loss: 0.007063   Batch Acc: 76.56
[Train] Epoch: 4 [133440/620022]    Loss: 0.006612   Batch Acc: 84.38
[Train] Epoch: 4 [133504/620022]    Loss: 0.008100   Batch Acc: 82.81
[Train] Epoch: 4 [133568/620022]    Loss: 0.008793   Batch Acc: 78.12
[Train] Epoch: 4 [133632/620022]    Loss: 0.009395   Batch Acc: 78.12
[Train] Epoch: 4 [133696/620022]    Loss: 0.009858   Batch Acc: 78.12
[Train] Epoch: 4 [133760/620022]    Loss: 0.010149   Batch Acc: 73.44
[Train] Epoch: 4 [133824/620022]    Loss: 0.005985   Batch Acc: 85.94
[Train] Epoch: 4 [133888/620022]    Loss: 0.009231   Batch Acc: 76.56
[Train] Epoch: 4 [133952/620022]    Loss: 0.009145   Batch Acc: 73.44
[Train] Epoch: 4 [134016/620022]    Loss: 0.007619   Batch Acc: 78.12
[Train] Epoch: 4 [134080/620022]    Loss: 0.010162   Batch Acc: 75.00
[Train] Epoch: 4 [134144/620022]    Loss: 0.008055   Batch Acc: 79.69
[Train] Epoch: 4 [134208/620022]    Loss: 0.009831   Batch Acc: 71.88
[Train] Epoch: 4 [134272/620022]    Loss: 0.006113   Batch Acc: 85.94
[Train] Epoch: 4 [134336/620022]    Loss: 0.011322   Batch Acc: 73.44
[Train] Epoch: 4 [134400/620022]    Loss: 0.010389   Batch Acc: 78.12
[Train] Epoch: 4 [134464/620022]    Loss: 0.007075   Batch Acc: 85.94
[Train] Epoch: 4 [134528/620022]    Loss: 0.010779   Batch Acc: 70.31
[Train] Epoch: 4 [134592/620022]    Loss: 0.008146   Batch Acc: 79.69
[Train] Epoch: 4 [134656/620022]    Loss: 0.007005   Batch Acc: 79.69
[Train] Epoch: 4 [134720/620022]    Loss: 0.009301   Batch Acc: 73.44
[Train] Epoch: 4 [134784/620022]    Loss: 0.008830   Batch Acc: 78.12
[Train] Epoch: 4 [134848/620022]    Loss: 0.008714   Batch Acc: 75.00
[Train] Epoch: 4 [134912/620022]    Loss: 0.008083   Batch Acc: 76.56
[Train] Epoch: 4 [134976/620022]    Loss: 0.009995   Batch Acc: 70.31
[Train] Epoch: 4 [135040/620022]    Loss: 0.009397   Batch Acc: 78.12
[Train] Epoch: 4 [135104/620022]    Loss: 0.007984   Batch Acc: 78.12
[Train] Epoch: 4 [135168/620022]    Loss: 0.008016   Batch Acc: 79.69
[Train] Epoch: 4 [135232/620022]    Loss: 0.008823   Batch Acc: 71.88
[Train] Epoch: 4 [135296/620022]    Loss: 0.005911   Batch Acc: 90.62
[Train] Epoch: 4 [135360/620022]    Loss: 0.008698   Batch Acc: 78.12
[Train] Epoch: 4 [135424/620022]    Loss: 0.005683   Batch Acc: 87.50
[Train] Epoch: 4 [135488/620022]    Loss: 0.009495   Batch Acc: 78.12
[Train] Epoch: 4 [135552/620022]    Loss: 0.008874   Batch Acc: 79.69
[Train] Epoch: 4 [135616/620022]    Loss: 0.007234   Batch Acc: 78.12
[Train] Epoch: 4 [135680/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 4 [135744/620022]    Loss: 0.009432   Batch Acc: 70.31
[Train] Epoch: 4 [135808/620022]    Loss: 0.009918   Batch Acc: 78.12
[Train] Epoch: 4 [135872/620022]    Loss: 0.007214   Batch Acc: 82.81
[Train] Epoch: 4 [135936/620022]    Loss: 0.005720   Batch Acc: 85.94
[Train] Epoch: 4 [136000/620022]    Loss: 0.010991   Batch Acc: 68.75
[Train] Epoch: 4 [136064/620022]    Loss: 0.009415   Batch Acc: 75.00
[Train] Epoch: 4 [136128/620022]    Loss: 0.009499   Batch Acc: 70.31
[Train] Epoch: 4 [136192/620022]    Loss: 0.010410   Batch Acc: 71.88
[Train] Epoch: 4 [136256/620022]    Loss: 0.007702   Batch Acc: 85.94
[Train] Epoch: 4 [136320/620022]    Loss: 0.008982   Batch Acc: 79.69
[Train] Epoch: 4 [136384/620022]    Loss: 0.010795   Batch Acc: 75.00
[Train] Epoch: 4 [136448/620022]    Loss: 0.009396   Batch Acc: 73.44
[Train] Epoch: 4 [136512/620022]    Loss: 0.009648   Batch Acc: 75.00
[Train] Epoch: 4 [136576/620022]    Loss: 0.006457   Batch Acc: 85.94
[Train] Epoch: 4 [136640/620022]    Loss: 0.008261   Batch Acc: 82.81
[Train] Epoch: 4 [136704/620022]    Loss: 0.009957   Batch Acc: 75.00
[Train] Epoch: 4 [136768/620022]    Loss: 0.008571   Batch Acc: 87.50
[Train] Epoch: 4 [136832/620022]    Loss: 0.008558   Batch Acc: 76.56
[Train] Epoch: 4 [136896/620022]    Loss: 0.007171   Batch Acc: 85.94
[Train] Epoch: 4 [136960/620022]    Loss: 0.008456   Batch Acc: 85.94
[Train] Epoch: 4 [137024/620022]    Loss: 0.008524   Batch Acc: 78.12
[Train] Epoch: 4 [137088/620022]    Loss: 0.008798   Batch Acc: 71.88
[Train] Epoch: 4 [137152/620022]    Loss: 0.008263   Batch Acc: 82.81
[Train] Epoch: 4 [137216/620022]    Loss: 0.007254   Batch Acc: 82.81
[Train] Epoch: 4 [137280/620022]    Loss: 0.008060   Batch Acc: 78.12
[Train] Epoch: 4 [137344/620022]    Loss: 0.008419   Batch Acc: 78.12
[Train] Epoch: 4 [137408/620022]    Loss: 0.008679   Batch Acc: 75.00
[Train] Epoch: 4 [137472/620022]    Loss: 0.007723   Batch Acc: 79.69
[Train] Epoch: 4 [137536/620022]    Loss: 0.006605   Batch Acc: 85.94
[Train] Epoch: 4 [137600/620022]    Loss: 0.009168   Batch Acc: 76.56
[Train] Epoch: 4 [137664/620022]    Loss: 0.007424   Batch Acc: 78.12
[Train] Epoch: 4 [137728/620022]    Loss: 0.008091   Batch Acc: 79.69
[Train] Epoch: 4 [137792/620022]    Loss: 0.008249   Batch Acc: 76.56
[Train] Epoch: 4 [137856/620022]    Loss: 0.006403   Batch Acc: 85.94
[Train] Epoch: 4 [137920/620022]    Loss: 0.007584   Batch Acc: 84.38
[Train] Epoch: 4 [137984/620022]    Loss: 0.011279   Batch Acc: 65.62
[Train] Epoch: 4 [138048/620022]    Loss: 0.009274   Batch Acc: 73.44
[Train] Epoch: 4 [138112/620022]    Loss: 0.007079   Batch Acc: 82.81
[Train] Epoch: 4 [138176/620022]    Loss: 0.009577   Batch Acc: 73.44
[Train] Epoch: 4 [138240/620022]    Loss: 0.009948   Batch Acc: 71.88
[Train] Epoch: 4 [138304/620022]    Loss: 0.008166   Batch Acc: 78.12
[Train] Epoch: 4 [138368/620022]    Loss: 0.007224   Batch Acc: 84.38
[Train] Epoch: 4 [138432/620022]    Loss: 0.008654   Batch Acc: 79.69
[Train] Epoch: 4 [138496/620022]    Loss: 0.007899   Batch Acc: 79.69
[Train] Epoch: 4 [138560/620022]    Loss: 0.009461   Batch Acc: 71.88
[Train] Epoch: 4 [138624/620022]    Loss: 0.008840   Batch Acc: 75.00
[Train] Epoch: 4 [138688/620022]    Loss: 0.007864   Batch Acc: 79.69
[Train] Epoch: 4 [138752/620022]    Loss: 0.008962   Batch Acc: 73.44
[Train] Epoch: 4 [138816/620022]    Loss: 0.008721   Batch Acc: 71.88
[Train] Epoch: 4 [138880/620022]    Loss: 0.009033   Batch Acc: 75.00
[Train] Epoch: 4 [138944/620022]    Loss: 0.008396   Batch Acc: 78.12
[Train] Epoch: 4 [139008/620022]    Loss: 0.007931   Batch Acc: 79.69
[Train] Epoch: 4 [139072/620022]    Loss: 0.009360   Batch Acc: 75.00
[Train] Epoch: 4 [139136/620022]    Loss: 0.008340   Batch Acc: 79.69
[Train] Epoch: 4 [139200/620022]    Loss: 0.008498   Batch Acc: 82.81
[Train] Epoch: 4 [139264/620022]    Loss: 0.008822   Batch Acc: 71.88
[Train] Epoch: 4 [139328/620022]    Loss: 0.006462   Batch Acc: 82.81
[Train] Epoch: 4 [139392/620022]    Loss: 0.008332   Batch Acc: 82.81
[Train] Epoch: 4 [139456/620022]    Loss: 0.010194   Batch Acc: 71.88
[Train] Epoch: 4 [139520/620022]    Loss: 0.009007   Batch Acc: 78.12
[Train] Epoch: 4 [139584/620022]    Loss: 0.009264   Batch Acc: 73.44
[Train] Epoch: 4 [139648/620022]    Loss: 0.009418   Batch Acc: 81.25
[Train] Epoch: 4 [139712/620022]    Loss: 0.006346   Batch Acc: 79.69
[Train] Epoch: 4 [139776/620022]    Loss: 0.010367   Batch Acc: 67.19
[Train] Epoch: 4 [139840/620022]    Loss: 0.008788   Batch Acc: 70.31
[Train] Epoch: 4 [139904/620022]    Loss: 0.008190   Batch Acc: 84.38
[Train] Epoch: 4 [139968/620022]    Loss: 0.006314   Batch Acc: 84.38
[Train] Epoch: 4 [140032/620022]    Loss: 0.008870   Batch Acc: 76.56
[Train] Epoch: 4 [140096/620022]    Loss: 0.009178   Batch Acc: 79.69
[Train] Epoch: 4 [140160/620022]    Loss: 0.009045   Batch Acc: 78.12
[Train] Epoch: 4 [140224/620022]    Loss: 0.008447   Batch Acc: 78.12
[Train] Epoch: 4 [140288/620022]    Loss: 0.006843   Batch Acc: 84.38
[Train] Epoch: 4 [140352/620022]    Loss: 0.009340   Batch Acc: 68.75
[Train] Epoch: 4 [140416/620022]    Loss: 0.008501   Batch Acc: 79.69
[Train] Epoch: 4 [140480/620022]    Loss: 0.008741   Batch Acc: 79.69
[Train] Epoch: 4 [140544/620022]    Loss: 0.010301   Batch Acc: 73.44
[Train] Epoch: 4 [140608/620022]    Loss: 0.009643   Batch Acc: 73.44
[Train] Epoch: 4 [140672/620022]    Loss: 0.009884   Batch Acc: 76.56
[Train] Epoch: 4 [140736/620022]    Loss: 0.007879   Batch Acc: 82.81
[Train] Epoch: 4 [140800/620022]    Loss: 0.007743   Batch Acc: 81.25
[Train] Epoch: 4 [140864/620022]    Loss: 0.007121   Batch Acc: 81.25
[Train] Epoch: 4 [140928/620022]    Loss: 0.008277   Batch Acc: 76.56
[Train] Epoch: 4 [140992/620022]    Loss: 0.007042   Batch Acc: 81.25
[Train] Epoch: 4 [141056/620022]    Loss: 0.008236   Batch Acc: 79.69
[Train] Epoch: 4 [141120/620022]    Loss: 0.008167   Batch Acc: 82.81
[Train] Epoch: 4 [141184/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 4 [141248/620022]    Loss: 0.009478   Batch Acc: 73.44
[Train] Epoch: 4 [141312/620022]    Loss: 0.009046   Batch Acc: 78.12
[Train] Epoch: 4 [141376/620022]    Loss: 0.008421   Batch Acc: 81.25
[Train] Epoch: 4 [141440/620022]    Loss: 0.008201   Batch Acc: 76.56
[Train] Epoch: 4 [141504/620022]    Loss: 0.010748   Batch Acc: 65.62
[Train] Epoch: 4 [141568/620022]    Loss: 0.008391   Batch Acc: 78.12
[Train] Epoch: 4 [141632/620022]    Loss: 0.008024   Batch Acc: 73.44
[Train] Epoch: 4 [141696/620022]    Loss: 0.010227   Batch Acc: 73.44
[Train] Epoch: 4 [141760/620022]    Loss: 0.009996   Batch Acc: 73.44
[Train] Epoch: 4 [141824/620022]    Loss: 0.009910   Batch Acc: 78.12
[Train] Epoch: 4 [141888/620022]    Loss: 0.007884   Batch Acc: 82.81
[Train] Epoch: 4 [141952/620022]    Loss: 0.009048   Batch Acc: 73.44
[Train] Epoch: 4 [142016/620022]    Loss: 0.008410   Batch Acc: 76.56
[Train] Epoch: 4 [142080/620022]    Loss: 0.007346   Batch Acc: 82.81
[Train] Epoch: 4 [142144/620022]    Loss: 0.009427   Batch Acc: 71.88
[Train] Epoch: 4 [142208/620022]    Loss: 0.008678   Batch Acc: 75.00
[Train] Epoch: 4 [142272/620022]    Loss: 0.010134   Batch Acc: 68.75
[Train] Epoch: 4 [142336/620022]    Loss: 0.010616   Batch Acc: 71.88
[Train] Epoch: 4 [142400/620022]    Loss: 0.009468   Batch Acc: 76.56
[Train] Epoch: 4 [142464/620022]    Loss: 0.008301   Batch Acc: 78.12
[Train] Epoch: 4 [142528/620022]    Loss: 0.008941   Batch Acc: 73.44
[Train] Epoch: 4 [142592/620022]    Loss: 0.007338   Batch Acc: 82.81
[Train] Epoch: 4 [142656/620022]    Loss: 0.009181   Batch Acc: 76.56
[Train] Epoch: 4 [142720/620022]    Loss: 0.010256   Batch Acc: 71.88
[Train] Epoch: 4 [142784/620022]    Loss: 0.012553   Batch Acc: 65.62
[Train] Epoch: 4 [142848/620022]    Loss: 0.009548   Batch Acc: 76.56
[Train] Epoch: 4 [142912/620022]    Loss: 0.008227   Batch Acc: 81.25
[Train] Epoch: 4 [142976/620022]    Loss: 0.008753   Batch Acc: 82.81
[Train] Epoch: 4 [143040/620022]    Loss: 0.007346   Batch Acc: 78.12
[Train] Epoch: 4 [143104/620022]    Loss: 0.008470   Batch Acc: 73.44
[Train] Epoch: 4 [143168/620022]    Loss: 0.009378   Batch Acc: 73.44
[Train] Epoch: 4 [143232/620022]    Loss: 0.010183   Batch Acc: 70.31
[Train] Epoch: 4 [143296/620022]    Loss: 0.009092   Batch Acc: 79.69
[Train] Epoch: 4 [143360/620022]    Loss: 0.008811   Batch Acc: 78.12
[Train] Epoch: 4 [143424/620022]    Loss: 0.008189   Batch Acc: 76.56
[Train] Epoch: 4 [143488/620022]    Loss: 0.007197   Batch Acc: 79.69
[Train] Epoch: 4 [143552/620022]    Loss: 0.008305   Batch Acc: 79.69
[Train] Epoch: 4 [143616/620022]    Loss: 0.006723   Batch Acc: 85.94
[Train] Epoch: 4 [143680/620022]    Loss: 0.008771   Batch Acc: 73.44
[Train] Epoch: 4 [143744/620022]    Loss: 0.009591   Batch Acc: 75.00
[Train] Epoch: 4 [143808/620022]    Loss: 0.007739   Batch Acc: 82.81
[Train] Epoch: 4 [143872/620022]    Loss: 0.009276   Batch Acc: 79.69
[Train] Epoch: 4 [143936/620022]    Loss: 0.008121   Batch Acc: 78.12
[Train] Epoch: 4 [144000/620022]    Loss: 0.009185   Batch Acc: 79.69
[Train] Epoch: 4 [144064/620022]    Loss: 0.006955   Batch Acc: 81.25
[Train] Epoch: 4 [144128/620022]    Loss: 0.010268   Batch Acc: 71.88
[Train] Epoch: 4 [144192/620022]    Loss: 0.010341   Batch Acc: 71.88
[Train] Epoch: 4 [144256/620022]    Loss: 0.012088   Batch Acc: 67.19
[Train] Epoch: 4 [144320/620022]    Loss: 0.006594   Batch Acc: 89.06
[Train] Epoch: 4 [144384/620022]    Loss: 0.009602   Batch Acc: 73.44
[Train] Epoch: 4 [144448/620022]    Loss: 0.007741   Batch Acc: 82.81
[Train] Epoch: 4 [144512/620022]    Loss: 0.008184   Batch Acc: 76.56
[Train] Epoch: 4 [144576/620022]    Loss: 0.007960   Batch Acc: 79.69
[Train] Epoch: 4 [144640/620022]    Loss: 0.008752   Batch Acc: 76.56
[Train] Epoch: 4 [144704/620022]    Loss: 0.008513   Batch Acc: 73.44
[Train] Epoch: 4 [144768/620022]    Loss: 0.009782   Batch Acc: 78.12
[Train] Epoch: 4 [144832/620022]    Loss: 0.006554   Batch Acc: 87.50
[Train] Epoch: 4 [144896/620022]    Loss: 0.008684   Batch Acc: 76.56
[Train] Epoch: 4 [144960/620022]    Loss: 0.006962   Batch Acc: 84.38
[Train] Epoch: 4 [145024/620022]    Loss: 0.007523   Batch Acc: 81.25
[Train] Epoch: 4 [145088/620022]    Loss: 0.007758   Batch Acc: 84.38
[Train] Epoch: 4 [145152/620022]    Loss: 0.011112   Batch Acc: 70.31
[Train] Epoch: 4 [145216/620022]    Loss: 0.007329   Batch Acc: 81.25
[Train] Epoch: 4 [145280/620022]    Loss: 0.008522   Batch Acc: 75.00
[Train] Epoch: 4 [145344/620022]    Loss: 0.008282   Batch Acc: 81.25
[Train] Epoch: 4 [145408/620022]    Loss: 0.009963   Batch Acc: 75.00
[Train] Epoch: 4 [145472/620022]    Loss: 0.007562   Batch Acc: 79.69
[Train] Epoch: 4 [145536/620022]    Loss: 0.008746   Batch Acc: 81.25
[Train] Epoch: 4 [145600/620022]    Loss: 0.008058   Batch Acc: 78.12
[Train] Epoch: 4 [145664/620022]    Loss: 0.008707   Batch Acc: 78.12
[Train] Epoch: 4 [145728/620022]    Loss: 0.007925   Batch Acc: 79.69
[Train] Epoch: 4 [145792/620022]    Loss: 0.009275   Batch Acc: 79.69
[Train] Epoch: 4 [145856/620022]    Loss: 0.008635   Batch Acc: 82.81
[Train] Epoch: 4 [145920/620022]    Loss: 0.010648   Batch Acc: 68.75
[Train] Epoch: 4 [145984/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 4 [146048/620022]    Loss: 0.007462   Batch Acc: 84.38
[Train] Epoch: 4 [146112/620022]    Loss: 0.010191   Batch Acc: 70.31
[Train] Epoch: 4 [146176/620022]    Loss: 0.010727   Batch Acc: 67.19
[Train] Epoch: 4 [146240/620022]    Loss: 0.009557   Batch Acc: 79.69
[Train] Epoch: 4 [146304/620022]    Loss: 0.007863   Batch Acc: 81.25
[Train] Epoch: 4 [146368/620022]    Loss: 0.009909   Batch Acc: 76.56
[Train] Epoch: 4 [146432/620022]    Loss: 0.009791   Batch Acc: 78.12
[Train] Epoch: 4 [146496/620022]    Loss: 0.009167   Batch Acc: 68.75
[Train] Epoch: 4 [146560/620022]    Loss: 0.008567   Batch Acc: 78.12
[Train] Epoch: 4 [146624/620022]    Loss: 0.010266   Batch Acc: 75.00
[Train] Epoch: 4 [146688/620022]    Loss: 0.008344   Batch Acc: 82.81
[Train] Epoch: 4 [146752/620022]    Loss: 0.008058   Batch Acc: 84.38
[Train] Epoch: 4 [146816/620022]    Loss: 0.008027   Batch Acc: 78.12
[Train] Epoch: 4 [146880/620022]    Loss: 0.008650   Batch Acc: 84.38
[Train] Epoch: 4 [146944/620022]    Loss: 0.010665   Batch Acc: 71.88
[Train] Epoch: 4 [147008/620022]    Loss: 0.008833   Batch Acc: 79.69
[Train] Epoch: 4 [147072/620022]    Loss: 0.008918   Batch Acc: 79.69
[Train] Epoch: 4 [147136/620022]    Loss: 0.007699   Batch Acc: 76.56
[Train] Epoch: 4 [147200/620022]    Loss: 0.011373   Batch Acc: 68.75
[Train] Epoch: 4 [147264/620022]    Loss: 0.009334   Batch Acc: 68.75
[Train] Epoch: 4 [147328/620022]    Loss: 0.009771   Batch Acc: 75.00
[Train] Epoch: 4 [147392/620022]    Loss: 0.008680   Batch Acc: 75.00
[Train] Epoch: 4 [147456/620022]    Loss: 0.011482   Batch Acc: 67.19
[Train] Epoch: 4 [147520/620022]    Loss: 0.006428   Batch Acc: 84.38
[Train] Epoch: 4 [147584/620022]    Loss: 0.009336   Batch Acc: 78.12
[Train] Epoch: 4 [147648/620022]    Loss: 0.009501   Batch Acc: 70.31
[Train] Epoch: 4 [147712/620022]    Loss: 0.009344   Batch Acc: 78.12
[Train] Epoch: 4 [147776/620022]    Loss: 0.008895   Batch Acc: 78.12
[Train] Epoch: 4 [147840/620022]    Loss: 0.009455   Batch Acc: 75.00
[Train] Epoch: 4 [147904/620022]    Loss: 0.007783   Batch Acc: 78.12
[Train] Epoch: 4 [147968/620022]    Loss: 0.008950   Batch Acc: 78.12
[Train] Epoch: 4 [148032/620022]    Loss: 0.005942   Batch Acc: 89.06
[Train] Epoch: 4 [148096/620022]    Loss: 0.008940   Batch Acc: 75.00
[Train] Epoch: 4 [148160/620022]    Loss: 0.008128   Batch Acc: 78.12
[Train] Epoch: 4 [148224/620022]    Loss: 0.009291   Batch Acc: 76.56
[Train] Epoch: 4 [148288/620022]    Loss: 0.007485   Batch Acc: 78.12
[Train] Epoch: 4 [148352/620022]    Loss: 0.007696   Batch Acc: 78.12
[Train] Epoch: 4 [148416/620022]    Loss: 0.007606   Batch Acc: 76.56
[Train] Epoch: 4 [148480/620022]    Loss: 0.009614   Batch Acc: 79.69
[Train] Epoch: 4 [148544/620022]    Loss: 0.007790   Batch Acc: 85.94
[Train] Epoch: 4 [148608/620022]    Loss: 0.008586   Batch Acc: 78.12
[Train] Epoch: 4 [148672/620022]    Loss: 0.011283   Batch Acc: 64.06
[Train] Epoch: 4 [148736/620022]    Loss: 0.006132   Batch Acc: 82.81
[Train] Epoch: 4 [148800/620022]    Loss: 0.008901   Batch Acc: 75.00
[Train] Epoch: 4 [148864/620022]    Loss: 0.008571   Batch Acc: 82.81
[Train] Epoch: 4 [148928/620022]    Loss: 0.010199   Batch Acc: 75.00
[Train] Epoch: 4 [148992/620022]    Loss: 0.008299   Batch Acc: 76.56
[Train] Epoch: 4 [149056/620022]    Loss: 0.010979   Batch Acc: 75.00
[Train] Epoch: 4 [149120/620022]    Loss: 0.009252   Batch Acc: 76.56
[Train] Epoch: 4 [149184/620022]    Loss: 0.009101   Batch Acc: 75.00
[Train] Epoch: 4 [149248/620022]    Loss: 0.009956   Batch Acc: 76.56
[Train] Epoch: 4 [149312/620022]    Loss: 0.010281   Batch Acc: 71.88
[Train] Epoch: 4 [149376/620022]    Loss: 0.008423   Batch Acc: 82.81
[Train] Epoch: 4 [149440/620022]    Loss: 0.008860   Batch Acc: 78.12
[Train] Epoch: 4 [149504/620022]    Loss: 0.006954   Batch Acc: 81.25
[Train] Epoch: 4 [149568/620022]    Loss: 0.009552   Batch Acc: 75.00
[Train] Epoch: 4 [149632/620022]    Loss: 0.007157   Batch Acc: 87.50
[Train] Epoch: 4 [149696/620022]    Loss: 0.008832   Batch Acc: 84.38
[Train] Epoch: 4 [149760/620022]    Loss: 0.010191   Batch Acc: 78.12
[Train] Epoch: 4 [149824/620022]    Loss: 0.010213   Batch Acc: 71.88
[Train] Epoch: 4 [149888/620022]    Loss: 0.007874   Batch Acc: 78.12
[Train] Epoch: 4 [149952/620022]    Loss: 0.008974   Batch Acc: 76.56
[Train] Epoch: 4 [150016/620022]    Loss: 0.010525   Batch Acc: 71.88
[Train] Epoch: 4 [150080/620022]    Loss: 0.009922   Batch Acc: 71.88
[Train] Epoch: 4 [150144/620022]    Loss: 0.008550   Batch Acc: 73.44
[Train] Epoch: 4 [150208/620022]    Loss: 0.007971   Batch Acc: 79.69
[Train] Epoch: 4 [150272/620022]    Loss: 0.006168   Batch Acc: 90.62
[Train] Epoch: 4 [150336/620022]    Loss: 0.010726   Batch Acc: 70.31
[Train] Epoch: 4 [150400/620022]    Loss: 0.012015   Batch Acc: 70.31
[Train] Epoch: 4 [150464/620022]    Loss: 0.008483   Batch Acc: 76.56
[Train] Epoch: 4 [150528/620022]    Loss: 0.007743   Batch Acc: 78.12
[Train] Epoch: 4 [150592/620022]    Loss: 0.008245   Batch Acc: 76.56
[Train] Epoch: 4 [150656/620022]    Loss: 0.009035   Batch Acc: 75.00
[Train] Epoch: 4 [150720/620022]    Loss: 0.010842   Batch Acc: 68.75
[Train] Epoch: 4 [150784/620022]    Loss: 0.011108   Batch Acc: 71.88
[Train] Epoch: 4 [150848/620022]    Loss: 0.009681   Batch Acc: 76.56
[Train] Epoch: 4 [150912/620022]    Loss: 0.009338   Batch Acc: 79.69
[Train] Epoch: 4 [150976/620022]    Loss: 0.009453   Batch Acc: 73.44
[Train] Epoch: 4 [151040/620022]    Loss: 0.013003   Batch Acc: 64.06
[Train] Epoch: 4 [151104/620022]    Loss: 0.009394   Batch Acc: 73.44
[Train] Epoch: 4 [151168/620022]    Loss: 0.006807   Batch Acc: 82.81
[Train] Epoch: 4 [151232/620022]    Loss: 0.009147   Batch Acc: 78.12
[Train] Epoch: 4 [151296/620022]    Loss: 0.011419   Batch Acc: 68.75
[Train] Epoch: 4 [151360/620022]    Loss: 0.007289   Batch Acc: 85.94
[Train] Epoch: 4 [151424/620022]    Loss: 0.008158   Batch Acc: 82.81
[Train] Epoch: 4 [151488/620022]    Loss: 0.008860   Batch Acc: 76.56
[Train] Epoch: 4 [151552/620022]    Loss: 0.008504   Batch Acc: 75.00
[Train] Epoch: 4 [151616/620022]    Loss: 0.007991   Batch Acc: 78.12
[Train] Epoch: 4 [151680/620022]    Loss: 0.008939   Batch Acc: 76.56
[Train] Epoch: 4 [151744/620022]    Loss: 0.008781   Batch Acc: 71.88
[Train] Epoch: 4 [151808/620022]    Loss: 0.007758   Batch Acc: 82.81
[Train] Epoch: 4 [151872/620022]    Loss: 0.007806   Batch Acc: 81.25
[Train] Epoch: 4 [151936/620022]    Loss: 0.010032   Batch Acc: 70.31
[Train] Epoch: 4 [152000/620022]    Loss: 0.008971   Batch Acc: 79.69
[Train] Epoch: 4 [152064/620022]    Loss: 0.006661   Batch Acc: 87.50
[Train] Epoch: 4 [152128/620022]    Loss: 0.008846   Batch Acc: 79.69
[Train] Epoch: 4 [152192/620022]    Loss: 0.007760   Batch Acc: 84.38
[Train] Epoch: 4 [152256/620022]    Loss: 0.008573   Batch Acc: 71.88
[Train] Epoch: 4 [152320/620022]    Loss: 0.008922   Batch Acc: 71.88
[Train] Epoch: 4 [152384/620022]    Loss: 0.006765   Batch Acc: 85.94
[Train] Epoch: 4 [152448/620022]    Loss: 0.009927   Batch Acc: 73.44
[Train] Epoch: 4 [152512/620022]    Loss: 0.009091   Batch Acc: 76.56
[Train] Epoch: 4 [152576/620022]    Loss: 0.009774   Batch Acc: 76.56
[Train] Epoch: 4 [152640/620022]    Loss: 0.006887   Batch Acc: 84.38
[Train] Epoch: 4 [152704/620022]    Loss: 0.008008   Batch Acc: 81.25
[Train] Epoch: 4 [152768/620022]    Loss: 0.009308   Batch Acc: 75.00
[Train] Epoch: 4 [152832/620022]    Loss: 0.008818   Batch Acc: 75.00
[Train] Epoch: 4 [152896/620022]    Loss: 0.007502   Batch Acc: 82.81
[Train] Epoch: 4 [152960/620022]    Loss: 0.007521   Batch Acc: 79.69
[Train] Epoch: 4 [153024/620022]    Loss: 0.007166   Batch Acc: 81.25
[Train] Epoch: 4 [153088/620022]    Loss: 0.007863   Batch Acc: 81.25
[Train] Epoch: 4 [153152/620022]    Loss: 0.008639   Batch Acc: 76.56
[Train] Epoch: 4 [153216/620022]    Loss: 0.007713   Batch Acc: 81.25
[Train] Epoch: 4 [153280/620022]    Loss: 0.008162   Batch Acc: 75.00
[Train] Epoch: 4 [153344/620022]    Loss: 0.007315   Batch Acc: 82.81
[Train] Epoch: 4 [153408/620022]    Loss: 0.008548   Batch Acc: 76.56
[Train] Epoch: 4 [153472/620022]    Loss: 0.009560   Batch Acc: 73.44
[Train] Epoch: 4 [153536/620022]    Loss: 0.007468   Batch Acc: 85.94
[Train] Epoch: 4 [153600/620022]    Loss: 0.008984   Batch Acc: 76.56
[Train] Epoch: 4 [153664/620022]    Loss: 0.008449   Batch Acc: 79.69
[Train] Epoch: 4 [153728/620022]    Loss: 0.006860   Batch Acc: 85.94
[Train] Epoch: 4 [153792/620022]    Loss: 0.007293   Batch Acc: 78.12
[Train] Epoch: 4 [153856/620022]    Loss: 0.011215   Batch Acc: 78.12
[Train] Epoch: 4 [153920/620022]    Loss: 0.008777   Batch Acc: 79.69
[Train] Epoch: 4 [153984/620022]    Loss: 0.008829   Batch Acc: 79.69
[Train] Epoch: 4 [154048/620022]    Loss: 0.006104   Batch Acc: 87.50
[Train] Epoch: 4 [154112/620022]    Loss: 0.010588   Batch Acc: 68.75
[Train] Epoch: 4 [154176/620022]    Loss: 0.009335   Batch Acc: 73.44
[Train] Epoch: 4 [154240/620022]    Loss: 0.010922   Batch Acc: 71.88
[Train] Epoch: 4 [154304/620022]    Loss: 0.012505   Batch Acc: 65.62
[Train] Epoch: 4 [154368/620022]    Loss: 0.011412   Batch Acc: 70.31
[Train] Epoch: 4 [154432/620022]    Loss: 0.008220   Batch Acc: 81.25
[Train] Epoch: 4 [154496/620022]    Loss: 0.008808   Batch Acc: 79.69
[Train] Epoch: 4 [154560/620022]    Loss: 0.009648   Batch Acc: 75.00
[Train] Epoch: 4 [154624/620022]    Loss: 0.007345   Batch Acc: 82.81
[Train] Epoch: 4 [154688/620022]    Loss: 0.007316   Batch Acc: 79.69
[Train] Epoch: 4 [154752/620022]    Loss: 0.008108   Batch Acc: 79.69
[Train] Epoch: 4 [154816/620022]    Loss: 0.007783   Batch Acc: 85.94
[Train] Epoch: 4 [154880/620022]    Loss: 0.008081   Batch Acc: 85.94
[Train] Epoch: 4 [154944/620022]    Loss: 0.008065   Batch Acc: 82.81
[Train] Epoch: 4 [155008/620022]    Loss: 0.008896   Batch Acc: 73.44
[Train] Epoch: 4 [155072/620022]    Loss: 0.007660   Batch Acc: 76.56
[Train] Epoch: 4 [155136/620022]    Loss: 0.008204   Batch Acc: 78.12
[Train] Epoch: 4 [155200/620022]    Loss: 0.010201   Batch Acc: 71.88
[Train] Epoch: 4 [155264/620022]    Loss: 0.010622   Batch Acc: 71.88
[Train] Epoch: 4 [155328/620022]    Loss: 0.008031   Batch Acc: 84.38
[Train] Epoch: 4 [155392/620022]    Loss: 0.008454   Batch Acc: 75.00
[Train] Epoch: 4 [155456/620022]    Loss: 0.009271   Batch Acc: 82.81
[Train] Epoch: 4 [155520/620022]    Loss: 0.007615   Batch Acc: 78.12
[Train] Epoch: 4 [155584/620022]    Loss: 0.008274   Batch Acc: 71.88
[Train] Epoch: 4 [155648/620022]    Loss: 0.008663   Batch Acc: 75.00
[Train] Epoch: 4 [155712/620022]    Loss: 0.011425   Batch Acc: 73.44
[Train] Epoch: 4 [155776/620022]    Loss: 0.009009   Batch Acc: 76.56
[Train] Epoch: 4 [155840/620022]    Loss: 0.007665   Batch Acc: 71.88
[Train] Epoch: 4 [155904/620022]    Loss: 0.008789   Batch Acc: 81.25
[Train] Epoch: 4 [155968/620022]    Loss: 0.008286   Batch Acc: 76.56
[Train] Epoch: 4 [156032/620022]    Loss: 0.008197   Batch Acc: 78.12
[Train] Epoch: 4 [156096/620022]    Loss: 0.009430   Batch Acc: 71.88
[Train] Epoch: 4 [156160/620022]    Loss: 0.011182   Batch Acc: 67.19
[Train] Epoch: 4 [156224/620022]    Loss: 0.009654   Batch Acc: 75.00
[Train] Epoch: 4 [156288/620022]    Loss: 0.008368   Batch Acc: 81.25
[Train] Epoch: 4 [156352/620022]    Loss: 0.010212   Batch Acc: 78.12
[Train] Epoch: 4 [156416/620022]    Loss: 0.006615   Batch Acc: 87.50
[Train] Epoch: 4 [156480/620022]    Loss: 0.010069   Batch Acc: 71.88
[Train] Epoch: 4 [156544/620022]    Loss: 0.008469   Batch Acc: 78.12
[Train] Epoch: 4 [156608/620022]    Loss: 0.008958   Batch Acc: 78.12
[Train] Epoch: 4 [156672/620022]    Loss: 0.007677   Batch Acc: 85.94
[Train] Epoch: 4 [156736/620022]    Loss: 0.010362   Batch Acc: 70.31
[Train] Epoch: 4 [156800/620022]    Loss: 0.007531   Batch Acc: 75.00
[Train] Epoch: 4 [156864/620022]    Loss: 0.007962   Batch Acc: 76.56
[Train] Epoch: 4 [156928/620022]    Loss: 0.007454   Batch Acc: 82.81
[Train] Epoch: 4 [156992/620022]    Loss: 0.010072   Batch Acc: 67.19
[Train] Epoch: 4 [157056/620022]    Loss: 0.010275   Batch Acc: 73.44
[Train] Epoch: 4 [157120/620022]    Loss: 0.007768   Batch Acc: 84.38
[Train] Epoch: 4 [157184/620022]    Loss: 0.009900   Batch Acc: 70.31
[Train] Epoch: 4 [157248/620022]    Loss: 0.009750   Batch Acc: 82.81
[Train] Epoch: 4 [157312/620022]    Loss: 0.008499   Batch Acc: 82.81
[Train] Epoch: 4 [157376/620022]    Loss: 0.008314   Batch Acc: 78.12
[Train] Epoch: 4 [157440/620022]    Loss: 0.008837   Batch Acc: 76.56
[Train] Epoch: 4 [157504/620022]    Loss: 0.008726   Batch Acc: 75.00
[Train] Epoch: 4 [157568/620022]    Loss: 0.008224   Batch Acc: 78.12
[Train] Epoch: 4 [157632/620022]    Loss: 0.008523   Batch Acc: 78.12
[Train] Epoch: 4 [157696/620022]    Loss: 0.008007   Batch Acc: 78.12
[Train] Epoch: 4 [157760/620022]    Loss: 0.010736   Batch Acc: 73.44
[Train] Epoch: 4 [157824/620022]    Loss: 0.007870   Batch Acc: 76.56
[Train] Epoch: 4 [157888/620022]    Loss: 0.007035   Batch Acc: 84.38
[Train] Epoch: 4 [157952/620022]    Loss: 0.011117   Batch Acc: 71.88
[Train] Epoch: 4 [158016/620022]    Loss: 0.008891   Batch Acc: 81.25
[Train] Epoch: 4 [158080/620022]    Loss: 0.007132   Batch Acc: 84.38
[Train] Epoch: 4 [158144/620022]    Loss: 0.009163   Batch Acc: 73.44
[Train] Epoch: 4 [158208/620022]    Loss: 0.008015   Batch Acc: 79.69
[Train] Epoch: 4 [158272/620022]    Loss: 0.008885   Batch Acc: 73.44
[Train] Epoch: 4 [158336/620022]    Loss: 0.009070   Batch Acc: 79.69
[Train] Epoch: 4 [158400/620022]    Loss: 0.008022   Batch Acc: 79.69
[Train] Epoch: 4 [158464/620022]    Loss: 0.006705   Batch Acc: 87.50
[Train] Epoch: 4 [158528/620022]    Loss: 0.010458   Batch Acc: 68.75
[Train] Epoch: 4 [158592/620022]    Loss: 0.010166   Batch Acc: 71.88
[Train] Epoch: 4 [158656/620022]    Loss: 0.009761   Batch Acc: 75.00
[Train] Epoch: 4 [158720/620022]    Loss: 0.008251   Batch Acc: 73.44
[Train] Epoch: 4 [158784/620022]    Loss: 0.011269   Batch Acc: 64.06
[Train] Epoch: 4 [158848/620022]    Loss: 0.011228   Batch Acc: 68.75
[Train] Epoch: 4 [158912/620022]    Loss: 0.006415   Batch Acc: 85.94
[Train] Epoch: 4 [158976/620022]    Loss: 0.009962   Batch Acc: 70.31
[Train] Epoch: 4 [159040/620022]    Loss: 0.008148   Batch Acc: 78.12
[Train] Epoch: 4 [159104/620022]    Loss: 0.011202   Batch Acc: 70.31
[Train] Epoch: 4 [159168/620022]    Loss: 0.009424   Batch Acc: 81.25
[Train] Epoch: 4 [159232/620022]    Loss: 0.008619   Batch Acc: 81.25
[Train] Epoch: 4 [159296/620022]    Loss: 0.009479   Batch Acc: 70.31
[Train] Epoch: 4 [159360/620022]    Loss: 0.008239   Batch Acc: 76.56
[Train] Epoch: 4 [159424/620022]    Loss: 0.008034   Batch Acc: 78.12
[Train] Epoch: 4 [159488/620022]    Loss: 0.008139   Batch Acc: 84.38
[Train] Epoch: 4 [159552/620022]    Loss: 0.007418   Batch Acc: 79.69
[Train] Epoch: 4 [159616/620022]    Loss: 0.008379   Batch Acc: 75.00
[Train] Epoch: 4 [159680/620022]    Loss: 0.009124   Batch Acc: 78.12
[Train] Epoch: 4 [159744/620022]    Loss: 0.009965   Batch Acc: 75.00
[Train] Epoch: 4 [159808/620022]    Loss: 0.006600   Batch Acc: 82.81
[Train] Epoch: 4 [159872/620022]    Loss: 0.007874   Batch Acc: 76.56
[Train] Epoch: 4 [159936/620022]    Loss: 0.006457   Batch Acc: 82.81
[Train] Epoch: 4 [160000/620022]    Loss: 0.009125   Batch Acc: 76.56
[Train] Epoch: 4 [160064/620022]    Loss: 0.007720   Batch Acc: 85.94
[Train] Epoch: 4 [160128/620022]    Loss: 0.010353   Batch Acc: 75.00
[Train] Epoch: 4 [160192/620022]    Loss: 0.007445   Batch Acc: 81.25
[Train] Epoch: 4 [160256/620022]    Loss: 0.010496   Batch Acc: 75.00
[Train] Epoch: 4 [160320/620022]    Loss: 0.007079   Batch Acc: 81.25
[Train] Epoch: 4 [160384/620022]    Loss: 0.009025   Batch Acc: 82.81
[Train] Epoch: 4 [160448/620022]    Loss: 0.008984   Batch Acc: 76.56
[Train] Epoch: 4 [160512/620022]    Loss: 0.008965   Batch Acc: 78.12
[Train] Epoch: 4 [160576/620022]    Loss: 0.011191   Batch Acc: 71.88
[Train] Epoch: 4 [160640/620022]    Loss: 0.007847   Batch Acc: 78.12
[Train] Epoch: 4 [160704/620022]    Loss: 0.008444   Batch Acc: 78.12
[Train] Epoch: 4 [160768/620022]    Loss: 0.008129   Batch Acc: 75.00
[Train] Epoch: 4 [160832/620022]    Loss: 0.008423   Batch Acc: 76.56
[Train] Epoch: 4 [160896/620022]    Loss: 0.010016   Batch Acc: 79.69
[Train] Epoch: 4 [160960/620022]    Loss: 0.007944   Batch Acc: 81.25
[Train] Epoch: 4 [161024/620022]    Loss: 0.011289   Batch Acc: 70.31
[Train] Epoch: 4 [161088/620022]    Loss: 0.009050   Batch Acc: 81.25
[Train] Epoch: 4 [161152/620022]    Loss: 0.010882   Batch Acc: 71.88
[Train] Epoch: 4 [161216/620022]    Loss: 0.007344   Batch Acc: 84.38
[Train] Epoch: 4 [161280/620022]    Loss: 0.009298   Batch Acc: 76.56
[Train] Epoch: 4 [161344/620022]    Loss: 0.009281   Batch Acc: 71.88
[Train] Epoch: 4 [161408/620022]    Loss: 0.009840   Batch Acc: 75.00
[Train] Epoch: 4 [161472/620022]    Loss: 0.011132   Batch Acc: 70.31
[Train] Epoch: 4 [161536/620022]    Loss: 0.007269   Batch Acc: 82.81
[Train] Epoch: 4 [161600/620022]    Loss: 0.008643   Batch Acc: 75.00
[Train] Epoch: 4 [161664/620022]    Loss: 0.009556   Batch Acc: 76.56
[Train] Epoch: 4 [161728/620022]    Loss: 0.007365   Batch Acc: 81.25
[Train] Epoch: 4 [161792/620022]    Loss: 0.005985   Batch Acc: 87.50
[Train] Epoch: 4 [161856/620022]    Loss: 0.009107   Batch Acc: 70.31
[Train] Epoch: 4 [161920/620022]    Loss: 0.010021   Batch Acc: 76.56
[Train] Epoch: 4 [161984/620022]    Loss: 0.009369   Batch Acc: 70.31
[Train] Epoch: 4 [162048/620022]    Loss: 0.008076   Batch Acc: 76.56
[Train] Epoch: 4 [162112/620022]    Loss: 0.010164   Batch Acc: 76.56
[Train] Epoch: 4 [162176/620022]    Loss: 0.008077   Batch Acc: 79.69
[Train] Epoch: 4 [162240/620022]    Loss: 0.009554   Batch Acc: 71.88
[Train] Epoch: 4 [162304/620022]    Loss: 0.009963   Batch Acc: 70.31
[Train] Epoch: 4 [162368/620022]    Loss: 0.009186   Batch Acc: 76.56
[Train] Epoch: 4 [162432/620022]    Loss: 0.007364   Batch Acc: 82.81
[Train] Epoch: 4 [162496/620022]    Loss: 0.009075   Batch Acc: 70.31
[Train] Epoch: 4 [162560/620022]    Loss: 0.007386   Batch Acc: 89.06
[Train] Epoch: 4 [162624/620022]    Loss: 0.008604   Batch Acc: 76.56
[Train] Epoch: 4 [162688/620022]    Loss: 0.008629   Batch Acc: 84.38
[Train] Epoch: 4 [162752/620022]    Loss: 0.010474   Batch Acc: 67.19
[Train] Epoch: 4 [162816/620022]    Loss: 0.008940   Batch Acc: 68.75
[Train] Epoch: 4 [162880/620022]    Loss: 0.009584   Batch Acc: 78.12
[Train] Epoch: 4 [162944/620022]    Loss: 0.008615   Batch Acc: 82.81
[Train] Epoch: 4 [163008/620022]    Loss: 0.010856   Batch Acc: 70.31
[Train] Epoch: 4 [163072/620022]    Loss: 0.008316   Batch Acc: 76.56
[Train] Epoch: 4 [163136/620022]    Loss: 0.008659   Batch Acc: 78.12
[Train] Epoch: 4 [163200/620022]    Loss: 0.007513   Batch Acc: 79.69
[Train] Epoch: 4 [163264/620022]    Loss: 0.008654   Batch Acc: 78.12
[Train] Epoch: 4 [163328/620022]    Loss: 0.007666   Batch Acc: 81.25
[Train] Epoch: 4 [163392/620022]    Loss: 0.009697   Batch Acc: 65.62
[Train] Epoch: 4 [163456/620022]    Loss: 0.010411   Batch Acc: 70.31
[Train] Epoch: 4 [163520/620022]    Loss: 0.006830   Batch Acc: 82.81
[Train] Epoch: 4 [163584/620022]    Loss: 0.008858   Batch Acc: 79.69
[Train] Epoch: 4 [163648/620022]    Loss: 0.008251   Batch Acc: 84.38
[Train] Epoch: 4 [163712/620022]    Loss: 0.007392   Batch Acc: 82.81
[Train] Epoch: 4 [163776/620022]    Loss: 0.010312   Batch Acc: 71.88
[Train] Epoch: 4 [163840/620022]    Loss: 0.007068   Batch Acc: 81.25
[Train] Epoch: 4 [163904/620022]    Loss: 0.007818   Batch Acc: 79.69
[Train] Epoch: 4 [163968/620022]    Loss: 0.007527   Batch Acc: 84.38
[Train] Epoch: 4 [164032/620022]    Loss: 0.007301   Batch Acc: 85.94
[Train] Epoch: 4 [164096/620022]    Loss: 0.010786   Batch Acc: 71.88
[Train] Epoch: 4 [164160/620022]    Loss: 0.009198   Batch Acc: 82.81
[Train] Epoch: 4 [164224/620022]    Loss: 0.007786   Batch Acc: 81.25
[Train] Epoch: 4 [164288/620022]    Loss: 0.009156   Batch Acc: 78.12
[Train] Epoch: 4 [164352/620022]    Loss: 0.011041   Batch Acc: 68.75
[Train] Epoch: 4 [164416/620022]    Loss: 0.007313   Batch Acc: 82.81
[Train] Epoch: 4 [164480/620022]    Loss: 0.008938   Batch Acc: 76.56
[Train] Epoch: 4 [164544/620022]    Loss: 0.007686   Batch Acc: 79.69
[Train] Epoch: 4 [164608/620022]    Loss: 0.011049   Batch Acc: 70.31
[Train] Epoch: 4 [164672/620022]    Loss: 0.009048   Batch Acc: 76.56
[Train] Epoch: 4 [164736/620022]    Loss: 0.006965   Batch Acc: 79.69
[Train] Epoch: 4 [164800/620022]    Loss: 0.006947   Batch Acc: 90.62
[Train] Epoch: 4 [164864/620022]    Loss: 0.012257   Batch Acc: 67.19
[Train] Epoch: 4 [164928/620022]    Loss: 0.009191   Batch Acc: 75.00
[Train] Epoch: 4 [164992/620022]    Loss: 0.009375   Batch Acc: 73.44
[Train] Epoch: 4 [165056/620022]    Loss: 0.008376   Batch Acc: 78.12
[Train] Epoch: 4 [165120/620022]    Loss: 0.008224   Batch Acc: 78.12
[Train] Epoch: 4 [165184/620022]    Loss: 0.007293   Batch Acc: 84.38
[Train] Epoch: 4 [165248/620022]    Loss: 0.007052   Batch Acc: 82.81
[Train] Epoch: 4 [165312/620022]    Loss: 0.010180   Batch Acc: 68.75
[Train] Epoch: 4 [165376/620022]    Loss: 0.010541   Batch Acc: 68.75
[Train] Epoch: 4 [165440/620022]    Loss: 0.009666   Batch Acc: 78.12
[Train] Epoch: 4 [165504/620022]    Loss: 0.007855   Batch Acc: 82.81
[Train] Epoch: 4 [165568/620022]    Loss: 0.008942   Batch Acc: 76.56
[Train] Epoch: 4 [165632/620022]    Loss: 0.008765   Batch Acc: 76.56
[Train] Epoch: 4 [165696/620022]    Loss: 0.006987   Batch Acc: 81.25
[Train] Epoch: 4 [165760/620022]    Loss: 0.008252   Batch Acc: 76.56
[Train] Epoch: 4 [165824/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 4 [165888/620022]    Loss: 0.007977   Batch Acc: 82.81
[Train] Epoch: 4 [165952/620022]    Loss: 0.009467   Batch Acc: 76.56
[Train] Epoch: 4 [166016/620022]    Loss: 0.009142   Batch Acc: 79.69
[Train] Epoch: 4 [166080/620022]    Loss: 0.009940   Batch Acc: 79.69
[Train] Epoch: 4 [166144/620022]    Loss: 0.009508   Batch Acc: 79.69
[Train] Epoch: 4 [166208/620022]    Loss: 0.009165   Batch Acc: 76.56
[Train] Epoch: 4 [166272/620022]    Loss: 0.005646   Batch Acc: 90.62
[Train] Epoch: 4 [166336/620022]    Loss: 0.010538   Batch Acc: 71.88
[Train] Epoch: 4 [166400/620022]    Loss: 0.008327   Batch Acc: 78.12
[Train] Epoch: 4 [166464/620022]    Loss: 0.008835   Batch Acc: 79.69
[Train] Epoch: 4 [166528/620022]    Loss: 0.011109   Batch Acc: 70.31
[Train] Epoch: 4 [166592/620022]    Loss: 0.007194   Batch Acc: 82.81
[Train] Epoch: 4 [166656/620022]    Loss: 0.009068   Batch Acc: 75.00
[Train] Epoch: 4 [166720/620022]    Loss: 0.010685   Batch Acc: 73.44
[Train] Epoch: 4 [166784/620022]    Loss: 0.007680   Batch Acc: 78.12
[Train] Epoch: 4 [166848/620022]    Loss: 0.006249   Batch Acc: 87.50
[Train] Epoch: 4 [166912/620022]    Loss: 0.007484   Batch Acc: 84.38
[Train] Epoch: 4 [166976/620022]    Loss: 0.010811   Batch Acc: 78.12
[Train] Epoch: 4 [167040/620022]    Loss: 0.007875   Batch Acc: 82.81
[Train] Epoch: 4 [167104/620022]    Loss: 0.009545   Batch Acc: 78.12
[Train] Epoch: 4 [167168/620022]    Loss: 0.007496   Batch Acc: 79.69
[Train] Epoch: 4 [167232/620022]    Loss: 0.010177   Batch Acc: 75.00
[Train] Epoch: 4 [167296/620022]    Loss: 0.010441   Batch Acc: 75.00
[Train] Epoch: 4 [167360/620022]    Loss: 0.011043   Batch Acc: 76.56
[Train] Epoch: 4 [167424/620022]    Loss: 0.007748   Batch Acc: 82.81
[Train] Epoch: 4 [167488/620022]    Loss: 0.009150   Batch Acc: 75.00
[Train] Epoch: 4 [167552/620022]    Loss: 0.008448   Batch Acc: 76.56
[Train] Epoch: 4 [167616/620022]    Loss: 0.008233   Batch Acc: 84.38
[Train] Epoch: 4 [167680/620022]    Loss: 0.007684   Batch Acc: 82.81
[Train] Epoch: 4 [167744/620022]    Loss: 0.010388   Batch Acc: 73.44
[Train] Epoch: 4 [167808/620022]    Loss: 0.007970   Batch Acc: 79.69
[Train] Epoch: 4 [167872/620022]    Loss: 0.008800   Batch Acc: 78.12
[Train] Epoch: 4 [167936/620022]    Loss: 0.010563   Batch Acc: 68.75
[Train] Epoch: 4 [168000/620022]    Loss: 0.009870   Batch Acc: 70.31
[Train] Epoch: 4 [168064/620022]    Loss: 0.005872   Batch Acc: 92.19
[Train] Epoch: 4 [168128/620022]    Loss: 0.008495   Batch Acc: 78.12
[Train] Epoch: 4 [168192/620022]    Loss: 0.006576   Batch Acc: 87.50
[Train] Epoch: 4 [168256/620022]    Loss: 0.007922   Batch Acc: 87.50
[Train] Epoch: 4 [168320/620022]    Loss: 0.007376   Batch Acc: 84.38
[Train] Epoch: 4 [168384/620022]    Loss: 0.009381   Batch Acc: 67.19
[Train] Epoch: 4 [168448/620022]    Loss: 0.008346   Batch Acc: 78.12
[Train] Epoch: 4 [168512/620022]    Loss: 0.008656   Batch Acc: 78.12
[Train] Epoch: 4 [168576/620022]    Loss: 0.007309   Batch Acc: 82.81
[Train] Epoch: 4 [168640/620022]    Loss: 0.007461   Batch Acc: 85.94
[Train] Epoch: 4 [168704/620022]    Loss: 0.008369   Batch Acc: 79.69
[Train] Epoch: 4 [168768/620022]    Loss: 0.009655   Batch Acc: 75.00
[Train] Epoch: 4 [168832/620022]    Loss: 0.006128   Batch Acc: 90.62
[Train] Epoch: 4 [168896/620022]    Loss: 0.009454   Batch Acc: 73.44
[Train] Epoch: 4 [168960/620022]    Loss: 0.009463   Batch Acc: 75.00
[Train] Epoch: 4 [169024/620022]    Loss: 0.009081   Batch Acc: 75.00
[Train] Epoch: 4 [169088/620022]    Loss: 0.008007   Batch Acc: 81.25
[Train] Epoch: 4 [169152/620022]    Loss: 0.007473   Batch Acc: 81.25
[Train] Epoch: 4 [169216/620022]    Loss: 0.008206   Batch Acc: 81.25
[Train] Epoch: 4 [169280/620022]    Loss: 0.008833   Batch Acc: 76.56
[Train] Epoch: 4 [169344/620022]    Loss: 0.009087   Batch Acc: 73.44
[Train] Epoch: 4 [169408/620022]    Loss: 0.007955   Batch Acc: 79.69
[Train] Epoch: 4 [169472/620022]    Loss: 0.007081   Batch Acc: 82.81
[Train] Epoch: 4 [169536/620022]    Loss: 0.008543   Batch Acc: 82.81
[Train] Epoch: 4 [169600/620022]    Loss: 0.007622   Batch Acc: 81.25
[Train] Epoch: 4 [169664/620022]    Loss: 0.009567   Batch Acc: 76.56
[Train] Epoch: 4 [169728/620022]    Loss: 0.007255   Batch Acc: 82.81
[Train] Epoch: 4 [169792/620022]    Loss: 0.006653   Batch Acc: 82.81
[Train] Epoch: 4 [169856/620022]    Loss: 0.007718   Batch Acc: 82.81
[Train] Epoch: 4 [169920/620022]    Loss: 0.008705   Batch Acc: 76.56
[Train] Epoch: 4 [169984/620022]    Loss: 0.006999   Batch Acc: 79.69
[Train] Epoch: 4 [170048/620022]    Loss: 0.009341   Batch Acc: 71.88
[Train] Epoch: 4 [170112/620022]    Loss: 0.006956   Batch Acc: 82.81
[Train] Epoch: 4 [170176/620022]    Loss: 0.008816   Batch Acc: 68.75
[Train] Epoch: 4 [170240/620022]    Loss: 0.008517   Batch Acc: 81.25
[Train] Epoch: 4 [170304/620022]    Loss: 0.012160   Batch Acc: 65.62
[Train] Epoch: 4 [170368/620022]    Loss: 0.010591   Batch Acc: 68.75
[Train] Epoch: 4 [170432/620022]    Loss: 0.010660   Batch Acc: 78.12
[Train] Epoch: 4 [170496/620022]    Loss: 0.008425   Batch Acc: 79.69
[Train] Epoch: 4 [170560/620022]    Loss: 0.008737   Batch Acc: 75.00
[Train] Epoch: 4 [170624/620022]    Loss: 0.008509   Batch Acc: 78.12
[Train] Epoch: 4 [170688/620022]    Loss: 0.008343   Batch Acc: 82.81
[Train] Epoch: 4 [170752/620022]    Loss: 0.006490   Batch Acc: 85.94
[Train] Epoch: 4 [170816/620022]    Loss: 0.008429   Batch Acc: 73.44
[Train] Epoch: 4 [170880/620022]    Loss: 0.007910   Batch Acc: 81.25
[Train] Epoch: 4 [170944/620022]    Loss: 0.008956   Batch Acc: 76.56
[Train] Epoch: 4 [171008/620022]    Loss: 0.010057   Batch Acc: 70.31
[Train] Epoch: 4 [171072/620022]    Loss: 0.007515   Batch Acc: 79.69
[Train] Epoch: 4 [171136/620022]    Loss: 0.009009   Batch Acc: 70.31
[Train] Epoch: 4 [171200/620022]    Loss: 0.008297   Batch Acc: 70.31
[Train] Epoch: 4 [171264/620022]    Loss: 0.010754   Batch Acc: 67.19
[Train] Epoch: 4 [171328/620022]    Loss: 0.008841   Batch Acc: 71.88
[Train] Epoch: 4 [171392/620022]    Loss: 0.007357   Batch Acc: 82.81
[Train] Epoch: 4 [171456/620022]    Loss: 0.008411   Batch Acc: 82.81
[Train] Epoch: 4 [171520/620022]    Loss: 0.012231   Batch Acc: 68.75
[Train] Epoch: 4 [171584/620022]    Loss: 0.008480   Batch Acc: 78.12
[Train] Epoch: 4 [171648/620022]    Loss: 0.009990   Batch Acc: 78.12
[Train] Epoch: 4 [171712/620022]    Loss: 0.008417   Batch Acc: 81.25
[Train] Epoch: 4 [171776/620022]    Loss: 0.013647   Batch Acc: 60.94
[Train] Epoch: 4 [171840/620022]    Loss: 0.010886   Batch Acc: 71.88
[Train] Epoch: 4 [171904/620022]    Loss: 0.010052   Batch Acc: 70.31
[Train] Epoch: 4 [171968/620022]    Loss: 0.007225   Batch Acc: 84.38
[Train] Epoch: 4 [172032/620022]    Loss: 0.009302   Batch Acc: 79.69
[Train] Epoch: 4 [172096/620022]    Loss: 0.006961   Batch Acc: 85.94
[Train] Epoch: 4 [172160/620022]    Loss: 0.007597   Batch Acc: 79.69
[Train] Epoch: 4 [172224/620022]    Loss: 0.009418   Batch Acc: 78.12
[Train] Epoch: 4 [172288/620022]    Loss: 0.008268   Batch Acc: 78.12
[Train] Epoch: 4 [172352/620022]    Loss: 0.009962   Batch Acc: 71.88
[Train] Epoch: 4 [172416/620022]    Loss: 0.006106   Batch Acc: 81.25
[Train] Epoch: 4 [172480/620022]    Loss: 0.007537   Batch Acc: 79.69
[Train] Epoch: 4 [172544/620022]    Loss: 0.008066   Batch Acc: 79.69
[Train] Epoch: 4 [172608/620022]    Loss: 0.007954   Batch Acc: 76.56
[Train] Epoch: 4 [172672/620022]    Loss: 0.008629   Batch Acc: 79.69
[Train] Epoch: 4 [172736/620022]    Loss: 0.010068   Batch Acc: 75.00
[Train] Epoch: 4 [172800/620022]    Loss: 0.007847   Batch Acc: 81.25
[Train] Epoch: 4 [172864/620022]    Loss: 0.007233   Batch Acc: 90.62
[Train] Epoch: 4 [172928/620022]    Loss: 0.006653   Batch Acc: 79.69
[Train] Epoch: 4 [172992/620022]    Loss: 0.008056   Batch Acc: 76.56
[Train] Epoch: 4 [173056/620022]    Loss: 0.007098   Batch Acc: 89.06
[Train] Epoch: 4 [173120/620022]    Loss: 0.009951   Batch Acc: 68.75
[Train] Epoch: 4 [173184/620022]    Loss: 0.009160   Batch Acc: 79.69
[Train] Epoch: 4 [173248/620022]    Loss: 0.008225   Batch Acc: 81.25
[Train] Epoch: 4 [173312/620022]    Loss: 0.008465   Batch Acc: 82.81
[Train] Epoch: 4 [173376/620022]    Loss: 0.011282   Batch Acc: 71.88
[Train] Epoch: 4 [173440/620022]    Loss: 0.007895   Batch Acc: 82.81
[Train] Epoch: 4 [173504/620022]    Loss: 0.008428   Batch Acc: 78.12
[Train] Epoch: 4 [173568/620022]    Loss: 0.008257   Batch Acc: 78.12
[Train] Epoch: 4 [173632/620022]    Loss: 0.009363   Batch Acc: 73.44
[Train] Epoch: 4 [173696/620022]    Loss: 0.008878   Batch Acc: 75.00
[Train] Epoch: 4 [173760/620022]    Loss: 0.010101   Batch Acc: 76.56
[Train] Epoch: 4 [173824/620022]    Loss: 0.008841   Batch Acc: 79.69
[Train] Epoch: 4 [173888/620022]    Loss: 0.008745   Batch Acc: 75.00
[Train] Epoch: 4 [173952/620022]    Loss: 0.008507   Batch Acc: 79.69
[Train] Epoch: 4 [174016/620022]    Loss: 0.008103   Batch Acc: 78.12
[Train] Epoch: 4 [174080/620022]    Loss: 0.006923   Batch Acc: 81.25
[Train] Epoch: 4 [174144/620022]    Loss: 0.009128   Batch Acc: 73.44
[Train] Epoch: 4 [174208/620022]    Loss: 0.008722   Batch Acc: 76.56
[Train] Epoch: 4 [174272/620022]    Loss: 0.009516   Batch Acc: 73.44
[Train] Epoch: 4 [174336/620022]    Loss: 0.008291   Batch Acc: 78.12
[Train] Epoch: 4 [174400/620022]    Loss: 0.009468   Batch Acc: 71.88
[Train] Epoch: 4 [174464/620022]    Loss: 0.007497   Batch Acc: 78.12
[Train] Epoch: 4 [174528/620022]    Loss: 0.008020   Batch Acc: 79.69
[Train] Epoch: 4 [174592/620022]    Loss: 0.009725   Batch Acc: 73.44
[Train] Epoch: 4 [174656/620022]    Loss: 0.007268   Batch Acc: 79.69
[Train] Epoch: 4 [174720/620022]    Loss: 0.006651   Batch Acc: 82.81
[Train] Epoch: 4 [174784/620022]    Loss: 0.008720   Batch Acc: 78.12
[Train] Epoch: 4 [174848/620022]    Loss: 0.011483   Batch Acc: 70.31
[Train] Epoch: 4 [174912/620022]    Loss: 0.008530   Batch Acc: 78.12
[Train] Epoch: 4 [174976/620022]    Loss: 0.008784   Batch Acc: 78.12
[Train] Epoch: 4 [175040/620022]    Loss: 0.010080   Batch Acc: 75.00
[Train] Epoch: 4 [175104/620022]    Loss: 0.007382   Batch Acc: 79.69
[Train] Epoch: 4 [175168/620022]    Loss: 0.009694   Batch Acc: 68.75
[Train] Epoch: 4 [175232/620022]    Loss: 0.007482   Batch Acc: 81.25
[Train] Epoch: 4 [175296/620022]    Loss: 0.008782   Batch Acc: 73.44
[Train] Epoch: 4 [175360/620022]    Loss: 0.008539   Batch Acc: 76.56
[Train] Epoch: 4 [175424/620022]    Loss: 0.009773   Batch Acc: 73.44
[Train] Epoch: 4 [175488/620022]    Loss: 0.010452   Batch Acc: 73.44
[Train] Epoch: 4 [175552/620022]    Loss: 0.010043   Batch Acc: 75.00
[Train] Epoch: 4 [175616/620022]    Loss: 0.007165   Batch Acc: 85.94
[Train] Epoch: 4 [175680/620022]    Loss: 0.006947   Batch Acc: 81.25
[Train] Epoch: 4 [175744/620022]    Loss: 0.006407   Batch Acc: 79.69
[Train] Epoch: 4 [175808/620022]    Loss: 0.007901   Batch Acc: 81.25
[Train] Epoch: 4 [175872/620022]    Loss: 0.008148   Batch Acc: 76.56
[Train] Epoch: 4 [175936/620022]    Loss: 0.011225   Batch Acc: 73.44
[Train] Epoch: 4 [176000/620022]    Loss: 0.010732   Batch Acc: 73.44
[Train] Epoch: 4 [176064/620022]    Loss: 0.007160   Batch Acc: 85.94
[Train] Epoch: 4 [176128/620022]    Loss: 0.006620   Batch Acc: 92.19
[Train] Epoch: 4 [176192/620022]    Loss: 0.008918   Batch Acc: 81.25
[Train] Epoch: 4 [176256/620022]    Loss: 0.009574   Batch Acc: 78.12
[Train] Epoch: 4 [176320/620022]    Loss: 0.008688   Batch Acc: 75.00
[Train] Epoch: 4 [176384/620022]    Loss: 0.007055   Batch Acc: 81.25
[Train] Epoch: 4 [176448/620022]    Loss: 0.009430   Batch Acc: 76.56
[Train] Epoch: 4 [176512/620022]    Loss: 0.011787   Batch Acc: 65.62
[Train] Epoch: 4 [176576/620022]    Loss: 0.010469   Batch Acc: 68.75
[Train] Epoch: 4 [176640/620022]    Loss: 0.006775   Batch Acc: 84.38
[Train] Epoch: 4 [176704/620022]    Loss: 0.008658   Batch Acc: 79.69
[Train] Epoch: 4 [176768/620022]    Loss: 0.009901   Batch Acc: 75.00
[Train] Epoch: 4 [176832/620022]    Loss: 0.008546   Batch Acc: 81.25
[Train] Epoch: 4 [176896/620022]    Loss: 0.010390   Batch Acc: 70.31
[Train] Epoch: 4 [176960/620022]    Loss: 0.007610   Batch Acc: 85.94
[Train] Epoch: 4 [177024/620022]    Loss: 0.007875   Batch Acc: 79.69
[Train] Epoch: 4 [177088/620022]    Loss: 0.009893   Batch Acc: 71.88
[Train] Epoch: 4 [177152/620022]    Loss: 0.008628   Batch Acc: 73.44
[Train] Epoch: 4 [177216/620022]    Loss: 0.008674   Batch Acc: 76.56
[Train] Epoch: 4 [177280/620022]    Loss: 0.008655   Batch Acc: 82.81
[Train] Epoch: 4 [177344/620022]    Loss: 0.008370   Batch Acc: 81.25
[Train] Epoch: 4 [177408/620022]    Loss: 0.008701   Batch Acc: 78.12
[Train] Epoch: 4 [177472/620022]    Loss: 0.008214   Batch Acc: 82.81
[Train] Epoch: 4 [177536/620022]    Loss: 0.009061   Batch Acc: 75.00
[Train] Epoch: 4 [177600/620022]    Loss: 0.008571   Batch Acc: 76.56
[Train] Epoch: 4 [177664/620022]    Loss: 0.011250   Batch Acc: 68.75
[Train] Epoch: 4 [177728/620022]    Loss: 0.010326   Batch Acc: 84.38
[Train] Epoch: 4 [177792/620022]    Loss: 0.008059   Batch Acc: 81.25
[Train] Epoch: 4 [177856/620022]    Loss: 0.007137   Batch Acc: 78.12
[Train] Epoch: 4 [177920/620022]    Loss: 0.009977   Batch Acc: 68.75
[Train] Epoch: 4 [177984/620022]    Loss: 0.008123   Batch Acc: 78.12
[Train] Epoch: 4 [178048/620022]    Loss: 0.009608   Batch Acc: 73.44
[Train] Epoch: 4 [178112/620022]    Loss: 0.009217   Batch Acc: 71.88
[Train] Epoch: 4 [178176/620022]    Loss: 0.007330   Batch Acc: 81.25
[Train] Epoch: 4 [178240/620022]    Loss: 0.008337   Batch Acc: 78.12
[Train] Epoch: 4 [178304/620022]    Loss: 0.008578   Batch Acc: 76.56
[Train] Epoch: 4 [178368/620022]    Loss: 0.008710   Batch Acc: 73.44
[Train] Epoch: 4 [178432/620022]    Loss: 0.007459   Batch Acc: 82.81
[Train] Epoch: 4 [178496/620022]    Loss: 0.008082   Batch Acc: 76.56
[Train] Epoch: 4 [178560/620022]    Loss: 0.009825   Batch Acc: 73.44
[Train] Epoch: 4 [178624/620022]    Loss: 0.009285   Batch Acc: 79.69
[Train] Epoch: 4 [178688/620022]    Loss: 0.008172   Batch Acc: 81.25
[Train] Epoch: 4 [178752/620022]    Loss: 0.007735   Batch Acc: 81.25
[Train] Epoch: 4 [178816/620022]    Loss: 0.008411   Batch Acc: 78.12
[Train] Epoch: 4 [178880/620022]    Loss: 0.007720   Batch Acc: 81.25
[Train] Epoch: 4 [178944/620022]    Loss: 0.010453   Batch Acc: 76.56
[Train] Epoch: 4 [179008/620022]    Loss: 0.006490   Batch Acc: 87.50
[Train] Epoch: 4 [179072/620022]    Loss: 0.008082   Batch Acc: 81.25
[Train] Epoch: 4 [179136/620022]    Loss: 0.007656   Batch Acc: 76.56
[Train] Epoch: 4 [179200/620022]    Loss: 0.006193   Batch Acc: 89.06
[Train] Epoch: 4 [179264/620022]    Loss: 0.007749   Batch Acc: 81.25
[Train] Epoch: 4 [179328/620022]    Loss: 0.009576   Batch Acc: 73.44
[Train] Epoch: 4 [179392/620022]    Loss: 0.009158   Batch Acc: 78.12
[Train] Epoch: 4 [179456/620022]    Loss: 0.006835   Batch Acc: 85.94
[Train] Epoch: 4 [179520/620022]    Loss: 0.007471   Batch Acc: 84.38
[Train] Epoch: 4 [179584/620022]    Loss: 0.009387   Batch Acc: 71.88
[Train] Epoch: 4 [179648/620022]    Loss: 0.009683   Batch Acc: 76.56
[Train] Epoch: 4 [179712/620022]    Loss: 0.008401   Batch Acc: 81.25
[Train] Epoch: 4 [179776/620022]    Loss: 0.009541   Batch Acc: 76.56
[Train] Epoch: 4 [179840/620022]    Loss: 0.008206   Batch Acc: 75.00
[Train] Epoch: 4 [179904/620022]    Loss: 0.009614   Batch Acc: 71.88
[Train] Epoch: 4 [179968/620022]    Loss: 0.011016   Batch Acc: 75.00
[Train] Epoch: 4 [180032/620022]    Loss: 0.007295   Batch Acc: 81.25
[Train] Epoch: 4 [180096/620022]    Loss: 0.010501   Batch Acc: 78.12
[Train] Epoch: 4 [180160/620022]    Loss: 0.005954   Batch Acc: 89.06
[Train] Epoch: 4 [180224/620022]    Loss: 0.006976   Batch Acc: 82.81
[Train] Epoch: 4 [180288/620022]    Loss: 0.010043   Batch Acc: 64.06
[Train] Epoch: 4 [180352/620022]    Loss: 0.008049   Batch Acc: 76.56
[Train] Epoch: 4 [180416/620022]    Loss: 0.009136   Batch Acc: 79.69
[Train] Epoch: 4 [180480/620022]    Loss: 0.008073   Batch Acc: 81.25
[Train] Epoch: 4 [180544/620022]    Loss: 0.008089   Batch Acc: 78.12
[Train] Epoch: 4 [180608/620022]    Loss: 0.009826   Batch Acc: 68.75
[Train] Epoch: 4 [180672/620022]    Loss: 0.007970   Batch Acc: 78.12
[Train] Epoch: 4 [180736/620022]    Loss: 0.009172   Batch Acc: 79.69
[Train] Epoch: 4 [180800/620022]    Loss: 0.008388   Batch Acc: 70.31
[Train] Epoch: 4 [180864/620022]    Loss: 0.006768   Batch Acc: 81.25
[Train] Epoch: 4 [180928/620022]    Loss: 0.010195   Batch Acc: 68.75
[Train] Epoch: 4 [180992/620022]    Loss: 0.008030   Batch Acc: 78.12
[Train] Epoch: 4 [181056/620022]    Loss: 0.007075   Batch Acc: 81.25
[Train] Epoch: 4 [181120/620022]    Loss: 0.008739   Batch Acc: 75.00
[Train] Epoch: 4 [181184/620022]    Loss: 0.010206   Batch Acc: 78.12
[Train] Epoch: 4 [181248/620022]    Loss: 0.009172   Batch Acc: 78.12
[Train] Epoch: 4 [181312/620022]    Loss: 0.008397   Batch Acc: 81.25
[Train] Epoch: 4 [181376/620022]    Loss: 0.007157   Batch Acc: 82.81
[Train] Epoch: 4 [181440/620022]    Loss: 0.008893   Batch Acc: 76.56
[Train] Epoch: 4 [181504/620022]    Loss: 0.009126   Batch Acc: 78.12
[Train] Epoch: 4 [181568/620022]    Loss: 0.009015   Batch Acc: 71.88
[Train] Epoch: 4 [181632/620022]    Loss: 0.006933   Batch Acc: 87.50
[Train] Epoch: 4 [181696/620022]    Loss: 0.009166   Batch Acc: 76.56
[Train] Epoch: 4 [181760/620022]    Loss: 0.009007   Batch Acc: 78.12
[Train] Epoch: 4 [181824/620022]    Loss: 0.008248   Batch Acc: 76.56
[Train] Epoch: 4 [181888/620022]    Loss: 0.010528   Batch Acc: 67.19
[Train] Epoch: 4 [181952/620022]    Loss: 0.010485   Batch Acc: 78.12
[Train] Epoch: 4 [182016/620022]    Loss: 0.009625   Batch Acc: 73.44
[Train] Epoch: 4 [182080/620022]    Loss: 0.009281   Batch Acc: 70.31
[Train] Epoch: 4 [182144/620022]    Loss: 0.010099   Batch Acc: 73.44
[Train] Epoch: 4 [182208/620022]    Loss: 0.013412   Batch Acc: 60.94
[Train] Epoch: 4 [182272/620022]    Loss: 0.007054   Batch Acc: 78.12
[Train] Epoch: 4 [182336/620022]    Loss: 0.010100   Batch Acc: 71.88
[Train] Epoch: 4 [182400/620022]    Loss: 0.007030   Batch Acc: 87.50
[Train] Epoch: 4 [182464/620022]    Loss: 0.008187   Batch Acc: 79.69
[Train] Epoch: 4 [182528/620022]    Loss: 0.008543   Batch Acc: 79.69
[Train] Epoch: 4 [182592/620022]    Loss: 0.007484   Batch Acc: 79.69
[Train] Epoch: 4 [182656/620022]    Loss: 0.010149   Batch Acc: 71.88
[Train] Epoch: 4 [182720/620022]    Loss: 0.010796   Batch Acc: 71.88
[Train] Epoch: 4 [182784/620022]    Loss: 0.009594   Batch Acc: 73.44
[Train] Epoch: 4 [182848/620022]    Loss: 0.009247   Batch Acc: 82.81
[Train] Epoch: 4 [182912/620022]    Loss: 0.006798   Batch Acc: 82.81
[Train] Epoch: 4 [182976/620022]    Loss: 0.006709   Batch Acc: 81.25
[Train] Epoch: 4 [183040/620022]    Loss: 0.010360   Batch Acc: 68.75
[Train] Epoch: 4 [183104/620022]    Loss: 0.009234   Batch Acc: 78.12
[Train] Epoch: 4 [183168/620022]    Loss: 0.008593   Batch Acc: 81.25
[Train] Epoch: 4 [183232/620022]    Loss: 0.009415   Batch Acc: 71.88
[Train] Epoch: 4 [183296/620022]    Loss: 0.008814   Batch Acc: 76.56
[Train] Epoch: 4 [183360/620022]    Loss: 0.010384   Batch Acc: 67.19
[Train] Epoch: 4 [183424/620022]    Loss: 0.007356   Batch Acc: 85.94
[Train] Epoch: 4 [183488/620022]    Loss: 0.006571   Batch Acc: 85.94
[Train] Epoch: 4 [183552/620022]    Loss: 0.009181   Batch Acc: 78.12
[Train] Epoch: 4 [183616/620022]    Loss: 0.009172   Batch Acc: 79.69
[Train] Epoch: 4 [183680/620022]    Loss: 0.007784   Batch Acc: 82.81
[Train] Epoch: 4 [183744/620022]    Loss: 0.009288   Batch Acc: 75.00
[Train] Epoch: 4 [183808/620022]    Loss: 0.010753   Batch Acc: 67.19
[Train] Epoch: 4 [183872/620022]    Loss: 0.007334   Batch Acc: 79.69
[Train] Epoch: 4 [183936/620022]    Loss: 0.007892   Batch Acc: 78.12
[Train] Epoch: 4 [184000/620022]    Loss: 0.008409   Batch Acc: 81.25
[Train] Epoch: 4 [184064/620022]    Loss: 0.008169   Batch Acc: 75.00
[Train] Epoch: 4 [184128/620022]    Loss: 0.008045   Batch Acc: 82.81
[Train] Epoch: 4 [184192/620022]    Loss: 0.007397   Batch Acc: 85.94
[Train] Epoch: 4 [184256/620022]    Loss: 0.007789   Batch Acc: 79.69
[Train] Epoch: 4 [184320/620022]    Loss: 0.007855   Batch Acc: 79.69
[Train] Epoch: 4 [184384/620022]    Loss: 0.008292   Batch Acc: 81.25
[Train] Epoch: 4 [184448/620022]    Loss: 0.010158   Batch Acc: 75.00
[Train] Epoch: 4 [184512/620022]    Loss: 0.009430   Batch Acc: 75.00
[Train] Epoch: 4 [184576/620022]    Loss: 0.008101   Batch Acc: 81.25
[Train] Epoch: 4 [184640/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 4 [184704/620022]    Loss: 0.007799   Batch Acc: 84.38
[Train] Epoch: 4 [184768/620022]    Loss: 0.007993   Batch Acc: 84.38
[Train] Epoch: 4 [184832/620022]    Loss: 0.008720   Batch Acc: 76.56
[Train] Epoch: 4 [184896/620022]    Loss: 0.008237   Batch Acc: 76.56
[Train] Epoch: 4 [184960/620022]    Loss: 0.009455   Batch Acc: 73.44
[Train] Epoch: 4 [185024/620022]    Loss: 0.009357   Batch Acc: 71.88
[Train] Epoch: 4 [185088/620022]    Loss: 0.009739   Batch Acc: 71.88
[Train] Epoch: 4 [185152/620022]    Loss: 0.011231   Batch Acc: 65.62
[Train] Epoch: 4 [185216/620022]    Loss: 0.007788   Batch Acc: 81.25
[Train] Epoch: 4 [185280/620022]    Loss: 0.007878   Batch Acc: 81.25
[Train] Epoch: 4 [185344/620022]    Loss: 0.008846   Batch Acc: 75.00
[Train] Epoch: 4 [185408/620022]    Loss: 0.006207   Batch Acc: 90.62
[Train] Epoch: 4 [185472/620022]    Loss: 0.010110   Batch Acc: 73.44
[Train] Epoch: 4 [185536/620022]    Loss: 0.007129   Batch Acc: 76.56
[Train] Epoch: 4 [185600/620022]    Loss: 0.008573   Batch Acc: 78.12
[Train] Epoch: 4 [185664/620022]    Loss: 0.007770   Batch Acc: 85.94
[Train] Epoch: 4 [185728/620022]    Loss: 0.008214   Batch Acc: 79.69
[Train] Epoch: 4 [185792/620022]    Loss: 0.007591   Batch Acc: 85.94
[Train] Epoch: 4 [185856/620022]    Loss: 0.009486   Batch Acc: 78.12
[Train] Epoch: 4 [185920/620022]    Loss: 0.010046   Batch Acc: 70.31
[Train] Epoch: 4 [185984/620022]    Loss: 0.007519   Batch Acc: 82.81
[Train] Epoch: 4 [186048/620022]    Loss: 0.007712   Batch Acc: 84.38
[Train] Epoch: 4 [186112/620022]    Loss: 0.009145   Batch Acc: 73.44
[Train] Epoch: 4 [186176/620022]    Loss: 0.008178   Batch Acc: 81.25
[Train] Epoch: 4 [186240/620022]    Loss: 0.009041   Batch Acc: 79.69
[Train] Epoch: 4 [186304/620022]    Loss: 0.009112   Batch Acc: 82.81
[Train] Epoch: 4 [186368/620022]    Loss: 0.008614   Batch Acc: 78.12
[Train] Epoch: 4 [186432/620022]    Loss: 0.008650   Batch Acc: 73.44
[Train] Epoch: 4 [186496/620022]    Loss: 0.008200   Batch Acc: 76.56
[Train] Epoch: 4 [186560/620022]    Loss: 0.008530   Batch Acc: 79.69
[Train] Epoch: 4 [186624/620022]    Loss: 0.011665   Batch Acc: 71.88
[Train] Epoch: 4 [186688/620022]    Loss: 0.009284   Batch Acc: 73.44
[Train] Epoch: 4 [186752/620022]    Loss: 0.009396   Batch Acc: 75.00
[Train] Epoch: 4 [186816/620022]    Loss: 0.008624   Batch Acc: 81.25
[Train] Epoch: 4 [186880/620022]    Loss: 0.009763   Batch Acc: 78.12
[Train] Epoch: 4 [186944/620022]    Loss: 0.007579   Batch Acc: 82.81
[Train] Epoch: 4 [187008/620022]    Loss: 0.008025   Batch Acc: 79.69
[Train] Epoch: 4 [187072/620022]    Loss: 0.008569   Batch Acc: 75.00
[Train] Epoch: 4 [187136/620022]    Loss: 0.007506   Batch Acc: 89.06
[Train] Epoch: 4 [187200/620022]    Loss: 0.007091   Batch Acc: 79.69
[Train] Epoch: 4 [187264/620022]    Loss: 0.008575   Batch Acc: 78.12
[Train] Epoch: 4 [187328/620022]    Loss: 0.008645   Batch Acc: 78.12
[Train] Epoch: 4 [187392/620022]    Loss: 0.011381   Batch Acc: 67.19
[Train] Epoch: 4 [187456/620022]    Loss: 0.007706   Batch Acc: 81.25
[Train] Epoch: 4 [187520/620022]    Loss: 0.007196   Batch Acc: 84.38
[Train] Epoch: 4 [187584/620022]    Loss: 0.008412   Batch Acc: 79.69
[Train] Epoch: 4 [187648/620022]    Loss: 0.008697   Batch Acc: 81.25
[Train] Epoch: 4 [187712/620022]    Loss: 0.008926   Batch Acc: 75.00
[Train] Epoch: 4 [187776/620022]    Loss: 0.009926   Batch Acc: 71.88
[Train] Epoch: 4 [187840/620022]    Loss: 0.008449   Batch Acc: 78.12
[Train] Epoch: 4 [187904/620022]    Loss: 0.008624   Batch Acc: 76.56
[Train] Epoch: 4 [187968/620022]    Loss: 0.006659   Batch Acc: 79.69
[Train] Epoch: 4 [188032/620022]    Loss: 0.010034   Batch Acc: 68.75
[Train] Epoch: 4 [188096/620022]    Loss: 0.010204   Batch Acc: 75.00
[Train] Epoch: 4 [188160/620022]    Loss: 0.009406   Batch Acc: 73.44
[Train] Epoch: 4 [188224/620022]    Loss: 0.006006   Batch Acc: 87.50
[Train] Epoch: 4 [188288/620022]    Loss: 0.009600   Batch Acc: 73.44
[Train] Epoch: 4 [188352/620022]    Loss: 0.007463   Batch Acc: 81.25
[Train] Epoch: 4 [188416/620022]    Loss: 0.009011   Batch Acc: 76.56
[Train] Epoch: 4 [188480/620022]    Loss: 0.007539   Batch Acc: 84.38
[Train] Epoch: 4 [188544/620022]    Loss: 0.010149   Batch Acc: 71.88
[Train] Epoch: 4 [188608/620022]    Loss: 0.008862   Batch Acc: 76.56
[Train] Epoch: 4 [188672/620022]    Loss: 0.008495   Batch Acc: 76.56
[Train] Epoch: 4 [188736/620022]    Loss: 0.010003   Batch Acc: 76.56
[Train] Epoch: 4 [188800/620022]    Loss: 0.007983   Batch Acc: 81.25
[Train] Epoch: 4 [188864/620022]    Loss: 0.008215   Batch Acc: 81.25
[Train] Epoch: 4 [188928/620022]    Loss: 0.009821   Batch Acc: 76.56
[Train] Epoch: 4 [188992/620022]    Loss: 0.006759   Batch Acc: 84.38
[Train] Epoch: 4 [189056/620022]    Loss: 0.008181   Batch Acc: 71.88
[Train] Epoch: 4 [189120/620022]    Loss: 0.009529   Batch Acc: 68.75
[Train] Epoch: 4 [189184/620022]    Loss: 0.007602   Batch Acc: 85.94
[Train] Epoch: 4 [189248/620022]    Loss: 0.007738   Batch Acc: 81.25
[Train] Epoch: 4 [189312/620022]    Loss: 0.008926   Batch Acc: 75.00
[Train] Epoch: 4 [189376/620022]    Loss: 0.006418   Batch Acc: 84.38
[Train] Epoch: 4 [189440/620022]    Loss: 0.009000   Batch Acc: 71.88
[Train] Epoch: 4 [189504/620022]    Loss: 0.010793   Batch Acc: 70.31
[Train] Epoch: 4 [189568/620022]    Loss: 0.011328   Batch Acc: 70.31
[Train] Epoch: 4 [189632/620022]    Loss: 0.009887   Batch Acc: 75.00
[Train] Epoch: 4 [189696/620022]    Loss: 0.010589   Batch Acc: 78.12
[Train] Epoch: 4 [189760/620022]    Loss: 0.007496   Batch Acc: 78.12
[Train] Epoch: 4 [189824/620022]    Loss: 0.008879   Batch Acc: 78.12
[Train] Epoch: 4 [189888/620022]    Loss: 0.009979   Batch Acc: 71.88
[Train] Epoch: 4 [189952/620022]    Loss: 0.009228   Batch Acc: 76.56
[Train] Epoch: 4 [190016/620022]    Loss: 0.007778   Batch Acc: 76.56
[Train] Epoch: 4 [190080/620022]    Loss: 0.011640   Batch Acc: 70.31
[Train] Epoch: 4 [190144/620022]    Loss: 0.006220   Batch Acc: 85.94
[Train] Epoch: 4 [190208/620022]    Loss: 0.007424   Batch Acc: 79.69
[Train] Epoch: 4 [190272/620022]    Loss: 0.010158   Batch Acc: 73.44
[Train] Epoch: 4 [190336/620022]    Loss: 0.008057   Batch Acc: 79.69
[Train] Epoch: 4 [190400/620022]    Loss: 0.008833   Batch Acc: 73.44
[Train] Epoch: 4 [190464/620022]    Loss: 0.007702   Batch Acc: 79.69
[Train] Epoch: 4 [190528/620022]    Loss: 0.007890   Batch Acc: 79.69
[Train] Epoch: 4 [190592/620022]    Loss: 0.007240   Batch Acc: 84.38
[Train] Epoch: 4 [190656/620022]    Loss: 0.008248   Batch Acc: 76.56
[Train] Epoch: 4 [190720/620022]    Loss: 0.008724   Batch Acc: 75.00
[Train] Epoch: 4 [190784/620022]    Loss: 0.008914   Batch Acc: 76.56
[Train] Epoch: 4 [190848/620022]    Loss: 0.006840   Batch Acc: 81.25
[Train] Epoch: 4 [190912/620022]    Loss: 0.010264   Batch Acc: 71.88
[Train] Epoch: 4 [190976/620022]    Loss: 0.007554   Batch Acc: 84.38
[Train] Epoch: 4 [191040/620022]    Loss: 0.009231   Batch Acc: 79.69
[Train] Epoch: 4 [191104/620022]    Loss: 0.008952   Batch Acc: 78.12
[Train] Epoch: 4 [191168/620022]    Loss: 0.009148   Batch Acc: 75.00
[Train] Epoch: 4 [191232/620022]    Loss: 0.009370   Batch Acc: 76.56
[Train] Epoch: 4 [191296/620022]    Loss: 0.010275   Batch Acc: 70.31
[Train] Epoch: 4 [191360/620022]    Loss: 0.007201   Batch Acc: 84.38
[Train] Epoch: 4 [191424/620022]    Loss: 0.007965   Batch Acc: 78.12
[Train] Epoch: 4 [191488/620022]    Loss: 0.009917   Batch Acc: 75.00
[Train] Epoch: 4 [191552/620022]    Loss: 0.008529   Batch Acc: 78.12
[Train] Epoch: 4 [191616/620022]    Loss: 0.006451   Batch Acc: 84.38
[Train] Epoch: 4 [191680/620022]    Loss: 0.010338   Batch Acc: 78.12
[Train] Epoch: 4 [191744/620022]    Loss: 0.008908   Batch Acc: 76.56
[Train] Epoch: 4 [191808/620022]    Loss: 0.009135   Batch Acc: 75.00
[Train] Epoch: 4 [191872/620022]    Loss: 0.009933   Batch Acc: 68.75
[Train] Epoch: 4 [191936/620022]    Loss: 0.010109   Batch Acc: 73.44
[Train] Epoch: 4 [192000/620022]    Loss: 0.010417   Batch Acc: 68.75
[Train] Epoch: 4 [192064/620022]    Loss: 0.013980   Batch Acc: 56.25
[Train] Epoch: 4 [192128/620022]    Loss: 0.008805   Batch Acc: 75.00
[Train] Epoch: 4 [192192/620022]    Loss: 0.011216   Batch Acc: 68.75
[Train] Epoch: 4 [192256/620022]    Loss: 0.008994   Batch Acc: 76.56
[Train] Epoch: 4 [192320/620022]    Loss: 0.009503   Batch Acc: 71.88
[Train] Epoch: 4 [192384/620022]    Loss: 0.009678   Batch Acc: 78.12
[Train] Epoch: 4 [192448/620022]    Loss: 0.010545   Batch Acc: 68.75
[Train] Epoch: 4 [192512/620022]    Loss: 0.006957   Batch Acc: 85.94
[Train] Epoch: 4 [192576/620022]    Loss: 0.007776   Batch Acc: 78.12
[Train] Epoch: 4 [192640/620022]    Loss: 0.008635   Batch Acc: 81.25
[Train] Epoch: 4 [192704/620022]    Loss: 0.008390   Batch Acc: 76.56
[Train] Epoch: 4 [192768/620022]    Loss: 0.007110   Batch Acc: 81.25
[Train] Epoch: 4 [192832/620022]    Loss: 0.008075   Batch Acc: 81.25
[Train] Epoch: 4 [192896/620022]    Loss: 0.008647   Batch Acc: 76.56
[Train] Epoch: 4 [192960/620022]    Loss: 0.010368   Batch Acc: 75.00
[Train] Epoch: 4 [193024/620022]    Loss: 0.008225   Batch Acc: 76.56
[Train] Epoch: 4 [193088/620022]    Loss: 0.007988   Batch Acc: 76.56
[Train] Epoch: 4 [193152/620022]    Loss: 0.007637   Batch Acc: 75.00
[Train] Epoch: 4 [193216/620022]    Loss: 0.009415   Batch Acc: 75.00
[Train] Epoch: 4 [193280/620022]    Loss: 0.008802   Batch Acc: 78.12
[Train] Epoch: 4 [193344/620022]    Loss: 0.007462   Batch Acc: 79.69
[Train] Epoch: 4 [193408/620022]    Loss: 0.009639   Batch Acc: 75.00
[Train] Epoch: 4 [193472/620022]    Loss: 0.009346   Batch Acc: 70.31
[Train] Epoch: 4 [193536/620022]    Loss: 0.008260   Batch Acc: 79.69
[Train] Epoch: 4 [193600/620022]    Loss: 0.010247   Batch Acc: 73.44
[Train] Epoch: 4 [193664/620022]    Loss: 0.007969   Batch Acc: 81.25
[Train] Epoch: 4 [193728/620022]    Loss: 0.007709   Batch Acc: 81.25
[Train] Epoch: 4 [193792/620022]    Loss: 0.009225   Batch Acc: 70.31
[Train] Epoch: 4 [193856/620022]    Loss: 0.009071   Batch Acc: 73.44
[Train] Epoch: 4 [193920/620022]    Loss: 0.008262   Batch Acc: 76.56
[Train] Epoch: 4 [193984/620022]    Loss: 0.009120   Batch Acc: 73.44
[Train] Epoch: 4 [194048/620022]    Loss: 0.006816   Batch Acc: 81.25
[Train] Epoch: 4 [194112/620022]    Loss: 0.007967   Batch Acc: 78.12
[Train] Epoch: 4 [194176/620022]    Loss: 0.007537   Batch Acc: 84.38
[Train] Epoch: 4 [194240/620022]    Loss: 0.010058   Batch Acc: 68.75
[Train] Epoch: 4 [194304/620022]    Loss: 0.008742   Batch Acc: 73.44
[Train] Epoch: 4 [194368/620022]    Loss: 0.007838   Batch Acc: 76.56
[Train] Epoch: 4 [194432/620022]    Loss: 0.009709   Batch Acc: 75.00
[Train] Epoch: 4 [194496/620022]    Loss: 0.006994   Batch Acc: 81.25
[Train] Epoch: 4 [194560/620022]    Loss: 0.008908   Batch Acc: 81.25
[Train] Epoch: 4 [194624/620022]    Loss: 0.008074   Batch Acc: 76.56
[Train] Epoch: 4 [194688/620022]    Loss: 0.008117   Batch Acc: 81.25
[Train] Epoch: 4 [194752/620022]    Loss: 0.009115   Batch Acc: 82.81
[Train] Epoch: 4 [194816/620022]    Loss: 0.008728   Batch Acc: 76.56
[Train] Epoch: 4 [194880/620022]    Loss: 0.010472   Batch Acc: 68.75
[Train] Epoch: 4 [194944/620022]    Loss: 0.007198   Batch Acc: 82.81
[Train] Epoch: 4 [195008/620022]    Loss: 0.007777   Batch Acc: 79.69
[Train] Epoch: 4 [195072/620022]    Loss: 0.011086   Batch Acc: 75.00
[Train] Epoch: 4 [195136/620022]    Loss: 0.010501   Batch Acc: 68.75
[Train] Epoch: 4 [195200/620022]    Loss: 0.010547   Batch Acc: 75.00
[Train] Epoch: 4 [195264/620022]    Loss: 0.007830   Batch Acc: 82.81
[Train] Epoch: 4 [195328/620022]    Loss: 0.007275   Batch Acc: 84.38
[Train] Epoch: 4 [195392/620022]    Loss: 0.006784   Batch Acc: 81.25
[Train] Epoch: 4 [195456/620022]    Loss: 0.007422   Batch Acc: 82.81
[Train] Epoch: 4 [195520/620022]    Loss: 0.010144   Batch Acc: 71.88
[Train] Epoch: 4 [195584/620022]    Loss: 0.008785   Batch Acc: 75.00
[Train] Epoch: 4 [195648/620022]    Loss: 0.007099   Batch Acc: 81.25
[Train] Epoch: 4 [195712/620022]    Loss: 0.007608   Batch Acc: 85.94
[Train] Epoch: 4 [195776/620022]    Loss: 0.010985   Batch Acc: 71.88
[Train] Epoch: 4 [195840/620022]    Loss: 0.008677   Batch Acc: 81.25
[Train] Epoch: 4 [195904/620022]    Loss: 0.007815   Batch Acc: 78.12
[Train] Epoch: 4 [195968/620022]    Loss: 0.009549   Batch Acc: 71.88
[Train] Epoch: 4 [196032/620022]    Loss: 0.008074   Batch Acc: 75.00
[Train] Epoch: 4 [196096/620022]    Loss: 0.007616   Batch Acc: 79.69
[Train] Epoch: 4 [196160/620022]    Loss: 0.007851   Batch Acc: 79.69
[Train] Epoch: 4 [196224/620022]    Loss: 0.007361   Batch Acc: 79.69
[Train] Epoch: 4 [196288/620022]    Loss: 0.007799   Batch Acc: 79.69
[Train] Epoch: 4 [196352/620022]    Loss: 0.009347   Batch Acc: 78.12
[Train] Epoch: 4 [196416/620022]    Loss: 0.008573   Batch Acc: 78.12
[Train] Epoch: 4 [196480/620022]    Loss: 0.007594   Batch Acc: 79.69
[Train] Epoch: 4 [196544/620022]    Loss: 0.008688   Batch Acc: 75.00
[Train] Epoch: 4 [196608/620022]    Loss: 0.010098   Batch Acc: 76.56
[Train] Epoch: 4 [196672/620022]    Loss: 0.007581   Batch Acc: 81.25
[Train] Epoch: 4 [196736/620022]    Loss: 0.008052   Batch Acc: 79.69
[Train] Epoch: 4 [196800/620022]    Loss: 0.006885   Batch Acc: 81.25
[Train] Epoch: 4 [196864/620022]    Loss: 0.008134   Batch Acc: 81.25
[Train] Epoch: 4 [196928/620022]    Loss: 0.009545   Batch Acc: 71.88
[Train] Epoch: 4 [196992/620022]    Loss: 0.009065   Batch Acc: 75.00
[Train] Epoch: 4 [197056/620022]    Loss: 0.008222   Batch Acc: 76.56
[Train] Epoch: 4 [197120/620022]    Loss: 0.011630   Batch Acc: 75.00
[Train] Epoch: 4 [197184/620022]    Loss: 0.008765   Batch Acc: 73.44
[Train] Epoch: 4 [197248/620022]    Loss: 0.008503   Batch Acc: 76.56
[Train] Epoch: 4 [197312/620022]    Loss: 0.009101   Batch Acc: 75.00
[Train] Epoch: 4 [197376/620022]    Loss: 0.008628   Batch Acc: 75.00
[Train] Epoch: 4 [197440/620022]    Loss: 0.008561   Batch Acc: 79.69
[Train] Epoch: 4 [197504/620022]    Loss: 0.007519   Batch Acc: 82.81
[Train] Epoch: 4 [197568/620022]    Loss: 0.007227   Batch Acc: 82.81
[Train] Epoch: 4 [197632/620022]    Loss: 0.007896   Batch Acc: 84.38
[Train] Epoch: 4 [197696/620022]    Loss: 0.009407   Batch Acc: 78.12
[Train] Epoch: 4 [197760/620022]    Loss: 0.008103   Batch Acc: 82.81
[Train] Epoch: 4 [197824/620022]    Loss: 0.008926   Batch Acc: 76.56
[Train] Epoch: 4 [197888/620022]    Loss: 0.007261   Batch Acc: 84.38
[Train] Epoch: 4 [197952/620022]    Loss: 0.006418   Batch Acc: 85.94
[Train] Epoch: 4 [198016/620022]    Loss: 0.008493   Batch Acc: 79.69
[Train] Epoch: 4 [198080/620022]    Loss: 0.007811   Batch Acc: 76.56
[Train] Epoch: 4 [198144/620022]    Loss: 0.006404   Batch Acc: 85.94
[Train] Epoch: 4 [198208/620022]    Loss: 0.007105   Batch Acc: 76.56
[Train] Epoch: 4 [198272/620022]    Loss: 0.008664   Batch Acc: 79.69
[Train] Epoch: 4 [198336/620022]    Loss: 0.008580   Batch Acc: 75.00
[Train] Epoch: 4 [198400/620022]    Loss: 0.007572   Batch Acc: 84.38
[Train] Epoch: 4 [198464/620022]    Loss: 0.008195   Batch Acc: 84.38
[Train] Epoch: 4 [198528/620022]    Loss: 0.010223   Batch Acc: 73.44
[Train] Epoch: 4 [198592/620022]    Loss: 0.008691   Batch Acc: 75.00
[Train] Epoch: 4 [198656/620022]    Loss: 0.007496   Batch Acc: 76.56
[Train] Epoch: 4 [198720/620022]    Loss: 0.009422   Batch Acc: 76.56
[Train] Epoch: 4 [198784/620022]    Loss: 0.008449   Batch Acc: 76.56
[Train] Epoch: 4 [198848/620022]    Loss: 0.009053   Batch Acc: 76.56
[Train] Epoch: 4 [198912/620022]    Loss: 0.008304   Batch Acc: 76.56
[Train] Epoch: 4 [198976/620022]    Loss: 0.007759   Batch Acc: 79.69
[Train] Epoch: 4 [199040/620022]    Loss: 0.008570   Batch Acc: 79.69
[Train] Epoch: 4 [199104/620022]    Loss: 0.010579   Batch Acc: 73.44
[Train] Epoch: 4 [199168/620022]    Loss: 0.006351   Batch Acc: 82.81
[Train] Epoch: 4 [199232/620022]    Loss: 0.010352   Batch Acc: 59.38
[Train] Epoch: 4 [199296/620022]    Loss: 0.008315   Batch Acc: 76.56
[Train] Epoch: 4 [199360/620022]    Loss: 0.010490   Batch Acc: 70.31
[Train] Epoch: 4 [199424/620022]    Loss: 0.008536   Batch Acc: 79.69
[Train] Epoch: 4 [199488/620022]    Loss: 0.007745   Batch Acc: 75.00
[Train] Epoch: 4 [199552/620022]    Loss: 0.007012   Batch Acc: 84.38
[Train] Epoch: 4 [199616/620022]    Loss: 0.010527   Batch Acc: 79.69
[Train] Epoch: 4 [199680/620022]    Loss: 0.007505   Batch Acc: 82.81
[Train] Epoch: 4 [199744/620022]    Loss: 0.011520   Batch Acc: 71.88
[Train] Epoch: 4 [199808/620022]    Loss: 0.009649   Batch Acc: 71.88
[Train] Epoch: 4 [199872/620022]    Loss: 0.009633   Batch Acc: 68.75
[Train] Epoch: 4 [199936/620022]    Loss: 0.008254   Batch Acc: 78.12
[Train] Epoch: 4 [200000/620022]    Loss: 0.007241   Batch Acc: 84.38
[Train] Epoch: 4 [200064/620022]    Loss: 0.008632   Batch Acc: 75.00
[Train] Epoch: 4 [200128/620022]    Loss: 0.009055   Batch Acc: 71.88
[Train] Epoch: 4 [200192/620022]    Loss: 0.008165   Batch Acc: 79.69
[Train] Epoch: 4 [200256/620022]    Loss: 0.008836   Batch Acc: 79.69
[Train] Epoch: 4 [200320/620022]    Loss: 0.008926   Batch Acc: 73.44
[Train] Epoch: 4 [200384/620022]    Loss: 0.011714   Batch Acc: 65.62
[Train] Epoch: 4 [200448/620022]    Loss: 0.010435   Batch Acc: 73.44
[Train] Epoch: 4 [200512/620022]    Loss: 0.008441   Batch Acc: 76.56
[Train] Epoch: 4 [200576/620022]    Loss: 0.008198   Batch Acc: 75.00
[Train] Epoch: 4 [200640/620022]    Loss: 0.007835   Batch Acc: 75.00
[Train] Epoch: 4 [200704/620022]    Loss: 0.008509   Batch Acc: 76.56
[Train] Epoch: 4 [200768/620022]    Loss: 0.008465   Batch Acc: 81.25
[Train] Epoch: 4 [200832/620022]    Loss: 0.009170   Batch Acc: 71.88
[Train] Epoch: 4 [200896/620022]    Loss: 0.007730   Batch Acc: 82.81
[Train] Epoch: 4 [200960/620022]    Loss: 0.009922   Batch Acc: 71.88
[Train] Epoch: 4 [201024/620022]    Loss: 0.010069   Batch Acc: 75.00
[Train] Epoch: 4 [201088/620022]    Loss: 0.009561   Batch Acc: 76.56
[Train] Epoch: 4 [201152/620022]    Loss: 0.008984   Batch Acc: 81.25
[Train] Epoch: 4 [201216/620022]    Loss: 0.008109   Batch Acc: 82.81
[Train] Epoch: 4 [201280/620022]    Loss: 0.007938   Batch Acc: 79.69
[Train] Epoch: 4 [201344/620022]    Loss: 0.009435   Batch Acc: 78.12
[Train] Epoch: 4 [201408/620022]    Loss: 0.006988   Batch Acc: 84.38
[Train] Epoch: 4 [201472/620022]    Loss: 0.012789   Batch Acc: 67.19
[Train] Epoch: 4 [201536/620022]    Loss: 0.007023   Batch Acc: 82.81
[Train] Epoch: 4 [201600/620022]    Loss: 0.008846   Batch Acc: 79.69
[Train] Epoch: 4 [201664/620022]    Loss: 0.006395   Batch Acc: 81.25
[Train] Epoch: 4 [201728/620022]    Loss: 0.008072   Batch Acc: 81.25
[Train] Epoch: 4 [201792/620022]    Loss: 0.008281   Batch Acc: 78.12
[Train] Epoch: 4 [201856/620022]    Loss: 0.006923   Batch Acc: 84.38
[Train] Epoch: 4 [201920/620022]    Loss: 0.006612   Batch Acc: 84.38
[Train] Epoch: 4 [201984/620022]    Loss: 0.008557   Batch Acc: 79.69
[Train] Epoch: 4 [202048/620022]    Loss: 0.007988   Batch Acc: 79.69
[Train] Epoch: 4 [202112/620022]    Loss: 0.009168   Batch Acc: 75.00
[Train] Epoch: 4 [202176/620022]    Loss: 0.009267   Batch Acc: 71.88
[Train] Epoch: 4 [202240/620022]    Loss: 0.008688   Batch Acc: 79.69
[Train] Epoch: 4 [202304/620022]    Loss: 0.009636   Batch Acc: 78.12
[Train] Epoch: 4 [202368/620022]    Loss: 0.007336   Batch Acc: 78.12
[Train] Epoch: 4 [202432/620022]    Loss: 0.008426   Batch Acc: 78.12
[Train] Epoch: 4 [202496/620022]    Loss: 0.008400   Batch Acc: 75.00
[Train] Epoch: 4 [202560/620022]    Loss: 0.008496   Batch Acc: 75.00
[Train] Epoch: 4 [202624/620022]    Loss: 0.008433   Batch Acc: 75.00
[Train] Epoch: 4 [202688/620022]    Loss: 0.008151   Batch Acc: 78.12
[Train] Epoch: 4 [202752/620022]    Loss: 0.008832   Batch Acc: 76.56
[Train] Epoch: 4 [202816/620022]    Loss: 0.009460   Batch Acc: 78.12
[Train] Epoch: 4 [202880/620022]    Loss: 0.009652   Batch Acc: 71.88
[Train] Epoch: 4 [202944/620022]    Loss: 0.010245   Batch Acc: 65.62
[Train] Epoch: 4 [203008/620022]    Loss: 0.009687   Batch Acc: 75.00
[Train] Epoch: 4 [203072/620022]    Loss: 0.007608   Batch Acc: 81.25
[Train] Epoch: 4 [203136/620022]    Loss: 0.008932   Batch Acc: 75.00
[Train] Epoch: 4 [203200/620022]    Loss: 0.006578   Batch Acc: 89.06
[Train] Epoch: 4 [203264/620022]    Loss: 0.009086   Batch Acc: 73.44
[Train] Epoch: 4 [203328/620022]    Loss: 0.007549   Batch Acc: 81.25
[Train] Epoch: 4 [203392/620022]    Loss: 0.005571   Batch Acc: 87.50
[Train] Epoch: 4 [203456/620022]    Loss: 0.009015   Batch Acc: 81.25
[Train] Epoch: 4 [203520/620022]    Loss: 0.009348   Batch Acc: 75.00
[Train] Epoch: 4 [203584/620022]    Loss: 0.009263   Batch Acc: 75.00
[Train] Epoch: 4 [203648/620022]    Loss: 0.007107   Batch Acc: 82.81
[Train] Epoch: 4 [203712/620022]    Loss: 0.007444   Batch Acc: 82.81
[Train] Epoch: 4 [203776/620022]    Loss: 0.009665   Batch Acc: 76.56
[Train] Epoch: 4 [203840/620022]    Loss: 0.008795   Batch Acc: 79.69
[Train] Epoch: 4 [203904/620022]    Loss: 0.010041   Batch Acc: 76.56
[Train] Epoch: 4 [203968/620022]    Loss: 0.010364   Batch Acc: 78.12
[Train] Epoch: 4 [204032/620022]    Loss: 0.008725   Batch Acc: 75.00
[Train] Epoch: 4 [204096/620022]    Loss: 0.009774   Batch Acc: 70.31
[Train] Epoch: 4 [204160/620022]    Loss: 0.007633   Batch Acc: 79.69
[Train] Epoch: 4 [204224/620022]    Loss: 0.008885   Batch Acc: 79.69
[Train] Epoch: 4 [204288/620022]    Loss: 0.008321   Batch Acc: 81.25
[Train] Epoch: 4 [204352/620022]    Loss: 0.008068   Batch Acc: 73.44
[Train] Epoch: 4 [204416/620022]    Loss: 0.009503   Batch Acc: 76.56
[Train] Epoch: 4 [204480/620022]    Loss: 0.008659   Batch Acc: 75.00
[Train] Epoch: 4 [204544/620022]    Loss: 0.010855   Batch Acc: 70.31
[Train] Epoch: 4 [204608/620022]    Loss: 0.008570   Batch Acc: 82.81
[Train] Epoch: 4 [204672/620022]    Loss: 0.007056   Batch Acc: 85.94
[Train] Epoch: 4 [204736/620022]    Loss: 0.008023   Batch Acc: 79.69
[Train] Epoch: 4 [204800/620022]    Loss: 0.011250   Batch Acc: 68.75
[Train] Epoch: 4 [204864/620022]    Loss: 0.007763   Batch Acc: 84.38
[Train] Epoch: 4 [204928/620022]    Loss: 0.008864   Batch Acc: 76.56
[Train] Epoch: 4 [204992/620022]    Loss: 0.009368   Batch Acc: 78.12
[Train] Epoch: 4 [205056/620022]    Loss: 0.008456   Batch Acc: 75.00
[Train] Epoch: 4 [205120/620022]    Loss: 0.008044   Batch Acc: 78.12
[Train] Epoch: 4 [205184/620022]    Loss: 0.009676   Batch Acc: 76.56
[Train] Epoch: 4 [205248/620022]    Loss: 0.008193   Batch Acc: 79.69
[Train] Epoch: 4 [205312/620022]    Loss: 0.009528   Batch Acc: 78.12
[Train] Epoch: 4 [205376/620022]    Loss: 0.009170   Batch Acc: 75.00
[Train] Epoch: 4 [205440/620022]    Loss: 0.008137   Batch Acc: 81.25
[Train] Epoch: 4 [205504/620022]    Loss: 0.007149   Batch Acc: 79.69
[Train] Epoch: 4 [205568/620022]    Loss: 0.010073   Batch Acc: 71.88
[Train] Epoch: 4 [205632/620022]    Loss: 0.006322   Batch Acc: 89.06
[Train] Epoch: 4 [205696/620022]    Loss: 0.007913   Batch Acc: 81.25
[Train] Epoch: 4 [205760/620022]    Loss: 0.007485   Batch Acc: 78.12
[Train] Epoch: 4 [205824/620022]    Loss: 0.007054   Batch Acc: 82.81
[Train] Epoch: 4 [205888/620022]    Loss: 0.010508   Batch Acc: 70.31
[Train] Epoch: 4 [205952/620022]    Loss: 0.007468   Batch Acc: 79.69
[Train] Epoch: 4 [206016/620022]    Loss: 0.007841   Batch Acc: 82.81
[Train] Epoch: 4 [206080/620022]    Loss: 0.006664   Batch Acc: 84.38
[Train] Epoch: 4 [206144/620022]    Loss: 0.007183   Batch Acc: 85.94
[Train] Epoch: 4 [206208/620022]    Loss: 0.007643   Batch Acc: 84.38
[Train] Epoch: 4 [206272/620022]    Loss: 0.011769   Batch Acc: 70.31
[Train] Epoch: 4 [206336/620022]    Loss: 0.008468   Batch Acc: 78.12
[Train] Epoch: 4 [206400/620022]    Loss: 0.008836   Batch Acc: 76.56
[Train] Epoch: 4 [206464/620022]    Loss: 0.007207   Batch Acc: 81.25
[Train] Epoch: 4 [206528/620022]    Loss: 0.007930   Batch Acc: 78.12
[Train] Epoch: 4 [206592/620022]    Loss: 0.007365   Batch Acc: 84.38
[Train] Epoch: 4 [206656/620022]    Loss: 0.008409   Batch Acc: 79.69
[Train] Epoch: 4 [206720/620022]    Loss: 0.010489   Batch Acc: 76.56
[Train] Epoch: 4 [206784/620022]    Loss: 0.007366   Batch Acc: 82.81
[Train] Epoch: 4 [206848/620022]    Loss: 0.008287   Batch Acc: 82.81
[Train] Epoch: 4 [206912/620022]    Loss: 0.007567   Batch Acc: 79.69
[Train] Epoch: 4 [206976/620022]    Loss: 0.007916   Batch Acc: 78.12
[Train] Epoch: 4 [207040/620022]    Loss: 0.008914   Batch Acc: 79.69
[Train] Epoch: 4 [207104/620022]    Loss: 0.007974   Batch Acc: 81.25
[Train] Epoch: 4 [207168/620022]    Loss: 0.007640   Batch Acc: 75.00
[Train] Epoch: 4 [207232/620022]    Loss: 0.009408   Batch Acc: 75.00
[Train] Epoch: 4 [207296/620022]    Loss: 0.010817   Batch Acc: 71.88
[Train] Epoch: 4 [207360/620022]    Loss: 0.010045   Batch Acc: 75.00
[Train] Epoch: 4 [207424/620022]    Loss: 0.008272   Batch Acc: 82.81
[Train] Epoch: 4 [207488/620022]    Loss: 0.009916   Batch Acc: 73.44
[Train] Epoch: 4 [207552/620022]    Loss: 0.009373   Batch Acc: 76.56
[Train] Epoch: 4 [207616/620022]    Loss: 0.008688   Batch Acc: 79.69
[Train] Epoch: 4 [207680/620022]    Loss: 0.008450   Batch Acc: 81.25
[Train] Epoch: 4 [207744/620022]    Loss: 0.007212   Batch Acc: 84.38
[Train] Epoch: 4 [207808/620022]    Loss: 0.009123   Batch Acc: 76.56
[Train] Epoch: 4 [207872/620022]    Loss: 0.008571   Batch Acc: 78.12
[Train] Epoch: 4 [207936/620022]    Loss: 0.009625   Batch Acc: 71.88
[Train] Epoch: 4 [208000/620022]    Loss: 0.009204   Batch Acc: 78.12
[Train] Epoch: 4 [208064/620022]    Loss: 0.008786   Batch Acc: 81.25
[Train] Epoch: 4 [208128/620022]    Loss: 0.008420   Batch Acc: 73.44
[Train] Epoch: 4 [208192/620022]    Loss: 0.009341   Batch Acc: 68.75
[Train] Epoch: 4 [208256/620022]    Loss: 0.007611   Batch Acc: 79.69
[Train] Epoch: 4 [208320/620022]    Loss: 0.007786   Batch Acc: 79.69
[Train] Epoch: 4 [208384/620022]    Loss: 0.007777   Batch Acc: 81.25
[Train] Epoch: 4 [208448/620022]    Loss: 0.009908   Batch Acc: 76.56
[Train] Epoch: 4 [208512/620022]    Loss: 0.007313   Batch Acc: 84.38
[Train] Epoch: 4 [208576/620022]    Loss: 0.008140   Batch Acc: 82.81
[Train] Epoch: 4 [208640/620022]    Loss: 0.008214   Batch Acc: 76.56
[Train] Epoch: 4 [208704/620022]    Loss: 0.009695   Batch Acc: 65.62
[Train] Epoch: 4 [208768/620022]    Loss: 0.006387   Batch Acc: 85.94
[Train] Epoch: 4 [208832/620022]    Loss: 0.006666   Batch Acc: 84.38
[Train] Epoch: 4 [208896/620022]    Loss: 0.010699   Batch Acc: 68.75
[Train] Epoch: 4 [208960/620022]    Loss: 0.010227   Batch Acc: 70.31
[Train] Epoch: 4 [209024/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 4 [209088/620022]    Loss: 0.009668   Batch Acc: 71.88
[Train] Epoch: 4 [209152/620022]    Loss: 0.011114   Batch Acc: 70.31
[Train] Epoch: 4 [209216/620022]    Loss: 0.010435   Batch Acc: 71.88
[Train] Epoch: 4 [209280/620022]    Loss: 0.009398   Batch Acc: 81.25
[Train] Epoch: 4 [209344/620022]    Loss: 0.008894   Batch Acc: 75.00
[Train] Epoch: 4 [209408/620022]    Loss: 0.007671   Batch Acc: 84.38
[Train] Epoch: 4 [209472/620022]    Loss: 0.007814   Batch Acc: 78.12
[Train] Epoch: 4 [209536/620022]    Loss: 0.008491   Batch Acc: 81.25
[Train] Epoch: 4 [209600/620022]    Loss: 0.011017   Batch Acc: 71.88
[Train] Epoch: 4 [209664/620022]    Loss: 0.007608   Batch Acc: 82.81
[Train] Epoch: 4 [209728/620022]    Loss: 0.008798   Batch Acc: 76.56
[Train] Epoch: 4 [209792/620022]    Loss: 0.006524   Batch Acc: 82.81
[Train] Epoch: 4 [209856/620022]    Loss: 0.010589   Batch Acc: 71.88
[Train] Epoch: 4 [209920/620022]    Loss: 0.009612   Batch Acc: 73.44
[Train] Epoch: 4 [209984/620022]    Loss: 0.009079   Batch Acc: 70.31
[Train] Epoch: 4 [210048/620022]    Loss: 0.009493   Batch Acc: 70.31
[Train] Epoch: 4 [210112/620022]    Loss: 0.010290   Batch Acc: 67.19
[Train] Epoch: 4 [210176/620022]    Loss: 0.008907   Batch Acc: 76.56
[Train] Epoch: 4 [210240/620022]    Loss: 0.007447   Batch Acc: 82.81
[Train] Epoch: 4 [210304/620022]    Loss: 0.007336   Batch Acc: 84.38
[Train] Epoch: 4 [210368/620022]    Loss: 0.008037   Batch Acc: 82.81
[Train] Epoch: 4 [210432/620022]    Loss: 0.009328   Batch Acc: 76.56
[Train] Epoch: 4 [210496/620022]    Loss: 0.008590   Batch Acc: 79.69
[Train] Epoch: 4 [210560/620022]    Loss: 0.009913   Batch Acc: 76.56
[Train] Epoch: 4 [210624/620022]    Loss: 0.007161   Batch Acc: 81.25
[Train] Epoch: 4 [210688/620022]    Loss: 0.008561   Batch Acc: 79.69
[Train] Epoch: 4 [210752/620022]    Loss: 0.007648   Batch Acc: 85.94
[Train] Epoch: 4 [210816/620022]    Loss: 0.006871   Batch Acc: 84.38
[Train] Epoch: 4 [210880/620022]    Loss: 0.007314   Batch Acc: 78.12
[Train] Epoch: 4 [210944/620022]    Loss: 0.008481   Batch Acc: 81.25
[Train] Epoch: 4 [211008/620022]    Loss: 0.008440   Batch Acc: 76.56
[Train] Epoch: 4 [211072/620022]    Loss: 0.009161   Batch Acc: 71.88
[Train] Epoch: 4 [211136/620022]    Loss: 0.010862   Batch Acc: 75.00
[Train] Epoch: 4 [211200/620022]    Loss: 0.008766   Batch Acc: 73.44
[Train] Epoch: 4 [211264/620022]    Loss: 0.007691   Batch Acc: 81.25
[Train] Epoch: 4 [211328/620022]    Loss: 0.010030   Batch Acc: 76.56
[Train] Epoch: 4 [211392/620022]    Loss: 0.008519   Batch Acc: 78.12
[Train] Epoch: 4 [211456/620022]    Loss: 0.010345   Batch Acc: 70.31
[Train] Epoch: 4 [211520/620022]    Loss: 0.009363   Batch Acc: 76.56
[Train] Epoch: 4 [211584/620022]    Loss: 0.009738   Batch Acc: 73.44
[Train] Epoch: 4 [211648/620022]    Loss: 0.007710   Batch Acc: 78.12
[Train] Epoch: 4 [211712/620022]    Loss: 0.011864   Batch Acc: 64.06
[Train] Epoch: 4 [211776/620022]    Loss: 0.009848   Batch Acc: 73.44
[Train] Epoch: 4 [211840/620022]    Loss: 0.009474   Batch Acc: 76.56
[Train] Epoch: 4 [211904/620022]    Loss: 0.009755   Batch Acc: 79.69
[Train] Epoch: 4 [211968/620022]    Loss: 0.011283   Batch Acc: 78.12
[Train] Epoch: 4 [212032/620022]    Loss: 0.009547   Batch Acc: 76.56
[Train] Epoch: 4 [212096/620022]    Loss: 0.007643   Batch Acc: 82.81
[Train] Epoch: 4 [212160/620022]    Loss: 0.011023   Batch Acc: 75.00
[Train] Epoch: 4 [212224/620022]    Loss: 0.007194   Batch Acc: 81.25
[Train] Epoch: 4 [212288/620022]    Loss: 0.009215   Batch Acc: 73.44
[Train] Epoch: 4 [212352/620022]    Loss: 0.007552   Batch Acc: 84.38
[Train] Epoch: 4 [212416/620022]    Loss: 0.008395   Batch Acc: 84.38
[Train] Epoch: 4 [212480/620022]    Loss: 0.008045   Batch Acc: 76.56
[Train] Epoch: 4 [212544/620022]    Loss: 0.009546   Batch Acc: 79.69
[Train] Epoch: 4 [212608/620022]    Loss: 0.007893   Batch Acc: 84.38
[Train] Epoch: 4 [212672/620022]    Loss: 0.008296   Batch Acc: 73.44
[Train] Epoch: 4 [212736/620022]    Loss: 0.009629   Batch Acc: 73.44
[Train] Epoch: 4 [212800/620022]    Loss: 0.007816   Batch Acc: 79.69
[Train] Epoch: 4 [212864/620022]    Loss: 0.010525   Batch Acc: 73.44
[Train] Epoch: 4 [212928/620022]    Loss: 0.009119   Batch Acc: 75.00
[Train] Epoch: 4 [212992/620022]    Loss: 0.007882   Batch Acc: 76.56
[Train] Epoch: 4 [213056/620022]    Loss: 0.008431   Batch Acc: 81.25
[Train] Epoch: 4 [213120/620022]    Loss: 0.008665   Batch Acc: 79.69
[Train] Epoch: 4 [213184/620022]    Loss: 0.009881   Batch Acc: 68.75
[Train] Epoch: 4 [213248/620022]    Loss: 0.008703   Batch Acc: 82.81
[Train] Epoch: 4 [213312/620022]    Loss: 0.007110   Batch Acc: 81.25
[Train] Epoch: 4 [213376/620022]    Loss: 0.008709   Batch Acc: 84.38
[Train] Epoch: 4 [213440/620022]    Loss: 0.007302   Batch Acc: 82.81
[Train] Epoch: 4 [213504/620022]    Loss: 0.010327   Batch Acc: 75.00
[Train] Epoch: 4 [213568/620022]    Loss: 0.012370   Batch Acc: 65.62
[Train] Epoch: 4 [213632/620022]    Loss: 0.008227   Batch Acc: 76.56
[Train] Epoch: 4 [213696/620022]    Loss: 0.008681   Batch Acc: 75.00
[Train] Epoch: 4 [213760/620022]    Loss: 0.007997   Batch Acc: 78.12
[Train] Epoch: 4 [213824/620022]    Loss: 0.007066   Batch Acc: 85.94
[Train] Epoch: 4 [213888/620022]    Loss: 0.008532   Batch Acc: 79.69
[Train] Epoch: 4 [213952/620022]    Loss: 0.008449   Batch Acc: 75.00
[Train] Epoch: 4 [214016/620022]    Loss: 0.009561   Batch Acc: 78.12
[Train] Epoch: 4 [214080/620022]    Loss: 0.009561   Batch Acc: 75.00
[Train] Epoch: 4 [214144/620022]    Loss: 0.007652   Batch Acc: 79.69
[Train] Epoch: 4 [214208/620022]    Loss: 0.008918   Batch Acc: 82.81
[Train] Epoch: 4 [214272/620022]    Loss: 0.007763   Batch Acc: 84.38
[Train] Epoch: 4 [214336/620022]    Loss: 0.006314   Batch Acc: 84.38
[Train] Epoch: 4 [214400/620022]    Loss: 0.010334   Batch Acc: 68.75
[Train] Epoch: 4 [214464/620022]    Loss: 0.006902   Batch Acc: 81.25
[Train] Epoch: 4 [214528/620022]    Loss: 0.008490   Batch Acc: 85.94
[Train] Epoch: 4 [214592/620022]    Loss: 0.008208   Batch Acc: 76.56
[Train] Epoch: 4 [214656/620022]    Loss: 0.009189   Batch Acc: 79.69
[Train] Epoch: 4 [214720/620022]    Loss: 0.008699   Batch Acc: 75.00
[Train] Epoch: 4 [214784/620022]    Loss: 0.008641   Batch Acc: 79.69
[Train] Epoch: 4 [214848/620022]    Loss: 0.007198   Batch Acc: 82.81
[Train] Epoch: 4 [214912/620022]    Loss: 0.007118   Batch Acc: 84.38
[Train] Epoch: 4 [214976/620022]    Loss: 0.007802   Batch Acc: 79.69
[Train] Epoch: 4 [215040/620022]    Loss: 0.009870   Batch Acc: 75.00
[Train] Epoch: 4 [215104/620022]    Loss: 0.009196   Batch Acc: 79.69
[Train] Epoch: 4 [215168/620022]    Loss: 0.008376   Batch Acc: 75.00
[Train] Epoch: 4 [215232/620022]    Loss: 0.005948   Batch Acc: 87.50
[Train] Epoch: 4 [215296/620022]    Loss: 0.009061   Batch Acc: 73.44
[Train] Epoch: 4 [215360/620022]    Loss: 0.009054   Batch Acc: 70.31
[Train] Epoch: 4 [215424/620022]    Loss: 0.008511   Batch Acc: 79.69
[Train] Epoch: 4 [215488/620022]    Loss: 0.008830   Batch Acc: 79.69
[Train] Epoch: 4 [215552/620022]    Loss: 0.008161   Batch Acc: 84.38
[Train] Epoch: 4 [215616/620022]    Loss: 0.010459   Batch Acc: 68.75
[Train] Epoch: 4 [215680/620022]    Loss: 0.010169   Batch Acc: 68.75
[Train] Epoch: 4 [215744/620022]    Loss: 0.008112   Batch Acc: 78.12
[Train] Epoch: 4 [215808/620022]    Loss: 0.007775   Batch Acc: 78.12
[Train] Epoch: 4 [215872/620022]    Loss: 0.009089   Batch Acc: 75.00
[Train] Epoch: 4 [215936/620022]    Loss: 0.009004   Batch Acc: 73.44
[Train] Epoch: 4 [216000/620022]    Loss: 0.007867   Batch Acc: 79.69
[Train] Epoch: 4 [216064/620022]    Loss: 0.008271   Batch Acc: 82.81
[Train] Epoch: 4 [216128/620022]    Loss: 0.009997   Batch Acc: 75.00
[Train] Epoch: 4 [216192/620022]    Loss: 0.010367   Batch Acc: 71.88
[Train] Epoch: 4 [216256/620022]    Loss: 0.011337   Batch Acc: 71.88
[Train] Epoch: 4 [216320/620022]    Loss: 0.007852   Batch Acc: 79.69
[Train] Epoch: 4 [216384/620022]    Loss: 0.010314   Batch Acc: 70.31
[Train] Epoch: 4 [216448/620022]    Loss: 0.011078   Batch Acc: 75.00
[Train] Epoch: 4 [216512/620022]    Loss: 0.010442   Batch Acc: 76.56
[Train] Epoch: 4 [216576/620022]    Loss: 0.011469   Batch Acc: 64.06
[Train] Epoch: 4 [216640/620022]    Loss: 0.007582   Batch Acc: 84.38
[Train] Epoch: 4 [216704/620022]    Loss: 0.007768   Batch Acc: 84.38
[Train] Epoch: 4 [216768/620022]    Loss: 0.008453   Batch Acc: 76.56
[Train] Epoch: 4 [216832/620022]    Loss: 0.008555   Batch Acc: 79.69
[Train] Epoch: 4 [216896/620022]    Loss: 0.007087   Batch Acc: 85.94
[Train] Epoch: 4 [216960/620022]    Loss: 0.006573   Batch Acc: 82.81
[Train] Epoch: 4 [217024/620022]    Loss: 0.007171   Batch Acc: 81.25
[Train] Epoch: 4 [217088/620022]    Loss: 0.006560   Batch Acc: 85.94
[Train] Epoch: 4 [217152/620022]    Loss: 0.009573   Batch Acc: 78.12
[Train] Epoch: 4 [217216/620022]    Loss: 0.008836   Batch Acc: 78.12
[Train] Epoch: 4 [217280/620022]    Loss: 0.009831   Batch Acc: 75.00
[Train] Epoch: 4 [217344/620022]    Loss: 0.010740   Batch Acc: 75.00
[Train] Epoch: 4 [217408/620022]    Loss: 0.007846   Batch Acc: 81.25
[Train] Epoch: 4 [217472/620022]    Loss: 0.009957   Batch Acc: 78.12
[Train] Epoch: 4 [217536/620022]    Loss: 0.008341   Batch Acc: 76.56
[Train] Epoch: 4 [217600/620022]    Loss: 0.006817   Batch Acc: 82.81
[Train] Epoch: 4 [217664/620022]    Loss: 0.008423   Batch Acc: 75.00
[Train] Epoch: 4 [217728/620022]    Loss: 0.007420   Batch Acc: 81.25
[Train] Epoch: 4 [217792/620022]    Loss: 0.007357   Batch Acc: 82.81
[Train] Epoch: 4 [217856/620022]    Loss: 0.009977   Batch Acc: 70.31
[Train] Epoch: 4 [217920/620022]    Loss: 0.007507   Batch Acc: 81.25
[Train] Epoch: 4 [217984/620022]    Loss: 0.008324   Batch Acc: 76.56
[Train] Epoch: 4 [218048/620022]    Loss: 0.008420   Batch Acc: 81.25
[Train] Epoch: 4 [218112/620022]    Loss: 0.007416   Batch Acc: 78.12
[Train] Epoch: 4 [218176/620022]    Loss: 0.008271   Batch Acc: 81.25
[Train] Epoch: 4 [218240/620022]    Loss: 0.008546   Batch Acc: 73.44
[Train] Epoch: 4 [218304/620022]    Loss: 0.009508   Batch Acc: 71.88
[Train] Epoch: 4 [218368/620022]    Loss: 0.009175   Batch Acc: 76.56
[Train] Epoch: 4 [218432/620022]    Loss: 0.007535   Batch Acc: 81.25
[Train] Epoch: 4 [218496/620022]    Loss: 0.008867   Batch Acc: 79.69
[Train] Epoch: 4 [218560/620022]    Loss: 0.006456   Batch Acc: 85.94
[Train] Epoch: 4 [218624/620022]    Loss: 0.008648   Batch Acc: 76.56
[Train] Epoch: 4 [218688/620022]    Loss: 0.008287   Batch Acc: 76.56
[Train] Epoch: 4 [218752/620022]    Loss: 0.007678   Batch Acc: 82.81
[Train] Epoch: 4 [218816/620022]    Loss: 0.009198   Batch Acc: 79.69
[Train] Epoch: 4 [218880/620022]    Loss: 0.008885   Batch Acc: 79.69
[Train] Epoch: 4 [218944/620022]    Loss: 0.008161   Batch Acc: 81.25
[Train] Epoch: 4 [219008/620022]    Loss: 0.008429   Batch Acc: 79.69
[Train] Epoch: 4 [219072/620022]    Loss: 0.008246   Batch Acc: 75.00
[Train] Epoch: 4 [219136/620022]    Loss: 0.008034   Batch Acc: 85.94
[Train] Epoch: 4 [219200/620022]    Loss: 0.010803   Batch Acc: 70.31
[Train] Epoch: 4 [219264/620022]    Loss: 0.006741   Batch Acc: 79.69
[Train] Epoch: 4 [219328/620022]    Loss: 0.006964   Batch Acc: 82.81
[Train] Epoch: 4 [219392/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 4 [219456/620022]    Loss: 0.008441   Batch Acc: 76.56
[Train] Epoch: 4 [219520/620022]    Loss: 0.010214   Batch Acc: 70.31
[Train] Epoch: 4 [219584/620022]    Loss: 0.010111   Batch Acc: 73.44
[Train] Epoch: 4 [219648/620022]    Loss: 0.008504   Batch Acc: 79.69
[Train] Epoch: 4 [219712/620022]    Loss: 0.007999   Batch Acc: 81.25
[Train] Epoch: 4 [219776/620022]    Loss: 0.008375   Batch Acc: 78.12
[Train] Epoch: 4 [219840/620022]    Loss: 0.011272   Batch Acc: 73.44
[Train] Epoch: 4 [219904/620022]    Loss: 0.009086   Batch Acc: 84.38
[Train] Epoch: 4 [219968/620022]    Loss: 0.007649   Batch Acc: 82.81
[Train] Epoch: 4 [220032/620022]    Loss: 0.008257   Batch Acc: 78.12
[Train] Epoch: 4 [220096/620022]    Loss: 0.006869   Batch Acc: 89.06
[Train] Epoch: 4 [220160/620022]    Loss: 0.009641   Batch Acc: 75.00
[Train] Epoch: 4 [220224/620022]    Loss: 0.007208   Batch Acc: 81.25
[Train] Epoch: 4 [220288/620022]    Loss: 0.008209   Batch Acc: 75.00
[Train] Epoch: 4 [220352/620022]    Loss: 0.009393   Batch Acc: 79.69
[Train] Epoch: 4 [220416/620022]    Loss: 0.009000   Batch Acc: 78.12
[Train] Epoch: 4 [220480/620022]    Loss: 0.006438   Batch Acc: 81.25
[Train] Epoch: 4 [220544/620022]    Loss: 0.008437   Batch Acc: 75.00
[Train] Epoch: 4 [220608/620022]    Loss: 0.007760   Batch Acc: 79.69
[Train] Epoch: 4 [220672/620022]    Loss: 0.008052   Batch Acc: 76.56
[Train] Epoch: 4 [220736/620022]    Loss: 0.008753   Batch Acc: 76.56
[Train] Epoch: 4 [220800/620022]    Loss: 0.009615   Batch Acc: 81.25
[Train] Epoch: 4 [220864/620022]    Loss: 0.010726   Batch Acc: 70.31
[Train] Epoch: 4 [220928/620022]    Loss: 0.009652   Batch Acc: 79.69
[Train] Epoch: 4 [220992/620022]    Loss: 0.009242   Batch Acc: 76.56
[Train] Epoch: 4 [221056/620022]    Loss: 0.006211   Batch Acc: 89.06
[Train] Epoch: 4 [221120/620022]    Loss: 0.009052   Batch Acc: 76.56
[Train] Epoch: 4 [221184/620022]    Loss: 0.006267   Batch Acc: 82.81
[Train] Epoch: 4 [221248/620022]    Loss: 0.007848   Batch Acc: 79.69
[Train] Epoch: 4 [221312/620022]    Loss: 0.007832   Batch Acc: 81.25
[Train] Epoch: 4 [221376/620022]    Loss: 0.009858   Batch Acc: 75.00
[Train] Epoch: 4 [221440/620022]    Loss: 0.007068   Batch Acc: 89.06
[Train] Epoch: 4 [221504/620022]    Loss: 0.009160   Batch Acc: 71.88
[Train] Epoch: 4 [221568/620022]    Loss: 0.007384   Batch Acc: 84.38
[Train] Epoch: 4 [221632/620022]    Loss: 0.010920   Batch Acc: 70.31
[Train] Epoch: 4 [221696/620022]    Loss: 0.011237   Batch Acc: 67.19
[Train] Epoch: 4 [221760/620022]    Loss: 0.007730   Batch Acc: 76.56
[Train] Epoch: 4 [221824/620022]    Loss: 0.010075   Batch Acc: 78.12
[Train] Epoch: 4 [221888/620022]    Loss: 0.007904   Batch Acc: 76.56
[Train] Epoch: 4 [221952/620022]    Loss: 0.007104   Batch Acc: 84.38
[Train] Epoch: 4 [222016/620022]    Loss: 0.009932   Batch Acc: 73.44
[Train] Epoch: 4 [222080/620022]    Loss: 0.007148   Batch Acc: 82.81
[Train] Epoch: 4 [222144/620022]    Loss: 0.011428   Batch Acc: 65.62
[Train] Epoch: 4 [222208/620022]    Loss: 0.007572   Batch Acc: 78.12
[Train] Epoch: 4 [222272/620022]    Loss: 0.007761   Batch Acc: 84.38
[Train] Epoch: 4 [222336/620022]    Loss: 0.008581   Batch Acc: 78.12
[Train] Epoch: 4 [222400/620022]    Loss: 0.008436   Batch Acc: 78.12
[Train] Epoch: 4 [222464/620022]    Loss: 0.007478   Batch Acc: 81.25
[Train] Epoch: 4 [222528/620022]    Loss: 0.010811   Batch Acc: 68.75
[Train] Epoch: 4 [222592/620022]    Loss: 0.009967   Batch Acc: 71.88
[Train] Epoch: 4 [222656/620022]    Loss: 0.009947   Batch Acc: 75.00
[Train] Epoch: 4 [222720/620022]    Loss: 0.008994   Batch Acc: 78.12
[Train] Epoch: 4 [222784/620022]    Loss: 0.007009   Batch Acc: 82.81
[Train] Epoch: 4 [222848/620022]    Loss: 0.006862   Batch Acc: 87.50
[Train] Epoch: 4 [222912/620022]    Loss: 0.010057   Batch Acc: 71.88
[Train] Epoch: 4 [222976/620022]    Loss: 0.008984   Batch Acc: 76.56
[Train] Epoch: 4 [223040/620022]    Loss: 0.008210   Batch Acc: 76.56
[Train] Epoch: 4 [223104/620022]    Loss: 0.008012   Batch Acc: 75.00
[Train] Epoch: 4 [223168/620022]    Loss: 0.011197   Batch Acc: 73.44
[Train] Epoch: 4 [223232/620022]    Loss: 0.007818   Batch Acc: 81.25
[Train] Epoch: 4 [223296/620022]    Loss: 0.008269   Batch Acc: 79.69
[Train] Epoch: 4 [223360/620022]    Loss: 0.009726   Batch Acc: 73.44
[Train] Epoch: 4 [223424/620022]    Loss: 0.008226   Batch Acc: 81.25
[Train] Epoch: 4 [223488/620022]    Loss: 0.010234   Batch Acc: 71.88
[Train] Epoch: 4 [223552/620022]    Loss: 0.008474   Batch Acc: 73.44
[Train] Epoch: 4 [223616/620022]    Loss: 0.011066   Batch Acc: 73.44
[Train] Epoch: 4 [223680/620022]    Loss: 0.007994   Batch Acc: 78.12
[Train] Epoch: 4 [223744/620022]    Loss: 0.005935   Batch Acc: 84.38
[Train] Epoch: 4 [223808/620022]    Loss: 0.008675   Batch Acc: 78.12
[Train] Epoch: 4 [223872/620022]    Loss: 0.006065   Batch Acc: 85.94
[Train] Epoch: 4 [223936/620022]    Loss: 0.009804   Batch Acc: 75.00
[Train] Epoch: 4 [224000/620022]    Loss: 0.008589   Batch Acc: 78.12
[Train] Epoch: 4 [224064/620022]    Loss: 0.008774   Batch Acc: 73.44
[Train] Epoch: 4 [224128/620022]    Loss: 0.007284   Batch Acc: 79.69
[Train] Epoch: 4 [224192/620022]    Loss: 0.006643   Batch Acc: 84.38
[Train] Epoch: 4 [224256/620022]    Loss: 0.007309   Batch Acc: 75.00
[Train] Epoch: 4 [224320/620022]    Loss: 0.008546   Batch Acc: 81.25
[Train] Epoch: 4 [224384/620022]    Loss: 0.008263   Batch Acc: 82.81
[Train] Epoch: 4 [224448/620022]    Loss: 0.009673   Batch Acc: 76.56
[Train] Epoch: 4 [224512/620022]    Loss: 0.007527   Batch Acc: 81.25
[Train] Epoch: 4 [224576/620022]    Loss: 0.009898   Batch Acc: 70.31
[Train] Epoch: 4 [224640/620022]    Loss: 0.007520   Batch Acc: 82.81
[Train] Epoch: 4 [224704/620022]    Loss: 0.008233   Batch Acc: 82.81
[Train] Epoch: 4 [224768/620022]    Loss: 0.009058   Batch Acc: 75.00
[Train] Epoch: 4 [224832/620022]    Loss: 0.007540   Batch Acc: 82.81
[Train] Epoch: 4 [224896/620022]    Loss: 0.008156   Batch Acc: 81.25
[Train] Epoch: 4 [224960/620022]    Loss: 0.009779   Batch Acc: 78.12
[Train] Epoch: 4 [225024/620022]    Loss: 0.006894   Batch Acc: 81.25
[Train] Epoch: 4 [225088/620022]    Loss: 0.005815   Batch Acc: 89.06
[Train] Epoch: 4 [225152/620022]    Loss: 0.007658   Batch Acc: 82.81
[Train] Epoch: 4 [225216/620022]    Loss: 0.007701   Batch Acc: 81.25
[Train] Epoch: 4 [225280/620022]    Loss: 0.007131   Batch Acc: 82.81
[Train] Epoch: 4 [225344/620022]    Loss: 0.006287   Batch Acc: 89.06
[Train] Epoch: 4 [225408/620022]    Loss: 0.008284   Batch Acc: 81.25
[Train] Epoch: 4 [225472/620022]    Loss: 0.010137   Batch Acc: 75.00
[Train] Epoch: 4 [225536/620022]    Loss: 0.007670   Batch Acc: 78.12
[Train] Epoch: 4 [225600/620022]    Loss: 0.009040   Batch Acc: 82.81
[Train] Epoch: 4 [225664/620022]    Loss: 0.006923   Batch Acc: 82.81
[Train] Epoch: 4 [225728/620022]    Loss: 0.008521   Batch Acc: 81.25
[Train] Epoch: 4 [225792/620022]    Loss: 0.007634   Batch Acc: 78.12
[Train] Epoch: 4 [225856/620022]    Loss: 0.011203   Batch Acc: 76.56
[Train] Epoch: 4 [225920/620022]    Loss: 0.007687   Batch Acc: 85.94
[Train] Epoch: 4 [225984/620022]    Loss: 0.008600   Batch Acc: 78.12
[Train] Epoch: 4 [226048/620022]    Loss: 0.013235   Batch Acc: 65.62
[Train] Epoch: 4 [226112/620022]    Loss: 0.008567   Batch Acc: 76.56
[Train] Epoch: 4 [226176/620022]    Loss: 0.008341   Batch Acc: 78.12
[Train] Epoch: 4 [226240/620022]    Loss: 0.009092   Batch Acc: 75.00
[Train] Epoch: 4 [226304/620022]    Loss: 0.009615   Batch Acc: 76.56
[Train] Epoch: 4 [226368/620022]    Loss: 0.007946   Batch Acc: 85.94
[Train] Epoch: 4 [226432/620022]    Loss: 0.008317   Batch Acc: 75.00
[Train] Epoch: 4 [226496/620022]    Loss: 0.010515   Batch Acc: 71.88
[Train] Epoch: 4 [226560/620022]    Loss: 0.008535   Batch Acc: 76.56
[Train] Epoch: 4 [226624/620022]    Loss: 0.010126   Batch Acc: 76.56
[Train] Epoch: 4 [226688/620022]    Loss: 0.006791   Batch Acc: 85.94
[Train] Epoch: 4 [226752/620022]    Loss: 0.008022   Batch Acc: 79.69
[Train] Epoch: 4 [226816/620022]    Loss: 0.009111   Batch Acc: 78.12
[Train] Epoch: 4 [226880/620022]    Loss: 0.007168   Batch Acc: 79.69
[Train] Epoch: 4 [226944/620022]    Loss: 0.007979   Batch Acc: 78.12
[Train] Epoch: 4 [227008/620022]    Loss: 0.007717   Batch Acc: 87.50
[Train] Epoch: 4 [227072/620022]    Loss: 0.008414   Batch Acc: 78.12
[Train] Epoch: 4 [227136/620022]    Loss: 0.007886   Batch Acc: 82.81
[Train] Epoch: 4 [227200/620022]    Loss: 0.008071   Batch Acc: 71.88
[Train] Epoch: 4 [227264/620022]    Loss: 0.008561   Batch Acc: 75.00
[Train] Epoch: 4 [227328/620022]    Loss: 0.007058   Batch Acc: 87.50
[Train] Epoch: 4 [227392/620022]    Loss: 0.008162   Batch Acc: 78.12
[Train] Epoch: 4 [227456/620022]    Loss: 0.010334   Batch Acc: 68.75
[Train] Epoch: 4 [227520/620022]    Loss: 0.008537   Batch Acc: 73.44
[Train] Epoch: 4 [227584/620022]    Loss: 0.008695   Batch Acc: 76.56
[Train] Epoch: 4 [227648/620022]    Loss: 0.009743   Batch Acc: 67.19
[Train] Epoch: 4 [227712/620022]    Loss: 0.006782   Batch Acc: 85.94
[Train] Epoch: 4 [227776/620022]    Loss: 0.012208   Batch Acc: 70.31
[Train] Epoch: 4 [227840/620022]    Loss: 0.009563   Batch Acc: 76.56
[Train] Epoch: 4 [227904/620022]    Loss: 0.007282   Batch Acc: 84.38
[Train] Epoch: 4 [227968/620022]    Loss: 0.006970   Batch Acc: 79.69
[Train] Epoch: 4 [228032/620022]    Loss: 0.009811   Batch Acc: 78.12
[Train] Epoch: 4 [228096/620022]    Loss: 0.009715   Batch Acc: 71.88
[Train] Epoch: 4 [228160/620022]    Loss: 0.007775   Batch Acc: 79.69
[Train] Epoch: 4 [228224/620022]    Loss: 0.010093   Batch Acc: 68.75
[Train] Epoch: 4 [228288/620022]    Loss: 0.008921   Batch Acc: 79.69
[Train] Epoch: 4 [228352/620022]    Loss: 0.007883   Batch Acc: 82.81
[Train] Epoch: 4 [228416/620022]    Loss: 0.010535   Batch Acc: 71.88
[Train] Epoch: 4 [228480/620022]    Loss: 0.010803   Batch Acc: 65.62
[Train] Epoch: 4 [228544/620022]    Loss: 0.008626   Batch Acc: 76.56
[Train] Epoch: 4 [228608/620022]    Loss: 0.007580   Batch Acc: 78.12
[Train] Epoch: 4 [228672/620022]    Loss: 0.007098   Batch Acc: 89.06
[Train] Epoch: 4 [228736/620022]    Loss: 0.010274   Batch Acc: 71.88
[Train] Epoch: 4 [228800/620022]    Loss: 0.008823   Batch Acc: 76.56
[Train] Epoch: 4 [228864/620022]    Loss: 0.010109   Batch Acc: 75.00
[Train] Epoch: 4 [228928/620022]    Loss: 0.007888   Batch Acc: 75.00
[Train] Epoch: 4 [228992/620022]    Loss: 0.008404   Batch Acc: 82.81
[Train] Epoch: 4 [229056/620022]    Loss: 0.009333   Batch Acc: 76.56
[Train] Epoch: 4 [229120/620022]    Loss: 0.010116   Batch Acc: 73.44
[Train] Epoch: 4 [229184/620022]    Loss: 0.009484   Batch Acc: 78.12
[Train] Epoch: 4 [229248/620022]    Loss: 0.007351   Batch Acc: 84.38
[Train] Epoch: 4 [229312/620022]    Loss: 0.010071   Batch Acc: 70.31
[Train] Epoch: 4 [229376/620022]    Loss: 0.008067   Batch Acc: 79.69
[Train] Epoch: 4 [229440/620022]    Loss: 0.009765   Batch Acc: 70.31
[Train] Epoch: 4 [229504/620022]    Loss: 0.009230   Batch Acc: 76.56
[Train] Epoch: 4 [229568/620022]    Loss: 0.007482   Batch Acc: 81.25
[Train] Epoch: 4 [229632/620022]    Loss: 0.009832   Batch Acc: 68.75
[Train] Epoch: 4 [229696/620022]    Loss: 0.008063   Batch Acc: 81.25
[Train] Epoch: 4 [229760/620022]    Loss: 0.008944   Batch Acc: 76.56
[Train] Epoch: 4 [229824/620022]    Loss: 0.006702   Batch Acc: 79.69
[Train] Epoch: 4 [229888/620022]    Loss: 0.009009   Batch Acc: 78.12
[Train] Epoch: 4 [229952/620022]    Loss: 0.008681   Batch Acc: 73.44
[Train] Epoch: 4 [230016/620022]    Loss: 0.007865   Batch Acc: 79.69
[Train] Epoch: 4 [230080/620022]    Loss: 0.007057   Batch Acc: 85.94
[Train] Epoch: 4 [230144/620022]    Loss: 0.009482   Batch Acc: 81.25
[Train] Epoch: 4 [230208/620022]    Loss: 0.008602   Batch Acc: 76.56
[Train] Epoch: 4 [230272/620022]    Loss: 0.011657   Batch Acc: 65.62
[Train] Epoch: 4 [230336/620022]    Loss: 0.008353   Batch Acc: 84.38
[Train] Epoch: 4 [230400/620022]    Loss: 0.009730   Batch Acc: 76.56
[Train] Epoch: 4 [230464/620022]    Loss: 0.007320   Batch Acc: 82.81
[Train] Epoch: 4 [230528/620022]    Loss: 0.007159   Batch Acc: 82.81
[Train] Epoch: 4 [230592/620022]    Loss: 0.007737   Batch Acc: 79.69
[Train] Epoch: 4 [230656/620022]    Loss: 0.009546   Batch Acc: 73.44
[Train] Epoch: 4 [230720/620022]    Loss: 0.008687   Batch Acc: 76.56
[Train] Epoch: 4 [230784/620022]    Loss: 0.009294   Batch Acc: 75.00
[Train] Epoch: 4 [230848/620022]    Loss: 0.008247   Batch Acc: 81.25
[Train] Epoch: 4 [230912/620022]    Loss: 0.009184   Batch Acc: 73.44
[Train] Epoch: 4 [230976/620022]    Loss: 0.010055   Batch Acc: 68.75
[Train] Epoch: 4 [231040/620022]    Loss: 0.009077   Batch Acc: 76.56
[Train] Epoch: 4 [231104/620022]    Loss: 0.008356   Batch Acc: 78.12
[Train] Epoch: 4 [231168/620022]    Loss: 0.008481   Batch Acc: 76.56
[Train] Epoch: 4 [231232/620022]    Loss: 0.008034   Batch Acc: 81.25
[Train] Epoch: 4 [231296/620022]    Loss: 0.009544   Batch Acc: 78.12
[Train] Epoch: 4 [231360/620022]    Loss: 0.008490   Batch Acc: 81.25
[Train] Epoch: 4 [231424/620022]    Loss: 0.007712   Batch Acc: 79.69
[Train] Epoch: 4 [231488/620022]    Loss: 0.007296   Batch Acc: 85.94
[Train] Epoch: 4 [231552/620022]    Loss: 0.009107   Batch Acc: 76.56
[Train] Epoch: 4 [231616/620022]    Loss: 0.011147   Batch Acc: 78.12
[Train] Epoch: 4 [231680/620022]    Loss: 0.008058   Batch Acc: 79.69
[Train] Epoch: 4 [231744/620022]    Loss: 0.009660   Batch Acc: 76.56
[Train] Epoch: 4 [231808/620022]    Loss: 0.011168   Batch Acc: 73.44
[Train] Epoch: 4 [231872/620022]    Loss: 0.006690   Batch Acc: 84.38
[Train] Epoch: 4 [231936/620022]    Loss: 0.006001   Batch Acc: 84.38
[Train] Epoch: 4 [232000/620022]    Loss: 0.008316   Batch Acc: 85.94
[Train] Epoch: 4 [232064/620022]    Loss: 0.008150   Batch Acc: 78.12
[Train] Epoch: 4 [232128/620022]    Loss: 0.008576   Batch Acc: 76.56
[Train] Epoch: 4 [232192/620022]    Loss: 0.009148   Batch Acc: 78.12
[Train] Epoch: 4 [232256/620022]    Loss: 0.008654   Batch Acc: 81.25
[Train] Epoch: 4 [232320/620022]    Loss: 0.005620   Batch Acc: 87.50
[Train] Epoch: 4 [232384/620022]    Loss: 0.007763   Batch Acc: 82.81
[Train] Epoch: 4 [232448/620022]    Loss: 0.009504   Batch Acc: 81.25
[Train] Epoch: 4 [232512/620022]    Loss: 0.010440   Batch Acc: 78.12
[Train] Epoch: 4 [232576/620022]    Loss: 0.008145   Batch Acc: 79.69
[Train] Epoch: 4 [232640/620022]    Loss: 0.010188   Batch Acc: 67.19
[Train] Epoch: 4 [232704/620022]    Loss: 0.006683   Batch Acc: 82.81
[Train] Epoch: 4 [232768/620022]    Loss: 0.008397   Batch Acc: 78.12
[Train] Epoch: 4 [232832/620022]    Loss: 0.007667   Batch Acc: 81.25
[Train] Epoch: 4 [232896/620022]    Loss: 0.010518   Batch Acc: 65.62
[Train] Epoch: 4 [232960/620022]    Loss: 0.006973   Batch Acc: 81.25
[Train] Epoch: 4 [233024/620022]    Loss: 0.007597   Batch Acc: 82.81
[Train] Epoch: 4 [233088/620022]    Loss: 0.008998   Batch Acc: 76.56
[Train] Epoch: 4 [233152/620022]    Loss: 0.007989   Batch Acc: 73.44
[Train] Epoch: 4 [233216/620022]    Loss: 0.006924   Batch Acc: 84.38
[Train] Epoch: 4 [233280/620022]    Loss: 0.009723   Batch Acc: 73.44
[Train] Epoch: 4 [233344/620022]    Loss: 0.006937   Batch Acc: 85.94
[Train] Epoch: 4 [233408/620022]    Loss: 0.009042   Batch Acc: 76.56
[Train] Epoch: 4 [233472/620022]    Loss: 0.008870   Batch Acc: 76.56
[Train] Epoch: 4 [233536/620022]    Loss: 0.008364   Batch Acc: 81.25
[Train] Epoch: 4 [233600/620022]    Loss: 0.009457   Batch Acc: 71.88
[Train] Epoch: 4 [233664/620022]    Loss: 0.010584   Batch Acc: 75.00
[Train] Epoch: 4 [233728/620022]    Loss: 0.009476   Batch Acc: 81.25
[Train] Epoch: 4 [233792/620022]    Loss: 0.006672   Batch Acc: 82.81
[Train] Epoch: 4 [233856/620022]    Loss: 0.010878   Batch Acc: 71.88
[Train] Epoch: 4 [233920/620022]    Loss: 0.008806   Batch Acc: 81.25
[Train] Epoch: 4 [233984/620022]    Loss: 0.009726   Batch Acc: 71.88
[Train] Epoch: 4 [234048/620022]    Loss: 0.009410   Batch Acc: 79.69
[Train] Epoch: 4 [234112/620022]    Loss: 0.010903   Batch Acc: 76.56
[Train] Epoch: 4 [234176/620022]    Loss: 0.007369   Batch Acc: 84.38
[Train] Epoch: 4 [234240/620022]    Loss: 0.007274   Batch Acc: 84.38
[Train] Epoch: 4 [234304/620022]    Loss: 0.007042   Batch Acc: 85.94
[Train] Epoch: 4 [234368/620022]    Loss: 0.006956   Batch Acc: 84.38
[Train] Epoch: 4 [234432/620022]    Loss: 0.011455   Batch Acc: 65.62
[Train] Epoch: 4 [234496/620022]    Loss: 0.006932   Batch Acc: 84.38
[Train] Epoch: 4 [234560/620022]    Loss: 0.008563   Batch Acc: 75.00
[Train] Epoch: 4 [234624/620022]    Loss: 0.009796   Batch Acc: 78.12
[Train] Epoch: 4 [234688/620022]    Loss: 0.008379   Batch Acc: 81.25
[Train] Epoch: 4 [234752/620022]    Loss: 0.009422   Batch Acc: 76.56
[Train] Epoch: 4 [234816/620022]    Loss: 0.008835   Batch Acc: 76.56
[Train] Epoch: 4 [234880/620022]    Loss: 0.007876   Batch Acc: 76.56
[Train] Epoch: 4 [234944/620022]    Loss: 0.010782   Batch Acc: 76.56
[Train] Epoch: 4 [235008/620022]    Loss: 0.008491   Batch Acc: 78.12
[Train] Epoch: 4 [235072/620022]    Loss: 0.008365   Batch Acc: 81.25
[Train] Epoch: 4 [235136/620022]    Loss: 0.010101   Batch Acc: 71.88
[Train] Epoch: 4 [235200/620022]    Loss: 0.009253   Batch Acc: 68.75
[Train] Epoch: 4 [235264/620022]    Loss: 0.007573   Batch Acc: 82.81
[Train] Epoch: 4 [235328/620022]    Loss: 0.008902   Batch Acc: 81.25
[Train] Epoch: 4 [235392/620022]    Loss: 0.008146   Batch Acc: 79.69
[Train] Epoch: 4 [235456/620022]    Loss: 0.011142   Batch Acc: 64.06
[Train] Epoch: 4 [235520/620022]    Loss: 0.011084   Batch Acc: 68.75
[Train] Epoch: 4 [235584/620022]    Loss: 0.007641   Batch Acc: 81.25
[Train] Epoch: 4 [235648/620022]    Loss: 0.009882   Batch Acc: 76.56
[Train] Epoch: 4 [235712/620022]    Loss: 0.008390   Batch Acc: 82.81
[Train] Epoch: 4 [235776/620022]    Loss: 0.007865   Batch Acc: 79.69
[Train] Epoch: 4 [235840/620022]    Loss: 0.008527   Batch Acc: 76.56
[Train] Epoch: 4 [235904/620022]    Loss: 0.007662   Batch Acc: 82.81
[Train] Epoch: 4 [235968/620022]    Loss: 0.009843   Batch Acc: 75.00
[Train] Epoch: 4 [236032/620022]    Loss: 0.008957   Batch Acc: 73.44
[Train] Epoch: 4 [236096/620022]    Loss: 0.008764   Batch Acc: 73.44
[Train] Epoch: 4 [236160/620022]    Loss: 0.007106   Batch Acc: 84.38
[Train] Epoch: 4 [236224/620022]    Loss: 0.007555   Batch Acc: 79.69
[Train] Epoch: 4 [236288/620022]    Loss: 0.008263   Batch Acc: 79.69
[Train] Epoch: 4 [236352/620022]    Loss: 0.010292   Batch Acc: 71.88
[Train] Epoch: 4 [236416/620022]    Loss: 0.008907   Batch Acc: 75.00
[Train] Epoch: 4 [236480/620022]    Loss: 0.009793   Batch Acc: 76.56
[Train] Epoch: 4 [236544/620022]    Loss: 0.009302   Batch Acc: 78.12
[Train] Epoch: 4 [236608/620022]    Loss: 0.006816   Batch Acc: 84.38
[Train] Epoch: 4 [236672/620022]    Loss: 0.006553   Batch Acc: 82.81
[Train] Epoch: 4 [236736/620022]    Loss: 0.007329   Batch Acc: 85.94
[Train] Epoch: 4 [236800/620022]    Loss: 0.008836   Batch Acc: 81.25
[Train] Epoch: 4 [236864/620022]    Loss: 0.007621   Batch Acc: 81.25
[Train] Epoch: 4 [236928/620022]    Loss: 0.007856   Batch Acc: 78.12
[Train] Epoch: 4 [236992/620022]    Loss: 0.007208   Batch Acc: 78.12
[Train] Epoch: 4 [237056/620022]    Loss: 0.007531   Batch Acc: 81.25
[Train] Epoch: 4 [237120/620022]    Loss: 0.007917   Batch Acc: 79.69
[Train] Epoch: 4 [237184/620022]    Loss: 0.008467   Batch Acc: 75.00
[Train] Epoch: 4 [237248/620022]    Loss: 0.008068   Batch Acc: 81.25
[Train] Epoch: 4 [237312/620022]    Loss: 0.008243   Batch Acc: 79.69
[Train] Epoch: 4 [237376/620022]    Loss: 0.008996   Batch Acc: 71.88
[Train] Epoch: 4 [237440/620022]    Loss: 0.007528   Batch Acc: 84.38
[Train] Epoch: 4 [237504/620022]    Loss: 0.008795   Batch Acc: 81.25
[Train] Epoch: 4 [237568/620022]    Loss: 0.009679   Batch Acc: 76.56
[Train] Epoch: 4 [237632/620022]    Loss: 0.009080   Batch Acc: 71.88
[Train] Epoch: 4 [237696/620022]    Loss: 0.011627   Batch Acc: 73.44
[Train] Epoch: 4 [237760/620022]    Loss: 0.008755   Batch Acc: 78.12
[Train] Epoch: 4 [237824/620022]    Loss: 0.009453   Batch Acc: 78.12
[Train] Epoch: 4 [237888/620022]    Loss: 0.008722   Batch Acc: 78.12
[Train] Epoch: 4 [237952/620022]    Loss: 0.008344   Batch Acc: 75.00
[Train] Epoch: 4 [238016/620022]    Loss: 0.008835   Batch Acc: 76.56
[Train] Epoch: 4 [238080/620022]    Loss: 0.009598   Batch Acc: 78.12
[Train] Epoch: 4 [238144/620022]    Loss: 0.010333   Batch Acc: 70.31
[Train] Epoch: 4 [238208/620022]    Loss: 0.007551   Batch Acc: 82.81
[Train] Epoch: 4 [238272/620022]    Loss: 0.010384   Batch Acc: 75.00
[Train] Epoch: 4 [238336/620022]    Loss: 0.008305   Batch Acc: 82.81
[Train] Epoch: 4 [238400/620022]    Loss: 0.009145   Batch Acc: 76.56
[Train] Epoch: 4 [238464/620022]    Loss: 0.010545   Batch Acc: 76.56
[Train] Epoch: 4 [238528/620022]    Loss: 0.009036   Batch Acc: 78.12
[Train] Epoch: 4 [238592/620022]    Loss: 0.009061   Batch Acc: 73.44
[Train] Epoch: 4 [238656/620022]    Loss: 0.007030   Batch Acc: 82.81
[Train] Epoch: 4 [238720/620022]    Loss: 0.010689   Batch Acc: 73.44
[Train] Epoch: 4 [238784/620022]    Loss: 0.006245   Batch Acc: 85.94
[Train] Epoch: 4 [238848/620022]    Loss: 0.009342   Batch Acc: 82.81
[Train] Epoch: 4 [238912/620022]    Loss: 0.009640   Batch Acc: 73.44
[Train] Epoch: 4 [238976/620022]    Loss: 0.011405   Batch Acc: 65.62
[Train] Epoch: 4 [239040/620022]    Loss: 0.008972   Batch Acc: 81.25
[Train] Epoch: 4 [239104/620022]    Loss: 0.007694   Batch Acc: 82.81
[Train] Epoch: 4 [239168/620022]    Loss: 0.006726   Batch Acc: 87.50
[Train] Epoch: 4 [239232/620022]    Loss: 0.009757   Batch Acc: 79.69
[Train] Epoch: 4 [239296/620022]    Loss: 0.008068   Batch Acc: 79.69
[Train] Epoch: 4 [239360/620022]    Loss: 0.010856   Batch Acc: 68.75
[Train] Epoch: 4 [239424/620022]    Loss: 0.009970   Batch Acc: 76.56
[Train] Epoch: 4 [239488/620022]    Loss: 0.010230   Batch Acc: 75.00
[Train] Epoch: 4 [239552/620022]    Loss: 0.010353   Batch Acc: 67.19
[Train] Epoch: 4 [239616/620022]    Loss: 0.007725   Batch Acc: 79.69
[Train] Epoch: 4 [239680/620022]    Loss: 0.008038   Batch Acc: 82.81
[Train] Epoch: 4 [239744/620022]    Loss: 0.006090   Batch Acc: 84.38
[Train] Epoch: 4 [239808/620022]    Loss: 0.010008   Batch Acc: 81.25
[Train] Epoch: 4 [239872/620022]    Loss: 0.009110   Batch Acc: 75.00
[Train] Epoch: 4 [239936/620022]    Loss: 0.009409   Batch Acc: 75.00
[Train] Epoch: 4 [240000/620022]    Loss: 0.009524   Batch Acc: 73.44
[Train] Epoch: 4 [240064/620022]    Loss: 0.009608   Batch Acc: 76.56
[Train] Epoch: 4 [240128/620022]    Loss: 0.010219   Batch Acc: 76.56
[Train] Epoch: 4 [240192/620022]    Loss: 0.007897   Batch Acc: 82.81
[Train] Epoch: 4 [240256/620022]    Loss: 0.007617   Batch Acc: 76.56
[Train] Epoch: 4 [240320/620022]    Loss: 0.010054   Batch Acc: 62.50
[Train] Epoch: 4 [240384/620022]    Loss: 0.011605   Batch Acc: 71.88
[Train] Epoch: 4 [240448/620022]    Loss: 0.007152   Batch Acc: 84.38
[Train] Epoch: 4 [240512/620022]    Loss: 0.010707   Batch Acc: 78.12
[Train] Epoch: 4 [240576/620022]    Loss: 0.009462   Batch Acc: 76.56
[Train] Epoch: 4 [240640/620022]    Loss: 0.006698   Batch Acc: 82.81
[Train] Epoch: 4 [240704/620022]    Loss: 0.009797   Batch Acc: 73.44
[Train] Epoch: 4 [240768/620022]    Loss: 0.011263   Batch Acc: 67.19
[Train] Epoch: 4 [240832/620022]    Loss: 0.006024   Batch Acc: 82.81
[Train] Epoch: 4 [240896/620022]    Loss: 0.009394   Batch Acc: 75.00
[Train] Epoch: 4 [240960/620022]    Loss: 0.007744   Batch Acc: 81.25
[Train] Epoch: 4 [241024/620022]    Loss: 0.010886   Batch Acc: 70.31
[Train] Epoch: 4 [241088/620022]    Loss: 0.009580   Batch Acc: 75.00
[Train] Epoch: 4 [241152/620022]    Loss: 0.007748   Batch Acc: 75.00
[Train] Epoch: 4 [241216/620022]    Loss: 0.011684   Batch Acc: 68.75
[Train] Epoch: 4 [241280/620022]    Loss: 0.007986   Batch Acc: 78.12
[Train] Epoch: 4 [241344/620022]    Loss: 0.011567   Batch Acc: 62.50
[Train] Epoch: 4 [241408/620022]    Loss: 0.010317   Batch Acc: 67.19
[Train] Epoch: 4 [241472/620022]    Loss: 0.007818   Batch Acc: 78.12
[Train] Epoch: 4 [241536/620022]    Loss: 0.007388   Batch Acc: 84.38
[Train] Epoch: 4 [241600/620022]    Loss: 0.009400   Batch Acc: 71.88
[Train] Epoch: 4 [241664/620022]    Loss: 0.005476   Batch Acc: 90.62
[Train] Epoch: 4 [241728/620022]    Loss: 0.008390   Batch Acc: 82.81
[Train] Epoch: 4 [241792/620022]    Loss: 0.008272   Batch Acc: 79.69
[Train] Epoch: 4 [241856/620022]    Loss: 0.010495   Batch Acc: 75.00
[Train] Epoch: 4 [241920/620022]    Loss: 0.009745   Batch Acc: 71.88
[Train] Epoch: 4 [241984/620022]    Loss: 0.009324   Batch Acc: 76.56
[Train] Epoch: 4 [242048/620022]    Loss: 0.008959   Batch Acc: 71.88
[Train] Epoch: 4 [242112/620022]    Loss: 0.008011   Batch Acc: 79.69
[Train] Epoch: 4 [242176/620022]    Loss: 0.010278   Batch Acc: 76.56
[Train] Epoch: 4 [242240/620022]    Loss: 0.011249   Batch Acc: 75.00
[Train] Epoch: 4 [242304/620022]    Loss: 0.010762   Batch Acc: 70.31
[Train] Epoch: 4 [242368/620022]    Loss: 0.008522   Batch Acc: 76.56
[Train] Epoch: 4 [242432/620022]    Loss: 0.006431   Batch Acc: 84.38
[Train] Epoch: 4 [242496/620022]    Loss: 0.007600   Batch Acc: 82.81
[Train] Epoch: 4 [242560/620022]    Loss: 0.009114   Batch Acc: 73.44
[Train] Epoch: 4 [242624/620022]    Loss: 0.007207   Batch Acc: 82.81
[Train] Epoch: 4 [242688/620022]    Loss: 0.009312   Batch Acc: 75.00
[Train] Epoch: 4 [242752/620022]    Loss: 0.010060   Batch Acc: 78.12
[Train] Epoch: 4 [242816/620022]    Loss: 0.007309   Batch Acc: 85.94
[Train] Epoch: 4 [242880/620022]    Loss: 0.007204   Batch Acc: 90.62
[Train] Epoch: 4 [242944/620022]    Loss: 0.009345   Batch Acc: 78.12
[Train] Epoch: 4 [243008/620022]    Loss: 0.008423   Batch Acc: 78.12
[Train] Epoch: 4 [243072/620022]    Loss: 0.008511   Batch Acc: 82.81
[Train] Epoch: 4 [243136/620022]    Loss: 0.006275   Batch Acc: 82.81
[Train] Epoch: 4 [243200/620022]    Loss: 0.007795   Batch Acc: 84.38
[Train] Epoch: 4 [243264/620022]    Loss: 0.008147   Batch Acc: 79.69
[Train] Epoch: 4 [243328/620022]    Loss: 0.009092   Batch Acc: 81.25
[Train] Epoch: 4 [243392/620022]    Loss: 0.007419   Batch Acc: 82.81
[Train] Epoch: 4 [243456/620022]    Loss: 0.007661   Batch Acc: 78.12
[Train] Epoch: 4 [243520/620022]    Loss: 0.008462   Batch Acc: 79.69
[Train] Epoch: 4 [243584/620022]    Loss: 0.009441   Batch Acc: 75.00
[Train] Epoch: 4 [243648/620022]    Loss: 0.009523   Batch Acc: 75.00
[Train] Epoch: 4 [243712/620022]    Loss: 0.005141   Batch Acc: 90.62
[Train] Epoch: 4 [243776/620022]    Loss: 0.007631   Batch Acc: 79.69
[Train] Epoch: 4 [243840/620022]    Loss: 0.008824   Batch Acc: 76.56
[Train] Epoch: 4 [243904/620022]    Loss: 0.009968   Batch Acc: 73.44
[Train] Epoch: 4 [243968/620022]    Loss: 0.008657   Batch Acc: 78.12
[Train] Epoch: 4 [244032/620022]    Loss: 0.008519   Batch Acc: 75.00
[Train] Epoch: 4 [244096/620022]    Loss: 0.009704   Batch Acc: 73.44
[Train] Epoch: 4 [244160/620022]    Loss: 0.008606   Batch Acc: 75.00
[Train] Epoch: 4 [244224/620022]    Loss: 0.007994   Batch Acc: 76.56
[Train] Epoch: 4 [244288/620022]    Loss: 0.008468   Batch Acc: 81.25
[Train] Epoch: 4 [244352/620022]    Loss: 0.005913   Batch Acc: 85.94
[Train] Epoch: 4 [244416/620022]    Loss: 0.011213   Batch Acc: 70.31
[Train] Epoch: 4 [244480/620022]    Loss: 0.009484   Batch Acc: 73.44
[Train] Epoch: 4 [244544/620022]    Loss: 0.005459   Batch Acc: 92.19
[Train] Epoch: 4 [244608/620022]    Loss: 0.009895   Batch Acc: 68.75
[Train] Epoch: 4 [244672/620022]    Loss: 0.006696   Batch Acc: 87.50
[Train] Epoch: 4 [244736/620022]    Loss: 0.008920   Batch Acc: 75.00
[Train] Epoch: 4 [244800/620022]    Loss: 0.010390   Batch Acc: 75.00
[Train] Epoch: 4 [244864/620022]    Loss: 0.007480   Batch Acc: 82.81
[Train] Epoch: 4 [244928/620022]    Loss: 0.008486   Batch Acc: 79.69
[Train] Epoch: 4 [244992/620022]    Loss: 0.007508   Batch Acc: 85.94
[Train] Epoch: 4 [245056/620022]    Loss: 0.006685   Batch Acc: 84.38
[Train] Epoch: 4 [245120/620022]    Loss: 0.009502   Batch Acc: 76.56
[Train] Epoch: 4 [245184/620022]    Loss: 0.007672   Batch Acc: 81.25
[Train] Epoch: 4 [245248/620022]    Loss: 0.009238   Batch Acc: 75.00
[Train] Epoch: 4 [245312/620022]    Loss: 0.008187   Batch Acc: 78.12
[Train] Epoch: 4 [245376/620022]    Loss: 0.007534   Batch Acc: 81.25
[Train] Epoch: 4 [245440/620022]    Loss: 0.008791   Batch Acc: 78.12
[Train] Epoch: 4 [245504/620022]    Loss: 0.009516   Batch Acc: 75.00
[Train] Epoch: 4 [245568/620022]    Loss: 0.008592   Batch Acc: 76.56
[Train] Epoch: 4 [245632/620022]    Loss: 0.008646   Batch Acc: 76.56
[Train] Epoch: 4 [245696/620022]    Loss: 0.009197   Batch Acc: 76.56
[Train] Epoch: 4 [245760/620022]    Loss: 0.006002   Batch Acc: 87.50
[Train] Epoch: 4 [245824/620022]    Loss: 0.008542   Batch Acc: 87.50
[Train] Epoch: 4 [245888/620022]    Loss: 0.008480   Batch Acc: 71.88
[Train] Epoch: 4 [245952/620022]    Loss: 0.009060   Batch Acc: 73.44
[Train] Epoch: 4 [246016/620022]    Loss: 0.007547   Batch Acc: 79.69
[Train] Epoch: 4 [246080/620022]    Loss: 0.008409   Batch Acc: 76.56
[Train] Epoch: 4 [246144/620022]    Loss: 0.011527   Batch Acc: 62.50
[Train] Epoch: 4 [246208/620022]    Loss: 0.008713   Batch Acc: 82.81
[Train] Epoch: 4 [246272/620022]    Loss: 0.006359   Batch Acc: 84.38
[Train] Epoch: 4 [246336/620022]    Loss: 0.008594   Batch Acc: 73.44
[Train] Epoch: 4 [246400/620022]    Loss: 0.011043   Batch Acc: 64.06
[Train] Epoch: 4 [246464/620022]    Loss: 0.009247   Batch Acc: 73.44
[Train] Epoch: 4 [246528/620022]    Loss: 0.009932   Batch Acc: 81.25
[Train] Epoch: 4 [246592/620022]    Loss: 0.008431   Batch Acc: 75.00
[Train] Epoch: 4 [246656/620022]    Loss: 0.007904   Batch Acc: 78.12
[Train] Epoch: 4 [246720/620022]    Loss: 0.009860   Batch Acc: 75.00
[Train] Epoch: 4 [246784/620022]    Loss: 0.006560   Batch Acc: 81.25
[Train] Epoch: 4 [246848/620022]    Loss: 0.008584   Batch Acc: 76.56
[Train] Epoch: 4 [246912/620022]    Loss: 0.007401   Batch Acc: 78.12
[Train] Epoch: 4 [246976/620022]    Loss: 0.010208   Batch Acc: 65.62
[Train] Epoch: 4 [247040/620022]    Loss: 0.009119   Batch Acc: 79.69
[Train] Epoch: 4 [247104/620022]    Loss: 0.008532   Batch Acc: 81.25
[Train] Epoch: 4 [247168/620022]    Loss: 0.008944   Batch Acc: 76.56
[Train] Epoch: 4 [247232/620022]    Loss: 0.009007   Batch Acc: 75.00
[Train] Epoch: 4 [247296/620022]    Loss: 0.010567   Batch Acc: 68.75
[Train] Epoch: 4 [247360/620022]    Loss: 0.008680   Batch Acc: 81.25
[Train] Epoch: 4 [247424/620022]    Loss: 0.006558   Batch Acc: 85.94
[Train] Epoch: 4 [247488/620022]    Loss: 0.006715   Batch Acc: 81.25
[Train] Epoch: 4 [247552/620022]    Loss: 0.007810   Batch Acc: 76.56
[Train] Epoch: 4 [247616/620022]    Loss: 0.010132   Batch Acc: 71.88
[Train] Epoch: 4 [247680/620022]    Loss: 0.011415   Batch Acc: 68.75
[Train] Epoch: 4 [247744/620022]    Loss: 0.009282   Batch Acc: 75.00
[Train] Epoch: 4 [247808/620022]    Loss: 0.009614   Batch Acc: 73.44
[Train] Epoch: 4 [247872/620022]    Loss: 0.009606   Batch Acc: 78.12
[Train] Epoch: 4 [247936/620022]    Loss: 0.007967   Batch Acc: 85.94
[Train] Epoch: 4 [248000/620022]    Loss: 0.010388   Batch Acc: 73.44
[Train] Epoch: 4 [248064/620022]    Loss: 0.007989   Batch Acc: 76.56
[Train] Epoch: 4 [248128/620022]    Loss: 0.006985   Batch Acc: 82.81
[Train] Epoch: 4 [248192/620022]    Loss: 0.008672   Batch Acc: 78.12
[Train] Epoch: 4 [248256/620022]    Loss: 0.006441   Batch Acc: 84.38
[Train] Epoch: 4 [248320/620022]    Loss: 0.007997   Batch Acc: 78.12
[Train] Epoch: 4 [248384/620022]    Loss: 0.011418   Batch Acc: 73.44
[Train] Epoch: 4 [248448/620022]    Loss: 0.008867   Batch Acc: 82.81
[Train] Epoch: 4 [248512/620022]    Loss: 0.007952   Batch Acc: 78.12
[Train] Epoch: 4 [248576/620022]    Loss: 0.009871   Batch Acc: 70.31
[Train] Epoch: 4 [248640/620022]    Loss: 0.007450   Batch Acc: 84.38
[Train] Epoch: 4 [248704/620022]    Loss: 0.007262   Batch Acc: 82.81
[Train] Epoch: 4 [248768/620022]    Loss: 0.009446   Batch Acc: 78.12
[Train] Epoch: 4 [248832/620022]    Loss: 0.006565   Batch Acc: 82.81
[Train] Epoch: 4 [248896/620022]    Loss: 0.010053   Batch Acc: 68.75
[Train] Epoch: 4 [248960/620022]    Loss: 0.007340   Batch Acc: 79.69
[Train] Epoch: 4 [249024/620022]    Loss: 0.008920   Batch Acc: 82.81
[Train] Epoch: 4 [249088/620022]    Loss: 0.008185   Batch Acc: 78.12
[Train] Epoch: 4 [249152/620022]    Loss: 0.007560   Batch Acc: 82.81
[Train] Epoch: 4 [249216/620022]    Loss: 0.009891   Batch Acc: 73.44
[Train] Epoch: 4 [249280/620022]    Loss: 0.011771   Batch Acc: 62.50
[Train] Epoch: 4 [249344/620022]    Loss: 0.009489   Batch Acc: 76.56
[Train] Epoch: 4 [249408/620022]    Loss: 0.010548   Batch Acc: 73.44
[Train] Epoch: 4 [249472/620022]    Loss: 0.006299   Batch Acc: 87.50
[Train] Epoch: 4 [249536/620022]    Loss: 0.010381   Batch Acc: 73.44
[Train] Epoch: 4 [249600/620022]    Loss: 0.009330   Batch Acc: 75.00
[Train] Epoch: 4 [249664/620022]    Loss: 0.010456   Batch Acc: 71.88
[Train] Epoch: 4 [249728/620022]    Loss: 0.008614   Batch Acc: 79.69
[Train] Epoch: 4 [249792/620022]    Loss: 0.008085   Batch Acc: 81.25
[Train] Epoch: 4 [249856/620022]    Loss: 0.009237   Batch Acc: 81.25
[Train] Epoch: 4 [249920/620022]    Loss: 0.008706   Batch Acc: 78.12
[Train] Epoch: 4 [249984/620022]    Loss: 0.007533   Batch Acc: 82.81
[Train] Epoch: 4 [250048/620022]    Loss: 0.007928   Batch Acc: 79.69
[Train] Epoch: 4 [250112/620022]    Loss: 0.009987   Batch Acc: 75.00
[Train] Epoch: 4 [250176/620022]    Loss: 0.009170   Batch Acc: 79.69
[Train] Epoch: 4 [250240/620022]    Loss: 0.008444   Batch Acc: 78.12
[Train] Epoch: 4 [250304/620022]    Loss: 0.010845   Batch Acc: 73.44
[Train] Epoch: 4 [250368/620022]    Loss: 0.008914   Batch Acc: 84.38
[Train] Epoch: 4 [250432/620022]    Loss: 0.008932   Batch Acc: 78.12
[Train] Epoch: 4 [250496/620022]    Loss: 0.009810   Batch Acc: 76.56
[Train] Epoch: 4 [250560/620022]    Loss: 0.008503   Batch Acc: 79.69
[Train] Epoch: 4 [250624/620022]    Loss: 0.008714   Batch Acc: 79.69
[Train] Epoch: 4 [250688/620022]    Loss: 0.008790   Batch Acc: 82.81
[Train] Epoch: 4 [250752/620022]    Loss: 0.010612   Batch Acc: 75.00
[Train] Epoch: 4 [250816/620022]    Loss: 0.009902   Batch Acc: 78.12
[Train] Epoch: 4 [250880/620022]    Loss: 0.006034   Batch Acc: 82.81
[Train] Epoch: 4 [250944/620022]    Loss: 0.010432   Batch Acc: 71.88
[Train] Epoch: 4 [251008/620022]    Loss: 0.008322   Batch Acc: 84.38
[Train] Epoch: 4 [251072/620022]    Loss: 0.008063   Batch Acc: 79.69
[Train] Epoch: 4 [251136/620022]    Loss: 0.009708   Batch Acc: 71.88
[Train] Epoch: 4 [251200/620022]    Loss: 0.009373   Batch Acc: 75.00
[Train] Epoch: 4 [251264/620022]    Loss: 0.007060   Batch Acc: 82.81
[Train] Epoch: 4 [251328/620022]    Loss: 0.009686   Batch Acc: 71.88
[Train] Epoch: 4 [251392/620022]    Loss: 0.007573   Batch Acc: 82.81
[Train] Epoch: 4 [251456/620022]    Loss: 0.008472   Batch Acc: 79.69
[Train] Epoch: 4 [251520/620022]    Loss: 0.009232   Batch Acc: 79.69
[Train] Epoch: 4 [251584/620022]    Loss: 0.008468   Batch Acc: 79.69
[Train] Epoch: 4 [251648/620022]    Loss: 0.008129   Batch Acc: 78.12
[Train] Epoch: 4 [251712/620022]    Loss: 0.006795   Batch Acc: 84.38
[Train] Epoch: 4 [251776/620022]    Loss: 0.009323   Batch Acc: 73.44
[Train] Epoch: 4 [251840/620022]    Loss: 0.008031   Batch Acc: 84.38
[Train] Epoch: 4 [251904/620022]    Loss: 0.008031   Batch Acc: 81.25
[Train] Epoch: 4 [251968/620022]    Loss: 0.006577   Batch Acc: 87.50
[Train] Epoch: 4 [252032/620022]    Loss: 0.009187   Batch Acc: 81.25
[Train] Epoch: 4 [252096/620022]    Loss: 0.009632   Batch Acc: 76.56
[Train] Epoch: 4 [252160/620022]    Loss: 0.010664   Batch Acc: 73.44
[Train] Epoch: 4 [252224/620022]    Loss: 0.008291   Batch Acc: 78.12
[Train] Epoch: 4 [252288/620022]    Loss: 0.009406   Batch Acc: 73.44
[Train] Epoch: 4 [252352/620022]    Loss: 0.007488   Batch Acc: 81.25
[Train] Epoch: 4 [252416/620022]    Loss: 0.007218   Batch Acc: 79.69
[Train] Epoch: 4 [252480/620022]    Loss: 0.010440   Batch Acc: 71.88
[Train] Epoch: 4 [252544/620022]    Loss: 0.008570   Batch Acc: 79.69
[Train] Epoch: 4 [252608/620022]    Loss: 0.007783   Batch Acc: 75.00
[Train] Epoch: 4 [252672/620022]    Loss: 0.012019   Batch Acc: 75.00
[Train] Epoch: 4 [252736/620022]    Loss: 0.008466   Batch Acc: 81.25
[Train] Epoch: 4 [252800/620022]    Loss: 0.006841   Batch Acc: 85.94
[Train] Epoch: 4 [252864/620022]    Loss: 0.009179   Batch Acc: 81.25
[Train] Epoch: 4 [252928/620022]    Loss: 0.007770   Batch Acc: 82.81
[Train] Epoch: 4 [252992/620022]    Loss: 0.009439   Batch Acc: 75.00
[Train] Epoch: 4 [253056/620022]    Loss: 0.009700   Batch Acc: 68.75
[Train] Epoch: 4 [253120/620022]    Loss: 0.011903   Batch Acc: 67.19
[Train] Epoch: 4 [253184/620022]    Loss: 0.008154   Batch Acc: 79.69
[Train] Epoch: 4 [253248/620022]    Loss: 0.006983   Batch Acc: 81.25
[Train] Epoch: 4 [253312/620022]    Loss: 0.010120   Batch Acc: 73.44
[Train] Epoch: 4 [253376/620022]    Loss: 0.009641   Batch Acc: 76.56
[Train] Epoch: 4 [253440/620022]    Loss: 0.007876   Batch Acc: 81.25
[Train] Epoch: 4 [253504/620022]    Loss: 0.008705   Batch Acc: 81.25
[Train] Epoch: 4 [253568/620022]    Loss: 0.009698   Batch Acc: 75.00
[Train] Epoch: 4 [253632/620022]    Loss: 0.007901   Batch Acc: 82.81
[Train] Epoch: 4 [253696/620022]    Loss: 0.007848   Batch Acc: 79.69
[Train] Epoch: 4 [253760/620022]    Loss: 0.009090   Batch Acc: 79.69
[Train] Epoch: 4 [253824/620022]    Loss: 0.011593   Batch Acc: 73.44
[Train] Epoch: 4 [253888/620022]    Loss: 0.009743   Batch Acc: 71.88
[Train] Epoch: 4 [253952/620022]    Loss: 0.007022   Batch Acc: 87.50
[Train] Epoch: 4 [254016/620022]    Loss: 0.008797   Batch Acc: 75.00
[Train] Epoch: 4 [254080/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 4 [254144/620022]    Loss: 0.009455   Batch Acc: 78.12
[Train] Epoch: 4 [254208/620022]    Loss: 0.008040   Batch Acc: 82.81
[Train] Epoch: 4 [254272/620022]    Loss: 0.007041   Batch Acc: 84.38
[Train] Epoch: 4 [254336/620022]    Loss: 0.008741   Batch Acc: 76.56
[Train] Epoch: 4 [254400/620022]    Loss: 0.008269   Batch Acc: 81.25
[Train] Epoch: 4 [254464/620022]    Loss: 0.009021   Batch Acc: 71.88
[Train] Epoch: 4 [254528/620022]    Loss: 0.009111   Batch Acc: 76.56
[Train] Epoch: 4 [254592/620022]    Loss: 0.009609   Batch Acc: 73.44
[Train] Epoch: 4 [254656/620022]    Loss: 0.007913   Batch Acc: 81.25
[Train] Epoch: 4 [254720/620022]    Loss: 0.007357   Batch Acc: 82.81
[Train] Epoch: 4 [254784/620022]    Loss: 0.009037   Batch Acc: 78.12
[Train] Epoch: 4 [254848/620022]    Loss: 0.007899   Batch Acc: 79.69
[Train] Epoch: 4 [254912/620022]    Loss: 0.008798   Batch Acc: 75.00
[Train] Epoch: 4 [254976/620022]    Loss: 0.009977   Batch Acc: 70.31
[Train] Epoch: 4 [255040/620022]    Loss: 0.007241   Batch Acc: 82.81
[Train] Epoch: 4 [255104/620022]    Loss: 0.006972   Batch Acc: 85.94
[Train] Epoch: 4 [255168/620022]    Loss: 0.008840   Batch Acc: 76.56
[Train] Epoch: 4 [255232/620022]    Loss: 0.009917   Batch Acc: 73.44
[Train] Epoch: 4 [255296/620022]    Loss: 0.006173   Batch Acc: 89.06
[Train] Epoch: 4 [255360/620022]    Loss: 0.009180   Batch Acc: 76.56
[Train] Epoch: 4 [255424/620022]    Loss: 0.007664   Batch Acc: 81.25
[Train] Epoch: 4 [255488/620022]    Loss: 0.007847   Batch Acc: 85.94
[Train] Epoch: 4 [255552/620022]    Loss: 0.008410   Batch Acc: 78.12
[Train] Epoch: 4 [255616/620022]    Loss: 0.008995   Batch Acc: 78.12
[Train] Epoch: 4 [255680/620022]    Loss: 0.008429   Batch Acc: 73.44
[Train] Epoch: 4 [255744/620022]    Loss: 0.009786   Batch Acc: 75.00
[Train] Epoch: 4 [255808/620022]    Loss: 0.008497   Batch Acc: 81.25
[Train] Epoch: 4 [255872/620022]    Loss: 0.007984   Batch Acc: 81.25
[Train] Epoch: 4 [255936/620022]    Loss: 0.007361   Batch Acc: 81.25
[Train] Epoch: 4 [256000/620022]    Loss: 0.011180   Batch Acc: 67.19
[Train] Epoch: 4 [256064/620022]    Loss: 0.009462   Batch Acc: 75.00
[Train] Epoch: 4 [256128/620022]    Loss: 0.006984   Batch Acc: 79.69
[Train] Epoch: 4 [256192/620022]    Loss: 0.007007   Batch Acc: 82.81
[Train] Epoch: 4 [256256/620022]    Loss: 0.012617   Batch Acc: 64.06
[Train] Epoch: 4 [256320/620022]    Loss: 0.008414   Batch Acc: 81.25
[Train] Epoch: 4 [256384/620022]    Loss: 0.008342   Batch Acc: 82.81
[Train] Epoch: 4 [256448/620022]    Loss: 0.005813   Batch Acc: 89.06
[Train] Epoch: 4 [256512/620022]    Loss: 0.008098   Batch Acc: 87.50
[Train] Epoch: 4 [256576/620022]    Loss: 0.008784   Batch Acc: 76.56
[Train] Epoch: 4 [256640/620022]    Loss: 0.010537   Batch Acc: 78.12
[Train] Epoch: 4 [256704/620022]    Loss: 0.011000   Batch Acc: 65.62
[Train] Epoch: 4 [256768/620022]    Loss: 0.009305   Batch Acc: 76.56
[Train] Epoch: 4 [256832/620022]    Loss: 0.007705   Batch Acc: 82.81
[Train] Epoch: 4 [256896/620022]    Loss: 0.008378   Batch Acc: 78.12
[Train] Epoch: 4 [256960/620022]    Loss: 0.009058   Batch Acc: 75.00
[Train] Epoch: 4 [257024/620022]    Loss: 0.009577   Batch Acc: 76.56
[Train] Epoch: 4 [257088/620022]    Loss: 0.011527   Batch Acc: 65.62
[Train] Epoch: 4 [257152/620022]    Loss: 0.007398   Batch Acc: 82.81
[Train] Epoch: 4 [257216/620022]    Loss: 0.007761   Batch Acc: 82.81
[Train] Epoch: 4 [257280/620022]    Loss: 0.008260   Batch Acc: 78.12
[Train] Epoch: 4 [257344/620022]    Loss: 0.009188   Batch Acc: 71.88
[Train] Epoch: 4 [257408/620022]    Loss: 0.007116   Batch Acc: 84.38
[Train] Epoch: 4 [257472/620022]    Loss: 0.008137   Batch Acc: 78.12
[Train] Epoch: 4 [257536/620022]    Loss: 0.009057   Batch Acc: 73.44
[Train] Epoch: 4 [257600/620022]    Loss: 0.008179   Batch Acc: 76.56
[Train] Epoch: 4 [257664/620022]    Loss: 0.008900   Batch Acc: 79.69
[Train] Epoch: 4 [257728/620022]    Loss: 0.010535   Batch Acc: 68.75
[Train] Epoch: 4 [257792/620022]    Loss: 0.008772   Batch Acc: 81.25
[Train] Epoch: 4 [257856/620022]    Loss: 0.009361   Batch Acc: 71.88
[Train] Epoch: 4 [257920/620022]    Loss: 0.007869   Batch Acc: 81.25
[Train] Epoch: 4 [257984/620022]    Loss: 0.008024   Batch Acc: 84.38
[Train] Epoch: 4 [258048/620022]    Loss: 0.008104   Batch Acc: 78.12
[Train] Epoch: 4 [258112/620022]    Loss: 0.007592   Batch Acc: 81.25
[Train] Epoch: 4 [258176/620022]    Loss: 0.008776   Batch Acc: 75.00
[Train] Epoch: 4 [258240/620022]    Loss: 0.009300   Batch Acc: 71.88
[Train] Epoch: 4 [258304/620022]    Loss: 0.010492   Batch Acc: 75.00
[Train] Epoch: 4 [258368/620022]    Loss: 0.009394   Batch Acc: 73.44
[Train] Epoch: 4 [258432/620022]    Loss: 0.008886   Batch Acc: 79.69
[Train] Epoch: 4 [258496/620022]    Loss: 0.009040   Batch Acc: 79.69
[Train] Epoch: 4 [258560/620022]    Loss: 0.006164   Batch Acc: 87.50
[Train] Epoch: 4 [258624/620022]    Loss: 0.010074   Batch Acc: 75.00
[Train] Epoch: 4 [258688/620022]    Loss: 0.008717   Batch Acc: 79.69
[Train] Epoch: 4 [258752/620022]    Loss: 0.008504   Batch Acc: 75.00
[Train] Epoch: 4 [258816/620022]    Loss: 0.006433   Batch Acc: 85.94
[Train] Epoch: 4 [258880/620022]    Loss: 0.007585   Batch Acc: 82.81
[Train] Epoch: 4 [258944/620022]    Loss: 0.008859   Batch Acc: 79.69
[Train] Epoch: 4 [259008/620022]    Loss: 0.008499   Batch Acc: 79.69
[Train] Epoch: 4 [259072/620022]    Loss: 0.011188   Batch Acc: 70.31
[Train] Epoch: 4 [259136/620022]    Loss: 0.012114   Batch Acc: 65.62
[Train] Epoch: 4 [259200/620022]    Loss: 0.006425   Batch Acc: 89.06
[Train] Epoch: 4 [259264/620022]    Loss: 0.008087   Batch Acc: 82.81
[Train] Epoch: 4 [259328/620022]    Loss: 0.010243   Batch Acc: 68.75
[Train] Epoch: 4 [259392/620022]    Loss: 0.009022   Batch Acc: 73.44
[Train] Epoch: 4 [259456/620022]    Loss: 0.007985   Batch Acc: 78.12
[Train] Epoch: 4 [259520/620022]    Loss: 0.007644   Batch Acc: 79.69
[Train] Epoch: 4 [259584/620022]    Loss: 0.008329   Batch Acc: 76.56
[Train] Epoch: 4 [259648/620022]    Loss: 0.007213   Batch Acc: 85.94
[Train] Epoch: 4 [259712/620022]    Loss: 0.010239   Batch Acc: 73.44
[Train] Epoch: 4 [259776/620022]    Loss: 0.008119   Batch Acc: 79.69
[Train] Epoch: 4 [259840/620022]    Loss: 0.009868   Batch Acc: 73.44
[Train] Epoch: 4 [259904/620022]    Loss: 0.010208   Batch Acc: 71.88
[Train] Epoch: 4 [259968/620022]    Loss: 0.011385   Batch Acc: 67.19
[Train] Epoch: 4 [260032/620022]    Loss: 0.010568   Batch Acc: 78.12
[Train] Epoch: 4 [260096/620022]    Loss: 0.007717   Batch Acc: 81.25
[Train] Epoch: 4 [260160/620022]    Loss: 0.008699   Batch Acc: 79.69
[Train] Epoch: 4 [260224/620022]    Loss: 0.008396   Batch Acc: 78.12
[Train] Epoch: 4 [260288/620022]    Loss: 0.009022   Batch Acc: 78.12
[Train] Epoch: 4 [260352/620022]    Loss: 0.007365   Batch Acc: 82.81
[Train] Epoch: 4 [260416/620022]    Loss: 0.007619   Batch Acc: 84.38
[Train] Epoch: 4 [260480/620022]    Loss: 0.010245   Batch Acc: 75.00
[Train] Epoch: 4 [260544/620022]    Loss: 0.012342   Batch Acc: 64.06
[Train] Epoch: 4 [260608/620022]    Loss: 0.006471   Batch Acc: 85.94
[Train] Epoch: 4 [260672/620022]    Loss: 0.008552   Batch Acc: 78.12
[Train] Epoch: 4 [260736/620022]    Loss: 0.007359   Batch Acc: 82.81
[Train] Epoch: 4 [260800/620022]    Loss: 0.006832   Batch Acc: 84.38
[Train] Epoch: 4 [260864/620022]    Loss: 0.009696   Batch Acc: 73.44
[Train] Epoch: 4 [260928/620022]    Loss: 0.006533   Batch Acc: 89.06
[Train] Epoch: 4 [260992/620022]    Loss: 0.006804   Batch Acc: 81.25
[Train] Epoch: 4 [261056/620022]    Loss: 0.008623   Batch Acc: 75.00
[Train] Epoch: 4 [261120/620022]    Loss: 0.008876   Batch Acc: 78.12
[Train] Epoch: 4 [261184/620022]    Loss: 0.009823   Batch Acc: 71.88
[Train] Epoch: 4 [261248/620022]    Loss: 0.008060   Batch Acc: 78.12
[Train] Epoch: 4 [261312/620022]    Loss: 0.010433   Batch Acc: 67.19
[Train] Epoch: 4 [261376/620022]    Loss: 0.009917   Batch Acc: 78.12
[Train] Epoch: 4 [261440/620022]    Loss: 0.010100   Batch Acc: 73.44
[Train] Epoch: 4 [261504/620022]    Loss: 0.008605   Batch Acc: 76.56
[Train] Epoch: 4 [261568/620022]    Loss: 0.006961   Batch Acc: 82.81
[Train] Epoch: 4 [261632/620022]    Loss: 0.005869   Batch Acc: 85.94
[Train] Epoch: 4 [261696/620022]    Loss: 0.008311   Batch Acc: 81.25
[Train] Epoch: 4 [261760/620022]    Loss: 0.009381   Batch Acc: 73.44
[Train] Epoch: 4 [261824/620022]    Loss: 0.008703   Batch Acc: 76.56
[Train] Epoch: 4 [261888/620022]    Loss: 0.006602   Batch Acc: 84.38
[Train] Epoch: 4 [261952/620022]    Loss: 0.007933   Batch Acc: 81.25
[Train] Epoch: 4 [262016/620022]    Loss: 0.009535   Batch Acc: 73.44
[Train] Epoch: 4 [262080/620022]    Loss: 0.009435   Batch Acc: 76.56
[Train] Epoch: 4 [262144/620022]    Loss: 0.009705   Batch Acc: 71.88
[Train] Epoch: 4 [262208/620022]    Loss: 0.010149   Batch Acc: 73.44
[Train] Epoch: 4 [262272/620022]    Loss: 0.008672   Batch Acc: 79.69
[Train] Epoch: 4 [262336/620022]    Loss: 0.008824   Batch Acc: 78.12
[Train] Epoch: 4 [262400/620022]    Loss: 0.009296   Batch Acc: 76.56
[Train] Epoch: 4 [262464/620022]    Loss: 0.006727   Batch Acc: 85.94
[Train] Epoch: 4 [262528/620022]    Loss: 0.006620   Batch Acc: 87.50
[Train] Epoch: 4 [262592/620022]    Loss: 0.009222   Batch Acc: 79.69
[Train] Epoch: 4 [262656/620022]    Loss: 0.008546   Batch Acc: 78.12
[Train] Epoch: 4 [262720/620022]    Loss: 0.007080   Batch Acc: 81.25
[Train] Epoch: 4 [262784/620022]    Loss: 0.010568   Batch Acc: 70.31
[Train] Epoch: 4 [262848/620022]    Loss: 0.007491   Batch Acc: 82.81
[Train] Epoch: 4 [262912/620022]    Loss: 0.007644   Batch Acc: 81.25
[Train] Epoch: 4 [262976/620022]    Loss: 0.009020   Batch Acc: 68.75
[Train] Epoch: 4 [263040/620022]    Loss: 0.008731   Batch Acc: 73.44
[Train] Epoch: 4 [263104/620022]    Loss: 0.009259   Batch Acc: 73.44
[Train] Epoch: 4 [263168/620022]    Loss: 0.008536   Batch Acc: 79.69
[Train] Epoch: 4 [263232/620022]    Loss: 0.008608   Batch Acc: 78.12
[Train] Epoch: 4 [263296/620022]    Loss: 0.009435   Batch Acc: 71.88
[Train] Epoch: 4 [263360/620022]    Loss: 0.007652   Batch Acc: 81.25
[Train] Epoch: 4 [263424/620022]    Loss: 0.007417   Batch Acc: 85.94
[Train] Epoch: 4 [263488/620022]    Loss: 0.007999   Batch Acc: 81.25
[Train] Epoch: 4 [263552/620022]    Loss: 0.008247   Batch Acc: 84.38
[Train] Epoch: 4 [263616/620022]    Loss: 0.009170   Batch Acc: 78.12
[Train] Epoch: 4 [263680/620022]    Loss: 0.009530   Batch Acc: 71.88
[Train] Epoch: 4 [263744/620022]    Loss: 0.009023   Batch Acc: 76.56
[Train] Epoch: 4 [263808/620022]    Loss: 0.007857   Batch Acc: 79.69
[Train] Epoch: 4 [263872/620022]    Loss: 0.011765   Batch Acc: 65.62
[Train] Epoch: 4 [263936/620022]    Loss: 0.011257   Batch Acc: 70.31
[Train] Epoch: 4 [264000/620022]    Loss: 0.009077   Batch Acc: 78.12
[Train] Epoch: 4 [264064/620022]    Loss: 0.009215   Batch Acc: 75.00
[Train] Epoch: 4 [264128/620022]    Loss: 0.008100   Batch Acc: 78.12
[Train] Epoch: 4 [264192/620022]    Loss: 0.011370   Batch Acc: 70.31
[Train] Epoch: 4 [264256/620022]    Loss: 0.010798   Batch Acc: 73.44
[Train] Epoch: 4 [264320/620022]    Loss: 0.009569   Batch Acc: 78.12
[Train] Epoch: 4 [264384/620022]    Loss: 0.009493   Batch Acc: 78.12
[Train] Epoch: 4 [264448/620022]    Loss: 0.009829   Batch Acc: 76.56
[Train] Epoch: 4 [264512/620022]    Loss: 0.006629   Batch Acc: 84.38
[Train] Epoch: 4 [264576/620022]    Loss: 0.010083   Batch Acc: 76.56
[Train] Epoch: 4 [264640/620022]    Loss: 0.008637   Batch Acc: 81.25
[Train] Epoch: 4 [264704/620022]    Loss: 0.007691   Batch Acc: 82.81
[Train] Epoch: 4 [264768/620022]    Loss: 0.007341   Batch Acc: 84.38
[Train] Epoch: 4 [264832/620022]    Loss: 0.009003   Batch Acc: 84.38
[Train] Epoch: 4 [264896/620022]    Loss: 0.007039   Batch Acc: 84.38
[Train] Epoch: 4 [264960/620022]    Loss: 0.009981   Batch Acc: 70.31
[Train] Epoch: 4 [265024/620022]    Loss: 0.009998   Batch Acc: 71.88
[Train] Epoch: 4 [265088/620022]    Loss: 0.007219   Batch Acc: 82.81
[Train] Epoch: 4 [265152/620022]    Loss: 0.012107   Batch Acc: 70.31
[Train] Epoch: 4 [265216/620022]    Loss: 0.007061   Batch Acc: 82.81
[Train] Epoch: 4 [265280/620022]    Loss: 0.008327   Batch Acc: 81.25
[Train] Epoch: 4 [265344/620022]    Loss: 0.008301   Batch Acc: 73.44
[Train] Epoch: 4 [265408/620022]    Loss: 0.007586   Batch Acc: 82.81
[Train] Epoch: 4 [265472/620022]    Loss: 0.008405   Batch Acc: 79.69
[Train] Epoch: 4 [265536/620022]    Loss: 0.006407   Batch Acc: 85.94
[Train] Epoch: 4 [265600/620022]    Loss: 0.009780   Batch Acc: 78.12
[Train] Epoch: 4 [265664/620022]    Loss: 0.007996   Batch Acc: 78.12
[Train] Epoch: 4 [265728/620022]    Loss: 0.009659   Batch Acc: 71.88
[Train] Epoch: 4 [265792/620022]    Loss: 0.009388   Batch Acc: 76.56
[Train] Epoch: 4 [265856/620022]    Loss: 0.013193   Batch Acc: 59.38
[Train] Epoch: 4 [265920/620022]    Loss: 0.007785   Batch Acc: 76.56
[Train] Epoch: 4 [265984/620022]    Loss: 0.006799   Batch Acc: 89.06
[Train] Epoch: 4 [266048/620022]    Loss: 0.005805   Batch Acc: 89.06
[Train] Epoch: 4 [266112/620022]    Loss: 0.008159   Batch Acc: 78.12
[Train] Epoch: 4 [266176/620022]    Loss: 0.007254   Batch Acc: 81.25
[Train] Epoch: 4 [266240/620022]    Loss: 0.008466   Batch Acc: 76.56
[Train] Epoch: 4 [266304/620022]    Loss: 0.007793   Batch Acc: 82.81
[Train] Epoch: 4 [266368/620022]    Loss: 0.008398   Batch Acc: 79.69
[Train] Epoch: 4 [266432/620022]    Loss: 0.008971   Batch Acc: 78.12
[Train] Epoch: 4 [266496/620022]    Loss: 0.009848   Batch Acc: 71.88
[Train] Epoch: 4 [266560/620022]    Loss: 0.007105   Batch Acc: 87.50
[Train] Epoch: 4 [266624/620022]    Loss: 0.008092   Batch Acc: 81.25
[Train] Epoch: 4 [266688/620022]    Loss: 0.007148   Batch Acc: 81.25
[Train] Epoch: 4 [266752/620022]    Loss: 0.007862   Batch Acc: 79.69
[Train] Epoch: 4 [266816/620022]    Loss: 0.007800   Batch Acc: 78.12
[Train] Epoch: 4 [266880/620022]    Loss: 0.008704   Batch Acc: 76.56
[Train] Epoch: 4 [266944/620022]    Loss: 0.008404   Batch Acc: 81.25
[Train] Epoch: 4 [267008/620022]    Loss: 0.007624   Batch Acc: 81.25
[Train] Epoch: 4 [267072/620022]    Loss: 0.007934   Batch Acc: 79.69
[Train] Epoch: 4 [267136/620022]    Loss: 0.008943   Batch Acc: 78.12
[Train] Epoch: 4 [267200/620022]    Loss: 0.009264   Batch Acc: 75.00
[Train] Epoch: 4 [267264/620022]    Loss: 0.009133   Batch Acc: 65.62
[Train] Epoch: 4 [267328/620022]    Loss: 0.008156   Batch Acc: 84.38
[Train] Epoch: 4 [267392/620022]    Loss: 0.007972   Batch Acc: 82.81
[Train] Epoch: 4 [267456/620022]    Loss: 0.007969   Batch Acc: 85.94
[Train] Epoch: 4 [267520/620022]    Loss: 0.006130   Batch Acc: 84.38
[Train] Epoch: 4 [267584/620022]    Loss: 0.007838   Batch Acc: 84.38
[Train] Epoch: 4 [267648/620022]    Loss: 0.008854   Batch Acc: 81.25
[Train] Epoch: 4 [267712/620022]    Loss: 0.007410   Batch Acc: 79.69
[Train] Epoch: 4 [267776/620022]    Loss: 0.006316   Batch Acc: 84.38
[Train] Epoch: 4 [267840/620022]    Loss: 0.008895   Batch Acc: 75.00
[Train] Epoch: 4 [267904/620022]    Loss: 0.007780   Batch Acc: 78.12
[Train] Epoch: 4 [267968/620022]    Loss: 0.007197   Batch Acc: 85.94
[Train] Epoch: 4 [268032/620022]    Loss: 0.009067   Batch Acc: 78.12
[Train] Epoch: 4 [268096/620022]    Loss: 0.006042   Batch Acc: 81.25
[Train] Epoch: 4 [268160/620022]    Loss: 0.007211   Batch Acc: 82.81
[Train] Epoch: 4 [268224/620022]    Loss: 0.008311   Batch Acc: 81.25
[Train] Epoch: 4 [268288/620022]    Loss: 0.009223   Batch Acc: 71.88
[Train] Epoch: 4 [268352/620022]    Loss: 0.009601   Batch Acc: 75.00
[Train] Epoch: 4 [268416/620022]    Loss: 0.009180   Batch Acc: 76.56
[Train] Epoch: 4 [268480/620022]    Loss: 0.008991   Batch Acc: 79.69
[Train] Epoch: 4 [268544/620022]    Loss: 0.007544   Batch Acc: 79.69
[Train] Epoch: 4 [268608/620022]    Loss: 0.007548   Batch Acc: 81.25
[Train] Epoch: 4 [268672/620022]    Loss: 0.011064   Batch Acc: 70.31
[Train] Epoch: 4 [268736/620022]    Loss: 0.010400   Batch Acc: 75.00
[Train] Epoch: 4 [268800/620022]    Loss: 0.007513   Batch Acc: 82.81
[Train] Epoch: 4 [268864/620022]    Loss: 0.006234   Batch Acc: 89.06
[Train] Epoch: 4 [268928/620022]    Loss: 0.007809   Batch Acc: 82.81
[Train] Epoch: 4 [268992/620022]    Loss: 0.008795   Batch Acc: 76.56
[Train] Epoch: 4 [269056/620022]    Loss: 0.006451   Batch Acc: 87.50
[Train] Epoch: 4 [269120/620022]    Loss: 0.009087   Batch Acc: 79.69
[Train] Epoch: 4 [269184/620022]    Loss: 0.006646   Batch Acc: 81.25
[Train] Epoch: 4 [269248/620022]    Loss: 0.009617   Batch Acc: 73.44
[Train] Epoch: 4 [269312/620022]    Loss: 0.006835   Batch Acc: 82.81
[Train] Epoch: 4 [269376/620022]    Loss: 0.007385   Batch Acc: 82.81
[Train] Epoch: 4 [269440/620022]    Loss: 0.010678   Batch Acc: 68.75
[Train] Epoch: 4 [269504/620022]    Loss: 0.008136   Batch Acc: 82.81
[Train] Epoch: 4 [269568/620022]    Loss: 0.010281   Batch Acc: 73.44
[Train] Epoch: 4 [269632/620022]    Loss: 0.008650   Batch Acc: 75.00
[Train] Epoch: 4 [269696/620022]    Loss: 0.009382   Batch Acc: 76.56
[Train] Epoch: 4 [269760/620022]    Loss: 0.006790   Batch Acc: 81.25
[Train] Epoch: 4 [269824/620022]    Loss: 0.007926   Batch Acc: 78.12
[Train] Epoch: 4 [269888/620022]    Loss: 0.009331   Batch Acc: 75.00
[Train] Epoch: 4 [269952/620022]    Loss: 0.010959   Batch Acc: 73.44
[Train] Epoch: 4 [270016/620022]    Loss: 0.008453   Batch Acc: 79.69
[Train] Epoch: 4 [270080/620022]    Loss: 0.008926   Batch Acc: 75.00
[Train] Epoch: 4 [270144/620022]    Loss: 0.007974   Batch Acc: 78.12
[Train] Epoch: 4 [270208/620022]    Loss: 0.008051   Batch Acc: 76.56
[Train] Epoch: 4 [270272/620022]    Loss: 0.008823   Batch Acc: 76.56
[Train] Epoch: 4 [270336/620022]    Loss: 0.008052   Batch Acc: 82.81
[Train] Epoch: 4 [270400/620022]    Loss: 0.007548   Batch Acc: 84.38
[Train] Epoch: 4 [270464/620022]    Loss: 0.008660   Batch Acc: 78.12
[Train] Epoch: 4 [270528/620022]    Loss: 0.008639   Batch Acc: 79.69
[Train] Epoch: 4 [270592/620022]    Loss: 0.006941   Batch Acc: 84.38
[Train] Epoch: 4 [270656/620022]    Loss: 0.009152   Batch Acc: 73.44
[Train] Epoch: 4 [270720/620022]    Loss: 0.010819   Batch Acc: 71.88
[Train] Epoch: 4 [270784/620022]    Loss: 0.006796   Batch Acc: 87.50
[Train] Epoch: 4 [270848/620022]    Loss: 0.007682   Batch Acc: 82.81
[Train] Epoch: 4 [270912/620022]    Loss: 0.008014   Batch Acc: 81.25
[Train] Epoch: 4 [270976/620022]    Loss: 0.006911   Batch Acc: 81.25
[Train] Epoch: 4 [271040/620022]    Loss: 0.009569   Batch Acc: 78.12
[Train] Epoch: 4 [271104/620022]    Loss: 0.010542   Batch Acc: 71.88
[Train] Epoch: 4 [271168/620022]    Loss: 0.007072   Batch Acc: 87.50
[Train] Epoch: 4 [271232/620022]    Loss: 0.007782   Batch Acc: 76.56
[Train] Epoch: 4 [271296/620022]    Loss: 0.009975   Batch Acc: 71.88
[Train] Epoch: 4 [271360/620022]    Loss: 0.007072   Batch Acc: 85.94
[Train] Epoch: 4 [271424/620022]    Loss: 0.007671   Batch Acc: 76.56
[Train] Epoch: 4 [271488/620022]    Loss: 0.008616   Batch Acc: 73.44
[Train] Epoch: 4 [271552/620022]    Loss: 0.009624   Batch Acc: 73.44
[Train] Epoch: 4 [271616/620022]    Loss: 0.007705   Batch Acc: 81.25
[Train] Epoch: 4 [271680/620022]    Loss: 0.007647   Batch Acc: 78.12
[Train] Epoch: 4 [271744/620022]    Loss: 0.008927   Batch Acc: 78.12
[Train] Epoch: 4 [271808/620022]    Loss: 0.007148   Batch Acc: 87.50
[Train] Epoch: 4 [271872/620022]    Loss: 0.009714   Batch Acc: 71.88
[Train] Epoch: 4 [271936/620022]    Loss: 0.009463   Batch Acc: 78.12
[Train] Epoch: 4 [272000/620022]    Loss: 0.011008   Batch Acc: 78.12
[Train] Epoch: 4 [272064/620022]    Loss: 0.008029   Batch Acc: 85.94
[Train] Epoch: 4 [272128/620022]    Loss: 0.007028   Batch Acc: 79.69
[Train] Epoch: 4 [272192/620022]    Loss: 0.009215   Batch Acc: 78.12
[Train] Epoch: 4 [272256/620022]    Loss: 0.007852   Batch Acc: 81.25
[Train] Epoch: 4 [272320/620022]    Loss: 0.007416   Batch Acc: 81.25
[Train] Epoch: 4 [272384/620022]    Loss: 0.008672   Batch Acc: 76.56
[Train] Epoch: 4 [272448/620022]    Loss: 0.007360   Batch Acc: 79.69
[Train] Epoch: 4 [272512/620022]    Loss: 0.007512   Batch Acc: 76.56
[Train] Epoch: 4 [272576/620022]    Loss: 0.008828   Batch Acc: 85.94
[Train] Epoch: 4 [272640/620022]    Loss: 0.009090   Batch Acc: 78.12
[Train] Epoch: 4 [272704/620022]    Loss: 0.009264   Batch Acc: 75.00
[Train] Epoch: 4 [272768/620022]    Loss: 0.008400   Batch Acc: 81.25
[Train] Epoch: 4 [272832/620022]    Loss: 0.010595   Batch Acc: 68.75
[Train] Epoch: 4 [272896/620022]    Loss: 0.010004   Batch Acc: 78.12
[Train] Epoch: 4 [272960/620022]    Loss: 0.007472   Batch Acc: 79.69
[Train] Epoch: 4 [273024/620022]    Loss: 0.008724   Batch Acc: 76.56
[Train] Epoch: 4 [273088/620022]    Loss: 0.009140   Batch Acc: 76.56
[Train] Epoch: 4 [273152/620022]    Loss: 0.008226   Batch Acc: 76.56
[Train] Epoch: 4 [273216/620022]    Loss: 0.008757   Batch Acc: 71.88
[Train] Epoch: 4 [273280/620022]    Loss: 0.007534   Batch Acc: 84.38
[Train] Epoch: 4 [273344/620022]    Loss: 0.010679   Batch Acc: 73.44
[Train] Epoch: 4 [273408/620022]    Loss: 0.007307   Batch Acc: 79.69
[Train] Epoch: 4 [273472/620022]    Loss: 0.009013   Batch Acc: 75.00
[Train] Epoch: 4 [273536/620022]    Loss: 0.008758   Batch Acc: 76.56
[Train] Epoch: 4 [273600/620022]    Loss: 0.009229   Batch Acc: 81.25
[Train] Epoch: 4 [273664/620022]    Loss: 0.009691   Batch Acc: 78.12
[Train] Epoch: 4 [273728/620022]    Loss: 0.009200   Batch Acc: 81.25
[Train] Epoch: 4 [273792/620022]    Loss: 0.008446   Batch Acc: 78.12
[Train] Epoch: 4 [273856/620022]    Loss: 0.007533   Batch Acc: 85.94
[Train] Epoch: 4 [273920/620022]    Loss: 0.010337   Batch Acc: 75.00
[Train] Epoch: 4 [273984/620022]    Loss: 0.007910   Batch Acc: 82.81
[Train] Epoch: 4 [274048/620022]    Loss: 0.005799   Batch Acc: 85.94
[Train] Epoch: 4 [274112/620022]    Loss: 0.008594   Batch Acc: 78.12
[Train] Epoch: 4 [274176/620022]    Loss: 0.009340   Batch Acc: 75.00
[Train] Epoch: 4 [274240/620022]    Loss: 0.008234   Batch Acc: 79.69
[Train] Epoch: 4 [274304/620022]    Loss: 0.007378   Batch Acc: 82.81
[Train] Epoch: 4 [274368/620022]    Loss: 0.011948   Batch Acc: 68.75
[Train] Epoch: 4 [274432/620022]    Loss: 0.008590   Batch Acc: 87.50
[Train] Epoch: 4 [274496/620022]    Loss: 0.010243   Batch Acc: 71.88
[Train] Epoch: 4 [274560/620022]    Loss: 0.007078   Batch Acc: 82.81
[Train] Epoch: 4 [274624/620022]    Loss: 0.009094   Batch Acc: 73.44
[Train] Epoch: 4 [274688/620022]    Loss: 0.008899   Batch Acc: 79.69
[Train] Epoch: 4 [274752/620022]    Loss: 0.010572   Batch Acc: 78.12
[Train] Epoch: 4 [274816/620022]    Loss: 0.010279   Batch Acc: 75.00
[Train] Epoch: 4 [274880/620022]    Loss: 0.008824   Batch Acc: 75.00
[Train] Epoch: 4 [274944/620022]    Loss: 0.009421   Batch Acc: 75.00
[Train] Epoch: 4 [275008/620022]    Loss: 0.010872   Batch Acc: 67.19
[Train] Epoch: 4 [275072/620022]    Loss: 0.009109   Batch Acc: 73.44
[Train] Epoch: 4 [275136/620022]    Loss: 0.008259   Batch Acc: 81.25
[Train] Epoch: 4 [275200/620022]    Loss: 0.008206   Batch Acc: 81.25
[Train] Epoch: 4 [275264/620022]    Loss: 0.009529   Batch Acc: 67.19
[Train] Epoch: 4 [275328/620022]    Loss: 0.007720   Batch Acc: 82.81
[Train] Epoch: 4 [275392/620022]    Loss: 0.006507   Batch Acc: 87.50
[Train] Epoch: 4 [275456/620022]    Loss: 0.009109   Batch Acc: 78.12
[Train] Epoch: 4 [275520/620022]    Loss: 0.010371   Batch Acc: 71.88
[Train] Epoch: 4 [275584/620022]    Loss: 0.008858   Batch Acc: 78.12
[Train] Epoch: 4 [275648/620022]    Loss: 0.008092   Batch Acc: 78.12
[Train] Epoch: 4 [275712/620022]    Loss: 0.006155   Batch Acc: 85.94
[Train] Epoch: 4 [275776/620022]    Loss: 0.008011   Batch Acc: 73.44
[Train] Epoch: 4 [275840/620022]    Loss: 0.008420   Batch Acc: 82.81
[Train] Epoch: 4 [275904/620022]    Loss: 0.007556   Batch Acc: 82.81
[Train] Epoch: 4 [275968/620022]    Loss: 0.007627   Batch Acc: 81.25
[Train] Epoch: 4 [276032/620022]    Loss: 0.007252   Batch Acc: 79.69
[Train] Epoch: 4 [276096/620022]    Loss: 0.008085   Batch Acc: 79.69
[Train] Epoch: 4 [276160/620022]    Loss: 0.011250   Batch Acc: 73.44
[Train] Epoch: 4 [276224/620022]    Loss: 0.007841   Batch Acc: 76.56
[Train] Epoch: 4 [276288/620022]    Loss: 0.010654   Batch Acc: 76.56
[Train] Epoch: 4 [276352/620022]    Loss: 0.010749   Batch Acc: 73.44
[Train] Epoch: 4 [276416/620022]    Loss: 0.007922   Batch Acc: 81.25
[Train] Epoch: 4 [276480/620022]    Loss: 0.007125   Batch Acc: 82.81
[Train] Epoch: 4 [276544/620022]    Loss: 0.009283   Batch Acc: 75.00
[Train] Epoch: 4 [276608/620022]    Loss: 0.008218   Batch Acc: 82.81
[Train] Epoch: 4 [276672/620022]    Loss: 0.009195   Batch Acc: 78.12
[Train] Epoch: 4 [276736/620022]    Loss: 0.009385   Batch Acc: 78.12
[Train] Epoch: 4 [276800/620022]    Loss: 0.009798   Batch Acc: 65.62
[Train] Epoch: 4 [276864/620022]    Loss: 0.008304   Batch Acc: 78.12
[Train] Epoch: 4 [276928/620022]    Loss: 0.008176   Batch Acc: 79.69
[Train] Epoch: 4 [276992/620022]    Loss: 0.008826   Batch Acc: 79.69
[Train] Epoch: 4 [277056/620022]    Loss: 0.007209   Batch Acc: 81.25
[Train] Epoch: 4 [277120/620022]    Loss: 0.007590   Batch Acc: 76.56
[Train] Epoch: 4 [277184/620022]    Loss: 0.008981   Batch Acc: 76.56
[Train] Epoch: 4 [277248/620022]    Loss: 0.008732   Batch Acc: 78.12
[Train] Epoch: 4 [277312/620022]    Loss: 0.007467   Batch Acc: 81.25
[Train] Epoch: 4 [277376/620022]    Loss: 0.009034   Batch Acc: 76.56
[Train] Epoch: 4 [277440/620022]    Loss: 0.008697   Batch Acc: 78.12
[Train] Epoch: 4 [277504/620022]    Loss: 0.009097   Batch Acc: 76.56
[Train] Epoch: 4 [277568/620022]    Loss: 0.007394   Batch Acc: 84.38
[Train] Epoch: 4 [277632/620022]    Loss: 0.008464   Batch Acc: 81.25
[Train] Epoch: 4 [277696/620022]    Loss: 0.008484   Batch Acc: 79.69
[Train] Epoch: 4 [277760/620022]    Loss: 0.012762   Batch Acc: 64.06
[Train] Epoch: 4 [277824/620022]    Loss: 0.008981   Batch Acc: 73.44
[Train] Epoch: 4 [277888/620022]    Loss: 0.009523   Batch Acc: 81.25
[Train] Epoch: 4 [277952/620022]    Loss: 0.009563   Batch Acc: 68.75
[Train] Epoch: 4 [278016/620022]    Loss: 0.008903   Batch Acc: 76.56
[Train] Epoch: 4 [278080/620022]    Loss: 0.010593   Batch Acc: 71.88
[Train] Epoch: 4 [278144/620022]    Loss: 0.007268   Batch Acc: 82.81
[Train] Epoch: 4 [278208/620022]    Loss: 0.009530   Batch Acc: 75.00
[Train] Epoch: 4 [278272/620022]    Loss: 0.008267   Batch Acc: 85.94
[Train] Epoch: 4 [278336/620022]    Loss: 0.009287   Batch Acc: 75.00
[Train] Epoch: 4 [278400/620022]    Loss: 0.009031   Batch Acc: 71.88
[Train] Epoch: 4 [278464/620022]    Loss: 0.010173   Batch Acc: 75.00
[Train] Epoch: 4 [278528/620022]    Loss: 0.008936   Batch Acc: 78.12
[Train] Epoch: 4 [278592/620022]    Loss: 0.010157   Batch Acc: 70.31
[Train] Epoch: 4 [278656/620022]    Loss: 0.009847   Batch Acc: 73.44
[Train] Epoch: 4 [278720/620022]    Loss: 0.009766   Batch Acc: 68.75
[Train] Epoch: 4 [278784/620022]    Loss: 0.006177   Batch Acc: 87.50
[Train] Epoch: 4 [278848/620022]    Loss: 0.010387   Batch Acc: 76.56
[Train] Epoch: 4 [278912/620022]    Loss: 0.008001   Batch Acc: 75.00
[Train] Epoch: 4 [278976/620022]    Loss: 0.007594   Batch Acc: 79.69
[Train] Epoch: 4 [279040/620022]    Loss: 0.009312   Batch Acc: 79.69
[Train] Epoch: 4 [279104/620022]    Loss: 0.008000   Batch Acc: 82.81
[Train] Epoch: 4 [279168/620022]    Loss: 0.009186   Batch Acc: 70.31
[Train] Epoch: 4 [279232/620022]    Loss: 0.007884   Batch Acc: 81.25
[Train] Epoch: 4 [279296/620022]    Loss: 0.007341   Batch Acc: 78.12
[Train] Epoch: 4 [279360/620022]    Loss: 0.007523   Batch Acc: 84.38
[Train] Epoch: 4 [279424/620022]    Loss: 0.007730   Batch Acc: 79.69
[Train] Epoch: 4 [279488/620022]    Loss: 0.011040   Batch Acc: 68.75
[Train] Epoch: 4 [279552/620022]    Loss: 0.007977   Batch Acc: 79.69
[Train] Epoch: 4 [279616/620022]    Loss: 0.010798   Batch Acc: 68.75
[Train] Epoch: 4 [279680/620022]    Loss: 0.010141   Batch Acc: 71.88
[Train] Epoch: 4 [279744/620022]    Loss: 0.007858   Batch Acc: 76.56
[Train] Epoch: 4 [279808/620022]    Loss: 0.008877   Batch Acc: 81.25
[Train] Epoch: 4 [279872/620022]    Loss: 0.010157   Batch Acc: 67.19
[Train] Epoch: 4 [279936/620022]    Loss: 0.010005   Batch Acc: 70.31
[Train] Epoch: 4 [280000/620022]    Loss: 0.008822   Batch Acc: 79.69
[Train] Epoch: 4 [280064/620022]    Loss: 0.009150   Batch Acc: 79.69
[Train] Epoch: 4 [280128/620022]    Loss: 0.008271   Batch Acc: 79.69
[Train] Epoch: 4 [280192/620022]    Loss: 0.008121   Batch Acc: 76.56
[Train] Epoch: 4 [280256/620022]    Loss: 0.008963   Batch Acc: 75.00
[Train] Epoch: 4 [280320/620022]    Loss: 0.007734   Batch Acc: 82.81
[Train] Epoch: 4 [280384/620022]    Loss: 0.007051   Batch Acc: 82.81
[Train] Epoch: 4 [280448/620022]    Loss: 0.007750   Batch Acc: 79.69
[Train] Epoch: 4 [280512/620022]    Loss: 0.009422   Batch Acc: 76.56
[Train] Epoch: 4 [280576/620022]    Loss: 0.008450   Batch Acc: 75.00
[Train] Epoch: 4 [280640/620022]    Loss: 0.008125   Batch Acc: 84.38
[Train] Epoch: 4 [280704/620022]    Loss: 0.008593   Batch Acc: 79.69
[Train] Epoch: 4 [280768/620022]    Loss: 0.009618   Batch Acc: 73.44
[Train] Epoch: 4 [280832/620022]    Loss: 0.009870   Batch Acc: 73.44
[Train] Epoch: 4 [280896/620022]    Loss: 0.007090   Batch Acc: 87.50
[Train] Epoch: 4 [280960/620022]    Loss: 0.007644   Batch Acc: 73.44
[Train] Epoch: 4 [281024/620022]    Loss: 0.008397   Batch Acc: 79.69
[Train] Epoch: 4 [281088/620022]    Loss: 0.008757   Batch Acc: 84.38
[Train] Epoch: 4 [281152/620022]    Loss: 0.010223   Batch Acc: 70.31
[Train] Epoch: 4 [281216/620022]    Loss: 0.005897   Batch Acc: 89.06
[Train] Epoch: 4 [281280/620022]    Loss: 0.007360   Batch Acc: 82.81
[Train] Epoch: 4 [281344/620022]    Loss: 0.009792   Batch Acc: 73.44
[Train] Epoch: 4 [281408/620022]    Loss: 0.007624   Batch Acc: 76.56
[Train] Epoch: 4 [281472/620022]    Loss: 0.009847   Batch Acc: 71.88
[Train] Epoch: 4 [281536/620022]    Loss: 0.009027   Batch Acc: 73.44
[Train] Epoch: 4 [281600/620022]    Loss: 0.009119   Batch Acc: 79.69
[Train] Epoch: 4 [281664/620022]    Loss: 0.009606   Batch Acc: 70.31
[Train] Epoch: 4 [281728/620022]    Loss: 0.006804   Batch Acc: 82.81
[Train] Epoch: 4 [281792/620022]    Loss: 0.007850   Batch Acc: 76.56
[Train] Epoch: 4 [281856/620022]    Loss: 0.006250   Batch Acc: 87.50
[Train] Epoch: 4 [281920/620022]    Loss: 0.007868   Batch Acc: 81.25
[Train] Epoch: 4 [281984/620022]    Loss: 0.008806   Batch Acc: 79.69
[Train] Epoch: 4 [282048/620022]    Loss: 0.008853   Batch Acc: 73.44
[Train] Epoch: 4 [282112/620022]    Loss: 0.007759   Batch Acc: 79.69
[Train] Epoch: 4 [282176/620022]    Loss: 0.011384   Batch Acc: 68.75
[Train] Epoch: 4 [282240/620022]    Loss: 0.009107   Batch Acc: 75.00
[Train] Epoch: 4 [282304/620022]    Loss: 0.007331   Batch Acc: 81.25
[Train] Epoch: 4 [282368/620022]    Loss: 0.008780   Batch Acc: 76.56
[Train] Epoch: 4 [282432/620022]    Loss: 0.007075   Batch Acc: 78.12
[Train] Epoch: 4 [282496/620022]    Loss: 0.010071   Batch Acc: 71.88
[Train] Epoch: 4 [282560/620022]    Loss: 0.009250   Batch Acc: 71.88
[Train] Epoch: 4 [282624/620022]    Loss: 0.006763   Batch Acc: 84.38
[Train] Epoch: 4 [282688/620022]    Loss: 0.010101   Batch Acc: 70.31
[Train] Epoch: 4 [282752/620022]    Loss: 0.007244   Batch Acc: 84.38
[Train] Epoch: 4 [282816/620022]    Loss: 0.008512   Batch Acc: 75.00
[Train] Epoch: 4 [282880/620022]    Loss: 0.008430   Batch Acc: 75.00
[Train] Epoch: 4 [282944/620022]    Loss: 0.006769   Batch Acc: 81.25
[Train] Epoch: 4 [283008/620022]    Loss: 0.008403   Batch Acc: 76.56
[Train] Epoch: 4 [283072/620022]    Loss: 0.007650   Batch Acc: 79.69
[Train] Epoch: 4 [283136/620022]    Loss: 0.009448   Batch Acc: 76.56
[Train] Epoch: 4 [283200/620022]    Loss: 0.006607   Batch Acc: 85.94
[Train] Epoch: 4 [283264/620022]    Loss: 0.008938   Batch Acc: 78.12
[Train] Epoch: 4 [283328/620022]    Loss: 0.009516   Batch Acc: 68.75
[Train] Epoch: 4 [283392/620022]    Loss: 0.007850   Batch Acc: 81.25
[Train] Epoch: 4 [283456/620022]    Loss: 0.008934   Batch Acc: 73.44
[Train] Epoch: 4 [283520/620022]    Loss: 0.010889   Batch Acc: 71.88
[Train] Epoch: 4 [283584/620022]    Loss: 0.008174   Batch Acc: 79.69
[Train] Epoch: 4 [283648/620022]    Loss: 0.008388   Batch Acc: 78.12
[Train] Epoch: 4 [283712/620022]    Loss: 0.010056   Batch Acc: 75.00
[Train] Epoch: 4 [283776/620022]    Loss: 0.006875   Batch Acc: 82.81
[Train] Epoch: 4 [283840/620022]    Loss: 0.010048   Batch Acc: 73.44
[Train] Epoch: 4 [283904/620022]    Loss: 0.008578   Batch Acc: 75.00
[Train] Epoch: 4 [283968/620022]    Loss: 0.009075   Batch Acc: 78.12
[Train] Epoch: 4 [284032/620022]    Loss: 0.005859   Batch Acc: 89.06
[Train] Epoch: 4 [284096/620022]    Loss: 0.006990   Batch Acc: 81.25
[Train] Epoch: 4 [284160/620022]    Loss: 0.012313   Batch Acc: 64.06
[Train] Epoch: 4 [284224/620022]    Loss: 0.006781   Batch Acc: 81.25
[Train] Epoch: 4 [284288/620022]    Loss: 0.007568   Batch Acc: 81.25
[Train] Epoch: 4 [284352/620022]    Loss: 0.007984   Batch Acc: 79.69
[Train] Epoch: 4 [284416/620022]    Loss: 0.010209   Batch Acc: 76.56
[Train] Epoch: 4 [284480/620022]    Loss: 0.009825   Batch Acc: 70.31
[Train] Epoch: 4 [284544/620022]    Loss: 0.010520   Batch Acc: 73.44
[Train] Epoch: 4 [284608/620022]    Loss: 0.009483   Batch Acc: 73.44
[Train] Epoch: 4 [284672/620022]    Loss: 0.010659   Batch Acc: 73.44
[Train] Epoch: 4 [284736/620022]    Loss: 0.007170   Batch Acc: 81.25
[Train] Epoch: 4 [284800/620022]    Loss: 0.008833   Batch Acc: 81.25
[Train] Epoch: 4 [284864/620022]    Loss: 0.010635   Batch Acc: 71.88
[Train] Epoch: 4 [284928/620022]    Loss: 0.006807   Batch Acc: 89.06
[Train] Epoch: 4 [284992/620022]    Loss: 0.007970   Batch Acc: 79.69
[Train] Epoch: 4 [285056/620022]    Loss: 0.009215   Batch Acc: 78.12
[Train] Epoch: 4 [285120/620022]    Loss: 0.007168   Batch Acc: 85.94
[Train] Epoch: 4 [285184/620022]    Loss: 0.009771   Batch Acc: 76.56
[Train] Epoch: 4 [285248/620022]    Loss: 0.007632   Batch Acc: 79.69
[Train] Epoch: 4 [285312/620022]    Loss: 0.007810   Batch Acc: 75.00
[Train] Epoch: 4 [285376/620022]    Loss: 0.007972   Batch Acc: 75.00
[Train] Epoch: 4 [285440/620022]    Loss: 0.008154   Batch Acc: 81.25
[Train] Epoch: 4 [285504/620022]    Loss: 0.010181   Batch Acc: 76.56
[Train] Epoch: 4 [285568/620022]    Loss: 0.010058   Batch Acc: 76.56
[Train] Epoch: 4 [285632/620022]    Loss: 0.008344   Batch Acc: 79.69
[Train] Epoch: 4 [285696/620022]    Loss: 0.008354   Batch Acc: 78.12
[Train] Epoch: 4 [285760/620022]    Loss: 0.007472   Batch Acc: 79.69
[Train] Epoch: 4 [285824/620022]    Loss: 0.010804   Batch Acc: 68.75
[Train] Epoch: 4 [285888/620022]    Loss: 0.011265   Batch Acc: 75.00
[Train] Epoch: 4 [285952/620022]    Loss: 0.007919   Batch Acc: 81.25
[Train] Epoch: 4 [286016/620022]    Loss: 0.007491   Batch Acc: 75.00
[Train] Epoch: 4 [286080/620022]    Loss: 0.010293   Batch Acc: 76.56
[Train] Epoch: 4 [286144/620022]    Loss: 0.009600   Batch Acc: 78.12
[Train] Epoch: 4 [286208/620022]    Loss: 0.008607   Batch Acc: 76.56
[Train] Epoch: 4 [286272/620022]    Loss: 0.009520   Batch Acc: 76.56
[Train] Epoch: 4 [286336/620022]    Loss: 0.008966   Batch Acc: 75.00
[Train] Epoch: 4 [286400/620022]    Loss: 0.009297   Batch Acc: 78.12
[Train] Epoch: 4 [286464/620022]    Loss: 0.011178   Batch Acc: 73.44
[Train] Epoch: 4 [286528/620022]    Loss: 0.008404   Batch Acc: 76.56
[Train] Epoch: 4 [286592/620022]    Loss: 0.009430   Batch Acc: 76.56
[Train] Epoch: 4 [286656/620022]    Loss: 0.009669   Batch Acc: 78.12
[Train] Epoch: 4 [286720/620022]    Loss: 0.009149   Batch Acc: 76.56
[Train] Epoch: 4 [286784/620022]    Loss: 0.007237   Batch Acc: 85.94
[Train] Epoch: 4 [286848/620022]    Loss: 0.007558   Batch Acc: 81.25
[Train] Epoch: 4 [286912/620022]    Loss: 0.009211   Batch Acc: 76.56
[Train] Epoch: 4 [286976/620022]    Loss: 0.006923   Batch Acc: 81.25
[Train] Epoch: 4 [287040/620022]    Loss: 0.010453   Batch Acc: 67.19
[Train] Epoch: 4 [287104/620022]    Loss: 0.009215   Batch Acc: 68.75
[Train] Epoch: 4 [287168/620022]    Loss: 0.009562   Batch Acc: 73.44
[Train] Epoch: 4 [287232/620022]    Loss: 0.007428   Batch Acc: 81.25
[Train] Epoch: 4 [287296/620022]    Loss: 0.009815   Batch Acc: 71.88
[Train] Epoch: 4 [287360/620022]    Loss: 0.009591   Batch Acc: 73.44
[Train] Epoch: 4 [287424/620022]    Loss: 0.009310   Batch Acc: 71.88
[Train] Epoch: 4 [287488/620022]    Loss: 0.008616   Batch Acc: 73.44
[Train] Epoch: 4 [287552/620022]    Loss: 0.007675   Batch Acc: 76.56
[Train] Epoch: 4 [287616/620022]    Loss: 0.009662   Batch Acc: 75.00
[Train] Epoch: 4 [287680/620022]    Loss: 0.008844   Batch Acc: 70.31
[Train] Epoch: 4 [287744/620022]    Loss: 0.009881   Batch Acc: 76.56
[Train] Epoch: 4 [287808/620022]    Loss: 0.009157   Batch Acc: 75.00
[Train] Epoch: 4 [287872/620022]    Loss: 0.008252   Batch Acc: 75.00
[Train] Epoch: 4 [287936/620022]    Loss: 0.011229   Batch Acc: 64.06
[Train] Epoch: 4 [288000/620022]    Loss: 0.007487   Batch Acc: 85.94
[Train] Epoch: 4 [288064/620022]    Loss: 0.009852   Batch Acc: 68.75
[Train] Epoch: 4 [288128/620022]    Loss: 0.009199   Batch Acc: 71.88
[Train] Epoch: 4 [288192/620022]    Loss: 0.008143   Batch Acc: 84.38
[Train] Epoch: 4 [288256/620022]    Loss: 0.009267   Batch Acc: 73.44
[Train] Epoch: 4 [288320/620022]    Loss: 0.008215   Batch Acc: 84.38
[Train] Epoch: 4 [288384/620022]    Loss: 0.010126   Batch Acc: 78.12
[Train] Epoch: 4 [288448/620022]    Loss: 0.009916   Batch Acc: 73.44
[Train] Epoch: 4 [288512/620022]    Loss: 0.010232   Batch Acc: 78.12
[Train] Epoch: 4 [288576/620022]    Loss: 0.007937   Batch Acc: 81.25
[Train] Epoch: 4 [288640/620022]    Loss: 0.010614   Batch Acc: 79.69
[Train] Epoch: 4 [288704/620022]    Loss: 0.008400   Batch Acc: 79.69
[Train] Epoch: 4 [288768/620022]    Loss: 0.007749   Batch Acc: 79.69
[Train] Epoch: 4 [288832/620022]    Loss: 0.008190   Batch Acc: 79.69
[Train] Epoch: 4 [288896/620022]    Loss: 0.006550   Batch Acc: 85.94
[Train] Epoch: 4 [288960/620022]    Loss: 0.008462   Batch Acc: 81.25
[Train] Epoch: 4 [289024/620022]    Loss: 0.010851   Batch Acc: 71.88
[Train] Epoch: 4 [289088/620022]    Loss: 0.010614   Batch Acc: 67.19
[Train] Epoch: 4 [289152/620022]    Loss: 0.009352   Batch Acc: 73.44
[Train] Epoch: 4 [289216/620022]    Loss: 0.008599   Batch Acc: 82.81
[Train] Epoch: 4 [289280/620022]    Loss: 0.010480   Batch Acc: 76.56
[Train] Epoch: 4 [289344/620022]    Loss: 0.008114   Batch Acc: 78.12
[Train] Epoch: 4 [289408/620022]    Loss: 0.007151   Batch Acc: 82.81
[Train] Epoch: 4 [289472/620022]    Loss: 0.010598   Batch Acc: 64.06
[Train] Epoch: 4 [289536/620022]    Loss: 0.008561   Batch Acc: 75.00
[Train] Epoch: 4 [289600/620022]    Loss: 0.010361   Batch Acc: 68.75
[Train] Epoch: 4 [289664/620022]    Loss: 0.007168   Batch Acc: 89.06
[Train] Epoch: 4 [289728/620022]    Loss: 0.008985   Batch Acc: 82.81
[Train] Epoch: 4 [289792/620022]    Loss: 0.007848   Batch Acc: 81.25
[Train] Epoch: 4 [289856/620022]    Loss: 0.009494   Batch Acc: 76.56
[Train] Epoch: 4 [289920/620022]    Loss: 0.008460   Batch Acc: 76.56
[Train] Epoch: 4 [289984/620022]    Loss: 0.008820   Batch Acc: 71.88
[Train] Epoch: 4 [290048/620022]    Loss: 0.008701   Batch Acc: 82.81
[Train] Epoch: 4 [290112/620022]    Loss: 0.009314   Batch Acc: 76.56
[Train] Epoch: 4 [290176/620022]    Loss: 0.008719   Batch Acc: 76.56
[Train] Epoch: 4 [290240/620022]    Loss: 0.010861   Batch Acc: 75.00
[Train] Epoch: 4 [290304/620022]    Loss: 0.006527   Batch Acc: 85.94
[Train] Epoch: 4 [290368/620022]    Loss: 0.009165   Batch Acc: 71.88
[Train] Epoch: 4 [290432/620022]    Loss: 0.009521   Batch Acc: 76.56
[Train] Epoch: 4 [290496/620022]    Loss: 0.009038   Batch Acc: 68.75
[Train] Epoch: 4 [290560/620022]    Loss: 0.008104   Batch Acc: 84.38
[Train] Epoch: 4 [290624/620022]    Loss: 0.008811   Batch Acc: 79.69
[Train] Epoch: 4 [290688/620022]    Loss: 0.010287   Batch Acc: 68.75
[Train] Epoch: 4 [290752/620022]    Loss: 0.008031   Batch Acc: 79.69
[Train] Epoch: 4 [290816/620022]    Loss: 0.011666   Batch Acc: 70.31
[Train] Epoch: 4 [290880/620022]    Loss: 0.007126   Batch Acc: 79.69
[Train] Epoch: 4 [290944/620022]    Loss: 0.005770   Batch Acc: 87.50
[Train] Epoch: 4 [291008/620022]    Loss: 0.008595   Batch Acc: 76.56
[Train] Epoch: 4 [291072/620022]    Loss: 0.008954   Batch Acc: 76.56
[Train] Epoch: 4 [291136/620022]    Loss: 0.008299   Batch Acc: 75.00
[Train] Epoch: 4 [291200/620022]    Loss: 0.008079   Batch Acc: 79.69
[Train] Epoch: 4 [291264/620022]    Loss: 0.007817   Batch Acc: 81.25
[Train] Epoch: 4 [291328/620022]    Loss: 0.008050   Batch Acc: 82.81
[Train] Epoch: 4 [291392/620022]    Loss: 0.007518   Batch Acc: 84.38
[Train] Epoch: 4 [291456/620022]    Loss: 0.010286   Batch Acc: 75.00
[Train] Epoch: 4 [291520/620022]    Loss: 0.008670   Batch Acc: 81.25
[Train] Epoch: 4 [291584/620022]    Loss: 0.007999   Batch Acc: 78.12
[Train] Epoch: 4 [291648/620022]    Loss: 0.008314   Batch Acc: 81.25
[Train] Epoch: 4 [291712/620022]    Loss: 0.007394   Batch Acc: 84.38
[Train] Epoch: 4 [291776/620022]    Loss: 0.008629   Batch Acc: 79.69
[Train] Epoch: 4 [291840/620022]    Loss: 0.007875   Batch Acc: 81.25
[Train] Epoch: 4 [291904/620022]    Loss: 0.009335   Batch Acc: 78.12
[Train] Epoch: 4 [291968/620022]    Loss: 0.008346   Batch Acc: 78.12
[Train] Epoch: 4 [292032/620022]    Loss: 0.009752   Batch Acc: 76.56
[Train] Epoch: 4 [292096/620022]    Loss: 0.009325   Batch Acc: 82.81
[Train] Epoch: 4 [292160/620022]    Loss: 0.009864   Batch Acc: 73.44
[Train] Epoch: 4 [292224/620022]    Loss: 0.009294   Batch Acc: 78.12
[Train] Epoch: 4 [292288/620022]    Loss: 0.009979   Batch Acc: 73.44
[Train] Epoch: 4 [292352/620022]    Loss: 0.009602   Batch Acc: 73.44
[Train] Epoch: 4 [292416/620022]    Loss: 0.009168   Batch Acc: 78.12
[Train] Epoch: 4 [292480/620022]    Loss: 0.008373   Batch Acc: 78.12
[Train] Epoch: 4 [292544/620022]    Loss: 0.008506   Batch Acc: 78.12
[Train] Epoch: 4 [292608/620022]    Loss: 0.010806   Batch Acc: 70.31
[Train] Epoch: 4 [292672/620022]    Loss: 0.008599   Batch Acc: 79.69
[Train] Epoch: 4 [292736/620022]    Loss: 0.009025   Batch Acc: 78.12
[Train] Epoch: 4 [292800/620022]    Loss: 0.008777   Batch Acc: 81.25
[Train] Epoch: 4 [292864/620022]    Loss: 0.007403   Batch Acc: 84.38
[Train] Epoch: 4 [292928/620022]    Loss: 0.007442   Batch Acc: 87.50
[Train] Epoch: 4 [292992/620022]    Loss: 0.009049   Batch Acc: 75.00
[Train] Epoch: 4 [293056/620022]    Loss: 0.006800   Batch Acc: 85.94
[Train] Epoch: 4 [293120/620022]    Loss: 0.006996   Batch Acc: 82.81
[Train] Epoch: 4 [293184/620022]    Loss: 0.010526   Batch Acc: 75.00
[Train] Epoch: 4 [293248/620022]    Loss: 0.009123   Batch Acc: 75.00
[Train] Epoch: 4 [293312/620022]    Loss: 0.006825   Batch Acc: 84.38
[Train] Epoch: 4 [293376/620022]    Loss: 0.009104   Batch Acc: 76.56
[Train] Epoch: 4 [293440/620022]    Loss: 0.008339   Batch Acc: 81.25
[Train] Epoch: 4 [293504/620022]    Loss: 0.008588   Batch Acc: 78.12
[Train] Epoch: 4 [293568/620022]    Loss: 0.008382   Batch Acc: 76.56
[Train] Epoch: 4 [293632/620022]    Loss: 0.007727   Batch Acc: 76.56
[Train] Epoch: 4 [293696/620022]    Loss: 0.008749   Batch Acc: 76.56
[Train] Epoch: 4 [293760/620022]    Loss: 0.008862   Batch Acc: 76.56
[Train] Epoch: 4 [293824/620022]    Loss: 0.007242   Batch Acc: 79.69
[Train] Epoch: 4 [293888/620022]    Loss: 0.008262   Batch Acc: 84.38
[Train] Epoch: 4 [293952/620022]    Loss: 0.011071   Batch Acc: 71.88
[Train] Epoch: 4 [294016/620022]    Loss: 0.010597   Batch Acc: 76.56
[Train] Epoch: 4 [294080/620022]    Loss: 0.009765   Batch Acc: 76.56
[Train] Epoch: 4 [294144/620022]    Loss: 0.008659   Batch Acc: 78.12
[Train] Epoch: 4 [294208/620022]    Loss: 0.006028   Batch Acc: 85.94
[Train] Epoch: 4 [294272/620022]    Loss: 0.009441   Batch Acc: 81.25
[Train] Epoch: 4 [294336/620022]    Loss: 0.008051   Batch Acc: 78.12
[Train] Epoch: 4 [294400/620022]    Loss: 0.008207   Batch Acc: 78.12
[Train] Epoch: 4 [294464/620022]    Loss: 0.010835   Batch Acc: 78.12
[Train] Epoch: 4 [294528/620022]    Loss: 0.010103   Batch Acc: 70.31
[Train] Epoch: 4 [294592/620022]    Loss: 0.008829   Batch Acc: 78.12
[Train] Epoch: 4 [294656/620022]    Loss: 0.008095   Batch Acc: 71.88
[Train] Epoch: 4 [294720/620022]    Loss: 0.007487   Batch Acc: 79.69
[Train] Epoch: 4 [294784/620022]    Loss: 0.007072   Batch Acc: 81.25
[Train] Epoch: 4 [294848/620022]    Loss: 0.008031   Batch Acc: 79.69
[Train] Epoch: 4 [294912/620022]    Loss: 0.009536   Batch Acc: 78.12
[Train] Epoch: 4 [294976/620022]    Loss: 0.009435   Batch Acc: 78.12
[Train] Epoch: 4 [295040/620022]    Loss: 0.008496   Batch Acc: 73.44
[Train] Epoch: 4 [295104/620022]    Loss: 0.007193   Batch Acc: 81.25
[Train] Epoch: 4 [295168/620022]    Loss: 0.009602   Batch Acc: 79.69
[Train] Epoch: 4 [295232/620022]    Loss: 0.009642   Batch Acc: 70.31
[Train] Epoch: 4 [295296/620022]    Loss: 0.008881   Batch Acc: 76.56
[Train] Epoch: 4 [295360/620022]    Loss: 0.011751   Batch Acc: 70.31
[Train] Epoch: 4 [295424/620022]    Loss: 0.007410   Batch Acc: 85.94
[Train] Epoch: 4 [295488/620022]    Loss: 0.006202   Batch Acc: 87.50
[Train] Epoch: 4 [295552/620022]    Loss: 0.007578   Batch Acc: 87.50
[Train] Epoch: 4 [295616/620022]    Loss: 0.008687   Batch Acc: 78.12
[Train] Epoch: 4 [295680/620022]    Loss: 0.009865   Batch Acc: 75.00
[Train] Epoch: 4 [295744/620022]    Loss: 0.010261   Batch Acc: 71.88
[Train] Epoch: 4 [295808/620022]    Loss: 0.009426   Batch Acc: 78.12
[Train] Epoch: 4 [295872/620022]    Loss: 0.006851   Batch Acc: 81.25
[Train] Epoch: 4 [295936/620022]    Loss: 0.008960   Batch Acc: 75.00
[Train] Epoch: 4 [296000/620022]    Loss: 0.008558   Batch Acc: 82.81
[Train] Epoch: 4 [296064/620022]    Loss: 0.008378   Batch Acc: 78.12
[Train] Epoch: 4 [296128/620022]    Loss: 0.009048   Batch Acc: 79.69
[Train] Epoch: 4 [296192/620022]    Loss: 0.008789   Batch Acc: 73.44
[Train] Epoch: 4 [296256/620022]    Loss: 0.010119   Batch Acc: 79.69
[Train] Epoch: 4 [296320/620022]    Loss: 0.009360   Batch Acc: 78.12
[Train] Epoch: 4 [296384/620022]    Loss: 0.009235   Batch Acc: 75.00
[Train] Epoch: 4 [296448/620022]    Loss: 0.010145   Batch Acc: 71.88
[Train] Epoch: 4 [296512/620022]    Loss: 0.006642   Batch Acc: 84.38
[Train] Epoch: 4 [296576/620022]    Loss: 0.009427   Batch Acc: 71.88
[Train] Epoch: 4 [296640/620022]    Loss: 0.009110   Batch Acc: 75.00
[Train] Epoch: 4 [296704/620022]    Loss: 0.007444   Batch Acc: 76.56
[Train] Epoch: 4 [296768/620022]    Loss: 0.006885   Batch Acc: 82.81
[Train] Epoch: 4 [296832/620022]    Loss: 0.007520   Batch Acc: 79.69
[Train] Epoch: 4 [296896/620022]    Loss: 0.012617   Batch Acc: 67.19
[Train] Epoch: 4 [296960/620022]    Loss: 0.008365   Batch Acc: 75.00
[Train] Epoch: 4 [297024/620022]    Loss: 0.010074   Batch Acc: 68.75
[Train] Epoch: 4 [297088/620022]    Loss: 0.009741   Batch Acc: 75.00
[Train] Epoch: 4 [297152/620022]    Loss: 0.009650   Batch Acc: 76.56
[Train] Epoch: 4 [297216/620022]    Loss: 0.008209   Batch Acc: 78.12
[Train] Epoch: 4 [297280/620022]    Loss: 0.010410   Batch Acc: 71.88
[Train] Epoch: 4 [297344/620022]    Loss: 0.007881   Batch Acc: 81.25
[Train] Epoch: 4 [297408/620022]    Loss: 0.007665   Batch Acc: 82.81
[Train] Epoch: 4 [297472/620022]    Loss: 0.010869   Batch Acc: 71.88
[Train] Epoch: 4 [297536/620022]    Loss: 0.007040   Batch Acc: 87.50
[Train] Epoch: 4 [297600/620022]    Loss: 0.009534   Batch Acc: 78.12
[Train] Epoch: 4 [297664/620022]    Loss: 0.008125   Batch Acc: 79.69
[Train] Epoch: 4 [297728/620022]    Loss: 0.008621   Batch Acc: 76.56
[Train] Epoch: 4 [297792/620022]    Loss: 0.006753   Batch Acc: 84.38
[Train] Epoch: 4 [297856/620022]    Loss: 0.008716   Batch Acc: 81.25
[Train] Epoch: 4 [297920/620022]    Loss: 0.011225   Batch Acc: 65.62
[Train] Epoch: 4 [297984/620022]    Loss: 0.010259   Batch Acc: 73.44
[Train] Epoch: 4 [298048/620022]    Loss: 0.008184   Batch Acc: 79.69
[Train] Epoch: 4 [298112/620022]    Loss: 0.010064   Batch Acc: 70.31
[Train] Epoch: 4 [298176/620022]    Loss: 0.009001   Batch Acc: 76.56
[Train] Epoch: 4 [298240/620022]    Loss: 0.007371   Batch Acc: 81.25
[Train] Epoch: 4 [298304/620022]    Loss: 0.007540   Batch Acc: 81.25
[Train] Epoch: 4 [298368/620022]    Loss: 0.011021   Batch Acc: 73.44
[Train] Epoch: 4 [298432/620022]    Loss: 0.009267   Batch Acc: 76.56
[Train] Epoch: 4 [298496/620022]    Loss: 0.010241   Batch Acc: 71.88
[Train] Epoch: 4 [298560/620022]    Loss: 0.008511   Batch Acc: 76.56
[Train] Epoch: 4 [298624/620022]    Loss: 0.008787   Batch Acc: 76.56
[Train] Epoch: 4 [298688/620022]    Loss: 0.010836   Batch Acc: 73.44
[Train] Epoch: 4 [298752/620022]    Loss: 0.006719   Batch Acc: 84.38
[Train] Epoch: 4 [298816/620022]    Loss: 0.010341   Batch Acc: 71.88
[Train] Epoch: 4 [298880/620022]    Loss: 0.009190   Batch Acc: 75.00
[Train] Epoch: 4 [298944/620022]    Loss: 0.008800   Batch Acc: 79.69
[Train] Epoch: 4 [299008/620022]    Loss: 0.010763   Batch Acc: 68.75
[Train] Epoch: 4 [299072/620022]    Loss: 0.010660   Batch Acc: 73.44
[Train] Epoch: 4 [299136/620022]    Loss: 0.009142   Batch Acc: 79.69
[Train] Epoch: 4 [299200/620022]    Loss: 0.008393   Batch Acc: 84.38
[Train] Epoch: 4 [299264/620022]    Loss: 0.006888   Batch Acc: 79.69
[Train] Epoch: 4 [299328/620022]    Loss: 0.007959   Batch Acc: 82.81
[Train] Epoch: 4 [299392/620022]    Loss: 0.009222   Batch Acc: 78.12
[Train] Epoch: 4 [299456/620022]    Loss: 0.007376   Batch Acc: 81.25
[Train] Epoch: 4 [299520/620022]    Loss: 0.007601   Batch Acc: 71.88
[Train] Epoch: 4 [299584/620022]    Loss: 0.009855   Batch Acc: 75.00
[Train] Epoch: 4 [299648/620022]    Loss: 0.006565   Batch Acc: 84.38
[Train] Epoch: 4 [299712/620022]    Loss: 0.009317   Batch Acc: 76.56
[Train] Epoch: 4 [299776/620022]    Loss: 0.008840   Batch Acc: 81.25
[Train] Epoch: 4 [299840/620022]    Loss: 0.007446   Batch Acc: 84.38
[Train] Epoch: 4 [299904/620022]    Loss: 0.008890   Batch Acc: 81.25
[Train] Epoch: 4 [299968/620022]    Loss: 0.006950   Batch Acc: 79.69
[Train] Epoch: 4 [300032/620022]    Loss: 0.009113   Batch Acc: 78.12
[Train] Epoch: 4 [300096/620022]    Loss: 0.007875   Batch Acc: 79.69
[Train] Epoch: 4 [300160/620022]    Loss: 0.008902   Batch Acc: 76.56
[Train] Epoch: 4 [300224/620022]    Loss: 0.009340   Batch Acc: 78.12
[Train] Epoch: 4 [300288/620022]    Loss: 0.008265   Batch Acc: 78.12
[Train] Epoch: 4 [300352/620022]    Loss: 0.007275   Batch Acc: 84.38
[Train] Epoch: 4 [300416/620022]    Loss: 0.008543   Batch Acc: 79.69
[Train] Epoch: 4 [300480/620022]    Loss: 0.008949   Batch Acc: 73.44
[Train] Epoch: 4 [300544/620022]    Loss: 0.007765   Batch Acc: 84.38
[Train] Epoch: 4 [300608/620022]    Loss: 0.011085   Batch Acc: 67.19
[Train] Epoch: 4 [300672/620022]    Loss: 0.007999   Batch Acc: 81.25
[Train] Epoch: 4 [300736/620022]    Loss: 0.009303   Batch Acc: 76.56
[Train] Epoch: 4 [300800/620022]    Loss: 0.010135   Batch Acc: 71.88
[Train] Epoch: 4 [300864/620022]    Loss: 0.008503   Batch Acc: 81.25
[Train] Epoch: 4 [300928/620022]    Loss: 0.007940   Batch Acc: 76.56
[Train] Epoch: 4 [300992/620022]    Loss: 0.006317   Batch Acc: 82.81
[Train] Epoch: 4 [301056/620022]    Loss: 0.009137   Batch Acc: 76.56
[Train] Epoch: 4 [301120/620022]    Loss: 0.011236   Batch Acc: 73.44
[Train] Epoch: 4 [301184/620022]    Loss: 0.010379   Batch Acc: 68.75
[Train] Epoch: 4 [301248/620022]    Loss: 0.008299   Batch Acc: 76.56
[Train] Epoch: 4 [301312/620022]    Loss: 0.006546   Batch Acc: 84.38
[Train] Epoch: 4 [301376/620022]    Loss: 0.010416   Batch Acc: 68.75
[Train] Epoch: 4 [301440/620022]    Loss: 0.008576   Batch Acc: 73.44
[Train] Epoch: 4 [301504/620022]    Loss: 0.010134   Batch Acc: 76.56
[Train] Epoch: 4 [301568/620022]    Loss: 0.008915   Batch Acc: 81.25
[Train] Epoch: 4 [301632/620022]    Loss: 0.010409   Batch Acc: 70.31
[Train] Epoch: 4 [301696/620022]    Loss: 0.008776   Batch Acc: 76.56
[Train] Epoch: 4 [301760/620022]    Loss: 0.005982   Batch Acc: 90.62
[Train] Epoch: 4 [301824/620022]    Loss: 0.009129   Batch Acc: 79.69
[Train] Epoch: 4 [301888/620022]    Loss: 0.007563   Batch Acc: 82.81
[Train] Epoch: 4 [301952/620022]    Loss: 0.006661   Batch Acc: 85.94
[Train] Epoch: 4 [302016/620022]    Loss: 0.009731   Batch Acc: 75.00
[Train] Epoch: 4 [302080/620022]    Loss: 0.010700   Batch Acc: 67.19
[Train] Epoch: 4 [302144/620022]    Loss: 0.007423   Batch Acc: 81.25
[Train] Epoch: 4 [302208/620022]    Loss: 0.009890   Batch Acc: 73.44
[Train] Epoch: 4 [302272/620022]    Loss: 0.008424   Batch Acc: 79.69
[Train] Epoch: 4 [302336/620022]    Loss: 0.007207   Batch Acc: 82.81
[Train] Epoch: 4 [302400/620022]    Loss: 0.010189   Batch Acc: 73.44
[Train] Epoch: 4 [302464/620022]    Loss: 0.007689   Batch Acc: 84.38
[Train] Epoch: 4 [302528/620022]    Loss: 0.009280   Batch Acc: 76.56
[Train] Epoch: 4 [302592/620022]    Loss: 0.008994   Batch Acc: 78.12
[Train] Epoch: 4 [302656/620022]    Loss: 0.007481   Batch Acc: 82.81
[Train] Epoch: 4 [302720/620022]    Loss: 0.008542   Batch Acc: 81.25
[Train] Epoch: 4 [302784/620022]    Loss: 0.007463   Batch Acc: 82.81
[Train] Epoch: 4 [302848/620022]    Loss: 0.010287   Batch Acc: 68.75
[Train] Epoch: 4 [302912/620022]    Loss: 0.009475   Batch Acc: 71.88
[Train] Epoch: 4 [302976/620022]    Loss: 0.010252   Batch Acc: 73.44
[Train] Epoch: 4 [303040/620022]    Loss: 0.007922   Batch Acc: 76.56
[Train] Epoch: 4 [303104/620022]    Loss: 0.007947   Batch Acc: 82.81
[Train] Epoch: 4 [303168/620022]    Loss: 0.008353   Batch Acc: 79.69
[Train] Epoch: 4 [303232/620022]    Loss: 0.010071   Batch Acc: 75.00
[Train] Epoch: 4 [303296/620022]    Loss: 0.006472   Batch Acc: 84.38
[Train] Epoch: 4 [303360/620022]    Loss: 0.006779   Batch Acc: 84.38
[Train] Epoch: 4 [303424/620022]    Loss: 0.008653   Batch Acc: 78.12
[Train] Epoch: 4 [303488/620022]    Loss: 0.010752   Batch Acc: 75.00
[Train] Epoch: 4 [303552/620022]    Loss: 0.007150   Batch Acc: 85.94
[Train] Epoch: 4 [303616/620022]    Loss: 0.009147   Batch Acc: 70.31
[Train] Epoch: 4 [303680/620022]    Loss: 0.009171   Batch Acc: 76.56
[Train] Epoch: 4 [303744/620022]    Loss: 0.009963   Batch Acc: 70.31
[Train] Epoch: 4 [303808/620022]    Loss: 0.007770   Batch Acc: 79.69
[Train] Epoch: 4 [303872/620022]    Loss: 0.007931   Batch Acc: 81.25
[Train] Epoch: 4 [303936/620022]    Loss: 0.006039   Batch Acc: 85.94
[Train] Epoch: 4 [304000/620022]    Loss: 0.007082   Batch Acc: 82.81
[Train] Epoch: 4 [304064/620022]    Loss: 0.007361   Batch Acc: 81.25
[Train] Epoch: 4 [304128/620022]    Loss: 0.008990   Batch Acc: 73.44
[Train] Epoch: 4 [304192/620022]    Loss: 0.007836   Batch Acc: 79.69
[Train] Epoch: 4 [304256/620022]    Loss: 0.007720   Batch Acc: 81.25
[Train] Epoch: 4 [304320/620022]    Loss: 0.007914   Batch Acc: 81.25
[Train] Epoch: 4 [304384/620022]    Loss: 0.008488   Batch Acc: 78.12
[Train] Epoch: 4 [304448/620022]    Loss: 0.008603   Batch Acc: 76.56
[Train] Epoch: 4 [304512/620022]    Loss: 0.006706   Batch Acc: 89.06
[Train] Epoch: 4 [304576/620022]    Loss: 0.011518   Batch Acc: 67.19
[Train] Epoch: 4 [304640/620022]    Loss: 0.008096   Batch Acc: 84.38
[Train] Epoch: 4 [304704/620022]    Loss: 0.009237   Batch Acc: 81.25
[Train] Epoch: 4 [304768/620022]    Loss: 0.010132   Batch Acc: 68.75
[Train] Epoch: 4 [304832/620022]    Loss: 0.008456   Batch Acc: 76.56
[Train] Epoch: 4 [304896/620022]    Loss: 0.005934   Batch Acc: 84.38
[Train] Epoch: 4 [304960/620022]    Loss: 0.005879   Batch Acc: 87.50
[Train] Epoch: 4 [305024/620022]    Loss: 0.008872   Batch Acc: 78.12
[Train] Epoch: 4 [305088/620022]    Loss: 0.007711   Batch Acc: 81.25
[Train] Epoch: 4 [305152/620022]    Loss: 0.008066   Batch Acc: 76.56
[Train] Epoch: 4 [305216/620022]    Loss: 0.011914   Batch Acc: 64.06
[Train] Epoch: 4 [305280/620022]    Loss: 0.010009   Batch Acc: 75.00
[Train] Epoch: 4 [305344/620022]    Loss: 0.011986   Batch Acc: 71.88
[Train] Epoch: 4 [305408/620022]    Loss: 0.007844   Batch Acc: 75.00
[Train] Epoch: 4 [305472/620022]    Loss: 0.009582   Batch Acc: 76.56
[Train] Epoch: 4 [305536/620022]    Loss: 0.008786   Batch Acc: 81.25
[Train] Epoch: 4 [305600/620022]    Loss: 0.010135   Batch Acc: 75.00
[Train] Epoch: 4 [305664/620022]    Loss: 0.009089   Batch Acc: 73.44
[Train] Epoch: 4 [305728/620022]    Loss: 0.008560   Batch Acc: 81.25
[Train] Epoch: 4 [305792/620022]    Loss: 0.008749   Batch Acc: 73.44
[Train] Epoch: 4 [305856/620022]    Loss: 0.008489   Batch Acc: 79.69
[Train] Epoch: 4 [305920/620022]    Loss: 0.008688   Batch Acc: 71.88
[Train] Epoch: 4 [305984/620022]    Loss: 0.008965   Batch Acc: 76.56
[Train] Epoch: 4 [306048/620022]    Loss: 0.009629   Batch Acc: 73.44
[Train] Epoch: 4 [306112/620022]    Loss: 0.008840   Batch Acc: 76.56
[Train] Epoch: 4 [306176/620022]    Loss: 0.006099   Batch Acc: 85.94
[Train] Epoch: 4 [306240/620022]    Loss: 0.008496   Batch Acc: 81.25
[Train] Epoch: 4 [306304/620022]    Loss: 0.010338   Batch Acc: 71.88
[Train] Epoch: 4 [306368/620022]    Loss: 0.005487   Batch Acc: 87.50
[Train] Epoch: 4 [306432/620022]    Loss: 0.007330   Batch Acc: 81.25
[Train] Epoch: 4 [306496/620022]    Loss: 0.007054   Batch Acc: 79.69
[Train] Epoch: 4 [306560/620022]    Loss: 0.010705   Batch Acc: 71.88
[Train] Epoch: 4 [306624/620022]    Loss: 0.009126   Batch Acc: 73.44
[Train] Epoch: 4 [306688/620022]    Loss: 0.010508   Batch Acc: 71.88
[Train] Epoch: 4 [306752/620022]    Loss: 0.009469   Batch Acc: 76.56
[Train] Epoch: 4 [306816/620022]    Loss: 0.011963   Batch Acc: 70.31
[Train] Epoch: 4 [306880/620022]    Loss: 0.006602   Batch Acc: 85.94
[Train] Epoch: 4 [306944/620022]    Loss: 0.008013   Batch Acc: 78.12
[Train] Epoch: 4 [307008/620022]    Loss: 0.008321   Batch Acc: 76.56
[Train] Epoch: 4 [307072/620022]    Loss: 0.007103   Batch Acc: 87.50
[Train] Epoch: 4 [307136/620022]    Loss: 0.006931   Batch Acc: 81.25
[Train] Epoch: 4 [307200/620022]    Loss: 0.006519   Batch Acc: 85.94
[Train] Epoch: 4 [307264/620022]    Loss: 0.008189   Batch Acc: 79.69
[Train] Epoch: 4 [307328/620022]    Loss: 0.010030   Batch Acc: 73.44
[Train] Epoch: 4 [307392/620022]    Loss: 0.009299   Batch Acc: 78.12
[Train] Epoch: 4 [307456/620022]    Loss: 0.007616   Batch Acc: 84.38
[Train] Epoch: 4 [307520/620022]    Loss: 0.007704   Batch Acc: 81.25
[Train] Epoch: 4 [307584/620022]    Loss: 0.007844   Batch Acc: 82.81
[Train] Epoch: 4 [307648/620022]    Loss: 0.005134   Batch Acc: 93.75
[Train] Epoch: 4 [307712/620022]    Loss: 0.006915   Batch Acc: 84.38
[Train] Epoch: 4 [307776/620022]    Loss: 0.006094   Batch Acc: 82.81
[Train] Epoch: 4 [307840/620022]    Loss: 0.009044   Batch Acc: 73.44
[Train] Epoch: 4 [307904/620022]    Loss: 0.007448   Batch Acc: 82.81
[Train] Epoch: 4 [307968/620022]    Loss: 0.010239   Batch Acc: 75.00
[Train] Epoch: 4 [308032/620022]    Loss: 0.007711   Batch Acc: 78.12
[Train] Epoch: 4 [308096/620022]    Loss: 0.008758   Batch Acc: 81.25
[Train] Epoch: 4 [308160/620022]    Loss: 0.009354   Batch Acc: 85.94
[Train] Epoch: 4 [308224/620022]    Loss: 0.010349   Batch Acc: 70.31
[Train] Epoch: 4 [308288/620022]    Loss: 0.008866   Batch Acc: 71.88
[Train] Epoch: 4 [308352/620022]    Loss: 0.009085   Batch Acc: 76.56
[Train] Epoch: 4 [308416/620022]    Loss: 0.010322   Batch Acc: 71.88
[Train] Epoch: 4 [308480/620022]    Loss: 0.011890   Batch Acc: 64.06
[Train] Epoch: 4 [308544/620022]    Loss: 0.009001   Batch Acc: 75.00
[Train] Epoch: 4 [308608/620022]    Loss: 0.008034   Batch Acc: 79.69
[Train] Epoch: 4 [308672/620022]    Loss: 0.007301   Batch Acc: 82.81
[Train] Epoch: 4 [308736/620022]    Loss: 0.009195   Batch Acc: 71.88
[Train] Epoch: 4 [308800/620022]    Loss: 0.009341   Batch Acc: 71.88
[Train] Epoch: 4 [308864/620022]    Loss: 0.007666   Batch Acc: 84.38
[Train] Epoch: 4 [308928/620022]    Loss: 0.009075   Batch Acc: 73.44
[Train] Epoch: 4 [308992/620022]    Loss: 0.009803   Batch Acc: 75.00
[Train] Epoch: 4 [309056/620022]    Loss: 0.009771   Batch Acc: 76.56
[Train] Epoch: 4 [309120/620022]    Loss: 0.009463   Batch Acc: 79.69
[Train] Epoch: 4 [309184/620022]    Loss: 0.007250   Batch Acc: 84.38
[Train] Epoch: 4 [309248/620022]    Loss: 0.010321   Batch Acc: 68.75
[Train] Epoch: 4 [309312/620022]    Loss: 0.007194   Batch Acc: 81.25
[Train] Epoch: 4 [309376/620022]    Loss: 0.010457   Batch Acc: 76.56
[Train] Epoch: 4 [309440/620022]    Loss: 0.009535   Batch Acc: 79.69
[Train] Epoch: 4 [309504/620022]    Loss: 0.009231   Batch Acc: 78.12
[Train] Epoch: 4 [309568/620022]    Loss: 0.011533   Batch Acc: 65.62
[Train] Epoch: 4 [309632/620022]    Loss: 0.007679   Batch Acc: 79.69
[Train] Epoch: 4 [309696/620022]    Loss: 0.009008   Batch Acc: 79.69
[Train] Epoch: 4 [309760/620022]    Loss: 0.009950   Batch Acc: 75.00
[Train] Epoch: 4 [309824/620022]    Loss: 0.007189   Batch Acc: 87.50
[Train] Epoch: 4 [309888/620022]    Loss: 0.009058   Batch Acc: 87.50
[Train] Epoch: 4 [309952/620022]    Loss: 0.009250   Batch Acc: 75.00
[Train] Epoch: 4 [310016/620022]    Loss: 0.008072   Batch Acc: 85.94
[Train] Epoch: 4 [310080/620022]    Loss: 0.007175   Batch Acc: 82.81
[Train] Epoch: 4 [310144/620022]    Loss: 0.008340   Batch Acc: 76.56
[Train] Epoch: 4 [310208/620022]    Loss: 0.010438   Batch Acc: 76.56
[Train] Epoch: 4 [310272/620022]    Loss: 0.007847   Batch Acc: 79.69
[Train] Epoch: 4 [310336/620022]    Loss: 0.008888   Batch Acc: 70.31
[Train] Epoch: 4 [310400/620022]    Loss: 0.006825   Batch Acc: 87.50
[Train] Epoch: 4 [310464/620022]    Loss: 0.008804   Batch Acc: 75.00
[Train] Epoch: 4 [310528/620022]    Loss: 0.007349   Batch Acc: 84.38
[Train] Epoch: 4 [310592/620022]    Loss: 0.013009   Batch Acc: 64.06
[Train] Epoch: 4 [310656/620022]    Loss: 0.009899   Batch Acc: 78.12
[Train] Epoch: 4 [310720/620022]    Loss: 0.008832   Batch Acc: 75.00
[Train] Epoch: 4 [310784/620022]    Loss: 0.007591   Batch Acc: 84.38
[Train] Epoch: 4 [310848/620022]    Loss: 0.010066   Batch Acc: 73.44
[Train] Epoch: 4 [310912/620022]    Loss: 0.007713   Batch Acc: 75.00
[Train] Epoch: 4 [310976/620022]    Loss: 0.007823   Batch Acc: 82.81
[Train] Epoch: 4 [311040/620022]    Loss: 0.006432   Batch Acc: 87.50
[Train] Epoch: 4 [311104/620022]    Loss: 0.009717   Batch Acc: 73.44
[Train] Epoch: 4 [311168/620022]    Loss: 0.008335   Batch Acc: 82.81
[Train] Epoch: 4 [311232/620022]    Loss: 0.007473   Batch Acc: 82.81
[Train] Epoch: 4 [311296/620022]    Loss: 0.008940   Batch Acc: 76.56
[Train] Epoch: 4 [311360/620022]    Loss: 0.009877   Batch Acc: 76.56
[Train] Epoch: 4 [311424/620022]    Loss: 0.009049   Batch Acc: 73.44
[Train] Epoch: 4 [311488/620022]    Loss: 0.009439   Batch Acc: 73.44
[Train] Epoch: 4 [311552/620022]    Loss: 0.006981   Batch Acc: 87.50
[Train] Epoch: 4 [311616/620022]    Loss: 0.007708   Batch Acc: 81.25
[Train] Epoch: 4 [311680/620022]    Loss: 0.007536   Batch Acc: 79.69
[Train] Epoch: 4 [311744/620022]    Loss: 0.009696   Batch Acc: 73.44
[Train] Epoch: 4 [311808/620022]    Loss: 0.009443   Batch Acc: 70.31
[Train] Epoch: 4 [311872/620022]    Loss: 0.006021   Batch Acc: 90.62
[Train] Epoch: 4 [311936/620022]    Loss: 0.008178   Batch Acc: 81.25
[Train] Epoch: 4 [312000/620022]    Loss: 0.008645   Batch Acc: 76.56
[Train] Epoch: 4 [312064/620022]    Loss: 0.010076   Batch Acc: 73.44
[Train] Epoch: 4 [312128/620022]    Loss: 0.011070   Batch Acc: 67.19
[Train] Epoch: 4 [312192/620022]    Loss: 0.006455   Batch Acc: 84.38
[Train] Epoch: 4 [312256/620022]    Loss: 0.006994   Batch Acc: 84.38
[Train] Epoch: 4 [312320/620022]    Loss: 0.010381   Batch Acc: 75.00
[Train] Epoch: 4 [312384/620022]    Loss: 0.008795   Batch Acc: 78.12
[Train] Epoch: 4 [312448/620022]    Loss: 0.008624   Batch Acc: 78.12
[Train] Epoch: 4 [312512/620022]    Loss: 0.008309   Batch Acc: 75.00
[Train] Epoch: 4 [312576/620022]    Loss: 0.007603   Batch Acc: 79.69
[Train] Epoch: 4 [312640/620022]    Loss: 0.009635   Batch Acc: 75.00
[Train] Epoch: 4 [312704/620022]    Loss: 0.007051   Batch Acc: 85.94
[Train] Epoch: 4 [312768/620022]    Loss: 0.009655   Batch Acc: 75.00
[Train] Epoch: 4 [312832/620022]    Loss: 0.008180   Batch Acc: 82.81
[Train] Epoch: 4 [312896/620022]    Loss: 0.007721   Batch Acc: 81.25
[Train] Epoch: 4 [312960/620022]    Loss: 0.008043   Batch Acc: 85.94
[Train] Epoch: 4 [313024/620022]    Loss: 0.009334   Batch Acc: 75.00
[Train] Epoch: 4 [313088/620022]    Loss: 0.007521   Batch Acc: 81.25
[Train] Epoch: 4 [313152/620022]    Loss: 0.009734   Batch Acc: 76.56
[Train] Epoch: 4 [313216/620022]    Loss: 0.008391   Batch Acc: 79.69
[Train] Epoch: 4 [313280/620022]    Loss: 0.007166   Batch Acc: 82.81
[Train] Epoch: 4 [313344/620022]    Loss: 0.009015   Batch Acc: 82.81
[Train] Epoch: 4 [313408/620022]    Loss: 0.008879   Batch Acc: 76.56
[Train] Epoch: 4 [313472/620022]    Loss: 0.011270   Batch Acc: 70.31
[Train] Epoch: 4 [313536/620022]    Loss: 0.007611   Batch Acc: 78.12
[Train] Epoch: 4 [313600/620022]    Loss: 0.009483   Batch Acc: 76.56
[Train] Epoch: 4 [313664/620022]    Loss: 0.010542   Batch Acc: 71.88
[Train] Epoch: 4 [313728/620022]    Loss: 0.005501   Batch Acc: 92.19
[Train] Epoch: 4 [313792/620022]    Loss: 0.009357   Batch Acc: 68.75
[Train] Epoch: 4 [313856/620022]    Loss: 0.009917   Batch Acc: 78.12
[Train] Epoch: 4 [313920/620022]    Loss: 0.007843   Batch Acc: 79.69
[Train] Epoch: 4 [313984/620022]    Loss: 0.007316   Batch Acc: 81.25
[Train] Epoch: 4 [314048/620022]    Loss: 0.006549   Batch Acc: 82.81
[Train] Epoch: 4 [314112/620022]    Loss: 0.008335   Batch Acc: 81.25
[Train] Epoch: 4 [314176/620022]    Loss: 0.010655   Batch Acc: 73.44
[Train] Epoch: 4 [314240/620022]    Loss: 0.010404   Batch Acc: 68.75
[Train] Epoch: 4 [314304/620022]    Loss: 0.007748   Batch Acc: 82.81
[Train] Epoch: 4 [314368/620022]    Loss: 0.008280   Batch Acc: 79.69
[Train] Epoch: 4 [314432/620022]    Loss: 0.007408   Batch Acc: 81.25
[Train] Epoch: 4 [314496/620022]    Loss: 0.005192   Batch Acc: 93.75
[Train] Epoch: 4 [314560/620022]    Loss: 0.010425   Batch Acc: 73.44
[Train] Epoch: 4 [314624/620022]    Loss: 0.010059   Batch Acc: 79.69
[Train] Epoch: 4 [314688/620022]    Loss: 0.009678   Batch Acc: 68.75
[Train] Epoch: 4 [314752/620022]    Loss: 0.010955   Batch Acc: 67.19
[Train] Epoch: 4 [314816/620022]    Loss: 0.008426   Batch Acc: 76.56
[Train] Epoch: 4 [314880/620022]    Loss: 0.009855   Batch Acc: 73.44
[Train] Epoch: 4 [314944/620022]    Loss: 0.007565   Batch Acc: 79.69
[Train] Epoch: 4 [315008/620022]    Loss: 0.008211   Batch Acc: 78.12
[Train] Epoch: 4 [315072/620022]    Loss: 0.009339   Batch Acc: 76.56
[Train] Epoch: 4 [315136/620022]    Loss: 0.008028   Batch Acc: 81.25
[Train] Epoch: 4 [315200/620022]    Loss: 0.008659   Batch Acc: 73.44
[Train] Epoch: 4 [315264/620022]    Loss: 0.007757   Batch Acc: 82.81
[Train] Epoch: 4 [315328/620022]    Loss: 0.008424   Batch Acc: 78.12
[Train] Epoch: 4 [315392/620022]    Loss: 0.010830   Batch Acc: 78.12
[Train] Epoch: 4 [315456/620022]    Loss: 0.008572   Batch Acc: 75.00
[Train] Epoch: 4 [315520/620022]    Loss: 0.010746   Batch Acc: 68.75
[Train] Epoch: 4 [315584/620022]    Loss: 0.009279   Batch Acc: 75.00
[Train] Epoch: 4 [315648/620022]    Loss: 0.009356   Batch Acc: 71.88
[Train] Epoch: 4 [315712/620022]    Loss: 0.008645   Batch Acc: 84.38
[Train] Epoch: 4 [315776/620022]    Loss: 0.008401   Batch Acc: 81.25
[Train] Epoch: 4 [315840/620022]    Loss: 0.007722   Batch Acc: 79.69
[Train] Epoch: 4 [315904/620022]    Loss: 0.009537   Batch Acc: 73.44
[Train] Epoch: 4 [315968/620022]    Loss: 0.008320   Batch Acc: 76.56
[Train] Epoch: 4 [316032/620022]    Loss: 0.007781   Batch Acc: 81.25
[Train] Epoch: 4 [316096/620022]    Loss: 0.009229   Batch Acc: 73.44
[Train] Epoch: 4 [316160/620022]    Loss: 0.009746   Batch Acc: 78.12
[Train] Epoch: 4 [316224/620022]    Loss: 0.008531   Batch Acc: 79.69
[Train] Epoch: 4 [316288/620022]    Loss: 0.008300   Batch Acc: 76.56
[Train] Epoch: 4 [316352/620022]    Loss: 0.011184   Batch Acc: 71.88
[Train] Epoch: 4 [316416/620022]    Loss: 0.007154   Batch Acc: 82.81
[Train] Epoch: 4 [316480/620022]    Loss: 0.007440   Batch Acc: 78.12
[Train] Epoch: 4 [316544/620022]    Loss: 0.009468   Batch Acc: 75.00
[Train] Epoch: 4 [316608/620022]    Loss: 0.010182   Batch Acc: 73.44
[Train] Epoch: 4 [316672/620022]    Loss: 0.008802   Batch Acc: 73.44
[Train] Epoch: 4 [316736/620022]    Loss: 0.008991   Batch Acc: 84.38
[Train] Epoch: 4 [316800/620022]    Loss: 0.008190   Batch Acc: 78.12
[Train] Epoch: 4 [316864/620022]    Loss: 0.008080   Batch Acc: 70.31
[Train] Epoch: 4 [316928/620022]    Loss: 0.009409   Batch Acc: 82.81
[Train] Epoch: 4 [316992/620022]    Loss: 0.009373   Batch Acc: 73.44
[Train] Epoch: 4 [317056/620022]    Loss: 0.009819   Batch Acc: 82.81
[Train] Epoch: 4 [317120/620022]    Loss: 0.008059   Batch Acc: 79.69
[Train] Epoch: 4 [317184/620022]    Loss: 0.009366   Batch Acc: 78.12
[Train] Epoch: 4 [317248/620022]    Loss: 0.007764   Batch Acc: 82.81
[Train] Epoch: 4 [317312/620022]    Loss: 0.008285   Batch Acc: 73.44
[Train] Epoch: 4 [317376/620022]    Loss: 0.010827   Batch Acc: 76.56
[Train] Epoch: 4 [317440/620022]    Loss: 0.006847   Batch Acc: 85.94
[Train] Epoch: 4 [317504/620022]    Loss: 0.008370   Batch Acc: 82.81
[Train] Epoch: 4 [317568/620022]    Loss: 0.009039   Batch Acc: 73.44
[Train] Epoch: 4 [317632/620022]    Loss: 0.009134   Batch Acc: 79.69
[Train] Epoch: 4 [317696/620022]    Loss: 0.006758   Batch Acc: 84.38
[Train] Epoch: 4 [317760/620022]    Loss: 0.008521   Batch Acc: 76.56
[Train] Epoch: 4 [317824/620022]    Loss: 0.009043   Batch Acc: 76.56
[Train] Epoch: 4 [317888/620022]    Loss: 0.010173   Batch Acc: 71.88
[Train] Epoch: 4 [317952/620022]    Loss: 0.011004   Batch Acc: 67.19
[Train] Epoch: 4 [318016/620022]    Loss: 0.009562   Batch Acc: 71.88
[Train] Epoch: 4 [318080/620022]    Loss: 0.008543   Batch Acc: 76.56
[Train] Epoch: 4 [318144/620022]    Loss: 0.007877   Batch Acc: 82.81
[Train] Epoch: 4 [318208/620022]    Loss: 0.006569   Batch Acc: 87.50
[Train] Epoch: 4 [318272/620022]    Loss: 0.007087   Batch Acc: 81.25
[Train] Epoch: 4 [318336/620022]    Loss: 0.006903   Batch Acc: 82.81
[Train] Epoch: 4 [318400/620022]    Loss: 0.005920   Batch Acc: 87.50
[Train] Epoch: 4 [318464/620022]    Loss: 0.005815   Batch Acc: 85.94
[Train] Epoch: 4 [318528/620022]    Loss: 0.008304   Batch Acc: 79.69
[Train] Epoch: 4 [318592/620022]    Loss: 0.007105   Batch Acc: 84.38
[Train] Epoch: 4 [318656/620022]    Loss: 0.009075   Batch Acc: 78.12
[Train] Epoch: 4 [318720/620022]    Loss: 0.008574   Batch Acc: 78.12
[Train] Epoch: 4 [318784/620022]    Loss: 0.009676   Batch Acc: 76.56
[Train] Epoch: 4 [318848/620022]    Loss: 0.007991   Batch Acc: 78.12
[Train] Epoch: 4 [318912/620022]    Loss: 0.010509   Batch Acc: 73.44
[Train] Epoch: 4 [318976/620022]    Loss: 0.008300   Batch Acc: 73.44
[Train] Epoch: 4 [319040/620022]    Loss: 0.007819   Batch Acc: 79.69
[Train] Epoch: 4 [319104/620022]    Loss: 0.007249   Batch Acc: 85.94
[Train] Epoch: 4 [319168/620022]    Loss: 0.010067   Batch Acc: 78.12
[Train] Epoch: 4 [319232/620022]    Loss: 0.009247   Batch Acc: 76.56
[Train] Epoch: 4 [319296/620022]    Loss: 0.009764   Batch Acc: 68.75
[Train] Epoch: 4 [319360/620022]    Loss: 0.010658   Batch Acc: 81.25
[Train] Epoch: 4 [319424/620022]    Loss: 0.009896   Batch Acc: 75.00
[Train] Epoch: 4 [319488/620022]    Loss: 0.006859   Batch Acc: 82.81
[Train] Epoch: 4 [319552/620022]    Loss: 0.008512   Batch Acc: 75.00
[Train] Epoch: 4 [319616/620022]    Loss: 0.007229   Batch Acc: 79.69
[Train] Epoch: 4 [319680/620022]    Loss: 0.009248   Batch Acc: 71.88
[Train] Epoch: 4 [319744/620022]    Loss: 0.008734   Batch Acc: 78.12
[Train] Epoch: 4 [319808/620022]    Loss: 0.006632   Batch Acc: 85.94
[Train] Epoch: 4 [319872/620022]    Loss: 0.007677   Batch Acc: 81.25
[Train] Epoch: 4 [319936/620022]    Loss: 0.008528   Batch Acc: 70.31
[Train] Epoch: 4 [320000/620022]    Loss: 0.009219   Batch Acc: 82.81
[Train] Epoch: 4 [320064/620022]    Loss: 0.011497   Batch Acc: 70.31
[Train] Epoch: 4 [320128/620022]    Loss: 0.006426   Batch Acc: 85.94
[Train] Epoch: 4 [320192/620022]    Loss: 0.009424   Batch Acc: 73.44
[Train] Epoch: 4 [320256/620022]    Loss: 0.011155   Batch Acc: 71.88
[Train] Epoch: 4 [320320/620022]    Loss: 0.007699   Batch Acc: 76.56
[Train] Epoch: 4 [320384/620022]    Loss: 0.007972   Batch Acc: 79.69
[Train] Epoch: 4 [320448/620022]    Loss: 0.010202   Batch Acc: 78.12
[Train] Epoch: 4 [320512/620022]    Loss: 0.006920   Batch Acc: 79.69
[Train] Epoch: 4 [320576/620022]    Loss: 0.008242   Batch Acc: 79.69
[Train] Epoch: 4 [320640/620022]    Loss: 0.008987   Batch Acc: 78.12
[Train] Epoch: 4 [320704/620022]    Loss: 0.009991   Batch Acc: 76.56
[Train] Epoch: 4 [320768/620022]    Loss: 0.009485   Batch Acc: 81.25
[Train] Epoch: 4 [320832/620022]    Loss: 0.006396   Batch Acc: 79.69
[Train] Epoch: 4 [320896/620022]    Loss: 0.007780   Batch Acc: 81.25
[Train] Epoch: 4 [320960/620022]    Loss: 0.007350   Batch Acc: 81.25
[Train] Epoch: 4 [321024/620022]    Loss: 0.007208   Batch Acc: 84.38
[Train] Epoch: 4 [321088/620022]    Loss: 0.007529   Batch Acc: 84.38
[Train] Epoch: 4 [321152/620022]    Loss: 0.007761   Batch Acc: 84.38
[Train] Epoch: 4 [321216/620022]    Loss: 0.006780   Batch Acc: 82.81
[Train] Epoch: 4 [321280/620022]    Loss: 0.007403   Batch Acc: 84.38
[Train] Epoch: 4 [321344/620022]    Loss: 0.008554   Batch Acc: 78.12
[Train] Epoch: 4 [321408/620022]    Loss: 0.011043   Batch Acc: 67.19
[Train] Epoch: 4 [321472/620022]    Loss: 0.010515   Batch Acc: 70.31
[Train] Epoch: 4 [321536/620022]    Loss: 0.010195   Batch Acc: 79.69
[Train] Epoch: 4 [321600/620022]    Loss: 0.011540   Batch Acc: 68.75
[Train] Epoch: 4 [321664/620022]    Loss: 0.010491   Batch Acc: 76.56
[Train] Epoch: 4 [321728/620022]    Loss: 0.009340   Batch Acc: 79.69
[Train] Epoch: 4 [321792/620022]    Loss: 0.008390   Batch Acc: 81.25
[Train] Epoch: 4 [321856/620022]    Loss: 0.009444   Batch Acc: 68.75
[Train] Epoch: 4 [321920/620022]    Loss: 0.007034   Batch Acc: 81.25
[Train] Epoch: 4 [321984/620022]    Loss: 0.011212   Batch Acc: 65.62
[Train] Epoch: 4 [322048/620022]    Loss: 0.011618   Batch Acc: 67.19
[Train] Epoch: 4 [322112/620022]    Loss: 0.009982   Batch Acc: 75.00
[Train] Epoch: 4 [322176/620022]    Loss: 0.009164   Batch Acc: 73.44
[Train] Epoch: 4 [322240/620022]    Loss: 0.009783   Batch Acc: 68.75
[Train] Epoch: 4 [322304/620022]    Loss: 0.008955   Batch Acc: 75.00
[Train] Epoch: 4 [322368/620022]    Loss: 0.007162   Batch Acc: 82.81
[Train] Epoch: 4 [322432/620022]    Loss: 0.007818   Batch Acc: 79.69
[Train] Epoch: 4 [322496/620022]    Loss: 0.007389   Batch Acc: 82.81
[Train] Epoch: 4 [322560/620022]    Loss: 0.006993   Batch Acc: 89.06
[Train] Epoch: 4 [322624/620022]    Loss: 0.008318   Batch Acc: 71.88
[Train] Epoch: 4 [322688/620022]    Loss: 0.012976   Batch Acc: 68.75
[Train] Epoch: 4 [322752/620022]    Loss: 0.009558   Batch Acc: 73.44
[Train] Epoch: 4 [322816/620022]    Loss: 0.009996   Batch Acc: 70.31
[Train] Epoch: 4 [322880/620022]    Loss: 0.009392   Batch Acc: 76.56
[Train] Epoch: 4 [322944/620022]    Loss: 0.008226   Batch Acc: 78.12
[Train] Epoch: 4 [323008/620022]    Loss: 0.006470   Batch Acc: 85.94
[Train] Epoch: 4 [323072/620022]    Loss: 0.010730   Batch Acc: 70.31
[Train] Epoch: 4 [323136/620022]    Loss: 0.008973   Batch Acc: 76.56
[Train] Epoch: 4 [323200/620022]    Loss: 0.008601   Batch Acc: 78.12
[Train] Epoch: 4 [323264/620022]    Loss: 0.010455   Batch Acc: 73.44
[Train] Epoch: 4 [323328/620022]    Loss: 0.010520   Batch Acc: 73.44
[Train] Epoch: 4 [323392/620022]    Loss: 0.008392   Batch Acc: 75.00
[Train] Epoch: 4 [323456/620022]    Loss: 0.008821   Batch Acc: 71.88
[Train] Epoch: 4 [323520/620022]    Loss: 0.008056   Batch Acc: 79.69
[Train] Epoch: 4 [323584/620022]    Loss: 0.007925   Batch Acc: 84.38
[Train] Epoch: 4 [323648/620022]    Loss: 0.007771   Batch Acc: 82.81
[Train] Epoch: 4 [323712/620022]    Loss: 0.007952   Batch Acc: 82.81
[Train] Epoch: 4 [323776/620022]    Loss: 0.006437   Batch Acc: 85.94
[Train] Epoch: 4 [323840/620022]    Loss: 0.009126   Batch Acc: 76.56
[Train] Epoch: 4 [323904/620022]    Loss: 0.008378   Batch Acc: 81.25
[Train] Epoch: 4 [323968/620022]    Loss: 0.006810   Batch Acc: 81.25
[Train] Epoch: 4 [324032/620022]    Loss: 0.006368   Batch Acc: 84.38
[Train] Epoch: 4 [324096/620022]    Loss: 0.008924   Batch Acc: 78.12
[Train] Epoch: 4 [324160/620022]    Loss: 0.010971   Batch Acc: 73.44
[Train] Epoch: 4 [324224/620022]    Loss: 0.010307   Batch Acc: 73.44
[Train] Epoch: 4 [324288/620022]    Loss: 0.009317   Batch Acc: 70.31
[Train] Epoch: 4 [324352/620022]    Loss: 0.009930   Batch Acc: 75.00
[Train] Epoch: 4 [324416/620022]    Loss: 0.007035   Batch Acc: 87.50
[Train] Epoch: 4 [324480/620022]    Loss: 0.006591   Batch Acc: 87.50
[Train] Epoch: 4 [324544/620022]    Loss: 0.007054   Batch Acc: 84.38
[Train] Epoch: 4 [324608/620022]    Loss: 0.008364   Batch Acc: 78.12
[Train] Epoch: 4 [324672/620022]    Loss: 0.007981   Batch Acc: 84.38
[Train] Epoch: 4 [324736/620022]    Loss: 0.009353   Batch Acc: 78.12
[Train] Epoch: 4 [324800/620022]    Loss: 0.010113   Batch Acc: 73.44
[Train] Epoch: 4 [324864/620022]    Loss: 0.008428   Batch Acc: 78.12
[Train] Epoch: 4 [324928/620022]    Loss: 0.009323   Batch Acc: 71.88
[Train] Epoch: 4 [324992/620022]    Loss: 0.008330   Batch Acc: 78.12
[Train] Epoch: 4 [325056/620022]    Loss: 0.007499   Batch Acc: 78.12
[Train] Epoch: 4 [325120/620022]    Loss: 0.011329   Batch Acc: 60.94
[Train] Epoch: 4 [325184/620022]    Loss: 0.007413   Batch Acc: 79.69
[Train] Epoch: 4 [325248/620022]    Loss: 0.008803   Batch Acc: 79.69
[Train] Epoch: 4 [325312/620022]    Loss: 0.008688   Batch Acc: 73.44
[Train] Epoch: 4 [325376/620022]    Loss: 0.009115   Batch Acc: 75.00
[Train] Epoch: 4 [325440/620022]    Loss: 0.009354   Batch Acc: 75.00
[Train] Epoch: 4 [325504/620022]    Loss: 0.009188   Batch Acc: 76.56
[Train] Epoch: 4 [325568/620022]    Loss: 0.011815   Batch Acc: 71.88
[Train] Epoch: 4 [325632/620022]    Loss: 0.008457   Batch Acc: 79.69
[Train] Epoch: 4 [325696/620022]    Loss: 0.010479   Batch Acc: 76.56
[Train] Epoch: 4 [325760/620022]    Loss: 0.009548   Batch Acc: 75.00
[Train] Epoch: 4 [325824/620022]    Loss: 0.008970   Batch Acc: 76.56
[Train] Epoch: 4 [325888/620022]    Loss: 0.007619   Batch Acc: 82.81
[Train] Epoch: 4 [325952/620022]    Loss: 0.009476   Batch Acc: 78.12
[Train] Epoch: 4 [326016/620022]    Loss: 0.008621   Batch Acc: 81.25
[Train] Epoch: 4 [326080/620022]    Loss: 0.010483   Batch Acc: 73.44
[Train] Epoch: 4 [326144/620022]    Loss: 0.009397   Batch Acc: 76.56
[Train] Epoch: 4 [326208/620022]    Loss: 0.006627   Batch Acc: 81.25
[Train] Epoch: 4 [326272/620022]    Loss: 0.008485   Batch Acc: 82.81
[Train] Epoch: 4 [326336/620022]    Loss: 0.010172   Batch Acc: 73.44
[Train] Epoch: 4 [326400/620022]    Loss: 0.008665   Batch Acc: 70.31
[Train] Epoch: 4 [326464/620022]    Loss: 0.008697   Batch Acc: 68.75
[Train] Epoch: 4 [326528/620022]    Loss: 0.008490   Batch Acc: 81.25
[Train] Epoch: 4 [326592/620022]    Loss: 0.010755   Batch Acc: 70.31
[Train] Epoch: 4 [326656/620022]    Loss: 0.008416   Batch Acc: 79.69
[Train] Epoch: 4 [326720/620022]    Loss: 0.007221   Batch Acc: 84.38
[Train] Epoch: 4 [326784/620022]    Loss: 0.008835   Batch Acc: 79.69
[Train] Epoch: 4 [326848/620022]    Loss: 0.008744   Batch Acc: 73.44
[Train] Epoch: 4 [326912/620022]    Loss: 0.006968   Batch Acc: 81.25
[Train] Epoch: 4 [326976/620022]    Loss: 0.008088   Batch Acc: 81.25
[Train] Epoch: 4 [327040/620022]    Loss: 0.009225   Batch Acc: 79.69
[Train] Epoch: 4 [327104/620022]    Loss: 0.010338   Batch Acc: 71.88
[Train] Epoch: 4 [327168/620022]    Loss: 0.011531   Batch Acc: 70.31
[Train] Epoch: 4 [327232/620022]    Loss: 0.007323   Batch Acc: 89.06
[Train] Epoch: 4 [327296/620022]    Loss: 0.009921   Batch Acc: 75.00
[Train] Epoch: 4 [327360/620022]    Loss: 0.009046   Batch Acc: 79.69
[Train] Epoch: 4 [327424/620022]    Loss: 0.007991   Batch Acc: 79.69
[Train] Epoch: 4 [327488/620022]    Loss: 0.008108   Batch Acc: 79.69
[Train] Epoch: 4 [327552/620022]    Loss: 0.008213   Batch Acc: 78.12
[Train] Epoch: 4 [327616/620022]    Loss: 0.009324   Batch Acc: 75.00
[Train] Epoch: 4 [327680/620022]    Loss: 0.010051   Batch Acc: 70.31
[Train] Epoch: 4 [327744/620022]    Loss: 0.009585   Batch Acc: 73.44
[Train] Epoch: 4 [327808/620022]    Loss: 0.009737   Batch Acc: 68.75
[Train] Epoch: 4 [327872/620022]    Loss: 0.008406   Batch Acc: 78.12
[Train] Epoch: 4 [327936/620022]    Loss: 0.007166   Batch Acc: 79.69
[Train] Epoch: 4 [328000/620022]    Loss: 0.008511   Batch Acc: 81.25
[Train] Epoch: 4 [328064/620022]    Loss: 0.007569   Batch Acc: 79.69
[Train] Epoch: 4 [328128/620022]    Loss: 0.008936   Batch Acc: 76.56
[Train] Epoch: 4 [328192/620022]    Loss: 0.008420   Batch Acc: 75.00
[Train] Epoch: 4 [328256/620022]    Loss: 0.008880   Batch Acc: 82.81
[Train] Epoch: 4 [328320/620022]    Loss: 0.008974   Batch Acc: 76.56
[Train] Epoch: 4 [328384/620022]    Loss: 0.007831   Batch Acc: 79.69
[Train] Epoch: 4 [328448/620022]    Loss: 0.009657   Batch Acc: 73.44
[Train] Epoch: 4 [328512/620022]    Loss: 0.008166   Batch Acc: 82.81
[Train] Epoch: 4 [328576/620022]    Loss: 0.008131   Batch Acc: 76.56
[Train] Epoch: 4 [328640/620022]    Loss: 0.007566   Batch Acc: 81.25
[Train] Epoch: 4 [328704/620022]    Loss: 0.008054   Batch Acc: 81.25
[Train] Epoch: 4 [328768/620022]    Loss: 0.009721   Batch Acc: 75.00
[Train] Epoch: 4 [328832/620022]    Loss: 0.008633   Batch Acc: 75.00
[Train] Epoch: 4 [328896/620022]    Loss: 0.011771   Batch Acc: 68.75
[Train] Epoch: 4 [328960/620022]    Loss: 0.009931   Batch Acc: 84.38
[Train] Epoch: 4 [329024/620022]    Loss: 0.007148   Batch Acc: 82.81
[Train] Epoch: 4 [329088/620022]    Loss: 0.011198   Batch Acc: 70.31
[Train] Epoch: 4 [329152/620022]    Loss: 0.011024   Batch Acc: 73.44
[Train] Epoch: 4 [329216/620022]    Loss: 0.006112   Batch Acc: 85.94
[Train] Epoch: 4 [329280/620022]    Loss: 0.009194   Batch Acc: 78.12
[Train] Epoch: 4 [329344/620022]    Loss: 0.005376   Batch Acc: 90.62
[Train] Epoch: 4 [329408/620022]    Loss: 0.011165   Batch Acc: 71.88
[Train] Epoch: 4 [329472/620022]    Loss: 0.008457   Batch Acc: 76.56
[Train] Epoch: 4 [329536/620022]    Loss: 0.011229   Batch Acc: 67.19
[Train] Epoch: 4 [329600/620022]    Loss: 0.007818   Batch Acc: 78.12
[Train] Epoch: 4 [329664/620022]    Loss: 0.010540   Batch Acc: 67.19
[Train] Epoch: 4 [329728/620022]    Loss: 0.008493   Batch Acc: 79.69
[Train] Epoch: 4 [329792/620022]    Loss: 0.007904   Batch Acc: 81.25
[Train] Epoch: 4 [329856/620022]    Loss: 0.008741   Batch Acc: 81.25
[Train] Epoch: 4 [329920/620022]    Loss: 0.008071   Batch Acc: 79.69
[Train] Epoch: 4 [329984/620022]    Loss: 0.008196   Batch Acc: 78.12
[Train] Epoch: 4 [330048/620022]    Loss: 0.009807   Batch Acc: 76.56
[Train] Epoch: 4 [330112/620022]    Loss: 0.010582   Batch Acc: 75.00
[Train] Epoch: 4 [330176/620022]    Loss: 0.007242   Batch Acc: 85.94
[Train] Epoch: 4 [330240/620022]    Loss: 0.008161   Batch Acc: 81.25
[Train] Epoch: 4 [330304/620022]    Loss: 0.009048   Batch Acc: 79.69
[Train] Epoch: 4 [330368/620022]    Loss: 0.009769   Batch Acc: 75.00
[Train] Epoch: 4 [330432/620022]    Loss: 0.006744   Batch Acc: 89.06
[Train] Epoch: 4 [330496/620022]    Loss: 0.008071   Batch Acc: 78.12
[Train] Epoch: 4 [330560/620022]    Loss: 0.009342   Batch Acc: 70.31
[Train] Epoch: 4 [330624/620022]    Loss: 0.007895   Batch Acc: 82.81
[Train] Epoch: 4 [330688/620022]    Loss: 0.006647   Batch Acc: 90.62
[Train] Epoch: 4 [330752/620022]    Loss: 0.007573   Batch Acc: 81.25
[Train] Epoch: 4 [330816/620022]    Loss: 0.008390   Batch Acc: 79.69
[Train] Epoch: 4 [330880/620022]    Loss: 0.008678   Batch Acc: 78.12
[Train] Epoch: 4 [330944/620022]    Loss: 0.006563   Batch Acc: 85.94
[Train] Epoch: 4 [331008/620022]    Loss: 0.007978   Batch Acc: 81.25
[Train] Epoch: 4 [331072/620022]    Loss: 0.009674   Batch Acc: 73.44
[Train] Epoch: 4 [331136/620022]    Loss: 0.008446   Batch Acc: 82.81
[Train] Epoch: 4 [331200/620022]    Loss: 0.007494   Batch Acc: 82.81
[Train] Epoch: 4 [331264/620022]    Loss: 0.008361   Batch Acc: 79.69
[Train] Epoch: 4 [331328/620022]    Loss: 0.007384   Batch Acc: 82.81
[Train] Epoch: 4 [331392/620022]    Loss: 0.008220   Batch Acc: 79.69
[Train] Epoch: 4 [331456/620022]    Loss: 0.006795   Batch Acc: 79.69
[Train] Epoch: 4 [331520/620022]    Loss: 0.007908   Batch Acc: 82.81
[Train] Epoch: 4 [331584/620022]    Loss: 0.009230   Batch Acc: 71.88
[Train] Epoch: 4 [331648/620022]    Loss: 0.007439   Batch Acc: 82.81
[Train] Epoch: 4 [331712/620022]    Loss: 0.008485   Batch Acc: 82.81
[Train] Epoch: 4 [331776/620022]    Loss: 0.005620   Batch Acc: 92.19
[Train] Epoch: 4 [331840/620022]    Loss: 0.009895   Batch Acc: 67.19
[Train] Epoch: 4 [331904/620022]    Loss: 0.007743   Batch Acc: 82.81
[Train] Epoch: 4 [331968/620022]    Loss: 0.010329   Batch Acc: 70.31
[Train] Epoch: 4 [332032/620022]    Loss: 0.007402   Batch Acc: 82.81
[Train] Epoch: 4 [332096/620022]    Loss: 0.014106   Batch Acc: 62.50
[Train] Epoch: 4 [332160/620022]    Loss: 0.010611   Batch Acc: 70.31
[Train] Epoch: 4 [332224/620022]    Loss: 0.009200   Batch Acc: 71.88
[Train] Epoch: 4 [332288/620022]    Loss: 0.012143   Batch Acc: 70.31
[Train] Epoch: 4 [332352/620022]    Loss: 0.009173   Batch Acc: 79.69
[Train] Epoch: 4 [332416/620022]    Loss: 0.006721   Batch Acc: 81.25
[Train] Epoch: 4 [332480/620022]    Loss: 0.009826   Batch Acc: 65.62
[Train] Epoch: 4 [332544/620022]    Loss: 0.008039   Batch Acc: 79.69
[Train] Epoch: 4 [332608/620022]    Loss: 0.008405   Batch Acc: 75.00
[Train] Epoch: 4 [332672/620022]    Loss: 0.009114   Batch Acc: 78.12
[Train] Epoch: 4 [332736/620022]    Loss: 0.010414   Batch Acc: 73.44
[Train] Epoch: 4 [332800/620022]    Loss: 0.012280   Batch Acc: 64.06
[Train] Epoch: 4 [332864/620022]    Loss: 0.008268   Batch Acc: 78.12
[Train] Epoch: 4 [332928/620022]    Loss: 0.007582   Batch Acc: 84.38
[Train] Epoch: 4 [332992/620022]    Loss: 0.008493   Batch Acc: 79.69
[Train] Epoch: 4 [333056/620022]    Loss: 0.007586   Batch Acc: 81.25
[Train] Epoch: 4 [333120/620022]    Loss: 0.007715   Batch Acc: 78.12
[Train] Epoch: 4 [333184/620022]    Loss: 0.007930   Batch Acc: 78.12
[Train] Epoch: 4 [333248/620022]    Loss: 0.008144   Batch Acc: 85.94
[Train] Epoch: 4 [333312/620022]    Loss: 0.009711   Batch Acc: 65.62
[Train] Epoch: 4 [333376/620022]    Loss: 0.007738   Batch Acc: 84.38
[Train] Epoch: 4 [333440/620022]    Loss: 0.008536   Batch Acc: 79.69
[Train] Epoch: 4 [333504/620022]    Loss: 0.009982   Batch Acc: 73.44
[Train] Epoch: 4 [333568/620022]    Loss: 0.007045   Batch Acc: 82.81
[Train] Epoch: 4 [333632/620022]    Loss: 0.008331   Batch Acc: 82.81
[Train] Epoch: 4 [333696/620022]    Loss: 0.009730   Batch Acc: 76.56
[Train] Epoch: 4 [333760/620022]    Loss: 0.009317   Batch Acc: 76.56
[Train] Epoch: 4 [333824/620022]    Loss: 0.008519   Batch Acc: 76.56
[Train] Epoch: 4 [333888/620022]    Loss: 0.008088   Batch Acc: 75.00
[Train] Epoch: 4 [333952/620022]    Loss: 0.007703   Batch Acc: 84.38
[Train] Epoch: 4 [334016/620022]    Loss: 0.007891   Batch Acc: 78.12
[Train] Epoch: 4 [334080/620022]    Loss: 0.008818   Batch Acc: 75.00
[Train] Epoch: 4 [334144/620022]    Loss: 0.007640   Batch Acc: 84.38
[Train] Epoch: 4 [334208/620022]    Loss: 0.008037   Batch Acc: 78.12
[Train] Epoch: 4 [334272/620022]    Loss: 0.008016   Batch Acc: 79.69
[Train] Epoch: 4 [334336/620022]    Loss: 0.007823   Batch Acc: 78.12
[Train] Epoch: 4 [334400/620022]    Loss: 0.008572   Batch Acc: 79.69
[Train] Epoch: 4 [334464/620022]    Loss: 0.005666   Batch Acc: 92.19
[Train] Epoch: 4 [334528/620022]    Loss: 0.008104   Batch Acc: 79.69
[Train] Epoch: 4 [334592/620022]    Loss: 0.007506   Batch Acc: 78.12
[Train] Epoch: 4 [334656/620022]    Loss: 0.009782   Batch Acc: 68.75
[Train] Epoch: 4 [334720/620022]    Loss: 0.009587   Batch Acc: 78.12
[Train] Epoch: 4 [334784/620022]    Loss: 0.008497   Batch Acc: 75.00
[Train] Epoch: 4 [334848/620022]    Loss: 0.007911   Batch Acc: 84.38
[Train] Epoch: 4 [334912/620022]    Loss: 0.007616   Batch Acc: 82.81
[Train] Epoch: 4 [334976/620022]    Loss: 0.010133   Batch Acc: 73.44
[Train] Epoch: 4 [335040/620022]    Loss: 0.009895   Batch Acc: 71.88
[Train] Epoch: 4 [335104/620022]    Loss: 0.008172   Batch Acc: 82.81
[Train] Epoch: 4 [335168/620022]    Loss: 0.010801   Batch Acc: 62.50
[Train] Epoch: 4 [335232/620022]    Loss: 0.009590   Batch Acc: 75.00
[Train] Epoch: 4 [335296/620022]    Loss: 0.010038   Batch Acc: 82.81
[Train] Epoch: 4 [335360/620022]    Loss: 0.008155   Batch Acc: 81.25
[Train] Epoch: 4 [335424/620022]    Loss: 0.009374   Batch Acc: 76.56
[Train] Epoch: 4 [335488/620022]    Loss: 0.010137   Batch Acc: 73.44
[Train] Epoch: 4 [335552/620022]    Loss: 0.008066   Batch Acc: 81.25
[Train] Epoch: 4 [335616/620022]    Loss: 0.006196   Batch Acc: 87.50
[Train] Epoch: 4 [335680/620022]    Loss: 0.008075   Batch Acc: 75.00
[Train] Epoch: 4 [335744/620022]    Loss: 0.009255   Batch Acc: 73.44
[Train] Epoch: 4 [335808/620022]    Loss: 0.009324   Batch Acc: 82.81
[Train] Epoch: 4 [335872/620022]    Loss: 0.008503   Batch Acc: 73.44
[Train] Epoch: 4 [335936/620022]    Loss: 0.010074   Batch Acc: 76.56
[Train] Epoch: 4 [336000/620022]    Loss: 0.007884   Batch Acc: 84.38
[Train] Epoch: 4 [336064/620022]    Loss: 0.009180   Batch Acc: 78.12
[Train] Epoch: 4 [336128/620022]    Loss: 0.008286   Batch Acc: 81.25
[Train] Epoch: 4 [336192/620022]    Loss: 0.008042   Batch Acc: 78.12
[Train] Epoch: 4 [336256/620022]    Loss: 0.010078   Batch Acc: 71.88
[Train] Epoch: 4 [336320/620022]    Loss: 0.009168   Batch Acc: 79.69
[Train] Epoch: 4 [336384/620022]    Loss: 0.007100   Batch Acc: 82.81
[Train] Epoch: 4 [336448/620022]    Loss: 0.009453   Batch Acc: 79.69
[Train] Epoch: 4 [336512/620022]    Loss: 0.009684   Batch Acc: 75.00
[Train] Epoch: 4 [336576/620022]    Loss: 0.008158   Batch Acc: 75.00
[Train] Epoch: 4 [336640/620022]    Loss: 0.008134   Batch Acc: 84.38
[Train] Epoch: 4 [336704/620022]    Loss: 0.008547   Batch Acc: 78.12
[Train] Epoch: 4 [336768/620022]    Loss: 0.006986   Batch Acc: 82.81
[Train] Epoch: 4 [336832/620022]    Loss: 0.009700   Batch Acc: 79.69
[Train] Epoch: 4 [336896/620022]    Loss: 0.010165   Batch Acc: 73.44
[Train] Epoch: 4 [336960/620022]    Loss: 0.006867   Batch Acc: 82.81
[Train] Epoch: 4 [337024/620022]    Loss: 0.009777   Batch Acc: 78.12
[Train] Epoch: 4 [337088/620022]    Loss: 0.007295   Batch Acc: 81.25
[Train] Epoch: 4 [337152/620022]    Loss: 0.007000   Batch Acc: 79.69
[Train] Epoch: 4 [337216/620022]    Loss: 0.006619   Batch Acc: 87.50
[Train] Epoch: 4 [337280/620022]    Loss: 0.008002   Batch Acc: 78.12
[Train] Epoch: 4 [337344/620022]    Loss: 0.007843   Batch Acc: 82.81
[Train] Epoch: 4 [337408/620022]    Loss: 0.007993   Batch Acc: 75.00
[Train] Epoch: 4 [337472/620022]    Loss: 0.010476   Batch Acc: 75.00
[Train] Epoch: 4 [337536/620022]    Loss: 0.006853   Batch Acc: 85.94
[Train] Epoch: 4 [337600/620022]    Loss: 0.008176   Batch Acc: 75.00
[Train] Epoch: 4 [337664/620022]    Loss: 0.007514   Batch Acc: 79.69
[Train] Epoch: 4 [337728/620022]    Loss: 0.006982   Batch Acc: 81.25
[Train] Epoch: 4 [337792/620022]    Loss: 0.009348   Batch Acc: 79.69
[Train] Epoch: 4 [337856/620022]    Loss: 0.008705   Batch Acc: 81.25
[Train] Epoch: 4 [337920/620022]    Loss: 0.007412   Batch Acc: 82.81
[Train] Epoch: 4 [337984/620022]    Loss: 0.010048   Batch Acc: 71.88
[Train] Epoch: 4 [338048/620022]    Loss: 0.009427   Batch Acc: 78.12
[Train] Epoch: 4 [338112/620022]    Loss: 0.007278   Batch Acc: 79.69
[Train] Epoch: 4 [338176/620022]    Loss: 0.006968   Batch Acc: 82.81
[Train] Epoch: 4 [338240/620022]    Loss: 0.008657   Batch Acc: 82.81
[Train] Epoch: 4 [338304/620022]    Loss: 0.007845   Batch Acc: 81.25
[Train] Epoch: 4 [338368/620022]    Loss: 0.010166   Batch Acc: 76.56
[Train] Epoch: 4 [338432/620022]    Loss: 0.008472   Batch Acc: 79.69
[Train] Epoch: 4 [338496/620022]    Loss: 0.010791   Batch Acc: 73.44
[Train] Epoch: 4 [338560/620022]    Loss: 0.009653   Batch Acc: 73.44
[Train] Epoch: 4 [338624/620022]    Loss: 0.009949   Batch Acc: 79.69
[Train] Epoch: 4 [338688/620022]    Loss: 0.008284   Batch Acc: 78.12
[Train] Epoch: 4 [338752/620022]    Loss: 0.011225   Batch Acc: 70.31
[Train] Epoch: 4 [338816/620022]    Loss: 0.007793   Batch Acc: 79.69
[Train] Epoch: 4 [338880/620022]    Loss: 0.008467   Batch Acc: 78.12
[Train] Epoch: 4 [338944/620022]    Loss: 0.009938   Batch Acc: 75.00
[Train] Epoch: 4 [339008/620022]    Loss: 0.008203   Batch Acc: 75.00
[Train] Epoch: 4 [339072/620022]    Loss: 0.008255   Batch Acc: 75.00
[Train] Epoch: 4 [339136/620022]    Loss: 0.008750   Batch Acc: 79.69
[Train] Epoch: 4 [339200/620022]    Loss: 0.010675   Batch Acc: 68.75
[Train] Epoch: 4 [339264/620022]    Loss: 0.006853   Batch Acc: 84.38
[Train] Epoch: 4 [339328/620022]    Loss: 0.006621   Batch Acc: 81.25
[Train] Epoch: 4 [339392/620022]    Loss: 0.008189   Batch Acc: 78.12
[Train] Epoch: 4 [339456/620022]    Loss: 0.008300   Batch Acc: 84.38
[Train] Epoch: 4 [339520/620022]    Loss: 0.007563   Batch Acc: 76.56
[Train] Epoch: 4 [339584/620022]    Loss: 0.007649   Batch Acc: 73.44
[Train] Epoch: 4 [339648/620022]    Loss: 0.008324   Batch Acc: 75.00
[Train] Epoch: 4 [339712/620022]    Loss: 0.008858   Batch Acc: 79.69
[Train] Epoch: 4 [339776/620022]    Loss: 0.009216   Batch Acc: 78.12
[Train] Epoch: 4 [339840/620022]    Loss: 0.007208   Batch Acc: 82.81
[Train] Epoch: 4 [339904/620022]    Loss: 0.009693   Batch Acc: 73.44
[Train] Epoch: 4 [339968/620022]    Loss: 0.010205   Batch Acc: 75.00
[Train] Epoch: 4 [340032/620022]    Loss: 0.010216   Batch Acc: 73.44
[Train] Epoch: 4 [340096/620022]    Loss: 0.009086   Batch Acc: 75.00
[Train] Epoch: 4 [340160/620022]    Loss: 0.007076   Batch Acc: 76.56
[Train] Epoch: 4 [340224/620022]    Loss: 0.008304   Batch Acc: 78.12
[Train] Epoch: 4 [340288/620022]    Loss: 0.007170   Batch Acc: 84.38
[Train] Epoch: 4 [340352/620022]    Loss: 0.007330   Batch Acc: 81.25
[Train] Epoch: 4 [340416/620022]    Loss: 0.008500   Batch Acc: 78.12
[Train] Epoch: 4 [340480/620022]    Loss: 0.010026   Batch Acc: 71.88
[Train] Epoch: 4 [340544/620022]    Loss: 0.009355   Batch Acc: 71.88
[Train] Epoch: 4 [340608/620022]    Loss: 0.009111   Batch Acc: 76.56
[Train] Epoch: 4 [340672/620022]    Loss: 0.007283   Batch Acc: 85.94
[Train] Epoch: 4 [340736/620022]    Loss: 0.007000   Batch Acc: 82.81
[Train] Epoch: 4 [340800/620022]    Loss: 0.007193   Batch Acc: 84.38
[Train] Epoch: 4 [340864/620022]    Loss: 0.009182   Batch Acc: 75.00
[Train] Epoch: 4 [340928/620022]    Loss: 0.008799   Batch Acc: 76.56
[Train] Epoch: 4 [340992/620022]    Loss: 0.007565   Batch Acc: 81.25
[Train] Epoch: 4 [341056/620022]    Loss: 0.010042   Batch Acc: 71.88
[Train] Epoch: 4 [341120/620022]    Loss: 0.009761   Batch Acc: 76.56
[Train] Epoch: 4 [341184/620022]    Loss: 0.008046   Batch Acc: 84.38
[Train] Epoch: 4 [341248/620022]    Loss: 0.010095   Batch Acc: 75.00
[Train] Epoch: 4 [341312/620022]    Loss: 0.008155   Batch Acc: 76.56
[Train] Epoch: 4 [341376/620022]    Loss: 0.009747   Batch Acc: 76.56
[Train] Epoch: 4 [341440/620022]    Loss: 0.008433   Batch Acc: 79.69
[Train] Epoch: 4 [341504/620022]    Loss: 0.008053   Batch Acc: 79.69
[Train] Epoch: 4 [341568/620022]    Loss: 0.007236   Batch Acc: 79.69
[Train] Epoch: 4 [341632/620022]    Loss: 0.007760   Batch Acc: 76.56
[Train] Epoch: 4 [341696/620022]    Loss: 0.007343   Batch Acc: 81.25
[Train] Epoch: 4 [341760/620022]    Loss: 0.007502   Batch Acc: 81.25
[Train] Epoch: 4 [341824/620022]    Loss: 0.008290   Batch Acc: 84.38
[Train] Epoch: 4 [341888/620022]    Loss: 0.008715   Batch Acc: 73.44
[Train] Epoch: 4 [341952/620022]    Loss: 0.006002   Batch Acc: 89.06
[Train] Epoch: 4 [342016/620022]    Loss: 0.010829   Batch Acc: 70.31
[Train] Epoch: 4 [342080/620022]    Loss: 0.007227   Batch Acc: 79.69
[Train] Epoch: 4 [342144/620022]    Loss: 0.008758   Batch Acc: 79.69
[Train] Epoch: 4 [342208/620022]    Loss: 0.008908   Batch Acc: 78.12
[Train] Epoch: 4 [342272/620022]    Loss: 0.007780   Batch Acc: 79.69
[Train] Epoch: 4 [342336/620022]    Loss: 0.007482   Batch Acc: 82.81
[Train] Epoch: 4 [342400/620022]    Loss: 0.007964   Batch Acc: 79.69
[Train] Epoch: 4 [342464/620022]    Loss: 0.009724   Batch Acc: 81.25
[Train] Epoch: 4 [342528/620022]    Loss: 0.009408   Batch Acc: 75.00
[Train] Epoch: 4 [342592/620022]    Loss: 0.009681   Batch Acc: 73.44
[Train] Epoch: 4 [342656/620022]    Loss: 0.008790   Batch Acc: 82.81
[Train] Epoch: 4 [342720/620022]    Loss: 0.008726   Batch Acc: 75.00
[Train] Epoch: 4 [342784/620022]    Loss: 0.009050   Batch Acc: 79.69
[Train] Epoch: 4 [342848/620022]    Loss: 0.008169   Batch Acc: 79.69
[Train] Epoch: 4 [342912/620022]    Loss: 0.008928   Batch Acc: 78.12
[Train] Epoch: 4 [342976/620022]    Loss: 0.008083   Batch Acc: 78.12
[Train] Epoch: 4 [343040/620022]    Loss: 0.010035   Batch Acc: 75.00
[Train] Epoch: 4 [343104/620022]    Loss: 0.009528   Batch Acc: 75.00
[Train] Epoch: 4 [343168/620022]    Loss: 0.007854   Batch Acc: 81.25
[Train] Epoch: 4 [343232/620022]    Loss: 0.009215   Batch Acc: 81.25
[Train] Epoch: 4 [343296/620022]    Loss: 0.008970   Batch Acc: 75.00
[Train] Epoch: 4 [343360/620022]    Loss: 0.008109   Batch Acc: 79.69
[Train] Epoch: 4 [343424/620022]    Loss: 0.008988   Batch Acc: 73.44
[Train] Epoch: 4 [343488/620022]    Loss: 0.007583   Batch Acc: 76.56
[Train] Epoch: 4 [343552/620022]    Loss: 0.008862   Batch Acc: 76.56
[Train] Epoch: 4 [343616/620022]    Loss: 0.008866   Batch Acc: 78.12
[Train] Epoch: 4 [343680/620022]    Loss: 0.009047   Batch Acc: 81.25
[Train] Epoch: 4 [343744/620022]    Loss: 0.009936   Batch Acc: 71.88
[Train] Epoch: 4 [343808/620022]    Loss: 0.006487   Batch Acc: 85.94
[Train] Epoch: 4 [343872/620022]    Loss: 0.006421   Batch Acc: 87.50
[Train] Epoch: 4 [343936/620022]    Loss: 0.008434   Batch Acc: 73.44
[Train] Epoch: 4 [344000/620022]    Loss: 0.009087   Batch Acc: 81.25
[Train] Epoch: 4 [344064/620022]    Loss: 0.007680   Batch Acc: 84.38
[Train] Epoch: 4 [344128/620022]    Loss: 0.009359   Batch Acc: 73.44
[Train] Epoch: 4 [344192/620022]    Loss: 0.007200   Batch Acc: 79.69
[Train] Epoch: 4 [344256/620022]    Loss: 0.010031   Batch Acc: 73.44
[Train] Epoch: 4 [344320/620022]    Loss: 0.011645   Batch Acc: 68.75
[Train] Epoch: 4 [344384/620022]    Loss: 0.008298   Batch Acc: 81.25
[Train] Epoch: 4 [344448/620022]    Loss: 0.009727   Batch Acc: 71.88
[Train] Epoch: 4 [344512/620022]    Loss: 0.009892   Batch Acc: 70.31
[Train] Epoch: 4 [344576/620022]    Loss: 0.010730   Batch Acc: 67.19
[Train] Epoch: 4 [344640/620022]    Loss: 0.006295   Batch Acc: 87.50
[Train] Epoch: 4 [344704/620022]    Loss: 0.010337   Batch Acc: 71.88
[Train] Epoch: 4 [344768/620022]    Loss: 0.008815   Batch Acc: 76.56
[Train] Epoch: 4 [344832/620022]    Loss: 0.007382   Batch Acc: 81.25
[Train] Epoch: 4 [344896/620022]    Loss: 0.008392   Batch Acc: 78.12
[Train] Epoch: 4 [344960/620022]    Loss: 0.008327   Batch Acc: 79.69
[Train] Epoch: 4 [345024/620022]    Loss: 0.007732   Batch Acc: 81.25
[Train] Epoch: 4 [345088/620022]    Loss: 0.007459   Batch Acc: 87.50
[Train] Epoch: 4 [345152/620022]    Loss: 0.009623   Batch Acc: 78.12
[Train] Epoch: 4 [345216/620022]    Loss: 0.008659   Batch Acc: 78.12
[Train] Epoch: 4 [345280/620022]    Loss: 0.010425   Batch Acc: 70.31
[Train] Epoch: 4 [345344/620022]    Loss: 0.007726   Batch Acc: 79.69
[Train] Epoch: 4 [345408/620022]    Loss: 0.009268   Batch Acc: 75.00
[Train] Epoch: 4 [345472/620022]    Loss: 0.008472   Batch Acc: 81.25
[Train] Epoch: 4 [345536/620022]    Loss: 0.010095   Batch Acc: 76.56
[Train] Epoch: 4 [345600/620022]    Loss: 0.005518   Batch Acc: 92.19
[Train] Epoch: 4 [345664/620022]    Loss: 0.010254   Batch Acc: 76.56
[Train] Epoch: 4 [345728/620022]    Loss: 0.009383   Batch Acc: 76.56
[Train] Epoch: 4 [345792/620022]    Loss: 0.008604   Batch Acc: 78.12
[Train] Epoch: 4 [345856/620022]    Loss: 0.009709   Batch Acc: 75.00
[Train] Epoch: 4 [345920/620022]    Loss: 0.007660   Batch Acc: 81.25
[Train] Epoch: 4 [345984/620022]    Loss: 0.008088   Batch Acc: 81.25
[Train] Epoch: 4 [346048/620022]    Loss: 0.008254   Batch Acc: 78.12
[Train] Epoch: 4 [346112/620022]    Loss: 0.007129   Batch Acc: 82.81
[Train] Epoch: 4 [346176/620022]    Loss: 0.006328   Batch Acc: 87.50
[Train] Epoch: 4 [346240/620022]    Loss: 0.009747   Batch Acc: 68.75
[Train] Epoch: 4 [346304/620022]    Loss: 0.008171   Batch Acc: 76.56
[Train] Epoch: 4 [346368/620022]    Loss: 0.008366   Batch Acc: 78.12
[Train] Epoch: 4 [346432/620022]    Loss: 0.008398   Batch Acc: 76.56
[Train] Epoch: 4 [346496/620022]    Loss: 0.009467   Batch Acc: 75.00
[Train] Epoch: 4 [346560/620022]    Loss: 0.008326   Batch Acc: 82.81
[Train] Epoch: 4 [346624/620022]    Loss: 0.007476   Batch Acc: 85.94
[Train] Epoch: 4 [346688/620022]    Loss: 0.008836   Batch Acc: 70.31
[Train] Epoch: 4 [346752/620022]    Loss: 0.006833   Batch Acc: 79.69
[Train] Epoch: 4 [346816/620022]    Loss: 0.008988   Batch Acc: 75.00
[Train] Epoch: 4 [346880/620022]    Loss: 0.010026   Batch Acc: 71.88
[Train] Epoch: 4 [346944/620022]    Loss: 0.009465   Batch Acc: 79.69
[Train] Epoch: 4 [347008/620022]    Loss: 0.007143   Batch Acc: 81.25
[Train] Epoch: 4 [347072/620022]    Loss: 0.008966   Batch Acc: 71.88
[Train] Epoch: 4 [347136/620022]    Loss: 0.009532   Batch Acc: 73.44
[Train] Epoch: 4 [347200/620022]    Loss: 0.010110   Batch Acc: 81.25
[Train] Epoch: 4 [347264/620022]    Loss: 0.008899   Batch Acc: 76.56
[Train] Epoch: 4 [347328/620022]    Loss: 0.006706   Batch Acc: 84.38
[Train] Epoch: 4 [347392/620022]    Loss: 0.008270   Batch Acc: 75.00
[Train] Epoch: 4 [347456/620022]    Loss: 0.009941   Batch Acc: 78.12
[Train] Epoch: 4 [347520/620022]    Loss: 0.009379   Batch Acc: 76.56
[Train] Epoch: 4 [347584/620022]    Loss: 0.008795   Batch Acc: 81.25
[Train] Epoch: 4 [347648/620022]    Loss: 0.006946   Batch Acc: 84.38
[Train] Epoch: 4 [347712/620022]    Loss: 0.007883   Batch Acc: 75.00
[Train] Epoch: 4 [347776/620022]    Loss: 0.008335   Batch Acc: 78.12
[Train] Epoch: 4 [347840/620022]    Loss: 0.008671   Batch Acc: 71.88
[Train] Epoch: 4 [347904/620022]    Loss: 0.008672   Batch Acc: 79.69
[Train] Epoch: 4 [347968/620022]    Loss: 0.011043   Batch Acc: 62.50
[Train] Epoch: 4 [348032/620022]    Loss: 0.006321   Batch Acc: 85.94
[Train] Epoch: 4 [348096/620022]    Loss: 0.009015   Batch Acc: 81.25
[Train] Epoch: 4 [348160/620022]    Loss: 0.009243   Batch Acc: 79.69
[Train] Epoch: 4 [348224/620022]    Loss: 0.008019   Batch Acc: 81.25
[Train] Epoch: 4 [348288/620022]    Loss: 0.007352   Batch Acc: 81.25
[Train] Epoch: 4 [348352/620022]    Loss: 0.007432   Batch Acc: 89.06
[Train] Epoch: 4 [348416/620022]    Loss: 0.007753   Batch Acc: 81.25
[Train] Epoch: 4 [348480/620022]    Loss: 0.007956   Batch Acc: 79.69
[Train] Epoch: 4 [348544/620022]    Loss: 0.009598   Batch Acc: 73.44
[Train] Epoch: 4 [348608/620022]    Loss: 0.011748   Batch Acc: 65.62
[Train] Epoch: 4 [348672/620022]    Loss: 0.009951   Batch Acc: 78.12
[Train] Epoch: 4 [348736/620022]    Loss: 0.009717   Batch Acc: 73.44
[Train] Epoch: 4 [348800/620022]    Loss: 0.007536   Batch Acc: 79.69
[Train] Epoch: 4 [348864/620022]    Loss: 0.009076   Batch Acc: 78.12
[Train] Epoch: 4 [348928/620022]    Loss: 0.009550   Batch Acc: 78.12
[Train] Epoch: 4 [348992/620022]    Loss: 0.007626   Batch Acc: 79.69
[Train] Epoch: 4 [349056/620022]    Loss: 0.011038   Batch Acc: 75.00
[Train] Epoch: 4 [349120/620022]    Loss: 0.010288   Batch Acc: 73.44
[Train] Epoch: 4 [349184/620022]    Loss: 0.008276   Batch Acc: 75.00
[Train] Epoch: 4 [349248/620022]    Loss: 0.008878   Batch Acc: 73.44
[Train] Epoch: 4 [349312/620022]    Loss: 0.006469   Batch Acc: 85.94
[Train] Epoch: 4 [349376/620022]    Loss: 0.010815   Batch Acc: 75.00
[Train] Epoch: 4 [349440/620022]    Loss: 0.007738   Batch Acc: 79.69
[Train] Epoch: 4 [349504/620022]    Loss: 0.007183   Batch Acc: 79.69
[Train] Epoch: 4 [349568/620022]    Loss: 0.007730   Batch Acc: 76.56
[Train] Epoch: 4 [349632/620022]    Loss: 0.007820   Batch Acc: 82.81
[Train] Epoch: 4 [349696/620022]    Loss: 0.010652   Batch Acc: 71.88
[Train] Epoch: 4 [349760/620022]    Loss: 0.009590   Batch Acc: 76.56
[Train] Epoch: 4 [349824/620022]    Loss: 0.007276   Batch Acc: 82.81
[Train] Epoch: 4 [349888/620022]    Loss: 0.007912   Batch Acc: 79.69
[Train] Epoch: 4 [349952/620022]    Loss: 0.012009   Batch Acc: 68.75
[Train] Epoch: 4 [350016/620022]    Loss: 0.011106   Batch Acc: 65.62
[Train] Epoch: 4 [350080/620022]    Loss: 0.009452   Batch Acc: 71.88
[Train] Epoch: 4 [350144/620022]    Loss: 0.008624   Batch Acc: 79.69
[Train] Epoch: 4 [350208/620022]    Loss: 0.010411   Batch Acc: 73.44
[Train] Epoch: 4 [350272/620022]    Loss: 0.007316   Batch Acc: 82.81
[Train] Epoch: 4 [350336/620022]    Loss: 0.007837   Batch Acc: 81.25
[Train] Epoch: 4 [350400/620022]    Loss: 0.010045   Batch Acc: 79.69
[Train] Epoch: 4 [350464/620022]    Loss: 0.007828   Batch Acc: 81.25
[Train] Epoch: 4 [350528/620022]    Loss: 0.010970   Batch Acc: 68.75
[Train] Epoch: 4 [350592/620022]    Loss: 0.007254   Batch Acc: 84.38
[Train] Epoch: 4 [350656/620022]    Loss: 0.008742   Batch Acc: 76.56
[Train] Epoch: 4 [350720/620022]    Loss: 0.008398   Batch Acc: 79.69
[Train] Epoch: 4 [350784/620022]    Loss: 0.008556   Batch Acc: 75.00
[Train] Epoch: 4 [350848/620022]    Loss: 0.009621   Batch Acc: 76.56
[Train] Epoch: 4 [350912/620022]    Loss: 0.009289   Batch Acc: 75.00
[Train] Epoch: 4 [350976/620022]    Loss: 0.008506   Batch Acc: 76.56
[Train] Epoch: 4 [351040/620022]    Loss: 0.006826   Batch Acc: 82.81
[Train] Epoch: 4 [351104/620022]    Loss: 0.009511   Batch Acc: 71.88
[Train] Epoch: 4 [351168/620022]    Loss: 0.008395   Batch Acc: 79.69
[Train] Epoch: 4 [351232/620022]    Loss: 0.007207   Batch Acc: 81.25
[Train] Epoch: 4 [351296/620022]    Loss: 0.009197   Batch Acc: 76.56
[Train] Epoch: 4 [351360/620022]    Loss: 0.007935   Batch Acc: 84.38
[Train] Epoch: 4 [351424/620022]    Loss: 0.009439   Batch Acc: 81.25
[Train] Epoch: 4 [351488/620022]    Loss: 0.007894   Batch Acc: 84.38
[Train] Epoch: 4 [351552/620022]    Loss: 0.009117   Batch Acc: 75.00
[Train] Epoch: 4 [351616/620022]    Loss: 0.008094   Batch Acc: 78.12
[Train] Epoch: 4 [351680/620022]    Loss: 0.006261   Batch Acc: 90.62
[Train] Epoch: 4 [351744/620022]    Loss: 0.007688   Batch Acc: 75.00
[Train] Epoch: 4 [351808/620022]    Loss: 0.009096   Batch Acc: 79.69
[Train] Epoch: 4 [351872/620022]    Loss: 0.007592   Batch Acc: 75.00
[Train] Epoch: 4 [351936/620022]    Loss: 0.008346   Batch Acc: 78.12
[Train] Epoch: 4 [352000/620022]    Loss: 0.009872   Batch Acc: 73.44
[Train] Epoch: 4 [352064/620022]    Loss: 0.008018   Batch Acc: 81.25
[Train] Epoch: 4 [352128/620022]    Loss: 0.007731   Batch Acc: 85.94
[Train] Epoch: 4 [352192/620022]    Loss: 0.010051   Batch Acc: 67.19
[Train] Epoch: 4 [352256/620022]    Loss: 0.007585   Batch Acc: 81.25
[Train] Epoch: 4 [352320/620022]    Loss: 0.008152   Batch Acc: 78.12
[Train] Epoch: 4 [352384/620022]    Loss: 0.007921   Batch Acc: 75.00
[Train] Epoch: 4 [352448/620022]    Loss: 0.007063   Batch Acc: 87.50
[Train] Epoch: 4 [352512/620022]    Loss: 0.007535   Batch Acc: 82.81
[Train] Epoch: 4 [352576/620022]    Loss: 0.008556   Batch Acc: 75.00
[Train] Epoch: 4 [352640/620022]    Loss: 0.008401   Batch Acc: 75.00
[Train] Epoch: 4 [352704/620022]    Loss: 0.009174   Batch Acc: 76.56
[Train] Epoch: 4 [352768/620022]    Loss: 0.008341   Batch Acc: 75.00
[Train] Epoch: 4 [352832/620022]    Loss: 0.008358   Batch Acc: 78.12
[Train] Epoch: 4 [352896/620022]    Loss: 0.009061   Batch Acc: 79.69
[Train] Epoch: 4 [352960/620022]    Loss: 0.006872   Batch Acc: 87.50
[Train] Epoch: 4 [353024/620022]    Loss: 0.011143   Batch Acc: 70.31
[Train] Epoch: 4 [353088/620022]    Loss: 0.008889   Batch Acc: 76.56
[Train] Epoch: 4 [353152/620022]    Loss: 0.009547   Batch Acc: 81.25
[Train] Epoch: 4 [353216/620022]    Loss: 0.008169   Batch Acc: 81.25
[Train] Epoch: 4 [353280/620022]    Loss: 0.010118   Batch Acc: 70.31
[Train] Epoch: 4 [353344/620022]    Loss: 0.010290   Batch Acc: 75.00
[Train] Epoch: 4 [353408/620022]    Loss: 0.008077   Batch Acc: 79.69
[Train] Epoch: 4 [353472/620022]    Loss: 0.007701   Batch Acc: 82.81
[Train] Epoch: 4 [353536/620022]    Loss: 0.010031   Batch Acc: 71.88
[Train] Epoch: 4 [353600/620022]    Loss: 0.008045   Batch Acc: 78.12
[Train] Epoch: 4 [353664/620022]    Loss: 0.010582   Batch Acc: 70.31
[Train] Epoch: 4 [353728/620022]    Loss: 0.007308   Batch Acc: 82.81
[Train] Epoch: 4 [353792/620022]    Loss: 0.008791   Batch Acc: 71.88
[Train] Epoch: 4 [353856/620022]    Loss: 0.006505   Batch Acc: 87.50
[Train] Epoch: 4 [353920/620022]    Loss: 0.008949   Batch Acc: 75.00
[Train] Epoch: 4 [353984/620022]    Loss: 0.008803   Batch Acc: 79.69
[Train] Epoch: 4 [354048/620022]    Loss: 0.010043   Batch Acc: 70.31
[Train] Epoch: 4 [354112/620022]    Loss: 0.006319   Batch Acc: 84.38
[Train] Epoch: 4 [354176/620022]    Loss: 0.007537   Batch Acc: 78.12
[Train] Epoch: 4 [354240/620022]    Loss: 0.008038   Batch Acc: 82.81
[Train] Epoch: 4 [354304/620022]    Loss: 0.010216   Batch Acc: 71.88
[Train] Epoch: 4 [354368/620022]    Loss: 0.012206   Batch Acc: 68.75
[Train] Epoch: 4 [354432/620022]    Loss: 0.007619   Batch Acc: 75.00
[Train] Epoch: 4 [354496/620022]    Loss: 0.011277   Batch Acc: 67.19
[Train] Epoch: 4 [354560/620022]    Loss: 0.010330   Batch Acc: 73.44
[Train] Epoch: 4 [354624/620022]    Loss: 0.010102   Batch Acc: 71.88
[Train] Epoch: 4 [354688/620022]    Loss: 0.007826   Batch Acc: 78.12
[Train] Epoch: 4 [354752/620022]    Loss: 0.007832   Batch Acc: 81.25
[Train] Epoch: 4 [354816/620022]    Loss: 0.007426   Batch Acc: 85.94
[Train] Epoch: 4 [354880/620022]    Loss: 0.007758   Batch Acc: 78.12
[Train] Epoch: 4 [354944/620022]    Loss: 0.007232   Batch Acc: 81.25
[Train] Epoch: 4 [355008/620022]    Loss: 0.007575   Batch Acc: 85.94
[Train] Epoch: 4 [355072/620022]    Loss: 0.007292   Batch Acc: 79.69
[Train] Epoch: 4 [355136/620022]    Loss: 0.006926   Batch Acc: 81.25
[Train] Epoch: 4 [355200/620022]    Loss: 0.007578   Batch Acc: 79.69
[Train] Epoch: 4 [355264/620022]    Loss: 0.006237   Batch Acc: 92.19
[Train] Epoch: 4 [355328/620022]    Loss: 0.011142   Batch Acc: 70.31
[Train] Epoch: 4 [355392/620022]    Loss: 0.007312   Batch Acc: 79.69
[Train] Epoch: 4 [355456/620022]    Loss: 0.007728   Batch Acc: 84.38
[Train] Epoch: 4 [355520/620022]    Loss: 0.009699   Batch Acc: 79.69
[Train] Epoch: 4 [355584/620022]    Loss: 0.008815   Batch Acc: 75.00
[Train] Epoch: 4 [355648/620022]    Loss: 0.006295   Batch Acc: 82.81
[Train] Epoch: 4 [355712/620022]    Loss: 0.008034   Batch Acc: 76.56
[Train] Epoch: 4 [355776/620022]    Loss: 0.009090   Batch Acc: 75.00
[Train] Epoch: 4 [355840/620022]    Loss: 0.007921   Batch Acc: 81.25
[Train] Epoch: 4 [355904/620022]    Loss: 0.006414   Batch Acc: 85.94
[Train] Epoch: 4 [355968/620022]    Loss: 0.009940   Batch Acc: 73.44
[Train] Epoch: 4 [356032/620022]    Loss: 0.009402   Batch Acc: 70.31
[Train] Epoch: 4 [356096/620022]    Loss: 0.009499   Batch Acc: 73.44
[Train] Epoch: 4 [356160/620022]    Loss: 0.007055   Batch Acc: 79.69
[Train] Epoch: 4 [356224/620022]    Loss: 0.009619   Batch Acc: 71.88
[Train] Epoch: 4 [356288/620022]    Loss: 0.008650   Batch Acc: 81.25
[Train] Epoch: 4 [356352/620022]    Loss: 0.008021   Batch Acc: 78.12
[Train] Epoch: 4 [356416/620022]    Loss: 0.009696   Batch Acc: 67.19
[Train] Epoch: 4 [356480/620022]    Loss: 0.009917   Batch Acc: 65.62
[Train] Epoch: 4 [356544/620022]    Loss: 0.009493   Batch Acc: 78.12
[Train] Epoch: 4 [356608/620022]    Loss: 0.008607   Batch Acc: 75.00
[Train] Epoch: 4 [356672/620022]    Loss: 0.009098   Batch Acc: 68.75
[Train] Epoch: 4 [356736/620022]    Loss: 0.006333   Batch Acc: 79.69
[Train] Epoch: 4 [356800/620022]    Loss: 0.008410   Batch Acc: 73.44
[Train] Epoch: 4 [356864/620022]    Loss: 0.009063   Batch Acc: 76.56
[Train] Epoch: 4 [356928/620022]    Loss: 0.008383   Batch Acc: 73.44
[Train] Epoch: 4 [356992/620022]    Loss: 0.009977   Batch Acc: 79.69
[Train] Epoch: 4 [357056/620022]    Loss: 0.010781   Batch Acc: 71.88
[Train] Epoch: 4 [357120/620022]    Loss: 0.008065   Batch Acc: 78.12
[Train] Epoch: 4 [357184/620022]    Loss: 0.007156   Batch Acc: 85.94
[Train] Epoch: 4 [357248/620022]    Loss: 0.008480   Batch Acc: 78.12
[Train] Epoch: 4 [357312/620022]    Loss: 0.007005   Batch Acc: 81.25
[Train] Epoch: 4 [357376/620022]    Loss: 0.007499   Batch Acc: 82.81
[Train] Epoch: 4 [357440/620022]    Loss: 0.008624   Batch Acc: 78.12
[Train] Epoch: 4 [357504/620022]    Loss: 0.007825   Batch Acc: 76.56
[Train] Epoch: 4 [357568/620022]    Loss: 0.008787   Batch Acc: 79.69
[Train] Epoch: 4 [357632/620022]    Loss: 0.009696   Batch Acc: 73.44
[Train] Epoch: 4 [357696/620022]    Loss: 0.010267   Batch Acc: 70.31
[Train] Epoch: 4 [357760/620022]    Loss: 0.006827   Batch Acc: 84.38
[Train] Epoch: 4 [357824/620022]    Loss: 0.006840   Batch Acc: 79.69
[Train] Epoch: 4 [357888/620022]    Loss: 0.010622   Batch Acc: 71.88
[Train] Epoch: 4 [357952/620022]    Loss: 0.010369   Batch Acc: 70.31
[Train] Epoch: 4 [358016/620022]    Loss: 0.007924   Batch Acc: 84.38
[Train] Epoch: 4 [358080/620022]    Loss: 0.009297   Batch Acc: 76.56
[Train] Epoch: 4 [358144/620022]    Loss: 0.007910   Batch Acc: 82.81
[Train] Epoch: 4 [358208/620022]    Loss: 0.009151   Batch Acc: 78.12
[Train] Epoch: 4 [358272/620022]    Loss: 0.010902   Batch Acc: 68.75
[Train] Epoch: 4 [358336/620022]    Loss: 0.007844   Batch Acc: 81.25
[Train] Epoch: 4 [358400/620022]    Loss: 0.006548   Batch Acc: 87.50
[Train] Epoch: 4 [358464/620022]    Loss: 0.009280   Batch Acc: 78.12
[Train] Epoch: 4 [358528/620022]    Loss: 0.009252   Batch Acc: 79.69
[Train] Epoch: 4 [358592/620022]    Loss: 0.007657   Batch Acc: 78.12
[Train] Epoch: 4 [358656/620022]    Loss: 0.009748   Batch Acc: 82.81
[Train] Epoch: 4 [358720/620022]    Loss: 0.007165   Batch Acc: 84.38
[Train] Epoch: 4 [358784/620022]    Loss: 0.007154   Batch Acc: 87.50
[Train] Epoch: 4 [358848/620022]    Loss: 0.008485   Batch Acc: 70.31
[Train] Epoch: 4 [358912/620022]    Loss: 0.009367   Batch Acc: 73.44
[Train] Epoch: 4 [358976/620022]    Loss: 0.005883   Batch Acc: 84.38
[Train] Epoch: 4 [359040/620022]    Loss: 0.008869   Batch Acc: 75.00
[Train] Epoch: 4 [359104/620022]    Loss: 0.010110   Batch Acc: 71.88
[Train] Epoch: 4 [359168/620022]    Loss: 0.009562   Batch Acc: 73.44
[Train] Epoch: 4 [359232/620022]    Loss: 0.010853   Batch Acc: 68.75
[Train] Epoch: 4 [359296/620022]    Loss: 0.009247   Batch Acc: 76.56
[Train] Epoch: 4 [359360/620022]    Loss: 0.008480   Batch Acc: 81.25
[Train] Epoch: 4 [359424/620022]    Loss: 0.007885   Batch Acc: 82.81
[Train] Epoch: 4 [359488/620022]    Loss: 0.006851   Batch Acc: 82.81
[Train] Epoch: 4 [359552/620022]    Loss: 0.009692   Batch Acc: 76.56
[Train] Epoch: 4 [359616/620022]    Loss: 0.009745   Batch Acc: 75.00
[Train] Epoch: 4 [359680/620022]    Loss: 0.008390   Batch Acc: 79.69
[Train] Epoch: 4 [359744/620022]    Loss: 0.007785   Batch Acc: 82.81
[Train] Epoch: 4 [359808/620022]    Loss: 0.007776   Batch Acc: 81.25
[Train] Epoch: 4 [359872/620022]    Loss: 0.009389   Batch Acc: 73.44
[Train] Epoch: 4 [359936/620022]    Loss: 0.007472   Batch Acc: 81.25
[Train] Epoch: 4 [360000/620022]    Loss: 0.009201   Batch Acc: 79.69
[Train] Epoch: 4 [360064/620022]    Loss: 0.006844   Batch Acc: 81.25
[Train] Epoch: 4 [360128/620022]    Loss: 0.007929   Batch Acc: 78.12
[Train] Epoch: 4 [360192/620022]    Loss: 0.009165   Batch Acc: 75.00
[Train] Epoch: 4 [360256/620022]    Loss: 0.009590   Batch Acc: 76.56
[Train] Epoch: 4 [360320/620022]    Loss: 0.009451   Batch Acc: 78.12
[Train] Epoch: 4 [360384/620022]    Loss: 0.008297   Batch Acc: 81.25
[Train] Epoch: 4 [360448/620022]    Loss: 0.008639   Batch Acc: 76.56
[Train] Epoch: 4 [360512/620022]    Loss: 0.007613   Batch Acc: 79.69
[Train] Epoch: 4 [360576/620022]    Loss: 0.009709   Batch Acc: 71.88
[Train] Epoch: 4 [360640/620022]    Loss: 0.007473   Batch Acc: 78.12
[Train] Epoch: 4 [360704/620022]    Loss: 0.012381   Batch Acc: 68.75
[Train] Epoch: 4 [360768/620022]    Loss: 0.009107   Batch Acc: 73.44
[Train] Epoch: 4 [360832/620022]    Loss: 0.009049   Batch Acc: 76.56
[Train] Epoch: 4 [360896/620022]    Loss: 0.007762   Batch Acc: 79.69
[Train] Epoch: 4 [360960/620022]    Loss: 0.008651   Batch Acc: 76.56
[Train] Epoch: 4 [361024/620022]    Loss: 0.010193   Batch Acc: 68.75
[Train] Epoch: 4 [361088/620022]    Loss: 0.008776   Batch Acc: 76.56
[Train] Epoch: 4 [361152/620022]    Loss: 0.009097   Batch Acc: 82.81
[Train] Epoch: 4 [361216/620022]    Loss: 0.006111   Batch Acc: 87.50
[Train] Epoch: 4 [361280/620022]    Loss: 0.008455   Batch Acc: 79.69
[Train] Epoch: 4 [361344/620022]    Loss: 0.008526   Batch Acc: 81.25
[Train] Epoch: 4 [361408/620022]    Loss: 0.009890   Batch Acc: 82.81
[Train] Epoch: 4 [361472/620022]    Loss: 0.010553   Batch Acc: 76.56
[Train] Epoch: 4 [361536/620022]    Loss: 0.005641   Batch Acc: 89.06
[Train] Epoch: 4 [361600/620022]    Loss: 0.008012   Batch Acc: 79.69
[Train] Epoch: 4 [361664/620022]    Loss: 0.007299   Batch Acc: 85.94
[Train] Epoch: 4 [361728/620022]    Loss: 0.007897   Batch Acc: 79.69
[Train] Epoch: 4 [361792/620022]    Loss: 0.011728   Batch Acc: 68.75
[Train] Epoch: 4 [361856/620022]    Loss: 0.010509   Batch Acc: 67.19
[Train] Epoch: 4 [361920/620022]    Loss: 0.010104   Batch Acc: 71.88
[Train] Epoch: 4 [361984/620022]    Loss: 0.007899   Batch Acc: 84.38
[Train] Epoch: 4 [362048/620022]    Loss: 0.009099   Batch Acc: 79.69
[Train] Epoch: 4 [362112/620022]    Loss: 0.008163   Batch Acc: 75.00
[Train] Epoch: 4 [362176/620022]    Loss: 0.007790   Batch Acc: 89.06
[Train] Epoch: 4 [362240/620022]    Loss: 0.006199   Batch Acc: 85.94
[Train] Epoch: 4 [362304/620022]    Loss: 0.008820   Batch Acc: 70.31
[Train] Epoch: 4 [362368/620022]    Loss: 0.011093   Batch Acc: 65.62
[Train] Epoch: 4 [362432/620022]    Loss: 0.007362   Batch Acc: 82.81
[Train] Epoch: 4 [362496/620022]    Loss: 0.005318   Batch Acc: 90.62
[Train] Epoch: 4 [362560/620022]    Loss: 0.009178   Batch Acc: 76.56
[Train] Epoch: 4 [362624/620022]    Loss: 0.009262   Batch Acc: 78.12
[Train] Epoch: 4 [362688/620022]    Loss: 0.008395   Batch Acc: 81.25
[Train] Epoch: 4 [362752/620022]    Loss: 0.010549   Batch Acc: 76.56
[Train] Epoch: 4 [362816/620022]    Loss: 0.006597   Batch Acc: 84.38
[Train] Epoch: 4 [362880/620022]    Loss: 0.008372   Batch Acc: 78.12
[Train] Epoch: 4 [362944/620022]    Loss: 0.007323   Batch Acc: 84.38
[Train] Epoch: 4 [363008/620022]    Loss: 0.007420   Batch Acc: 76.56
[Train] Epoch: 4 [363072/620022]    Loss: 0.006569   Batch Acc: 84.38
[Train] Epoch: 4 [363136/620022]    Loss: 0.009958   Batch Acc: 70.31
[Train] Epoch: 4 [363200/620022]    Loss: 0.011775   Batch Acc: 65.62
[Train] Epoch: 4 [363264/620022]    Loss: 0.008159   Batch Acc: 79.69
[Train] Epoch: 4 [363328/620022]    Loss: 0.009112   Batch Acc: 81.25
[Train] Epoch: 4 [363392/620022]    Loss: 0.008373   Batch Acc: 84.38
[Train] Epoch: 4 [363456/620022]    Loss: 0.008944   Batch Acc: 81.25
[Train] Epoch: 4 [363520/620022]    Loss: 0.010568   Batch Acc: 68.75
[Train] Epoch: 4 [363584/620022]    Loss: 0.007401   Batch Acc: 81.25
[Train] Epoch: 4 [363648/620022]    Loss: 0.009874   Batch Acc: 73.44
[Train] Epoch: 4 [363712/620022]    Loss: 0.007885   Batch Acc: 81.25
[Train] Epoch: 4 [363776/620022]    Loss: 0.009735   Batch Acc: 70.31
[Train] Epoch: 4 [363840/620022]    Loss: 0.011388   Batch Acc: 67.19
[Train] Epoch: 4 [363904/620022]    Loss: 0.008052   Batch Acc: 81.25
[Train] Epoch: 4 [363968/620022]    Loss: 0.008246   Batch Acc: 75.00
[Train] Epoch: 4 [364032/620022]    Loss: 0.008981   Batch Acc: 78.12
[Train] Epoch: 4 [364096/620022]    Loss: 0.008368   Batch Acc: 79.69
[Train] Epoch: 4 [364160/620022]    Loss: 0.008646   Batch Acc: 78.12
[Train] Epoch: 4 [364224/620022]    Loss: 0.007462   Batch Acc: 76.56
[Train] Epoch: 4 [364288/620022]    Loss: 0.009360   Batch Acc: 81.25
[Train] Epoch: 4 [364352/620022]    Loss: 0.008777   Batch Acc: 79.69
[Train] Epoch: 4 [364416/620022]    Loss: 0.009783   Batch Acc: 82.81
[Train] Epoch: 4 [364480/620022]    Loss: 0.007836   Batch Acc: 79.69
[Train] Epoch: 4 [364544/620022]    Loss: 0.007647   Batch Acc: 79.69
[Train] Epoch: 4 [364608/620022]    Loss: 0.009005   Batch Acc: 84.38
[Train] Epoch: 4 [364672/620022]    Loss: 0.006578   Batch Acc: 85.94
[Train] Epoch: 4 [364736/620022]    Loss: 0.007852   Batch Acc: 81.25
[Train] Epoch: 4 [364800/620022]    Loss: 0.007930   Batch Acc: 76.56
[Train] Epoch: 4 [364864/620022]    Loss: 0.007179   Batch Acc: 79.69
[Train] Epoch: 4 [364928/620022]    Loss: 0.007801   Batch Acc: 81.25
[Train] Epoch: 4 [364992/620022]    Loss: 0.008599   Batch Acc: 78.12
[Train] Epoch: 4 [365056/620022]    Loss: 0.009249   Batch Acc: 73.44
[Train] Epoch: 4 [365120/620022]    Loss: 0.010052   Batch Acc: 71.88
[Train] Epoch: 4 [365184/620022]    Loss: 0.007605   Batch Acc: 79.69
[Train] Epoch: 4 [365248/620022]    Loss: 0.009411   Batch Acc: 78.12
[Train] Epoch: 4 [365312/620022]    Loss: 0.009908   Batch Acc: 73.44
[Train] Epoch: 4 [365376/620022]    Loss: 0.010464   Batch Acc: 71.88
[Train] Epoch: 4 [365440/620022]    Loss: 0.010014   Batch Acc: 73.44
[Train] Epoch: 4 [365504/620022]    Loss: 0.007520   Batch Acc: 79.69
[Train] Epoch: 4 [365568/620022]    Loss: 0.008328   Batch Acc: 79.69
[Train] Epoch: 4 [365632/620022]    Loss: 0.008408   Batch Acc: 73.44
[Train] Epoch: 4 [365696/620022]    Loss: 0.009085   Batch Acc: 78.12
[Train] Epoch: 4 [365760/620022]    Loss: 0.006340   Batch Acc: 84.38
[Train] Epoch: 4 [365824/620022]    Loss: 0.009198   Batch Acc: 75.00
[Train] Epoch: 4 [365888/620022]    Loss: 0.009171   Batch Acc: 73.44
[Train] Epoch: 4 [365952/620022]    Loss: 0.008550   Batch Acc: 79.69
[Train] Epoch: 4 [366016/620022]    Loss: 0.006783   Batch Acc: 89.06
[Train] Epoch: 4 [366080/620022]    Loss: 0.010863   Batch Acc: 68.75
[Train] Epoch: 4 [366144/620022]    Loss: 0.009228   Batch Acc: 76.56
[Train] Epoch: 4 [366208/620022]    Loss: 0.008406   Batch Acc: 71.88
[Train] Epoch: 4 [366272/620022]    Loss: 0.008562   Batch Acc: 79.69
[Train] Epoch: 4 [366336/620022]    Loss: 0.007065   Batch Acc: 81.25
[Train] Epoch: 4 [366400/620022]    Loss: 0.008089   Batch Acc: 81.25
[Train] Epoch: 4 [366464/620022]    Loss: 0.007609   Batch Acc: 81.25
[Train] Epoch: 4 [366528/620022]    Loss: 0.010358   Batch Acc: 73.44
[Train] Epoch: 4 [366592/620022]    Loss: 0.006461   Batch Acc: 84.38
[Train] Epoch: 4 [366656/620022]    Loss: 0.007801   Batch Acc: 78.12
[Train] Epoch: 4 [366720/620022]    Loss: 0.007392   Batch Acc: 78.12
[Train] Epoch: 4 [366784/620022]    Loss: 0.008869   Batch Acc: 78.12
[Train] Epoch: 4 [366848/620022]    Loss: 0.008431   Batch Acc: 79.69
[Train] Epoch: 4 [366912/620022]    Loss: 0.009910   Batch Acc: 79.69
[Train] Epoch: 4 [366976/620022]    Loss: 0.011044   Batch Acc: 65.62
[Train] Epoch: 4 [367040/620022]    Loss: 0.010075   Batch Acc: 79.69
[Train] Epoch: 4 [367104/620022]    Loss: 0.010384   Batch Acc: 73.44
[Train] Epoch: 4 [367168/620022]    Loss: 0.008726   Batch Acc: 78.12
[Train] Epoch: 4 [367232/620022]    Loss: 0.008321   Batch Acc: 81.25
[Train] Epoch: 4 [367296/620022]    Loss: 0.007717   Batch Acc: 84.38
[Train] Epoch: 4 [367360/620022]    Loss: 0.009658   Batch Acc: 75.00
[Train] Epoch: 4 [367424/620022]    Loss: 0.008791   Batch Acc: 79.69
[Train] Epoch: 4 [367488/620022]    Loss: 0.008346   Batch Acc: 76.56
[Train] Epoch: 4 [367552/620022]    Loss: 0.007179   Batch Acc: 84.38
[Train] Epoch: 4 [367616/620022]    Loss: 0.008664   Batch Acc: 79.69
[Train] Epoch: 4 [367680/620022]    Loss: 0.007346   Batch Acc: 87.50
[Train] Epoch: 4 [367744/620022]    Loss: 0.008006   Batch Acc: 82.81
[Train] Epoch: 4 [367808/620022]    Loss: 0.009036   Batch Acc: 75.00
[Train] Epoch: 4 [367872/620022]    Loss: 0.008181   Batch Acc: 84.38
[Train] Epoch: 4 [367936/620022]    Loss: 0.005828   Batch Acc: 90.62
[Train] Epoch: 4 [368000/620022]    Loss: 0.008048   Batch Acc: 75.00
[Train] Epoch: 4 [368064/620022]    Loss: 0.006805   Batch Acc: 87.50
[Train] Epoch: 4 [368128/620022]    Loss: 0.010136   Batch Acc: 73.44
[Train] Epoch: 4 [368192/620022]    Loss: 0.009222   Batch Acc: 75.00
[Train] Epoch: 4 [368256/620022]    Loss: 0.010102   Batch Acc: 75.00
[Train] Epoch: 4 [368320/620022]    Loss: 0.009749   Batch Acc: 75.00
[Train] Epoch: 4 [368384/620022]    Loss: 0.009996   Batch Acc: 70.31
[Train] Epoch: 4 [368448/620022]    Loss: 0.007946   Batch Acc: 79.69
[Train] Epoch: 4 [368512/620022]    Loss: 0.008377   Batch Acc: 84.38
[Train] Epoch: 4 [368576/620022]    Loss: 0.006629   Batch Acc: 81.25
[Train] Epoch: 4 [368640/620022]    Loss: 0.007569   Batch Acc: 82.81
[Train] Epoch: 4 [368704/620022]    Loss: 0.008354   Batch Acc: 75.00
[Train] Epoch: 4 [368768/620022]    Loss: 0.007648   Batch Acc: 79.69
[Train] Epoch: 4 [368832/620022]    Loss: 0.007730   Batch Acc: 82.81
[Train] Epoch: 4 [368896/620022]    Loss: 0.009834   Batch Acc: 65.62
[Train] Epoch: 4 [368960/620022]    Loss: 0.008757   Batch Acc: 78.12
[Train] Epoch: 4 [369024/620022]    Loss: 0.010564   Batch Acc: 75.00
[Train] Epoch: 4 [369088/620022]    Loss: 0.008116   Batch Acc: 78.12
[Train] Epoch: 4 [369152/620022]    Loss: 0.009824   Batch Acc: 70.31
[Train] Epoch: 4 [369216/620022]    Loss: 0.008149   Batch Acc: 81.25
[Train] Epoch: 4 [369280/620022]    Loss: 0.008919   Batch Acc: 78.12
[Train] Epoch: 4 [369344/620022]    Loss: 0.009239   Batch Acc: 70.31
[Train] Epoch: 4 [369408/620022]    Loss: 0.008599   Batch Acc: 75.00
[Train] Epoch: 4 [369472/620022]    Loss: 0.010271   Batch Acc: 71.88
[Train] Epoch: 4 [369536/620022]    Loss: 0.007628   Batch Acc: 79.69
[Train] Epoch: 4 [369600/620022]    Loss: 0.009544   Batch Acc: 68.75
[Train] Epoch: 4 [369664/620022]    Loss: 0.007385   Batch Acc: 84.38
[Train] Epoch: 4 [369728/620022]    Loss: 0.011234   Batch Acc: 71.88
[Train] Epoch: 4 [369792/620022]    Loss: 0.008143   Batch Acc: 82.81
[Train] Epoch: 4 [369856/620022]    Loss: 0.007891   Batch Acc: 79.69
[Train] Epoch: 4 [369920/620022]    Loss: 0.010144   Batch Acc: 75.00
[Train] Epoch: 4 [369984/620022]    Loss: 0.009282   Batch Acc: 79.69
[Train] Epoch: 4 [370048/620022]    Loss: 0.009214   Batch Acc: 76.56
[Train] Epoch: 4 [370112/620022]    Loss: 0.009243   Batch Acc: 75.00
[Train] Epoch: 4 [370176/620022]    Loss: 0.008239   Batch Acc: 78.12
[Train] Epoch: 4 [370240/620022]    Loss: 0.009998   Batch Acc: 78.12
[Train] Epoch: 4 [370304/620022]    Loss: 0.009046   Batch Acc: 78.12
[Train] Epoch: 4 [370368/620022]    Loss: 0.007047   Batch Acc: 85.94
[Train] Epoch: 4 [370432/620022]    Loss: 0.007791   Batch Acc: 78.12
[Train] Epoch: 4 [370496/620022]    Loss: 0.007907   Batch Acc: 76.56
[Train] Epoch: 4 [370560/620022]    Loss: 0.006988   Batch Acc: 79.69
[Train] Epoch: 4 [370624/620022]    Loss: 0.007769   Batch Acc: 82.81
[Train] Epoch: 4 [370688/620022]    Loss: 0.009224   Batch Acc: 73.44
[Train] Epoch: 4 [370752/620022]    Loss: 0.008340   Batch Acc: 75.00
[Train] Epoch: 4 [370816/620022]    Loss: 0.008917   Batch Acc: 81.25
[Train] Epoch: 4 [370880/620022]    Loss: 0.011051   Batch Acc: 65.62
[Train] Epoch: 4 [370944/620022]    Loss: 0.008186   Batch Acc: 78.12
[Train] Epoch: 4 [371008/620022]    Loss: 0.008690   Batch Acc: 76.56
[Train] Epoch: 4 [371072/620022]    Loss: 0.010308   Batch Acc: 70.31
[Train] Epoch: 4 [371136/620022]    Loss: 0.010573   Batch Acc: 68.75
[Train] Epoch: 4 [371200/620022]    Loss: 0.008148   Batch Acc: 79.69
[Train] Epoch: 4 [371264/620022]    Loss: 0.009093   Batch Acc: 76.56
[Train] Epoch: 4 [371328/620022]    Loss: 0.009007   Batch Acc: 75.00
[Train] Epoch: 4 [371392/620022]    Loss: 0.009302   Batch Acc: 75.00
[Train] Epoch: 4 [371456/620022]    Loss: 0.007755   Batch Acc: 84.38
[Train] Epoch: 4 [371520/620022]    Loss: 0.007937   Batch Acc: 78.12
[Train] Epoch: 4 [371584/620022]    Loss: 0.010992   Batch Acc: 68.75
[Train] Epoch: 4 [371648/620022]    Loss: 0.009534   Batch Acc: 68.75
[Train] Epoch: 4 [371712/620022]    Loss: 0.007746   Batch Acc: 82.81
[Train] Epoch: 4 [371776/620022]    Loss: 0.006653   Batch Acc: 84.38
[Train] Epoch: 4 [371840/620022]    Loss: 0.005947   Batch Acc: 84.38
[Train] Epoch: 4 [371904/620022]    Loss: 0.008285   Batch Acc: 78.12
[Train] Epoch: 4 [371968/620022]    Loss: 0.010272   Batch Acc: 75.00
[Train] Epoch: 4 [372032/620022]    Loss: 0.008687   Batch Acc: 79.69
[Train] Epoch: 4 [372096/620022]    Loss: 0.007768   Batch Acc: 78.12
[Train] Epoch: 4 [372160/620022]    Loss: 0.010042   Batch Acc: 65.62
[Train] Epoch: 4 [372224/620022]    Loss: 0.010393   Batch Acc: 71.88
[Train] Epoch: 4 [372288/620022]    Loss: 0.008126   Batch Acc: 81.25
[Train] Epoch: 4 [372352/620022]    Loss: 0.009443   Batch Acc: 71.88
[Train] Epoch: 4 [372416/620022]    Loss: 0.009949   Batch Acc: 75.00
[Train] Epoch: 4 [372480/620022]    Loss: 0.009555   Batch Acc: 75.00
[Train] Epoch: 4 [372544/620022]    Loss: 0.009544   Batch Acc: 71.88
[Train] Epoch: 4 [372608/620022]    Loss: 0.007995   Batch Acc: 79.69
[Train] Epoch: 4 [372672/620022]    Loss: 0.007531   Batch Acc: 79.69
[Train] Epoch: 4 [372736/620022]    Loss: 0.006102   Batch Acc: 90.62
[Train] Epoch: 4 [372800/620022]    Loss: 0.007523   Batch Acc: 81.25
[Train] Epoch: 4 [372864/620022]    Loss: 0.009524   Batch Acc: 73.44
[Train] Epoch: 4 [372928/620022]    Loss: 0.007849   Batch Acc: 75.00
[Train] Epoch: 4 [372992/620022]    Loss: 0.010179   Batch Acc: 73.44
[Train] Epoch: 4 [373056/620022]    Loss: 0.009030   Batch Acc: 79.69
[Train] Epoch: 4 [373120/620022]    Loss: 0.007980   Batch Acc: 78.12
[Train] Epoch: 4 [373184/620022]    Loss: 0.006615   Batch Acc: 82.81
[Train] Epoch: 4 [373248/620022]    Loss: 0.009206   Batch Acc: 81.25
[Train] Epoch: 4 [373312/620022]    Loss: 0.008153   Batch Acc: 79.69
[Train] Epoch: 4 [373376/620022]    Loss: 0.007346   Batch Acc: 84.38
[Train] Epoch: 4 [373440/620022]    Loss: 0.009117   Batch Acc: 78.12
[Train] Epoch: 4 [373504/620022]    Loss: 0.009028   Batch Acc: 75.00
[Train] Epoch: 4 [373568/620022]    Loss: 0.008160   Batch Acc: 75.00
[Train] Epoch: 4 [373632/620022]    Loss: 0.010622   Batch Acc: 68.75
[Train] Epoch: 4 [373696/620022]    Loss: 0.008258   Batch Acc: 76.56
[Train] Epoch: 4 [373760/620022]    Loss: 0.007718   Batch Acc: 81.25
[Train] Epoch: 4 [373824/620022]    Loss: 0.009357   Batch Acc: 73.44
[Train] Epoch: 4 [373888/620022]    Loss: 0.007730   Batch Acc: 81.25
[Train] Epoch: 4 [373952/620022]    Loss: 0.008478   Batch Acc: 78.12
[Train] Epoch: 4 [374016/620022]    Loss: 0.007402   Batch Acc: 81.25
[Train] Epoch: 4 [374080/620022]    Loss: 0.009755   Batch Acc: 67.19
[Train] Epoch: 4 [374144/620022]    Loss: 0.007012   Batch Acc: 84.38
[Train] Epoch: 4 [374208/620022]    Loss: 0.007606   Batch Acc: 84.38
[Train] Epoch: 4 [374272/620022]    Loss: 0.009906   Batch Acc: 79.69
[Train] Epoch: 4 [374336/620022]    Loss: 0.007247   Batch Acc: 82.81
[Train] Epoch: 4 [374400/620022]    Loss: 0.008295   Batch Acc: 79.69
[Train] Epoch: 4 [374464/620022]    Loss: 0.007361   Batch Acc: 89.06
[Train] Epoch: 4 [374528/620022]    Loss: 0.007628   Batch Acc: 78.12
[Train] Epoch: 4 [374592/620022]    Loss: 0.008822   Batch Acc: 76.56
[Train] Epoch: 4 [374656/620022]    Loss: 0.009656   Batch Acc: 71.88
[Train] Epoch: 4 [374720/620022]    Loss: 0.008693   Batch Acc: 79.69
[Train] Epoch: 4 [374784/620022]    Loss: 0.007837   Batch Acc: 79.69
[Train] Epoch: 4 [374848/620022]    Loss: 0.007896   Batch Acc: 79.69
[Train] Epoch: 4 [374912/620022]    Loss: 0.007518   Batch Acc: 71.88
[Train] Epoch: 4 [374976/620022]    Loss: 0.008099   Batch Acc: 79.69
[Train] Epoch: 4 [375040/620022]    Loss: 0.008989   Batch Acc: 79.69
[Train] Epoch: 4 [375104/620022]    Loss: 0.009741   Batch Acc: 73.44
[Train] Epoch: 4 [375168/620022]    Loss: 0.007932   Batch Acc: 79.69
[Train] Epoch: 4 [375232/620022]    Loss: 0.007880   Batch Acc: 85.94
[Train] Epoch: 4 [375296/620022]    Loss: 0.009454   Batch Acc: 79.69
[Train] Epoch: 4 [375360/620022]    Loss: 0.008077   Batch Acc: 82.81
[Train] Epoch: 4 [375424/620022]    Loss: 0.011907   Batch Acc: 65.62
[Train] Epoch: 4 [375488/620022]    Loss: 0.008520   Batch Acc: 76.56
[Train] Epoch: 4 [375552/620022]    Loss: 0.010284   Batch Acc: 73.44
[Train] Epoch: 4 [375616/620022]    Loss: 0.012396   Batch Acc: 70.31
[Train] Epoch: 4 [375680/620022]    Loss: 0.011436   Batch Acc: 67.19
[Train] Epoch: 4 [375744/620022]    Loss: 0.010396   Batch Acc: 75.00
[Train] Epoch: 4 [375808/620022]    Loss: 0.010314   Batch Acc: 73.44
[Train] Epoch: 4 [375872/620022]    Loss: 0.009385   Batch Acc: 79.69
[Train] Epoch: 4 [375936/620022]    Loss: 0.008048   Batch Acc: 81.25
[Train] Epoch: 4 [376000/620022]    Loss: 0.008161   Batch Acc: 81.25
[Train] Epoch: 4 [376064/620022]    Loss: 0.010626   Batch Acc: 71.88
[Train] Epoch: 4 [376128/620022]    Loss: 0.010204   Batch Acc: 73.44
[Train] Epoch: 4 [376192/620022]    Loss: 0.006591   Batch Acc: 81.25
[Train] Epoch: 4 [376256/620022]    Loss: 0.009500   Batch Acc: 67.19
[Train] Epoch: 4 [376320/620022]    Loss: 0.007050   Batch Acc: 78.12
[Train] Epoch: 4 [376384/620022]    Loss: 0.007309   Batch Acc: 82.81
[Train] Epoch: 4 [376448/620022]    Loss: 0.008749   Batch Acc: 75.00
[Train] Epoch: 4 [376512/620022]    Loss: 0.006989   Batch Acc: 85.94
[Train] Epoch: 4 [376576/620022]    Loss: 0.006661   Batch Acc: 85.94
[Train] Epoch: 4 [376640/620022]    Loss: 0.006528   Batch Acc: 85.94
[Train] Epoch: 4 [376704/620022]    Loss: 0.006536   Batch Acc: 82.81
[Train] Epoch: 4 [376768/620022]    Loss: 0.010928   Batch Acc: 67.19
[Train] Epoch: 4 [376832/620022]    Loss: 0.008213   Batch Acc: 78.12
[Train] Epoch: 4 [376896/620022]    Loss: 0.005348   Batch Acc: 87.50
[Train] Epoch: 4 [376960/620022]    Loss: 0.010513   Batch Acc: 68.75
[Train] Epoch: 4 [377024/620022]    Loss: 0.009322   Batch Acc: 71.88
[Train] Epoch: 4 [377088/620022]    Loss: 0.006727   Batch Acc: 81.25
[Train] Epoch: 4 [377152/620022]    Loss: 0.009286   Batch Acc: 76.56
[Train] Epoch: 4 [377216/620022]    Loss: 0.007786   Batch Acc: 81.25
[Train] Epoch: 4 [377280/620022]    Loss: 0.004991   Batch Acc: 89.06
[Train] Epoch: 4 [377344/620022]    Loss: 0.010665   Batch Acc: 73.44
[Train] Epoch: 4 [377408/620022]    Loss: 0.008248   Batch Acc: 78.12
[Train] Epoch: 4 [377472/620022]    Loss: 0.008111   Batch Acc: 81.25
[Train] Epoch: 4 [377536/620022]    Loss: 0.007592   Batch Acc: 76.56
[Train] Epoch: 4 [377600/620022]    Loss: 0.008480   Batch Acc: 81.25
[Train] Epoch: 4 [377664/620022]    Loss: 0.007905   Batch Acc: 78.12
[Train] Epoch: 4 [377728/620022]    Loss: 0.009098   Batch Acc: 73.44
[Train] Epoch: 4 [377792/620022]    Loss: 0.007730   Batch Acc: 81.25
[Train] Epoch: 4 [377856/620022]    Loss: 0.007482   Batch Acc: 81.25
[Train] Epoch: 4 [377920/620022]    Loss: 0.007689   Batch Acc: 78.12
[Train] Epoch: 4 [377984/620022]    Loss: 0.007839   Batch Acc: 79.69
[Train] Epoch: 4 [378048/620022]    Loss: 0.010406   Batch Acc: 73.44
[Train] Epoch: 4 [378112/620022]    Loss: 0.008235   Batch Acc: 79.69
[Train] Epoch: 4 [378176/620022]    Loss: 0.007492   Batch Acc: 84.38
[Train] Epoch: 4 [378240/620022]    Loss: 0.007681   Batch Acc: 78.12
[Train] Epoch: 4 [378304/620022]    Loss: 0.009226   Batch Acc: 70.31
[Train] Epoch: 4 [378368/620022]    Loss: 0.007769   Batch Acc: 84.38
[Train] Epoch: 4 [378432/620022]    Loss: 0.009995   Batch Acc: 70.31
[Train] Epoch: 4 [378496/620022]    Loss: 0.006575   Batch Acc: 85.94
[Train] Epoch: 4 [378560/620022]    Loss: 0.007506   Batch Acc: 76.56
[Train] Epoch: 4 [378624/620022]    Loss: 0.006472   Batch Acc: 87.50
[Train] Epoch: 4 [378688/620022]    Loss: 0.007926   Batch Acc: 81.25
[Train] Epoch: 4 [378752/620022]    Loss: 0.006969   Batch Acc: 82.81
[Train] Epoch: 4 [378816/620022]    Loss: 0.006732   Batch Acc: 87.50
[Train] Epoch: 4 [378880/620022]    Loss: 0.008975   Batch Acc: 75.00
[Train] Epoch: 4 [378944/620022]    Loss: 0.009486   Batch Acc: 75.00
[Train] Epoch: 4 [379008/620022]    Loss: 0.005373   Batch Acc: 87.50
[Train] Epoch: 4 [379072/620022]    Loss: 0.007578   Batch Acc: 79.69
[Train] Epoch: 4 [379136/620022]    Loss: 0.008495   Batch Acc: 76.56
[Train] Epoch: 4 [379200/620022]    Loss: 0.009013   Batch Acc: 73.44
[Train] Epoch: 4 [379264/620022]    Loss: 0.008598   Batch Acc: 79.69
[Train] Epoch: 4 [379328/620022]    Loss: 0.008036   Batch Acc: 76.56
[Train] Epoch: 4 [379392/620022]    Loss: 0.008044   Batch Acc: 76.56
[Train] Epoch: 4 [379456/620022]    Loss: 0.009723   Batch Acc: 75.00
[Train] Epoch: 4 [379520/620022]    Loss: 0.006298   Batch Acc: 85.94
[Train] Epoch: 4 [379584/620022]    Loss: 0.006826   Batch Acc: 81.25
[Train] Epoch: 4 [379648/620022]    Loss: 0.012246   Batch Acc: 75.00
[Train] Epoch: 4 [379712/620022]    Loss: 0.008786   Batch Acc: 79.69
[Train] Epoch: 4 [379776/620022]    Loss: 0.007687   Batch Acc: 75.00
[Train] Epoch: 4 [379840/620022]    Loss: 0.012046   Batch Acc: 67.19
[Train] Epoch: 4 [379904/620022]    Loss: 0.006701   Batch Acc: 82.81
[Train] Epoch: 4 [379968/620022]    Loss: 0.011191   Batch Acc: 73.44
[Train] Epoch: 4 [380032/620022]    Loss: 0.009711   Batch Acc: 70.31
[Train] Epoch: 4 [380096/620022]    Loss: 0.006727   Batch Acc: 82.81
[Train] Epoch: 4 [380160/620022]    Loss: 0.008916   Batch Acc: 79.69
[Train] Epoch: 4 [380224/620022]    Loss: 0.008463   Batch Acc: 76.56
[Train] Epoch: 4 [380288/620022]    Loss: 0.011586   Batch Acc: 70.31
[Train] Epoch: 4 [380352/620022]    Loss: 0.008492   Batch Acc: 76.56
[Train] Epoch: 4 [380416/620022]    Loss: 0.007525   Batch Acc: 82.81
[Train] Epoch: 4 [380480/620022]    Loss: 0.008414   Batch Acc: 79.69
[Train] Epoch: 4 [380544/620022]    Loss: 0.008753   Batch Acc: 71.88
[Train] Epoch: 4 [380608/620022]    Loss: 0.010277   Batch Acc: 70.31
[Train] Epoch: 4 [380672/620022]    Loss: 0.008848   Batch Acc: 76.56
[Train] Epoch: 4 [380736/620022]    Loss: 0.010051   Batch Acc: 73.44
[Train] Epoch: 4 [380800/620022]    Loss: 0.008276   Batch Acc: 81.25
[Train] Epoch: 4 [380864/620022]    Loss: 0.010292   Batch Acc: 67.19
[Train] Epoch: 4 [380928/620022]    Loss: 0.008887   Batch Acc: 78.12
[Train] Epoch: 4 [380992/620022]    Loss: 0.007153   Batch Acc: 81.25
[Train] Epoch: 4 [381056/620022]    Loss: 0.007019   Batch Acc: 84.38
[Train] Epoch: 4 [381120/620022]    Loss: 0.009697   Batch Acc: 76.56
[Train] Epoch: 4 [381184/620022]    Loss: 0.007880   Batch Acc: 78.12
[Train] Epoch: 4 [381248/620022]    Loss: 0.007830   Batch Acc: 85.94
[Train] Epoch: 4 [381312/620022]    Loss: 0.008390   Batch Acc: 76.56
[Train] Epoch: 4 [381376/620022]    Loss: 0.007620   Batch Acc: 81.25
[Train] Epoch: 4 [381440/620022]    Loss: 0.008072   Batch Acc: 81.25
[Train] Epoch: 4 [381504/620022]    Loss: 0.011256   Batch Acc: 68.75
[Train] Epoch: 4 [381568/620022]    Loss: 0.011313   Batch Acc: 67.19
[Train] Epoch: 4 [381632/620022]    Loss: 0.010308   Batch Acc: 73.44
[Train] Epoch: 4 [381696/620022]    Loss: 0.008322   Batch Acc: 81.25
[Train] Epoch: 4 [381760/620022]    Loss: 0.007814   Batch Acc: 76.56
[Train] Epoch: 4 [381824/620022]    Loss: 0.010146   Batch Acc: 68.75
[Train] Epoch: 4 [381888/620022]    Loss: 0.008022   Batch Acc: 82.81
[Train] Epoch: 4 [381952/620022]    Loss: 0.008898   Batch Acc: 75.00
[Train] Epoch: 4 [382016/620022]    Loss: 0.007930   Batch Acc: 78.12
[Train] Epoch: 4 [382080/620022]    Loss: 0.008386   Batch Acc: 82.81
[Train] Epoch: 4 [382144/620022]    Loss: 0.009885   Batch Acc: 73.44
[Train] Epoch: 4 [382208/620022]    Loss: 0.007513   Batch Acc: 81.25
[Train] Epoch: 4 [382272/620022]    Loss: 0.008480   Batch Acc: 82.81
[Train] Epoch: 4 [382336/620022]    Loss: 0.008738   Batch Acc: 78.12
[Train] Epoch: 4 [382400/620022]    Loss: 0.007400   Batch Acc: 85.94
[Train] Epoch: 4 [382464/620022]    Loss: 0.007876   Batch Acc: 79.69
[Train] Epoch: 4 [382528/620022]    Loss: 0.012732   Batch Acc: 64.06
[Train] Epoch: 4 [382592/620022]    Loss: 0.009961   Batch Acc: 73.44
[Train] Epoch: 4 [382656/620022]    Loss: 0.006702   Batch Acc: 85.94
[Train] Epoch: 4 [382720/620022]    Loss: 0.007199   Batch Acc: 87.50
[Train] Epoch: 4 [382784/620022]    Loss: 0.009545   Batch Acc: 81.25
[Train] Epoch: 4 [382848/620022]    Loss: 0.007933   Batch Acc: 78.12
[Train] Epoch: 4 [382912/620022]    Loss: 0.006999   Batch Acc: 81.25
[Train] Epoch: 4 [382976/620022]    Loss: 0.008559   Batch Acc: 78.12
[Train] Epoch: 4 [383040/620022]    Loss: 0.008986   Batch Acc: 73.44
[Train] Epoch: 4 [383104/620022]    Loss: 0.008386   Batch Acc: 78.12
[Train] Epoch: 4 [383168/620022]    Loss: 0.007334   Batch Acc: 79.69
[Train] Epoch: 4 [383232/620022]    Loss: 0.010251   Batch Acc: 71.88
[Train] Epoch: 4 [383296/620022]    Loss: 0.010478   Batch Acc: 73.44
[Train] Epoch: 4 [383360/620022]    Loss: 0.009074   Batch Acc: 78.12
[Train] Epoch: 4 [383424/620022]    Loss: 0.008851   Batch Acc: 75.00
[Train] Epoch: 4 [383488/620022]    Loss: 0.009401   Batch Acc: 73.44
[Train] Epoch: 4 [383552/620022]    Loss: 0.009386   Batch Acc: 75.00
[Train] Epoch: 4 [383616/620022]    Loss: 0.009189   Batch Acc: 79.69
[Train] Epoch: 4 [383680/620022]    Loss: 0.009933   Batch Acc: 79.69
[Train] Epoch: 4 [383744/620022]    Loss: 0.006513   Batch Acc: 85.94
[Train] Epoch: 4 [383808/620022]    Loss: 0.007011   Batch Acc: 82.81
[Train] Epoch: 4 [383872/620022]    Loss: 0.005940   Batch Acc: 87.50
[Train] Epoch: 4 [383936/620022]    Loss: 0.008593   Batch Acc: 82.81
[Train] Epoch: 4 [384000/620022]    Loss: 0.008104   Batch Acc: 75.00
[Train] Epoch: 4 [384064/620022]    Loss: 0.008615   Batch Acc: 75.00
[Train] Epoch: 4 [384128/620022]    Loss: 0.007782   Batch Acc: 71.88
[Train] Epoch: 4 [384192/620022]    Loss: 0.007154   Batch Acc: 89.06
[Train] Epoch: 4 [384256/620022]    Loss: 0.007351   Batch Acc: 81.25
[Train] Epoch: 4 [384320/620022]    Loss: 0.006946   Batch Acc: 81.25
[Train] Epoch: 4 [384384/620022]    Loss: 0.010516   Batch Acc: 71.88
[Train] Epoch: 4 [384448/620022]    Loss: 0.007087   Batch Acc: 79.69
[Train] Epoch: 4 [384512/620022]    Loss: 0.010659   Batch Acc: 73.44
[Train] Epoch: 4 [384576/620022]    Loss: 0.007764   Batch Acc: 78.12
[Train] Epoch: 4 [384640/620022]    Loss: 0.008457   Batch Acc: 81.25
[Train] Epoch: 4 [384704/620022]    Loss: 0.008076   Batch Acc: 81.25
[Train] Epoch: 4 [384768/620022]    Loss: 0.008970   Batch Acc: 79.69
[Train] Epoch: 4 [384832/620022]    Loss: 0.009502   Batch Acc: 76.56
[Train] Epoch: 4 [384896/620022]    Loss: 0.004951   Batch Acc: 93.75
[Train] Epoch: 4 [384960/620022]    Loss: 0.009743   Batch Acc: 75.00
[Train] Epoch: 4 [385024/620022]    Loss: 0.010692   Batch Acc: 71.88
[Train] Epoch: 4 [385088/620022]    Loss: 0.008533   Batch Acc: 76.56
[Train] Epoch: 4 [385152/620022]    Loss: 0.009050   Batch Acc: 85.94
[Train] Epoch: 4 [385216/620022]    Loss: 0.007437   Batch Acc: 79.69
[Train] Epoch: 4 [385280/620022]    Loss: 0.006128   Batch Acc: 82.81
[Train] Epoch: 4 [385344/620022]    Loss: 0.008655   Batch Acc: 75.00
[Train] Epoch: 4 [385408/620022]    Loss: 0.011071   Batch Acc: 71.88
[Train] Epoch: 4 [385472/620022]    Loss: 0.007671   Batch Acc: 79.69
[Train] Epoch: 4 [385536/620022]    Loss: 0.009262   Batch Acc: 78.12
[Train] Epoch: 4 [385600/620022]    Loss: 0.010686   Batch Acc: 71.88
[Train] Epoch: 4 [385664/620022]    Loss: 0.009414   Batch Acc: 64.06
[Train] Epoch: 4 [385728/620022]    Loss: 0.009533   Batch Acc: 76.56
[Train] Epoch: 4 [385792/620022]    Loss: 0.008109   Batch Acc: 76.56
[Train] Epoch: 4 [385856/620022]    Loss: 0.004736   Batch Acc: 90.62
[Train] Epoch: 4 [385920/620022]    Loss: 0.008822   Batch Acc: 79.69
[Train] Epoch: 4 [385984/620022]    Loss: 0.007549   Batch Acc: 85.94
[Train] Epoch: 4 [386048/620022]    Loss: 0.007048   Batch Acc: 82.81
[Train] Epoch: 4 [386112/620022]    Loss: 0.009129   Batch Acc: 75.00
[Train] Epoch: 4 [386176/620022]    Loss: 0.007628   Batch Acc: 82.81
[Train] Epoch: 4 [386240/620022]    Loss: 0.007559   Batch Acc: 82.81
[Train] Epoch: 4 [386304/620022]    Loss: 0.008098   Batch Acc: 82.81
[Train] Epoch: 4 [386368/620022]    Loss: 0.007451   Batch Acc: 78.12
[Train] Epoch: 4 [386432/620022]    Loss: 0.009856   Batch Acc: 71.88
[Train] Epoch: 4 [386496/620022]    Loss: 0.007445   Batch Acc: 81.25
[Train] Epoch: 4 [386560/620022]    Loss: 0.010088   Batch Acc: 71.88
[Train] Epoch: 4 [386624/620022]    Loss: 0.007754   Batch Acc: 78.12
[Train] Epoch: 4 [386688/620022]    Loss: 0.008230   Batch Acc: 81.25
[Train] Epoch: 4 [386752/620022]    Loss: 0.008461   Batch Acc: 78.12
[Train] Epoch: 4 [386816/620022]    Loss: 0.006905   Batch Acc: 82.81
[Train] Epoch: 4 [386880/620022]    Loss: 0.008704   Batch Acc: 78.12
[Train] Epoch: 4 [386944/620022]    Loss: 0.007534   Batch Acc: 82.81
[Train] Epoch: 4 [387008/620022]    Loss: 0.008940   Batch Acc: 75.00
[Train] Epoch: 4 [387072/620022]    Loss: 0.008047   Batch Acc: 78.12
[Train] Epoch: 4 [387136/620022]    Loss: 0.009426   Batch Acc: 71.88
[Train] Epoch: 4 [387200/620022]    Loss: 0.008610   Batch Acc: 79.69
[Train] Epoch: 4 [387264/620022]    Loss: 0.009836   Batch Acc: 71.88
[Train] Epoch: 4 [387328/620022]    Loss: 0.008451   Batch Acc: 82.81
[Train] Epoch: 4 [387392/620022]    Loss: 0.009864   Batch Acc: 70.31
[Train] Epoch: 4 [387456/620022]    Loss: 0.007994   Batch Acc: 81.25
[Train] Epoch: 4 [387520/620022]    Loss: 0.008445   Batch Acc: 85.94
[Train] Epoch: 4 [387584/620022]    Loss: 0.010177   Batch Acc: 71.88
[Train] Epoch: 4 [387648/620022]    Loss: 0.010046   Batch Acc: 70.31
[Train] Epoch: 4 [387712/620022]    Loss: 0.007030   Batch Acc: 82.81
[Train] Epoch: 4 [387776/620022]    Loss: 0.008232   Batch Acc: 78.12
[Train] Epoch: 4 [387840/620022]    Loss: 0.006540   Batch Acc: 81.25
[Train] Epoch: 4 [387904/620022]    Loss: 0.008698   Batch Acc: 75.00
[Train] Epoch: 4 [387968/620022]    Loss: 0.008908   Batch Acc: 79.69
[Train] Epoch: 4 [388032/620022]    Loss: 0.008934   Batch Acc: 78.12
[Train] Epoch: 4 [388096/620022]    Loss: 0.008596   Batch Acc: 78.12
[Train] Epoch: 4 [388160/620022]    Loss: 0.006382   Batch Acc: 81.25
[Train] Epoch: 4 [388224/620022]    Loss: 0.009531   Batch Acc: 71.88
[Train] Epoch: 4 [388288/620022]    Loss: 0.008046   Batch Acc: 82.81
[Train] Epoch: 4 [388352/620022]    Loss: 0.008461   Batch Acc: 76.56
[Train] Epoch: 4 [388416/620022]    Loss: 0.009993   Batch Acc: 76.56
[Train] Epoch: 4 [388480/620022]    Loss: 0.011505   Batch Acc: 68.75
[Train] Epoch: 4 [388544/620022]    Loss: 0.008541   Batch Acc: 79.69
[Train] Epoch: 4 [388608/620022]    Loss: 0.010039   Batch Acc: 65.62
[Train] Epoch: 4 [388672/620022]    Loss: 0.009176   Batch Acc: 78.12
[Train] Epoch: 4 [388736/620022]    Loss: 0.007070   Batch Acc: 81.25
[Train] Epoch: 4 [388800/620022]    Loss: 0.008042   Batch Acc: 78.12
[Train] Epoch: 4 [388864/620022]    Loss: 0.012074   Batch Acc: 70.31
[Train] Epoch: 4 [388928/620022]    Loss: 0.008659   Batch Acc: 79.69
[Train] Epoch: 4 [388992/620022]    Loss: 0.009146   Batch Acc: 78.12
[Train] Epoch: 4 [389056/620022]    Loss: 0.009325   Batch Acc: 73.44
[Train] Epoch: 4 [389120/620022]    Loss: 0.009366   Batch Acc: 79.69
[Train] Epoch: 4 [389184/620022]    Loss: 0.006594   Batch Acc: 84.38
[Train] Epoch: 4 [389248/620022]    Loss: 0.010322   Batch Acc: 73.44
[Train] Epoch: 4 [389312/620022]    Loss: 0.010242   Batch Acc: 70.31
[Train] Epoch: 4 [389376/620022]    Loss: 0.009846   Batch Acc: 75.00
[Train] Epoch: 4 [389440/620022]    Loss: 0.008401   Batch Acc: 79.69
[Train] Epoch: 4 [389504/620022]    Loss: 0.009951   Batch Acc: 76.56
[Train] Epoch: 4 [389568/620022]    Loss: 0.006721   Batch Acc: 81.25
[Train] Epoch: 4 [389632/620022]    Loss: 0.010218   Batch Acc: 75.00
[Train] Epoch: 4 [389696/620022]    Loss: 0.008783   Batch Acc: 79.69
[Train] Epoch: 4 [389760/620022]    Loss: 0.008755   Batch Acc: 73.44
[Train] Epoch: 4 [389824/620022]    Loss: 0.010377   Batch Acc: 71.88
[Train] Epoch: 4 [389888/620022]    Loss: 0.008938   Batch Acc: 81.25
[Train] Epoch: 4 [389952/620022]    Loss: 0.011723   Batch Acc: 71.88
[Train] Epoch: 4 [390016/620022]    Loss: 0.011270   Batch Acc: 70.31
[Train] Epoch: 4 [390080/620022]    Loss: 0.008607   Batch Acc: 78.12
[Train] Epoch: 4 [390144/620022]    Loss: 0.010533   Batch Acc: 73.44
[Train] Epoch: 4 [390208/620022]    Loss: 0.009417   Batch Acc: 76.56
[Train] Epoch: 4 [390272/620022]    Loss: 0.009820   Batch Acc: 73.44
[Train] Epoch: 4 [390336/620022]    Loss: 0.008354   Batch Acc: 78.12
[Train] Epoch: 4 [390400/620022]    Loss: 0.009130   Batch Acc: 73.44
[Train] Epoch: 4 [390464/620022]    Loss: 0.008087   Batch Acc: 84.38
[Train] Epoch: 4 [390528/620022]    Loss: 0.011031   Batch Acc: 65.62
[Train] Epoch: 4 [390592/620022]    Loss: 0.009158   Batch Acc: 76.56
[Train] Epoch: 4 [390656/620022]    Loss: 0.007935   Batch Acc: 82.81
[Train] Epoch: 4 [390720/620022]    Loss: 0.008546   Batch Acc: 75.00
[Train] Epoch: 4 [390784/620022]    Loss: 0.010296   Batch Acc: 70.31
[Train] Epoch: 4 [390848/620022]    Loss: 0.008407   Batch Acc: 82.81
[Train] Epoch: 4 [390912/620022]    Loss: 0.007721   Batch Acc: 82.81
[Train] Epoch: 4 [390976/620022]    Loss: 0.007063   Batch Acc: 84.38
[Train] Epoch: 4 [391040/620022]    Loss: 0.007790   Batch Acc: 81.25
[Train] Epoch: 4 [391104/620022]    Loss: 0.007918   Batch Acc: 79.69
[Train] Epoch: 4 [391168/620022]    Loss: 0.009999   Batch Acc: 71.88
[Train] Epoch: 4 [391232/620022]    Loss: 0.009491   Batch Acc: 70.31
[Train] Epoch: 4 [391296/620022]    Loss: 0.008729   Batch Acc: 79.69
[Train] Epoch: 4 [391360/620022]    Loss: 0.009282   Batch Acc: 81.25
[Train] Epoch: 4 [391424/620022]    Loss: 0.008164   Batch Acc: 79.69
[Train] Epoch: 4 [391488/620022]    Loss: 0.008105   Batch Acc: 79.69
[Train] Epoch: 4 [391552/620022]    Loss: 0.008650   Batch Acc: 79.69
[Train] Epoch: 4 [391616/620022]    Loss: 0.008170   Batch Acc: 76.56
[Train] Epoch: 4 [391680/620022]    Loss: 0.009468   Batch Acc: 65.62
[Train] Epoch: 4 [391744/620022]    Loss: 0.008530   Batch Acc: 76.56
[Train] Epoch: 4 [391808/620022]    Loss: 0.007790   Batch Acc: 78.12
[Train] Epoch: 4 [391872/620022]    Loss: 0.008798   Batch Acc: 73.44
[Train] Epoch: 4 [391936/620022]    Loss: 0.007153   Batch Acc: 85.94
[Train] Epoch: 4 [392000/620022]    Loss: 0.010649   Batch Acc: 71.88
[Train] Epoch: 4 [392064/620022]    Loss: 0.009916   Batch Acc: 76.56
[Train] Epoch: 4 [392128/620022]    Loss: 0.009643   Batch Acc: 73.44
[Train] Epoch: 4 [392192/620022]    Loss: 0.007059   Batch Acc: 85.94
[Train] Epoch: 4 [392256/620022]    Loss: 0.009366   Batch Acc: 76.56
[Train] Epoch: 4 [392320/620022]    Loss: 0.008437   Batch Acc: 84.38
[Train] Epoch: 4 [392384/620022]    Loss: 0.010834   Batch Acc: 70.31
[Train] Epoch: 4 [392448/620022]    Loss: 0.007412   Batch Acc: 79.69
[Train] Epoch: 4 [392512/620022]    Loss: 0.010385   Batch Acc: 70.31
[Train] Epoch: 4 [392576/620022]    Loss: 0.009841   Batch Acc: 68.75
[Train] Epoch: 4 [392640/620022]    Loss: 0.009897   Batch Acc: 81.25
[Train] Epoch: 4 [392704/620022]    Loss: 0.007594   Batch Acc: 75.00
[Train] Epoch: 4 [392768/620022]    Loss: 0.007179   Batch Acc: 79.69
[Train] Epoch: 4 [392832/620022]    Loss: 0.009542   Batch Acc: 75.00
[Train] Epoch: 4 [392896/620022]    Loss: 0.009300   Batch Acc: 78.12
[Train] Epoch: 4 [392960/620022]    Loss: 0.014023   Batch Acc: 62.50
[Train] Epoch: 4 [393024/620022]    Loss: 0.008091   Batch Acc: 76.56
[Train] Epoch: 4 [393088/620022]    Loss: 0.008121   Batch Acc: 75.00
[Train] Epoch: 4 [393152/620022]    Loss: 0.007039   Batch Acc: 81.25
[Train] Epoch: 4 [393216/620022]    Loss: 0.009513   Batch Acc: 70.31
[Train] Epoch: 4 [393280/620022]    Loss: 0.010013   Batch Acc: 75.00
[Train] Epoch: 4 [393344/620022]    Loss: 0.007175   Batch Acc: 79.69
[Train] Epoch: 4 [393408/620022]    Loss: 0.010251   Batch Acc: 73.44
[Train] Epoch: 4 [393472/620022]    Loss: 0.008966   Batch Acc: 78.12
[Train] Epoch: 4 [393536/620022]    Loss: 0.009599   Batch Acc: 64.06
[Train] Epoch: 4 [393600/620022]    Loss: 0.009111   Batch Acc: 79.69
[Train] Epoch: 4 [393664/620022]    Loss: 0.011915   Batch Acc: 64.06
[Train] Epoch: 4 [393728/620022]    Loss: 0.010465   Batch Acc: 79.69
[Train] Epoch: 4 [393792/620022]    Loss: 0.006694   Batch Acc: 85.94
[Train] Epoch: 4 [393856/620022]    Loss: 0.005931   Batch Acc: 89.06
[Train] Epoch: 4 [393920/620022]    Loss: 0.010111   Batch Acc: 68.75
[Train] Epoch: 4 [393984/620022]    Loss: 0.008202   Batch Acc: 79.69
[Train] Epoch: 4 [394048/620022]    Loss: 0.008856   Batch Acc: 78.12
[Train] Epoch: 4 [394112/620022]    Loss: 0.010765   Batch Acc: 65.62
[Train] Epoch: 4 [394176/620022]    Loss: 0.009106   Batch Acc: 79.69
[Train] Epoch: 4 [394240/620022]    Loss: 0.007564   Batch Acc: 78.12
[Train] Epoch: 4 [394304/620022]    Loss: 0.007522   Batch Acc: 84.38
[Train] Epoch: 4 [394368/620022]    Loss: 0.006104   Batch Acc: 85.94
[Train] Epoch: 4 [394432/620022]    Loss: 0.007436   Batch Acc: 81.25
[Train] Epoch: 4 [394496/620022]    Loss: 0.011049   Batch Acc: 67.19
[Train] Epoch: 4 [394560/620022]    Loss: 0.008545   Batch Acc: 76.56
[Train] Epoch: 4 [394624/620022]    Loss: 0.006730   Batch Acc: 85.94
[Train] Epoch: 4 [394688/620022]    Loss: 0.008454   Batch Acc: 84.38
[Train] Epoch: 4 [394752/620022]    Loss: 0.011711   Batch Acc: 71.88
[Train] Epoch: 4 [394816/620022]    Loss: 0.010788   Batch Acc: 65.62
[Train] Epoch: 4 [394880/620022]    Loss: 0.008841   Batch Acc: 78.12
[Train] Epoch: 4 [394944/620022]    Loss: 0.007801   Batch Acc: 81.25
[Train] Epoch: 4 [395008/620022]    Loss: 0.008608   Batch Acc: 76.56
[Train] Epoch: 4 [395072/620022]    Loss: 0.008769   Batch Acc: 75.00
[Train] Epoch: 4 [395136/620022]    Loss: 0.008909   Batch Acc: 75.00
[Train] Epoch: 4 [395200/620022]    Loss: 0.008385   Batch Acc: 79.69
[Train] Epoch: 4 [395264/620022]    Loss: 0.008237   Batch Acc: 79.69
[Train] Epoch: 4 [395328/620022]    Loss: 0.006593   Batch Acc: 84.38
[Train] Epoch: 4 [395392/620022]    Loss: 0.009481   Batch Acc: 75.00
[Train] Epoch: 4 [395456/620022]    Loss: 0.008084   Batch Acc: 79.69
[Train] Epoch: 4 [395520/620022]    Loss: 0.008090   Batch Acc: 78.12
[Train] Epoch: 4 [395584/620022]    Loss: 0.009534   Batch Acc: 78.12
[Train] Epoch: 4 [395648/620022]    Loss: 0.007464   Batch Acc: 81.25
[Train] Epoch: 4 [395712/620022]    Loss: 0.008133   Batch Acc: 81.25
[Train] Epoch: 4 [395776/620022]    Loss: 0.006950   Batch Acc: 82.81
[Train] Epoch: 4 [395840/620022]    Loss: 0.008368   Batch Acc: 76.56
[Train] Epoch: 4 [395904/620022]    Loss: 0.008005   Batch Acc: 79.69
[Train] Epoch: 4 [395968/620022]    Loss: 0.008490   Batch Acc: 79.69
[Train] Epoch: 4 [396032/620022]    Loss: 0.007450   Batch Acc: 81.25
[Train] Epoch: 4 [396096/620022]    Loss: 0.008158   Batch Acc: 78.12
[Train] Epoch: 4 [396160/620022]    Loss: 0.007977   Batch Acc: 81.25
[Train] Epoch: 4 [396224/620022]    Loss: 0.008230   Batch Acc: 78.12
[Train] Epoch: 4 [396288/620022]    Loss: 0.007138   Batch Acc: 81.25
[Train] Epoch: 4 [396352/620022]    Loss: 0.008095   Batch Acc: 79.69
[Train] Epoch: 4 [396416/620022]    Loss: 0.009275   Batch Acc: 73.44
[Train] Epoch: 4 [396480/620022]    Loss: 0.007221   Batch Acc: 84.38
[Train] Epoch: 4 [396544/620022]    Loss: 0.007130   Batch Acc: 90.62
[Train] Epoch: 4 [396608/620022]    Loss: 0.010933   Batch Acc: 73.44
[Train] Epoch: 4 [396672/620022]    Loss: 0.010314   Batch Acc: 73.44
[Train] Epoch: 4 [396736/620022]    Loss: 0.010794   Batch Acc: 73.44
[Train] Epoch: 4 [396800/620022]    Loss: 0.007869   Batch Acc: 78.12
[Train] Epoch: 4 [396864/620022]    Loss: 0.007680   Batch Acc: 78.12
[Train] Epoch: 4 [396928/620022]    Loss: 0.009207   Batch Acc: 73.44
[Train] Epoch: 4 [396992/620022]    Loss: 0.008225   Batch Acc: 79.69
[Train] Epoch: 4 [397056/620022]    Loss: 0.006917   Batch Acc: 82.81
[Train] Epoch: 4 [397120/620022]    Loss: 0.008922   Batch Acc: 84.38
[Train] Epoch: 4 [397184/620022]    Loss: 0.010578   Batch Acc: 65.62
[Train] Epoch: 4 [397248/620022]    Loss: 0.008785   Batch Acc: 76.56
[Train] Epoch: 4 [397312/620022]    Loss: 0.007863   Batch Acc: 76.56
[Train] Epoch: 4 [397376/620022]    Loss: 0.007352   Batch Acc: 84.38
[Train] Epoch: 4 [397440/620022]    Loss: 0.009756   Batch Acc: 76.56
[Train] Epoch: 4 [397504/620022]    Loss: 0.007591   Batch Acc: 78.12
[Train] Epoch: 4 [397568/620022]    Loss: 0.009549   Batch Acc: 76.56
[Train] Epoch: 4 [397632/620022]    Loss: 0.010315   Batch Acc: 73.44
[Train] Epoch: 4 [397696/620022]    Loss: 0.009929   Batch Acc: 71.88
[Train] Epoch: 4 [397760/620022]    Loss: 0.009098   Batch Acc: 78.12
[Train] Epoch: 4 [397824/620022]    Loss: 0.011051   Batch Acc: 75.00
[Train] Epoch: 4 [397888/620022]    Loss: 0.009361   Batch Acc: 71.88
[Train] Epoch: 4 [397952/620022]    Loss: 0.007880   Batch Acc: 78.12
[Train] Epoch: 4 [398016/620022]    Loss: 0.006665   Batch Acc: 85.94
[Train] Epoch: 4 [398080/620022]    Loss: 0.009384   Batch Acc: 75.00
[Train] Epoch: 4 [398144/620022]    Loss: 0.007332   Batch Acc: 84.38
[Train] Epoch: 4 [398208/620022]    Loss: 0.008329   Batch Acc: 79.69
[Train] Epoch: 4 [398272/620022]    Loss: 0.007449   Batch Acc: 78.12
[Train] Epoch: 4 [398336/620022]    Loss: 0.008593   Batch Acc: 73.44
[Train] Epoch: 4 [398400/620022]    Loss: 0.007885   Batch Acc: 81.25
[Train] Epoch: 4 [398464/620022]    Loss: 0.007636   Batch Acc: 84.38
[Train] Epoch: 4 [398528/620022]    Loss: 0.006218   Batch Acc: 87.50
[Train] Epoch: 4 [398592/620022]    Loss: 0.007635   Batch Acc: 84.38
[Train] Epoch: 4 [398656/620022]    Loss: 0.008992   Batch Acc: 82.81
[Train] Epoch: 4 [398720/620022]    Loss: 0.007057   Batch Acc: 81.25
[Train] Epoch: 4 [398784/620022]    Loss: 0.008497   Batch Acc: 75.00
[Train] Epoch: 4 [398848/620022]    Loss: 0.010644   Batch Acc: 73.44
[Train] Epoch: 4 [398912/620022]    Loss: 0.008840   Batch Acc: 78.12
[Train] Epoch: 4 [398976/620022]    Loss: 0.008127   Batch Acc: 75.00
[Train] Epoch: 4 [399040/620022]    Loss: 0.012002   Batch Acc: 70.31
[Train] Epoch: 4 [399104/620022]    Loss: 0.006274   Batch Acc: 87.50
[Train] Epoch: 4 [399168/620022]    Loss: 0.009104   Batch Acc: 76.56
[Train] Epoch: 4 [399232/620022]    Loss: 0.006843   Batch Acc: 84.38
[Train] Epoch: 4 [399296/620022]    Loss: 0.008881   Batch Acc: 78.12
[Train] Epoch: 4 [399360/620022]    Loss: 0.006678   Batch Acc: 85.94
[Train] Epoch: 4 [399424/620022]    Loss: 0.009774   Batch Acc: 73.44
[Train] Epoch: 4 [399488/620022]    Loss: 0.007580   Batch Acc: 81.25
[Train] Epoch: 4 [399552/620022]    Loss: 0.009215   Batch Acc: 79.69
[Train] Epoch: 4 [399616/620022]    Loss: 0.007540   Batch Acc: 81.25
[Train] Epoch: 4 [399680/620022]    Loss: 0.009814   Batch Acc: 78.12
[Train] Epoch: 4 [399744/620022]    Loss: 0.007198   Batch Acc: 82.81
[Train] Epoch: 4 [399808/620022]    Loss: 0.008425   Batch Acc: 78.12
[Train] Epoch: 4 [399872/620022]    Loss: 0.007484   Batch Acc: 78.12
[Train] Epoch: 4 [399936/620022]    Loss: 0.009895   Batch Acc: 75.00
[Train] Epoch: 4 [400000/620022]    Loss: 0.008636   Batch Acc: 79.69
[Train] Epoch: 4 [400064/620022]    Loss: 0.006970   Batch Acc: 87.50
[Train] Epoch: 4 [400128/620022]    Loss: 0.009604   Batch Acc: 75.00
[Train] Epoch: 4 [400192/620022]    Loss: 0.009509   Batch Acc: 68.75
[Train] Epoch: 4 [400256/620022]    Loss: 0.008214   Batch Acc: 79.69
[Train] Epoch: 4 [400320/620022]    Loss: 0.008361   Batch Acc: 78.12
[Train] Epoch: 4 [400384/620022]    Loss: 0.008402   Batch Acc: 76.56
[Train] Epoch: 4 [400448/620022]    Loss: 0.008362   Batch Acc: 79.69
[Train] Epoch: 4 [400512/620022]    Loss: 0.009466   Batch Acc: 76.56
[Train] Epoch: 4 [400576/620022]    Loss: 0.009036   Batch Acc: 70.31
[Train] Epoch: 4 [400640/620022]    Loss: 0.007969   Batch Acc: 78.12
[Train] Epoch: 4 [400704/620022]    Loss: 0.007499   Batch Acc: 78.12
[Train] Epoch: 4 [400768/620022]    Loss: 0.007416   Batch Acc: 78.12
[Train] Epoch: 4 [400832/620022]    Loss: 0.007111   Batch Acc: 84.38
[Train] Epoch: 4 [400896/620022]    Loss: 0.008059   Batch Acc: 82.81
[Train] Epoch: 4 [400960/620022]    Loss: 0.009165   Batch Acc: 81.25
[Train] Epoch: 4 [401024/620022]    Loss: 0.008137   Batch Acc: 81.25
[Train] Epoch: 4 [401088/620022]    Loss: 0.009441   Batch Acc: 81.25
[Train] Epoch: 4 [401152/620022]    Loss: 0.011181   Batch Acc: 73.44
[Train] Epoch: 4 [401216/620022]    Loss: 0.008175   Batch Acc: 76.56
[Train] Epoch: 4 [401280/620022]    Loss: 0.009642   Batch Acc: 78.12
[Train] Epoch: 4 [401344/620022]    Loss: 0.010217   Batch Acc: 73.44
[Train] Epoch: 4 [401408/620022]    Loss: 0.007970   Batch Acc: 79.69
[Train] Epoch: 4 [401472/620022]    Loss: 0.009871   Batch Acc: 75.00
[Train] Epoch: 4 [401536/620022]    Loss: 0.009003   Batch Acc: 76.56
[Train] Epoch: 4 [401600/620022]    Loss: 0.009620   Batch Acc: 75.00
[Train] Epoch: 4 [401664/620022]    Loss: 0.006995   Batch Acc: 84.38
[Train] Epoch: 4 [401728/620022]    Loss: 0.010432   Batch Acc: 71.88
[Train] Epoch: 4 [401792/620022]    Loss: 0.010888   Batch Acc: 71.88
[Train] Epoch: 4 [401856/620022]    Loss: 0.008997   Batch Acc: 73.44
[Train] Epoch: 4 [401920/620022]    Loss: 0.008498   Batch Acc: 76.56
[Train] Epoch: 4 [401984/620022]    Loss: 0.008771   Batch Acc: 75.00
[Train] Epoch: 4 [402048/620022]    Loss: 0.008189   Batch Acc: 81.25
[Train] Epoch: 4 [402112/620022]    Loss: 0.010149   Batch Acc: 75.00
[Train] Epoch: 4 [402176/620022]    Loss: 0.009293   Batch Acc: 70.31
[Train] Epoch: 4 [402240/620022]    Loss: 0.009761   Batch Acc: 78.12
[Train] Epoch: 4 [402304/620022]    Loss: 0.008344   Batch Acc: 73.44
[Train] Epoch: 4 [402368/620022]    Loss: 0.009459   Batch Acc: 75.00
[Train] Epoch: 4 [402432/620022]    Loss: 0.007612   Batch Acc: 79.69
[Train] Epoch: 4 [402496/620022]    Loss: 0.008366   Batch Acc: 73.44
[Train] Epoch: 4 [402560/620022]    Loss: 0.009341   Batch Acc: 70.31
[Train] Epoch: 4 [402624/620022]    Loss: 0.010474   Batch Acc: 78.12
[Train] Epoch: 4 [402688/620022]    Loss: 0.010179   Batch Acc: 75.00
[Train] Epoch: 4 [402752/620022]    Loss: 0.006069   Batch Acc: 82.81
[Train] Epoch: 4 [402816/620022]    Loss: 0.009192   Batch Acc: 73.44
[Train] Epoch: 4 [402880/620022]    Loss: 0.007695   Batch Acc: 75.00
[Train] Epoch: 4 [402944/620022]    Loss: 0.007630   Batch Acc: 85.94
[Train] Epoch: 4 [403008/620022]    Loss: 0.007716   Batch Acc: 79.69
[Train] Epoch: 4 [403072/620022]    Loss: 0.007114   Batch Acc: 81.25
[Train] Epoch: 4 [403136/620022]    Loss: 0.009869   Batch Acc: 71.88
[Train] Epoch: 4 [403200/620022]    Loss: 0.009306   Batch Acc: 78.12
[Train] Epoch: 4 [403264/620022]    Loss: 0.009111   Batch Acc: 78.12
[Train] Epoch: 4 [403328/620022]    Loss: 0.008159   Batch Acc: 81.25
[Train] Epoch: 4 [403392/620022]    Loss: 0.008468   Batch Acc: 78.12
[Train] Epoch: 4 [403456/620022]    Loss: 0.009500   Batch Acc: 71.88
[Train] Epoch: 4 [403520/620022]    Loss: 0.008183   Batch Acc: 76.56
[Train] Epoch: 4 [403584/620022]    Loss: 0.008984   Batch Acc: 81.25
[Train] Epoch: 4 [403648/620022]    Loss: 0.007859   Batch Acc: 85.94
[Train] Epoch: 4 [403712/620022]    Loss: 0.006705   Batch Acc: 82.81
[Train] Epoch: 4 [403776/620022]    Loss: 0.009052   Batch Acc: 71.88
[Train] Epoch: 4 [403840/620022]    Loss: 0.008794   Batch Acc: 73.44
[Train] Epoch: 4 [403904/620022]    Loss: 0.008858   Batch Acc: 73.44
[Train] Epoch: 4 [403968/620022]    Loss: 0.007977   Batch Acc: 78.12
[Train] Epoch: 4 [404032/620022]    Loss: 0.010337   Batch Acc: 71.88
[Train] Epoch: 4 [404096/620022]    Loss: 0.010210   Batch Acc: 67.19
[Train] Epoch: 4 [404160/620022]    Loss: 0.008228   Batch Acc: 81.25
[Train] Epoch: 4 [404224/620022]    Loss: 0.008965   Batch Acc: 81.25
[Train] Epoch: 4 [404288/620022]    Loss: 0.009304   Batch Acc: 79.69
[Train] Epoch: 4 [404352/620022]    Loss: 0.009714   Batch Acc: 76.56
[Train] Epoch: 4 [404416/620022]    Loss: 0.009282   Batch Acc: 70.31
[Train] Epoch: 4 [404480/620022]    Loss: 0.007339   Batch Acc: 81.25
[Train] Epoch: 4 [404544/620022]    Loss: 0.010803   Batch Acc: 73.44
[Train] Epoch: 4 [404608/620022]    Loss: 0.007277   Batch Acc: 84.38
[Train] Epoch: 4 [404672/620022]    Loss: 0.006810   Batch Acc: 84.38
[Train] Epoch: 4 [404736/620022]    Loss: 0.009776   Batch Acc: 73.44
[Train] Epoch: 4 [404800/620022]    Loss: 0.009106   Batch Acc: 78.12
[Train] Epoch: 4 [404864/620022]    Loss: 0.009535   Batch Acc: 71.88
[Train] Epoch: 4 [404928/620022]    Loss: 0.007676   Batch Acc: 78.12
[Train] Epoch: 4 [404992/620022]    Loss: 0.010131   Batch Acc: 71.88
[Train] Epoch: 4 [405056/620022]    Loss: 0.007683   Batch Acc: 79.69
[Train] Epoch: 4 [405120/620022]    Loss: 0.005745   Batch Acc: 87.50
[Train] Epoch: 4 [405184/620022]    Loss: 0.006694   Batch Acc: 84.38
[Train] Epoch: 4 [405248/620022]    Loss: 0.009406   Batch Acc: 76.56
[Train] Epoch: 4 [405312/620022]    Loss: 0.008480   Batch Acc: 68.75
[Train] Epoch: 4 [405376/620022]    Loss: 0.007564   Batch Acc: 79.69
[Train] Epoch: 4 [405440/620022]    Loss: 0.008192   Batch Acc: 78.12
[Train] Epoch: 4 [405504/620022]    Loss: 0.007138   Batch Acc: 84.38
[Train] Epoch: 4 [405568/620022]    Loss: 0.011911   Batch Acc: 70.31
[Train] Epoch: 4 [405632/620022]    Loss: 0.008872   Batch Acc: 68.75
[Train] Epoch: 4 [405696/620022]    Loss: 0.008657   Batch Acc: 79.69
[Train] Epoch: 4 [405760/620022]    Loss: 0.008840   Batch Acc: 73.44
[Train] Epoch: 4 [405824/620022]    Loss: 0.006816   Batch Acc: 84.38
[Train] Epoch: 4 [405888/620022]    Loss: 0.008018   Batch Acc: 78.12
[Train] Epoch: 4 [405952/620022]    Loss: 0.007936   Batch Acc: 78.12
[Train] Epoch: 4 [406016/620022]    Loss: 0.007653   Batch Acc: 76.56
[Train] Epoch: 4 [406080/620022]    Loss: 0.008880   Batch Acc: 78.12
[Train] Epoch: 4 [406144/620022]    Loss: 0.010094   Batch Acc: 75.00
[Train] Epoch: 4 [406208/620022]    Loss: 0.009033   Batch Acc: 76.56
[Train] Epoch: 4 [406272/620022]    Loss: 0.011350   Batch Acc: 68.75
[Train] Epoch: 4 [406336/620022]    Loss: 0.006111   Batch Acc: 84.38
[Train] Epoch: 4 [406400/620022]    Loss: 0.009673   Batch Acc: 68.75
[Train] Epoch: 4 [406464/620022]    Loss: 0.008116   Batch Acc: 81.25
[Train] Epoch: 4 [406528/620022]    Loss: 0.008781   Batch Acc: 76.56
[Train] Epoch: 4 [406592/620022]    Loss: 0.007633   Batch Acc: 85.94
[Train] Epoch: 4 [406656/620022]    Loss: 0.007392   Batch Acc: 81.25
[Train] Epoch: 4 [406720/620022]    Loss: 0.009804   Batch Acc: 79.69
[Train] Epoch: 4 [406784/620022]    Loss: 0.007958   Batch Acc: 79.69
[Train] Epoch: 4 [406848/620022]    Loss: 0.008225   Batch Acc: 73.44
[Train] Epoch: 4 [406912/620022]    Loss: 0.007085   Batch Acc: 87.50
[Train] Epoch: 4 [406976/620022]    Loss: 0.009324   Batch Acc: 79.69
[Train] Epoch: 4 [407040/620022]    Loss: 0.008083   Batch Acc: 78.12
[Train] Epoch: 4 [407104/620022]    Loss: 0.007643   Batch Acc: 81.25
[Train] Epoch: 4 [407168/620022]    Loss: 0.006180   Batch Acc: 85.94
[Train] Epoch: 4 [407232/620022]    Loss: 0.009651   Batch Acc: 78.12
[Train] Epoch: 4 [407296/620022]    Loss: 0.007463   Batch Acc: 81.25
[Train] Epoch: 4 [407360/620022]    Loss: 0.008850   Batch Acc: 73.44
[Train] Epoch: 4 [407424/620022]    Loss: 0.009243   Batch Acc: 73.44
[Train] Epoch: 4 [407488/620022]    Loss: 0.009725   Batch Acc: 71.88
[Train] Epoch: 4 [407552/620022]    Loss: 0.010087   Batch Acc: 70.31
[Train] Epoch: 4 [407616/620022]    Loss: 0.009653   Batch Acc: 79.69
[Train] Epoch: 4 [407680/620022]    Loss: 0.008809   Batch Acc: 78.12
[Train] Epoch: 4 [407744/620022]    Loss: 0.009098   Batch Acc: 73.44
[Train] Epoch: 4 [407808/620022]    Loss: 0.006765   Batch Acc: 82.81
[Train] Epoch: 4 [407872/620022]    Loss: 0.008814   Batch Acc: 76.56
[Train] Epoch: 4 [407936/620022]    Loss: 0.006517   Batch Acc: 87.50
[Train] Epoch: 4 [408000/620022]    Loss: 0.009261   Batch Acc: 78.12
[Train] Epoch: 4 [408064/620022]    Loss: 0.010185   Batch Acc: 76.56
[Train] Epoch: 4 [408128/620022]    Loss: 0.009562   Batch Acc: 76.56
[Train] Epoch: 4 [408192/620022]    Loss: 0.009327   Batch Acc: 76.56
[Train] Epoch: 4 [408256/620022]    Loss: 0.008775   Batch Acc: 78.12
[Train] Epoch: 4 [408320/620022]    Loss: 0.008245   Batch Acc: 75.00
[Train] Epoch: 4 [408384/620022]    Loss: 0.009262   Batch Acc: 75.00
[Train] Epoch: 4 [408448/620022]    Loss: 0.009377   Batch Acc: 76.56
[Train] Epoch: 4 [408512/620022]    Loss: 0.011233   Batch Acc: 75.00
[Train] Epoch: 4 [408576/620022]    Loss: 0.006890   Batch Acc: 84.38
[Train] Epoch: 4 [408640/620022]    Loss: 0.008584   Batch Acc: 81.25
[Train] Epoch: 4 [408704/620022]    Loss: 0.009576   Batch Acc: 76.56
[Train] Epoch: 4 [408768/620022]    Loss: 0.009881   Batch Acc: 73.44
[Train] Epoch: 4 [408832/620022]    Loss: 0.009779   Batch Acc: 70.31
[Train] Epoch: 4 [408896/620022]    Loss: 0.008777   Batch Acc: 79.69
[Train] Epoch: 4 [408960/620022]    Loss: 0.008308   Batch Acc: 78.12
[Train] Epoch: 4 [409024/620022]    Loss: 0.009107   Batch Acc: 79.69
[Train] Epoch: 4 [409088/620022]    Loss: 0.007812   Batch Acc: 79.69
[Train] Epoch: 4 [409152/620022]    Loss: 0.010110   Batch Acc: 78.12
[Train] Epoch: 4 [409216/620022]    Loss: 0.009472   Batch Acc: 73.44
[Train] Epoch: 4 [409280/620022]    Loss: 0.010195   Batch Acc: 76.56
[Train] Epoch: 4 [409344/620022]    Loss: 0.007766   Batch Acc: 81.25
[Train] Epoch: 4 [409408/620022]    Loss: 0.006704   Batch Acc: 84.38
[Train] Epoch: 4 [409472/620022]    Loss: 0.008875   Batch Acc: 79.69
[Train] Epoch: 4 [409536/620022]    Loss: 0.009008   Batch Acc: 76.56
[Train] Epoch: 4 [409600/620022]    Loss: 0.008401   Batch Acc: 79.69
[Train] Epoch: 4 [409664/620022]    Loss: 0.009183   Batch Acc: 76.56
[Train] Epoch: 4 [409728/620022]    Loss: 0.009924   Batch Acc: 79.69
[Train] Epoch: 4 [409792/620022]    Loss: 0.009368   Batch Acc: 76.56
[Train] Epoch: 4 [409856/620022]    Loss: 0.009729   Batch Acc: 75.00
[Train] Epoch: 4 [409920/620022]    Loss: 0.009143   Batch Acc: 75.00
[Train] Epoch: 4 [409984/620022]    Loss: 0.009758   Batch Acc: 76.56
[Train] Epoch: 4 [410048/620022]    Loss: 0.007459   Batch Acc: 79.69
[Train] Epoch: 4 [410112/620022]    Loss: 0.008824   Batch Acc: 76.56
[Train] Epoch: 4 [410176/620022]    Loss: 0.011103   Batch Acc: 70.31
[Train] Epoch: 4 [410240/620022]    Loss: 0.008590   Batch Acc: 81.25
[Train] Epoch: 4 [410304/620022]    Loss: 0.010004   Batch Acc: 79.69
[Train] Epoch: 4 [410368/620022]    Loss: 0.008262   Batch Acc: 82.81
[Train] Epoch: 4 [410432/620022]    Loss: 0.006714   Batch Acc: 82.81
[Train] Epoch: 4 [410496/620022]    Loss: 0.010516   Batch Acc: 73.44
[Train] Epoch: 4 [410560/620022]    Loss: 0.008983   Batch Acc: 78.12
[Train] Epoch: 4 [410624/620022]    Loss: 0.010452   Batch Acc: 64.06
[Train] Epoch: 4 [410688/620022]    Loss: 0.008720   Batch Acc: 75.00
[Train] Epoch: 4 [410752/620022]    Loss: 0.007069   Batch Acc: 82.81
[Train] Epoch: 4 [410816/620022]    Loss: 0.010617   Batch Acc: 68.75
[Train] Epoch: 4 [410880/620022]    Loss: 0.009330   Batch Acc: 76.56
[Train] Epoch: 4 [410944/620022]    Loss: 0.007041   Batch Acc: 82.81
[Train] Epoch: 4 [411008/620022]    Loss: 0.007932   Batch Acc: 73.44
[Train] Epoch: 4 [411072/620022]    Loss: 0.007777   Batch Acc: 81.25
[Train] Epoch: 4 [411136/620022]    Loss: 0.008617   Batch Acc: 73.44
[Train] Epoch: 4 [411200/620022]    Loss: 0.010596   Batch Acc: 71.88
[Train] Epoch: 4 [411264/620022]    Loss: 0.010519   Batch Acc: 71.88
[Train] Epoch: 4 [411328/620022]    Loss: 0.007668   Batch Acc: 79.69
[Train] Epoch: 4 [411392/620022]    Loss: 0.010553   Batch Acc: 76.56
[Train] Epoch: 4 [411456/620022]    Loss: 0.007116   Batch Acc: 81.25
[Train] Epoch: 4 [411520/620022]    Loss: 0.007390   Batch Acc: 84.38
[Train] Epoch: 4 [411584/620022]    Loss: 0.009784   Batch Acc: 75.00
[Train] Epoch: 4 [411648/620022]    Loss: 0.008166   Batch Acc: 81.25
[Train] Epoch: 4 [411712/620022]    Loss: 0.008413   Batch Acc: 85.94
[Train] Epoch: 4 [411776/620022]    Loss: 0.007809   Batch Acc: 79.69
[Train] Epoch: 4 [411840/620022]    Loss: 0.007630   Batch Acc: 81.25
[Train] Epoch: 4 [411904/620022]    Loss: 0.007655   Batch Acc: 84.38
[Train] Epoch: 4 [411968/620022]    Loss: 0.007687   Batch Acc: 81.25
[Train] Epoch: 4 [412032/620022]    Loss: 0.007597   Batch Acc: 82.81
[Train] Epoch: 4 [412096/620022]    Loss: 0.008125   Batch Acc: 82.81
[Train] Epoch: 4 [412160/620022]    Loss: 0.009720   Batch Acc: 70.31
[Train] Epoch: 4 [412224/620022]    Loss: 0.008284   Batch Acc: 76.56
[Train] Epoch: 4 [412288/620022]    Loss: 0.007409   Batch Acc: 81.25
[Train] Epoch: 4 [412352/620022]    Loss: 0.011059   Batch Acc: 71.88
[Train] Epoch: 4 [412416/620022]    Loss: 0.013311   Batch Acc: 71.88
[Train] Epoch: 4 [412480/620022]    Loss: 0.009899   Batch Acc: 70.31
[Train] Epoch: 4 [412544/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 4 [412608/620022]    Loss: 0.009287   Batch Acc: 79.69
[Train] Epoch: 4 [412672/620022]    Loss: 0.008166   Batch Acc: 82.81
[Train] Epoch: 4 [412736/620022]    Loss: 0.006917   Batch Acc: 87.50
[Train] Epoch: 4 [412800/620022]    Loss: 0.007935   Batch Acc: 76.56
[Train] Epoch: 4 [412864/620022]    Loss: 0.009508   Batch Acc: 70.31
[Train] Epoch: 4 [412928/620022]    Loss: 0.009957   Batch Acc: 76.56
[Train] Epoch: 4 [412992/620022]    Loss: 0.006586   Batch Acc: 82.81
[Train] Epoch: 4 [413056/620022]    Loss: 0.008785   Batch Acc: 78.12
[Train] Epoch: 4 [413120/620022]    Loss: 0.010336   Batch Acc: 73.44
[Train] Epoch: 4 [413184/620022]    Loss: 0.008034   Batch Acc: 84.38
[Train] Epoch: 4 [413248/620022]    Loss: 0.009388   Batch Acc: 71.88
[Train] Epoch: 4 [413312/620022]    Loss: 0.006902   Batch Acc: 84.38
[Train] Epoch: 4 [413376/620022]    Loss: 0.008471   Batch Acc: 76.56
[Train] Epoch: 4 [413440/620022]    Loss: 0.009724   Batch Acc: 64.06
[Train] Epoch: 4 [413504/620022]    Loss: 0.009066   Batch Acc: 79.69
[Train] Epoch: 4 [413568/620022]    Loss: 0.008299   Batch Acc: 85.94
[Train] Epoch: 4 [413632/620022]    Loss: 0.006445   Batch Acc: 90.62
[Train] Epoch: 4 [413696/620022]    Loss: 0.006919   Batch Acc: 82.81
[Train] Epoch: 4 [413760/620022]    Loss: 0.006135   Batch Acc: 82.81
[Train] Epoch: 4 [413824/620022]    Loss: 0.008693   Batch Acc: 82.81
[Train] Epoch: 4 [413888/620022]    Loss: 0.008118   Batch Acc: 81.25
[Train] Epoch: 4 [413952/620022]    Loss: 0.010816   Batch Acc: 70.31
[Train] Epoch: 4 [414016/620022]    Loss: 0.009331   Batch Acc: 70.31
[Train] Epoch: 4 [414080/620022]    Loss: 0.005994   Batch Acc: 90.62
[Train] Epoch: 4 [414144/620022]    Loss: 0.008873   Batch Acc: 81.25
[Train] Epoch: 4 [414208/620022]    Loss: 0.007810   Batch Acc: 81.25
[Train] Epoch: 4 [414272/620022]    Loss: 0.007000   Batch Acc: 85.94
[Train] Epoch: 4 [414336/620022]    Loss: 0.007780   Batch Acc: 81.25
[Train] Epoch: 4 [414400/620022]    Loss: 0.007008   Batch Acc: 82.81
[Train] Epoch: 4 [414464/620022]    Loss: 0.008189   Batch Acc: 78.12
[Train] Epoch: 4 [414528/620022]    Loss: 0.008201   Batch Acc: 79.69
[Train] Epoch: 4 [414592/620022]    Loss: 0.007827   Batch Acc: 82.81
[Train] Epoch: 4 [414656/620022]    Loss: 0.007410   Batch Acc: 81.25
[Train] Epoch: 4 [414720/620022]    Loss: 0.006993   Batch Acc: 82.81
[Train] Epoch: 4 [414784/620022]    Loss: 0.012993   Batch Acc: 70.31
[Train] Epoch: 4 [414848/620022]    Loss: 0.006616   Batch Acc: 85.94
[Train] Epoch: 4 [414912/620022]    Loss: 0.006878   Batch Acc: 85.94
[Train] Epoch: 4 [414976/620022]    Loss: 0.009260   Batch Acc: 81.25
[Train] Epoch: 4 [415040/620022]    Loss: 0.009579   Batch Acc: 73.44
[Train] Epoch: 4 [415104/620022]    Loss: 0.009706   Batch Acc: 73.44
[Train] Epoch: 4 [415168/620022]    Loss: 0.009789   Batch Acc: 73.44
[Train] Epoch: 4 [415232/620022]    Loss: 0.008515   Batch Acc: 81.25
[Train] Epoch: 4 [415296/620022]    Loss: 0.009100   Batch Acc: 84.38
[Train] Epoch: 4 [415360/620022]    Loss: 0.008596   Batch Acc: 73.44
[Train] Epoch: 4 [415424/620022]    Loss: 0.007125   Batch Acc: 87.50
[Train] Epoch: 4 [415488/620022]    Loss: 0.008934   Batch Acc: 82.81
[Train] Epoch: 4 [415552/620022]    Loss: 0.009254   Batch Acc: 67.19
[Train] Epoch: 4 [415616/620022]    Loss: 0.006966   Batch Acc: 84.38
[Train] Epoch: 4 [415680/620022]    Loss: 0.007767   Batch Acc: 79.69
[Train] Epoch: 4 [415744/620022]    Loss: 0.012213   Batch Acc: 64.06
[Train] Epoch: 4 [415808/620022]    Loss: 0.010106   Batch Acc: 75.00
[Train] Epoch: 4 [415872/620022]    Loss: 0.007276   Batch Acc: 78.12
[Train] Epoch: 4 [415936/620022]    Loss: 0.008202   Batch Acc: 79.69
[Train] Epoch: 4 [416000/620022]    Loss: 0.007765   Batch Acc: 85.94
[Train] Epoch: 4 [416064/620022]    Loss: 0.008354   Batch Acc: 73.44
[Train] Epoch: 4 [416128/620022]    Loss: 0.010346   Batch Acc: 79.69
[Train] Epoch: 4 [416192/620022]    Loss: 0.009325   Batch Acc: 76.56
[Train] Epoch: 4 [416256/620022]    Loss: 0.006498   Batch Acc: 81.25
[Train] Epoch: 4 [416320/620022]    Loss: 0.010541   Batch Acc: 73.44
[Train] Epoch: 4 [416384/620022]    Loss: 0.010163   Batch Acc: 75.00
[Train] Epoch: 4 [416448/620022]    Loss: 0.010133   Batch Acc: 75.00
[Train] Epoch: 4 [416512/620022]    Loss: 0.008048   Batch Acc: 78.12
[Train] Epoch: 4 [416576/620022]    Loss: 0.010075   Batch Acc: 71.88
[Train] Epoch: 4 [416640/620022]    Loss: 0.010926   Batch Acc: 75.00
[Train] Epoch: 4 [416704/620022]    Loss: 0.008852   Batch Acc: 84.38
[Train] Epoch: 4 [416768/620022]    Loss: 0.009172   Batch Acc: 81.25
[Train] Epoch: 4 [416832/620022]    Loss: 0.008709   Batch Acc: 75.00
[Train] Epoch: 4 [416896/620022]    Loss: 0.008080   Batch Acc: 81.25
[Train] Epoch: 4 [416960/620022]    Loss: 0.009684   Batch Acc: 78.12
[Train] Epoch: 4 [417024/620022]    Loss: 0.010227   Batch Acc: 71.88
[Train] Epoch: 4 [417088/620022]    Loss: 0.009453   Batch Acc: 71.88
[Train] Epoch: 4 [417152/620022]    Loss: 0.005493   Batch Acc: 84.38
[Train] Epoch: 4 [417216/620022]    Loss: 0.007719   Batch Acc: 79.69
[Train] Epoch: 4 [417280/620022]    Loss: 0.007060   Batch Acc: 81.25
[Train] Epoch: 4 [417344/620022]    Loss: 0.007535   Batch Acc: 78.12
[Train] Epoch: 4 [417408/620022]    Loss: 0.011529   Batch Acc: 73.44
[Train] Epoch: 4 [417472/620022]    Loss: 0.007672   Batch Acc: 81.25
[Train] Epoch: 4 [417536/620022]    Loss: 0.008253   Batch Acc: 79.69
[Train] Epoch: 4 [417600/620022]    Loss: 0.008448   Batch Acc: 81.25
[Train] Epoch: 4 [417664/620022]    Loss: 0.010670   Batch Acc: 76.56
[Train] Epoch: 4 [417728/620022]    Loss: 0.006200   Batch Acc: 84.38
[Train] Epoch: 4 [417792/620022]    Loss: 0.007765   Batch Acc: 79.69
[Train] Epoch: 4 [417856/620022]    Loss: 0.009373   Batch Acc: 75.00
[Train] Epoch: 4 [417920/620022]    Loss: 0.007275   Batch Acc: 79.69
[Train] Epoch: 4 [417984/620022]    Loss: 0.008677   Batch Acc: 78.12
[Train] Epoch: 4 [418048/620022]    Loss: 0.008584   Batch Acc: 81.25
[Train] Epoch: 4 [418112/620022]    Loss: 0.007206   Batch Acc: 81.25
[Train] Epoch: 4 [418176/620022]    Loss: 0.012044   Batch Acc: 68.75
[Train] Epoch: 4 [418240/620022]    Loss: 0.010089   Batch Acc: 71.88
[Train] Epoch: 4 [418304/620022]    Loss: 0.008127   Batch Acc: 78.12
[Train] Epoch: 4 [418368/620022]    Loss: 0.010559   Batch Acc: 73.44
[Train] Epoch: 4 [418432/620022]    Loss: 0.006388   Batch Acc: 87.50
[Train] Epoch: 4 [418496/620022]    Loss: 0.007879   Batch Acc: 82.81
[Train] Epoch: 4 [418560/620022]    Loss: 0.009480   Batch Acc: 71.88
[Train] Epoch: 4 [418624/620022]    Loss: 0.010382   Batch Acc: 71.88
[Train] Epoch: 4 [418688/620022]    Loss: 0.010125   Batch Acc: 71.88
[Train] Epoch: 4 [418752/620022]    Loss: 0.009523   Batch Acc: 71.88
[Train] Epoch: 4 [418816/620022]    Loss: 0.007471   Batch Acc: 78.12
[Train] Epoch: 4 [418880/620022]    Loss: 0.007360   Batch Acc: 82.81
[Train] Epoch: 4 [418944/620022]    Loss: 0.007657   Batch Acc: 79.69
[Train] Epoch: 4 [419008/620022]    Loss: 0.007870   Batch Acc: 78.12
[Train] Epoch: 4 [419072/620022]    Loss: 0.008066   Batch Acc: 78.12
[Train] Epoch: 4 [419136/620022]    Loss: 0.008956   Batch Acc: 71.88
[Train] Epoch: 4 [419200/620022]    Loss: 0.010307   Batch Acc: 67.19
[Train] Epoch: 4 [419264/620022]    Loss: 0.009499   Batch Acc: 71.88
[Train] Epoch: 4 [419328/620022]    Loss: 0.008185   Batch Acc: 84.38
[Train] Epoch: 4 [419392/620022]    Loss: 0.010783   Batch Acc: 71.88
[Train] Epoch: 4 [419456/620022]    Loss: 0.008523   Batch Acc: 76.56
[Train] Epoch: 4 [419520/620022]    Loss: 0.007862   Batch Acc: 71.88
[Train] Epoch: 4 [419584/620022]    Loss: 0.008448   Batch Acc: 73.44
[Train] Epoch: 4 [419648/620022]    Loss: 0.007267   Batch Acc: 84.38
[Train] Epoch: 4 [419712/620022]    Loss: 0.007107   Batch Acc: 84.38
[Train] Epoch: 4 [419776/620022]    Loss: 0.010237   Batch Acc: 73.44
[Train] Epoch: 4 [419840/620022]    Loss: 0.009938   Batch Acc: 75.00
[Train] Epoch: 4 [419904/620022]    Loss: 0.006852   Batch Acc: 84.38
[Train] Epoch: 4 [419968/620022]    Loss: 0.007319   Batch Acc: 81.25
[Train] Epoch: 4 [420032/620022]    Loss: 0.010907   Batch Acc: 71.88
[Train] Epoch: 4 [420096/620022]    Loss: 0.008993   Batch Acc: 73.44
[Train] Epoch: 4 [420160/620022]    Loss: 0.008752   Batch Acc: 67.19
[Train] Epoch: 4 [420224/620022]    Loss: 0.009108   Batch Acc: 78.12
[Train] Epoch: 4 [420288/620022]    Loss: 0.006051   Batch Acc: 84.38
[Train] Epoch: 4 [420352/620022]    Loss: 0.007813   Batch Acc: 78.12
[Train] Epoch: 4 [420416/620022]    Loss: 0.007406   Batch Acc: 81.25
[Train] Epoch: 4 [420480/620022]    Loss: 0.009466   Batch Acc: 78.12
[Train] Epoch: 4 [420544/620022]    Loss: 0.008353   Batch Acc: 76.56
[Train] Epoch: 4 [420608/620022]    Loss: 0.010344   Batch Acc: 71.88
[Train] Epoch: 4 [420672/620022]    Loss: 0.008115   Batch Acc: 79.69
[Train] Epoch: 4 [420736/620022]    Loss: 0.009323   Batch Acc: 68.75
[Train] Epoch: 4 [420800/620022]    Loss: 0.008566   Batch Acc: 71.88
[Train] Epoch: 4 [420864/620022]    Loss: 0.009765   Batch Acc: 73.44
[Train] Epoch: 4 [420928/620022]    Loss: 0.007988   Batch Acc: 79.69
[Train] Epoch: 4 [420992/620022]    Loss: 0.008988   Batch Acc: 76.56
[Train] Epoch: 4 [421056/620022]    Loss: 0.008396   Batch Acc: 75.00
[Train] Epoch: 4 [421120/620022]    Loss: 0.007882   Batch Acc: 82.81
[Train] Epoch: 4 [421184/620022]    Loss: 0.007362   Batch Acc: 79.69
[Train] Epoch: 4 [421248/620022]    Loss: 0.008917   Batch Acc: 76.56
[Train] Epoch: 4 [421312/620022]    Loss: 0.008325   Batch Acc: 81.25
[Train] Epoch: 4 [421376/620022]    Loss: 0.009085   Batch Acc: 79.69
[Train] Epoch: 4 [421440/620022]    Loss: 0.010770   Batch Acc: 68.75
[Train] Epoch: 4 [421504/620022]    Loss: 0.007029   Batch Acc: 79.69
[Train] Epoch: 4 [421568/620022]    Loss: 0.008545   Batch Acc: 79.69
[Train] Epoch: 4 [421632/620022]    Loss: 0.010779   Batch Acc: 70.31
[Train] Epoch: 4 [421696/620022]    Loss: 0.007767   Batch Acc: 82.81
[Train] Epoch: 4 [421760/620022]    Loss: 0.009814   Batch Acc: 75.00
[Train] Epoch: 4 [421824/620022]    Loss: 0.009694   Batch Acc: 78.12
[Train] Epoch: 4 [421888/620022]    Loss: 0.007039   Batch Acc: 81.25
[Train] Epoch: 4 [421952/620022]    Loss: 0.009338   Batch Acc: 79.69
[Train] Epoch: 4 [422016/620022]    Loss: 0.007557   Batch Acc: 79.69
[Train] Epoch: 4 [422080/620022]    Loss: 0.009503   Batch Acc: 75.00
[Train] Epoch: 4 [422144/620022]    Loss: 0.010994   Batch Acc: 75.00
[Train] Epoch: 4 [422208/620022]    Loss: 0.010550   Batch Acc: 67.19
[Train] Epoch: 4 [422272/620022]    Loss: 0.009334   Batch Acc: 75.00
[Train] Epoch: 4 [422336/620022]    Loss: 0.009929   Batch Acc: 76.56
[Train] Epoch: 4 [422400/620022]    Loss: 0.011398   Batch Acc: 65.62
[Train] Epoch: 4 [422464/620022]    Loss: 0.009638   Batch Acc: 82.81
[Train] Epoch: 4 [422528/620022]    Loss: 0.007894   Batch Acc: 82.81
[Train] Epoch: 4 [422592/620022]    Loss: 0.009697   Batch Acc: 78.12
[Train] Epoch: 4 [422656/620022]    Loss: 0.009667   Batch Acc: 71.88
[Train] Epoch: 4 [422720/620022]    Loss: 0.009672   Batch Acc: 65.62
[Train] Epoch: 4 [422784/620022]    Loss: 0.009403   Batch Acc: 75.00
[Train] Epoch: 4 [422848/620022]    Loss: 0.007789   Batch Acc: 81.25
[Train] Epoch: 4 [422912/620022]    Loss: 0.008153   Batch Acc: 79.69
[Train] Epoch: 4 [422976/620022]    Loss: 0.008338   Batch Acc: 81.25
[Train] Epoch: 4 [423040/620022]    Loss: 0.006259   Batch Acc: 85.94
[Train] Epoch: 4 [423104/620022]    Loss: 0.009198   Batch Acc: 70.31
[Train] Epoch: 4 [423168/620022]    Loss: 0.009082   Batch Acc: 73.44
[Train] Epoch: 4 [423232/620022]    Loss: 0.007261   Batch Acc: 84.38
[Train] Epoch: 4 [423296/620022]    Loss: 0.007176   Batch Acc: 82.81
[Train] Epoch: 4 [423360/620022]    Loss: 0.009367   Batch Acc: 71.88
[Train] Epoch: 4 [423424/620022]    Loss: 0.008646   Batch Acc: 73.44
[Train] Epoch: 4 [423488/620022]    Loss: 0.008230   Batch Acc: 81.25
[Train] Epoch: 4 [423552/620022]    Loss: 0.007701   Batch Acc: 82.81
[Train] Epoch: 4 [423616/620022]    Loss: 0.006314   Batch Acc: 87.50
[Train] Epoch: 4 [423680/620022]    Loss: 0.009773   Batch Acc: 71.88
[Train] Epoch: 4 [423744/620022]    Loss: 0.008815   Batch Acc: 75.00
[Train] Epoch: 4 [423808/620022]    Loss: 0.007872   Batch Acc: 82.81
[Train] Epoch: 4 [423872/620022]    Loss: 0.007754   Batch Acc: 79.69
[Train] Epoch: 4 [423936/620022]    Loss: 0.007791   Batch Acc: 78.12
[Train] Epoch: 4 [424000/620022]    Loss: 0.008087   Batch Acc: 76.56
[Train] Epoch: 4 [424064/620022]    Loss: 0.008328   Batch Acc: 81.25
[Train] Epoch: 4 [424128/620022]    Loss: 0.007787   Batch Acc: 84.38
[Train] Epoch: 4 [424192/620022]    Loss: 0.008672   Batch Acc: 75.00
[Train] Epoch: 4 [424256/620022]    Loss: 0.011227   Batch Acc: 70.31
[Train] Epoch: 4 [424320/620022]    Loss: 0.010676   Batch Acc: 73.44
[Train] Epoch: 4 [424384/620022]    Loss: 0.009155   Batch Acc: 73.44
[Train] Epoch: 4 [424448/620022]    Loss: 0.008608   Batch Acc: 79.69
[Train] Epoch: 4 [424512/620022]    Loss: 0.008502   Batch Acc: 78.12
[Train] Epoch: 4 [424576/620022]    Loss: 0.011309   Batch Acc: 65.62
[Train] Epoch: 4 [424640/620022]    Loss: 0.008990   Batch Acc: 81.25
[Train] Epoch: 4 [424704/620022]    Loss: 0.007650   Batch Acc: 82.81
[Train] Epoch: 4 [424768/620022]    Loss: 0.008646   Batch Acc: 75.00
[Train] Epoch: 4 [424832/620022]    Loss: 0.009117   Batch Acc: 78.12
[Train] Epoch: 4 [424896/620022]    Loss: 0.008537   Batch Acc: 75.00
[Train] Epoch: 4 [424960/620022]    Loss: 0.008946   Batch Acc: 78.12
[Train] Epoch: 4 [425024/620022]    Loss: 0.009835   Batch Acc: 78.12
[Train] Epoch: 4 [425088/620022]    Loss: 0.007058   Batch Acc: 82.81
[Train] Epoch: 4 [425152/620022]    Loss: 0.008612   Batch Acc: 81.25
[Train] Epoch: 4 [425216/620022]    Loss: 0.006468   Batch Acc: 85.94
[Train] Epoch: 4 [425280/620022]    Loss: 0.009269   Batch Acc: 75.00
[Train] Epoch: 4 [425344/620022]    Loss: 0.008940   Batch Acc: 76.56
[Train] Epoch: 4 [425408/620022]    Loss: 0.005731   Batch Acc: 90.62
[Train] Epoch: 4 [425472/620022]    Loss: 0.008051   Batch Acc: 75.00
[Train] Epoch: 4 [425536/620022]    Loss: 0.009280   Batch Acc: 76.56
[Train] Epoch: 4 [425600/620022]    Loss: 0.008397   Batch Acc: 76.56
[Train] Epoch: 4 [425664/620022]    Loss: 0.010359   Batch Acc: 68.75
[Train] Epoch: 4 [425728/620022]    Loss: 0.008593   Batch Acc: 76.56
[Train] Epoch: 4 [425792/620022]    Loss: 0.007765   Batch Acc: 81.25
[Train] Epoch: 4 [425856/620022]    Loss: 0.009903   Batch Acc: 71.88
[Train] Epoch: 4 [425920/620022]    Loss: 0.009893   Batch Acc: 75.00
[Train] Epoch: 4 [425984/620022]    Loss: 0.010546   Batch Acc: 71.88
[Train] Epoch: 4 [426048/620022]    Loss: 0.008696   Batch Acc: 79.69
[Train] Epoch: 4 [426112/620022]    Loss: 0.008729   Batch Acc: 78.12
[Train] Epoch: 4 [426176/620022]    Loss: 0.010505   Batch Acc: 73.44
[Train] Epoch: 4 [426240/620022]    Loss: 0.012578   Batch Acc: 65.62
[Train] Epoch: 4 [426304/620022]    Loss: 0.008800   Batch Acc: 82.81
[Train] Epoch: 4 [426368/620022]    Loss: 0.010235   Batch Acc: 75.00
[Train] Epoch: 4 [426432/620022]    Loss: 0.007960   Batch Acc: 79.69
[Train] Epoch: 4 [426496/620022]    Loss: 0.008562   Batch Acc: 82.81
[Train] Epoch: 4 [426560/620022]    Loss: 0.008302   Batch Acc: 78.12
[Train] Epoch: 4 [426624/620022]    Loss: 0.011033   Batch Acc: 71.88
[Train] Epoch: 4 [426688/620022]    Loss: 0.011443   Batch Acc: 71.88
[Train] Epoch: 4 [426752/620022]    Loss: 0.009274   Batch Acc: 75.00
[Train] Epoch: 4 [426816/620022]    Loss: 0.007611   Batch Acc: 82.81
[Train] Epoch: 4 [426880/620022]    Loss: 0.009354   Batch Acc: 81.25
[Train] Epoch: 4 [426944/620022]    Loss: 0.008236   Batch Acc: 78.12
[Train] Epoch: 4 [427008/620022]    Loss: 0.011045   Batch Acc: 73.44
[Train] Epoch: 4 [427072/620022]    Loss: 0.010379   Batch Acc: 68.75
[Train] Epoch: 4 [427136/620022]    Loss: 0.008333   Batch Acc: 79.69
[Train] Epoch: 4 [427200/620022]    Loss: 0.009459   Batch Acc: 75.00
[Train] Epoch: 4 [427264/620022]    Loss: 0.008144   Batch Acc: 79.69
[Train] Epoch: 4 [427328/620022]    Loss: 0.008491   Batch Acc: 78.12
[Train] Epoch: 4 [427392/620022]    Loss: 0.008297   Batch Acc: 82.81
[Train] Epoch: 4 [427456/620022]    Loss: 0.007952   Batch Acc: 81.25
[Train] Epoch: 4 [427520/620022]    Loss: 0.010182   Batch Acc: 73.44
[Train] Epoch: 4 [427584/620022]    Loss: 0.012639   Batch Acc: 71.88
[Train] Epoch: 4 [427648/620022]    Loss: 0.008001   Batch Acc: 84.38
[Train] Epoch: 4 [427712/620022]    Loss: 0.007627   Batch Acc: 85.94
[Train] Epoch: 4 [427776/620022]    Loss: 0.009862   Batch Acc: 79.69
[Train] Epoch: 4 [427840/620022]    Loss: 0.009736   Batch Acc: 76.56
[Train] Epoch: 4 [427904/620022]    Loss: 0.009216   Batch Acc: 81.25
[Train] Epoch: 4 [427968/620022]    Loss: 0.008642   Batch Acc: 79.69
[Train] Epoch: 4 [428032/620022]    Loss: 0.008182   Batch Acc: 78.12
[Train] Epoch: 4 [428096/620022]    Loss: 0.008834   Batch Acc: 78.12
[Train] Epoch: 4 [428160/620022]    Loss: 0.008687   Batch Acc: 75.00
[Train] Epoch: 4 [428224/620022]    Loss: 0.008127   Batch Acc: 79.69
[Train] Epoch: 4 [428288/620022]    Loss: 0.007371   Batch Acc: 79.69
[Train] Epoch: 4 [428352/620022]    Loss: 0.009509   Batch Acc: 71.88
[Train] Epoch: 4 [428416/620022]    Loss: 0.008833   Batch Acc: 79.69
[Train] Epoch: 4 [428480/620022]    Loss: 0.006411   Batch Acc: 85.94
[Train] Epoch: 4 [428544/620022]    Loss: 0.007991   Batch Acc: 82.81
[Train] Epoch: 4 [428608/620022]    Loss: 0.008174   Batch Acc: 84.38
[Train] Epoch: 4 [428672/620022]    Loss: 0.009664   Batch Acc: 73.44
[Train] Epoch: 4 [428736/620022]    Loss: 0.009449   Batch Acc: 71.88
[Train] Epoch: 4 [428800/620022]    Loss: 0.007388   Batch Acc: 82.81
[Train] Epoch: 4 [428864/620022]    Loss: 0.007564   Batch Acc: 81.25
[Train] Epoch: 4 [428928/620022]    Loss: 0.009932   Batch Acc: 75.00
[Train] Epoch: 4 [428992/620022]    Loss: 0.008164   Batch Acc: 85.94
[Train] Epoch: 4 [429056/620022]    Loss: 0.008376   Batch Acc: 75.00
[Train] Epoch: 4 [429120/620022]    Loss: 0.010837   Batch Acc: 70.31
[Train] Epoch: 4 [429184/620022]    Loss: 0.008404   Batch Acc: 70.31
[Train] Epoch: 4 [429248/620022]    Loss: 0.009594   Batch Acc: 73.44
[Train] Epoch: 4 [429312/620022]    Loss: 0.006569   Batch Acc: 85.94
[Train] Epoch: 4 [429376/620022]    Loss: 0.007654   Batch Acc: 89.06
[Train] Epoch: 4 [429440/620022]    Loss: 0.010271   Batch Acc: 76.56
[Train] Epoch: 4 [429504/620022]    Loss: 0.007539   Batch Acc: 81.25
[Train] Epoch: 4 [429568/620022]    Loss: 0.007747   Batch Acc: 79.69
[Train] Epoch: 4 [429632/620022]    Loss: 0.007201   Batch Acc: 84.38
[Train] Epoch: 4 [429696/620022]    Loss: 0.007428   Batch Acc: 78.12
[Train] Epoch: 4 [429760/620022]    Loss: 0.007958   Batch Acc: 87.50
[Train] Epoch: 4 [429824/620022]    Loss: 0.007422   Batch Acc: 78.12
[Train] Epoch: 4 [429888/620022]    Loss: 0.009749   Batch Acc: 70.31
[Train] Epoch: 4 [429952/620022]    Loss: 0.008359   Batch Acc: 73.44
[Train] Epoch: 4 [430016/620022]    Loss: 0.008387   Batch Acc: 75.00
[Train] Epoch: 4 [430080/620022]    Loss: 0.007835   Batch Acc: 82.81
[Train] Epoch: 4 [430144/620022]    Loss: 0.008234   Batch Acc: 75.00
[Train] Epoch: 4 [430208/620022]    Loss: 0.009369   Batch Acc: 73.44
[Train] Epoch: 4 [430272/620022]    Loss: 0.006585   Batch Acc: 89.06
[Train] Epoch: 4 [430336/620022]    Loss: 0.009021   Batch Acc: 78.12
[Train] Epoch: 4 [430400/620022]    Loss: 0.010041   Batch Acc: 73.44
[Train] Epoch: 4 [430464/620022]    Loss: 0.008361   Batch Acc: 78.12
[Train] Epoch: 4 [430528/620022]    Loss: 0.006363   Batch Acc: 85.94
[Train] Epoch: 4 [430592/620022]    Loss: 0.009860   Batch Acc: 73.44
[Train] Epoch: 4 [430656/620022]    Loss: 0.009914   Batch Acc: 78.12
[Train] Epoch: 4 [430720/620022]    Loss: 0.008292   Batch Acc: 76.56
[Train] Epoch: 4 [430784/620022]    Loss: 0.010697   Batch Acc: 70.31
[Train] Epoch: 4 [430848/620022]    Loss: 0.007763   Batch Acc: 79.69
[Train] Epoch: 4 [430912/620022]    Loss: 0.010489   Batch Acc: 67.19
[Train] Epoch: 4 [430976/620022]    Loss: 0.009494   Batch Acc: 71.88
[Train] Epoch: 4 [431040/620022]    Loss: 0.006329   Batch Acc: 84.38
[Train] Epoch: 4 [431104/620022]    Loss: 0.008820   Batch Acc: 79.69
[Train] Epoch: 4 [431168/620022]    Loss: 0.008599   Batch Acc: 75.00
[Train] Epoch: 4 [431232/620022]    Loss: 0.008577   Batch Acc: 79.69
[Train] Epoch: 4 [431296/620022]    Loss: 0.008000   Batch Acc: 81.25
[Train] Epoch: 4 [431360/620022]    Loss: 0.009867   Batch Acc: 73.44
[Train] Epoch: 4 [431424/620022]    Loss: 0.007721   Batch Acc: 79.69
[Train] Epoch: 4 [431488/620022]    Loss: 0.008037   Batch Acc: 84.38
[Train] Epoch: 4 [431552/620022]    Loss: 0.007697   Batch Acc: 81.25
[Train] Epoch: 4 [431616/620022]    Loss: 0.007680   Batch Acc: 76.56
[Train] Epoch: 4 [431680/620022]    Loss: 0.011099   Batch Acc: 64.06
[Train] Epoch: 4 [431744/620022]    Loss: 0.007366   Batch Acc: 81.25
[Train] Epoch: 4 [431808/620022]    Loss: 0.008728   Batch Acc: 78.12
[Train] Epoch: 4 [431872/620022]    Loss: 0.008313   Batch Acc: 79.69
[Train] Epoch: 4 [431936/620022]    Loss: 0.007831   Batch Acc: 79.69
[Train] Epoch: 4 [432000/620022]    Loss: 0.007174   Batch Acc: 81.25
[Train] Epoch: 4 [432064/620022]    Loss: 0.007847   Batch Acc: 79.69
[Train] Epoch: 4 [432128/620022]    Loss: 0.007472   Batch Acc: 82.81
[Train] Epoch: 4 [432192/620022]    Loss: 0.007964   Batch Acc: 81.25
[Train] Epoch: 4 [432256/620022]    Loss: 0.007002   Batch Acc: 81.25
[Train] Epoch: 4 [432320/620022]    Loss: 0.007928   Batch Acc: 82.81
[Train] Epoch: 4 [432384/620022]    Loss: 0.006085   Batch Acc: 85.94
[Train] Epoch: 4 [432448/620022]    Loss: 0.008345   Batch Acc: 76.56
[Train] Epoch: 4 [432512/620022]    Loss: 0.009189   Batch Acc: 81.25
[Train] Epoch: 4 [432576/620022]    Loss: 0.008628   Batch Acc: 78.12
[Train] Epoch: 4 [432640/620022]    Loss: 0.006065   Batch Acc: 89.06
[Train] Epoch: 4 [432704/620022]    Loss: 0.007170   Batch Acc: 84.38
[Train] Epoch: 4 [432768/620022]    Loss: 0.009946   Batch Acc: 75.00
[Train] Epoch: 4 [432832/620022]    Loss: 0.010504   Batch Acc: 75.00
[Train] Epoch: 4 [432896/620022]    Loss: 0.008443   Batch Acc: 82.81
[Train] Epoch: 4 [432960/620022]    Loss: 0.010273   Batch Acc: 71.88
[Train] Epoch: 4 [433024/620022]    Loss: 0.009367   Batch Acc: 79.69
[Train] Epoch: 4 [433088/620022]    Loss: 0.010099   Batch Acc: 73.44
[Train] Epoch: 4 [433152/620022]    Loss: 0.007509   Batch Acc: 81.25
[Train] Epoch: 4 [433216/620022]    Loss: 0.007159   Batch Acc: 82.81
[Train] Epoch: 4 [433280/620022]    Loss: 0.008571   Batch Acc: 75.00
[Train] Epoch: 4 [433344/620022]    Loss: 0.007856   Batch Acc: 71.88
[Train] Epoch: 4 [433408/620022]    Loss: 0.010858   Batch Acc: 75.00
[Train] Epoch: 4 [433472/620022]    Loss: 0.007217   Batch Acc: 81.25
[Train] Epoch: 4 [433536/620022]    Loss: 0.005814   Batch Acc: 85.94
[Train] Epoch: 4 [433600/620022]    Loss: 0.008953   Batch Acc: 79.69
[Train] Epoch: 4 [433664/620022]    Loss: 0.010636   Batch Acc: 70.31
[Train] Epoch: 4 [433728/620022]    Loss: 0.008435   Batch Acc: 76.56
[Train] Epoch: 4 [433792/620022]    Loss: 0.006835   Batch Acc: 82.81
[Train] Epoch: 4 [433856/620022]    Loss: 0.009627   Batch Acc: 73.44
[Train] Epoch: 4 [433920/620022]    Loss: 0.006838   Batch Acc: 85.94
[Train] Epoch: 4 [433984/620022]    Loss: 0.008321   Batch Acc: 79.69
[Train] Epoch: 4 [434048/620022]    Loss: 0.009004   Batch Acc: 75.00
[Train] Epoch: 4 [434112/620022]    Loss: 0.007858   Batch Acc: 79.69
[Train] Epoch: 4 [434176/620022]    Loss: 0.008581   Batch Acc: 76.56
[Train] Epoch: 4 [434240/620022]    Loss: 0.008752   Batch Acc: 76.56
[Train] Epoch: 4 [434304/620022]    Loss: 0.009388   Batch Acc: 70.31
[Train] Epoch: 4 [434368/620022]    Loss: 0.007562   Batch Acc: 85.94
[Train] Epoch: 4 [434432/620022]    Loss: 0.007013   Batch Acc: 84.38
[Train] Epoch: 4 [434496/620022]    Loss: 0.007496   Batch Acc: 81.25
[Train] Epoch: 4 [434560/620022]    Loss: 0.006936   Batch Acc: 85.94
[Train] Epoch: 4 [434624/620022]    Loss: 0.009988   Batch Acc: 73.44
[Train] Epoch: 4 [434688/620022]    Loss: 0.009811   Batch Acc: 75.00
[Train] Epoch: 4 [434752/620022]    Loss: 0.009527   Batch Acc: 75.00
[Train] Epoch: 4 [434816/620022]    Loss: 0.006659   Batch Acc: 78.12
[Train] Epoch: 4 [434880/620022]    Loss: 0.010625   Batch Acc: 73.44
[Train] Epoch: 4 [434944/620022]    Loss: 0.009045   Batch Acc: 73.44
[Train] Epoch: 4 [435008/620022]    Loss: 0.008230   Batch Acc: 82.81
[Train] Epoch: 4 [435072/620022]    Loss: 0.005571   Batch Acc: 89.06
[Train] Epoch: 4 [435136/620022]    Loss: 0.007035   Batch Acc: 87.50
[Train] Epoch: 4 [435200/620022]    Loss: 0.008858   Batch Acc: 81.25
[Train] Epoch: 4 [435264/620022]    Loss: 0.006508   Batch Acc: 84.38
[Train] Epoch: 4 [435328/620022]    Loss: 0.010150   Batch Acc: 75.00
[Train] Epoch: 4 [435392/620022]    Loss: 0.008785   Batch Acc: 81.25
[Train] Epoch: 4 [435456/620022]    Loss: 0.008533   Batch Acc: 76.56
[Train] Epoch: 4 [435520/620022]    Loss: 0.009345   Batch Acc: 79.69
[Train] Epoch: 4 [435584/620022]    Loss: 0.008544   Batch Acc: 75.00
[Train] Epoch: 4 [435648/620022]    Loss: 0.009785   Batch Acc: 82.81
[Train] Epoch: 4 [435712/620022]    Loss: 0.005389   Batch Acc: 85.94
[Train] Epoch: 4 [435776/620022]    Loss: 0.008513   Batch Acc: 81.25
[Train] Epoch: 4 [435840/620022]    Loss: 0.008703   Batch Acc: 68.75
[Train] Epoch: 4 [435904/620022]    Loss: 0.009581   Batch Acc: 76.56
[Train] Epoch: 4 [435968/620022]    Loss: 0.007439   Batch Acc: 71.88
[Train] Epoch: 4 [436032/620022]    Loss: 0.007847   Batch Acc: 82.81
[Train] Epoch: 4 [436096/620022]    Loss: 0.009819   Batch Acc: 75.00
[Train] Epoch: 4 [436160/620022]    Loss: 0.008335   Batch Acc: 76.56
[Train] Epoch: 4 [436224/620022]    Loss: 0.006594   Batch Acc: 82.81
[Train] Epoch: 4 [436288/620022]    Loss: 0.009350   Batch Acc: 76.56
[Train] Epoch: 4 [436352/620022]    Loss: 0.010248   Batch Acc: 75.00
[Train] Epoch: 4 [436416/620022]    Loss: 0.006827   Batch Acc: 87.50
[Train] Epoch: 4 [436480/620022]    Loss: 0.007283   Batch Acc: 79.69
[Train] Epoch: 4 [436544/620022]    Loss: 0.009576   Batch Acc: 76.56
[Train] Epoch: 4 [436608/620022]    Loss: 0.007489   Batch Acc: 84.38
[Train] Epoch: 4 [436672/620022]    Loss: 0.007120   Batch Acc: 85.94
[Train] Epoch: 4 [436736/620022]    Loss: 0.008564   Batch Acc: 75.00
[Train] Epoch: 4 [436800/620022]    Loss: 0.009052   Batch Acc: 81.25
[Train] Epoch: 4 [436864/620022]    Loss: 0.009671   Batch Acc: 71.88
[Train] Epoch: 4 [436928/620022]    Loss: 0.008160   Batch Acc: 78.12
[Train] Epoch: 4 [436992/620022]    Loss: 0.006442   Batch Acc: 87.50
[Train] Epoch: 4 [437056/620022]    Loss: 0.009809   Batch Acc: 70.31
[Train] Epoch: 4 [437120/620022]    Loss: 0.006907   Batch Acc: 85.94
[Train] Epoch: 4 [437184/620022]    Loss: 0.008909   Batch Acc: 79.69
[Train] Epoch: 4 [437248/620022]    Loss: 0.007639   Batch Acc: 81.25
[Train] Epoch: 4 [437312/620022]    Loss: 0.007886   Batch Acc: 81.25
[Train] Epoch: 4 [437376/620022]    Loss: 0.008955   Batch Acc: 71.88
[Train] Epoch: 4 [437440/620022]    Loss: 0.006806   Batch Acc: 85.94
[Train] Epoch: 4 [437504/620022]    Loss: 0.006842   Batch Acc: 84.38
[Train] Epoch: 4 [437568/620022]    Loss: 0.008728   Batch Acc: 76.56
[Train] Epoch: 4 [437632/620022]    Loss: 0.008160   Batch Acc: 78.12
[Train] Epoch: 4 [437696/620022]    Loss: 0.010134   Batch Acc: 73.44
[Train] Epoch: 4 [437760/620022]    Loss: 0.008949   Batch Acc: 76.56
[Train] Epoch: 4 [437824/620022]    Loss: 0.008763   Batch Acc: 84.38
[Train] Epoch: 4 [437888/620022]    Loss: 0.008156   Batch Acc: 79.69
[Train] Epoch: 4 [437952/620022]    Loss: 0.009175   Batch Acc: 73.44
[Train] Epoch: 4 [438016/620022]    Loss: 0.008300   Batch Acc: 82.81
[Train] Epoch: 4 [438080/620022]    Loss: 0.008898   Batch Acc: 75.00
[Train] Epoch: 4 [438144/620022]    Loss: 0.007083   Batch Acc: 76.56
[Train] Epoch: 4 [438208/620022]    Loss: 0.008371   Batch Acc: 76.56
[Train] Epoch: 4 [438272/620022]    Loss: 0.008679   Batch Acc: 71.88
[Train] Epoch: 4 [438336/620022]    Loss: 0.008107   Batch Acc: 75.00
[Train] Epoch: 4 [438400/620022]    Loss: 0.008432   Batch Acc: 82.81
[Train] Epoch: 4 [438464/620022]    Loss: 0.009059   Batch Acc: 79.69
[Train] Epoch: 4 [438528/620022]    Loss: 0.008597   Batch Acc: 79.69
[Train] Epoch: 4 [438592/620022]    Loss: 0.008342   Batch Acc: 79.69
[Train] Epoch: 4 [438656/620022]    Loss: 0.007510   Batch Acc: 82.81
[Train] Epoch: 4 [438720/620022]    Loss: 0.008385   Batch Acc: 79.69
[Train] Epoch: 4 [438784/620022]    Loss: 0.007499   Batch Acc: 81.25
[Train] Epoch: 4 [438848/620022]    Loss: 0.009835   Batch Acc: 75.00
[Train] Epoch: 4 [438912/620022]    Loss: 0.007370   Batch Acc: 82.81
[Train] Epoch: 4 [438976/620022]    Loss: 0.010378   Batch Acc: 70.31
[Train] Epoch: 4 [439040/620022]    Loss: 0.008505   Batch Acc: 71.88
[Train] Epoch: 4 [439104/620022]    Loss: 0.009091   Batch Acc: 81.25
[Train] Epoch: 4 [439168/620022]    Loss: 0.007317   Batch Acc: 82.81
[Train] Epoch: 4 [439232/620022]    Loss: 0.005549   Batch Acc: 87.50
[Train] Epoch: 4 [439296/620022]    Loss: 0.008933   Batch Acc: 78.12
[Train] Epoch: 4 [439360/620022]    Loss: 0.009195   Batch Acc: 78.12
[Train] Epoch: 4 [439424/620022]    Loss: 0.007102   Batch Acc: 82.81
[Train] Epoch: 4 [439488/620022]    Loss: 0.009744   Batch Acc: 75.00
[Train] Epoch: 4 [439552/620022]    Loss: 0.007940   Batch Acc: 81.25
[Train] Epoch: 4 [439616/620022]    Loss: 0.007619   Batch Acc: 76.56
[Train] Epoch: 4 [439680/620022]    Loss: 0.008629   Batch Acc: 78.12
[Train] Epoch: 4 [439744/620022]    Loss: 0.009532   Batch Acc: 75.00
[Train] Epoch: 4 [439808/620022]    Loss: 0.010355   Batch Acc: 70.31
[Train] Epoch: 4 [439872/620022]    Loss: 0.010804   Batch Acc: 60.94
[Train] Epoch: 4 [439936/620022]    Loss: 0.006804   Batch Acc: 81.25
[Train] Epoch: 4 [440000/620022]    Loss: 0.008592   Batch Acc: 78.12
[Train] Epoch: 4 [440064/620022]    Loss: 0.006887   Batch Acc: 78.12
[Train] Epoch: 4 [440128/620022]    Loss: 0.007773   Batch Acc: 79.69
[Train] Epoch: 4 [440192/620022]    Loss: 0.007120   Batch Acc: 82.81
[Train] Epoch: 4 [440256/620022]    Loss: 0.008158   Batch Acc: 76.56
[Train] Epoch: 4 [440320/620022]    Loss: 0.008635   Batch Acc: 76.56
[Train] Epoch: 4 [440384/620022]    Loss: 0.006874   Batch Acc: 85.94
[Train] Epoch: 4 [440448/620022]    Loss: 0.009894   Batch Acc: 76.56
[Train] Epoch: 4 [440512/620022]    Loss: 0.008220   Batch Acc: 71.88
[Train] Epoch: 4 [440576/620022]    Loss: 0.012516   Batch Acc: 62.50
[Train] Epoch: 4 [440640/620022]    Loss: 0.010430   Batch Acc: 75.00
[Train] Epoch: 4 [440704/620022]    Loss: 0.010646   Batch Acc: 70.31
[Train] Epoch: 4 [440768/620022]    Loss: 0.008747   Batch Acc: 81.25
[Train] Epoch: 4 [440832/620022]    Loss: 0.008411   Batch Acc: 75.00
[Train] Epoch: 4 [440896/620022]    Loss: 0.006085   Batch Acc: 85.94
[Train] Epoch: 4 [440960/620022]    Loss: 0.009550   Batch Acc: 78.12
[Train] Epoch: 4 [441024/620022]    Loss: 0.010207   Batch Acc: 71.88
[Train] Epoch: 4 [441088/620022]    Loss: 0.011722   Batch Acc: 73.44
[Train] Epoch: 4 [441152/620022]    Loss: 0.010773   Batch Acc: 67.19
[Train] Epoch: 4 [441216/620022]    Loss: 0.009371   Batch Acc: 76.56
[Train] Epoch: 4 [441280/620022]    Loss: 0.007552   Batch Acc: 84.38
[Train] Epoch: 4 [441344/620022]    Loss: 0.007335   Batch Acc: 84.38
[Train] Epoch: 4 [441408/620022]    Loss: 0.009942   Batch Acc: 71.88
[Train] Epoch: 4 [441472/620022]    Loss: 0.007193   Batch Acc: 78.12
[Train] Epoch: 4 [441536/620022]    Loss: 0.010410   Batch Acc: 71.88
[Train] Epoch: 4 [441600/620022]    Loss: 0.007496   Batch Acc: 84.38
[Train] Epoch: 4 [441664/620022]    Loss: 0.006972   Batch Acc: 85.94
[Train] Epoch: 4 [441728/620022]    Loss: 0.009096   Batch Acc: 76.56
[Train] Epoch: 4 [441792/620022]    Loss: 0.007525   Batch Acc: 84.38
[Train] Epoch: 4 [441856/620022]    Loss: 0.008665   Batch Acc: 79.69
[Train] Epoch: 4 [441920/620022]    Loss: 0.009892   Batch Acc: 75.00
[Train] Epoch: 4 [441984/620022]    Loss: 0.009313   Batch Acc: 75.00
[Train] Epoch: 4 [442048/620022]    Loss: 0.009679   Batch Acc: 73.44
[Train] Epoch: 4 [442112/620022]    Loss: 0.009382   Batch Acc: 79.69
[Train] Epoch: 4 [442176/620022]    Loss: 0.008420   Batch Acc: 81.25
[Train] Epoch: 4 [442240/620022]    Loss: 0.008689   Batch Acc: 79.69
[Train] Epoch: 4 [442304/620022]    Loss: 0.007695   Batch Acc: 78.12
[Train] Epoch: 4 [442368/620022]    Loss: 0.007972   Batch Acc: 81.25
[Train] Epoch: 4 [442432/620022]    Loss: 0.008132   Batch Acc: 79.69
[Train] Epoch: 4 [442496/620022]    Loss: 0.006369   Batch Acc: 89.06
[Train] Epoch: 4 [442560/620022]    Loss: 0.008920   Batch Acc: 78.12
[Train] Epoch: 4 [442624/620022]    Loss: 0.009510   Batch Acc: 76.56
[Train] Epoch: 4 [442688/620022]    Loss: 0.008511   Batch Acc: 82.81
[Train] Epoch: 4 [442752/620022]    Loss: 0.008320   Batch Acc: 76.56
[Train] Epoch: 4 [442816/620022]    Loss: 0.007966   Batch Acc: 78.12
[Train] Epoch: 4 [442880/620022]    Loss: 0.007684   Batch Acc: 85.94
[Train] Epoch: 4 [442944/620022]    Loss: 0.007764   Batch Acc: 81.25
[Train] Epoch: 4 [443008/620022]    Loss: 0.009012   Batch Acc: 79.69
[Train] Epoch: 4 [443072/620022]    Loss: 0.008894   Batch Acc: 75.00
[Train] Epoch: 4 [443136/620022]    Loss: 0.009051   Batch Acc: 79.69
[Train] Epoch: 4 [443200/620022]    Loss: 0.009845   Batch Acc: 73.44
[Train] Epoch: 4 [443264/620022]    Loss: 0.007077   Batch Acc: 82.81
[Train] Epoch: 4 [443328/620022]    Loss: 0.009216   Batch Acc: 76.56
[Train] Epoch: 4 [443392/620022]    Loss: 0.007964   Batch Acc: 79.69
[Train] Epoch: 4 [443456/620022]    Loss: 0.010507   Batch Acc: 73.44
[Train] Epoch: 4 [443520/620022]    Loss: 0.006881   Batch Acc: 82.81
[Train] Epoch: 4 [443584/620022]    Loss: 0.008468   Batch Acc: 71.88
[Train] Epoch: 4 [443648/620022]    Loss: 0.008581   Batch Acc: 81.25
[Train] Epoch: 4 [443712/620022]    Loss: 0.009470   Batch Acc: 76.56
[Train] Epoch: 4 [443776/620022]    Loss: 0.010564   Batch Acc: 71.88
[Train] Epoch: 4 [443840/620022]    Loss: 0.009611   Batch Acc: 79.69
[Train] Epoch: 4 [443904/620022]    Loss: 0.009240   Batch Acc: 73.44
[Train] Epoch: 4 [443968/620022]    Loss: 0.006644   Batch Acc: 85.94
[Train] Epoch: 4 [444032/620022]    Loss: 0.007127   Batch Acc: 84.38
[Train] Epoch: 4 [444096/620022]    Loss: 0.006916   Batch Acc: 84.38
[Train] Epoch: 4 [444160/620022]    Loss: 0.010588   Batch Acc: 73.44
[Train] Epoch: 4 [444224/620022]    Loss: 0.006942   Batch Acc: 85.94
[Train] Epoch: 4 [444288/620022]    Loss: 0.008054   Batch Acc: 79.69
[Train] Epoch: 4 [444352/620022]    Loss: 0.008891   Batch Acc: 75.00
[Train] Epoch: 4 [444416/620022]    Loss: 0.004460   Batch Acc: 93.75
[Train] Epoch: 4 [444480/620022]    Loss: 0.008394   Batch Acc: 75.00
[Train] Epoch: 4 [444544/620022]    Loss: 0.008860   Batch Acc: 81.25
[Train] Epoch: 4 [444608/620022]    Loss: 0.008797   Batch Acc: 73.44
[Train] Epoch: 4 [444672/620022]    Loss: 0.009345   Batch Acc: 76.56
[Train] Epoch: 4 [444736/620022]    Loss: 0.009750   Batch Acc: 71.88
[Train] Epoch: 4 [444800/620022]    Loss: 0.011459   Batch Acc: 70.31
[Train] Epoch: 4 [444864/620022]    Loss: 0.008223   Batch Acc: 79.69
[Train] Epoch: 4 [444928/620022]    Loss: 0.009581   Batch Acc: 73.44
[Train] Epoch: 4 [444992/620022]    Loss: 0.008339   Batch Acc: 79.69
[Train] Epoch: 4 [445056/620022]    Loss: 0.008109   Batch Acc: 78.12
[Train] Epoch: 4 [445120/620022]    Loss: 0.007534   Batch Acc: 78.12
[Train] Epoch: 4 [445184/620022]    Loss: 0.009575   Batch Acc: 75.00
[Train] Epoch: 4 [445248/620022]    Loss: 0.009189   Batch Acc: 76.56
[Train] Epoch: 4 [445312/620022]    Loss: 0.010015   Batch Acc: 73.44
[Train] Epoch: 4 [445376/620022]    Loss: 0.009437   Batch Acc: 76.56
[Train] Epoch: 4 [445440/620022]    Loss: 0.007797   Batch Acc: 79.69
[Train] Epoch: 4 [445504/620022]    Loss: 0.009336   Batch Acc: 73.44
[Train] Epoch: 4 [445568/620022]    Loss: 0.007218   Batch Acc: 76.56
[Train] Epoch: 4 [445632/620022]    Loss: 0.010461   Batch Acc: 71.88
[Train] Epoch: 4 [445696/620022]    Loss: 0.010184   Batch Acc: 75.00
[Train] Epoch: 4 [445760/620022]    Loss: 0.009490   Batch Acc: 76.56
[Train] Epoch: 4 [445824/620022]    Loss: 0.009228   Batch Acc: 73.44
[Train] Epoch: 4 [445888/620022]    Loss: 0.008393   Batch Acc: 75.00
[Train] Epoch: 4 [445952/620022]    Loss: 0.007617   Batch Acc: 78.12
[Train] Epoch: 4 [446016/620022]    Loss: 0.009357   Batch Acc: 73.44
[Train] Epoch: 4 [446080/620022]    Loss: 0.007038   Batch Acc: 82.81
[Train] Epoch: 4 [446144/620022]    Loss: 0.006537   Batch Acc: 87.50
[Train] Epoch: 4 [446208/620022]    Loss: 0.008711   Batch Acc: 78.12
[Train] Epoch: 4 [446272/620022]    Loss: 0.007894   Batch Acc: 79.69
[Train] Epoch: 4 [446336/620022]    Loss: 0.010067   Batch Acc: 76.56
[Train] Epoch: 4 [446400/620022]    Loss: 0.009697   Batch Acc: 75.00
[Train] Epoch: 4 [446464/620022]    Loss: 0.009491   Batch Acc: 76.56
[Train] Epoch: 4 [446528/620022]    Loss: 0.008853   Batch Acc: 68.75
[Train] Epoch: 4 [446592/620022]    Loss: 0.006939   Batch Acc: 84.38
[Train] Epoch: 4 [446656/620022]    Loss: 0.008764   Batch Acc: 76.56
[Train] Epoch: 4 [446720/620022]    Loss: 0.011254   Batch Acc: 71.88
[Train] Epoch: 4 [446784/620022]    Loss: 0.008692   Batch Acc: 79.69
[Train] Epoch: 4 [446848/620022]    Loss: 0.009279   Batch Acc: 73.44
[Train] Epoch: 4 [446912/620022]    Loss: 0.009297   Batch Acc: 73.44
[Train] Epoch: 4 [446976/620022]    Loss: 0.008540   Batch Acc: 79.69
[Train] Epoch: 4 [447040/620022]    Loss: 0.007494   Batch Acc: 78.12
[Train] Epoch: 4 [447104/620022]    Loss: 0.008166   Batch Acc: 79.69
[Train] Epoch: 4 [447168/620022]    Loss: 0.008979   Batch Acc: 71.88
[Train] Epoch: 4 [447232/620022]    Loss: 0.007843   Batch Acc: 78.12
[Train] Epoch: 4 [447296/620022]    Loss: 0.010859   Batch Acc: 70.31
[Train] Epoch: 4 [447360/620022]    Loss: 0.008677   Batch Acc: 76.56
[Train] Epoch: 4 [447424/620022]    Loss: 0.007242   Batch Acc: 82.81
[Train] Epoch: 4 [447488/620022]    Loss: 0.008261   Batch Acc: 78.12
[Train] Epoch: 4 [447552/620022]    Loss: 0.010498   Batch Acc: 71.88
[Train] Epoch: 4 [447616/620022]    Loss: 0.008970   Batch Acc: 79.69
[Train] Epoch: 4 [447680/620022]    Loss: 0.008690   Batch Acc: 79.69
[Train] Epoch: 4 [447744/620022]    Loss: 0.007920   Batch Acc: 81.25
[Train] Epoch: 4 [447808/620022]    Loss: 0.006774   Batch Acc: 84.38
[Train] Epoch: 4 [447872/620022]    Loss: 0.009162   Batch Acc: 78.12
[Train] Epoch: 4 [447936/620022]    Loss: 0.006480   Batch Acc: 81.25
[Train] Epoch: 4 [448000/620022]    Loss: 0.010007   Batch Acc: 78.12
[Train] Epoch: 4 [448064/620022]    Loss: 0.008006   Batch Acc: 78.12
[Train] Epoch: 4 [448128/620022]    Loss: 0.007470   Batch Acc: 81.25
[Train] Epoch: 4 [448192/620022]    Loss: 0.009739   Batch Acc: 76.56
[Train] Epoch: 4 [448256/620022]    Loss: 0.009721   Batch Acc: 76.56
[Train] Epoch: 4 [448320/620022]    Loss: 0.009683   Batch Acc: 68.75
[Train] Epoch: 4 [448384/620022]    Loss: 0.011029   Batch Acc: 67.19
[Train] Epoch: 4 [448448/620022]    Loss: 0.006790   Batch Acc: 81.25
[Train] Epoch: 4 [448512/620022]    Loss: 0.009561   Batch Acc: 79.69
[Train] Epoch: 4 [448576/620022]    Loss: 0.010722   Batch Acc: 64.06
[Train] Epoch: 4 [448640/620022]    Loss: 0.006567   Batch Acc: 81.25
[Train] Epoch: 4 [448704/620022]    Loss: 0.008639   Batch Acc: 82.81
[Train] Epoch: 4 [448768/620022]    Loss: 0.006673   Batch Acc: 82.81
[Train] Epoch: 4 [448832/620022]    Loss: 0.008512   Batch Acc: 76.56
[Train] Epoch: 4 [448896/620022]    Loss: 0.007445   Batch Acc: 82.81
[Train] Epoch: 4 [448960/620022]    Loss: 0.007556   Batch Acc: 81.25
[Train] Epoch: 4 [449024/620022]    Loss: 0.008905   Batch Acc: 75.00
[Train] Epoch: 4 [449088/620022]    Loss: 0.008711   Batch Acc: 79.69
[Train] Epoch: 4 [449152/620022]    Loss: 0.007476   Batch Acc: 82.81
[Train] Epoch: 4 [449216/620022]    Loss: 0.007370   Batch Acc: 82.81
[Train] Epoch: 4 [449280/620022]    Loss: 0.009068   Batch Acc: 76.56
[Train] Epoch: 4 [449344/620022]    Loss: 0.006869   Batch Acc: 82.81
[Train] Epoch: 4 [449408/620022]    Loss: 0.010272   Batch Acc: 68.75
[Train] Epoch: 4 [449472/620022]    Loss: 0.005448   Batch Acc: 81.25
[Train] Epoch: 4 [449536/620022]    Loss: 0.007833   Batch Acc: 81.25
[Train] Epoch: 4 [449600/620022]    Loss: 0.009442   Batch Acc: 75.00
[Train] Epoch: 4 [449664/620022]    Loss: 0.011678   Batch Acc: 67.19
[Train] Epoch: 4 [449728/620022]    Loss: 0.010408   Batch Acc: 75.00
[Train] Epoch: 4 [449792/620022]    Loss: 0.009773   Batch Acc: 76.56
[Train] Epoch: 4 [449856/620022]    Loss: 0.008032   Batch Acc: 78.12
[Train] Epoch: 4 [449920/620022]    Loss: 0.010233   Batch Acc: 70.31
[Train] Epoch: 4 [449984/620022]    Loss: 0.007492   Batch Acc: 82.81
[Train] Epoch: 4 [450048/620022]    Loss: 0.009165   Batch Acc: 76.56
[Train] Epoch: 4 [450112/620022]    Loss: 0.008049   Batch Acc: 82.81
[Train] Epoch: 4 [450176/620022]    Loss: 0.009978   Batch Acc: 71.88
[Train] Epoch: 4 [450240/620022]    Loss: 0.007236   Batch Acc: 81.25
[Train] Epoch: 4 [450304/620022]    Loss: 0.007887   Batch Acc: 79.69
[Train] Epoch: 4 [450368/620022]    Loss: 0.009525   Batch Acc: 78.12
[Train] Epoch: 4 [450432/620022]    Loss: 0.007481   Batch Acc: 82.81
[Train] Epoch: 4 [450496/620022]    Loss: 0.006342   Batch Acc: 85.94
[Train] Epoch: 4 [450560/620022]    Loss: 0.007621   Batch Acc: 78.12
[Train] Epoch: 4 [450624/620022]    Loss: 0.008175   Batch Acc: 79.69
[Train] Epoch: 4 [450688/620022]    Loss: 0.007583   Batch Acc: 73.44
[Train] Epoch: 4 [450752/620022]    Loss: 0.009993   Batch Acc: 70.31
[Train] Epoch: 4 [450816/620022]    Loss: 0.007615   Batch Acc: 82.81
[Train] Epoch: 4 [450880/620022]    Loss: 0.008766   Batch Acc: 75.00
[Train] Epoch: 4 [450944/620022]    Loss: 0.008768   Batch Acc: 76.56
[Train] Epoch: 4 [451008/620022]    Loss: 0.007950   Batch Acc: 82.81
[Train] Epoch: 4 [451072/620022]    Loss: 0.008585   Batch Acc: 76.56
[Train] Epoch: 4 [451136/620022]    Loss: 0.008270   Batch Acc: 81.25
[Train] Epoch: 4 [451200/620022]    Loss: 0.006713   Batch Acc: 82.81
[Train] Epoch: 4 [451264/620022]    Loss: 0.009359   Batch Acc: 79.69
[Train] Epoch: 4 [451328/620022]    Loss: 0.008756   Batch Acc: 79.69
[Train] Epoch: 4 [451392/620022]    Loss: 0.009332   Batch Acc: 76.56
[Train] Epoch: 4 [451456/620022]    Loss: 0.008660   Batch Acc: 79.69
[Train] Epoch: 4 [451520/620022]    Loss: 0.007973   Batch Acc: 81.25
[Train] Epoch: 4 [451584/620022]    Loss: 0.009128   Batch Acc: 71.88
[Train] Epoch: 4 [451648/620022]    Loss: 0.009114   Batch Acc: 70.31
[Train] Epoch: 4 [451712/620022]    Loss: 0.007665   Batch Acc: 87.50
[Train] Epoch: 4 [451776/620022]    Loss: 0.006904   Batch Acc: 82.81
[Train] Epoch: 4 [451840/620022]    Loss: 0.008977   Batch Acc: 79.69
[Train] Epoch: 4 [451904/620022]    Loss: 0.007210   Batch Acc: 85.94
[Train] Epoch: 4 [451968/620022]    Loss: 0.009840   Batch Acc: 76.56
[Train] Epoch: 4 [452032/620022]    Loss: 0.010120   Batch Acc: 71.88
[Train] Epoch: 4 [452096/620022]    Loss: 0.011030   Batch Acc: 67.19
[Train] Epoch: 4 [452160/620022]    Loss: 0.008443   Batch Acc: 78.12
[Train] Epoch: 4 [452224/620022]    Loss: 0.010465   Batch Acc: 67.19
[Train] Epoch: 4 [452288/620022]    Loss: 0.011412   Batch Acc: 68.75
[Train] Epoch: 4 [452352/620022]    Loss: 0.008610   Batch Acc: 76.56
[Train] Epoch: 4 [452416/620022]    Loss: 0.010222   Batch Acc: 75.00
[Train] Epoch: 4 [452480/620022]    Loss: 0.012842   Batch Acc: 64.06
[Train] Epoch: 4 [452544/620022]    Loss: 0.010637   Batch Acc: 73.44
[Train] Epoch: 4 [452608/620022]    Loss: 0.008890   Batch Acc: 76.56
[Train] Epoch: 4 [452672/620022]    Loss: 0.007698   Batch Acc: 87.50
[Train] Epoch: 4 [452736/620022]    Loss: 0.008153   Batch Acc: 79.69
[Train] Epoch: 4 [452800/620022]    Loss: 0.007957   Batch Acc: 71.88
[Train] Epoch: 4 [452864/620022]    Loss: 0.007729   Batch Acc: 78.12
[Train] Epoch: 4 [452928/620022]    Loss: 0.007201   Batch Acc: 81.25
[Train] Epoch: 4 [452992/620022]    Loss: 0.009641   Batch Acc: 71.88
[Train] Epoch: 4 [453056/620022]    Loss: 0.008728   Batch Acc: 75.00
[Train] Epoch: 4 [453120/620022]    Loss: 0.005650   Batch Acc: 90.62
[Train] Epoch: 4 [453184/620022]    Loss: 0.009725   Batch Acc: 75.00
[Train] Epoch: 4 [453248/620022]    Loss: 0.010602   Batch Acc: 73.44
[Train] Epoch: 4 [453312/620022]    Loss: 0.008544   Batch Acc: 78.12
[Train] Epoch: 4 [453376/620022]    Loss: 0.009950   Batch Acc: 79.69
[Train] Epoch: 4 [453440/620022]    Loss: 0.008523   Batch Acc: 78.12
[Train] Epoch: 4 [453504/620022]    Loss: 0.007419   Batch Acc: 82.81
[Train] Epoch: 4 [453568/620022]    Loss: 0.007094   Batch Acc: 87.50
[Train] Epoch: 4 [453632/620022]    Loss: 0.009390   Batch Acc: 79.69
[Train] Epoch: 4 [453696/620022]    Loss: 0.010832   Batch Acc: 68.75
[Train] Epoch: 4 [453760/620022]    Loss: 0.007951   Batch Acc: 78.12
[Train] Epoch: 4 [453824/620022]    Loss: 0.007162   Batch Acc: 82.81
[Train] Epoch: 4 [453888/620022]    Loss: 0.008103   Batch Acc: 75.00
[Train] Epoch: 4 [453952/620022]    Loss: 0.007303   Batch Acc: 84.38
[Train] Epoch: 4 [454016/620022]    Loss: 0.007876   Batch Acc: 81.25
[Train] Epoch: 4 [454080/620022]    Loss: 0.009408   Batch Acc: 79.69
[Train] Epoch: 4 [454144/620022]    Loss: 0.008001   Batch Acc: 79.69
[Train] Epoch: 4 [454208/620022]    Loss: 0.011639   Batch Acc: 64.06
[Train] Epoch: 4 [454272/620022]    Loss: 0.008294   Batch Acc: 71.88
[Train] Epoch: 4 [454336/620022]    Loss: 0.009224   Batch Acc: 75.00
[Train] Epoch: 4 [454400/620022]    Loss: 0.011030   Batch Acc: 70.31
[Train] Epoch: 4 [454464/620022]    Loss: 0.009637   Batch Acc: 76.56
[Train] Epoch: 4 [454528/620022]    Loss: 0.007146   Batch Acc: 89.06
[Train] Epoch: 4 [454592/620022]    Loss: 0.010654   Batch Acc: 78.12
[Train] Epoch: 4 [454656/620022]    Loss: 0.011770   Batch Acc: 68.75
[Train] Epoch: 4 [454720/620022]    Loss: 0.006710   Batch Acc: 81.25
[Train] Epoch: 4 [454784/620022]    Loss: 0.009263   Batch Acc: 79.69
[Train] Epoch: 4 [454848/620022]    Loss: 0.007312   Batch Acc: 81.25
[Train] Epoch: 4 [454912/620022]    Loss: 0.008645   Batch Acc: 78.12
[Train] Epoch: 4 [454976/620022]    Loss: 0.009841   Batch Acc: 73.44
[Train] Epoch: 4 [455040/620022]    Loss: 0.008428   Batch Acc: 79.69
[Train] Epoch: 4 [455104/620022]    Loss: 0.010646   Batch Acc: 68.75
[Train] Epoch: 4 [455168/620022]    Loss: 0.005295   Batch Acc: 89.06
[Train] Epoch: 4 [455232/620022]    Loss: 0.007217   Batch Acc: 84.38
[Train] Epoch: 4 [455296/620022]    Loss: 0.008448   Batch Acc: 78.12
[Train] Epoch: 4 [455360/620022]    Loss: 0.007382   Batch Acc: 79.69
[Train] Epoch: 4 [455424/620022]    Loss: 0.010549   Batch Acc: 76.56
[Train] Epoch: 4 [455488/620022]    Loss: 0.007663   Batch Acc: 81.25
[Train] Epoch: 4 [455552/620022]    Loss: 0.010203   Batch Acc: 67.19
[Train] Epoch: 4 [455616/620022]    Loss: 0.007231   Batch Acc: 79.69
[Train] Epoch: 4 [455680/620022]    Loss: 0.008010   Batch Acc: 78.12
[Train] Epoch: 4 [455744/620022]    Loss: 0.007024   Batch Acc: 81.25
[Train] Epoch: 4 [455808/620022]    Loss: 0.009363   Batch Acc: 76.56
[Train] Epoch: 4 [455872/620022]    Loss: 0.008648   Batch Acc: 79.69
[Train] Epoch: 4 [455936/620022]    Loss: 0.010962   Batch Acc: 68.75
[Train] Epoch: 4 [456000/620022]    Loss: 0.008537   Batch Acc: 78.12
[Train] Epoch: 4 [456064/620022]    Loss: 0.008667   Batch Acc: 78.12
[Train] Epoch: 4 [456128/620022]    Loss: 0.007965   Batch Acc: 84.38
[Train] Epoch: 4 [456192/620022]    Loss: 0.008072   Batch Acc: 78.12
[Train] Epoch: 4 [456256/620022]    Loss: 0.010226   Batch Acc: 76.56
[Train] Epoch: 4 [456320/620022]    Loss: 0.009992   Batch Acc: 73.44
[Train] Epoch: 4 [456384/620022]    Loss: 0.007476   Batch Acc: 84.38
[Train] Epoch: 4 [456448/620022]    Loss: 0.010658   Batch Acc: 81.25
[Train] Epoch: 4 [456512/620022]    Loss: 0.008037   Batch Acc: 81.25
[Train] Epoch: 4 [456576/620022]    Loss: 0.007731   Batch Acc: 87.50
[Train] Epoch: 4 [456640/620022]    Loss: 0.008792   Batch Acc: 82.81
[Train] Epoch: 4 [456704/620022]    Loss: 0.009268   Batch Acc: 75.00
[Train] Epoch: 4 [456768/620022]    Loss: 0.009526   Batch Acc: 76.56
[Train] Epoch: 4 [456832/620022]    Loss: 0.008673   Batch Acc: 79.69
[Train] Epoch: 4 [456896/620022]    Loss: 0.006796   Batch Acc: 85.94
[Train] Epoch: 4 [456960/620022]    Loss: 0.009409   Batch Acc: 75.00
[Train] Epoch: 4 [457024/620022]    Loss: 0.009673   Batch Acc: 71.88
[Train] Epoch: 4 [457088/620022]    Loss: 0.007258   Batch Acc: 85.94
[Train] Epoch: 4 [457152/620022]    Loss: 0.008976   Batch Acc: 73.44
[Train] Epoch: 4 [457216/620022]    Loss: 0.009275   Batch Acc: 78.12
[Train] Epoch: 4 [457280/620022]    Loss: 0.009730   Batch Acc: 78.12
[Train] Epoch: 4 [457344/620022]    Loss: 0.009858   Batch Acc: 76.56
[Train] Epoch: 4 [457408/620022]    Loss: 0.010596   Batch Acc: 70.31
[Train] Epoch: 4 [457472/620022]    Loss: 0.008966   Batch Acc: 78.12
[Train] Epoch: 4 [457536/620022]    Loss: 0.007786   Batch Acc: 79.69
[Train] Epoch: 4 [457600/620022]    Loss: 0.009893   Batch Acc: 73.44
[Train] Epoch: 4 [457664/620022]    Loss: 0.010392   Batch Acc: 70.31
[Train] Epoch: 4 [457728/620022]    Loss: 0.008138   Batch Acc: 81.25
[Train] Epoch: 4 [457792/620022]    Loss: 0.009153   Batch Acc: 76.56
[Train] Epoch: 4 [457856/620022]    Loss: 0.007381   Batch Acc: 82.81
[Train] Epoch: 4 [457920/620022]    Loss: 0.007985   Batch Acc: 81.25
[Train] Epoch: 4 [457984/620022]    Loss: 0.005753   Batch Acc: 84.38
[Train] Epoch: 4 [458048/620022]    Loss: 0.010392   Batch Acc: 68.75
[Train] Epoch: 4 [458112/620022]    Loss: 0.009019   Batch Acc: 84.38
[Train] Epoch: 4 [458176/620022]    Loss: 0.010770   Batch Acc: 75.00
[Train] Epoch: 4 [458240/620022]    Loss: 0.006386   Batch Acc: 87.50
[Train] Epoch: 4 [458304/620022]    Loss: 0.008928   Batch Acc: 82.81
[Train] Epoch: 4 [458368/620022]    Loss: 0.010091   Batch Acc: 73.44
[Train] Epoch: 4 [458432/620022]    Loss: 0.006657   Batch Acc: 82.81
[Train] Epoch: 4 [458496/620022]    Loss: 0.008886   Batch Acc: 81.25
[Train] Epoch: 4 [458560/620022]    Loss: 0.009807   Batch Acc: 75.00
[Train] Epoch: 4 [458624/620022]    Loss: 0.009196   Batch Acc: 75.00
[Train] Epoch: 4 [458688/620022]    Loss: 0.008563   Batch Acc: 81.25
[Train] Epoch: 4 [458752/620022]    Loss: 0.011195   Batch Acc: 68.75
[Train] Epoch: 4 [458816/620022]    Loss: 0.009734   Batch Acc: 75.00
[Train] Epoch: 4 [458880/620022]    Loss: 0.008082   Batch Acc: 82.81
[Train] Epoch: 4 [458944/620022]    Loss: 0.007514   Batch Acc: 78.12
[Train] Epoch: 4 [459008/620022]    Loss: 0.006865   Batch Acc: 84.38
[Train] Epoch: 4 [459072/620022]    Loss: 0.009373   Batch Acc: 71.88
[Train] Epoch: 4 [459136/620022]    Loss: 0.008868   Batch Acc: 71.88
[Train] Epoch: 4 [459200/620022]    Loss: 0.008296   Batch Acc: 76.56
[Train] Epoch: 4 [459264/620022]    Loss: 0.007342   Batch Acc: 79.69
[Train] Epoch: 4 [459328/620022]    Loss: 0.008619   Batch Acc: 82.81
[Train] Epoch: 4 [459392/620022]    Loss: 0.010791   Batch Acc: 75.00
[Train] Epoch: 4 [459456/620022]    Loss: 0.006163   Batch Acc: 85.94
[Train] Epoch: 4 [459520/620022]    Loss: 0.010093   Batch Acc: 81.25
[Train] Epoch: 4 [459584/620022]    Loss: 0.008158   Batch Acc: 79.69
[Train] Epoch: 4 [459648/620022]    Loss: 0.009013   Batch Acc: 76.56
[Train] Epoch: 4 [459712/620022]    Loss: 0.006869   Batch Acc: 87.50
[Train] Epoch: 4 [459776/620022]    Loss: 0.008926   Batch Acc: 75.00
[Train] Epoch: 4 [459840/620022]    Loss: 0.006666   Batch Acc: 82.81
[Train] Epoch: 4 [459904/620022]    Loss: 0.010543   Batch Acc: 71.88
[Train] Epoch: 4 [459968/620022]    Loss: 0.008118   Batch Acc: 82.81
[Train] Epoch: 4 [460032/620022]    Loss: 0.008731   Batch Acc: 76.56
[Train] Epoch: 4 [460096/620022]    Loss: 0.008944   Batch Acc: 78.12
[Train] Epoch: 4 [460160/620022]    Loss: 0.007923   Batch Acc: 76.56
[Train] Epoch: 4 [460224/620022]    Loss: 0.008673   Batch Acc: 76.56
[Train] Epoch: 4 [460288/620022]    Loss: 0.006203   Batch Acc: 90.62
[Train] Epoch: 4 [460352/620022]    Loss: 0.008724   Batch Acc: 75.00
[Train] Epoch: 4 [460416/620022]    Loss: 0.012685   Batch Acc: 65.62
[Train] Epoch: 4 [460480/620022]    Loss: 0.007240   Batch Acc: 84.38
[Train] Epoch: 4 [460544/620022]    Loss: 0.007268   Batch Acc: 82.81
[Train] Epoch: 4 [460608/620022]    Loss: 0.008878   Batch Acc: 76.56
[Train] Epoch: 4 [460672/620022]    Loss: 0.007134   Batch Acc: 79.69
[Train] Epoch: 4 [460736/620022]    Loss: 0.010172   Batch Acc: 75.00
[Train] Epoch: 4 [460800/620022]    Loss: 0.007962   Batch Acc: 76.56
[Train] Epoch: 4 [460864/620022]    Loss: 0.007188   Batch Acc: 85.94
[Train] Epoch: 4 [460928/620022]    Loss: 0.008222   Batch Acc: 81.25
[Train] Epoch: 4 [460992/620022]    Loss: 0.010946   Batch Acc: 70.31
[Train] Epoch: 4 [461056/620022]    Loss: 0.008325   Batch Acc: 79.69
[Train] Epoch: 4 [461120/620022]    Loss: 0.007761   Batch Acc: 81.25
[Train] Epoch: 4 [461184/620022]    Loss: 0.009448   Batch Acc: 78.12
[Train] Epoch: 4 [461248/620022]    Loss: 0.007999   Batch Acc: 79.69
[Train] Epoch: 4 [461312/620022]    Loss: 0.009046   Batch Acc: 81.25
[Train] Epoch: 4 [461376/620022]    Loss: 0.010740   Batch Acc: 70.31
[Train] Epoch: 4 [461440/620022]    Loss: 0.008026   Batch Acc: 82.81
[Train] Epoch: 4 [461504/620022]    Loss: 0.006122   Batch Acc: 81.25
[Train] Epoch: 4 [461568/620022]    Loss: 0.008977   Batch Acc: 78.12
[Train] Epoch: 4 [461632/620022]    Loss: 0.005930   Batch Acc: 87.50
[Train] Epoch: 4 [461696/620022]    Loss: 0.008397   Batch Acc: 75.00
[Train] Epoch: 4 [461760/620022]    Loss: 0.008943   Batch Acc: 78.12
[Train] Epoch: 4 [461824/620022]    Loss: 0.010095   Batch Acc: 73.44
[Train] Epoch: 4 [461888/620022]    Loss: 0.006466   Batch Acc: 82.81
[Train] Epoch: 4 [461952/620022]    Loss: 0.009035   Batch Acc: 79.69
[Train] Epoch: 4 [462016/620022]    Loss: 0.011246   Batch Acc: 68.75
[Train] Epoch: 4 [462080/620022]    Loss: 0.008243   Batch Acc: 79.69
[Train] Epoch: 4 [462144/620022]    Loss: 0.007916   Batch Acc: 76.56
[Train] Epoch: 4 [462208/620022]    Loss: 0.008667   Batch Acc: 81.25
[Train] Epoch: 4 [462272/620022]    Loss: 0.009798   Batch Acc: 71.88
[Train] Epoch: 4 [462336/620022]    Loss: 0.009460   Batch Acc: 76.56
[Train] Epoch: 4 [462400/620022]    Loss: 0.007783   Batch Acc: 78.12
[Train] Epoch: 4 [462464/620022]    Loss: 0.009249   Batch Acc: 78.12
[Train] Epoch: 4 [462528/620022]    Loss: 0.006405   Batch Acc: 90.62
[Train] Epoch: 4 [462592/620022]    Loss: 0.009357   Batch Acc: 71.88
[Train] Epoch: 4 [462656/620022]    Loss: 0.007098   Batch Acc: 81.25
[Train] Epoch: 4 [462720/620022]    Loss: 0.010160   Batch Acc: 71.88
[Train] Epoch: 4 [462784/620022]    Loss: 0.009651   Batch Acc: 78.12
[Train] Epoch: 4 [462848/620022]    Loss: 0.007644   Batch Acc: 81.25
[Train] Epoch: 4 [462912/620022]    Loss: 0.008746   Batch Acc: 76.56
[Train] Epoch: 4 [462976/620022]    Loss: 0.006669   Batch Acc: 85.94
[Train] Epoch: 4 [463040/620022]    Loss: 0.006468   Batch Acc: 85.94
[Train] Epoch: 4 [463104/620022]    Loss: 0.007953   Batch Acc: 82.81
[Train] Epoch: 4 [463168/620022]    Loss: 0.009299   Batch Acc: 76.56
[Train] Epoch: 4 [463232/620022]    Loss: 0.008032   Batch Acc: 75.00
[Train] Epoch: 4 [463296/620022]    Loss: 0.008116   Batch Acc: 78.12
