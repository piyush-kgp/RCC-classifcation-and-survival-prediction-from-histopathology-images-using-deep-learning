ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)
  (fc): Linear(in_features=512, out_features=2, bias=True)
)
DEVICE cuda
[Train] Epoch: 0 [128/387873]    Loss: 0.005058   Batch Acc: 61.72
[Train] Epoch: 0 [256/387873]    Loss: 0.004918   Batch Acc: 67.97
[Train] Epoch: 0 [384/387873]    Loss: 0.004631   Batch Acc: 71.09
[Train] Epoch: 0 [512/387873]    Loss: 0.004810   Batch Acc: 67.19
[Train] Epoch: 0 [640/387873]    Loss: 0.004586   Batch Acc: 71.09
[Train] Epoch: 0 [768/387873]    Loss: 0.005015   Batch Acc: 66.41
[Train] Epoch: 0 [896/387873]    Loss: 0.005052   Batch Acc: 64.06
[Train] Epoch: 0 [1024/387873]    Loss: 0.004905   Batch Acc: 63.28
[Train] Epoch: 0 [1152/387873]    Loss: 0.004250   Batch Acc: 78.12
[Train] Epoch: 0 [1280/387873]    Loss: 0.005079   Batch Acc: 64.84
[Train] Epoch: 0 [1408/387873]    Loss: 0.004870   Batch Acc: 64.06
[Train] Epoch: 0 [1536/387873]    Loss: 0.004606   Batch Acc: 65.62
[Train] Epoch: 0 [1664/387873]    Loss: 0.004456   Batch Acc: 70.31
[Train] Epoch: 0 [1792/387873]    Loss: 0.004597   Batch Acc: 73.44
[Train] Epoch: 0 [1920/387873]    Loss: 0.004713   Batch Acc: 66.41
[Train] Epoch: 0 [2048/387873]    Loss: 0.004793   Batch Acc: 71.09
[Train] Epoch: 0 [2176/387873]    Loss: 0.004864   Batch Acc: 66.41
[Train] Epoch: 0 [2304/387873]    Loss: 0.004858   Batch Acc: 67.97
[Train] Epoch: 0 [2432/387873]    Loss: 0.004739   Batch Acc: 69.53
[Train] Epoch: 0 [2560/387873]    Loss: 0.004385   Batch Acc: 73.44
[Train] Epoch: 0 [2688/387873]    Loss: 0.004832   Batch Acc: 68.75
[Train] Epoch: 0 [2816/387873]    Loss: 0.004823   Batch Acc: 63.28
[Train] Epoch: 0 [2944/387873]    Loss: 0.004412   Batch Acc: 73.44
[Train] Epoch: 0 [3072/387873]    Loss: 0.004295   Batch Acc: 75.00
[Train] Epoch: 0 [3200/387873]    Loss: 0.005211   Batch Acc: 62.50
[Train] Epoch: 0 [3328/387873]    Loss: 0.004449   Batch Acc: 70.31
[Train] Epoch: 0 [3456/387873]    Loss: 0.004656   Batch Acc: 73.44
[Train] Epoch: 0 [3584/387873]    Loss: 0.004578   Batch Acc: 70.31
[Train] Epoch: 0 [3712/387873]    Loss: 0.004692   Batch Acc: 66.41
[Train] Epoch: 0 [3840/387873]    Loss: 0.004661   Batch Acc: 63.28
[Train] Epoch: 0 [3968/387873]    Loss: 0.004703   Batch Acc: 70.31
[Train] Epoch: 0 [4096/387873]    Loss: 0.004154   Batch Acc: 78.91
[Train] Epoch: 0 [4224/387873]    Loss: 0.004835   Batch Acc: 71.09
[Train] Epoch: 0 [4352/387873]    Loss: 0.004339   Batch Acc: 73.44
[Train] Epoch: 0 [4480/387873]    Loss: 0.004421   Batch Acc: 72.66
[Train] Epoch: 0 [4608/387873]    Loss: 0.004507   Batch Acc: 72.66
[Train] Epoch: 0 [4736/387873]    Loss: 0.004303   Batch Acc: 74.22
[Train] Epoch: 0 [4864/387873]    Loss: 0.004586   Batch Acc: 69.53
[Train] Epoch: 0 [4992/387873]    Loss: 0.004982   Batch Acc: 64.06
[Train] Epoch: 0 [5120/387873]    Loss: 0.004562   Batch Acc: 66.41
[Train] Epoch: 0 [5248/387873]    Loss: 0.004874   Batch Acc: 67.97
[Train] Epoch: 0 [5376/387873]    Loss: 0.004993   Batch Acc: 66.41
[Train] Epoch: 0 [5504/387873]    Loss: 0.004817   Batch Acc: 63.28
[Train] Epoch: 0 [5632/387873]    Loss: 0.004987   Batch Acc: 59.38
[Train] Epoch: 0 [5760/387873]    Loss: 0.004383   Batch Acc: 75.00
[Train] Epoch: 0 [5888/387873]    Loss: 0.004149   Batch Acc: 74.22
[Train] Epoch: 0 [6016/387873]    Loss: 0.004741   Batch Acc: 71.88
[Train] Epoch: 0 [6144/387873]    Loss: 0.004513   Batch Acc: 71.09
[Train] Epoch: 0 [6272/387873]    Loss: 0.004049   Batch Acc: 78.12
[Train] Epoch: 0 [6400/387873]    Loss: 0.004582   Batch Acc: 73.44
[Train] Epoch: 0 [6528/387873]    Loss: 0.004560   Batch Acc: 66.41
[Train] Epoch: 0 [6656/387873]    Loss: 0.004617   Batch Acc: 70.31
[Train] Epoch: 0 [6784/387873]    Loss: 0.004555   Batch Acc: 71.09
[Train] Epoch: 0 [6912/387873]    Loss: 0.004380   Batch Acc: 75.00
[Train] Epoch: 0 [7040/387873]    Loss: 0.004474   Batch Acc: 71.88
[Train] Epoch: 0 [7168/387873]    Loss: 0.004461   Batch Acc: 74.22
[Train] Epoch: 0 [7296/387873]    Loss: 0.004115   Batch Acc: 72.66
[Train] Epoch: 0 [7424/387873]    Loss: 0.004667   Batch Acc: 69.53
[Train] Epoch: 0 [7552/387873]    Loss: 0.004436   Batch Acc: 70.31
[Train] Epoch: 0 [7680/387873]    Loss: 0.004525   Batch Acc: 71.88
[Train] Epoch: 0 [7808/387873]    Loss: 0.004435   Batch Acc: 73.44
[Train] Epoch: 0 [7936/387873]    Loss: 0.004722   Batch Acc: 67.97
[Train] Epoch: 0 [8064/387873]    Loss: 0.004021   Batch Acc: 73.44
[Train] Epoch: 0 [8192/387873]    Loss: 0.004200   Batch Acc: 73.44
[Train] Epoch: 0 [8320/387873]    Loss: 0.004400   Batch Acc: 70.31
[Train] Epoch: 0 [8448/387873]    Loss: 0.003762   Batch Acc: 79.69
[Train] Epoch: 0 [8576/387873]    Loss: 0.004233   Batch Acc: 77.34
[Train] Epoch: 0 [8704/387873]    Loss: 0.004279   Batch Acc: 74.22
[Train] Epoch: 0 [8832/387873]    Loss: 0.004757   Batch Acc: 70.31
[Train] Epoch: 0 [8960/387873]    Loss: 0.004470   Batch Acc: 68.75
[Train] Epoch: 0 [9088/387873]    Loss: 0.003797   Batch Acc: 75.78
[Train] Epoch: 0 [9216/387873]    Loss: 0.004697   Batch Acc: 67.97
[Train] Epoch: 0 [9344/387873]    Loss: 0.004281   Batch Acc: 71.09
[Train] Epoch: 0 [9472/387873]    Loss: 0.004191   Batch Acc: 75.78
[Train] Epoch: 0 [9600/387873]    Loss: 0.004066   Batch Acc: 76.56
[Train] Epoch: 0 [9728/387873]    Loss: 0.003908   Batch Acc: 78.91
[Train] Epoch: 0 [9856/387873]    Loss: 0.003944   Batch Acc: 76.56
[Train] Epoch: 0 [9984/387873]    Loss: 0.003891   Batch Acc: 80.47
[Train] Epoch: 0 [10112/387873]    Loss: 0.003717   Batch Acc: 81.25
[Train] Epoch: 0 [10240/387873]    Loss: 0.004298   Batch Acc: 71.09
[Train] Epoch: 0 [10368/387873]    Loss: 0.004274   Batch Acc: 75.00
[Train] Epoch: 0 [10496/387873]    Loss: 0.004270   Batch Acc: 72.66
[Train] Epoch: 0 [10624/387873]    Loss: 0.004491   Batch Acc: 70.31
[Train] Epoch: 0 [10752/387873]    Loss: 0.003965   Batch Acc: 74.22
[Train] Epoch: 0 [10880/387873]    Loss: 0.003852   Batch Acc: 76.56
[Train] Epoch: 0 [11008/387873]    Loss: 0.003980   Batch Acc: 75.78
[Train] Epoch: 0 [11136/387873]    Loss: 0.004324   Batch Acc: 75.00
[Train] Epoch: 0 [11264/387873]    Loss: 0.004685   Batch Acc: 67.19
[Train] Epoch: 0 [11392/387873]    Loss: 0.004446   Batch Acc: 67.19
[Train] Epoch: 0 [11520/387873]    Loss: 0.004033   Batch Acc: 75.78
[Train] Epoch: 0 [11648/387873]    Loss: 0.004345   Batch Acc: 67.19
[Train] Epoch: 0 [11776/387873]    Loss: 0.004043   Batch Acc: 75.78
[Train] Epoch: 0 [11904/387873]    Loss: 0.004702   Batch Acc: 66.41
[Train] Epoch: 0 [12032/387873]    Loss: 0.004078   Batch Acc: 74.22
[Train] Epoch: 0 [12160/387873]    Loss: 0.004019   Batch Acc: 75.78
[Train] Epoch: 0 [12288/387873]    Loss: 0.004244   Batch Acc: 72.66
[Train] Epoch: 0 [12416/387873]    Loss: 0.004375   Batch Acc: 69.53
[Train] Epoch: 0 [12544/387873]    Loss: 0.004362   Batch Acc: 69.53
[Train] Epoch: 0 [12672/387873]    Loss: 0.003815   Batch Acc: 75.00
[Train] Epoch: 0 [12800/387873]    Loss: 0.004273   Batch Acc: 72.66
[Train] Epoch: 0 [12928/387873]    Loss: 0.003983   Batch Acc: 75.78
[Train] Epoch: 0 [13056/387873]    Loss: 0.004410   Batch Acc: 70.31
[Train] Epoch: 0 [13184/387873]    Loss: 0.003700   Batch Acc: 76.56
[Train] Epoch: 0 [13312/387873]    Loss: 0.004025   Batch Acc: 74.22
[Train] Epoch: 0 [13440/387873]    Loss: 0.003624   Batch Acc: 78.91
[Train] Epoch: 0 [13568/387873]    Loss: 0.004326   Batch Acc: 72.66
[Train] Epoch: 0 [13696/387873]    Loss: 0.004239   Batch Acc: 75.78
[Train] Epoch: 0 [13824/387873]    Loss: 0.003914   Batch Acc: 77.34
[Train] Epoch: 0 [13952/387873]    Loss: 0.003757   Batch Acc: 81.25
[Train] Epoch: 0 [14080/387873]    Loss: 0.004287   Batch Acc: 71.88
[Train] Epoch: 0 [14208/387873]    Loss: 0.003820   Batch Acc: 79.69
[Train] Epoch: 0 [14336/387873]    Loss: 0.004278   Batch Acc: 77.34
[Train] Epoch: 0 [14464/387873]    Loss: 0.004182   Batch Acc: 72.66
[Train] Epoch: 0 [14592/387873]    Loss: 0.004291   Batch Acc: 71.88
[Train] Epoch: 0 [14720/387873]    Loss: 0.003512   Batch Acc: 82.03
[Train] Epoch: 0 [14848/387873]    Loss: 0.004474   Batch Acc: 66.41
[Train] Epoch: 0 [14976/387873]    Loss: 0.003282   Batch Acc: 87.50
[Train] Epoch: 0 [15104/387873]    Loss: 0.003702   Batch Acc: 82.03
[Train] Epoch: 0 [15232/387873]    Loss: 0.003573   Batch Acc: 78.91
[Train] Epoch: 0 [15360/387873]    Loss: 0.003787   Batch Acc: 82.81
[Train] Epoch: 0 [15488/387873]    Loss: 0.003986   Batch Acc: 76.56
[Train] Epoch: 0 [15616/387873]    Loss: 0.004533   Batch Acc: 67.19
[Train] Epoch: 0 [15744/387873]    Loss: 0.003826   Batch Acc: 75.78
[Train] Epoch: 0 [15872/387873]    Loss: 0.003631   Batch Acc: 81.25
[Train] Epoch: 0 [16000/387873]    Loss: 0.003691   Batch Acc: 82.03
[Train] Epoch: 0 [16128/387873]    Loss: 0.003587   Batch Acc: 80.47
[Train] Epoch: 0 [16256/387873]    Loss: 0.003859   Batch Acc: 80.47
[Train] Epoch: 0 [16384/387873]    Loss: 0.003812   Batch Acc: 79.69
[Train] Epoch: 0 [16512/387873]    Loss: 0.004345   Batch Acc: 70.31
[Train] Epoch: 0 [16640/387873]    Loss: 0.003961   Batch Acc: 75.78
[Train] Epoch: 0 [16768/387873]    Loss: 0.003881   Batch Acc: 78.12
[Train] Epoch: 0 [16896/387873]    Loss: 0.004233   Batch Acc: 68.75
[Train] Epoch: 0 [17024/387873]    Loss: 0.003754   Batch Acc: 77.34
[Train] Epoch: 0 [17152/387873]    Loss: 0.004094   Batch Acc: 72.66
[Train] Epoch: 0 [17280/387873]    Loss: 0.003728   Batch Acc: 79.69
[Train] Epoch: 0 [17408/387873]    Loss: 0.004056   Batch Acc: 71.88
[Train] Epoch: 0 [17536/387873]    Loss: 0.003788   Batch Acc: 74.22
[Train] Epoch: 0 [17664/387873]    Loss: 0.003942   Batch Acc: 75.78
[Train] Epoch: 0 [17792/387873]    Loss: 0.003548   Batch Acc: 75.78
[Train] Epoch: 0 [17920/387873]    Loss: 0.003883   Batch Acc: 75.78
[Train] Epoch: 0 [18048/387873]    Loss: 0.004198   Batch Acc: 71.88
[Train] Epoch: 0 [18176/387873]    Loss: 0.003602   Batch Acc: 81.25
[Train] Epoch: 0 [18304/387873]    Loss: 0.003722   Batch Acc: 76.56
[Train] Epoch: 0 [18432/387873]    Loss: 0.004285   Batch Acc: 74.22
[Train] Epoch: 0 [18560/387873]    Loss: 0.004264   Batch Acc: 71.88
[Train] Epoch: 0 [18688/387873]    Loss: 0.004141   Batch Acc: 71.88
[Train] Epoch: 0 [18816/387873]    Loss: 0.003896   Batch Acc: 73.44
[Train] Epoch: 0 [18944/387873]    Loss: 0.004183   Batch Acc: 71.88
[Train] Epoch: 0 [19072/387873]    Loss: 0.003484   Batch Acc: 77.34
[Train] Epoch: 0 [19200/387873]    Loss: 0.003418   Batch Acc: 82.81
[Train] Epoch: 0 [19328/387873]    Loss: 0.004071   Batch Acc: 76.56
[Train] Epoch: 0 [19456/387873]    Loss: 0.004347   Batch Acc: 71.09
[Train] Epoch: 0 [19584/387873]    Loss: 0.004117   Batch Acc: 74.22
[Train] Epoch: 0 [19712/387873]    Loss: 0.003525   Batch Acc: 82.03
[Train] Epoch: 0 [19840/387873]    Loss: 0.003587   Batch Acc: 78.91
[Train] Epoch: 0 [19968/387873]    Loss: 0.003647   Batch Acc: 77.34
[Train] Epoch: 0 [20096/387873]    Loss: 0.003458   Batch Acc: 82.03
[Train] Epoch: 0 [20224/387873]    Loss: 0.004443   Batch Acc: 73.44
[Train] Epoch: 0 [20352/387873]    Loss: 0.003669   Batch Acc: 78.12
[Train] Epoch: 0 [20480/387873]    Loss: 0.003767   Batch Acc: 76.56
[Train] Epoch: 0 [20608/387873]    Loss: 0.003554   Batch Acc: 80.47
[Train] Epoch: 0 [20736/387873]    Loss: 0.003759   Batch Acc: 78.91
[Train] Epoch: 0 [20864/387873]    Loss: 0.003740   Batch Acc: 80.47
[Train] Epoch: 0 [20992/387873]    Loss: 0.003931   Batch Acc: 76.56
[Train] Epoch: 0 [21120/387873]    Loss: 0.003731   Batch Acc: 78.12
[Train] Epoch: 0 [21248/387873]    Loss: 0.003653   Batch Acc: 78.12
[Train] Epoch: 0 [21376/387873]    Loss: 0.003611   Batch Acc: 78.91
[Train] Epoch: 0 [21504/387873]    Loss: 0.003859   Batch Acc: 78.12
[Train] Epoch: 0 [21632/387873]    Loss: 0.003677   Batch Acc: 75.00
[Train] Epoch: 0 [21760/387873]    Loss: 0.003659   Batch Acc: 78.91
[Train] Epoch: 0 [21888/387873]    Loss: 0.003044   Batch Acc: 88.28
[Train] Epoch: 0 [22016/387873]    Loss: 0.003682   Batch Acc: 80.47
[Train] Epoch: 0 [22144/387873]    Loss: 0.003747   Batch Acc: 72.66
[Train] Epoch: 0 [22272/387873]    Loss: 0.003436   Batch Acc: 76.56
[Train] Epoch: 0 [22400/387873]    Loss: 0.003687   Batch Acc: 80.47
[Train] Epoch: 0 [22528/387873]    Loss: 0.003783   Batch Acc: 79.69
[Train] Epoch: 0 [22656/387873]    Loss: 0.003674   Batch Acc: 77.34
[Train] Epoch: 0 [22784/387873]    Loss: 0.003781   Batch Acc: 77.34
[Train] Epoch: 0 [22912/387873]    Loss: 0.003724   Batch Acc: 78.12
[Train] Epoch: 0 [23040/387873]    Loss: 0.004110   Batch Acc: 76.56
[Train] Epoch: 0 [23168/387873]    Loss: 0.003429   Batch Acc: 83.59
[Train] Epoch: 0 [23296/387873]    Loss: 0.004067   Batch Acc: 75.00
[Train] Epoch: 0 [23424/387873]    Loss: 0.003740   Batch Acc: 78.91
[Train] Epoch: 0 [23552/387873]    Loss: 0.003992   Batch Acc: 78.12
[Train] Epoch: 0 [23680/387873]    Loss: 0.004280   Batch Acc: 75.00
[Train] Epoch: 0 [23808/387873]    Loss: 0.003651   Batch Acc: 76.56
[Train] Epoch: 0 [23936/387873]    Loss: 0.003829   Batch Acc: 78.12
[Train] Epoch: 0 [24064/387873]    Loss: 0.003830   Batch Acc: 77.34
[Train] Epoch: 0 [24192/387873]    Loss: 0.003663   Batch Acc: 75.78
[Train] Epoch: 0 [24320/387873]    Loss: 0.003980   Batch Acc: 76.56
[Train] Epoch: 0 [24448/387873]    Loss: 0.004186   Batch Acc: 72.66
[Train] Epoch: 0 [24576/387873]    Loss: 0.003819   Batch Acc: 74.22
[Train] Epoch: 0 [24704/387873]    Loss: 0.003538   Batch Acc: 75.00
[Train] Epoch: 0 [24832/387873]    Loss: 0.004258   Batch Acc: 74.22
[Train] Epoch: 0 [24960/387873]    Loss: 0.003637   Batch Acc: 78.12
[Train] Epoch: 0 [25088/387873]    Loss: 0.003263   Batch Acc: 85.16
[Train] Epoch: 0 [25216/387873]    Loss: 0.004015   Batch Acc: 71.88
[Train] Epoch: 0 [25344/387873]    Loss: 0.003558   Batch Acc: 79.69
[Train] Epoch: 0 [25472/387873]    Loss: 0.003903   Batch Acc: 77.34
[Train] Epoch: 0 [25600/387873]    Loss: 0.003533   Batch Acc: 82.03
[Train] Epoch: 0 [25728/387873]    Loss: 0.003751   Batch Acc: 78.91
[Train] Epoch: 0 [25856/387873]    Loss: 0.003842   Batch Acc: 75.78
[Train] Epoch: 0 [25984/387873]    Loss: 0.003948   Batch Acc: 80.47
[Train] Epoch: 0 [26112/387873]    Loss: 0.003713   Batch Acc: 80.47
[Train] Epoch: 0 [26240/387873]    Loss: 0.003433   Batch Acc: 82.03
[Train] Epoch: 0 [26368/387873]    Loss: 0.004003   Batch Acc: 74.22
[Train] Epoch: 0 [26496/387873]    Loss: 0.003980   Batch Acc: 76.56
[Train] Epoch: 0 [26624/387873]    Loss: 0.003687   Batch Acc: 77.34
[Train] Epoch: 0 [26752/387873]    Loss: 0.004136   Batch Acc: 72.66
[Train] Epoch: 0 [26880/387873]    Loss: 0.003394   Batch Acc: 83.59
[Train] Epoch: 0 [27008/387873]    Loss: 0.003545   Batch Acc: 80.47
[Train] Epoch: 0 [27136/387873]    Loss: 0.003068   Batch Acc: 85.16
[Train] Epoch: 0 [27264/387873]    Loss: 0.003727   Batch Acc: 80.47
[Train] Epoch: 0 [27392/387873]    Loss: 0.003328   Batch Acc: 81.25
[Train] Epoch: 0 [27520/387873]    Loss: 0.003254   Batch Acc: 82.81
[Train] Epoch: 0 [27648/387873]    Loss: 0.003497   Batch Acc: 82.81
[Train] Epoch: 0 [27776/387873]    Loss: 0.003725   Batch Acc: 74.22
[Train] Epoch: 0 [27904/387873]    Loss: 0.003841   Batch Acc: 75.00
[Train] Epoch: 0 [28032/387873]    Loss: 0.003667   Batch Acc: 77.34
[Train] Epoch: 0 [28160/387873]    Loss: 0.003959   Batch Acc: 77.34
[Train] Epoch: 0 [28288/387873]    Loss: 0.003652   Batch Acc: 75.00
[Train] Epoch: 0 [28416/387873]    Loss: 0.003353   Batch Acc: 84.38
[Train] Epoch: 0 [28544/387873]    Loss: 0.003436   Batch Acc: 79.69
[Train] Epoch: 0 [28672/387873]    Loss: 0.004148   Batch Acc: 71.09
[Train] Epoch: 0 [28800/387873]    Loss: 0.003474   Batch Acc: 82.03
[Train] Epoch: 0 [28928/387873]    Loss: 0.003109   Batch Acc: 83.59
[Train] Epoch: 0 [29056/387873]    Loss: 0.003850   Batch Acc: 76.56
[Train] Epoch: 0 [29184/387873]    Loss: 0.004208   Batch Acc: 70.31
[Train] Epoch: 0 [29312/387873]    Loss: 0.003533   Batch Acc: 77.34
[Train] Epoch: 0 [29440/387873]    Loss: 0.003300   Batch Acc: 82.81
[Train] Epoch: 0 [29568/387873]    Loss: 0.003875   Batch Acc: 77.34
[Train] Epoch: 0 [29696/387873]    Loss: 0.003353   Batch Acc: 79.69
[Train] Epoch: 0 [29824/387873]    Loss: 0.003169   Batch Acc: 84.38
[Train] Epoch: 0 [29952/387873]    Loss: 0.003475   Batch Acc: 76.56
[Train] Epoch: 0 [30080/387873]    Loss: 0.003481   Batch Acc: 81.25
[Train] Epoch: 0 [30208/387873]    Loss: 0.003354   Batch Acc: 83.59
[Train] Epoch: 0 [30336/387873]    Loss: 0.003510   Batch Acc: 84.38
[Train] Epoch: 0 [30464/387873]    Loss: 0.003792   Batch Acc: 75.00
[Train] Epoch: 0 [30592/387873]    Loss: 0.003515   Batch Acc: 80.47
[Train] Epoch: 0 [30720/387873]    Loss: 0.003347   Batch Acc: 83.59
[Train] Epoch: 0 [30848/387873]    Loss: 0.003712   Batch Acc: 73.44
[Train] Epoch: 0 [30976/387873]    Loss: 0.002977   Batch Acc: 85.16
[Train] Epoch: 0 [31104/387873]    Loss: 0.003045   Batch Acc: 86.72
[Train] Epoch: 0 [31232/387873]    Loss: 0.003681   Batch Acc: 77.34
[Train] Epoch: 0 [31360/387873]    Loss: 0.003555   Batch Acc: 78.12
[Train] Epoch: 0 [31488/387873]    Loss: 0.003572   Batch Acc: 78.91
[Train] Epoch: 0 [31616/387873]    Loss: 0.003627   Batch Acc: 80.47
[Train] Epoch: 0 [31744/387873]    Loss: 0.003301   Batch Acc: 82.81
[Train] Epoch: 0 [31872/387873]    Loss: 0.003416   Batch Acc: 83.59
[Train] Epoch: 0 [32000/387873]    Loss: 0.003511   Batch Acc: 83.59
[Train] Epoch: 0 [32128/387873]    Loss: 0.003237   Batch Acc: 86.72
[Train] Epoch: 0 [32256/387873]    Loss: 0.003485   Batch Acc: 76.56
[Train] Epoch: 0 [32384/387873]    Loss: 0.003162   Batch Acc: 83.59
[Train] Epoch: 0 [32512/387873]    Loss: 0.003997   Batch Acc: 71.88
[Train] Epoch: 0 [32640/387873]    Loss: 0.004032   Batch Acc: 75.00
[Train] Epoch: 0 [32768/387873]    Loss: 0.003584   Batch Acc: 77.34
[Train] Epoch: 0 [32896/387873]    Loss: 0.003399   Batch Acc: 83.59
[Train] Epoch: 0 [33024/387873]    Loss: 0.003114   Batch Acc: 82.81
[Train] Epoch: 0 [33152/387873]    Loss: 0.003644   Batch Acc: 75.78
[Train] Epoch: 0 [33280/387873]    Loss: 0.003470   Batch Acc: 80.47
[Train] Epoch: 0 [33408/387873]    Loss: 0.003381   Batch Acc: 82.81
[Train] Epoch: 0 [33536/387873]    Loss: 0.003436   Batch Acc: 81.25
[Train] Epoch: 0 [33664/387873]    Loss: 0.003553   Batch Acc: 77.34
[Train] Epoch: 0 [33792/387873]    Loss: 0.003846   Batch Acc: 75.00
[Train] Epoch: 0 [33920/387873]    Loss: 0.003290   Batch Acc: 82.03
[Train] Epoch: 0 [34048/387873]    Loss: 0.003444   Batch Acc: 81.25
[Train] Epoch: 0 [34176/387873]    Loss: 0.003476   Batch Acc: 80.47
[Train] Epoch: 0 [34304/387873]    Loss: 0.003020   Batch Acc: 84.38
[Train] Epoch: 0 [34432/387873]    Loss: 0.003342   Batch Acc: 83.59
[Train] Epoch: 0 [34560/387873]    Loss: 0.003253   Batch Acc: 85.94
[Train] Epoch: 0 [34688/387873]    Loss: 0.003860   Batch Acc: 79.69
[Train] Epoch: 0 [34816/387873]    Loss: 0.003544   Batch Acc: 77.34
[Train] Epoch: 0 [34944/387873]    Loss: 0.003061   Batch Acc: 86.72
[Train] Epoch: 0 [35072/387873]    Loss: 0.003292   Batch Acc: 80.47
[Train] Epoch: 0 [35200/387873]    Loss: 0.003280   Batch Acc: 79.69
[Train] Epoch: 0 [35328/387873]    Loss: 0.004045   Batch Acc: 74.22
[Train] Epoch: 0 [35456/387873]    Loss: 0.003089   Batch Acc: 84.38
[Train] Epoch: 0 [35584/387873]    Loss: 0.003166   Batch Acc: 81.25
[Train] Epoch: 0 [35712/387873]    Loss: 0.003422   Batch Acc: 77.34
[Train] Epoch: 0 [35840/387873]    Loss: 0.002851   Batch Acc: 85.94
[Train] Epoch: 0 [35968/387873]    Loss: 0.003369   Batch Acc: 79.69
[Train] Epoch: 0 [36096/387873]    Loss: 0.003195   Batch Acc: 80.47
[Train] Epoch: 0 [36224/387873]    Loss: 0.003321   Batch Acc: 77.34
[Train] Epoch: 0 [36352/387873]    Loss: 0.003821   Batch Acc: 71.88
[Train] Epoch: 0 [36480/387873]    Loss: 0.002938   Batch Acc: 86.72
[Train] Epoch: 0 [36608/387873]    Loss: 0.003190   Batch Acc: 85.94
[Train] Epoch: 0 [36736/387873]    Loss: 0.003729   Batch Acc: 78.12
[Train] Epoch: 0 [36864/387873]    Loss: 0.003220   Batch Acc: 82.81
[Train] Epoch: 0 [36992/387873]    Loss: 0.002998   Batch Acc: 83.59
[Train] Epoch: 0 [37120/387873]    Loss: 0.003632   Batch Acc: 79.69
[Train] Epoch: 0 [37248/387873]    Loss: 0.003050   Batch Acc: 85.16
[Train] Epoch: 0 [37376/387873]    Loss: 0.003285   Batch Acc: 78.91
[Train] Epoch: 0 [37504/387873]    Loss: 0.003528   Batch Acc: 78.12
[Train] Epoch: 0 [37632/387873]    Loss: 0.003135   Batch Acc: 82.81
[Train] Epoch: 0 [37760/387873]    Loss: 0.003638   Batch Acc: 78.91
[Train] Epoch: 0 [37888/387873]    Loss: 0.003615   Batch Acc: 77.34
[Train] Epoch: 0 [38016/387873]    Loss: 0.003053   Batch Acc: 86.72
[Train] Epoch: 0 [38144/387873]    Loss: 0.003509   Batch Acc: 78.12
[Train] Epoch: 0 [38272/387873]    Loss: 0.003248   Batch Acc: 78.12
[Train] Epoch: 0 [38400/387873]    Loss: 0.003608   Batch Acc: 78.91
[Train] Epoch: 0 [38528/387873]    Loss: 0.003112   Batch Acc: 81.25
[Train] Epoch: 0 [38656/387873]    Loss: 0.003025   Batch Acc: 85.16
[Train] Epoch: 0 [38784/387873]    Loss: 0.002963   Batch Acc: 85.94
[Train] Epoch: 0 [38912/387873]    Loss: 0.003366   Batch Acc: 82.03
[Train] Epoch: 0 [39040/387873]    Loss: 0.002847   Batch Acc: 86.72
[Train] Epoch: 0 [39168/387873]    Loss: 0.003418   Batch Acc: 80.47
[Train] Epoch: 0 [39296/387873]    Loss: 0.003624   Batch Acc: 77.34
[Train] Epoch: 0 [39424/387873]    Loss: 0.003298   Batch Acc: 84.38
[Train] Epoch: 0 [39552/387873]    Loss: 0.003278   Batch Acc: 82.03
[Train] Epoch: 0 [39680/387873]    Loss: 0.003360   Batch Acc: 81.25
[Train] Epoch: 0 [39808/387873]    Loss: 0.003492   Batch Acc: 82.81
[Train] Epoch: 0 [39936/387873]    Loss: 0.003408   Batch Acc: 80.47
[Train] Epoch: 0 [40064/387873]    Loss: 0.003406   Batch Acc: 80.47
[Train] Epoch: 0 [40192/387873]    Loss: 0.003104   Batch Acc: 83.59
[Train] Epoch: 0 [40320/387873]    Loss: 0.003095   Batch Acc: 89.84
[Train] Epoch: 0 [40448/387873]    Loss: 0.003325   Batch Acc: 80.47
[Train] Epoch: 0 [40576/387873]    Loss: 0.003317   Batch Acc: 82.81
[Train] Epoch: 0 [40704/387873]    Loss: 0.003310   Batch Acc: 79.69
[Train] Epoch: 0 [40832/387873]    Loss: 0.003142   Batch Acc: 79.69
[Train] Epoch: 0 [40960/387873]    Loss: 0.003072   Batch Acc: 82.03
[Train] Epoch: 0 [41088/387873]    Loss: 0.003031   Batch Acc: 82.03
[Train] Epoch: 0 [41216/387873]    Loss: 0.003635   Batch Acc: 81.25
[Train] Epoch: 0 [41344/387873]    Loss: 0.003417   Batch Acc: 77.34
[Train] Epoch: 0 [41472/387873]    Loss: 0.003095   Batch Acc: 85.16
[Train] Epoch: 0 [41600/387873]    Loss: 0.003023   Batch Acc: 86.72
[Train] Epoch: 0 [41728/387873]    Loss: 0.003148   Batch Acc: 76.56
[Train] Epoch: 0 [41856/387873]    Loss: 0.003232   Batch Acc: 83.59
[Train] Epoch: 0 [41984/387873]    Loss: 0.003258   Batch Acc: 79.69
[Train] Epoch: 0 [42112/387873]    Loss: 0.003682   Batch Acc: 76.56
[Train] Epoch: 0 [42240/387873]    Loss: 0.003041   Batch Acc: 86.72
[Train] Epoch: 0 [42368/387873]    Loss: 0.002940   Batch Acc: 85.16
[Train] Epoch: 0 [42496/387873]    Loss: 0.003346   Batch Acc: 80.47
[Train] Epoch: 0 [42624/387873]    Loss: 0.003514   Batch Acc: 77.34
[Train] Epoch: 0 [42752/387873]    Loss: 0.003247   Batch Acc: 81.25
[Train] Epoch: 0 [42880/387873]    Loss: 0.003695   Batch Acc: 76.56
[Train] Epoch: 0 [43008/387873]    Loss: 0.003093   Batch Acc: 85.16
[Train] Epoch: 0 [43136/387873]    Loss: 0.003252   Batch Acc: 78.12
[Train] Epoch: 0 [43264/387873]    Loss: 0.003318   Batch Acc: 79.69
[Train] Epoch: 0 [43392/387873]    Loss: 0.003373   Batch Acc: 82.03
[Train] Epoch: 0 [43520/387873]    Loss: 0.003608   Batch Acc: 75.00
[Train] Epoch: 0 [43648/387873]    Loss: 0.003315   Batch Acc: 79.69
[Train] Epoch: 0 [43776/387873]    Loss: 0.002937   Batch Acc: 85.94
[Train] Epoch: 0 [43904/387873]    Loss: 0.003010   Batch Acc: 84.38
[Train] Epoch: 0 [44032/387873]    Loss: 0.003207   Batch Acc: 81.25
[Train] Epoch: 0 [44160/387873]    Loss: 0.002853   Batch Acc: 85.94
[Train] Epoch: 0 [44288/387873]    Loss: 0.002958   Batch Acc: 83.59
[Train] Epoch: 0 [44416/387873]    Loss: 0.003235   Batch Acc: 82.03
[Train] Epoch: 0 [44544/387873]    Loss: 0.002837   Batch Acc: 82.81
[Train] Epoch: 0 [44672/387873]    Loss: 0.003448   Batch Acc: 76.56
[Train] Epoch: 0 [44800/387873]    Loss: 0.003046   Batch Acc: 82.03
[Train] Epoch: 0 [44928/387873]    Loss: 0.002873   Batch Acc: 87.50
[Train] Epoch: 0 [45056/387873]    Loss: 0.002872   Batch Acc: 85.16
[Train] Epoch: 0 [45184/387873]    Loss: 0.003229   Batch Acc: 82.03
[Train] Epoch: 0 [45312/387873]    Loss: 0.003306   Batch Acc: 82.03
[Train] Epoch: 0 [45440/387873]    Loss: 0.003527   Batch Acc: 75.78
[Train] Epoch: 0 [45568/387873]    Loss: 0.003436   Batch Acc: 78.91
[Train] Epoch: 0 [45696/387873]    Loss: 0.002877   Batch Acc: 86.72
[Train] Epoch: 0 [45824/387873]    Loss: 0.002659   Batch Acc: 89.84
[Train] Epoch: 0 [45952/387873]    Loss: 0.003696   Batch Acc: 77.34
[Train] Epoch: 0 [46080/387873]    Loss: 0.003393   Batch Acc: 82.03
[Train] Epoch: 0 [46208/387873]    Loss: 0.003474   Batch Acc: 81.25
[Train] Epoch: 0 [46336/387873]    Loss: 0.003642   Batch Acc: 79.69
[Train] Epoch: 0 [46464/387873]    Loss: 0.003267   Batch Acc: 81.25
[Train] Epoch: 0 [46592/387873]    Loss: 0.003273   Batch Acc: 85.16
[Train] Epoch: 0 [46720/387873]    Loss: 0.002720   Batch Acc: 88.28
[Train] Epoch: 0 [46848/387873]    Loss: 0.003542   Batch Acc: 82.03
[Train] Epoch: 0 [46976/387873]    Loss: 0.003278   Batch Acc: 82.81
[Train] Epoch: 0 [47104/387873]    Loss: 0.002608   Batch Acc: 89.06
[Train] Epoch: 0 [47232/387873]    Loss: 0.003148   Batch Acc: 85.94
[Train] Epoch: 0 [47360/387873]    Loss: 0.003722   Batch Acc: 75.00
[Train] Epoch: 0 [47488/387873]    Loss: 0.003336   Batch Acc: 82.03
[Train] Epoch: 0 [47616/387873]    Loss: 0.003773   Batch Acc: 78.12
[Train] Epoch: 0 [47744/387873]    Loss: 0.003077   Batch Acc: 80.47
[Train] Epoch: 0 [47872/387873]    Loss: 0.003424   Batch Acc: 82.81
[Train] Epoch: 0 [48000/387873]    Loss: 0.003302   Batch Acc: 82.03
[Train] Epoch: 0 [48128/387873]    Loss: 0.003204   Batch Acc: 84.38
[Train] Epoch: 0 [48256/387873]    Loss: 0.003569   Batch Acc: 74.22
[Train] Epoch: 0 [48384/387873]    Loss: 0.003453   Batch Acc: 77.34
[Train] Epoch: 0 [48512/387873]    Loss: 0.002825   Batch Acc: 83.59
[Train] Epoch: 0 [48640/387873]    Loss: 0.003073   Batch Acc: 83.59
[Train] Epoch: 0 [48768/387873]    Loss: 0.003293   Batch Acc: 78.91
[Train] Epoch: 0 [48896/387873]    Loss: 0.002902   Batch Acc: 85.94
[Train] Epoch: 0 [49024/387873]    Loss: 0.003140   Batch Acc: 82.81
[Train] Epoch: 0 [49152/387873]    Loss: 0.003438   Batch Acc: 83.59
[Train] Epoch: 0 [49280/387873]    Loss: 0.003735   Batch Acc: 81.25
[Train] Epoch: 0 [49408/387873]    Loss: 0.002820   Batch Acc: 86.72
[Train] Epoch: 0 [49536/387873]    Loss: 0.002905   Batch Acc: 84.38
[Train] Epoch: 0 [49664/387873]    Loss: 0.003091   Batch Acc: 84.38
[Train] Epoch: 0 [49792/387873]    Loss: 0.003319   Batch Acc: 82.03
[Train] Epoch: 0 [49920/387873]    Loss: 0.003174   Batch Acc: 82.81
[Train] Epoch: 0 [50048/387873]    Loss: 0.002861   Batch Acc: 83.59
[Train] Epoch: 0 [50176/387873]    Loss: 0.003233   Batch Acc: 79.69
[Train] Epoch: 0 [50304/387873]    Loss: 0.003326   Batch Acc: 80.47
[Train] Epoch: 0 [50432/387873]    Loss: 0.003668   Batch Acc: 76.56
[Train] Epoch: 0 [50560/387873]    Loss: 0.002882   Batch Acc: 84.38
[Train] Epoch: 0 [50688/387873]    Loss: 0.002852   Batch Acc: 86.72
[Train] Epoch: 0 [50816/387873]    Loss: 0.003409   Batch Acc: 82.81
[Train] Epoch: 0 [50944/387873]    Loss: 0.003466   Batch Acc: 78.91
[Train] Epoch: 0 [51072/387873]    Loss: 0.002806   Batch Acc: 85.94
[Train] Epoch: 0 [51200/387873]    Loss: 0.003990   Batch Acc: 77.34
[Train] Epoch: 0 [51328/387873]    Loss: 0.003205   Batch Acc: 79.69
[Train] Epoch: 0 [51456/387873]    Loss: 0.002844   Batch Acc: 85.94
[Train] Epoch: 0 [51584/387873]    Loss: 0.002986   Batch Acc: 85.16
[Train] Epoch: 0 [51712/387873]    Loss: 0.003454   Batch Acc: 80.47
[Train] Epoch: 0 [51840/387873]    Loss: 0.002862   Batch Acc: 88.28
[Train] Epoch: 0 [51968/387873]    Loss: 0.003471   Batch Acc: 79.69
[Train] Epoch: 0 [52096/387873]    Loss: 0.002780   Batch Acc: 88.28
[Train] Epoch: 0 [52224/387873]    Loss: 0.003254   Batch Acc: 81.25
[Train] Epoch: 0 [52352/387873]    Loss: 0.003332   Batch Acc: 79.69
[Train] Epoch: 0 [52480/387873]    Loss: 0.003108   Batch Acc: 85.16
[Train] Epoch: 0 [52608/387873]    Loss: 0.003516   Batch Acc: 80.47
[Train] Epoch: 0 [52736/387873]    Loss: 0.003081   Batch Acc: 82.03
[Train] Epoch: 0 [52864/387873]    Loss: 0.002782   Batch Acc: 83.59
[Train] Epoch: 0 [52992/387873]    Loss: 0.003360   Batch Acc: 84.38
[Train] Epoch: 0 [53120/387873]    Loss: 0.003300   Batch Acc: 82.81
[Train] Epoch: 0 [53248/387873]    Loss: 0.003219   Batch Acc: 80.47
[Train] Epoch: 0 [53376/387873]    Loss: 0.003269   Batch Acc: 82.03
[Train] Epoch: 0 [53504/387873]    Loss: 0.003143   Batch Acc: 83.59
[Train] Epoch: 0 [53632/387873]    Loss: 0.002774   Batch Acc: 84.38
[Train] Epoch: 0 [53760/387873]    Loss: 0.003079   Batch Acc: 83.59
[Train] Epoch: 0 [53888/387873]    Loss: 0.003049   Batch Acc: 85.94
[Train] Epoch: 0 [54016/387873]    Loss: 0.002844   Batch Acc: 89.06
[Train] Epoch: 0 [54144/387873]    Loss: 0.003090   Batch Acc: 82.03
[Train] Epoch: 0 [54272/387873]    Loss: 0.003442   Batch Acc: 78.12
[Train] Epoch: 0 [54400/387873]    Loss: 0.003210   Batch Acc: 82.81
[Train] Epoch: 0 [54528/387873]    Loss: 0.002957   Batch Acc: 82.81
[Train] Epoch: 0 [54656/387873]    Loss: 0.003055   Batch Acc: 86.72
[Train] Epoch: 0 [54784/387873]    Loss: 0.003346   Batch Acc: 82.81
[Train] Epoch: 0 [54912/387873]    Loss: 0.002885   Batch Acc: 85.16
[Train] Epoch: 0 [55040/387873]    Loss: 0.002774   Batch Acc: 87.50
[Train] Epoch: 0 [55168/387873]    Loss: 0.003637   Batch Acc: 78.91
[Train] Epoch: 0 [55296/387873]    Loss: 0.003416   Batch Acc: 80.47
[Train] Epoch: 0 [55424/387873]    Loss: 0.003023   Batch Acc: 84.38
[Train] Epoch: 0 [55552/387873]    Loss: 0.003261   Batch Acc: 78.91
[Train] Epoch: 0 [55680/387873]    Loss: 0.002765   Batch Acc: 85.16
[Train] Epoch: 0 [55808/387873]    Loss: 0.003314   Batch Acc: 78.12
[Train] Epoch: 0 [55936/387873]    Loss: 0.002979   Batch Acc: 81.25
[Train] Epoch: 0 [56064/387873]    Loss: 0.002786   Batch Acc: 83.59
[Train] Epoch: 0 [56192/387873]    Loss: 0.002769   Batch Acc: 85.16
[Train] Epoch: 0 [56320/387873]    Loss: 0.003031   Batch Acc: 84.38
[Train] Epoch: 0 [56448/387873]    Loss: 0.003176   Batch Acc: 85.94
[Train] Epoch: 0 [56576/387873]    Loss: 0.003345   Batch Acc: 82.81
[Train] Epoch: 0 [56704/387873]    Loss: 0.003112   Batch Acc: 85.94
[Train] Epoch: 0 [56832/387873]    Loss: 0.002816   Batch Acc: 85.94
[Train] Epoch: 0 [56960/387873]    Loss: 0.003283   Batch Acc: 79.69
[Train] Epoch: 0 [57088/387873]    Loss: 0.003063   Batch Acc: 83.59
[Train] Epoch: 0 [57216/387873]    Loss: 0.004062   Batch Acc: 71.09
[Train] Epoch: 0 [57344/387873]    Loss: 0.003020   Batch Acc: 83.59
[Train] Epoch: 0 [57472/387873]    Loss: 0.003188   Batch Acc: 80.47
[Train] Epoch: 0 [57600/387873]    Loss: 0.002882   Batch Acc: 83.59
[Train] Epoch: 0 [57728/387873]    Loss: 0.002643   Batch Acc: 87.50
[Train] Epoch: 0 [57856/387873]    Loss: 0.002524   Batch Acc: 87.50
[Train] Epoch: 0 [57984/387873]    Loss: 0.003866   Batch Acc: 77.34
[Train] Epoch: 0 [58112/387873]    Loss: 0.002277   Batch Acc: 91.41
[Train] Epoch: 0 [58240/387873]    Loss: 0.002915   Batch Acc: 85.16
[Train] Epoch: 0 [58368/387873]    Loss: 0.003398   Batch Acc: 78.12
[Train] Epoch: 0 [58496/387873]    Loss: 0.002661   Batch Acc: 85.94
[Train] Epoch: 0 [58624/387873]    Loss: 0.003460   Batch Acc: 75.78
[Train] Epoch: 0 [58752/387873]    Loss: 0.003456   Batch Acc: 78.12
[Train] Epoch: 0 [58880/387873]    Loss: 0.003113   Batch Acc: 82.81
[Train] Epoch: 0 [59008/387873]    Loss: 0.003268   Batch Acc: 83.59
[Train] Epoch: 0 [59136/387873]    Loss: 0.003028   Batch Acc: 84.38
[Train] Epoch: 0 [59264/387873]    Loss: 0.003015   Batch Acc: 83.59
[Train] Epoch: 0 [59392/387873]    Loss: 0.002700   Batch Acc: 88.28
[Train] Epoch: 0 [59520/387873]    Loss: 0.003034   Batch Acc: 84.38
[Train] Epoch: 0 [59648/387873]    Loss: 0.003030   Batch Acc: 82.03
[Train] Epoch: 0 [59776/387873]    Loss: 0.003025   Batch Acc: 84.38
[Train] Epoch: 0 [59904/387873]    Loss: 0.003049   Batch Acc: 82.03
[Train] Epoch: 0 [60032/387873]    Loss: 0.003311   Batch Acc: 84.38
[Train] Epoch: 0 [60160/387873]    Loss: 0.003098   Batch Acc: 78.12
[Train] Epoch: 0 [60288/387873]    Loss: 0.003232   Batch Acc: 80.47
[Train] Epoch: 0 [60416/387873]    Loss: 0.003510   Batch Acc: 79.69
[Train] Epoch: 0 [60544/387873]    Loss: 0.002943   Batch Acc: 88.28
[Train] Epoch: 0 [60672/387873]    Loss: 0.003033   Batch Acc: 80.47
[Train] Epoch: 0 [60800/387873]    Loss: 0.002439   Batch Acc: 90.62
[Train] Epoch: 0 [60928/387873]    Loss: 0.003208   Batch Acc: 80.47
[Train] Epoch: 0 [61056/387873]    Loss: 0.002894   Batch Acc: 85.16
[Train] Epoch: 0 [61184/387873]    Loss: 0.003208   Batch Acc: 82.81
[Train] Epoch: 0 [61312/387873]    Loss: 0.002791   Batch Acc: 82.03
[Train] Epoch: 0 [61440/387873]    Loss: 0.002986   Batch Acc: 83.59
[Train] Epoch: 0 [61568/387873]    Loss: 0.003250   Batch Acc: 83.59
[Train] Epoch: 0 [61696/387873]    Loss: 0.003278   Batch Acc: 82.03
[Train] Epoch: 0 [61824/387873]    Loss: 0.002786   Batch Acc: 84.38
[Train] Epoch: 0 [61952/387873]    Loss: 0.002981   Batch Acc: 85.16
[Train] Epoch: 0 [62080/387873]    Loss: 0.002901   Batch Acc: 83.59
[Train] Epoch: 0 [62208/387873]    Loss: 0.002717   Batch Acc: 82.03
[Train] Epoch: 0 [62336/387873]    Loss: 0.002734   Batch Acc: 87.50
[Train] Epoch: 0 [62464/387873]    Loss: 0.003308   Batch Acc: 82.81
[Train] Epoch: 0 [62592/387873]    Loss: 0.003539   Batch Acc: 79.69
[Train] Epoch: 0 [62720/387873]    Loss: 0.003328   Batch Acc: 82.81
[Train] Epoch: 0 [62848/387873]    Loss: 0.003179   Batch Acc: 82.03
[Train] Epoch: 0 [62976/387873]    Loss: 0.003230   Batch Acc: 84.38
[Train] Epoch: 0 [63104/387873]    Loss: 0.002659   Batch Acc: 85.94
[Train] Epoch: 0 [63232/387873]    Loss: 0.003327   Batch Acc: 79.69
[Train] Epoch: 0 [63360/387873]    Loss: 0.003222   Batch Acc: 80.47
[Train] Epoch: 0 [63488/387873]    Loss: 0.002946   Batch Acc: 85.16
[Train] Epoch: 0 [63616/387873]    Loss: 0.003338   Batch Acc: 82.81
[Train] Epoch: 0 [63744/387873]    Loss: 0.002657   Batch Acc: 88.28
[Train] Epoch: 0 [63872/387873]    Loss: 0.002978   Batch Acc: 84.38
[Train] Epoch: 0 [64000/387873]    Loss: 0.002935   Batch Acc: 85.16
[Train] Epoch: 0 [64128/387873]    Loss: 0.002980   Batch Acc: 83.59
[Train] Epoch: 0 [64256/387873]    Loss: 0.002746   Batch Acc: 86.72
[Train] Epoch: 0 [64384/387873]    Loss: 0.002735   Batch Acc: 85.16
[Train] Epoch: 0 [64512/387873]    Loss: 0.003482   Batch Acc: 80.47
[Train] Epoch: 0 [64640/387873]    Loss: 0.002669   Batch Acc: 89.84
[Train] Epoch: 0 [64768/387873]    Loss: 0.002829   Batch Acc: 88.28
[Train] Epoch: 0 [64896/387873]    Loss: 0.003217   Batch Acc: 85.16
[Train] Epoch: 0 [65024/387873]    Loss: 0.002954   Batch Acc: 82.81
[Train] Epoch: 0 [65152/387873]    Loss: 0.002896   Batch Acc: 85.94
[Train] Epoch: 0 [65280/387873]    Loss: 0.003290   Batch Acc: 78.91
[Train] Epoch: 0 [65408/387873]    Loss: 0.002670   Batch Acc: 89.06
[Train] Epoch: 0 [65536/387873]    Loss: 0.003813   Batch Acc: 72.66
[Train] Epoch: 0 [65664/387873]    Loss: 0.002978   Batch Acc: 86.72
[Train] Epoch: 0 [65792/387873]    Loss: 0.002765   Batch Acc: 85.16
[Train] Epoch: 0 [65920/387873]    Loss: 0.002894   Batch Acc: 88.28
[Train] Epoch: 0 [66048/387873]    Loss: 0.002979   Batch Acc: 81.25
[Train] Epoch: 0 [66176/387873]    Loss: 0.002981   Batch Acc: 85.16
[Train] Epoch: 0 [66304/387873]    Loss: 0.002473   Batch Acc: 91.41
[Train] Epoch: 0 [66432/387873]    Loss: 0.002900   Batch Acc: 84.38
[Train] Epoch: 0 [66560/387873]    Loss: 0.003051   Batch Acc: 85.94
[Train] Epoch: 0 [66688/387873]    Loss: 0.003467   Batch Acc: 80.47
[Train] Epoch: 0 [66816/387873]    Loss: 0.003120   Batch Acc: 78.91
[Train] Epoch: 0 [66944/387873]    Loss: 0.003042   Batch Acc: 79.69
[Train] Epoch: 0 [67072/387873]    Loss: 0.003809   Batch Acc: 76.56
[Train] Epoch: 0 [67200/387873]    Loss: 0.002751   Batch Acc: 88.28
[Train] Epoch: 0 [67328/387873]    Loss: 0.002736   Batch Acc: 87.50
[Train] Epoch: 0 [67456/387873]    Loss: 0.003059   Batch Acc: 82.03
[Train] Epoch: 0 [67584/387873]    Loss: 0.002876   Batch Acc: 87.50
[Train] Epoch: 0 [67712/387873]    Loss: 0.002999   Batch Acc: 87.50
[Train] Epoch: 0 [67840/387873]    Loss: 0.002582   Batch Acc: 87.50
[Train] Epoch: 0 [67968/387873]    Loss: 0.002865   Batch Acc: 87.50
[Train] Epoch: 0 [68096/387873]    Loss: 0.002380   Batch Acc: 89.84
[Train] Epoch: 0 [68224/387873]    Loss: 0.003550   Batch Acc: 83.59
[Train] Epoch: 0 [68352/387873]    Loss: 0.003318   Batch Acc: 78.91
[Train] Epoch: 0 [68480/387873]    Loss: 0.003520   Batch Acc: 78.12
[Train] Epoch: 0 [68608/387873]    Loss: 0.002787   Batch Acc: 85.16
[Train] Epoch: 0 [68736/387873]    Loss: 0.002486   Batch Acc: 88.28
[Train] Epoch: 0 [68864/387873]    Loss: 0.002870   Batch Acc: 85.16
[Train] Epoch: 0 [68992/387873]    Loss: 0.002657   Batch Acc: 89.06
[Train] Epoch: 0 [69120/387873]    Loss: 0.003281   Batch Acc: 78.91
[Train] Epoch: 0 [69248/387873]    Loss: 0.003000   Batch Acc: 85.94
[Train] Epoch: 0 [69376/387873]    Loss: 0.003515   Batch Acc: 82.03
[Train] Epoch: 0 [69504/387873]    Loss: 0.003113   Batch Acc: 80.47
[Train] Epoch: 0 [69632/387873]    Loss: 0.003007   Batch Acc: 83.59
[Train] Epoch: 0 [69760/387873]    Loss: 0.003061   Batch Acc: 81.25
[Train] Epoch: 0 [69888/387873]    Loss: 0.002982   Batch Acc: 84.38
[Train] Epoch: 0 [70016/387873]    Loss: 0.002745   Batch Acc: 89.06
[Train] Epoch: 0 [70144/387873]    Loss: 0.002503   Batch Acc: 89.06
[Train] Epoch: 0 [70272/387873]    Loss: 0.003571   Batch Acc: 76.56
[Train] Epoch: 0 [70400/387873]    Loss: 0.003326   Batch Acc: 82.03
[Train] Epoch: 0 [70528/387873]    Loss: 0.002949   Batch Acc: 83.59
[Train] Epoch: 0 [70656/387873]    Loss: 0.003318   Batch Acc: 82.03
[Train] Epoch: 0 [70784/387873]    Loss: 0.003114   Batch Acc: 81.25
[Train] Epoch: 0 [70912/387873]    Loss: 0.002786   Batch Acc: 80.47
[Train] Epoch: 0 [71040/387873]    Loss: 0.002871   Batch Acc: 85.16
[Train] Epoch: 0 [71168/387873]    Loss: 0.003467   Batch Acc: 77.34
[Train] Epoch: 0 [71296/387873]    Loss: 0.002731   Batch Acc: 88.28
[Train] Epoch: 0 [71424/387873]    Loss: 0.003368   Batch Acc: 79.69
[Train] Epoch: 0 [71552/387873]    Loss: 0.003319   Batch Acc: 80.47
[Train] Epoch: 0 [71680/387873]    Loss: 0.003157   Batch Acc: 78.12
[Train] Epoch: 0 [71808/387873]    Loss: 0.003361   Batch Acc: 78.12
[Train] Epoch: 0 [71936/387873]    Loss: 0.002790   Batch Acc: 85.16
[Train] Epoch: 0 [72064/387873]    Loss: 0.002899   Batch Acc: 85.94
[Train] Epoch: 0 [72192/387873]    Loss: 0.002948   Batch Acc: 85.16
[Train] Epoch: 0 [72320/387873]    Loss: 0.002460   Batch Acc: 85.16
[Train] Epoch: 0 [72448/387873]    Loss: 0.003475   Batch Acc: 78.12
[Train] Epoch: 0 [72576/387873]    Loss: 0.003512   Batch Acc: 82.03
[Train] Epoch: 0 [72704/387873]    Loss: 0.002363   Batch Acc: 86.72
[Train] Epoch: 0 [72832/387873]    Loss: 0.003290   Batch Acc: 82.81
[Train] Epoch: 0 [72960/387873]    Loss: 0.002611   Batch Acc: 85.94
[Train] Epoch: 0 [73088/387873]    Loss: 0.003123   Batch Acc: 80.47
[Train] Epoch: 0 [73216/387873]    Loss: 0.002968   Batch Acc: 82.81
[Train] Epoch: 0 [73344/387873]    Loss: 0.002950   Batch Acc: 84.38
[Train] Epoch: 0 [73472/387873]    Loss: 0.002943   Batch Acc: 80.47
[Train] Epoch: 0 [73600/387873]    Loss: 0.002597   Batch Acc: 85.94
[Train] Epoch: 0 [73728/387873]    Loss: 0.003030   Batch Acc: 82.81
[Train] Epoch: 0 [73856/387873]    Loss: 0.002794   Batch Acc: 87.50
[Train] Epoch: 0 [73984/387873]    Loss: 0.002321   Batch Acc: 90.62
[Train] Epoch: 0 [74112/387873]    Loss: 0.002568   Batch Acc: 84.38
[Train] Epoch: 0 [74240/387873]    Loss: 0.002709   Batch Acc: 86.72
[Train] Epoch: 0 [74368/387873]    Loss: 0.002995   Batch Acc: 85.94
[Train] Epoch: 0 [74496/387873]    Loss: 0.002634   Batch Acc: 87.50
[Train] Epoch: 0 [74624/387873]    Loss: 0.003270   Batch Acc: 79.69
[Train] Epoch: 0 [74752/387873]    Loss: 0.002832   Batch Acc: 87.50
[Train] Epoch: 0 [74880/387873]    Loss: 0.002890   Batch Acc: 85.94
[Train] Epoch: 0 [75008/387873]    Loss: 0.002408   Batch Acc: 89.84
[Train] Epoch: 0 [75136/387873]    Loss: 0.002612   Batch Acc: 85.16
[Train] Epoch: 0 [75264/387873]    Loss: 0.003028   Batch Acc: 84.38
[Train] Epoch: 0 [75392/387873]    Loss: 0.002293   Batch Acc: 91.41
[Train] Epoch: 0 [75520/387873]    Loss: 0.003415   Batch Acc: 82.03
[Train] Epoch: 0 [75648/387873]    Loss: 0.002893   Batch Acc: 84.38
[Train] Epoch: 0 [75776/387873]    Loss: 0.002525   Batch Acc: 89.84
[Train] Epoch: 0 [75904/387873]    Loss: 0.002725   Batch Acc: 84.38
[Train] Epoch: 0 [76032/387873]    Loss: 0.002920   Batch Acc: 85.94
[Train] Epoch: 0 [76160/387873]    Loss: 0.002622   Batch Acc: 89.84
[Train] Epoch: 0 [76288/387873]    Loss: 0.003473   Batch Acc: 82.03
[Train] Epoch: 0 [76416/387873]    Loss: 0.002553   Batch Acc: 90.62
[Train] Epoch: 0 [76544/387873]    Loss: 0.002866   Batch Acc: 86.72
[Train] Epoch: 0 [76672/387873]    Loss: 0.002917   Batch Acc: 85.94
[Train] Epoch: 0 [76800/387873]    Loss: 0.002619   Batch Acc: 85.94
[Train] Epoch: 0 [76928/387873]    Loss: 0.003312   Batch Acc: 83.59
[Train] Epoch: 0 [77056/387873]    Loss: 0.002737   Batch Acc: 86.72
[Train] Epoch: 0 [77184/387873]    Loss: 0.002676   Batch Acc: 82.03
[Train] Epoch: 0 [77312/387873]    Loss: 0.003122   Batch Acc: 81.25
[Train] Epoch: 0 [77440/387873]    Loss: 0.003196   Batch Acc: 83.59
[Train] Epoch: 0 [77568/387873]    Loss: 0.002925   Batch Acc: 85.16
[Train] Epoch: 0 [77696/387873]    Loss: 0.002761   Batch Acc: 85.16
[Train] Epoch: 0 [77824/387873]    Loss: 0.002566   Batch Acc: 89.06
[Train] Epoch: 0 [77952/387873]    Loss: 0.002674   Batch Acc: 85.16
[Train] Epoch: 0 [78080/387873]    Loss: 0.003046   Batch Acc: 81.25
[Train] Epoch: 0 [78208/387873]    Loss: 0.002981   Batch Acc: 84.38
[Train] Epoch: 0 [78336/387873]    Loss: 0.002856   Batch Acc: 81.25
[Train] Epoch: 0 [78464/387873]    Loss: 0.002899   Batch Acc: 83.59
[Train] Epoch: 0 [78592/387873]    Loss: 0.003424   Batch Acc: 79.69
[Train] Epoch: 0 [78720/387873]    Loss: 0.002740   Batch Acc: 85.94
[Train] Epoch: 0 [78848/387873]    Loss: 0.003161   Batch Acc: 82.81
[Train] Epoch: 0 [78976/387873]    Loss: 0.002822   Batch Acc: 82.81
[Train] Epoch: 0 [79104/387873]    Loss: 0.003177   Batch Acc: 80.47
[Train] Epoch: 0 [79232/387873]    Loss: 0.002683   Batch Acc: 87.50
[Train] Epoch: 0 [79360/387873]    Loss: 0.002940   Batch Acc: 88.28
[Train] Epoch: 0 [79488/387873]    Loss: 0.002575   Batch Acc: 87.50
[Train] Epoch: 0 [79616/387873]    Loss: 0.002683   Batch Acc: 86.72
[Train] Epoch: 0 [79744/387873]    Loss: 0.002756   Batch Acc: 86.72
[Train] Epoch: 0 [79872/387873]    Loss: 0.002641   Batch Acc: 87.50
[Train] Epoch: 0 [80000/387873]    Loss: 0.003401   Batch Acc: 74.22
[Train] Epoch: 0 [80128/387873]    Loss: 0.002915   Batch Acc: 81.25
[Train] Epoch: 0 [80256/387873]    Loss: 0.002765   Batch Acc: 87.50
[Train] Epoch: 0 [80384/387873]    Loss: 0.003422   Batch Acc: 78.91
[Train] Epoch: 0 [80512/387873]    Loss: 0.002677   Batch Acc: 84.38
[Train] Epoch: 0 [80640/387873]    Loss: 0.002778   Batch Acc: 86.72
[Train] Epoch: 0 [80768/387873]    Loss: 0.002497   Batch Acc: 88.28
[Train] Epoch: 0 [80896/387873]    Loss: 0.002896   Batch Acc: 80.47
[Train] Epoch: 0 [81024/387873]    Loss: 0.003326   Batch Acc: 82.81
[Train] Epoch: 0 [81152/387873]    Loss: 0.002663   Batch Acc: 85.16
[Train] Epoch: 0 [81280/387873]    Loss: 0.002210   Batch Acc: 89.84
[Train] Epoch: 0 [81408/387873]    Loss: 0.003333   Batch Acc: 81.25
[Train] Epoch: 0 [81536/387873]    Loss: 0.003241   Batch Acc: 82.03
[Train] Epoch: 0 [81664/387873]    Loss: 0.003360   Batch Acc: 82.03
[Train] Epoch: 0 [81792/387873]    Loss: 0.002787   Batch Acc: 82.81
[Train] Epoch: 0 [81920/387873]    Loss: 0.002814   Batch Acc: 85.16
[Train] Epoch: 0 [82048/387873]    Loss: 0.002649   Batch Acc: 85.16
[Train] Epoch: 0 [82176/387873]    Loss: 0.002884   Batch Acc: 84.38
[Train] Epoch: 0 [82304/387873]    Loss: 0.003340   Batch Acc: 85.16
[Train] Epoch: 0 [82432/387873]    Loss: 0.003009   Batch Acc: 85.16
[Train] Epoch: 0 [82560/387873]    Loss: 0.002910   Batch Acc: 84.38
[Train] Epoch: 0 [82688/387873]    Loss: 0.002325   Batch Acc: 89.06
[Train] Epoch: 0 [82816/387873]    Loss: 0.002988   Batch Acc: 83.59
[Train] Epoch: 0 [82944/387873]    Loss: 0.002795   Batch Acc: 88.28
[Train] Epoch: 0 [83072/387873]    Loss: 0.002859   Batch Acc: 85.16
[Train] Epoch: 0 [83200/387873]    Loss: 0.002871   Batch Acc: 85.16
[Train] Epoch: 0 [83328/387873]    Loss: 0.002706   Batch Acc: 89.06
[Train] Epoch: 0 [83456/387873]    Loss: 0.002819   Batch Acc: 83.59
[Train] Epoch: 0 [83584/387873]    Loss: 0.002773   Batch Acc: 86.72
[Train] Epoch: 0 [83712/387873]    Loss: 0.002624   Batch Acc: 89.06
[Train] Epoch: 0 [83840/387873]    Loss: 0.003139   Batch Acc: 85.16
[Train] Epoch: 0 [83968/387873]    Loss: 0.002928   Batch Acc: 82.81
[Train] Epoch: 0 [84096/387873]    Loss: 0.003357   Batch Acc: 79.69
[Train] Epoch: 0 [84224/387873]    Loss: 0.002770   Batch Acc: 87.50
[Train] Epoch: 0 [84352/387873]    Loss: 0.003104   Batch Acc: 83.59
[Train] Epoch: 0 [84480/387873]    Loss: 0.003183   Batch Acc: 78.91
[Train] Epoch: 0 [84608/387873]    Loss: 0.002976   Batch Acc: 84.38
[Train] Epoch: 0 [84736/387873]    Loss: 0.002997   Batch Acc: 82.03
[Train] Epoch: 0 [84864/387873]    Loss: 0.002747   Batch Acc: 86.72
[Train] Epoch: 0 [84992/387873]    Loss: 0.002731   Batch Acc: 84.38
[Train] Epoch: 0 [85120/387873]    Loss: 0.002842   Batch Acc: 87.50
[Train] Epoch: 0 [85248/387873]    Loss: 0.003553   Batch Acc: 76.56
[Train] Epoch: 0 [85376/387873]    Loss: 0.003242   Batch Acc: 86.72
[Train] Epoch: 0 [85504/387873]    Loss: 0.002757   Batch Acc: 88.28
[Train] Epoch: 0 [85632/387873]    Loss: 0.002495   Batch Acc: 87.50
[Train] Epoch: 0 [85760/387873]    Loss: 0.002779   Batch Acc: 86.72
[Train] Epoch: 0 [85888/387873]    Loss: 0.002571   Batch Acc: 90.62
[Train] Epoch: 0 [86016/387873]    Loss: 0.003003   Batch Acc: 84.38
[Train] Epoch: 0 [86144/387873]    Loss: 0.002435   Batch Acc: 89.84
[Train] Epoch: 0 [86272/387873]    Loss: 0.002601   Batch Acc: 85.16
[Train] Epoch: 0 [86400/387873]    Loss: 0.003421   Batch Acc: 79.69
[Train] Epoch: 0 [86528/387873]    Loss: 0.002574   Batch Acc: 88.28
[Train] Epoch: 0 [86656/387873]    Loss: 0.002731   Batch Acc: 85.16
[Train] Epoch: 0 [86784/387873]    Loss: 0.003143   Batch Acc: 85.94
[Train] Epoch: 0 [86912/387873]    Loss: 0.002628   Batch Acc: 85.16
[Train] Epoch: 0 [87040/387873]    Loss: 0.002352   Batch Acc: 89.84
[Train] Epoch: 0 [87168/387873]    Loss: 0.002967   Batch Acc: 86.72
[Train] Epoch: 0 [87296/387873]    Loss: 0.003088   Batch Acc: 81.25
[Train] Epoch: 0 [87424/387873]    Loss: 0.003277   Batch Acc: 82.81
[Train] Epoch: 0 [87552/387873]    Loss: 0.002448   Batch Acc: 84.38
[Train] Epoch: 0 [87680/387873]    Loss: 0.003162   Batch Acc: 82.81
[Train] Epoch: 0 [87808/387873]    Loss: 0.002727   Batch Acc: 86.72
[Train] Epoch: 0 [87936/387873]    Loss: 0.002903   Batch Acc: 83.59
[Train] Epoch: 0 [88064/387873]    Loss: 0.002315   Batch Acc: 89.06
[Train] Epoch: 0 [88192/387873]    Loss: 0.002718   Batch Acc: 87.50
[Train] Epoch: 0 [88320/387873]    Loss: 0.003485   Batch Acc: 78.91
[Train] Epoch: 0 [88448/387873]    Loss: 0.002749   Batch Acc: 86.72
[Train] Epoch: 0 [88576/387873]    Loss: 0.002557   Batch Acc: 86.72
[Train] Epoch: 0 [88704/387873]    Loss: 0.002398   Batch Acc: 86.72
[Train] Epoch: 0 [88832/387873]    Loss: 0.003401   Batch Acc: 79.69
[Train] Epoch: 0 [88960/387873]    Loss: 0.002808   Batch Acc: 82.03
[Train] Epoch: 0 [89088/387873]    Loss: 0.002634   Batch Acc: 89.06
[Train] Epoch: 0 [89216/387873]    Loss: 0.002851   Batch Acc: 82.03
[Train] Epoch: 0 [89344/387873]    Loss: 0.002270   Batch Acc: 90.62
[Train] Epoch: 0 [89472/387873]    Loss: 0.002411   Batch Acc: 88.28
[Train] Epoch: 0 [89600/387873]    Loss: 0.002279   Batch Acc: 88.28
[Train] Epoch: 0 [89728/387873]    Loss: 0.002659   Batch Acc: 83.59
[Train] Epoch: 0 [89856/387873]    Loss: 0.002465   Batch Acc: 86.72
[Train] Epoch: 0 [89984/387873]    Loss: 0.003097   Batch Acc: 82.81
[Train] Epoch: 0 [90112/387873]    Loss: 0.002452   Batch Acc: 85.94
[Train] Epoch: 0 [90240/387873]    Loss: 0.002820   Batch Acc: 85.94
[Train] Epoch: 0 [90368/387873]    Loss: 0.003414   Batch Acc: 76.56
[Train] Epoch: 0 [90496/387873]    Loss: 0.002869   Batch Acc: 85.94
[Train] Epoch: 0 [90624/387873]    Loss: 0.003254   Batch Acc: 82.81
[Train] Epoch: 0 [90752/387873]    Loss: 0.002544   Batch Acc: 88.28
[Train] Epoch: 0 [90880/387873]    Loss: 0.002491   Batch Acc: 86.72
[Train] Epoch: 0 [91008/387873]    Loss: 0.002998   Batch Acc: 85.16
[Train] Epoch: 0 [91136/387873]    Loss: 0.002211   Batch Acc: 88.28
[Train] Epoch: 0 [91264/387873]    Loss: 0.002304   Batch Acc: 91.41
[Train] Epoch: 0 [91392/387873]    Loss: 0.002593   Batch Acc: 85.16
[Train] Epoch: 0 [91520/387873]    Loss: 0.002828   Batch Acc: 83.59
[Train] Epoch: 0 [91648/387873]    Loss: 0.003045   Batch Acc: 80.47
[Train] Epoch: 0 [91776/387873]    Loss: 0.003365   Batch Acc: 81.25
[Train] Epoch: 0 [91904/387873]    Loss: 0.003382   Batch Acc: 79.69
[Train] Epoch: 0 [92032/387873]    Loss: 0.002957   Batch Acc: 83.59
[Train] Epoch: 0 [92160/387873]    Loss: 0.002922   Batch Acc: 84.38
[Train] Epoch: 0 [92288/387873]    Loss: 0.002302   Batch Acc: 87.50
[Train] Epoch: 0 [92416/387873]    Loss: 0.003530   Batch Acc: 82.81
[Train] Epoch: 0 [92544/387873]    Loss: 0.002338   Batch Acc: 89.06
[Train] Epoch: 0 [92672/387873]    Loss: 0.002842   Batch Acc: 82.81
[Train] Epoch: 0 [92800/387873]    Loss: 0.003051   Batch Acc: 82.81
[Train] Epoch: 0 [92928/387873]    Loss: 0.003020   Batch Acc: 83.59
[Train] Epoch: 0 [93056/387873]    Loss: 0.002603   Batch Acc: 87.50
[Train] Epoch: 0 [93184/387873]    Loss: 0.003311   Batch Acc: 78.12
[Train] Epoch: 0 [93312/387873]    Loss: 0.002854   Batch Acc: 82.81
[Train] Epoch: 0 [93440/387873]    Loss: 0.002610   Batch Acc: 85.94
[Train] Epoch: 0 [93568/387873]    Loss: 0.002651   Batch Acc: 85.94
[Train] Epoch: 0 [93696/387873]    Loss: 0.002973   Batch Acc: 85.16
[Train] Epoch: 0 [93824/387873]    Loss: 0.003009   Batch Acc: 82.81
[Train] Epoch: 0 [93952/387873]    Loss: 0.003559   Batch Acc: 78.91
[Train] Epoch: 0 [94080/387873]    Loss: 0.002955   Batch Acc: 81.25
[Train] Epoch: 0 [94208/387873]    Loss: 0.003154   Batch Acc: 79.69
[Train] Epoch: 0 [94336/387873]    Loss: 0.003004   Batch Acc: 81.25
[Train] Epoch: 0 [94464/387873]    Loss: 0.002887   Batch Acc: 83.59
[Train] Epoch: 0 [94592/387873]    Loss: 0.002812   Batch Acc: 83.59
[Train] Epoch: 0 [94720/387873]    Loss: 0.002128   Batch Acc: 91.41
[Train] Epoch: 0 [94848/387873]    Loss: 0.002893   Batch Acc: 83.59
[Train] Epoch: 0 [94976/387873]    Loss: 0.002606   Batch Acc: 84.38
[Train] Epoch: 0 [95104/387873]    Loss: 0.003190   Batch Acc: 82.03
[Train] Epoch: 0 [95232/387873]    Loss: 0.002606   Batch Acc: 87.50
[Train] Epoch: 0 [95360/387873]    Loss: 0.003222   Batch Acc: 81.25
[Train] Epoch: 0 [95488/387873]    Loss: 0.003114   Batch Acc: 85.16
[Train] Epoch: 0 [95616/387873]    Loss: 0.002912   Batch Acc: 85.94
[Train] Epoch: 0 [95744/387873]    Loss: 0.003195   Batch Acc: 78.91
[Train] Epoch: 0 [95872/387873]    Loss: 0.002677   Batch Acc: 85.16
[Train] Epoch: 0 [96000/387873]    Loss: 0.003114   Batch Acc: 83.59
[Train] Epoch: 0 [96128/387873]    Loss: 0.002729   Batch Acc: 85.16
[Train] Epoch: 0 [96256/387873]    Loss: 0.002887   Batch Acc: 84.38
[Train] Epoch: 0 [96384/387873]    Loss: 0.002591   Batch Acc: 84.38
[Train] Epoch: 0 [96512/387873]    Loss: 0.003289   Batch Acc: 78.12
[Train] Epoch: 0 [96640/387873]    Loss: 0.002471   Batch Acc: 87.50
[Train] Epoch: 0 [96768/387873]    Loss: 0.002852   Batch Acc: 84.38
[Train] Epoch: 0 [96896/387873]    Loss: 0.002979   Batch Acc: 85.16
[Train] Epoch: 0 [97024/387873]    Loss: 0.003674   Batch Acc: 78.12
[Train] Epoch: 0 [97152/387873]    Loss: 0.003128   Batch Acc: 82.81
[Train] Epoch: 0 [97280/387873]    Loss: 0.002492   Batch Acc: 85.16
[Train] Epoch: 0 [97408/387873]    Loss: 0.003056   Batch Acc: 82.03
[Train] Epoch: 0 [97536/387873]    Loss: 0.002512   Batch Acc: 89.06
[Train] Epoch: 0 [97664/387873]    Loss: 0.003113   Batch Acc: 82.81
[Train] Epoch: 0 [97792/387873]    Loss: 0.002481   Batch Acc: 87.50
[Train] Epoch: 0 [97920/387873]    Loss: 0.002701   Batch Acc: 84.38
[Train] Epoch: 0 [98048/387873]    Loss: 0.002913   Batch Acc: 84.38
[Train] Epoch: 0 [98176/387873]    Loss: 0.002685   Batch Acc: 85.94
[Train] Epoch: 0 [98304/387873]    Loss: 0.002919   Batch Acc: 84.38
[Train] Epoch: 0 [98432/387873]    Loss: 0.002800   Batch Acc: 82.03
[Train] Epoch: 0 [98560/387873]    Loss: 0.002758   Batch Acc: 86.72
[Train] Epoch: 0 [98688/387873]    Loss: 0.003254   Batch Acc: 82.81
[Train] Epoch: 0 [98816/387873]    Loss: 0.002786   Batch Acc: 85.94
[Train] Epoch: 0 [98944/387873]    Loss: 0.002300   Batch Acc: 89.06
[Train] Epoch: 0 [99072/387873]    Loss: 0.002420   Batch Acc: 89.84
[Train] Epoch: 0 [99200/387873]    Loss: 0.003599   Batch Acc: 78.91
[Train] Epoch: 0 [99328/387873]    Loss: 0.003075   Batch Acc: 84.38
[Train] Epoch: 0 [99456/387873]    Loss: 0.002880   Batch Acc: 85.94
[Train] Epoch: 0 [99584/387873]    Loss: 0.002556   Batch Acc: 86.72
[Train] Epoch: 0 [99712/387873]    Loss: 0.003123   Batch Acc: 86.72
[Train] Epoch: 0 [99840/387873]    Loss: 0.003589   Batch Acc: 82.81
[Train] Epoch: 0 [99968/387873]    Loss: 0.002432   Batch Acc: 89.06
[Train] Epoch: 0 [100096/387873]    Loss: 0.002423   Batch Acc: 92.19
[Train] Epoch: 0 [100224/387873]    Loss: 0.002406   Batch Acc: 86.72
[Train] Epoch: 0 [100352/387873]    Loss: 0.003292   Batch Acc: 80.47
[Train] Epoch: 0 [100480/387873]    Loss: 0.002395   Batch Acc: 88.28
[Train] Epoch: 0 [100608/387873]    Loss: 0.002312   Batch Acc: 86.72
[Train] Epoch: 0 [100736/387873]    Loss: 0.003008   Batch Acc: 82.03
[Train] Epoch: 0 [100864/387873]    Loss: 0.002209   Batch Acc: 89.84
[Train] Epoch: 0 [100992/387873]    Loss: 0.002730   Batch Acc: 84.38
[Train] Epoch: 0 [101120/387873]    Loss: 0.003015   Batch Acc: 85.16
[Train] Epoch: 0 [101248/387873]    Loss: 0.002893   Batch Acc: 82.81
[Train] Epoch: 0 [101376/387873]    Loss: 0.002857   Batch Acc: 82.81
[Train] Epoch: 0 [101504/387873]    Loss: 0.002746   Batch Acc: 87.50
[Train] Epoch: 0 [101632/387873]    Loss: 0.003025   Batch Acc: 85.16
[Train] Epoch: 0 [101760/387873]    Loss: 0.003297   Batch Acc: 78.91
[Train] Epoch: 0 [101888/387873]    Loss: 0.002778   Batch Acc: 84.38
[Train] Epoch: 0 [102016/387873]    Loss: 0.002653   Batch Acc: 85.94
[Train] Epoch: 0 [102144/387873]    Loss: 0.002650   Batch Acc: 85.16
[Train] Epoch: 0 [102272/387873]    Loss: 0.003155   Batch Acc: 84.38
[Train] Epoch: 0 [102400/387873]    Loss: 0.003026   Batch Acc: 82.81
[Train] Epoch: 0 [102528/387873]    Loss: 0.002840   Batch Acc: 82.03
[Train] Epoch: 0 [102656/387873]    Loss: 0.002548   Batch Acc: 87.50
[Train] Epoch: 0 [102784/387873]    Loss: 0.002053   Batch Acc: 92.97
[Train] Epoch: 0 [102912/387873]    Loss: 0.002827   Batch Acc: 86.72
[Train] Epoch: 0 [103040/387873]    Loss: 0.002967   Batch Acc: 81.25
[Train] Epoch: 0 [103168/387873]    Loss: 0.002279   Batch Acc: 92.19
[Train] Epoch: 0 [103296/387873]    Loss: 0.002738   Batch Acc: 85.16
[Train] Epoch: 0 [103424/387873]    Loss: 0.002659   Batch Acc: 87.50
[Train] Epoch: 0 [103552/387873]    Loss: 0.002563   Batch Acc: 85.16
[Train] Epoch: 0 [103680/387873]    Loss: 0.002524   Batch Acc: 86.72
[Train] Epoch: 0 [103808/387873]    Loss: 0.002827   Batch Acc: 80.47
[Train] Epoch: 0 [103936/387873]    Loss: 0.002542   Batch Acc: 85.94
[Train] Epoch: 0 [104064/387873]    Loss: 0.002354   Batch Acc: 88.28
[Train] Epoch: 0 [104192/387873]    Loss: 0.002971   Batch Acc: 82.03
[Train] Epoch: 0 [104320/387873]    Loss: 0.002819   Batch Acc: 84.38
[Train] Epoch: 0 [104448/387873]    Loss: 0.002511   Batch Acc: 85.94
[Train] Epoch: 0 [104576/387873]    Loss: 0.002660   Batch Acc: 85.94
[Train] Epoch: 0 [104704/387873]    Loss: 0.002450   Batch Acc: 85.16
[Train] Epoch: 0 [104832/387873]    Loss: 0.002916   Batch Acc: 84.38
[Train] Epoch: 0 [104960/387873]    Loss: 0.002446   Batch Acc: 85.16
[Train] Epoch: 0 [105088/387873]    Loss: 0.003044   Batch Acc: 83.59
[Train] Epoch: 0 [105216/387873]    Loss: 0.002725   Batch Acc: 86.72
[Train] Epoch: 0 [105344/387873]    Loss: 0.002209   Batch Acc: 89.06
[Train] Epoch: 0 [105472/387873]    Loss: 0.002477   Batch Acc: 85.16
[Train] Epoch: 0 [105600/387873]    Loss: 0.002949   Batch Acc: 84.38
[Train] Epoch: 0 [105728/387873]    Loss: 0.002651   Batch Acc: 89.84
[Train] Epoch: 0 [105856/387873]    Loss: 0.002777   Batch Acc: 83.59
[Train] Epoch: 0 [105984/387873]    Loss: 0.002831   Batch Acc: 82.81
[Train] Epoch: 0 [106112/387873]    Loss: 0.002546   Batch Acc: 86.72
[Train] Epoch: 0 [106240/387873]    Loss: 0.003180   Batch Acc: 81.25
[Train] Epoch: 0 [106368/387873]    Loss: 0.003014   Batch Acc: 80.47
[Train] Epoch: 0 [106496/387873]    Loss: 0.002209   Batch Acc: 88.28
[Train] Epoch: 0 [106624/387873]    Loss: 0.002896   Batch Acc: 83.59
[Train] Epoch: 0 [106752/387873]    Loss: 0.002958   Batch Acc: 84.38
[Train] Epoch: 0 [106880/387873]    Loss: 0.002659   Batch Acc: 85.16
[Train] Epoch: 0 [107008/387873]    Loss: 0.002891   Batch Acc: 84.38
[Train] Epoch: 0 [107136/387873]    Loss: 0.002836   Batch Acc: 85.16
[Train] Epoch: 0 [107264/387873]    Loss: 0.002727   Batch Acc: 85.94
[Train] Epoch: 0 [107392/387873]    Loss: 0.002161   Batch Acc: 91.41
[Train] Epoch: 0 [107520/387873]    Loss: 0.003184   Batch Acc: 82.81
[Train] Epoch: 0 [107648/387873]    Loss: 0.003279   Batch Acc: 79.69
[Train] Epoch: 0 [107776/387873]    Loss: 0.002809   Batch Acc: 82.03
[Train] Epoch: 0 [107904/387873]    Loss: 0.001967   Batch Acc: 93.75
[Train] Epoch: 0 [108032/387873]    Loss: 0.002470   Batch Acc: 85.94
[Train] Epoch: 0 [108160/387873]    Loss: 0.002743   Batch Acc: 89.06
[Train] Epoch: 0 [108288/387873]    Loss: 0.002733   Batch Acc: 84.38
[Train] Epoch: 0 [108416/387873]    Loss: 0.002495   Batch Acc: 85.16
[Train] Epoch: 0 [108544/387873]    Loss: 0.002387   Batch Acc: 89.84
[Train] Epoch: 0 [108672/387873]    Loss: 0.002652   Batch Acc: 88.28
[Train] Epoch: 0 [108800/387873]    Loss: 0.002381   Batch Acc: 86.72
[Train] Epoch: 0 [108928/387873]    Loss: 0.002830   Batch Acc: 84.38
[Train] Epoch: 0 [109056/387873]    Loss: 0.003223   Batch Acc: 81.25
[Train] Epoch: 0 [109184/387873]    Loss: 0.002899   Batch Acc: 82.03
[Train] Epoch: 0 [109312/387873]    Loss: 0.002642   Batch Acc: 85.94
[Train] Epoch: 0 [109440/387873]    Loss: 0.002947   Batch Acc: 83.59
[Train] Epoch: 0 [109568/387873]    Loss: 0.003056   Batch Acc: 82.81
[Train] Epoch: 0 [109696/387873]    Loss: 0.002886   Batch Acc: 85.16
[Train] Epoch: 0 [109824/387873]    Loss: 0.003109   Batch Acc: 79.69
[Train] Epoch: 0 [109952/387873]    Loss: 0.002448   Batch Acc: 89.84
[Train] Epoch: 0 [110080/387873]    Loss: 0.002839   Batch Acc: 81.25
[Train] Epoch: 0 [110208/387873]    Loss: 0.002418   Batch Acc: 88.28
[Train] Epoch: 0 [110336/387873]    Loss: 0.002307   Batch Acc: 89.84
[Train] Epoch: 0 [110464/387873]    Loss: 0.002865   Batch Acc: 86.72
[Train] Epoch: 0 [110592/387873]    Loss: 0.003042   Batch Acc: 85.94
[Train] Epoch: 0 [110720/387873]    Loss: 0.002127   Batch Acc: 90.62
[Train] Epoch: 0 [110848/387873]    Loss: 0.002386   Batch Acc: 86.72
[Train] Epoch: 0 [110976/387873]    Loss: 0.002570   Batch Acc: 86.72
[Train] Epoch: 0 [111104/387873]    Loss: 0.002768   Batch Acc: 85.94
[Train] Epoch: 0 [111232/387873]    Loss: 0.002416   Batch Acc: 86.72
[Train] Epoch: 0 [111360/387873]    Loss: 0.002376   Batch Acc: 88.28
[Train] Epoch: 0 [111488/387873]    Loss: 0.003040   Batch Acc: 83.59
[Train] Epoch: 0 [111616/387873]    Loss: 0.002208   Batch Acc: 91.41
[Train] Epoch: 0 [111744/387873]    Loss: 0.002823   Batch Acc: 83.59
[Train] Epoch: 0 [111872/387873]    Loss: 0.002553   Batch Acc: 85.94
[Train] Epoch: 0 [112000/387873]    Loss: 0.002825   Batch Acc: 83.59
[Train] Epoch: 0 [112128/387873]    Loss: 0.002788   Batch Acc: 85.94
[Train] Epoch: 0 [112256/387873]    Loss: 0.002893   Batch Acc: 85.16
[Train] Epoch: 0 [112384/387873]    Loss: 0.002636   Batch Acc: 89.06
[Train] Epoch: 0 [112512/387873]    Loss: 0.001976   Batch Acc: 91.41
[Train] Epoch: 0 [112640/387873]    Loss: 0.002692   Batch Acc: 81.25
[Train] Epoch: 0 [112768/387873]    Loss: 0.002564   Batch Acc: 88.28
[Train] Epoch: 0 [112896/387873]    Loss: 0.002662   Batch Acc: 85.16
[Train] Epoch: 0 [113024/387873]    Loss: 0.003145   Batch Acc: 83.59
[Train] Epoch: 0 [113152/387873]    Loss: 0.002583   Batch Acc: 86.72
[Train] Epoch: 0 [113280/387873]    Loss: 0.002728   Batch Acc: 86.72
[Train] Epoch: 0 [113408/387873]    Loss: 0.002575   Batch Acc: 86.72
[Train] Epoch: 0 [113536/387873]    Loss: 0.002518   Batch Acc: 85.16
[Train] Epoch: 0 [113664/387873]    Loss: 0.002610   Batch Acc: 86.72
[Train] Epoch: 0 [113792/387873]    Loss: 0.002532   Batch Acc: 85.16
[Train] Epoch: 0 [113920/387873]    Loss: 0.002640   Batch Acc: 89.06
[Train] Epoch: 0 [114048/387873]    Loss: 0.003091   Batch Acc: 82.81
[Train] Epoch: 0 [114176/387873]    Loss: 0.003013   Batch Acc: 85.16
[Train] Epoch: 0 [114304/387873]    Loss: 0.002605   Batch Acc: 88.28
[Train] Epoch: 0 [114432/387873]    Loss: 0.002142   Batch Acc: 89.06
[Train] Epoch: 0 [114560/387873]    Loss: 0.002442   Batch Acc: 85.94
[Train] Epoch: 0 [114688/387873]    Loss: 0.002439   Batch Acc: 88.28
[Train] Epoch: 0 [114816/387873]    Loss: 0.002746   Batch Acc: 83.59
[Train] Epoch: 0 [114944/387873]    Loss: 0.002749   Batch Acc: 86.72
[Train] Epoch: 0 [115072/387873]    Loss: 0.002965   Batch Acc: 82.03
[Train] Epoch: 0 [115200/387873]    Loss: 0.002551   Batch Acc: 85.94
[Train] Epoch: 0 [115328/387873]    Loss: 0.002898   Batch Acc: 84.38
[Train] Epoch: 0 [115456/387873]    Loss: 0.002921   Batch Acc: 84.38
[Train] Epoch: 0 [115584/387873]    Loss: 0.002572   Batch Acc: 84.38
[Train] Epoch: 0 [115712/387873]    Loss: 0.003200   Batch Acc: 82.81
[Train] Epoch: 0 [115840/387873]    Loss: 0.002783   Batch Acc: 86.72
[Train] Epoch: 0 [115968/387873]    Loss: 0.002136   Batch Acc: 92.97
[Train] Epoch: 0 [116096/387873]    Loss: 0.002328   Batch Acc: 86.72
[Train] Epoch: 0 [116224/387873]    Loss: 0.002372   Batch Acc: 89.84
[Train] Epoch: 0 [116352/387873]    Loss: 0.002515   Batch Acc: 88.28
[Train] Epoch: 0 [116480/387873]    Loss: 0.002073   Batch Acc: 90.62
[Train] Epoch: 0 [116608/387873]    Loss: 0.002855   Batch Acc: 85.94
[Train] Epoch: 0 [116736/387873]    Loss: 0.002482   Batch Acc: 85.94
[Train] Epoch: 0 [116864/387873]    Loss: 0.002894   Batch Acc: 85.16
[Train] Epoch: 0 [116992/387873]    Loss: 0.002879   Batch Acc: 82.81
[Train] Epoch: 0 [117120/387873]    Loss: 0.003268   Batch Acc: 83.59
[Train] Epoch: 0 [117248/387873]    Loss: 0.003191   Batch Acc: 82.03
[Train] Epoch: 0 [117376/387873]    Loss: 0.002914   Batch Acc: 86.72
[Train] Epoch: 0 [117504/387873]    Loss: 0.002830   Batch Acc: 84.38
[Train] Epoch: 0 [117632/387873]    Loss: 0.002794   Batch Acc: 84.38
[Train] Epoch: 0 [117760/387873]    Loss: 0.002760   Batch Acc: 83.59
[Train] Epoch: 0 [117888/387873]    Loss: 0.002236   Batch Acc: 86.72
[Train] Epoch: 0 [118016/387873]    Loss: 0.002553   Batch Acc: 84.38
[Train] Epoch: 0 [118144/387873]    Loss: 0.002926   Batch Acc: 82.03
[Train] Epoch: 0 [118272/387873]    Loss: 0.002802   Batch Acc: 86.72
[Train] Epoch: 0 [118400/387873]    Loss: 0.002430   Batch Acc: 85.16
[Train] Epoch: 0 [118528/387873]    Loss: 0.002596   Batch Acc: 86.72
[Train] Epoch: 0 [118656/387873]    Loss: 0.002632   Batch Acc: 84.38
[Train] Epoch: 0 [118784/387873]    Loss: 0.002509   Batch Acc: 86.72
[Train] Epoch: 0 [118912/387873]    Loss: 0.002657   Batch Acc: 83.59
[Train] Epoch: 0 [119040/387873]    Loss: 0.002551   Batch Acc: 86.72
[Train] Epoch: 0 [119168/387873]    Loss: 0.003191   Batch Acc: 79.69
[Train] Epoch: 0 [119296/387873]    Loss: 0.003384   Batch Acc: 82.03
[Train] Epoch: 0 [119424/387873]    Loss: 0.002738   Batch Acc: 85.94
[Train] Epoch: 0 [119552/387873]    Loss: 0.002474   Batch Acc: 89.84
[Train] Epoch: 0 [119680/387873]    Loss: 0.002554   Batch Acc: 85.16
[Train] Epoch: 0 [119808/387873]    Loss: 0.002767   Batch Acc: 83.59
[Train] Epoch: 0 [119936/387873]    Loss: 0.002720   Batch Acc: 87.50
[Train] Epoch: 0 [120064/387873]    Loss: 0.002501   Batch Acc: 85.16
[Train] Epoch: 0 [120192/387873]    Loss: 0.002237   Batch Acc: 90.62
[Train] Epoch: 0 [120320/387873]    Loss: 0.002195   Batch Acc: 90.62
[Train] Epoch: 0 [120448/387873]    Loss: 0.002514   Batch Acc: 85.16
[Train] Epoch: 0 [120576/387873]    Loss: 0.002987   Batch Acc: 84.38
[Train] Epoch: 0 [120704/387873]    Loss: 0.002366   Batch Acc: 88.28
[Train] Epoch: 0 [120832/387873]    Loss: 0.002349   Batch Acc: 87.50
[Train] Epoch: 0 [120960/387873]    Loss: 0.002883   Batch Acc: 83.59
[Train] Epoch: 0 [121088/387873]    Loss: 0.002889   Batch Acc: 82.81
[Train] Epoch: 0 [121216/387873]    Loss: 0.002608   Batch Acc: 89.84
[Train] Epoch: 0 [121344/387873]    Loss: 0.002054   Batch Acc: 92.19
[Train] Epoch: 0 [121472/387873]    Loss: 0.002327   Batch Acc: 86.72
[Train] Epoch: 0 [121600/387873]    Loss: 0.002956   Batch Acc: 83.59
[Train] Epoch: 0 [121728/387873]    Loss: 0.002848   Batch Acc: 85.16
[Train] Epoch: 0 [121856/387873]    Loss: 0.003519   Batch Acc: 81.25
[Train] Epoch: 0 [121984/387873]    Loss: 0.002938   Batch Acc: 84.38
[Train] Epoch: 0 [122112/387873]    Loss: 0.002743   Batch Acc: 84.38
[Train] Epoch: 0 [122240/387873]    Loss: 0.002285   Batch Acc: 92.19
[Train] Epoch: 0 [122368/387873]    Loss: 0.003248   Batch Acc: 79.69
[Train] Epoch: 0 [122496/387873]    Loss: 0.002658   Batch Acc: 86.72
[Train] Epoch: 0 [122624/387873]    Loss: 0.002571   Batch Acc: 88.28
[Train] Epoch: 0 [122752/387873]    Loss: 0.002612   Batch Acc: 85.94
[Train] Epoch: 0 [122880/387873]    Loss: 0.002675   Batch Acc: 84.38
[Train] Epoch: 0 [123008/387873]    Loss: 0.002458   Batch Acc: 88.28
[Train] Epoch: 0 [123136/387873]    Loss: 0.002525   Batch Acc: 85.94
[Train] Epoch: 0 [123264/387873]    Loss: 0.002356   Batch Acc: 85.94
[Train] Epoch: 0 [123392/387873]    Loss: 0.002916   Batch Acc: 84.38
[Train] Epoch: 0 [123520/387873]    Loss: 0.002742   Batch Acc: 82.81
[Train] Epoch: 0 [123648/387873]    Loss: 0.002170   Batch Acc: 89.84
[Train] Epoch: 0 [123776/387873]    Loss: 0.002677   Batch Acc: 86.72
[Train] Epoch: 0 [123904/387873]    Loss: 0.002804   Batch Acc: 83.59
[Train] Epoch: 0 [124032/387873]    Loss: 0.002925   Batch Acc: 84.38
[Train] Epoch: 0 [124160/387873]    Loss: 0.002876   Batch Acc: 83.59
[Train] Epoch: 0 [124288/387873]    Loss: 0.002276   Batch Acc: 86.72
[Train] Epoch: 0 [124416/387873]    Loss: 0.002217   Batch Acc: 87.50
[Train] Epoch: 0 [124544/387873]    Loss: 0.002048   Batch Acc: 91.41
[Train] Epoch: 0 [124672/387873]    Loss: 0.003030   Batch Acc: 84.38
[Train] Epoch: 0 [124800/387873]    Loss: 0.002511   Batch Acc: 86.72
[Train] Epoch: 0 [124928/387873]    Loss: 0.002389   Batch Acc: 86.72
[Train] Epoch: 0 [125056/387873]    Loss: 0.003540   Batch Acc: 78.12
[Train] Epoch: 0 [125184/387873]    Loss: 0.002142   Batch Acc: 90.62
[Train] Epoch: 0 [125312/387873]    Loss: 0.002219   Batch Acc: 87.50
[Train] Epoch: 0 [125440/387873]    Loss: 0.002533   Batch Acc: 85.94
[Train] Epoch: 0 [125568/387873]    Loss: 0.002508   Batch Acc: 87.50
[Train] Epoch: 0 [125696/387873]    Loss: 0.002487   Batch Acc: 84.38
[Train] Epoch: 0 [125824/387873]    Loss: 0.002817   Batch Acc: 82.03
[Train] Epoch: 0 [125952/387873]    Loss: 0.002721   Batch Acc: 81.25
[Train] Epoch: 0 [126080/387873]    Loss: 0.002563   Batch Acc: 85.16
[Train] Epoch: 0 [126208/387873]    Loss: 0.002726   Batch Acc: 83.59
[Train] Epoch: 0 [126336/387873]    Loss: 0.002408   Batch Acc: 86.72
[Train] Epoch: 0 [126464/387873]    Loss: 0.002373   Batch Acc: 88.28
[Train] Epoch: 0 [126592/387873]    Loss: 0.002173   Batch Acc: 90.62
[Train] Epoch: 0 [126720/387873]    Loss: 0.002270   Batch Acc: 89.06
[Train] Epoch: 0 [126848/387873]    Loss: 0.002801   Batch Acc: 84.38
[Train] Epoch: 0 [126976/387873]    Loss: 0.002692   Batch Acc: 84.38
[Train] Epoch: 0 [127104/387873]    Loss: 0.002692   Batch Acc: 82.03
[Train] Epoch: 0 [127232/387873]    Loss: 0.002680   Batch Acc: 85.16
[Train] Epoch: 0 [127360/387873]    Loss: 0.002605   Batch Acc: 86.72
[Train] Epoch: 0 [127488/387873]    Loss: 0.002999   Batch Acc: 80.47
[Train] Epoch: 0 [127616/387873]    Loss: 0.002437   Batch Acc: 91.41
[Train] Epoch: 0 [127744/387873]    Loss: 0.002129   Batch Acc: 88.28
[Train] Epoch: 0 [127872/387873]    Loss: 0.002317   Batch Acc: 89.06
[Train] Epoch: 0 [128000/387873]    Loss: 0.002339   Batch Acc: 89.06
[Train] Epoch: 0 [128128/387873]    Loss: 0.002383   Batch Acc: 89.06
[Train] Epoch: 0 [128256/387873]    Loss: 0.002390   Batch Acc: 87.50
[Train] Epoch: 0 [128384/387873]    Loss: 0.002795   Batch Acc: 83.59
[Train] Epoch: 0 [128512/387873]    Loss: 0.001987   Batch Acc: 89.06
[Train] Epoch: 0 [128640/387873]    Loss: 0.002749   Batch Acc: 85.94
[Train] Epoch: 0 [128768/387873]    Loss: 0.002523   Batch Acc: 88.28
[Train] Epoch: 0 [128896/387873]    Loss: 0.002809   Batch Acc: 85.16
[Train] Epoch: 0 [129024/387873]    Loss: 0.002502   Batch Acc: 86.72
[Train] Epoch: 0 [129152/387873]    Loss: 0.002138   Batch Acc: 89.06
[Train] Epoch: 0 [129280/387873]    Loss: 0.002357   Batch Acc: 90.62
[Train] Epoch: 0 [129408/387873]    Loss: 0.003112   Batch Acc: 84.38
[Train] Epoch: 0 [129536/387873]    Loss: 0.002603   Batch Acc: 88.28
[Train] Epoch: 0 [129664/387873]    Loss: 0.002655   Batch Acc: 82.03
[Train] Epoch: 0 [129792/387873]    Loss: 0.002966   Batch Acc: 80.47
[Train] Epoch: 0 [129920/387873]    Loss: 0.002917   Batch Acc: 83.59
[Train] Epoch: 0 [130048/387873]    Loss: 0.002446   Batch Acc: 89.84
[Train] Epoch: 0 [130176/387873]    Loss: 0.002575   Batch Acc: 84.38
[Train] Epoch: 0 [130304/387873]    Loss: 0.002971   Batch Acc: 78.12
[Train] Epoch: 0 [130432/387873]    Loss: 0.002459   Batch Acc: 89.84
[Train] Epoch: 0 [130560/387873]    Loss: 0.002999   Batch Acc: 82.81
[Train] Epoch: 0 [130688/387873]    Loss: 0.002066   Batch Acc: 94.53
[Train] Epoch: 0 [130816/387873]    Loss: 0.002903   Batch Acc: 85.16
[Train] Epoch: 0 [130944/387873]    Loss: 0.002739   Batch Acc: 88.28
[Train] Epoch: 0 [131072/387873]    Loss: 0.002761   Batch Acc: 86.72
[Train] Epoch: 0 [131200/387873]    Loss: 0.002683   Batch Acc: 82.81
[Train] Epoch: 0 [131328/387873]    Loss: 0.002859   Batch Acc: 82.81
[Train] Epoch: 0 [131456/387873]    Loss: 0.002033   Batch Acc: 90.62
[Train] Epoch: 0 [131584/387873]    Loss: 0.002489   Batch Acc: 85.94
[Train] Epoch: 0 [131712/387873]    Loss: 0.002287   Batch Acc: 89.84
[Train] Epoch: 0 [131840/387873]    Loss: 0.002420   Batch Acc: 85.94
[Train] Epoch: 0 [131968/387873]    Loss: 0.002296   Batch Acc: 89.06
[Train] Epoch: 0 [132096/387873]    Loss: 0.002584   Batch Acc: 87.50
[Train] Epoch: 0 [132224/387873]    Loss: 0.002955   Batch Acc: 84.38
[Train] Epoch: 0 [132352/387873]    Loss: 0.002642   Batch Acc: 85.94
[Train] Epoch: 0 [132480/387873]    Loss: 0.002381   Batch Acc: 89.06
[Train] Epoch: 0 [132608/387873]    Loss: 0.002201   Batch Acc: 86.72
[Train] Epoch: 0 [132736/387873]    Loss: 0.002599   Batch Acc: 83.59
[Train] Epoch: 0 [132864/387873]    Loss: 0.002544   Batch Acc: 88.28
[Train] Epoch: 0 [132992/387873]    Loss: 0.002761   Batch Acc: 83.59
[Train] Epoch: 0 [133120/387873]    Loss: 0.002330   Batch Acc: 86.72
[Train] Epoch: 0 [133248/387873]    Loss: 0.002664   Batch Acc: 85.16
[Train] Epoch: 0 [133376/387873]    Loss: 0.002908   Batch Acc: 82.81
[Train] Epoch: 0 [133504/387873]    Loss: 0.002892   Batch Acc: 85.94
[Train] Epoch: 0 [133632/387873]    Loss: 0.003091   Batch Acc: 80.47
[Train] Epoch: 0 [133760/387873]    Loss: 0.002798   Batch Acc: 83.59
[Train] Epoch: 0 [133888/387873]    Loss: 0.002319   Batch Acc: 88.28
[Train] Epoch: 0 [134016/387873]    Loss: 0.002730   Batch Acc: 85.16
[Train] Epoch: 0 [134144/387873]    Loss: 0.003333   Batch Acc: 82.03
[Train] Epoch: 0 [134272/387873]    Loss: 0.002906   Batch Acc: 82.03
[Train] Epoch: 0 [134400/387873]    Loss: 0.002443   Batch Acc: 89.06
[Train] Epoch: 0 [134528/387873]    Loss: 0.002639   Batch Acc: 82.81
[Train] Epoch: 0 [134656/387873]    Loss: 0.002119   Batch Acc: 88.28
[Train] Epoch: 0 [134784/387873]    Loss: 0.002503   Batch Acc: 87.50
[Train] Epoch: 0 [134912/387873]    Loss: 0.002583   Batch Acc: 87.50
[Train] Epoch: 0 [135040/387873]    Loss: 0.002402   Batch Acc: 87.50
[Train] Epoch: 0 [135168/387873]    Loss: 0.002169   Batch Acc: 91.41
[Train] Epoch: 0 [135296/387873]    Loss: 0.002352   Batch Acc: 86.72
[Train] Epoch: 0 [135424/387873]    Loss: 0.002599   Batch Acc: 85.16
[Train] Epoch: 0 [135552/387873]    Loss: 0.002172   Batch Acc: 86.72
[Train] Epoch: 0 [135680/387873]    Loss: 0.002238   Batch Acc: 89.84
[Train] Epoch: 0 [135808/387873]    Loss: 0.002230   Batch Acc: 89.84
[Train] Epoch: 0 [135936/387873]    Loss: 0.002704   Batch Acc: 82.03
[Train] Epoch: 0 [136064/387873]    Loss: 0.002427   Batch Acc: 85.94
[Train] Epoch: 0 [136192/387873]    Loss: 0.002202   Batch Acc: 91.41
[Train] Epoch: 0 [136320/387873]    Loss: 0.002694   Batch Acc: 85.16
[Train] Epoch: 0 [136448/387873]    Loss: 0.002234   Batch Acc: 89.84
[Train] Epoch: 0 [136576/387873]    Loss: 0.002762   Batch Acc: 80.47
[Train] Epoch: 0 [136704/387873]    Loss: 0.003022   Batch Acc: 82.03
[Train] Epoch: 0 [136832/387873]    Loss: 0.002918   Batch Acc: 85.94
[Train] Epoch: 0 [136960/387873]    Loss: 0.003124   Batch Acc: 82.03
[Train] Epoch: 0 [137088/387873]    Loss: 0.002360   Batch Acc: 89.84
[Train] Epoch: 0 [137216/387873]    Loss: 0.002318   Batch Acc: 88.28
[Train] Epoch: 0 [137344/387873]    Loss: 0.002631   Batch Acc: 86.72
[Train] Epoch: 0 [137472/387873]    Loss: 0.002637   Batch Acc: 87.50
[Train] Epoch: 0 [137600/387873]    Loss: 0.002394   Batch Acc: 89.84
[Train] Epoch: 0 [137728/387873]    Loss: 0.002610   Batch Acc: 88.28
[Train] Epoch: 0 [137856/387873]    Loss: 0.002315   Batch Acc: 88.28
[Train] Epoch: 0 [137984/387873]    Loss: 0.002241   Batch Acc: 88.28
[Train] Epoch: 0 [138112/387873]    Loss: 0.002373   Batch Acc: 87.50
[Train] Epoch: 0 [138240/387873]    Loss: 0.002736   Batch Acc: 83.59
[Train] Epoch: 0 [138368/387873]    Loss: 0.002846   Batch Acc: 82.81
[Train] Epoch: 0 [138496/387873]    Loss: 0.002457   Batch Acc: 86.72
[Train] Epoch: 0 [138624/387873]    Loss: 0.002516   Batch Acc: 88.28
[Train] Epoch: 0 [138752/387873]    Loss: 0.002408   Batch Acc: 88.28
[Train] Epoch: 0 [138880/387873]    Loss: 0.002352   Batch Acc: 85.16
[Train] Epoch: 0 [139008/387873]    Loss: 0.002446   Batch Acc: 89.06
[Train] Epoch: 0 [139136/387873]    Loss: 0.002381   Batch Acc: 89.84
[Train] Epoch: 0 [139264/387873]    Loss: 0.002624   Batch Acc: 85.94
[Train] Epoch: 0 [139392/387873]    Loss: 0.002311   Batch Acc: 89.84
[Train] Epoch: 0 [139520/387873]    Loss: 0.002149   Batch Acc: 90.62
[Train] Epoch: 0 [139648/387873]    Loss: 0.002553   Batch Acc: 85.16
[Train] Epoch: 0 [139776/387873]    Loss: 0.002469   Batch Acc: 91.41
[Train] Epoch: 0 [139904/387873]    Loss: 0.002266   Batch Acc: 85.94
[Train] Epoch: 0 [140032/387873]    Loss: 0.002206   Batch Acc: 90.62
[Train] Epoch: 0 [140160/387873]    Loss: 0.002787   Batch Acc: 86.72
[Train] Epoch: 0 [140288/387873]    Loss: 0.002652   Batch Acc: 85.16
[Train] Epoch: 0 [140416/387873]    Loss: 0.002298   Batch Acc: 88.28
[Train] Epoch: 0 [140544/387873]    Loss: 0.002405   Batch Acc: 89.84
[Train] Epoch: 0 [140672/387873]    Loss: 0.002862   Batch Acc: 84.38
[Train] Epoch: 0 [140800/387873]    Loss: 0.002459   Batch Acc: 88.28
[Train] Epoch: 0 [140928/387873]    Loss: 0.002203   Batch Acc: 87.50
[Train] Epoch: 0 [141056/387873]    Loss: 0.002523   Batch Acc: 83.59
[Train] Epoch: 0 [141184/387873]    Loss: 0.002196   Batch Acc: 87.50
[Train] Epoch: 0 [141312/387873]    Loss: 0.002089   Batch Acc: 92.19
[Train] Epoch: 0 [141440/387873]    Loss: 0.002412   Batch Acc: 87.50
[Train] Epoch: 0 [141568/387873]    Loss: 0.003315   Batch Acc: 82.03
[Train] Epoch: 0 [141696/387873]    Loss: 0.002547   Batch Acc: 86.72
[Train] Epoch: 0 [141824/387873]    Loss: 0.002861   Batch Acc: 82.03
[Train] Epoch: 0 [141952/387873]    Loss: 0.002666   Batch Acc: 83.59
[Train] Epoch: 0 [142080/387873]    Loss: 0.001987   Batch Acc: 90.62
[Train] Epoch: 0 [142208/387873]    Loss: 0.002888   Batch Acc: 85.16
[Train] Epoch: 0 [142336/387873]    Loss: 0.003226   Batch Acc: 80.47
[Train] Epoch: 0 [142464/387873]    Loss: 0.002885   Batch Acc: 81.25
[Train] Epoch: 0 [142592/387873]    Loss: 0.002973   Batch Acc: 85.16
[Train] Epoch: 0 [142720/387873]    Loss: 0.002498   Batch Acc: 87.50
[Train] Epoch: 0 [142848/387873]    Loss: 0.002464   Batch Acc: 87.50
[Train] Epoch: 0 [142976/387873]    Loss: 0.002555   Batch Acc: 86.72
[Train] Epoch: 0 [143104/387873]    Loss: 0.002216   Batch Acc: 91.41
[Train] Epoch: 0 [143232/387873]    Loss: 0.002624   Batch Acc: 85.94
[Train] Epoch: 0 [143360/387873]    Loss: 0.002829   Batch Acc: 84.38
[Train] Epoch: 0 [143488/387873]    Loss: 0.002443   Batch Acc: 87.50
[Train] Epoch: 0 [143616/387873]    Loss: 0.003291   Batch Acc: 80.47
[Train] Epoch: 0 [143744/387873]    Loss: 0.002578   Batch Acc: 87.50
[Train] Epoch: 0 [143872/387873]    Loss: 0.002640   Batch Acc: 85.94
[Train] Epoch: 0 [144000/387873]    Loss: 0.002150   Batch Acc: 89.84
[Train] Epoch: 0 [144128/387873]    Loss: 0.002494   Batch Acc: 85.94
[Train] Epoch: 0 [144256/387873]    Loss: 0.002466   Batch Acc: 85.94
[Train] Epoch: 0 [144384/387873]    Loss: 0.002746   Batch Acc: 85.94
[Train] Epoch: 0 [144512/387873]    Loss: 0.002498   Batch Acc: 88.28
[Train] Epoch: 0 [144640/387873]    Loss: 0.002286   Batch Acc: 89.06
[Train] Epoch: 0 [144768/387873]    Loss: 0.002709   Batch Acc: 85.16
[Train] Epoch: 0 [144896/387873]    Loss: 0.002147   Batch Acc: 88.28
[Train] Epoch: 0 [145024/387873]    Loss: 0.002154   Batch Acc: 91.41
[Train] Epoch: 0 [145152/387873]    Loss: 0.002825   Batch Acc: 80.47
[Train] Epoch: 0 [145280/387873]    Loss: 0.002229   Batch Acc: 89.06
[Train] Epoch: 0 [145408/387873]    Loss: 0.002486   Batch Acc: 87.50
[Train] Epoch: 0 [145536/387873]    Loss: 0.002883   Batch Acc: 85.94
[Train] Epoch: 0 [145664/387873]    Loss: 0.002898   Batch Acc: 85.16
[Train] Epoch: 0 [145792/387873]    Loss: 0.002286   Batch Acc: 85.16
[Train] Epoch: 0 [145920/387873]    Loss: 0.002845   Batch Acc: 85.94
[Train] Epoch: 0 [146048/387873]    Loss: 0.002649   Batch Acc: 85.94
[Train] Epoch: 0 [146176/387873]    Loss: 0.003460   Batch Acc: 79.69
[Train] Epoch: 0 [146304/387873]    Loss: 0.002445   Batch Acc: 87.50
[Train] Epoch: 0 [146432/387873]    Loss: 0.002707   Batch Acc: 85.16
[Train] Epoch: 0 [146560/387873]    Loss: 0.002659   Batch Acc: 85.16
[Train] Epoch: 0 [146688/387873]    Loss: 0.002429   Batch Acc: 87.50
[Train] Epoch: 0 [146816/387873]    Loss: 0.002429   Batch Acc: 85.94
[Train] Epoch: 0 [146944/387873]    Loss: 0.002724   Batch Acc: 82.03
[Train] Epoch: 0 [147072/387873]    Loss: 0.002711   Batch Acc: 84.38
[Train] Epoch: 0 [147200/387873]    Loss: 0.002371   Batch Acc: 88.28
[Train] Epoch: 0 [147328/387873]    Loss: 0.002896   Batch Acc: 81.25
[Train] Epoch: 0 [147456/387873]    Loss: 0.002148   Batch Acc: 89.84
[Train] Epoch: 0 [147584/387873]    Loss: 0.002377   Batch Acc: 86.72
[Train] Epoch: 0 [147712/387873]    Loss: 0.002568   Batch Acc: 85.94
[Train] Epoch: 0 [147840/387873]    Loss: 0.002953   Batch Acc: 82.03
[Train] Epoch: 0 [147968/387873]    Loss: 0.002885   Batch Acc: 80.47
[Train] Epoch: 0 [148096/387873]    Loss: 0.002201   Batch Acc: 91.41
[Train] Epoch: 0 [148224/387873]    Loss: 0.002617   Batch Acc: 81.25
[Train] Epoch: 0 [148352/387873]    Loss: 0.002466   Batch Acc: 89.06
[Train] Epoch: 0 [148480/387873]    Loss: 0.002984   Batch Acc: 82.81
[Train] Epoch: 0 [148608/387873]    Loss: 0.002310   Batch Acc: 86.72
[Train] Epoch: 0 [148736/387873]    Loss: 0.003558   Batch Acc: 81.25
[Train] Epoch: 0 [148864/387873]    Loss: 0.002338   Batch Acc: 89.84
[Train] Epoch: 0 [148992/387873]    Loss: 0.002545   Batch Acc: 83.59
[Train] Epoch: 0 [149120/387873]    Loss: 0.002336   Batch Acc: 87.50
[Train] Epoch: 0 [149248/387873]    Loss: 0.002552   Batch Acc: 85.94
[Train] Epoch: 0 [149376/387873]    Loss: 0.003014   Batch Acc: 84.38
[Train] Epoch: 0 [149504/387873]    Loss: 0.002525   Batch Acc: 89.84
[Train] Epoch: 0 [149632/387873]    Loss: 0.002740   Batch Acc: 86.72
[Train] Epoch: 0 [149760/387873]    Loss: 0.002439   Batch Acc: 87.50
[Train] Epoch: 0 [149888/387873]    Loss: 0.002290   Batch Acc: 86.72
[Train] Epoch: 0 [150016/387873]    Loss: 0.002020   Batch Acc: 92.97
[Train] Epoch: 0 [150144/387873]    Loss: 0.002698   Batch Acc: 83.59
[Train] Epoch: 0 [150272/387873]    Loss: 0.002581   Batch Acc: 86.72
[Train] Epoch: 0 [150400/387873]    Loss: 0.002398   Batch Acc: 89.84
[Train] Epoch: 0 [150528/387873]    Loss: 0.002741   Batch Acc: 88.28
[Train] Epoch: 0 [150656/387873]    Loss: 0.002354   Batch Acc: 88.28
[Train] Epoch: 0 [150784/387873]    Loss: 0.002506   Batch Acc: 89.06
[Train] Epoch: 0 [150912/387873]    Loss: 0.002049   Batch Acc: 91.41
[Train] Epoch: 0 [151040/387873]    Loss: 0.002496   Batch Acc: 86.72
[Train] Epoch: 0 [151168/387873]    Loss: 0.002690   Batch Acc: 82.81
[Train] Epoch: 0 [151296/387873]    Loss: 0.003131   Batch Acc: 81.25
[Train] Epoch: 0 [151424/387873]    Loss: 0.002583   Batch Acc: 87.50
[Train] Epoch: 0 [151552/387873]    Loss: 0.002324   Batch Acc: 89.06
[Train] Epoch: 0 [151680/387873]    Loss: 0.002384   Batch Acc: 87.50
[Train] Epoch: 0 [151808/387873]    Loss: 0.003110   Batch Acc: 80.47
[Train] Epoch: 0 [151936/387873]    Loss: 0.003362   Batch Acc: 82.81
[Train] Epoch: 0 [152064/387873]    Loss: 0.002245   Batch Acc: 89.84
[Train] Epoch: 0 [152192/387873]    Loss: 0.002474   Batch Acc: 89.06
[Train] Epoch: 0 [152320/387873]    Loss: 0.002979   Batch Acc: 81.25
[Train] Epoch: 0 [152448/387873]    Loss: 0.002399   Batch Acc: 84.38
[Train] Epoch: 0 [152576/387873]    Loss: 0.003483   Batch Acc: 81.25
[Train] Epoch: 0 [152704/387873]    Loss: 0.002589   Batch Acc: 88.28
[Train] Epoch: 0 [152832/387873]    Loss: 0.002802   Batch Acc: 82.81
[Train] Epoch: 0 [152960/387873]    Loss: 0.002266   Batch Acc: 89.06
[Train] Epoch: 0 [153088/387873]    Loss: 0.002641   Batch Acc: 85.94
[Train] Epoch: 0 [153216/387873]    Loss: 0.002533   Batch Acc: 88.28
[Train] Epoch: 0 [153344/387873]    Loss: 0.002775   Batch Acc: 84.38
[Train] Epoch: 0 [153472/387873]    Loss: 0.002491   Batch Acc: 85.16
[Train] Epoch: 0 [153600/387873]    Loss: 0.002398   Batch Acc: 89.84
[Train] Epoch: 0 [153728/387873]    Loss: 0.003696   Batch Acc: 74.22
[Train] Epoch: 0 [153856/387873]    Loss: 0.002351   Batch Acc: 89.84
[Train] Epoch: 0 [153984/387873]    Loss: 0.003362   Batch Acc: 80.47
[Train] Epoch: 0 [154112/387873]    Loss: 0.002121   Batch Acc: 89.84
[Train] Epoch: 0 [154240/387873]    Loss: 0.002318   Batch Acc: 89.84
[Train] Epoch: 0 [154368/387873]    Loss: 0.002330   Batch Acc: 89.84
[Train] Epoch: 0 [154496/387873]    Loss: 0.002493   Batch Acc: 83.59
[Train] Epoch: 0 [154624/387873]    Loss: 0.002682   Batch Acc: 84.38
[Train] Epoch: 0 [154752/387873]    Loss: 0.001890   Batch Acc: 91.41
[Train] Epoch: 0 [154880/387873]    Loss: 0.002203   Batch Acc: 91.41
[Train] Epoch: 0 [155008/387873]    Loss: 0.002401   Batch Acc: 87.50
[Train] Epoch: 0 [155136/387873]    Loss: 0.002414   Batch Acc: 85.94
[Train] Epoch: 0 [155264/387873]    Loss: 0.002828   Batch Acc: 83.59
[Train] Epoch: 0 [155392/387873]    Loss: 0.002669   Batch Acc: 85.16
[Train] Epoch: 0 [155520/387873]    Loss: 0.002696   Batch Acc: 85.94
[Train] Epoch: 0 [155648/387873]    Loss: 0.002166   Batch Acc: 89.06
[Train] Epoch: 0 [155776/387873]    Loss: 0.002969   Batch Acc: 83.59
[Train] Epoch: 0 [155904/387873]    Loss: 0.002693   Batch Acc: 83.59
[Train] Epoch: 0 [156032/387873]    Loss: 0.002499   Batch Acc: 87.50
[Train] Epoch: 0 [156160/387873]    Loss: 0.002456   Batch Acc: 88.28
[Train] Epoch: 0 [156288/387873]    Loss: 0.002281   Batch Acc: 90.62
[Train] Epoch: 0 [156416/387873]    Loss: 0.002631   Batch Acc: 89.84
[Train] Epoch: 0 [156544/387873]    Loss: 0.002280   Batch Acc: 88.28
[Train] Epoch: 0 [156672/387873]    Loss: 0.002413   Batch Acc: 85.94
[Train] Epoch: 0 [156800/387873]    Loss: 0.002669   Batch Acc: 84.38
[Train] Epoch: 0 [156928/387873]    Loss: 0.002403   Batch Acc: 86.72
[Train] Epoch: 0 [157056/387873]    Loss: 0.002562   Batch Acc: 85.16
[Train] Epoch: 0 [157184/387873]    Loss: 0.002319   Batch Acc: 89.84
[Train] Epoch: 0 [157312/387873]    Loss: 0.003014   Batch Acc: 82.03
[Train] Epoch: 0 [157440/387873]    Loss: 0.002214   Batch Acc: 87.50
[Train] Epoch: 0 [157568/387873]    Loss: 0.002333   Batch Acc: 88.28
[Train] Epoch: 0 [157696/387873]    Loss: 0.002364   Batch Acc: 88.28
[Train] Epoch: 0 [157824/387873]    Loss: 0.002788   Batch Acc: 86.72
[Train] Epoch: 0 [157952/387873]    Loss: 0.003081   Batch Acc: 81.25
[Train] Epoch: 0 [158080/387873]    Loss: 0.002410   Batch Acc: 86.72
[Train] Epoch: 0 [158208/387873]    Loss: 0.002752   Batch Acc: 81.25
[Train] Epoch: 0 [158336/387873]    Loss: 0.002146   Batch Acc: 92.97
[Train] Epoch: 0 [158464/387873]    Loss: 0.002581   Batch Acc: 86.72
[Train] Epoch: 0 [158592/387873]    Loss: 0.002717   Batch Acc: 86.72
[Train] Epoch: 0 [158720/387873]    Loss: 0.002266   Batch Acc: 87.50
[Train] Epoch: 0 [158848/387873]    Loss: 0.002774   Batch Acc: 82.03
[Train] Epoch: 0 [158976/387873]    Loss: 0.002347   Batch Acc: 89.06
[Train] Epoch: 0 [159104/387873]    Loss: 0.002252   Batch Acc: 87.50
[Train] Epoch: 0 [159232/387873]    Loss: 0.002096   Batch Acc: 92.19
[Train] Epoch: 0 [159360/387873]    Loss: 0.001980   Batch Acc: 89.84
[Train] Epoch: 0 [159488/387873]    Loss: 0.003040   Batch Acc: 81.25
[Train] Epoch: 0 [159616/387873]    Loss: 0.002427   Batch Acc: 86.72
[Train] Epoch: 0 [159744/387873]    Loss: 0.002492   Batch Acc: 86.72
[Train] Epoch: 0 [159872/387873]    Loss: 0.002462   Batch Acc: 87.50
[Train] Epoch: 0 [160000/387873]    Loss: 0.002511   Batch Acc: 85.16
[Train] Epoch: 0 [160128/387873]    Loss: 0.003594   Batch Acc: 77.34
[Train] Epoch: 0 [160256/387873]    Loss: 0.002160   Batch Acc: 89.84
[Train] Epoch: 0 [160384/387873]    Loss: 0.002572   Batch Acc: 88.28
[Train] Epoch: 0 [160512/387873]    Loss: 0.002588   Batch Acc: 87.50
[Train] Epoch: 0 [160640/387873]    Loss: 0.002584   Batch Acc: 85.16
[Train] Epoch: 0 [160768/387873]    Loss: 0.002658   Batch Acc: 86.72
[Train] Epoch: 0 [160896/387873]    Loss: 0.002246   Batch Acc: 87.50
[Train] Epoch: 0 [161024/387873]    Loss: 0.002889   Batch Acc: 81.25
[Train] Epoch: 0 [161152/387873]    Loss: 0.002431   Batch Acc: 87.50
[Train] Epoch: 0 [161280/387873]    Loss: 0.002526   Batch Acc: 88.28
[Train] Epoch: 0 [161408/387873]    Loss: 0.003306   Batch Acc: 82.81
[Train] Epoch: 0 [161536/387873]    Loss: 0.002334   Batch Acc: 87.50
[Train] Epoch: 0 [161664/387873]    Loss: 0.002592   Batch Acc: 87.50
[Train] Epoch: 0 [161792/387873]    Loss: 0.002494   Batch Acc: 83.59
[Train] Epoch: 0 [161920/387873]    Loss: 0.002856   Batch Acc: 82.03
[Train] Epoch: 0 [162048/387873]    Loss: 0.002604   Batch Acc: 82.81
[Train] Epoch: 0 [162176/387873]    Loss: 0.002680   Batch Acc: 87.50
[Train] Epoch: 0 [162304/387873]    Loss: 0.002431   Batch Acc: 90.62
[Train] Epoch: 0 [162432/387873]    Loss: 0.002364   Batch Acc: 87.50
[Train] Epoch: 0 [162560/387873]    Loss: 0.002539   Batch Acc: 82.81
[Train] Epoch: 0 [162688/387873]    Loss: 0.002389   Batch Acc: 88.28
[Train] Epoch: 0 [162816/387873]    Loss: 0.002588   Batch Acc: 85.94
[Train] Epoch: 0 [162944/387873]    Loss: 0.002664   Batch Acc: 80.47
[Train] Epoch: 0 [163072/387873]    Loss: 0.002300   Batch Acc: 87.50
[Train] Epoch: 0 [163200/387873]    Loss: 0.003085   Batch Acc: 82.03
[Train] Epoch: 0 [163328/387873]    Loss: 0.002368   Batch Acc: 88.28
[Train] Epoch: 0 [163456/387873]    Loss: 0.002316   Batch Acc: 89.06
[Train] Epoch: 0 [163584/387873]    Loss: 0.002263   Batch Acc: 89.84
[Train] Epoch: 0 [163712/387873]    Loss: 0.002897   Batch Acc: 84.38
[Train] Epoch: 0 [163840/387873]    Loss: 0.002693   Batch Acc: 85.94
[Train] Epoch: 0 [163968/387873]    Loss: 0.002500   Batch Acc: 84.38
[Train] Epoch: 0 [164096/387873]    Loss: 0.002483   Batch Acc: 85.16
[Train] Epoch: 0 [164224/387873]    Loss: 0.002619   Batch Acc: 85.16
[Train] Epoch: 0 [164352/387873]    Loss: 0.002141   Batch Acc: 88.28
[Train] Epoch: 0 [164480/387873]    Loss: 0.002739   Batch Acc: 83.59
[Train] Epoch: 0 [164608/387873]    Loss: 0.002658   Batch Acc: 84.38
[Train] Epoch: 0 [164736/387873]    Loss: 0.002383   Batch Acc: 86.72
[Train] Epoch: 0 [164864/387873]    Loss: 0.002177   Batch Acc: 86.72
[Train] Epoch: 0 [164992/387873]    Loss: 0.002502   Batch Acc: 84.38
[Train] Epoch: 0 [165120/387873]    Loss: 0.002320   Batch Acc: 89.06
[Train] Epoch: 0 [165248/387873]    Loss: 0.002618   Batch Acc: 88.28
[Train] Epoch: 0 [165376/387873]    Loss: 0.002911   Batch Acc: 81.25
[Train] Epoch: 0 [165504/387873]    Loss: 0.002772   Batch Acc: 82.03
[Train] Epoch: 0 [165632/387873]    Loss: 0.002237   Batch Acc: 90.62
[Train] Epoch: 0 [165760/387873]    Loss: 0.002416   Batch Acc: 89.06
[Train] Epoch: 0 [165888/387873]    Loss: 0.001790   Batch Acc: 92.97
[Train] Epoch: 0 [166016/387873]    Loss: 0.002128   Batch Acc: 89.84
[Train] Epoch: 0 [166144/387873]    Loss: 0.002811   Batch Acc: 83.59
[Train] Epoch: 0 [166272/387873]    Loss: 0.002993   Batch Acc: 82.81
[Train] Epoch: 0 [166400/387873]    Loss: 0.002411   Batch Acc: 86.72
[Train] Epoch: 0 [166528/387873]    Loss: 0.002325   Batch Acc: 87.50
[Train] Epoch: 0 [166656/387873]    Loss: 0.002780   Batch Acc: 82.81
[Train] Epoch: 0 [166784/387873]    Loss: 0.002556   Batch Acc: 86.72
[Train] Epoch: 0 [166912/387873]    Loss: 0.002279   Batch Acc: 89.84
[Train] Epoch: 0 [167040/387873]    Loss: 0.002723   Batch Acc: 85.94
[Train] Epoch: 0 [167168/387873]    Loss: 0.002296   Batch Acc: 87.50
[Train] Epoch: 0 [167296/387873]    Loss: 0.002959   Batch Acc: 83.59
[Train] Epoch: 0 [167424/387873]    Loss: 0.002467   Batch Acc: 85.16
[Train] Epoch: 0 [167552/387873]    Loss: 0.002579   Batch Acc: 86.72
[Train] Epoch: 0 [167680/387873]    Loss: 0.002533   Batch Acc: 86.72
[Train] Epoch: 0 [167808/387873]    Loss: 0.002359   Batch Acc: 85.94
[Train] Epoch: 0 [167936/387873]    Loss: 0.002667   Batch Acc: 85.16
[Train] Epoch: 0 [168064/387873]    Loss: 0.002535   Batch Acc: 82.03
[Train] Epoch: 0 [168192/387873]    Loss: 0.002368   Batch Acc: 87.50
[Train] Epoch: 0 [168320/387873]    Loss: 0.002514   Batch Acc: 89.06
[Train] Epoch: 0 [168448/387873]    Loss: 0.002871   Batch Acc: 85.16
[Train] Epoch: 0 [168576/387873]    Loss: 0.002404   Batch Acc: 87.50
[Train] Epoch: 0 [168704/387873]    Loss: 0.002330   Batch Acc: 89.06
[Train] Epoch: 0 [168832/387873]    Loss: 0.002369   Batch Acc: 88.28
[Train] Epoch: 0 [168960/387873]    Loss: 0.001734   Batch Acc: 96.09
[Train] Epoch: 0 [169088/387873]    Loss: 0.002651   Batch Acc: 85.94
[Train] Epoch: 0 [169216/387873]    Loss: 0.002405   Batch Acc: 88.28
[Train] Epoch: 0 [169344/387873]    Loss: 0.002231   Batch Acc: 86.72
[Train] Epoch: 0 [169472/387873]    Loss: 0.002457   Batch Acc: 85.94
[Train] Epoch: 0 [169600/387873]    Loss: 0.002502   Batch Acc: 88.28
[Train] Epoch: 0 [169728/387873]    Loss: 0.002448   Batch Acc: 85.94
[Train] Epoch: 0 [169856/387873]    Loss: 0.002470   Batch Acc: 85.94
[Train] Epoch: 0 [169984/387873]    Loss: 0.002036   Batch Acc: 92.19
[Train] Epoch: 0 [170112/387873]    Loss: 0.002301   Batch Acc: 85.94
[Train] Epoch: 0 [170240/387873]    Loss: 0.002422   Batch Acc: 88.28
[Train] Epoch: 0 [170368/387873]    Loss: 0.002432   Batch Acc: 87.50
[Train] Epoch: 0 [170496/387873]    Loss: 0.002858   Batch Acc: 84.38
[Train] Epoch: 0 [170624/387873]    Loss: 0.002301   Batch Acc: 85.16
[Train] Epoch: 0 [170752/387873]    Loss: 0.002285   Batch Acc: 89.06
[Train] Epoch: 0 [170880/387873]    Loss: 0.002775   Batch Acc: 82.03
[Train] Epoch: 0 [171008/387873]    Loss: 0.002503   Batch Acc: 84.38
[Train] Epoch: 0 [171136/387873]    Loss: 0.002750   Batch Acc: 85.16
[Train] Epoch: 0 [171264/387873]    Loss: 0.002541   Batch Acc: 87.50
[Train] Epoch: 0 [171392/387873]    Loss: 0.002003   Batch Acc: 86.72
[Train] Epoch: 0 [171520/387873]    Loss: 0.002342   Batch Acc: 87.50
[Train] Epoch: 0 [171648/387873]    Loss: 0.002446   Batch Acc: 87.50
[Train] Epoch: 0 [171776/387873]    Loss: 0.002272   Batch Acc: 85.94
[Train] Epoch: 0 [171904/387873]    Loss: 0.002621   Batch Acc: 87.50
[Train] Epoch: 0 [172032/387873]    Loss: 0.002636   Batch Acc: 89.84
[Train] Epoch: 0 [172160/387873]    Loss: 0.002871   Batch Acc: 84.38
[Train] Epoch: 0 [172288/387873]    Loss: 0.002554   Batch Acc: 81.25
[Train] Epoch: 0 [172416/387873]    Loss: 0.002190   Batch Acc: 89.84
[Train] Epoch: 0 [172544/387873]    Loss: 0.003233   Batch Acc: 80.47
[Train] Epoch: 0 [172672/387873]    Loss: 0.002464   Batch Acc: 86.72
[Train] Epoch: 0 [172800/387873]    Loss: 0.002041   Batch Acc: 88.28
[Train] Epoch: 0 [172928/387873]    Loss: 0.003164   Batch Acc: 83.59
[Train] Epoch: 0 [173056/387873]    Loss: 0.002465   Batch Acc: 88.28
[Train] Epoch: 0 [173184/387873]    Loss: 0.002784   Batch Acc: 86.72
[Train] Epoch: 0 [173312/387873]    Loss: 0.002259   Batch Acc: 92.19
[Train] Epoch: 0 [173440/387873]    Loss: 0.002334   Batch Acc: 87.50
[Train] Epoch: 0 [173568/387873]    Loss: 0.002321   Batch Acc: 88.28
[Train] Epoch: 0 [173696/387873]    Loss: 0.002622   Batch Acc: 85.16
[Train] Epoch: 0 [173824/387873]    Loss: 0.002743   Batch Acc: 82.81
[Train] Epoch: 0 [173952/387873]    Loss: 0.002491   Batch Acc: 84.38
[Train] Epoch: 0 [174080/387873]    Loss: 0.002940   Batch Acc: 85.16
[Train] Epoch: 0 [174208/387873]    Loss: 0.002508   Batch Acc: 88.28
[Train] Epoch: 0 [174336/387873]    Loss: 0.002476   Batch Acc: 85.16
[Train] Epoch: 0 [174464/387873]    Loss: 0.002615   Batch Acc: 85.16
[Train] Epoch: 0 [174592/387873]    Loss: 0.002100   Batch Acc: 92.19
[Train] Epoch: 0 [174720/387873]    Loss: 0.003002   Batch Acc: 81.25
[Train] Epoch: 0 [174848/387873]    Loss: 0.002836   Batch Acc: 83.59
[Train] Epoch: 0 [174976/387873]    Loss: 0.002777   Batch Acc: 85.94
[Train] Epoch: 0 [175104/387873]    Loss: 0.002608   Batch Acc: 88.28
[Train] Epoch: 0 [175232/387873]    Loss: 0.002734   Batch Acc: 84.38
[Train] Epoch: 0 [175360/387873]    Loss: 0.002424   Batch Acc: 87.50
[Train] Epoch: 0 [175488/387873]    Loss: 0.002806   Batch Acc: 82.81
[Train] Epoch: 0 [175616/387873]    Loss: 0.002520   Batch Acc: 86.72
[Train] Epoch: 0 [175744/387873]    Loss: 0.002877   Batch Acc: 86.72
[Train] Epoch: 0 [175872/387873]    Loss: 0.002414   Batch Acc: 88.28
[Train] Epoch: 0 [176000/387873]    Loss: 0.002218   Batch Acc: 89.06
[Train] Epoch: 0 [176128/387873]    Loss: 0.002177   Batch Acc: 89.06
[Train] Epoch: 0 [176256/387873]    Loss: 0.002553   Batch Acc: 85.94
[Train] Epoch: 0 [176384/387873]    Loss: 0.002311   Batch Acc: 87.50
[Train] Epoch: 0 [176512/387873]    Loss: 0.002292   Batch Acc: 87.50
[Train] Epoch: 0 [176640/387873]    Loss: 0.002787   Batch Acc: 83.59
[Train] Epoch: 0 [176768/387873]    Loss: 0.002985   Batch Acc: 79.69
[Train] Epoch: 0 [176896/387873]    Loss: 0.002432   Batch Acc: 85.16
[Train] Epoch: 0 [177024/387873]    Loss: 0.002333   Batch Acc: 86.72
[Train] Epoch: 0 [177152/387873]    Loss: 0.002853   Batch Acc: 82.81
[Train] Epoch: 0 [177280/387873]    Loss: 0.002173   Batch Acc: 90.62
[Train] Epoch: 0 [177408/387873]    Loss: 0.002991   Batch Acc: 80.47
[Train] Epoch: 0 [177536/387873]    Loss: 0.002095   Batch Acc: 89.84
[Train] Epoch: 0 [177664/387873]    Loss: 0.002183   Batch Acc: 88.28
[Train] Epoch: 0 [177792/387873]    Loss: 0.002543   Batch Acc: 85.94
[Train] Epoch: 0 [177920/387873]    Loss: 0.002527   Batch Acc: 88.28
[Train] Epoch: 0 [178048/387873]    Loss: 0.002304   Batch Acc: 88.28
[Train] Epoch: 0 [178176/387873]    Loss: 0.002434   Batch Acc: 89.06
[Train] Epoch: 0 [178304/387873]    Loss: 0.003012   Batch Acc: 83.59
[Train] Epoch: 0 [178432/387873]    Loss: 0.002699   Batch Acc: 80.47
[Train] Epoch: 0 [178560/387873]    Loss: 0.002377   Batch Acc: 86.72
[Train] Epoch: 0 [178688/387873]    Loss: 0.002099   Batch Acc: 89.84
[Train] Epoch: 0 [178816/387873]    Loss: 0.002467   Batch Acc: 89.06
[Train] Epoch: 0 [178944/387873]    Loss: 0.002394   Batch Acc: 85.16
[Train] Epoch: 0 [179072/387873]    Loss: 0.003004   Batch Acc: 78.12
[Train] Epoch: 0 [179200/387873]    Loss: 0.002390   Batch Acc: 87.50
[Train] Epoch: 0 [179328/387873]    Loss: 0.002157   Batch Acc: 88.28
[Train] Epoch: 0 [179456/387873]    Loss: 0.002401   Batch Acc: 89.84
[Train] Epoch: 0 [179584/387873]    Loss: 0.003107   Batch Acc: 80.47
[Train] Epoch: 0 [179712/387873]    Loss: 0.002250   Batch Acc: 89.84
[Train] Epoch: 0 [179840/387873]    Loss: 0.002583   Batch Acc: 84.38
[Train] Epoch: 0 [179968/387873]    Loss: 0.002284   Batch Acc: 89.84
[Train] Epoch: 0 [180096/387873]    Loss: 0.002608   Batch Acc: 89.06
[Train] Epoch: 0 [180224/387873]    Loss: 0.001893   Batch Acc: 91.41
[Train] Epoch: 0 [180352/387873]    Loss: 0.002188   Batch Acc: 86.72
[Train] Epoch: 0 [180480/387873]    Loss: 0.002661   Batch Acc: 85.94
[Train] Epoch: 0 [180608/387873]    Loss: 0.002757   Batch Acc: 81.25
[Train] Epoch: 0 [180736/387873]    Loss: 0.002207   Batch Acc: 87.50
[Train] Epoch: 0 [180864/387873]    Loss: 0.001980   Batch Acc: 90.62
[Train] Epoch: 0 [180992/387873]    Loss: 0.002640   Batch Acc: 81.25
[Train] Epoch: 0 [181120/387873]    Loss: 0.002451   Batch Acc: 85.94
[Train] Epoch: 0 [181248/387873]    Loss: 0.002965   Batch Acc: 85.16
[Train] Epoch: 0 [181376/387873]    Loss: 0.002740   Batch Acc: 85.94
[Train] Epoch: 0 [181504/387873]    Loss: 0.003042   Batch Acc: 82.03
[Train] Epoch: 0 [181632/387873]    Loss: 0.003380   Batch Acc: 81.25
[Train] Epoch: 0 [181760/387873]    Loss: 0.003299   Batch Acc: 81.25
[Train] Epoch: 0 [181888/387873]    Loss: 0.002268   Batch Acc: 89.06
[Train] Epoch: 0 [182016/387873]    Loss: 0.002579   Batch Acc: 85.16
[Train] Epoch: 0 [182144/387873]    Loss: 0.002704   Batch Acc: 85.16
[Train] Epoch: 0 [182272/387873]    Loss: 0.002756   Batch Acc: 84.38
[Train] Epoch: 0 [182400/387873]    Loss: 0.001993   Batch Acc: 89.84
[Train] Epoch: 0 [182528/387873]    Loss: 0.002175   Batch Acc: 87.50
[Train] Epoch: 0 [182656/387873]    Loss: 0.002268   Batch Acc: 89.06
[Train] Epoch: 0 [182784/387873]    Loss: 0.002695   Batch Acc: 82.03
[Train] Epoch: 0 [182912/387873]    Loss: 0.002739   Batch Acc: 84.38
[Train] Epoch: 0 [183040/387873]    Loss: 0.002464   Batch Acc: 83.59
[Train] Epoch: 0 [183168/387873]    Loss: 0.002359   Batch Acc: 86.72
[Train] Epoch: 0 [183296/387873]    Loss: 0.002372   Batch Acc: 87.50
[Train] Epoch: 0 [183424/387873]    Loss: 0.002426   Batch Acc: 86.72
[Train] Epoch: 0 [183552/387873]    Loss: 0.002597   Batch Acc: 87.50
[Train] Epoch: 0 [183680/387873]    Loss: 0.003142   Batch Acc: 78.91
[Train] Epoch: 0 [183808/387873]    Loss: 0.002645   Batch Acc: 85.94
[Train] Epoch: 0 [183936/387873]    Loss: 0.002661   Batch Acc: 86.72
[Train] Epoch: 0 [184064/387873]    Loss: 0.002763   Batch Acc: 81.25
[Train] Epoch: 0 [184192/387873]    Loss: 0.002591   Batch Acc: 87.50
[Train] Epoch: 0 [184320/387873]    Loss: 0.002537   Batch Acc: 85.94
[Train] Epoch: 0 [184448/387873]    Loss: 0.002427   Batch Acc: 83.59
[Train] Epoch: 0 [184576/387873]    Loss: 0.002378   Batch Acc: 89.84
[Train] Epoch: 0 [184704/387873]    Loss: 0.002714   Batch Acc: 86.72
[Train] Epoch: 0 [184832/387873]    Loss: 0.001946   Batch Acc: 95.31
[Train] Epoch: 0 [184960/387873]    Loss: 0.002562   Batch Acc: 84.38
[Train] Epoch: 0 [185088/387873]    Loss: 0.002539   Batch Acc: 87.50
[Train] Epoch: 0 [185216/387873]    Loss: 0.002098   Batch Acc: 89.06
[Train] Epoch: 0 [185344/387873]    Loss: 0.002468   Batch Acc: 88.28
[Train] Epoch: 0 [185472/387873]    Loss: 0.002207   Batch Acc: 89.84
[Train] Epoch: 0 [185600/387873]    Loss: 0.002603   Batch Acc: 86.72
[Train] Epoch: 0 [185728/387873]    Loss: 0.002580   Batch Acc: 85.94
[Train] Epoch: 0 [185856/387873]    Loss: 0.002713   Batch Acc: 82.03
[Train] Epoch: 0 [185984/387873]    Loss: 0.002531   Batch Acc: 90.62
[Train] Epoch: 0 [186112/387873]    Loss: 0.003343   Batch Acc: 78.91
[Train] Epoch: 0 [186240/387873]    Loss: 0.002520   Batch Acc: 86.72
[Train] Epoch: 0 [186368/387873]    Loss: 0.002654   Batch Acc: 82.03
[Train] Epoch: 0 [186496/387873]    Loss: 0.002519   Batch Acc: 84.38
[Train] Epoch: 0 [186624/387873]    Loss: 0.002922   Batch Acc: 86.72
[Train] Epoch: 0 [186752/387873]    Loss: 0.002672   Batch Acc: 86.72
[Train] Epoch: 0 [186880/387873]    Loss: 0.002625   Batch Acc: 85.16
[Train] Epoch: 0 [187008/387873]    Loss: 0.002095   Batch Acc: 87.50
[Train] Epoch: 0 [187136/387873]    Loss: 0.002881   Batch Acc: 80.47
[Train] Epoch: 0 [187264/387873]    Loss: 0.002800   Batch Acc: 83.59
[Train] Epoch: 0 [187392/387873]    Loss: 0.002115   Batch Acc: 91.41
[Train] Epoch: 0 [187520/387873]    Loss: 0.002266   Batch Acc: 88.28
[Train] Epoch: 0 [187648/387873]    Loss: 0.002254   Batch Acc: 90.62
[Train] Epoch: 0 [187776/387873]    Loss: 0.002279   Batch Acc: 91.41
[Train] Epoch: 0 [187904/387873]    Loss: 0.002171   Batch Acc: 88.28
[Train] Epoch: 0 [188032/387873]    Loss: 0.002334   Batch Acc: 88.28
[Train] Epoch: 0 [188160/387873]    Loss: 0.002330   Batch Acc: 92.19
[Train] Epoch: 0 [188288/387873]    Loss: 0.002084   Batch Acc: 87.50
[Train] Epoch: 0 [188416/387873]    Loss: 0.002674   Batch Acc: 83.59
[Train] Epoch: 0 [188544/387873]    Loss: 0.002359   Batch Acc: 87.50
[Train] Epoch: 0 [188672/387873]    Loss: 0.002353   Batch Acc: 87.50
[Train] Epoch: 0 [188800/387873]    Loss: 0.002681   Batch Acc: 83.59
[Train] Epoch: 0 [188928/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 0 [189056/387873]    Loss: 0.003041   Batch Acc: 82.03
[Train] Epoch: 0 [189184/387873]    Loss: 0.002294   Batch Acc: 85.94
[Train] Epoch: 0 [189312/387873]    Loss: 0.001836   Batch Acc: 92.97
[Train] Epoch: 0 [189440/387873]    Loss: 0.002140   Batch Acc: 90.62
[Train] Epoch: 0 [189568/387873]    Loss: 0.002639   Batch Acc: 88.28
[Train] Epoch: 0 [189696/387873]    Loss: 0.002365   Batch Acc: 84.38
[Train] Epoch: 0 [189824/387873]    Loss: 0.002364   Batch Acc: 91.41
[Train] Epoch: 0 [189952/387873]    Loss: 0.002095   Batch Acc: 90.62
[Train] Epoch: 0 [190080/387873]    Loss: 0.002660   Batch Acc: 83.59
[Train] Epoch: 0 [190208/387873]    Loss: 0.002415   Batch Acc: 87.50
[Train] Epoch: 0 [190336/387873]    Loss: 0.002955   Batch Acc: 80.47
[Train] Epoch: 0 [190464/387873]    Loss: 0.002996   Batch Acc: 82.81
[Train] Epoch: 0 [190592/387873]    Loss: 0.002550   Batch Acc: 86.72
[Train] Epoch: 0 [190720/387873]    Loss: 0.002683   Batch Acc: 85.16
[Train] Epoch: 0 [190848/387873]    Loss: 0.002048   Batch Acc: 92.97
[Train] Epoch: 0 [190976/387873]    Loss: 0.002473   Batch Acc: 86.72
[Train] Epoch: 0 [191104/387873]    Loss: 0.002817   Batch Acc: 82.81
[Train] Epoch: 0 [191232/387873]    Loss: 0.002994   Batch Acc: 85.16
[Train] Epoch: 0 [191360/387873]    Loss: 0.002565   Batch Acc: 88.28
[Train] Epoch: 0 [191488/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 0 [191616/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 0 [191744/387873]    Loss: 0.002569   Batch Acc: 85.94
[Train] Epoch: 0 [191872/387873]    Loss: 0.001973   Batch Acc: 92.19
[Train] Epoch: 0 [192000/387873]    Loss: 0.002914   Batch Acc: 83.59
[Train] Epoch: 0 [192128/387873]    Loss: 0.002307   Batch Acc: 89.06
[Train] Epoch: 0 [192256/387873]    Loss: 0.002389   Batch Acc: 88.28
[Train] Epoch: 0 [192384/387873]    Loss: 0.002509   Batch Acc: 85.94
[Train] Epoch: 0 [192512/387873]    Loss: 0.002440   Batch Acc: 90.62
[Train] Epoch: 0 [192640/387873]    Loss: 0.001756   Batch Acc: 94.53
[Train] Epoch: 0 [192768/387873]    Loss: 0.001946   Batch Acc: 89.06
[Train] Epoch: 0 [192896/387873]    Loss: 0.002810   Batch Acc: 83.59
[Train] Epoch: 0 [193024/387873]    Loss: 0.002875   Batch Acc: 84.38
[Train] Epoch: 0 [193152/387873]    Loss: 0.002415   Batch Acc: 88.28
[Train] Epoch: 0 [193280/387873]    Loss: 0.001798   Batch Acc: 94.53
[Train] Epoch: 0 [193408/387873]    Loss: 0.002521   Batch Acc: 85.94
[Train] Epoch: 0 [193536/387873]    Loss: 0.002305   Batch Acc: 85.94
[Train] Epoch: 0 [193664/387873]    Loss: 0.002334   Batch Acc: 89.84
[Train] Epoch: 0 [193792/387873]    Loss: 0.002522   Batch Acc: 84.38
[Train] Epoch: 0 [193920/387873]    Loss: 0.002465   Batch Acc: 90.62
[Train] Epoch: 0 [194048/387873]    Loss: 0.002427   Batch Acc: 86.72
[Train] Epoch: 0 [194176/387873]    Loss: 0.002545   Batch Acc: 85.94
[Train] Epoch: 0 [194304/387873]    Loss: 0.002114   Batch Acc: 92.19
[Train] Epoch: 0 [194432/387873]    Loss: 0.002336   Batch Acc: 85.16
[Train] Epoch: 0 [194560/387873]    Loss: 0.002699   Batch Acc: 86.72
[Train] Epoch: 0 [194688/387873]    Loss: 0.002071   Batch Acc: 91.41
[Train] Epoch: 0 [194816/387873]    Loss: 0.002492   Batch Acc: 86.72
[Train] Epoch: 0 [194944/387873]    Loss: 0.002309   Batch Acc: 85.94
[Train] Epoch: 0 [195072/387873]    Loss: 0.002283   Batch Acc: 87.50
[Train] Epoch: 0 [195200/387873]    Loss: 0.002665   Batch Acc: 82.03
[Train] Epoch: 0 [195328/387873]    Loss: 0.002163   Batch Acc: 89.06
[Train] Epoch: 0 [195456/387873]    Loss: 0.002779   Batch Acc: 83.59
[Train] Epoch: 0 [195584/387873]    Loss: 0.002841   Batch Acc: 88.28
[Train] Epoch: 0 [195712/387873]    Loss: 0.002100   Batch Acc: 90.62
[Train] Epoch: 0 [195840/387873]    Loss: 0.001963   Batch Acc: 92.19
[Train] Epoch: 0 [195968/387873]    Loss: 0.002994   Batch Acc: 85.16
[Train] Epoch: 0 [196096/387873]    Loss: 0.002268   Batch Acc: 89.06
[Train] Epoch: 0 [196224/387873]    Loss: 0.002410   Batch Acc: 88.28
[Train] Epoch: 0 [196352/387873]    Loss: 0.002304   Batch Acc: 88.28
[Train] Epoch: 0 [196480/387873]    Loss: 0.002388   Batch Acc: 89.84
[Train] Epoch: 0 [196608/387873]    Loss: 0.002965   Batch Acc: 84.38
[Train] Epoch: 0 [196736/387873]    Loss: 0.002532   Batch Acc: 89.06
[Train] Epoch: 0 [196864/387873]    Loss: 0.002277   Batch Acc: 89.06
[Train] Epoch: 0 [196992/387873]    Loss: 0.003199   Batch Acc: 83.59
[Train] Epoch: 0 [197120/387873]    Loss: 0.002620   Batch Acc: 82.81
[Train] Epoch: 0 [197248/387873]    Loss: 0.002511   Batch Acc: 85.16
[Train] Epoch: 0 [197376/387873]    Loss: 0.002139   Batch Acc: 85.94
[Train] Epoch: 0 [197504/387873]    Loss: 0.002351   Batch Acc: 90.62
[Train] Epoch: 0 [197632/387873]    Loss: 0.002257   Batch Acc: 89.84
[Train] Epoch: 0 [197760/387873]    Loss: 0.002195   Batch Acc: 90.62
[Train] Epoch: 0 [197888/387873]    Loss: 0.002231   Batch Acc: 89.06
[Train] Epoch: 0 [198016/387873]    Loss: 0.002521   Batch Acc: 84.38
[Train] Epoch: 0 [198144/387873]    Loss: 0.002350   Batch Acc: 87.50
[Train] Epoch: 0 [198272/387873]    Loss: 0.002844   Batch Acc: 83.59
[Train] Epoch: 0 [198400/387873]    Loss: 0.002071   Batch Acc: 89.06
[Train] Epoch: 0 [198528/387873]    Loss: 0.002286   Batch Acc: 89.84
[Train] Epoch: 0 [198656/387873]    Loss: 0.002292   Batch Acc: 89.06
[Train] Epoch: 0 [198784/387873]    Loss: 0.002280   Batch Acc: 85.94
[Train] Epoch: 0 [198912/387873]    Loss: 0.002189   Batch Acc: 87.50
[Train] Epoch: 0 [199040/387873]    Loss: 0.002434   Batch Acc: 84.38
[Train] Epoch: 0 [199168/387873]    Loss: 0.002426   Batch Acc: 86.72
[Train] Epoch: 0 [199296/387873]    Loss: 0.002372   Batch Acc: 89.84
[Train] Epoch: 0 [199424/387873]    Loss: 0.002088   Batch Acc: 88.28
[Train] Epoch: 0 [199552/387873]    Loss: 0.002814   Batch Acc: 83.59
[Train] Epoch: 0 [199680/387873]    Loss: 0.002169   Batch Acc: 88.28
[Train] Epoch: 0 [199808/387873]    Loss: 0.002783   Batch Acc: 85.16
[Train] Epoch: 0 [199936/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 0 [200064/387873]    Loss: 0.002464   Batch Acc: 89.06
[Train] Epoch: 0 [200192/387873]    Loss: 0.001710   Batch Acc: 92.97
[Train] Epoch: 0 [200320/387873]    Loss: 0.001912   Batch Acc: 93.75
[Train] Epoch: 0 [200448/387873]    Loss: 0.002326   Batch Acc: 85.94
[Train] Epoch: 0 [200576/387873]    Loss: 0.002152   Batch Acc: 91.41
[Train] Epoch: 0 [200704/387873]    Loss: 0.002653   Batch Acc: 87.50
[Train] Epoch: 0 [200832/387873]    Loss: 0.002431   Batch Acc: 85.94
[Train] Epoch: 0 [200960/387873]    Loss: 0.002776   Batch Acc: 84.38
[Train] Epoch: 0 [201088/387873]    Loss: 0.001888   Batch Acc: 92.97
[Train] Epoch: 0 [201216/387873]    Loss: 0.002785   Batch Acc: 82.81
[Train] Epoch: 0 [201344/387873]    Loss: 0.002056   Batch Acc: 89.84
[Train] Epoch: 0 [201472/387873]    Loss: 0.002379   Batch Acc: 86.72
[Train] Epoch: 0 [201600/387873]    Loss: 0.002237   Batch Acc: 89.84
[Train] Epoch: 0 [201728/387873]    Loss: 0.002190   Batch Acc: 89.06
[Train] Epoch: 0 [201856/387873]    Loss: 0.001864   Batch Acc: 91.41
[Train] Epoch: 0 [201984/387873]    Loss: 0.002476   Batch Acc: 88.28
[Train] Epoch: 0 [202112/387873]    Loss: 0.002769   Batch Acc: 82.81
[Train] Epoch: 0 [202240/387873]    Loss: 0.002278   Batch Acc: 89.06
[Train] Epoch: 0 [202368/387873]    Loss: 0.002232   Batch Acc: 90.62
[Train] Epoch: 0 [202496/387873]    Loss: 0.002244   Batch Acc: 89.06
[Train] Epoch: 0 [202624/387873]    Loss: 0.002624   Batch Acc: 88.28
[Train] Epoch: 0 [202752/387873]    Loss: 0.002334   Batch Acc: 89.06
[Train] Epoch: 0 [202880/387873]    Loss: 0.002759   Batch Acc: 83.59
[Train] Epoch: 0 [203008/387873]    Loss: 0.002598   Batch Acc: 84.38
[Train] Epoch: 0 [203136/387873]    Loss: 0.002404   Batch Acc: 86.72
[Train] Epoch: 0 [203264/387873]    Loss: 0.002581   Batch Acc: 87.50
[Train] Epoch: 0 [203392/387873]    Loss: 0.002341   Batch Acc: 90.62
[Train] Epoch: 0 [203520/387873]    Loss: 0.002223   Batch Acc: 89.06
[Train] Epoch: 0 [203648/387873]    Loss: 0.002634   Batch Acc: 86.72
[Train] Epoch: 0 [203776/387873]    Loss: 0.002867   Batch Acc: 82.03
[Train] Epoch: 0 [203904/387873]    Loss: 0.002549   Batch Acc: 86.72
[Train] Epoch: 0 [204032/387873]    Loss: 0.002201   Batch Acc: 90.62
[Train] Epoch: 0 [204160/387873]    Loss: 0.002376   Batch Acc: 84.38
[Train] Epoch: 0 [204288/387873]    Loss: 0.002339   Batch Acc: 89.06
[Train] Epoch: 0 [204416/387873]    Loss: 0.002409   Batch Acc: 86.72
[Train] Epoch: 0 [204544/387873]    Loss: 0.002549   Batch Acc: 85.94
[Train] Epoch: 0 [204672/387873]    Loss: 0.002604   Batch Acc: 87.50
[Train] Epoch: 0 [204800/387873]    Loss: 0.002021   Batch Acc: 86.72
[Train] Epoch: 0 [204928/387873]    Loss: 0.002306   Batch Acc: 89.84
[Train] Epoch: 0 [205056/387873]    Loss: 0.002215   Batch Acc: 88.28
[Train] Epoch: 0 [205184/387873]    Loss: 0.002873   Batch Acc: 84.38
[Train] Epoch: 0 [205312/387873]    Loss: 0.002704   Batch Acc: 84.38
[Train] Epoch: 0 [205440/387873]    Loss: 0.002176   Batch Acc: 91.41
[Train] Epoch: 0 [205568/387873]    Loss: 0.001999   Batch Acc: 90.62
[Train] Epoch: 0 [205696/387873]    Loss: 0.002250   Batch Acc: 86.72
[Train] Epoch: 0 [205824/387873]    Loss: 0.001974   Batch Acc: 93.75
[Train] Epoch: 0 [205952/387873]    Loss: 0.001996   Batch Acc: 89.84
[Train] Epoch: 0 [206080/387873]    Loss: 0.003103   Batch Acc: 81.25
[Train] Epoch: 0 [206208/387873]    Loss: 0.002175   Batch Acc: 90.62
[Train] Epoch: 0 [206336/387873]    Loss: 0.002544   Batch Acc: 85.16
[Train] Epoch: 0 [206464/387873]    Loss: 0.002225   Batch Acc: 89.84
[Train] Epoch: 0 [206592/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 0 [206720/387873]    Loss: 0.002094   Batch Acc: 89.84
[Train] Epoch: 0 [206848/387873]    Loss: 0.001819   Batch Acc: 92.19
[Train] Epoch: 0 [206976/387873]    Loss: 0.002785   Batch Acc: 84.38
[Train] Epoch: 0 [207104/387873]    Loss: 0.001805   Batch Acc: 91.41
[Train] Epoch: 0 [207232/387873]    Loss: 0.002815   Batch Acc: 82.81
[Train] Epoch: 0 [207360/387873]    Loss: 0.002915   Batch Acc: 82.03
[Train] Epoch: 0 [207488/387873]    Loss: 0.002296   Batch Acc: 87.50
[Train] Epoch: 0 [207616/387873]    Loss: 0.002088   Batch Acc: 90.62
[Train] Epoch: 0 [207744/387873]    Loss: 0.002571   Batch Acc: 83.59
[Train] Epoch: 0 [207872/387873]    Loss: 0.002979   Batch Acc: 83.59
[Train] Epoch: 0 [208000/387873]    Loss: 0.002113   Batch Acc: 92.19
[Train] Epoch: 0 [208128/387873]    Loss: 0.002375   Batch Acc: 87.50
[Train] Epoch: 0 [208256/387873]    Loss: 0.001873   Batch Acc: 91.41
[Train] Epoch: 0 [208384/387873]    Loss: 0.002608   Batch Acc: 85.16
[Train] Epoch: 0 [208512/387873]    Loss: 0.002228   Batch Acc: 87.50
[Train] Epoch: 0 [208640/387873]    Loss: 0.002363   Batch Acc: 89.06
[Train] Epoch: 0 [208768/387873]    Loss: 0.001906   Batch Acc: 91.41
[Train] Epoch: 0 [208896/387873]    Loss: 0.002582   Batch Acc: 85.16
[Train] Epoch: 0 [209024/387873]    Loss: 0.002503   Batch Acc: 87.50
[Train] Epoch: 0 [209152/387873]    Loss: 0.002728   Batch Acc: 83.59
[Train] Epoch: 0 [209280/387873]    Loss: 0.002446   Batch Acc: 88.28
[Train] Epoch: 0 [209408/387873]    Loss: 0.002525   Batch Acc: 87.50
[Train] Epoch: 0 [209536/387873]    Loss: 0.002298   Batch Acc: 87.50
[Train] Epoch: 0 [209664/387873]    Loss: 0.002550   Batch Acc: 86.72
[Train] Epoch: 0 [209792/387873]    Loss: 0.002771   Batch Acc: 83.59
[Train] Epoch: 0 [209920/387873]    Loss: 0.002721   Batch Acc: 85.16
[Train] Epoch: 0 [210048/387873]    Loss: 0.002658   Batch Acc: 87.50
[Train] Epoch: 0 [210176/387873]    Loss: 0.002274   Batch Acc: 87.50
[Train] Epoch: 0 [210304/387873]    Loss: 0.002960   Batch Acc: 82.81
[Train] Epoch: 0 [210432/387873]    Loss: 0.002257   Batch Acc: 89.06
[Train] Epoch: 0 [210560/387873]    Loss: 0.001972   Batch Acc: 91.41
[Train] Epoch: 0 [210688/387873]    Loss: 0.002298   Batch Acc: 88.28
[Train] Epoch: 0 [210816/387873]    Loss: 0.002504   Batch Acc: 85.16
[Train] Epoch: 0 [210944/387873]    Loss: 0.002637   Batch Acc: 87.50
[Train] Epoch: 0 [211072/387873]    Loss: 0.002360   Batch Acc: 87.50
[Train] Epoch: 0 [211200/387873]    Loss: 0.002309   Batch Acc: 89.06
[Train] Epoch: 0 [211328/387873]    Loss: 0.002617   Batch Acc: 88.28
[Train] Epoch: 0 [211456/387873]    Loss: 0.002577   Batch Acc: 85.94
[Train] Epoch: 0 [211584/387873]    Loss: 0.002366   Batch Acc: 87.50
[Train] Epoch: 0 [211712/387873]    Loss: 0.002980   Batch Acc: 80.47
[Train] Epoch: 0 [211840/387873]    Loss: 0.002938   Batch Acc: 85.16
[Train] Epoch: 0 [211968/387873]    Loss: 0.002321   Batch Acc: 89.84
[Train] Epoch: 0 [212096/387873]    Loss: 0.003051   Batch Acc: 83.59
[Train] Epoch: 0 [212224/387873]    Loss: 0.002338   Batch Acc: 91.41
[Train] Epoch: 0 [212352/387873]    Loss: 0.002649   Batch Acc: 83.59
[Train] Epoch: 0 [212480/387873]    Loss: 0.002485   Batch Acc: 85.94
[Train] Epoch: 0 [212608/387873]    Loss: 0.002267   Batch Acc: 90.62
[Train] Epoch: 0 [212736/387873]    Loss: 0.002760   Batch Acc: 85.16
[Train] Epoch: 0 [212864/387873]    Loss: 0.002695   Batch Acc: 82.81
[Train] Epoch: 0 [212992/387873]    Loss: 0.002161   Batch Acc: 89.84
[Train] Epoch: 0 [213120/387873]    Loss: 0.002142   Batch Acc: 89.06
[Train] Epoch: 0 [213248/387873]    Loss: 0.002002   Batch Acc: 88.28
[Train] Epoch: 0 [213376/387873]    Loss: 0.002343   Batch Acc: 87.50
[Train] Epoch: 0 [213504/387873]    Loss: 0.003036   Batch Acc: 83.59
[Train] Epoch: 0 [213632/387873]    Loss: 0.001939   Batch Acc: 90.62
[Train] Epoch: 0 [213760/387873]    Loss: 0.002387   Batch Acc: 87.50
[Train] Epoch: 0 [213888/387873]    Loss: 0.002367   Batch Acc: 87.50
[Train] Epoch: 0 [214016/387873]    Loss: 0.002066   Batch Acc: 90.62
[Train] Epoch: 0 [214144/387873]    Loss: 0.001634   Batch Acc: 91.41
[Train] Epoch: 0 [214272/387873]    Loss: 0.002210   Batch Acc: 88.28
[Train] Epoch: 0 [214400/387873]    Loss: 0.002776   Batch Acc: 83.59
[Train] Epoch: 0 [214528/387873]    Loss: 0.002587   Batch Acc: 84.38
[Train] Epoch: 0 [214656/387873]    Loss: 0.002914   Batch Acc: 84.38
[Train] Epoch: 0 [214784/387873]    Loss: 0.002486   Batch Acc: 87.50
[Train] Epoch: 0 [214912/387873]    Loss: 0.002313   Batch Acc: 87.50
[Train] Epoch: 0 [215040/387873]    Loss: 0.002416   Batch Acc: 88.28
[Train] Epoch: 0 [215168/387873]    Loss: 0.002574   Batch Acc: 85.94
[Train] Epoch: 0 [215296/387873]    Loss: 0.002836   Batch Acc: 81.25
[Train] Epoch: 0 [215424/387873]    Loss: 0.002399   Batch Acc: 85.94
[Train] Epoch: 0 [215552/387873]    Loss: 0.002251   Batch Acc: 84.38
[Train] Epoch: 0 [215680/387873]    Loss: 0.001878   Batch Acc: 90.62
[Train] Epoch: 0 [215808/387873]    Loss: 0.002247   Batch Acc: 89.06
[Train] Epoch: 0 [215936/387873]    Loss: 0.002018   Batch Acc: 89.84
[Train] Epoch: 0 [216064/387873]    Loss: 0.002765   Batch Acc: 85.94
[Train] Epoch: 0 [216192/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 0 [216320/387873]    Loss: 0.002318   Batch Acc: 84.38
[Train] Epoch: 0 [216448/387873]    Loss: 0.002495   Batch Acc: 85.94
[Train] Epoch: 0 [216576/387873]    Loss: 0.002489   Batch Acc: 88.28
[Train] Epoch: 0 [216704/387873]    Loss: 0.003195   Batch Acc: 81.25
[Train] Epoch: 0 [216832/387873]    Loss: 0.002470   Batch Acc: 88.28
[Train] Epoch: 0 [216960/387873]    Loss: 0.002459   Batch Acc: 88.28
[Train] Epoch: 0 [217088/387873]    Loss: 0.002115   Batch Acc: 89.84
[Train] Epoch: 0 [217216/387873]    Loss: 0.002470   Batch Acc: 88.28
[Train] Epoch: 0 [217344/387873]    Loss: 0.002600   Batch Acc: 82.81
[Train] Epoch: 0 [217472/387873]    Loss: 0.002723   Batch Acc: 85.16
[Train] Epoch: 0 [217600/387873]    Loss: 0.001813   Batch Acc: 93.75
[Train] Epoch: 0 [217728/387873]    Loss: 0.002244   Batch Acc: 88.28
[Train] Epoch: 0 [217856/387873]    Loss: 0.002624   Batch Acc: 86.72
[Train] Epoch: 0 [217984/387873]    Loss: 0.002742   Batch Acc: 84.38
[Train] Epoch: 0 [218112/387873]    Loss: 0.002342   Batch Acc: 89.06
[Train] Epoch: 0 [218240/387873]    Loss: 0.002185   Batch Acc: 89.84
[Train] Epoch: 0 [218368/387873]    Loss: 0.002485   Batch Acc: 87.50
[Train] Epoch: 0 [218496/387873]    Loss: 0.003166   Batch Acc: 77.34
[Train] Epoch: 0 [218624/387873]    Loss: 0.002680   Batch Acc: 84.38
[Train] Epoch: 0 [218752/387873]    Loss: 0.002296   Batch Acc: 89.06
[Train] Epoch: 0 [218880/387873]    Loss: 0.002636   Batch Acc: 84.38
[Train] Epoch: 0 [219008/387873]    Loss: 0.002326   Batch Acc: 88.28
[Train] Epoch: 0 [219136/387873]    Loss: 0.001887   Batch Acc: 91.41
[Train] Epoch: 0 [219264/387873]    Loss: 0.002337   Batch Acc: 86.72
[Train] Epoch: 0 [219392/387873]    Loss: 0.002411   Batch Acc: 89.84
[Train] Epoch: 0 [219520/387873]    Loss: 0.002394   Batch Acc: 85.94
[Train] Epoch: 0 [219648/387873]    Loss: 0.002367   Batch Acc: 85.94
[Train] Epoch: 0 [219776/387873]    Loss: 0.001740   Batch Acc: 93.75
[Train] Epoch: 0 [219904/387873]    Loss: 0.002345   Batch Acc: 88.28
[Train] Epoch: 0 [220032/387873]    Loss: 0.002420   Batch Acc: 85.94
[Train] Epoch: 0 [220160/387873]    Loss: 0.002273   Batch Acc: 88.28
[Train] Epoch: 0 [220288/387873]    Loss: 0.002204   Batch Acc: 89.06
[Train] Epoch: 0 [220416/387873]    Loss: 0.002547   Batch Acc: 88.28
[Train] Epoch: 0 [220544/387873]    Loss: 0.002641   Batch Acc: 85.94
[Train] Epoch: 0 [220672/387873]    Loss: 0.002483   Batch Acc: 89.06
[Train] Epoch: 0 [220800/387873]    Loss: 0.002427   Batch Acc: 87.50
[Train] Epoch: 0 [220928/387873]    Loss: 0.002216   Batch Acc: 88.28
[Train] Epoch: 0 [221056/387873]    Loss: 0.001922   Batch Acc: 90.62
[Train] Epoch: 0 [221184/387873]    Loss: 0.002930   Batch Acc: 85.16
[Train] Epoch: 0 [221312/387873]    Loss: 0.002162   Batch Acc: 89.06
[Train] Epoch: 0 [221440/387873]    Loss: 0.002190   Batch Acc: 86.72
[Train] Epoch: 0 [221568/387873]    Loss: 0.002185   Batch Acc: 88.28
[Train] Epoch: 0 [221696/387873]    Loss: 0.002366   Batch Acc: 86.72
[Train] Epoch: 0 [221824/387873]    Loss: 0.002116   Batch Acc: 89.84
[Train] Epoch: 0 [221952/387873]    Loss: 0.002853   Batch Acc: 80.47
[Train] Epoch: 0 [222080/387873]    Loss: 0.001901   Batch Acc: 91.41
[Train] Epoch: 0 [222208/387873]    Loss: 0.002656   Batch Acc: 83.59
[Train] Epoch: 0 [222336/387873]    Loss: 0.002107   Batch Acc: 89.06
[Train] Epoch: 0 [222464/387873]    Loss: 0.002063   Batch Acc: 89.84
[Train] Epoch: 0 [222592/387873]    Loss: 0.002431   Batch Acc: 86.72
[Train] Epoch: 0 [222720/387873]    Loss: 0.002240   Batch Acc: 86.72
[Train] Epoch: 0 [222848/387873]    Loss: 0.002547   Batch Acc: 85.16
[Train] Epoch: 0 [222976/387873]    Loss: 0.002278   Batch Acc: 88.28
[Train] Epoch: 0 [223104/387873]    Loss: 0.002024   Batch Acc: 91.41
[Train] Epoch: 0 [223232/387873]    Loss: 0.002576   Batch Acc: 82.03
[Train] Epoch: 0 [223360/387873]    Loss: 0.002730   Batch Acc: 86.72
[Train] Epoch: 0 [223488/387873]    Loss: 0.002154   Batch Acc: 87.50
[Train] Epoch: 0 [223616/387873]    Loss: 0.002264   Batch Acc: 92.97
[Train] Epoch: 0 [223744/387873]    Loss: 0.002462   Batch Acc: 89.06
[Train] Epoch: 0 [223872/387873]    Loss: 0.002280   Batch Acc: 87.50
[Train] Epoch: 0 [224000/387873]    Loss: 0.002185   Batch Acc: 88.28
[Train] Epoch: 0 [224128/387873]    Loss: 0.002297   Batch Acc: 85.94
[Train] Epoch: 0 [224256/387873]    Loss: 0.002170   Batch Acc: 85.16
[Train] Epoch: 0 [224384/387873]    Loss: 0.001640   Batch Acc: 92.19
[Train] Epoch: 0 [224512/387873]    Loss: 0.002082   Batch Acc: 90.62
[Train] Epoch: 0 [224640/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 0 [224768/387873]    Loss: 0.002439   Batch Acc: 85.94
[Train] Epoch: 0 [224896/387873]    Loss: 0.002149   Batch Acc: 88.28
[Train] Epoch: 0 [225024/387873]    Loss: 0.003018   Batch Acc: 81.25
[Train] Epoch: 0 [225152/387873]    Loss: 0.002294   Batch Acc: 88.28
[Train] Epoch: 0 [225280/387873]    Loss: 0.001913   Batch Acc: 89.06
[Train] Epoch: 0 [225408/387873]    Loss: 0.001964   Batch Acc: 88.28
[Train] Epoch: 0 [225536/387873]    Loss: 0.002122   Batch Acc: 88.28
[Train] Epoch: 0 [225664/387873]    Loss: 0.002528   Batch Acc: 85.94
[Train] Epoch: 0 [225792/387873]    Loss: 0.002107   Batch Acc: 89.84
[Train] Epoch: 0 [225920/387873]    Loss: 0.001874   Batch Acc: 92.19
[Train] Epoch: 0 [226048/387873]    Loss: 0.002317   Batch Acc: 86.72
[Train] Epoch: 0 [226176/387873]    Loss: 0.002184   Batch Acc: 89.84
[Train] Epoch: 0 [226304/387873]    Loss: 0.002430   Batch Acc: 88.28
[Train] Epoch: 0 [226432/387873]    Loss: 0.002198   Batch Acc: 92.19
[Train] Epoch: 0 [226560/387873]    Loss: 0.002370   Batch Acc: 88.28
[Train] Epoch: 0 [226688/387873]    Loss: 0.002347   Batch Acc: 87.50
[Train] Epoch: 0 [226816/387873]    Loss: 0.002408   Batch Acc: 87.50
[Train] Epoch: 0 [226944/387873]    Loss: 0.002040   Batch Acc: 88.28
[Train] Epoch: 0 [227072/387873]    Loss: 0.002740   Batch Acc: 82.81
[Train] Epoch: 0 [227200/387873]    Loss: 0.002032   Batch Acc: 87.50
[Train] Epoch: 0 [227328/387873]    Loss: 0.002710   Batch Acc: 84.38
[Train] Epoch: 0 [227456/387873]    Loss: 0.002427   Batch Acc: 85.94
[Train] Epoch: 0 [227584/387873]    Loss: 0.002887   Batch Acc: 86.72
[Train] Epoch: 0 [227712/387873]    Loss: 0.002465   Batch Acc: 85.16
[Train] Epoch: 0 [227840/387873]    Loss: 0.002625   Batch Acc: 82.81
[Train] Epoch: 0 [227968/387873]    Loss: 0.002048   Batch Acc: 89.06
[Train] Epoch: 0 [228096/387873]    Loss: 0.002120   Batch Acc: 89.84
[Train] Epoch: 0 [228224/387873]    Loss: 0.002444   Batch Acc: 82.03
[Train] Epoch: 0 [228352/387873]    Loss: 0.002554   Batch Acc: 84.38
[Train] Epoch: 0 [228480/387873]    Loss: 0.002343   Batch Acc: 85.16
[Train] Epoch: 0 [228608/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 0 [228736/387873]    Loss: 0.002568   Batch Acc: 85.94
[Train] Epoch: 0 [228864/387873]    Loss: 0.002403   Batch Acc: 86.72
[Train] Epoch: 0 [228992/387873]    Loss: 0.002595   Batch Acc: 84.38
[Train] Epoch: 0 [229120/387873]    Loss: 0.002211   Batch Acc: 88.28
[Train] Epoch: 0 [229248/387873]    Loss: 0.002286   Batch Acc: 89.06
[Train] Epoch: 0 [229376/387873]    Loss: 0.002089   Batch Acc: 87.50
[Train] Epoch: 0 [229504/387873]    Loss: 0.003304   Batch Acc: 83.59
[Train] Epoch: 0 [229632/387873]    Loss: 0.003669   Batch Acc: 79.69
[Train] Epoch: 0 [229760/387873]    Loss: 0.002953   Batch Acc: 80.47
[Train] Epoch: 0 [229888/387873]    Loss: 0.002448   Batch Acc: 85.94
[Train] Epoch: 0 [230016/387873]    Loss: 0.002189   Batch Acc: 89.84
[Train] Epoch: 0 [230144/387873]    Loss: 0.002819   Batch Acc: 87.50
[Train] Epoch: 0 [230272/387873]    Loss: 0.002268   Batch Acc: 85.94
[Train] Epoch: 0 [230400/387873]    Loss: 0.002478   Batch Acc: 85.16
[Train] Epoch: 0 [230528/387873]    Loss: 0.002387   Batch Acc: 86.72
[Train] Epoch: 0 [230656/387873]    Loss: 0.002109   Batch Acc: 85.94
[Train] Epoch: 0 [230784/387873]    Loss: 0.002155   Batch Acc: 90.62
[Train] Epoch: 0 [230912/387873]    Loss: 0.002292   Batch Acc: 89.84
[Train] Epoch: 0 [231040/387873]    Loss: 0.002451   Batch Acc: 89.06
[Train] Epoch: 0 [231168/387873]    Loss: 0.002236   Batch Acc: 87.50
[Train] Epoch: 0 [231296/387873]    Loss: 0.003327   Batch Acc: 84.38
[Train] Epoch: 0 [231424/387873]    Loss: 0.002719   Batch Acc: 85.94
[Train] Epoch: 0 [231552/387873]    Loss: 0.002234   Batch Acc: 85.94
[Train] Epoch: 0 [231680/387873]    Loss: 0.002627   Batch Acc: 84.38
[Train] Epoch: 0 [231808/387873]    Loss: 0.002087   Batch Acc: 88.28
[Train] Epoch: 0 [231936/387873]    Loss: 0.001654   Batch Acc: 92.19
[Train] Epoch: 0 [232064/387873]    Loss: 0.002513   Batch Acc: 89.84
[Train] Epoch: 0 [232192/387873]    Loss: 0.002086   Batch Acc: 91.41
[Train] Epoch: 0 [232320/387873]    Loss: 0.003130   Batch Acc: 81.25
[Train] Epoch: 0 [232448/387873]    Loss: 0.002539   Batch Acc: 86.72
[Train] Epoch: 0 [232576/387873]    Loss: 0.002206   Batch Acc: 86.72
[Train] Epoch: 0 [232704/387873]    Loss: 0.001957   Batch Acc: 90.62
[Train] Epoch: 0 [232832/387873]    Loss: 0.002058   Batch Acc: 91.41
[Train] Epoch: 0 [232960/387873]    Loss: 0.002155   Batch Acc: 89.06
[Train] Epoch: 0 [233088/387873]    Loss: 0.001791   Batch Acc: 95.31
[Train] Epoch: 0 [233216/387873]    Loss: 0.002175   Batch Acc: 87.50
[Train] Epoch: 0 [233344/387873]    Loss: 0.002263   Batch Acc: 88.28
[Train] Epoch: 0 [233472/387873]    Loss: 0.003135   Batch Acc: 82.03
[Train] Epoch: 0 [233600/387873]    Loss: 0.002602   Batch Acc: 85.16
[Train] Epoch: 0 [233728/387873]    Loss: 0.002213   Batch Acc: 89.06
[Train] Epoch: 0 [233856/387873]    Loss: 0.002784   Batch Acc: 83.59
[Train] Epoch: 0 [233984/387873]    Loss: 0.002117   Batch Acc: 86.72
[Train] Epoch: 0 [234112/387873]    Loss: 0.002150   Batch Acc: 89.06
[Train] Epoch: 0 [234240/387873]    Loss: 0.002338   Batch Acc: 84.38
[Train] Epoch: 0 [234368/387873]    Loss: 0.002582   Batch Acc: 85.94
[Train] Epoch: 0 [234496/387873]    Loss: 0.002561   Batch Acc: 87.50
[Train] Epoch: 0 [234624/387873]    Loss: 0.002235   Batch Acc: 87.50
[Train] Epoch: 0 [234752/387873]    Loss: 0.002472   Batch Acc: 86.72
[Train] Epoch: 0 [234880/387873]    Loss: 0.001917   Batch Acc: 91.41
[Train] Epoch: 0 [235008/387873]    Loss: 0.002906   Batch Acc: 85.16
[Train] Epoch: 0 [235136/387873]    Loss: 0.002164   Batch Acc: 87.50
[Train] Epoch: 0 [235264/387873]    Loss: 0.002430   Batch Acc: 88.28
[Train] Epoch: 0 [235392/387873]    Loss: 0.002300   Batch Acc: 85.16
[Train] Epoch: 0 [235520/387873]    Loss: 0.002497   Batch Acc: 85.16
[Train] Epoch: 0 [235648/387873]    Loss: 0.002040   Batch Acc: 87.50
[Train] Epoch: 0 [235776/387873]    Loss: 0.002566   Batch Acc: 83.59
[Train] Epoch: 0 [235904/387873]    Loss: 0.002528   Batch Acc: 86.72
[Train] Epoch: 0 [236032/387873]    Loss: 0.002457   Batch Acc: 83.59
[Train] Epoch: 0 [236160/387873]    Loss: 0.002404   Batch Acc: 89.84
[Train] Epoch: 0 [236288/387873]    Loss: 0.002242   Batch Acc: 87.50
[Train] Epoch: 0 [236416/387873]    Loss: 0.002078   Batch Acc: 88.28
[Train] Epoch: 0 [236544/387873]    Loss: 0.001742   Batch Acc: 93.75
[Train] Epoch: 0 [236672/387873]    Loss: 0.001914   Batch Acc: 89.84
[Train] Epoch: 0 [236800/387873]    Loss: 0.002601   Batch Acc: 86.72
[Train] Epoch: 0 [236928/387873]    Loss: 0.002841   Batch Acc: 83.59
[Train] Epoch: 0 [237056/387873]    Loss: 0.002428   Batch Acc: 84.38
[Train] Epoch: 0 [237184/387873]    Loss: 0.002659   Batch Acc: 82.81
[Train] Epoch: 0 [237312/387873]    Loss: 0.002449   Batch Acc: 88.28
[Train] Epoch: 0 [237440/387873]    Loss: 0.002168   Batch Acc: 91.41
[Train] Epoch: 0 [237568/387873]    Loss: 0.002126   Batch Acc: 89.06
[Train] Epoch: 0 [237696/387873]    Loss: 0.002557   Batch Acc: 82.81
[Train] Epoch: 0 [237824/387873]    Loss: 0.002081   Batch Acc: 87.50
[Train] Epoch: 0 [237952/387873]    Loss: 0.002925   Batch Acc: 81.25
[Train] Epoch: 0 [238080/387873]    Loss: 0.001977   Batch Acc: 92.97
[Train] Epoch: 0 [238208/387873]    Loss: 0.002668   Batch Acc: 85.16
[Train] Epoch: 0 [238336/387873]    Loss: 0.003367   Batch Acc: 82.03
[Train] Epoch: 0 [238464/387873]    Loss: 0.001980   Batch Acc: 92.19
[Train] Epoch: 0 [238592/387873]    Loss: 0.002227   Batch Acc: 89.06
[Train] Epoch: 0 [238720/387873]    Loss: 0.002285   Batch Acc: 86.72
[Train] Epoch: 0 [238848/387873]    Loss: 0.002139   Batch Acc: 88.28
[Train] Epoch: 0 [238976/387873]    Loss: 0.002277   Batch Acc: 89.06
[Train] Epoch: 0 [239104/387873]    Loss: 0.002713   Batch Acc: 84.38
[Train] Epoch: 0 [239232/387873]    Loss: 0.002308   Batch Acc: 87.50
[Train] Epoch: 0 [239360/387873]    Loss: 0.002942   Batch Acc: 83.59
[Train] Epoch: 0 [239488/387873]    Loss: 0.002792   Batch Acc: 84.38
[Train] Epoch: 0 [239616/387873]    Loss: 0.002346   Batch Acc: 87.50
[Train] Epoch: 0 [239744/387873]    Loss: 0.002218   Batch Acc: 90.62
[Train] Epoch: 0 [239872/387873]    Loss: 0.002603   Batch Acc: 82.81
[Train] Epoch: 0 [240000/387873]    Loss: 0.002274   Batch Acc: 88.28
[Train] Epoch: 0 [240128/387873]    Loss: 0.002385   Batch Acc: 89.06
[Train] Epoch: 0 [240256/387873]    Loss: 0.002387   Batch Acc: 88.28
[Train] Epoch: 0 [240384/387873]    Loss: 0.002563   Batch Acc: 89.84
[Train] Epoch: 0 [240512/387873]    Loss: 0.002464   Batch Acc: 83.59
[Train] Epoch: 0 [240640/387873]    Loss: 0.001786   Batch Acc: 89.06
[Train] Epoch: 0 [240768/387873]    Loss: 0.002686   Batch Acc: 85.16
[Train] Epoch: 0 [240896/387873]    Loss: 0.002239   Batch Acc: 88.28
[Train] Epoch: 0 [241024/387873]    Loss: 0.001935   Batch Acc: 92.19
[Train] Epoch: 0 [241152/387873]    Loss: 0.002224   Batch Acc: 87.50
[Train] Epoch: 0 [241280/387873]    Loss: 0.002305   Batch Acc: 89.06
[Train] Epoch: 0 [241408/387873]    Loss: 0.002563   Batch Acc: 85.16
[Train] Epoch: 0 [241536/387873]    Loss: 0.001622   Batch Acc: 96.09
[Train] Epoch: 0 [241664/387873]    Loss: 0.002787   Batch Acc: 82.81
[Train] Epoch: 0 [241792/387873]    Loss: 0.002192   Batch Acc: 89.06
[Train] Epoch: 0 [241920/387873]    Loss: 0.002864   Batch Acc: 82.81
[Train] Epoch: 0 [242048/387873]    Loss: 0.002277   Batch Acc: 88.28
[Train] Epoch: 0 [242176/387873]    Loss: 0.001883   Batch Acc: 89.84
[Train] Epoch: 0 [242304/387873]    Loss: 0.002503   Batch Acc: 86.72
[Train] Epoch: 0 [242432/387873]    Loss: 0.002420   Batch Acc: 86.72
[Train] Epoch: 0 [242560/387873]    Loss: 0.002563   Batch Acc: 85.94
[Train] Epoch: 0 [242688/387873]    Loss: 0.002219   Batch Acc: 89.84
[Train] Epoch: 0 [242816/387873]    Loss: 0.002155   Batch Acc: 89.06
[Train] Epoch: 0 [242944/387873]    Loss: 0.002321   Batch Acc: 85.16
[Train] Epoch: 0 [243072/387873]    Loss: 0.001895   Batch Acc: 91.41
[Train] Epoch: 0 [243200/387873]    Loss: 0.002466   Batch Acc: 85.16
[Train] Epoch: 0 [243328/387873]    Loss: 0.002233   Batch Acc: 89.84
[Train] Epoch: 0 [243456/387873]    Loss: 0.002941   Batch Acc: 83.59
[Train] Epoch: 0 [243584/387873]    Loss: 0.002456   Batch Acc: 87.50
[Train] Epoch: 0 [243712/387873]    Loss: 0.002429   Batch Acc: 87.50
[Train] Epoch: 0 [243840/387873]    Loss: 0.002518   Batch Acc: 85.94
[Train] Epoch: 0 [243968/387873]    Loss: 0.002296   Batch Acc: 85.16
[Train] Epoch: 0 [244096/387873]    Loss: 0.002786   Batch Acc: 84.38
[Train] Epoch: 0 [244224/387873]    Loss: 0.002281   Batch Acc: 86.72
[Train] Epoch: 0 [244352/387873]    Loss: 0.003539   Batch Acc: 77.34
[Train] Epoch: 0 [244480/387873]    Loss: 0.002399   Batch Acc: 88.28
[Train] Epoch: 0 [244608/387873]    Loss: 0.001957   Batch Acc: 91.41
[Train] Epoch: 0 [244736/387873]    Loss: 0.002143   Batch Acc: 89.06
[Train] Epoch: 0 [244864/387873]    Loss: 0.002182   Batch Acc: 89.06
[Train] Epoch: 0 [244992/387873]    Loss: 0.002151   Batch Acc: 89.84
[Train] Epoch: 0 [245120/387873]    Loss: 0.002704   Batch Acc: 82.81
[Train] Epoch: 0 [245248/387873]    Loss: 0.001941   Batch Acc: 91.41
[Train] Epoch: 0 [245376/387873]    Loss: 0.002351   Batch Acc: 85.94
[Train] Epoch: 0 [245504/387873]    Loss: 0.002463   Batch Acc: 90.62
[Train] Epoch: 0 [245632/387873]    Loss: 0.002259   Batch Acc: 87.50
[Train] Epoch: 0 [245760/387873]    Loss: 0.002535   Batch Acc: 89.06
[Train] Epoch: 0 [245888/387873]    Loss: 0.002139   Batch Acc: 89.06
[Train] Epoch: 0 [246016/387873]    Loss: 0.002122   Batch Acc: 85.94
[Train] Epoch: 0 [246144/387873]    Loss: 0.002333   Batch Acc: 89.06
[Train] Epoch: 0 [246272/387873]    Loss: 0.002356   Batch Acc: 88.28
[Train] Epoch: 0 [246400/387873]    Loss: 0.002509   Batch Acc: 87.50
[Train] Epoch: 0 [246528/387873]    Loss: 0.002041   Batch Acc: 88.28
[Train] Epoch: 0 [246656/387873]    Loss: 0.002177   Batch Acc: 87.50
[Train] Epoch: 0 [246784/387873]    Loss: 0.002425   Batch Acc: 85.94
[Train] Epoch: 0 [246912/387873]    Loss: 0.002506   Batch Acc: 83.59
[Train] Epoch: 0 [247040/387873]    Loss: 0.001735   Batch Acc: 94.53
[Train] Epoch: 0 [247168/387873]    Loss: 0.002277   Batch Acc: 89.06
[Train] Epoch: 0 [247296/387873]    Loss: 0.002057   Batch Acc: 89.06
[Train] Epoch: 0 [247424/387873]    Loss: 0.002579   Batch Acc: 86.72
[Train] Epoch: 0 [247552/387873]    Loss: 0.002183   Batch Acc: 87.50
[Train] Epoch: 0 [247680/387873]    Loss: 0.002905   Batch Acc: 80.47
[Train] Epoch: 0 [247808/387873]    Loss: 0.002277   Batch Acc: 87.50
[Train] Epoch: 0 [247936/387873]    Loss: 0.002271   Batch Acc: 87.50
[Train] Epoch: 0 [248064/387873]    Loss: 0.002672   Batch Acc: 85.16
[Train] Epoch: 0 [248192/387873]    Loss: 0.002244   Batch Acc: 89.84
[Train] Epoch: 0 [248320/387873]    Loss: 0.002010   Batch Acc: 89.84
[Train] Epoch: 0 [248448/387873]    Loss: 0.002303   Batch Acc: 89.06
[Train] Epoch: 0 [248576/387873]    Loss: 0.002090   Batch Acc: 89.84
[Train] Epoch: 0 [248704/387873]    Loss: 0.002023   Batch Acc: 88.28
[Train] Epoch: 0 [248832/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 0 [248960/387873]    Loss: 0.002519   Batch Acc: 85.16
[Train] Epoch: 0 [249088/387873]    Loss: 0.002220   Batch Acc: 89.84
[Train] Epoch: 0 [249216/387873]    Loss: 0.002727   Batch Acc: 80.47
[Train] Epoch: 0 [249344/387873]    Loss: 0.001984   Batch Acc: 85.94
[Train] Epoch: 0 [249472/387873]    Loss: 0.002674   Batch Acc: 86.72
[Train] Epoch: 0 [249600/387873]    Loss: 0.002571   Batch Acc: 85.16
[Train] Epoch: 0 [249728/387873]    Loss: 0.002409   Batch Acc: 86.72
[Train] Epoch: 0 [249856/387873]    Loss: 0.002572   Batch Acc: 83.59
[Train] Epoch: 0 [249984/387873]    Loss: 0.002310   Batch Acc: 90.62
[Train] Epoch: 0 [250112/387873]    Loss: 0.002186   Batch Acc: 91.41
[Train] Epoch: 0 [250240/387873]    Loss: 0.002503   Batch Acc: 85.94
[Train] Epoch: 0 [250368/387873]    Loss: 0.002490   Batch Acc: 85.16
[Train] Epoch: 0 [250496/387873]    Loss: 0.002168   Batch Acc: 89.84
[Train] Epoch: 0 [250624/387873]    Loss: 0.002674   Batch Acc: 85.16
[Train] Epoch: 0 [250752/387873]    Loss: 0.002252   Batch Acc: 85.94
[Train] Epoch: 0 [250880/387873]    Loss: 0.002669   Batch Acc: 85.94
[Train] Epoch: 0 [251008/387873]    Loss: 0.002536   Batch Acc: 85.94
[Train] Epoch: 0 [251136/387873]    Loss: 0.002543   Batch Acc: 84.38
[Train] Epoch: 0 [251264/387873]    Loss: 0.002569   Batch Acc: 86.72
[Train] Epoch: 0 [251392/387873]    Loss: 0.001694   Batch Acc: 92.19
[Train] Epoch: 0 [251520/387873]    Loss: 0.002105   Batch Acc: 89.84
[Train] Epoch: 0 [251648/387873]    Loss: 0.001979   Batch Acc: 92.97
[Train] Epoch: 0 [251776/387873]    Loss: 0.002901   Batch Acc: 85.16
[Train] Epoch: 0 [251904/387873]    Loss: 0.002435   Batch Acc: 86.72
[Train] Epoch: 0 [252032/387873]    Loss: 0.002829   Batch Acc: 81.25
[Train] Epoch: 0 [252160/387873]    Loss: 0.002767   Batch Acc: 85.16
[Train] Epoch: 0 [252288/387873]    Loss: 0.002481   Batch Acc: 85.94
[Train] Epoch: 0 [252416/387873]    Loss: 0.002142   Batch Acc: 90.62
[Train] Epoch: 0 [252544/387873]    Loss: 0.002777   Batch Acc: 82.81
[Train] Epoch: 0 [252672/387873]    Loss: 0.002088   Batch Acc: 89.06
[Train] Epoch: 0 [252800/387873]    Loss: 0.002269   Batch Acc: 87.50
[Train] Epoch: 0 [252928/387873]    Loss: 0.002239   Batch Acc: 87.50
[Train] Epoch: 0 [253056/387873]    Loss: 0.002023   Batch Acc: 90.62
[Train] Epoch: 0 [253184/387873]    Loss: 0.002153   Batch Acc: 87.50
[Train] Epoch: 0 [253312/387873]    Loss: 0.002502   Batch Acc: 83.59
[Train] Epoch: 0 [253440/387873]    Loss: 0.002322   Batch Acc: 88.28
[Train] Epoch: 0 [253568/387873]    Loss: 0.002666   Batch Acc: 85.94
[Train] Epoch: 0 [253696/387873]    Loss: 0.002064   Batch Acc: 90.62
[Train] Epoch: 0 [253824/387873]    Loss: 0.001669   Batch Acc: 93.75
[Train] Epoch: 0 [253952/387873]    Loss: 0.002489   Batch Acc: 85.94
[Train] Epoch: 0 [254080/387873]    Loss: 0.002665   Batch Acc: 85.94
[Train] Epoch: 0 [254208/387873]    Loss: 0.002162   Batch Acc: 86.72
[Train] Epoch: 0 [254336/387873]    Loss: 0.001798   Batch Acc: 90.62
[Train] Epoch: 0 [254464/387873]    Loss: 0.002427   Batch Acc: 85.16
[Train] Epoch: 0 [254592/387873]    Loss: 0.002031   Batch Acc: 89.06
[Train] Epoch: 0 [254720/387873]    Loss: 0.001915   Batch Acc: 90.62
[Train] Epoch: 0 [254848/387873]    Loss: 0.002641   Batch Acc: 82.03
[Train] Epoch: 0 [254976/387873]    Loss: 0.002182   Batch Acc: 88.28
[Train] Epoch: 0 [255104/387873]    Loss: 0.003175   Batch Acc: 78.91
[Train] Epoch: 0 [255232/387873]    Loss: 0.002840   Batch Acc: 79.69
[Train] Epoch: 0 [255360/387873]    Loss: 0.002623   Batch Acc: 87.50
[Train] Epoch: 0 [255488/387873]    Loss: 0.002204   Batch Acc: 88.28
[Train] Epoch: 0 [255616/387873]    Loss: 0.002648   Batch Acc: 82.81
[Train] Epoch: 0 [255744/387873]    Loss: 0.002348   Batch Acc: 89.84
[Train] Epoch: 0 [255872/387873]    Loss: 0.002371   Batch Acc: 89.06
[Train] Epoch: 0 [256000/387873]    Loss: 0.002088   Batch Acc: 89.84
[Train] Epoch: 0 [256128/387873]    Loss: 0.002543   Batch Acc: 88.28
[Train] Epoch: 0 [256256/387873]    Loss: 0.002108   Batch Acc: 89.06
[Train] Epoch: 0 [256384/387873]    Loss: 0.002749   Batch Acc: 85.94
[Train] Epoch: 0 [256512/387873]    Loss: 0.002168   Batch Acc: 86.72
[Train] Epoch: 0 [256640/387873]    Loss: 0.002571   Batch Acc: 85.94
[Train] Epoch: 0 [256768/387873]    Loss: 0.002538   Batch Acc: 84.38
[Train] Epoch: 0 [256896/387873]    Loss: 0.002072   Batch Acc: 92.19
[Train] Epoch: 0 [257024/387873]    Loss: 0.002664   Batch Acc: 86.72
[Train] Epoch: 0 [257152/387873]    Loss: 0.002619   Batch Acc: 86.72
[Train] Epoch: 0 [257280/387873]    Loss: 0.002223   Batch Acc: 89.06
[Train] Epoch: 0 [257408/387873]    Loss: 0.002255   Batch Acc: 87.50
[Train] Epoch: 0 [257536/387873]    Loss: 0.001969   Batch Acc: 92.19
[Train] Epoch: 0 [257664/387873]    Loss: 0.002356   Batch Acc: 87.50
[Train] Epoch: 0 [257792/387873]    Loss: 0.002467   Batch Acc: 82.03
[Train] Epoch: 0 [257920/387873]    Loss: 0.002467   Batch Acc: 86.72
[Train] Epoch: 0 [258048/387873]    Loss: 0.002857   Batch Acc: 84.38
[Train] Epoch: 0 [258176/387873]    Loss: 0.002539   Batch Acc: 84.38
[Train] Epoch: 0 [258304/387873]    Loss: 0.002653   Batch Acc: 84.38
[Train] Epoch: 0 [258432/387873]    Loss: 0.002330   Batch Acc: 87.50
[Train] Epoch: 0 [258560/387873]    Loss: 0.002667   Batch Acc: 86.72
[Train] Epoch: 0 [258688/387873]    Loss: 0.002011   Batch Acc: 89.06
[Train] Epoch: 0 [258816/387873]    Loss: 0.002675   Batch Acc: 85.16
[Train] Epoch: 0 [258944/387873]    Loss: 0.002286   Batch Acc: 85.16
[Train] Epoch: 0 [259072/387873]    Loss: 0.002355   Batch Acc: 88.28
[Train] Epoch: 0 [259200/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 0 [259328/387873]    Loss: 0.002272   Batch Acc: 87.50
[Train] Epoch: 0 [259456/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 0 [259584/387873]    Loss: 0.002023   Batch Acc: 86.72
[Train] Epoch: 0 [259712/387873]    Loss: 0.002216   Batch Acc: 90.62
[Train] Epoch: 0 [259840/387873]    Loss: 0.002263   Batch Acc: 87.50
[Train] Epoch: 0 [259968/387873]    Loss: 0.002575   Batch Acc: 83.59
[Train] Epoch: 0 [260096/387873]    Loss: 0.002722   Batch Acc: 88.28
[Train] Epoch: 0 [260224/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 0 [260352/387873]    Loss: 0.002412   Batch Acc: 87.50
[Train] Epoch: 0 [260480/387873]    Loss: 0.002231   Batch Acc: 89.06
[Train] Epoch: 0 [260608/387873]    Loss: 0.001865   Batch Acc: 92.97
[Train] Epoch: 0 [260736/387873]    Loss: 0.002418   Batch Acc: 88.28
[Train] Epoch: 0 [260864/387873]    Loss: 0.002305   Batch Acc: 89.06
[Train] Epoch: 0 [260992/387873]    Loss: 0.002410   Batch Acc: 87.50
[Train] Epoch: 0 [261120/387873]    Loss: 0.002034   Batch Acc: 92.97
[Train] Epoch: 0 [261248/387873]    Loss: 0.002243   Batch Acc: 90.62
[Train] Epoch: 0 [261376/387873]    Loss: 0.002180   Batch Acc: 88.28
[Train] Epoch: 0 [261504/387873]    Loss: 0.002363   Batch Acc: 89.06
[Train] Epoch: 0 [261632/387873]    Loss: 0.002346   Batch Acc: 88.28
[Train] Epoch: 0 [261760/387873]    Loss: 0.002540   Batch Acc: 86.72
[Train] Epoch: 0 [261888/387873]    Loss: 0.002214   Batch Acc: 86.72
[Train] Epoch: 0 [262016/387873]    Loss: 0.002179   Batch Acc: 91.41
[Train] Epoch: 0 [262144/387873]    Loss: 0.002187   Batch Acc: 88.28
[Train] Epoch: 0 [262272/387873]    Loss: 0.002584   Batch Acc: 85.94
[Train] Epoch: 0 [262400/387873]    Loss: 0.002162   Batch Acc: 85.94
[Train] Epoch: 0 [262528/387873]    Loss: 0.002181   Batch Acc: 89.06
[Train] Epoch: 0 [262656/387873]    Loss: 0.001827   Batch Acc: 90.62
[Train] Epoch: 0 [262784/387873]    Loss: 0.002701   Batch Acc: 85.94
[Train] Epoch: 0 [262912/387873]    Loss: 0.002848   Batch Acc: 84.38
[Train] Epoch: 0 [263040/387873]    Loss: 0.002186   Batch Acc: 88.28
[Train] Epoch: 0 [263168/387873]    Loss: 0.002353   Batch Acc: 86.72
[Train] Epoch: 0 [263296/387873]    Loss: 0.002450   Batch Acc: 84.38
[Train] Epoch: 0 [263424/387873]    Loss: 0.002130   Batch Acc: 87.50
[Train] Epoch: 0 [263552/387873]    Loss: 0.002274   Batch Acc: 87.50
[Train] Epoch: 0 [263680/387873]    Loss: 0.002772   Batch Acc: 81.25
[Train] Epoch: 0 [263808/387873]    Loss: 0.002732   Batch Acc: 87.50
[Train] Epoch: 0 [263936/387873]    Loss: 0.002755   Batch Acc: 86.72
[Train] Epoch: 0 [264064/387873]    Loss: 0.001816   Batch Acc: 91.41
[Train] Epoch: 0 [264192/387873]    Loss: 0.002898   Batch Acc: 87.50
[Train] Epoch: 0 [264320/387873]    Loss: 0.002723   Batch Acc: 85.16
[Train] Epoch: 0 [264448/387873]    Loss: 0.002726   Batch Acc: 87.50
[Train] Epoch: 0 [264576/387873]    Loss: 0.002988   Batch Acc: 81.25
[Train] Epoch: 0 [264704/387873]    Loss: 0.002026   Batch Acc: 89.84
[Train] Epoch: 0 [264832/387873]    Loss: 0.002355   Batch Acc: 85.94
[Train] Epoch: 0 [264960/387873]    Loss: 0.002531   Batch Acc: 86.72
[Train] Epoch: 0 [265088/387873]    Loss: 0.002536   Batch Acc: 83.59
[Train] Epoch: 0 [265216/387873]    Loss: 0.002198   Batch Acc: 89.06
[Train] Epoch: 0 [265344/387873]    Loss: 0.002552   Batch Acc: 88.28
[Train] Epoch: 0 [265472/387873]    Loss: 0.002819   Batch Acc: 85.16
[Train] Epoch: 0 [265600/387873]    Loss: 0.002530   Batch Acc: 87.50
[Train] Epoch: 0 [265728/387873]    Loss: 0.002142   Batch Acc: 89.84
[Train] Epoch: 0 [265856/387873]    Loss: 0.002340   Batch Acc: 86.72
[Train] Epoch: 0 [265984/387873]    Loss: 0.002181   Batch Acc: 88.28
[Train] Epoch: 0 [266112/387873]    Loss: 0.002651   Batch Acc: 85.16
[Train] Epoch: 0 [266240/387873]    Loss: 0.002635   Batch Acc: 83.59
[Train] Epoch: 0 [266368/387873]    Loss: 0.002866   Batch Acc: 85.94
[Train] Epoch: 0 [266496/387873]    Loss: 0.002197   Batch Acc: 87.50
[Train] Epoch: 0 [266624/387873]    Loss: 0.002386   Batch Acc: 85.94
[Train] Epoch: 0 [266752/387873]    Loss: 0.002415   Batch Acc: 85.94
[Train] Epoch: 0 [266880/387873]    Loss: 0.002357   Batch Acc: 86.72
[Train] Epoch: 0 [267008/387873]    Loss: 0.002135   Batch Acc: 89.84
[Train] Epoch: 0 [267136/387873]    Loss: 0.002111   Batch Acc: 89.06
[Train] Epoch: 0 [267264/387873]    Loss: 0.002558   Batch Acc: 83.59
[Train] Epoch: 0 [267392/387873]    Loss: 0.002619   Batch Acc: 87.50
[Train] Epoch: 0 [267520/387873]    Loss: 0.002158   Batch Acc: 87.50
[Train] Epoch: 0 [267648/387873]    Loss: 0.001934   Batch Acc: 88.28
[Train] Epoch: 0 [267776/387873]    Loss: 0.002355   Batch Acc: 85.94
[Train] Epoch: 0 [267904/387873]    Loss: 0.002062   Batch Acc: 89.06
[Train] Epoch: 0 [268032/387873]    Loss: 0.002750   Batch Acc: 85.16
[Train] Epoch: 0 [268160/387873]    Loss: 0.002233   Batch Acc: 86.72
[Train] Epoch: 0 [268288/387873]    Loss: 0.002124   Batch Acc: 89.84
[Train] Epoch: 0 [268416/387873]    Loss: 0.002148   Batch Acc: 88.28
[Train] Epoch: 0 [268544/387873]    Loss: 0.002589   Batch Acc: 83.59
[Train] Epoch: 0 [268672/387873]    Loss: 0.003134   Batch Acc: 78.91
[Train] Epoch: 0 [268800/387873]    Loss: 0.003220   Batch Acc: 81.25
[Train] Epoch: 0 [268928/387873]    Loss: 0.002363   Batch Acc: 85.94
[Train] Epoch: 0 [269056/387873]    Loss: 0.002364   Batch Acc: 89.84
[Train] Epoch: 0 [269184/387873]    Loss: 0.001787   Batch Acc: 92.97
[Train] Epoch: 0 [269312/387873]    Loss: 0.002720   Batch Acc: 82.81
[Train] Epoch: 0 [269440/387873]    Loss: 0.002308   Batch Acc: 88.28
[Train] Epoch: 0 [269568/387873]    Loss: 0.002034   Batch Acc: 89.84
[Train] Epoch: 0 [269696/387873]    Loss: 0.002107   Batch Acc: 89.06
[Train] Epoch: 0 [269824/387873]    Loss: 0.002303   Batch Acc: 89.06
[Train] Epoch: 0 [269952/387873]    Loss: 0.002675   Batch Acc: 86.72
[Train] Epoch: 0 [270080/387873]    Loss: 0.002821   Batch Acc: 79.69
[Train] Epoch: 0 [270208/387873]    Loss: 0.002278   Batch Acc: 84.38
[Train] Epoch: 0 [270336/387873]    Loss: 0.002645   Batch Acc: 85.94
[Train] Epoch: 0 [270464/387873]    Loss: 0.002164   Batch Acc: 89.06
[Train] Epoch: 0 [270592/387873]    Loss: 0.002834   Batch Acc: 83.59
[Train] Epoch: 0 [270720/387873]    Loss: 0.002320   Batch Acc: 83.59
[Train] Epoch: 0 [270848/387873]    Loss: 0.002732   Batch Acc: 82.81
[Train] Epoch: 0 [270976/387873]    Loss: 0.002379   Batch Acc: 88.28
[Train] Epoch: 0 [271104/387873]    Loss: 0.002378   Batch Acc: 90.62
[Train] Epoch: 0 [271232/387873]    Loss: 0.002173   Batch Acc: 90.62
[Train] Epoch: 0 [271360/387873]    Loss: 0.002414   Batch Acc: 88.28
[Train] Epoch: 0 [271488/387873]    Loss: 0.001847   Batch Acc: 89.84
[Train] Epoch: 0 [271616/387873]    Loss: 0.002329   Batch Acc: 89.06
[Train] Epoch: 0 [271744/387873]    Loss: 0.002174   Batch Acc: 88.28
[Train] Epoch: 0 [271872/387873]    Loss: 0.002458   Batch Acc: 87.50
[Train] Epoch: 0 [272000/387873]    Loss: 0.002091   Batch Acc: 89.84
[Train] Epoch: 0 [272128/387873]    Loss: 0.002433   Batch Acc: 87.50
[Train] Epoch: 0 [272256/387873]    Loss: 0.002400   Batch Acc: 88.28
[Train] Epoch: 0 [272384/387873]    Loss: 0.002857   Batch Acc: 83.59
[Train] Epoch: 0 [272512/387873]    Loss: 0.002431   Batch Acc: 85.94
[Train] Epoch: 0 [272640/387873]    Loss: 0.002667   Batch Acc: 85.16
[Train] Epoch: 0 [272768/387873]    Loss: 0.002053   Batch Acc: 87.50
[Train] Epoch: 0 [272896/387873]    Loss: 0.002543   Batch Acc: 88.28
[Train] Epoch: 0 [273024/387873]    Loss: 0.002366   Batch Acc: 90.62
[Train] Epoch: 0 [273152/387873]    Loss: 0.002600   Batch Acc: 85.94
[Train] Epoch: 0 [273280/387873]    Loss: 0.002171   Batch Acc: 88.28
[Train] Epoch: 0 [273408/387873]    Loss: 0.002148   Batch Acc: 89.06
[Train] Epoch: 0 [273536/387873]    Loss: 0.003081   Batch Acc: 78.91
[Train] Epoch: 0 [273664/387873]    Loss: 0.002380   Batch Acc: 89.84
[Train] Epoch: 0 [273792/387873]    Loss: 0.002305   Batch Acc: 89.84
[Train] Epoch: 0 [273920/387873]    Loss: 0.001940   Batch Acc: 89.84
[Train] Epoch: 0 [274048/387873]    Loss: 0.002378   Batch Acc: 87.50
[Train] Epoch: 0 [274176/387873]    Loss: 0.002314   Batch Acc: 86.72
[Train] Epoch: 0 [274304/387873]    Loss: 0.002256   Batch Acc: 88.28
[Train] Epoch: 0 [274432/387873]    Loss: 0.001917   Batch Acc: 92.19
[Train] Epoch: 0 [274560/387873]    Loss: 0.002534   Batch Acc: 86.72
[Train] Epoch: 0 [274688/387873]    Loss: 0.002733   Batch Acc: 85.16
[Train] Epoch: 0 [274816/387873]    Loss: 0.002112   Batch Acc: 86.72
[Train] Epoch: 0 [274944/387873]    Loss: 0.002183   Batch Acc: 86.72
[Train] Epoch: 0 [275072/387873]    Loss: 0.002725   Batch Acc: 85.16
[Train] Epoch: 0 [275200/387873]    Loss: 0.001885   Batch Acc: 91.41
[Train] Epoch: 0 [275328/387873]    Loss: 0.001946   Batch Acc: 91.41
[Train] Epoch: 0 [275456/387873]    Loss: 0.002336   Batch Acc: 89.84
[Train] Epoch: 0 [275584/387873]    Loss: 0.001978   Batch Acc: 89.06
[Train] Epoch: 0 [275712/387873]    Loss: 0.002296   Batch Acc: 85.16
[Train] Epoch: 0 [275840/387873]    Loss: 0.002613   Batch Acc: 84.38
[Train] Epoch: 0 [275968/387873]    Loss: 0.002063   Batch Acc: 90.62
[Train] Epoch: 0 [276096/387873]    Loss: 0.002327   Batch Acc: 89.06
[Train] Epoch: 0 [276224/387873]    Loss: 0.002393   Batch Acc: 85.16
[Train] Epoch: 0 [276352/387873]    Loss: 0.002155   Batch Acc: 89.84
[Train] Epoch: 0 [276480/387873]    Loss: 0.002772   Batch Acc: 82.81
[Train] Epoch: 0 [276608/387873]    Loss: 0.002051   Batch Acc: 91.41
[Train] Epoch: 0 [276736/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 0 [276864/387873]    Loss: 0.002464   Batch Acc: 89.06
[Train] Epoch: 0 [276992/387873]    Loss: 0.001994   Batch Acc: 92.19
[Train] Epoch: 0 [277120/387873]    Loss: 0.002019   Batch Acc: 86.72
[Train] Epoch: 0 [277248/387873]    Loss: 0.002639   Batch Acc: 87.50
[Train] Epoch: 0 [277376/387873]    Loss: 0.002649   Batch Acc: 89.06
[Train] Epoch: 0 [277504/387873]    Loss: 0.002609   Batch Acc: 86.72
[Train] Epoch: 0 [277632/387873]    Loss: 0.002567   Batch Acc: 85.16
[Train] Epoch: 0 [277760/387873]    Loss: 0.002052   Batch Acc: 88.28
[Train] Epoch: 0 [277888/387873]    Loss: 0.002896   Batch Acc: 85.16
[Train] Epoch: 0 [278016/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 0 [278144/387873]    Loss: 0.002154   Batch Acc: 88.28
[Train] Epoch: 0 [278272/387873]    Loss: 0.002771   Batch Acc: 83.59
[Train] Epoch: 0 [278400/387873]    Loss: 0.002708   Batch Acc: 85.16
[Train] Epoch: 0 [278528/387873]    Loss: 0.002068   Batch Acc: 89.84
[Train] Epoch: 0 [278656/387873]    Loss: 0.001935   Batch Acc: 92.97
[Train] Epoch: 0 [278784/387873]    Loss: 0.002375   Batch Acc: 88.28
[Train] Epoch: 0 [278912/387873]    Loss: 0.002263   Batch Acc: 88.28
[Train] Epoch: 0 [279040/387873]    Loss: 0.002228   Batch Acc: 87.50
[Train] Epoch: 0 [279168/387873]    Loss: 0.002325   Batch Acc: 85.94
[Train] Epoch: 0 [279296/387873]    Loss: 0.002977   Batch Acc: 82.81
[Train] Epoch: 0 [279424/387873]    Loss: 0.002106   Batch Acc: 90.62
[Train] Epoch: 0 [279552/387873]    Loss: 0.002344   Batch Acc: 88.28
[Train] Epoch: 0 [279680/387873]    Loss: 0.002291   Batch Acc: 85.94
[Train] Epoch: 0 [279808/387873]    Loss: 0.002404   Batch Acc: 87.50
[Train] Epoch: 0 [279936/387873]    Loss: 0.002265   Batch Acc: 85.94
[Train] Epoch: 0 [280064/387873]    Loss: 0.002290   Batch Acc: 85.94
[Train] Epoch: 0 [280192/387873]    Loss: 0.002153   Batch Acc: 90.62
[Train] Epoch: 0 [280320/387873]    Loss: 0.002387   Batch Acc: 86.72
[Train] Epoch: 0 [280448/387873]    Loss: 0.002628   Batch Acc: 82.81
[Train] Epoch: 0 [280576/387873]    Loss: 0.002395   Batch Acc: 86.72
[Train] Epoch: 0 [280704/387873]    Loss: 0.002175   Batch Acc: 89.84
[Train] Epoch: 0 [280832/387873]    Loss: 0.003127   Batch Acc: 84.38
[Train] Epoch: 0 [280960/387873]    Loss: 0.001738   Batch Acc: 92.97
[Train] Epoch: 0 [281088/387873]    Loss: 0.002513   Batch Acc: 84.38
[Train] Epoch: 0 [281216/387873]    Loss: 0.001933   Batch Acc: 91.41
[Train] Epoch: 0 [281344/387873]    Loss: 0.002265   Batch Acc: 86.72
[Train] Epoch: 0 [281472/387873]    Loss: 0.002603   Batch Acc: 86.72
[Train] Epoch: 0 [281600/387873]    Loss: 0.001823   Batch Acc: 91.41
[Train] Epoch: 0 [281728/387873]    Loss: 0.002200   Batch Acc: 91.41
[Train] Epoch: 0 [281856/387873]    Loss: 0.002637   Batch Acc: 85.94
[Train] Epoch: 0 [281984/387873]    Loss: 0.001515   Batch Acc: 96.09
[Train] Epoch: 0 [282112/387873]    Loss: 0.002313   Batch Acc: 89.06
[Train] Epoch: 0 [282240/387873]    Loss: 0.002664   Batch Acc: 85.16
[Train] Epoch: 0 [282368/387873]    Loss: 0.002274   Batch Acc: 86.72
[Train] Epoch: 0 [282496/387873]    Loss: 0.002550   Batch Acc: 86.72
[Train] Epoch: 0 [282624/387873]    Loss: 0.002044   Batch Acc: 88.28
[Train] Epoch: 0 [282752/387873]    Loss: 0.002350   Batch Acc: 87.50
[Train] Epoch: 0 [282880/387873]    Loss: 0.002168   Batch Acc: 89.06
[Train] Epoch: 0 [283008/387873]    Loss: 0.002822   Batch Acc: 83.59
[Train] Epoch: 0 [283136/387873]    Loss: 0.003223   Batch Acc: 82.03
[Train] Epoch: 0 [283264/387873]    Loss: 0.001864   Batch Acc: 92.97
[Train] Epoch: 0 [283392/387873]    Loss: 0.002105   Batch Acc: 89.06
[Train] Epoch: 0 [283520/387873]    Loss: 0.002615   Batch Acc: 87.50
[Train] Epoch: 0 [283648/387873]    Loss: 0.002086   Batch Acc: 91.41
[Train] Epoch: 0 [283776/387873]    Loss: 0.001903   Batch Acc: 92.19
[Train] Epoch: 0 [283904/387873]    Loss: 0.002303   Batch Acc: 90.62
[Train] Epoch: 0 [284032/387873]    Loss: 0.001289   Batch Acc: 96.88
[Train] Epoch: 0 [284160/387873]    Loss: 0.002705   Batch Acc: 83.59
[Train] Epoch: 0 [284288/387873]    Loss: 0.002221   Batch Acc: 89.06
[Train] Epoch: 0 [284416/387873]    Loss: 0.002154   Batch Acc: 86.72
[Train] Epoch: 0 [284544/387873]    Loss: 0.002845   Batch Acc: 86.72
[Train] Epoch: 0 [284672/387873]    Loss: 0.002029   Batch Acc: 90.62
[Train] Epoch: 0 [284800/387873]    Loss: 0.002191   Batch Acc: 89.06
[Train] Epoch: 0 [284928/387873]    Loss: 0.002409   Batch Acc: 89.06
[Train] Epoch: 0 [285056/387873]    Loss: 0.002659   Batch Acc: 85.16
[Train] Epoch: 0 [285184/387873]    Loss: 0.001512   Batch Acc: 95.31
[Train] Epoch: 0 [285312/387873]    Loss: 0.002232   Batch Acc: 88.28
[Train] Epoch: 0 [285440/387873]    Loss: 0.001853   Batch Acc: 92.97
[Train] Epoch: 0 [285568/387873]    Loss: 0.002120   Batch Acc: 89.84
[Train] Epoch: 0 [285696/387873]    Loss: 0.002318   Batch Acc: 87.50
[Train] Epoch: 0 [285824/387873]    Loss: 0.002496   Batch Acc: 83.59
[Train] Epoch: 0 [285952/387873]    Loss: 0.002484   Batch Acc: 87.50
[Train] Epoch: 0 [286080/387873]    Loss: 0.002752   Batch Acc: 86.72
[Train] Epoch: 0 [286208/387873]    Loss: 0.001863   Batch Acc: 89.84
[Train] Epoch: 0 [286336/387873]    Loss: 0.002719   Batch Acc: 84.38
[Train] Epoch: 0 [286464/387873]    Loss: 0.002141   Batch Acc: 89.84
[Train] Epoch: 0 [286592/387873]    Loss: 0.002792   Batch Acc: 84.38
[Train] Epoch: 0 [286720/387873]    Loss: 0.002061   Batch Acc: 92.19
[Train] Epoch: 0 [286848/387873]    Loss: 0.002320   Batch Acc: 87.50
[Train] Epoch: 0 [286976/387873]    Loss: 0.002863   Batch Acc: 84.38
[Train] Epoch: 0 [287104/387873]    Loss: 0.002281   Batch Acc: 87.50
[Train] Epoch: 0 [287232/387873]    Loss: 0.002441   Batch Acc: 85.16
[Train] Epoch: 0 [287360/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 0 [287488/387873]    Loss: 0.002453   Batch Acc: 86.72
[Train] Epoch: 0 [287616/387873]    Loss: 0.002619   Batch Acc: 85.16
[Train] Epoch: 0 [287744/387873]    Loss: 0.002251   Batch Acc: 90.62
[Train] Epoch: 0 [287872/387873]    Loss: 0.002605   Batch Acc: 85.16
[Train] Epoch: 0 [288000/387873]    Loss: 0.002196   Batch Acc: 86.72
[Train] Epoch: 0 [288128/387873]    Loss: 0.002269   Batch Acc: 84.38
[Train] Epoch: 0 [288256/387873]    Loss: 0.002357   Batch Acc: 85.16
[Train] Epoch: 0 [288384/387873]    Loss: 0.002367   Batch Acc: 85.94
[Train] Epoch: 0 [288512/387873]    Loss: 0.002061   Batch Acc: 89.06
[Train] Epoch: 0 [288640/387873]    Loss: 0.002222   Batch Acc: 88.28
[Train] Epoch: 0 [288768/387873]    Loss: 0.002128   Batch Acc: 90.62
[Train] Epoch: 0 [288896/387873]    Loss: 0.002323   Batch Acc: 87.50
[Train] Epoch: 0 [289024/387873]    Loss: 0.002052   Batch Acc: 89.06
[Train] Epoch: 0 [289152/387873]    Loss: 0.002330   Batch Acc: 88.28
[Train] Epoch: 0 [289280/387873]    Loss: 0.002651   Batch Acc: 83.59
[Train] Epoch: 0 [289408/387873]    Loss: 0.002270   Batch Acc: 87.50
[Train] Epoch: 0 [289536/387873]    Loss: 0.002736   Batch Acc: 82.81
[Train] Epoch: 0 [289664/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 0 [289792/387873]    Loss: 0.002282   Batch Acc: 86.72
[Train] Epoch: 0 [289920/387873]    Loss: 0.002077   Batch Acc: 88.28
[Train] Epoch: 0 [290048/387873]    Loss: 0.002103   Batch Acc: 87.50
[Train] Epoch: 0 [290176/387873]    Loss: 0.002088   Batch Acc: 91.41
[Train] Epoch: 0 [290304/387873]    Loss: 0.002036   Batch Acc: 92.19
[Train] Epoch: 0 [290432/387873]    Loss: 0.002495   Batch Acc: 82.81
[Train] Epoch: 0 [290560/387873]    Loss: 0.002481   Batch Acc: 88.28
[Train] Epoch: 0 [290688/387873]    Loss: 0.002343   Batch Acc: 88.28
[Train] Epoch: 0 [290816/387873]    Loss: 0.002963   Batch Acc: 82.81
[Train] Epoch: 0 [290944/387873]    Loss: 0.002702   Batch Acc: 85.94
[Train] Epoch: 0 [291072/387873]    Loss: 0.002155   Batch Acc: 88.28
[Train] Epoch: 0 [291200/387873]    Loss: 0.002575   Batch Acc: 85.16
[Train] Epoch: 0 [291328/387873]    Loss: 0.002763   Batch Acc: 83.59
[Train] Epoch: 0 [291456/387873]    Loss: 0.002894   Batch Acc: 81.25
[Train] Epoch: 0 [291584/387873]    Loss: 0.002252   Batch Acc: 89.84
[Train] Epoch: 0 [291712/387873]    Loss: 0.002824   Batch Acc: 85.16
[Train] Epoch: 0 [291840/387873]    Loss: 0.002216   Batch Acc: 87.50
[Train] Epoch: 0 [291968/387873]    Loss: 0.001933   Batch Acc: 89.06
[Train] Epoch: 0 [292096/387873]    Loss: 0.002467   Batch Acc: 83.59
[Train] Epoch: 0 [292224/387873]    Loss: 0.002827   Batch Acc: 84.38
[Train] Epoch: 0 [292352/387873]    Loss: 0.001995   Batch Acc: 89.06
[Train] Epoch: 0 [292480/387873]    Loss: 0.002484   Batch Acc: 85.94
[Train] Epoch: 0 [292608/387873]    Loss: 0.002264   Batch Acc: 89.06
[Train] Epoch: 0 [292736/387873]    Loss: 0.001952   Batch Acc: 92.19
[Train] Epoch: 0 [292864/387873]    Loss: 0.002582   Batch Acc: 85.94
[Train] Epoch: 0 [292992/387873]    Loss: 0.002982   Batch Acc: 82.81
[Train] Epoch: 0 [293120/387873]    Loss: 0.002436   Batch Acc: 87.50
[Train] Epoch: 0 [293248/387873]    Loss: 0.002477   Batch Acc: 87.50
[Train] Epoch: 0 [293376/387873]    Loss: 0.002192   Batch Acc: 89.84
[Train] Epoch: 0 [293504/387873]    Loss: 0.001666   Batch Acc: 95.31
[Train] Epoch: 0 [293632/387873]    Loss: 0.002258   Batch Acc: 89.06
[Train] Epoch: 0 [293760/387873]    Loss: 0.002591   Batch Acc: 85.94
[Train] Epoch: 0 [293888/387873]    Loss: 0.002651   Batch Acc: 85.16
[Train] Epoch: 0 [294016/387873]    Loss: 0.002000   Batch Acc: 90.62
[Train] Epoch: 0 [294144/387873]    Loss: 0.002549   Batch Acc: 85.16
[Train] Epoch: 0 [294272/387873]    Loss: 0.003031   Batch Acc: 82.03
[Train] Epoch: 0 [294400/387873]    Loss: 0.002213   Batch Acc: 89.84
[Train] Epoch: 0 [294528/387873]    Loss: 0.001829   Batch Acc: 92.19
[Train] Epoch: 0 [294656/387873]    Loss: 0.002344   Batch Acc: 89.06
[Train] Epoch: 0 [294784/387873]    Loss: 0.002626   Batch Acc: 83.59
[Train] Epoch: 0 [294912/387873]    Loss: 0.002480   Batch Acc: 85.16
[Train] Epoch: 0 [295040/387873]    Loss: 0.001934   Batch Acc: 87.50
[Train] Epoch: 0 [295168/387873]    Loss: 0.002403   Batch Acc: 89.84
[Train] Epoch: 0 [295296/387873]    Loss: 0.002075   Batch Acc: 87.50
[Train] Epoch: 0 [295424/387873]    Loss: 0.001838   Batch Acc: 92.19
[Train] Epoch: 0 [295552/387873]    Loss: 0.002693   Batch Acc: 82.03
[Train] Epoch: 0 [295680/387873]    Loss: 0.002136   Batch Acc: 89.84
[Train] Epoch: 0 [295808/387873]    Loss: 0.002335   Batch Acc: 88.28
[Train] Epoch: 0 [295936/387873]    Loss: 0.002139   Batch Acc: 88.28
[Train] Epoch: 0 [296064/387873]    Loss: 0.002621   Batch Acc: 85.94
[Train] Epoch: 0 [296192/387873]    Loss: 0.002539   Batch Acc: 84.38
[Train] Epoch: 0 [296320/387873]    Loss: 0.003071   Batch Acc: 81.25
[Train] Epoch: 0 [296448/387873]    Loss: 0.002295   Batch Acc: 88.28
[Train] Epoch: 0 [296576/387873]    Loss: 0.002038   Batch Acc: 89.84
[Train] Epoch: 0 [296704/387873]    Loss: 0.001884   Batch Acc: 93.75
[Train] Epoch: 0 [296832/387873]    Loss: 0.002328   Batch Acc: 89.06
[Train] Epoch: 0 [296960/387873]    Loss: 0.003094   Batch Acc: 84.38
[Train] Epoch: 0 [297088/387873]    Loss: 0.002385   Batch Acc: 89.06
[Train] Epoch: 0 [297216/387873]    Loss: 0.002443   Batch Acc: 86.72
[Train] Epoch: 0 [297344/387873]    Loss: 0.002737   Batch Acc: 86.72
[Train] Epoch: 0 [297472/387873]    Loss: 0.002156   Batch Acc: 89.06
[Train] Epoch: 0 [297600/387873]    Loss: 0.001837   Batch Acc: 92.97
[Train] Epoch: 0 [297728/387873]    Loss: 0.002310   Batch Acc: 89.06
[Train] Epoch: 0 [297856/387873]    Loss: 0.002159   Batch Acc: 87.50
[Train] Epoch: 0 [297984/387873]    Loss: 0.002778   Batch Acc: 82.81
[Train] Epoch: 0 [298112/387873]    Loss: 0.002398   Batch Acc: 89.06
[Train] Epoch: 0 [298240/387873]    Loss: 0.002305   Batch Acc: 89.06
[Train] Epoch: 0 [298368/387873]    Loss: 0.002146   Batch Acc: 91.41
[Train] Epoch: 0 [298496/387873]    Loss: 0.002371   Batch Acc: 85.94
[Train] Epoch: 0 [298624/387873]    Loss: 0.002072   Batch Acc: 89.06
[Train] Epoch: 0 [298752/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 0 [298880/387873]    Loss: 0.002334   Batch Acc: 88.28
[Train] Epoch: 0 [299008/387873]    Loss: 0.002697   Batch Acc: 85.94
[Train] Epoch: 0 [299136/387873]    Loss: 0.002246   Batch Acc: 85.16
[Train] Epoch: 0 [299264/387873]    Loss: 0.001953   Batch Acc: 89.84
[Train] Epoch: 0 [299392/387873]    Loss: 0.002899   Batch Acc: 83.59
[Train] Epoch: 0 [299520/387873]    Loss: 0.002785   Batch Acc: 83.59
[Train] Epoch: 0 [299648/387873]    Loss: 0.002513   Batch Acc: 87.50
[Train] Epoch: 0 [299776/387873]    Loss: 0.002084   Batch Acc: 88.28
[Train] Epoch: 0 [299904/387873]    Loss: 0.001876   Batch Acc: 89.06
[Train] Epoch: 0 [300032/387873]    Loss: 0.001943   Batch Acc: 87.50
[Train] Epoch: 0 [300160/387873]    Loss: 0.002952   Batch Acc: 82.81
[Train] Epoch: 0 [300288/387873]    Loss: 0.002463   Batch Acc: 84.38
[Train] Epoch: 0 [300416/387873]    Loss: 0.002134   Batch Acc: 89.06
[Train] Epoch: 0 [300544/387873]    Loss: 0.002266   Batch Acc: 89.84
[Train] Epoch: 0 [300672/387873]    Loss: 0.001626   Batch Acc: 93.75
[Train] Epoch: 0 [300800/387873]    Loss: 0.001939   Batch Acc: 90.62
[Train] Epoch: 0 [300928/387873]    Loss: 0.003020   Batch Acc: 81.25
[Train] Epoch: 0 [301056/387873]    Loss: 0.002248   Batch Acc: 86.72
[Train] Epoch: 0 [301184/387873]    Loss: 0.002439   Batch Acc: 86.72
[Train] Epoch: 0 [301312/387873]    Loss: 0.002017   Batch Acc: 88.28
[Train] Epoch: 0 [301440/387873]    Loss: 0.002459   Batch Acc: 86.72
[Train] Epoch: 0 [301568/387873]    Loss: 0.002320   Batch Acc: 86.72
[Train] Epoch: 0 [301696/387873]    Loss: 0.002346   Batch Acc: 85.16
[Train] Epoch: 0 [301824/387873]    Loss: 0.002967   Batch Acc: 83.59
[Train] Epoch: 0 [301952/387873]    Loss: 0.001827   Batch Acc: 91.41
[Train] Epoch: 0 [302080/387873]    Loss: 0.002024   Batch Acc: 91.41
[Train] Epoch: 0 [302208/387873]    Loss: 0.002189   Batch Acc: 89.84
[Train] Epoch: 0 [302336/387873]    Loss: 0.002862   Batch Acc: 82.81
[Train] Epoch: 0 [302464/387873]    Loss: 0.001700   Batch Acc: 94.53
[Train] Epoch: 0 [302592/387873]    Loss: 0.002529   Batch Acc: 87.50
[Train] Epoch: 0 [302720/387873]    Loss: 0.002358   Batch Acc: 88.28
[Train] Epoch: 0 [302848/387873]    Loss: 0.001903   Batch Acc: 92.19
[Train] Epoch: 0 [302976/387873]    Loss: 0.002744   Batch Acc: 82.03
[Train] Epoch: 0 [303104/387873]    Loss: 0.002443   Batch Acc: 86.72
[Train] Epoch: 0 [303232/387873]    Loss: 0.002481   Batch Acc: 86.72
[Train] Epoch: 0 [303360/387873]    Loss: 0.002763   Batch Acc: 84.38
[Train] Epoch: 0 [303488/387873]    Loss: 0.003021   Batch Acc: 82.03
[Train] Epoch: 0 [303616/387873]    Loss: 0.002072   Batch Acc: 88.28
[Train] Epoch: 0 [303744/387873]    Loss: 0.001829   Batch Acc: 92.97
[Train] Epoch: 0 [303872/387873]    Loss: 0.002533   Batch Acc: 85.16
[Train] Epoch: 0 [304000/387873]    Loss: 0.002126   Batch Acc: 88.28
[Train] Epoch: 0 [304128/387873]    Loss: 0.002112   Batch Acc: 90.62
[Train] Epoch: 0 [304256/387873]    Loss: 0.002439   Batch Acc: 86.72
[Train] Epoch: 0 [304384/387873]    Loss: 0.002472   Batch Acc: 89.84
[Train] Epoch: 0 [304512/387873]    Loss: 0.002214   Batch Acc: 89.06
[Train] Epoch: 0 [304640/387873]    Loss: 0.001764   Batch Acc: 90.62
[Train] Epoch: 0 [304768/387873]    Loss: 0.002818   Batch Acc: 83.59
[Train] Epoch: 0 [304896/387873]    Loss: 0.002290   Batch Acc: 89.06
[Train] Epoch: 0 [305024/387873]    Loss: 0.002406   Batch Acc: 85.16
[Train] Epoch: 0 [305152/387873]    Loss: 0.002332   Batch Acc: 87.50
[Train] Epoch: 0 [305280/387873]    Loss: 0.002176   Batch Acc: 90.62
[Train] Epoch: 0 [305408/387873]    Loss: 0.002448   Batch Acc: 89.84
[Train] Epoch: 0 [305536/387873]    Loss: 0.002142   Batch Acc: 90.62
[Train] Epoch: 0 [305664/387873]    Loss: 0.002343   Batch Acc: 85.94
[Train] Epoch: 0 [305792/387873]    Loss: 0.003351   Batch Acc: 81.25
[Train] Epoch: 0 [305920/387873]    Loss: 0.001786   Batch Acc: 94.53
[Train] Epoch: 0 [306048/387873]    Loss: 0.002188   Batch Acc: 90.62
[Train] Epoch: 0 [306176/387873]    Loss: 0.002211   Batch Acc: 89.06
[Train] Epoch: 0 [306304/387873]    Loss: 0.001954   Batch Acc: 92.19
[Train] Epoch: 0 [306432/387873]    Loss: 0.002111   Batch Acc: 90.62
[Train] Epoch: 0 [306560/387873]    Loss: 0.002954   Batch Acc: 84.38
[Train] Epoch: 0 [306688/387873]    Loss: 0.001609   Batch Acc: 92.97
[Train] Epoch: 0 [306816/387873]    Loss: 0.002365   Batch Acc: 87.50
[Train] Epoch: 0 [306944/387873]    Loss: 0.002210   Batch Acc: 88.28
[Train] Epoch: 0 [307072/387873]    Loss: 0.001739   Batch Acc: 92.19
[Train] Epoch: 0 [307200/387873]    Loss: 0.002077   Batch Acc: 91.41
[Train] Epoch: 0 [307328/387873]    Loss: 0.002103   Batch Acc: 88.28
[Train] Epoch: 0 [307456/387873]    Loss: 0.002204   Batch Acc: 87.50
[Train] Epoch: 0 [307584/387873]    Loss: 0.002492   Batch Acc: 81.25
[Train] Epoch: 0 [307712/387873]    Loss: 0.002485   Batch Acc: 87.50
[Train] Epoch: 0 [307840/387873]    Loss: 0.002357   Batch Acc: 91.41
[Train] Epoch: 0 [307968/387873]    Loss: 0.002151   Batch Acc: 90.62
[Train] Epoch: 0 [308096/387873]    Loss: 0.002194   Batch Acc: 85.94
[Train] Epoch: 0 [308224/387873]    Loss: 0.002408   Batch Acc: 87.50
[Train] Epoch: 0 [308352/387873]    Loss: 0.001785   Batch Acc: 90.62
[Train] Epoch: 0 [308480/387873]    Loss: 0.001928   Batch Acc: 92.19
[Train] Epoch: 0 [308608/387873]    Loss: 0.002327   Batch Acc: 86.72
[Train] Epoch: 0 [308736/387873]    Loss: 0.001937   Batch Acc: 88.28
[Train] Epoch: 0 [308864/387873]    Loss: 0.001997   Batch Acc: 91.41
[Train] Epoch: 0 [308992/387873]    Loss: 0.002471   Batch Acc: 87.50
[Train] Epoch: 0 [309120/387873]    Loss: 0.002139   Batch Acc: 87.50
[Train] Epoch: 0 [309248/387873]    Loss: 0.002070   Batch Acc: 90.62
[Train] Epoch: 0 [309376/387873]    Loss: 0.002362   Batch Acc: 84.38
[Train] Epoch: 0 [309504/387873]    Loss: 0.002295   Batch Acc: 87.50
[Train] Epoch: 0 [309632/387873]    Loss: 0.003265   Batch Acc: 82.81
[Train] Epoch: 0 [309760/387873]    Loss: 0.001942   Batch Acc: 90.62
[Train] Epoch: 0 [309888/387873]    Loss: 0.002423   Batch Acc: 89.06
[Train] Epoch: 0 [310016/387873]    Loss: 0.001788   Batch Acc: 92.97
[Train] Epoch: 0 [310144/387873]    Loss: 0.002886   Batch Acc: 84.38
[Train] Epoch: 0 [310272/387873]    Loss: 0.001658   Batch Acc: 92.97
[Train] Epoch: 0 [310400/387873]    Loss: 0.002416   Batch Acc: 88.28
[Train] Epoch: 0 [310528/387873]    Loss: 0.002179   Batch Acc: 86.72
[Train] Epoch: 0 [310656/387873]    Loss: 0.002451   Batch Acc: 87.50
[Train] Epoch: 0 [310784/387873]    Loss: 0.002894   Batch Acc: 84.38
[Train] Epoch: 0 [310912/387873]    Loss: 0.002399   Batch Acc: 87.50
[Train] Epoch: 0 [311040/387873]    Loss: 0.002117   Batch Acc: 89.06
[Train] Epoch: 0 [311168/387873]    Loss: 0.002039   Batch Acc: 89.84
[Train] Epoch: 0 [311296/387873]    Loss: 0.002884   Batch Acc: 82.81
[Train] Epoch: 0 [311424/387873]    Loss: 0.002388   Batch Acc: 85.94
[Train] Epoch: 0 [311552/387873]    Loss: 0.002444   Batch Acc: 87.50
[Train] Epoch: 0 [311680/387873]    Loss: 0.002418   Batch Acc: 84.38
[Train] Epoch: 0 [311808/387873]    Loss: 0.002473   Batch Acc: 85.94
[Train] Epoch: 0 [311936/387873]    Loss: 0.002388   Batch Acc: 83.59
[Train] Epoch: 0 [312064/387873]    Loss: 0.002783   Batch Acc: 84.38
[Train] Epoch: 0 [312192/387873]    Loss: 0.001497   Batch Acc: 94.53
[Train] Epoch: 0 [312320/387873]    Loss: 0.002410   Batch Acc: 83.59
[Train] Epoch: 0 [312448/387873]    Loss: 0.002173   Batch Acc: 89.84
[Train] Epoch: 0 [312576/387873]    Loss: 0.002481   Batch Acc: 85.94
[Train] Epoch: 0 [312704/387873]    Loss: 0.002494   Batch Acc: 86.72
[Train] Epoch: 0 [312832/387873]    Loss: 0.002150   Batch Acc: 88.28
[Train] Epoch: 0 [312960/387873]    Loss: 0.002724   Batch Acc: 85.94
[Train] Epoch: 0 [313088/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 0 [313216/387873]    Loss: 0.001909   Batch Acc: 90.62
[Train] Epoch: 0 [313344/387873]    Loss: 0.002725   Batch Acc: 85.16
[Train] Epoch: 0 [313472/387873]    Loss: 0.002277   Batch Acc: 86.72
[Train] Epoch: 0 [313600/387873]    Loss: 0.002366   Batch Acc: 85.94
[Train] Epoch: 0 [313728/387873]    Loss: 0.002155   Batch Acc: 88.28
[Train] Epoch: 0 [313856/387873]    Loss: 0.002706   Batch Acc: 82.81
[Train] Epoch: 0 [313984/387873]    Loss: 0.002814   Batch Acc: 85.16
[Train] Epoch: 0 [314112/387873]    Loss: 0.002620   Batch Acc: 83.59
[Train] Epoch: 0 [314240/387873]    Loss: 0.001848   Batch Acc: 89.84
[Train] Epoch: 0 [314368/387873]    Loss: 0.001889   Batch Acc: 91.41
[Train] Epoch: 0 [314496/387873]    Loss: 0.001957   Batch Acc: 91.41
[Train] Epoch: 0 [314624/387873]    Loss: 0.002086   Batch Acc: 88.28
[Train] Epoch: 0 [314752/387873]    Loss: 0.002321   Batch Acc: 88.28
[Train] Epoch: 0 [314880/387873]    Loss: 0.002389   Batch Acc: 86.72
[Train] Epoch: 0 [315008/387873]    Loss: 0.002414   Batch Acc: 86.72
[Train] Epoch: 0 [315136/387873]    Loss: 0.001981   Batch Acc: 90.62
[Train] Epoch: 0 [315264/387873]    Loss: 0.002584   Batch Acc: 85.16
[Train] Epoch: 0 [315392/387873]    Loss: 0.002400   Batch Acc: 86.72
[Train] Epoch: 0 [315520/387873]    Loss: 0.001729   Batch Acc: 92.19
[Train] Epoch: 0 [315648/387873]    Loss: 0.001940   Batch Acc: 91.41
[Train] Epoch: 0 [315776/387873]    Loss: 0.002230   Batch Acc: 86.72
[Train] Epoch: 0 [315904/387873]    Loss: 0.002839   Batch Acc: 82.03
[Train] Epoch: 0 [316032/387873]    Loss: 0.002735   Batch Acc: 83.59
[Train] Epoch: 0 [316160/387873]    Loss: 0.002606   Batch Acc: 86.72
[Train] Epoch: 0 [316288/387873]    Loss: 0.002275   Batch Acc: 89.84
[Train] Epoch: 0 [316416/387873]    Loss: 0.002146   Batch Acc: 89.06
[Train] Epoch: 0 [316544/387873]    Loss: 0.002158   Batch Acc: 86.72
[Train] Epoch: 0 [316672/387873]    Loss: 0.002173   Batch Acc: 89.06
[Train] Epoch: 0 [316800/387873]    Loss: 0.002833   Batch Acc: 85.16
[Train] Epoch: 0 [316928/387873]    Loss: 0.001928   Batch Acc: 89.06
[Train] Epoch: 0 [317056/387873]    Loss: 0.002307   Batch Acc: 89.84
[Train] Epoch: 0 [317184/387873]    Loss: 0.002046   Batch Acc: 90.62
[Train] Epoch: 0 [317312/387873]    Loss: 0.002066   Batch Acc: 91.41
[Train] Epoch: 0 [317440/387873]    Loss: 0.002008   Batch Acc: 90.62
[Train] Epoch: 0 [317568/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 0 [317696/387873]    Loss: 0.001795   Batch Acc: 91.41
[Train] Epoch: 0 [317824/387873]    Loss: 0.001912   Batch Acc: 93.75
[Train] Epoch: 0 [317952/387873]    Loss: 0.002402   Batch Acc: 88.28
[Train] Epoch: 0 [318080/387873]    Loss: 0.002105   Batch Acc: 85.16
[Train] Epoch: 0 [318208/387873]    Loss: 0.002562   Batch Acc: 89.06
[Train] Epoch: 0 [318336/387873]    Loss: 0.002148   Batch Acc: 89.06
[Train] Epoch: 0 [318464/387873]    Loss: 0.002222   Batch Acc: 92.19
[Train] Epoch: 0 [318592/387873]    Loss: 0.001957   Batch Acc: 92.19
[Train] Epoch: 0 [318720/387873]    Loss: 0.001784   Batch Acc: 92.19
[Train] Epoch: 0 [318848/387873]    Loss: 0.002696   Batch Acc: 86.72
[Train] Epoch: 0 [318976/387873]    Loss: 0.001823   Batch Acc: 90.62
[Train] Epoch: 0 [319104/387873]    Loss: 0.002083   Batch Acc: 90.62
[Train] Epoch: 0 [319232/387873]    Loss: 0.001695   Batch Acc: 92.97
[Train] Epoch: 0 [319360/387873]    Loss: 0.002248   Batch Acc: 85.94
[Train] Epoch: 0 [319488/387873]    Loss: 0.002218   Batch Acc: 88.28
[Train] Epoch: 0 [319616/387873]    Loss: 0.002489   Batch Acc: 89.06
[Train] Epoch: 0 [319744/387873]    Loss: 0.001719   Batch Acc: 91.41
[Train] Epoch: 0 [319872/387873]    Loss: 0.001706   Batch Acc: 92.97
[Train] Epoch: 0 [320000/387873]    Loss: 0.002526   Batch Acc: 83.59
[Train] Epoch: 0 [320128/387873]    Loss: 0.002177   Batch Acc: 91.41
[Train] Epoch: 0 [320256/387873]    Loss: 0.002825   Batch Acc: 82.81
[Train] Epoch: 0 [320384/387873]    Loss: 0.002016   Batch Acc: 90.62
[Train] Epoch: 0 [320512/387873]    Loss: 0.002168   Batch Acc: 85.94
[Train] Epoch: 0 [320640/387873]    Loss: 0.002112   Batch Acc: 88.28
[Train] Epoch: 0 [320768/387873]    Loss: 0.002362   Batch Acc: 88.28
[Train] Epoch: 0 [320896/387873]    Loss: 0.002138   Batch Acc: 89.06
[Train] Epoch: 0 [321024/387873]    Loss: 0.002037   Batch Acc: 85.94
[Train] Epoch: 0 [321152/387873]    Loss: 0.002395   Batch Acc: 88.28
[Train] Epoch: 0 [321280/387873]    Loss: 0.002276   Batch Acc: 88.28
[Train] Epoch: 0 [321408/387873]    Loss: 0.002473   Batch Acc: 88.28
[Train] Epoch: 0 [321536/387873]    Loss: 0.002478   Batch Acc: 84.38
[Train] Epoch: 0 [321664/387873]    Loss: 0.002132   Batch Acc: 88.28
[Train] Epoch: 0 [321792/387873]    Loss: 0.001910   Batch Acc: 92.19
[Train] Epoch: 0 [321920/387873]    Loss: 0.002409   Batch Acc: 89.84
[Train] Epoch: 0 [322048/387873]    Loss: 0.001643   Batch Acc: 90.62
[Train] Epoch: 0 [322176/387873]    Loss: 0.001910   Batch Acc: 92.19
[Train] Epoch: 0 [322304/387873]    Loss: 0.002210   Batch Acc: 89.06
[Train] Epoch: 0 [322432/387873]    Loss: 0.002461   Batch Acc: 85.16
[Train] Epoch: 0 [322560/387873]    Loss: 0.002146   Batch Acc: 87.50
[Train] Epoch: 0 [322688/387873]    Loss: 0.002018   Batch Acc: 90.62
[Train] Epoch: 0 [322816/387873]    Loss: 0.002084   Batch Acc: 90.62
[Train] Epoch: 0 [322944/387873]    Loss: 0.001983   Batch Acc: 87.50
[Train] Epoch: 0 [323072/387873]    Loss: 0.002439   Batch Acc: 85.16
[Train] Epoch: 0 [323200/387873]    Loss: 0.001749   Batch Acc: 92.97
[Train] Epoch: 0 [323328/387873]    Loss: 0.002274   Batch Acc: 86.72
[Train] Epoch: 0 [323456/387873]    Loss: 0.001930   Batch Acc: 90.62
[Train] Epoch: 0 [323584/387873]    Loss: 0.002072   Batch Acc: 87.50
[Train] Epoch: 0 [323712/387873]    Loss: 0.002239   Batch Acc: 87.50
[Train] Epoch: 0 [323840/387873]    Loss: 0.002385   Batch Acc: 87.50
[Train] Epoch: 0 [323968/387873]    Loss: 0.002295   Batch Acc: 86.72
[Train] Epoch: 0 [324096/387873]    Loss: 0.001963   Batch Acc: 90.62
[Train] Epoch: 0 [324224/387873]    Loss: 0.002114   Batch Acc: 89.84
[Train] Epoch: 0 [324352/387873]    Loss: 0.002145   Batch Acc: 89.84
[Train] Epoch: 0 [324480/387873]    Loss: 0.002262   Batch Acc: 87.50
[Train] Epoch: 0 [324608/387873]    Loss: 0.002325   Batch Acc: 87.50
[Train] Epoch: 0 [324736/387873]    Loss: 0.002346   Batch Acc: 84.38
[Train] Epoch: 0 [324864/387873]    Loss: 0.002555   Batch Acc: 85.94
[Train] Epoch: 0 [324992/387873]    Loss: 0.002558   Batch Acc: 84.38
[Train] Epoch: 0 [325120/387873]    Loss: 0.002256   Batch Acc: 88.28
[Train] Epoch: 0 [325248/387873]    Loss: 0.002800   Batch Acc: 85.94
[Train] Epoch: 0 [325376/387873]    Loss: 0.002392   Batch Acc: 84.38
[Train] Epoch: 0 [325504/387873]    Loss: 0.001807   Batch Acc: 89.84
[Train] Epoch: 0 [325632/387873]    Loss: 0.002814   Batch Acc: 84.38
[Train] Epoch: 0 [325760/387873]    Loss: 0.002097   Batch Acc: 89.06
[Train] Epoch: 0 [325888/387873]    Loss: 0.002643   Batch Acc: 83.59
[Train] Epoch: 0 [326016/387873]    Loss: 0.002233   Batch Acc: 89.06
[Train] Epoch: 0 [326144/387873]    Loss: 0.002255   Batch Acc: 83.59
[Train] Epoch: 0 [326272/387873]    Loss: 0.002929   Batch Acc: 81.25
[Train] Epoch: 0 [326400/387873]    Loss: 0.002851   Batch Acc: 84.38
[Train] Epoch: 0 [326528/387873]    Loss: 0.002639   Batch Acc: 84.38
[Train] Epoch: 0 [326656/387873]    Loss: 0.001816   Batch Acc: 94.53
[Train] Epoch: 0 [326784/387873]    Loss: 0.001811   Batch Acc: 90.62
[Train] Epoch: 0 [326912/387873]    Loss: 0.002287   Batch Acc: 87.50
[Train] Epoch: 0 [327040/387873]    Loss: 0.001628   Batch Acc: 93.75
[Train] Epoch: 0 [327168/387873]    Loss: 0.002225   Batch Acc: 91.41
[Train] Epoch: 0 [327296/387873]    Loss: 0.002231   Batch Acc: 89.06
[Train] Epoch: 0 [327424/387873]    Loss: 0.002030   Batch Acc: 90.62
[Train] Epoch: 0 [327552/387873]    Loss: 0.001869   Batch Acc: 92.19
[Train] Epoch: 0 [327680/387873]    Loss: 0.002224   Batch Acc: 88.28
[Train] Epoch: 0 [327808/387873]    Loss: 0.002574   Batch Acc: 85.16
[Train] Epoch: 0 [327936/387873]    Loss: 0.002189   Batch Acc: 89.84
[Train] Epoch: 0 [328064/387873]    Loss: 0.002417   Batch Acc: 88.28
[Train] Epoch: 0 [328192/387873]    Loss: 0.001917   Batch Acc: 91.41
[Train] Epoch: 0 [328320/387873]    Loss: 0.003110   Batch Acc: 82.03
[Train] Epoch: 0 [328448/387873]    Loss: 0.002206   Batch Acc: 88.28
[Train] Epoch: 0 [328576/387873]    Loss: 0.002324   Batch Acc: 86.72
[Train] Epoch: 0 [328704/387873]    Loss: 0.002025   Batch Acc: 88.28
[Train] Epoch: 0 [328832/387873]    Loss: 0.002163   Batch Acc: 91.41
[Train] Epoch: 0 [328960/387873]    Loss: 0.002500   Batch Acc: 85.16
[Train] Epoch: 0 [329088/387873]    Loss: 0.002376   Batch Acc: 88.28
[Train] Epoch: 0 [329216/387873]    Loss: 0.002431   Batch Acc: 88.28
[Train] Epoch: 0 [329344/387873]    Loss: 0.002266   Batch Acc: 89.06
[Train] Epoch: 0 [329472/387873]    Loss: 0.002473   Batch Acc: 85.16
[Train] Epoch: 0 [329600/387873]    Loss: 0.002133   Batch Acc: 86.72
[Train] Epoch: 0 [329728/387873]    Loss: 0.002193   Batch Acc: 89.84
[Train] Epoch: 0 [329856/387873]    Loss: 0.002468   Batch Acc: 87.50
[Train] Epoch: 0 [329984/387873]    Loss: 0.002387   Batch Acc: 89.06
[Train] Epoch: 0 [330112/387873]    Loss: 0.002148   Batch Acc: 91.41
[Train] Epoch: 0 [330240/387873]    Loss: 0.001657   Batch Acc: 95.31
[Train] Epoch: 0 [330368/387873]    Loss: 0.003024   Batch Acc: 78.91
[Train] Epoch: 0 [330496/387873]    Loss: 0.003002   Batch Acc: 85.16
[Train] Epoch: 0 [330624/387873]    Loss: 0.002237   Batch Acc: 86.72
[Train] Epoch: 0 [330752/387873]    Loss: 0.002304   Batch Acc: 88.28
[Train] Epoch: 0 [330880/387873]    Loss: 0.002778   Batch Acc: 82.81
[Train] Epoch: 0 [331008/387873]    Loss: 0.002318   Batch Acc: 84.38
[Train] Epoch: 0 [331136/387873]    Loss: 0.002176   Batch Acc: 90.62
[Train] Epoch: 0 [331264/387873]    Loss: 0.002010   Batch Acc: 89.84
[Train] Epoch: 0 [331392/387873]    Loss: 0.001953   Batch Acc: 90.62
[Train] Epoch: 0 [331520/387873]    Loss: 0.002417   Batch Acc: 83.59
[Train] Epoch: 0 [331648/387873]    Loss: 0.002382   Batch Acc: 85.94
[Train] Epoch: 0 [331776/387873]    Loss: 0.002294   Batch Acc: 87.50
[Train] Epoch: 0 [331904/387873]    Loss: 0.002888   Batch Acc: 85.16
[Train] Epoch: 0 [332032/387873]    Loss: 0.002152   Batch Acc: 89.84
[Train] Epoch: 0 [332160/387873]    Loss: 0.002135   Batch Acc: 88.28
[Train] Epoch: 0 [332288/387873]    Loss: 0.001723   Batch Acc: 92.19
[Train] Epoch: 0 [332416/387873]    Loss: 0.002309   Batch Acc: 85.16
[Train] Epoch: 0 [332544/387873]    Loss: 0.002201   Batch Acc: 88.28
[Train] Epoch: 0 [332672/387873]    Loss: 0.002351   Batch Acc: 90.62
[Train] Epoch: 0 [332800/387873]    Loss: 0.002767   Batch Acc: 85.16
[Train] Epoch: 0 [332928/387873]    Loss: 0.002822   Batch Acc: 81.25
[Train] Epoch: 0 [333056/387873]    Loss: 0.002281   Batch Acc: 87.50
[Train] Epoch: 0 [333184/387873]    Loss: 0.002433   Batch Acc: 85.94
[Train] Epoch: 0 [333312/387873]    Loss: 0.002473   Batch Acc: 90.62
[Train] Epoch: 0 [333440/387873]    Loss: 0.002516   Batch Acc: 85.16
[Train] Epoch: 0 [333568/387873]    Loss: 0.002860   Batch Acc: 79.69
[Train] Epoch: 0 [333696/387873]    Loss: 0.002339   Batch Acc: 89.06
[Train] Epoch: 0 [333824/387873]    Loss: 0.002065   Batch Acc: 90.62
[Train] Epoch: 0 [333952/387873]    Loss: 0.002464   Batch Acc: 85.94
[Train] Epoch: 0 [334080/387873]    Loss: 0.002570   Batch Acc: 85.16
[Train] Epoch: 0 [334208/387873]    Loss: 0.002254   Batch Acc: 85.94
[Train] Epoch: 0 [334336/387873]    Loss: 0.002092   Batch Acc: 88.28
[Train] Epoch: 0 [334464/387873]    Loss: 0.001727   Batch Acc: 93.75
[Train] Epoch: 0 [334592/387873]    Loss: 0.001888   Batch Acc: 90.62
[Train] Epoch: 0 [334720/387873]    Loss: 0.002505   Batch Acc: 85.94
[Train] Epoch: 0 [334848/387873]    Loss: 0.001803   Batch Acc: 91.41
[Train] Epoch: 0 [334976/387873]    Loss: 0.001894   Batch Acc: 89.06
[Train] Epoch: 0 [335104/387873]    Loss: 0.002352   Batch Acc: 86.72
[Train] Epoch: 0 [335232/387873]    Loss: 0.002409   Batch Acc: 85.16
[Train] Epoch: 0 [335360/387873]    Loss: 0.002505   Batch Acc: 87.50
[Train] Epoch: 0 [335488/387873]    Loss: 0.002179   Batch Acc: 88.28
[Train] Epoch: 0 [335616/387873]    Loss: 0.002067   Batch Acc: 89.84
[Train] Epoch: 0 [335744/387873]    Loss: 0.002260   Batch Acc: 88.28
[Train] Epoch: 0 [335872/387873]    Loss: 0.002183   Batch Acc: 87.50
[Train] Epoch: 0 [336000/387873]    Loss: 0.002158   Batch Acc: 89.84
[Train] Epoch: 0 [336128/387873]    Loss: 0.002470   Batch Acc: 83.59
[Train] Epoch: 0 [336256/387873]    Loss: 0.002646   Batch Acc: 85.16
[Train] Epoch: 0 [336384/387873]    Loss: 0.002349   Batch Acc: 85.16
[Train] Epoch: 0 [336512/387873]    Loss: 0.002358   Batch Acc: 84.38
[Train] Epoch: 0 [336640/387873]    Loss: 0.002680   Batch Acc: 86.72
[Train] Epoch: 0 [336768/387873]    Loss: 0.002200   Batch Acc: 86.72
[Train] Epoch: 0 [336896/387873]    Loss: 0.002240   Batch Acc: 89.06
[Train] Epoch: 0 [337024/387873]    Loss: 0.001807   Batch Acc: 91.41
[Train] Epoch: 0 [337152/387873]    Loss: 0.003000   Batch Acc: 82.03
[Train] Epoch: 0 [337280/387873]    Loss: 0.002305   Batch Acc: 88.28
[Train] Epoch: 0 [337408/387873]    Loss: 0.002412   Batch Acc: 87.50
[Train] Epoch: 0 [337536/387873]    Loss: 0.002259   Batch Acc: 87.50
[Train] Epoch: 0 [337664/387873]    Loss: 0.002689   Batch Acc: 85.16
[Train] Epoch: 0 [337792/387873]    Loss: 0.002856   Batch Acc: 85.94
[Train] Epoch: 0 [337920/387873]    Loss: 0.002526   Batch Acc: 86.72
[Train] Epoch: 0 [338048/387873]    Loss: 0.002624   Batch Acc: 85.16
[Train] Epoch: 0 [338176/387873]    Loss: 0.002436   Batch Acc: 86.72
[Train] Epoch: 0 [338304/387873]    Loss: 0.002097   Batch Acc: 88.28
[Train] Epoch: 0 [338432/387873]    Loss: 0.001949   Batch Acc: 88.28
[Train] Epoch: 0 [338560/387873]    Loss: 0.002592   Batch Acc: 89.06
[Train] Epoch: 0 [338688/387873]    Loss: 0.002956   Batch Acc: 82.03
[Train] Epoch: 0 [338816/387873]    Loss: 0.002204   Batch Acc: 89.06
[Train] Epoch: 0 [338944/387873]    Loss: 0.002212   Batch Acc: 89.06
[Train] Epoch: 0 [339072/387873]    Loss: 0.002448   Batch Acc: 87.50
[Train] Epoch: 0 [339200/387873]    Loss: 0.002800   Batch Acc: 82.03
[Train] Epoch: 0 [339328/387873]    Loss: 0.002628   Batch Acc: 81.25
[Train] Epoch: 0 [339456/387873]    Loss: 0.001981   Batch Acc: 93.75
[Train] Epoch: 0 [339584/387873]    Loss: 0.002307   Batch Acc: 85.94
[Train] Epoch: 0 [339712/387873]    Loss: 0.002911   Batch Acc: 84.38
[Train] Epoch: 0 [339840/387873]    Loss: 0.002056   Batch Acc: 90.62
[Train] Epoch: 0 [339968/387873]    Loss: 0.002289   Batch Acc: 89.06
[Train] Epoch: 0 [340096/387873]    Loss: 0.002408   Batch Acc: 88.28
[Train] Epoch: 0 [340224/387873]    Loss: 0.001752   Batch Acc: 93.75
[Train] Epoch: 0 [340352/387873]    Loss: 0.002116   Batch Acc: 89.06
[Train] Epoch: 0 [340480/387873]    Loss: 0.002694   Batch Acc: 82.81
[Train] Epoch: 0 [340608/387873]    Loss: 0.001862   Batch Acc: 92.97
[Train] Epoch: 0 [340736/387873]    Loss: 0.002483   Batch Acc: 85.94
[Train] Epoch: 0 [340864/387873]    Loss: 0.002688   Batch Acc: 84.38
[Train] Epoch: 0 [340992/387873]    Loss: 0.003355   Batch Acc: 79.69
[Train] Epoch: 0 [341120/387873]    Loss: 0.001698   Batch Acc: 93.75
[Train] Epoch: 0 [341248/387873]    Loss: 0.002355   Batch Acc: 86.72
[Train] Epoch: 0 [341376/387873]    Loss: 0.001858   Batch Acc: 93.75
[Train] Epoch: 0 [341504/387873]    Loss: 0.002189   Batch Acc: 88.28
[Train] Epoch: 0 [341632/387873]    Loss: 0.002056   Batch Acc: 88.28
[Train] Epoch: 0 [341760/387873]    Loss: 0.001968   Batch Acc: 90.62
[Train] Epoch: 0 [341888/387873]    Loss: 0.002528   Batch Acc: 86.72
[Train] Epoch: 0 [342016/387873]    Loss: 0.002574   Batch Acc: 86.72
[Train] Epoch: 0 [342144/387873]    Loss: 0.002523   Batch Acc: 88.28
[Train] Epoch: 0 [342272/387873]    Loss: 0.002417   Batch Acc: 87.50
[Train] Epoch: 0 [342400/387873]    Loss: 0.001661   Batch Acc: 92.97
[Train] Epoch: 0 [342528/387873]    Loss: 0.002394   Batch Acc: 85.94
[Train] Epoch: 0 [342656/387873]    Loss: 0.002385   Batch Acc: 85.94
[Train] Epoch: 0 [342784/387873]    Loss: 0.002556   Batch Acc: 86.72
[Train] Epoch: 0 [342912/387873]    Loss: 0.002110   Batch Acc: 89.84
[Train] Epoch: 0 [343040/387873]    Loss: 0.002102   Batch Acc: 91.41
[Train] Epoch: 0 [343168/387873]    Loss: 0.002326   Batch Acc: 86.72
[Train] Epoch: 0 [343296/387873]    Loss: 0.002396   Batch Acc: 87.50
[Train] Epoch: 0 [343424/387873]    Loss: 0.002370   Batch Acc: 86.72
[Train] Epoch: 0 [343552/387873]    Loss: 0.002166   Batch Acc: 86.72
[Train] Epoch: 0 [343680/387873]    Loss: 0.002113   Batch Acc: 90.62
[Train] Epoch: 0 [343808/387873]    Loss: 0.003241   Batch Acc: 83.59
[Train] Epoch: 0 [343936/387873]    Loss: 0.002397   Batch Acc: 86.72
[Train] Epoch: 0 [344064/387873]    Loss: 0.002772   Batch Acc: 79.69
[Train] Epoch: 0 [344192/387873]    Loss: 0.002356   Batch Acc: 84.38
[Train] Epoch: 0 [344320/387873]    Loss: 0.001684   Batch Acc: 93.75
[Train] Epoch: 0 [344448/387873]    Loss: 0.002377   Batch Acc: 89.06
[Train] Epoch: 0 [344576/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 0 [344704/387873]    Loss: 0.002727   Batch Acc: 85.16
[Train] Epoch: 0 [344832/387873]    Loss: 0.002122   Batch Acc: 87.50
[Train] Epoch: 0 [344960/387873]    Loss: 0.002404   Batch Acc: 89.06
[Train] Epoch: 0 [345088/387873]    Loss: 0.001880   Batch Acc: 91.41
[Train] Epoch: 0 [345216/387873]    Loss: 0.002720   Batch Acc: 82.81
[Train] Epoch: 0 [345344/387873]    Loss: 0.002904   Batch Acc: 84.38
[Train] Epoch: 0 [345472/387873]    Loss: 0.002464   Batch Acc: 87.50
[Train] Epoch: 0 [345600/387873]    Loss: 0.002267   Batch Acc: 88.28
[Train] Epoch: 0 [345728/387873]    Loss: 0.001876   Batch Acc: 89.84
[Train] Epoch: 0 [345856/387873]    Loss: 0.001767   Batch Acc: 93.75
[Train] Epoch: 0 [345984/387873]    Loss: 0.002180   Batch Acc: 87.50
[Train] Epoch: 0 [346112/387873]    Loss: 0.002485   Batch Acc: 85.16
[Train] Epoch: 0 [346240/387873]    Loss: 0.001944   Batch Acc: 92.97
[Train] Epoch: 0 [346368/387873]    Loss: 0.002377   Batch Acc: 88.28
[Train] Epoch: 0 [346496/387873]    Loss: 0.002413   Batch Acc: 82.81
[Train] Epoch: 0 [346624/387873]    Loss: 0.002757   Batch Acc: 80.47
[Train] Epoch: 0 [346752/387873]    Loss: 0.002408   Batch Acc: 89.06
[Train] Epoch: 0 [346880/387873]    Loss: 0.002279   Batch Acc: 85.16
[Train] Epoch: 0 [347008/387873]    Loss: 0.002723   Batch Acc: 85.16
[Train] Epoch: 0 [347136/387873]    Loss: 0.002287   Batch Acc: 90.62
[Train] Epoch: 0 [347264/387873]    Loss: 0.002952   Batch Acc: 85.16
[Train] Epoch: 0 [347392/387873]    Loss: 0.002599   Batch Acc: 83.59
[Train] Epoch: 0 [347520/387873]    Loss: 0.002238   Batch Acc: 89.06
[Train] Epoch: 0 [347648/387873]    Loss: 0.002292   Batch Acc: 85.94
[Train] Epoch: 0 [347776/387873]    Loss: 0.001894   Batch Acc: 91.41
[Train] Epoch: 0 [347904/387873]    Loss: 0.002663   Batch Acc: 86.72
[Train] Epoch: 0 [348032/387873]    Loss: 0.002824   Batch Acc: 86.72
[Train] Epoch: 0 [348160/387873]    Loss: 0.002071   Batch Acc: 88.28
[Train] Epoch: 0 [348288/387873]    Loss: 0.001738   Batch Acc: 90.62
[Train] Epoch: 0 [348416/387873]    Loss: 0.001964   Batch Acc: 89.84
[Train] Epoch: 0 [348544/387873]    Loss: 0.002678   Batch Acc: 87.50
[Train] Epoch: 0 [348672/387873]    Loss: 0.002719   Batch Acc: 85.16
[Train] Epoch: 0 [348800/387873]    Loss: 0.002133   Batch Acc: 88.28
[Train] Epoch: 0 [348928/387873]    Loss: 0.002262   Batch Acc: 85.16
[Train] Epoch: 0 [349056/387873]    Loss: 0.002180   Batch Acc: 88.28
[Train] Epoch: 0 [349184/387873]    Loss: 0.002512   Batch Acc: 88.28
[Train] Epoch: 0 [349312/387873]    Loss: 0.002746   Batch Acc: 80.47
[Train] Epoch: 0 [349440/387873]    Loss: 0.001768   Batch Acc: 90.62
[Train] Epoch: 0 [349568/387873]    Loss: 0.002578   Batch Acc: 85.16
[Train] Epoch: 0 [349696/387873]    Loss: 0.002877   Batch Acc: 85.94
[Train] Epoch: 0 [349824/387873]    Loss: 0.002289   Batch Acc: 89.06
[Train] Epoch: 0 [349952/387873]    Loss: 0.001817   Batch Acc: 89.06
[Train] Epoch: 0 [350080/387873]    Loss: 0.002144   Batch Acc: 92.19
[Train] Epoch: 0 [350208/387873]    Loss: 0.001517   Batch Acc: 95.31
[Train] Epoch: 0 [350336/387873]    Loss: 0.002000   Batch Acc: 89.06
[Train] Epoch: 0 [350464/387873]    Loss: 0.002350   Batch Acc: 88.28
[Train] Epoch: 0 [350592/387873]    Loss: 0.001891   Batch Acc: 90.62
[Train] Epoch: 0 [350720/387873]    Loss: 0.002470   Batch Acc: 85.94
[Train] Epoch: 0 [350848/387873]    Loss: 0.002351   Batch Acc: 85.94
[Train] Epoch: 0 [350976/387873]    Loss: 0.002674   Batch Acc: 81.25
[Train] Epoch: 0 [351104/387873]    Loss: 0.002349   Batch Acc: 87.50
[Train] Epoch: 0 [351232/387873]    Loss: 0.002739   Batch Acc: 85.16
[Train] Epoch: 0 [351360/387873]    Loss: 0.001814   Batch Acc: 92.19
[Train] Epoch: 0 [351488/387873]    Loss: 0.002682   Batch Acc: 85.16
[Train] Epoch: 0 [351616/387873]    Loss: 0.002066   Batch Acc: 89.06
[Train] Epoch: 0 [351744/387873]    Loss: 0.002645   Batch Acc: 86.72
[Train] Epoch: 0 [351872/387873]    Loss: 0.002175   Batch Acc: 85.94
[Train] Epoch: 0 [352000/387873]    Loss: 0.002130   Batch Acc: 86.72
[Train] Epoch: 0 [352128/387873]    Loss: 0.001693   Batch Acc: 89.84
[Train] Epoch: 0 [352256/387873]    Loss: 0.002243   Batch Acc: 87.50
[Train] Epoch: 0 [352384/387873]    Loss: 0.001510   Batch Acc: 92.97
[Train] Epoch: 0 [352512/387873]    Loss: 0.002154   Batch Acc: 90.62
[Train] Epoch: 0 [352640/387873]    Loss: 0.002058   Batch Acc: 92.19
[Train] Epoch: 0 [352768/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 0 [352896/387873]    Loss: 0.002462   Batch Acc: 83.59
[Train] Epoch: 0 [353024/387873]    Loss: 0.001689   Batch Acc: 91.41
[Train] Epoch: 0 [353152/387873]    Loss: 0.002267   Batch Acc: 86.72
[Train] Epoch: 0 [353280/387873]    Loss: 0.001542   Batch Acc: 94.53
[Train] Epoch: 0 [353408/387873]    Loss: 0.002293   Batch Acc: 88.28
[Train] Epoch: 0 [353536/387873]    Loss: 0.002109   Batch Acc: 92.19
[Train] Epoch: 0 [353664/387873]    Loss: 0.002061   Batch Acc: 85.94
[Train] Epoch: 0 [353792/387873]    Loss: 0.002073   Batch Acc: 89.06
[Train] Epoch: 0 [353920/387873]    Loss: 0.001762   Batch Acc: 92.19
[Train] Epoch: 0 [354048/387873]    Loss: 0.001887   Batch Acc: 91.41
[Train] Epoch: 0 [354176/387873]    Loss: 0.002115   Batch Acc: 87.50
[Train] Epoch: 0 [354304/387873]    Loss: 0.002021   Batch Acc: 91.41
[Train] Epoch: 0 [354432/387873]    Loss: 0.002226   Batch Acc: 86.72
[Train] Epoch: 0 [354560/387873]    Loss: 0.002283   Batch Acc: 86.72
[Train] Epoch: 0 [354688/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 0 [354816/387873]    Loss: 0.002755   Batch Acc: 83.59
[Train] Epoch: 0 [354944/387873]    Loss: 0.002072   Batch Acc: 90.62
[Train] Epoch: 0 [355072/387873]    Loss: 0.002445   Batch Acc: 86.72
[Train] Epoch: 0 [355200/387873]    Loss: 0.001773   Batch Acc: 90.62
[Train] Epoch: 0 [355328/387873]    Loss: 0.002362   Batch Acc: 86.72
[Train] Epoch: 0 [355456/387873]    Loss: 0.002969   Batch Acc: 82.81
[Train] Epoch: 0 [355584/387873]    Loss: 0.002271   Batch Acc: 89.06
[Train] Epoch: 0 [355712/387873]    Loss: 0.002279   Batch Acc: 87.50
[Train] Epoch: 0 [355840/387873]    Loss: 0.001983   Batch Acc: 89.84
[Train] Epoch: 0 [355968/387873]    Loss: 0.002412   Batch Acc: 88.28
[Train] Epoch: 0 [356096/387873]    Loss: 0.002342   Batch Acc: 87.50
[Train] Epoch: 0 [356224/387873]    Loss: 0.002301   Batch Acc: 88.28
[Train] Epoch: 0 [356352/387873]    Loss: 0.002574   Batch Acc: 82.03
[Train] Epoch: 0 [356480/387873]    Loss: 0.002532   Batch Acc: 89.06
[Train] Epoch: 0 [356608/387873]    Loss: 0.002081   Batch Acc: 87.50
[Train] Epoch: 0 [356736/387873]    Loss: 0.001959   Batch Acc: 90.62
[Train] Epoch: 0 [356864/387873]    Loss: 0.002364   Batch Acc: 87.50
[Train] Epoch: 0 [356992/387873]    Loss: 0.002554   Batch Acc: 89.06
[Train] Epoch: 0 [357120/387873]    Loss: 0.002427   Batch Acc: 86.72
[Train] Epoch: 0 [357248/387873]    Loss: 0.002406   Batch Acc: 85.94
[Train] Epoch: 0 [357376/387873]    Loss: 0.001964   Batch Acc: 90.62
[Train] Epoch: 0 [357504/387873]    Loss: 0.002112   Batch Acc: 89.84
[Train] Epoch: 0 [357632/387873]    Loss: 0.002157   Batch Acc: 88.28
[Train] Epoch: 0 [357760/387873]    Loss: 0.002023   Batch Acc: 89.06
[Train] Epoch: 0 [357888/387873]    Loss: 0.002249   Batch Acc: 89.06
[Train] Epoch: 0 [358016/387873]    Loss: 0.002400   Batch Acc: 87.50
[Train] Epoch: 0 [358144/387873]    Loss: 0.002320   Batch Acc: 87.50
[Train] Epoch: 0 [358272/387873]    Loss: 0.002159   Batch Acc: 88.28
[Train] Epoch: 0 [358400/387873]    Loss: 0.002570   Batch Acc: 85.16
[Train] Epoch: 0 [358528/387873]    Loss: 0.002019   Batch Acc: 89.84
[Train] Epoch: 0 [358656/387873]    Loss: 0.001997   Batch Acc: 89.84
[Train] Epoch: 0 [358784/387873]    Loss: 0.002702   Batch Acc: 85.16
[Train] Epoch: 0 [358912/387873]    Loss: 0.002769   Batch Acc: 82.03
[Train] Epoch: 0 [359040/387873]    Loss: 0.002886   Batch Acc: 85.16
[Train] Epoch: 0 [359168/387873]    Loss: 0.002444   Batch Acc: 83.59
[Train] Epoch: 0 [359296/387873]    Loss: 0.002430   Batch Acc: 87.50
[Train] Epoch: 0 [359424/387873]    Loss: 0.002162   Batch Acc: 89.06
[Train] Epoch: 0 [359552/387873]    Loss: 0.002521   Batch Acc: 85.94
[Train] Epoch: 0 [359680/387873]    Loss: 0.002351   Batch Acc: 88.28
[Train] Epoch: 0 [359808/387873]    Loss: 0.002122   Batch Acc: 89.06
[Train] Epoch: 0 [359936/387873]    Loss: 0.001647   Batch Acc: 94.53
[Train] Epoch: 0 [360064/387873]    Loss: 0.002741   Batch Acc: 85.16
[Train] Epoch: 0 [360192/387873]    Loss: 0.001735   Batch Acc: 89.84
[Train] Epoch: 0 [360320/387873]    Loss: 0.001991   Batch Acc: 91.41
[Train] Epoch: 0 [360448/387873]    Loss: 0.002191   Batch Acc: 85.16
[Train] Epoch: 0 [360576/387873]    Loss: 0.002271   Batch Acc: 89.06
[Train] Epoch: 0 [360704/387873]    Loss: 0.002158   Batch Acc: 89.06
[Train] Epoch: 0 [360832/387873]    Loss: 0.002114   Batch Acc: 85.94
[Train] Epoch: 0 [360960/387873]    Loss: 0.002507   Batch Acc: 85.94
[Train] Epoch: 0 [361088/387873]    Loss: 0.002460   Batch Acc: 83.59
[Train] Epoch: 0 [361216/387873]    Loss: 0.001927   Batch Acc: 92.97
[Train] Epoch: 0 [361344/387873]    Loss: 0.002034   Batch Acc: 86.72
[Train] Epoch: 0 [361472/387873]    Loss: 0.002525   Batch Acc: 85.94
[Train] Epoch: 0 [361600/387873]    Loss: 0.001783   Batch Acc: 92.97
[Train] Epoch: 0 [361728/387873]    Loss: 0.002616   Batch Acc: 83.59
[Train] Epoch: 0 [361856/387873]    Loss: 0.002132   Batch Acc: 88.28
[Train] Epoch: 0 [361984/387873]    Loss: 0.002474   Batch Acc: 85.16
[Train] Epoch: 0 [362112/387873]    Loss: 0.002586   Batch Acc: 85.16
[Train] Epoch: 0 [362240/387873]    Loss: 0.002176   Batch Acc: 88.28
[Train] Epoch: 0 [362368/387873]    Loss: 0.002153   Batch Acc: 88.28
[Train] Epoch: 0 [362496/387873]    Loss: 0.001911   Batch Acc: 89.06
[Train] Epoch: 0 [362624/387873]    Loss: 0.002206   Batch Acc: 89.06
[Train] Epoch: 0 [362752/387873]    Loss: 0.001981   Batch Acc: 92.19
[Train] Epoch: 0 [362880/387873]    Loss: 0.002072   Batch Acc: 89.84
[Train] Epoch: 0 [363008/387873]    Loss: 0.002476   Batch Acc: 83.59
[Train] Epoch: 0 [363136/387873]    Loss: 0.001558   Batch Acc: 95.31
[Train] Epoch: 0 [363264/387873]    Loss: 0.002049   Batch Acc: 89.06
[Train] Epoch: 0 [363392/387873]    Loss: 0.002261   Batch Acc: 90.62
[Train] Epoch: 0 [363520/387873]    Loss: 0.001976   Batch Acc: 89.84
[Train] Epoch: 0 [363648/387873]    Loss: 0.002022   Batch Acc: 88.28
[Train] Epoch: 0 [363776/387873]    Loss: 0.002107   Batch Acc: 89.84
[Train] Epoch: 0 [363904/387873]    Loss: 0.002518   Batch Acc: 87.50
[Train] Epoch: 0 [364032/387873]    Loss: 0.001925   Batch Acc: 90.62
[Train] Epoch: 0 [364160/387873]    Loss: 0.001947   Batch Acc: 88.28
[Train] Epoch: 0 [364288/387873]    Loss: 0.002467   Batch Acc: 83.59
[Train] Epoch: 0 [364416/387873]    Loss: 0.002300   Batch Acc: 91.41
[Train] Epoch: 0 [364544/387873]    Loss: 0.002342   Batch Acc: 84.38
[Train] Epoch: 0 [364672/387873]    Loss: 0.002696   Batch Acc: 85.94
[Train] Epoch: 0 [364800/387873]    Loss: 0.001870   Batch Acc: 91.41
[Train] Epoch: 0 [364928/387873]    Loss: 0.001703   Batch Acc: 92.19
[Train] Epoch: 0 [365056/387873]    Loss: 0.001753   Batch Acc: 90.62
[Train] Epoch: 0 [365184/387873]    Loss: 0.002079   Batch Acc: 88.28
[Train] Epoch: 0 [365312/387873]    Loss: 0.002204   Batch Acc: 90.62
[Train] Epoch: 0 [365440/387873]    Loss: 0.002264   Batch Acc: 86.72
[Train] Epoch: 0 [365568/387873]    Loss: 0.002088   Batch Acc: 85.16
[Train] Epoch: 0 [365696/387873]    Loss: 0.002127   Batch Acc: 88.28
[Train] Epoch: 0 [365824/387873]    Loss: 0.002084   Batch Acc: 89.84
[Train] Epoch: 0 [365952/387873]    Loss: 0.003049   Batch Acc: 84.38
[Train] Epoch: 0 [366080/387873]    Loss: 0.002375   Batch Acc: 87.50
[Train] Epoch: 0 [366208/387873]    Loss: 0.002667   Batch Acc: 86.72
[Train] Epoch: 0 [366336/387873]    Loss: 0.001806   Batch Acc: 93.75
[Train] Epoch: 0 [366464/387873]    Loss: 0.002550   Batch Acc: 82.03
[Train] Epoch: 0 [366592/387873]    Loss: 0.002279   Batch Acc: 91.41
[Train] Epoch: 0 [366720/387873]    Loss: 0.002595   Batch Acc: 85.94
[Train] Epoch: 0 [366848/387873]    Loss: 0.002438   Batch Acc: 85.94
[Train] Epoch: 0 [366976/387873]    Loss: 0.003399   Batch Acc: 77.34
[Train] Epoch: 0 [367104/387873]    Loss: 0.002774   Batch Acc: 86.72
[Train] Epoch: 0 [367232/387873]    Loss: 0.001940   Batch Acc: 92.19
[Train] Epoch: 0 [367360/387873]    Loss: 0.002268   Batch Acc: 85.94
[Train] Epoch: 0 [367488/387873]    Loss: 0.001874   Batch Acc: 90.62
[Train] Epoch: 0 [367616/387873]    Loss: 0.002060   Batch Acc: 89.84
[Train] Epoch: 0 [367744/387873]    Loss: 0.001764   Batch Acc: 93.75
[Train] Epoch: 0 [367872/387873]    Loss: 0.002527   Batch Acc: 85.94
[Train] Epoch: 0 [368000/387873]    Loss: 0.002073   Batch Acc: 91.41
[Train] Epoch: 0 [368128/387873]    Loss: 0.002182   Batch Acc: 89.06
[Train] Epoch: 0 [368256/387873]    Loss: 0.002121   Batch Acc: 93.75
[Train] Epoch: 0 [368384/387873]    Loss: 0.002925   Batch Acc: 82.03
[Train] Epoch: 0 [368512/387873]    Loss: 0.001743   Batch Acc: 91.41
[Train] Epoch: 0 [368640/387873]    Loss: 0.002531   Batch Acc: 85.16
[Train] Epoch: 0 [368768/387873]    Loss: 0.001849   Batch Acc: 90.62
[Train] Epoch: 0 [368896/387873]    Loss: 0.001964   Batch Acc: 89.84
[Train] Epoch: 0 [369024/387873]    Loss: 0.002015   Batch Acc: 90.62
[Train] Epoch: 0 [369152/387873]    Loss: 0.002797   Batch Acc: 85.16
[Train] Epoch: 0 [369280/387873]    Loss: 0.002697   Batch Acc: 88.28
[Train] Epoch: 0 [369408/387873]    Loss: 0.003066   Batch Acc: 83.59
[Train] Epoch: 0 [369536/387873]    Loss: 0.001745   Batch Acc: 90.62
[Train] Epoch: 0 [369664/387873]    Loss: 0.002242   Batch Acc: 88.28
[Train] Epoch: 0 [369792/387873]    Loss: 0.002059   Batch Acc: 92.19
[Train] Epoch: 0 [369920/387873]    Loss: 0.002136   Batch Acc: 86.72
[Train] Epoch: 0 [370048/387873]    Loss: 0.002544   Batch Acc: 89.06
[Train] Epoch: 0 [370176/387873]    Loss: 0.002318   Batch Acc: 85.16
[Train] Epoch: 0 [370304/387873]    Loss: 0.002068   Batch Acc: 90.62
[Train] Epoch: 0 [370432/387873]    Loss: 0.002330   Batch Acc: 85.94
[Train] Epoch: 0 [370560/387873]    Loss: 0.002031   Batch Acc: 90.62
[Train] Epoch: 0 [370688/387873]    Loss: 0.002172   Batch Acc: 85.94
[Train] Epoch: 0 [370816/387873]    Loss: 0.002261   Batch Acc: 83.59
[Train] Epoch: 0 [370944/387873]    Loss: 0.002036   Batch Acc: 89.06
[Train] Epoch: 0 [371072/387873]    Loss: 0.002689   Batch Acc: 85.16
[Train] Epoch: 0 [371200/387873]    Loss: 0.001742   Batch Acc: 92.19
[Train] Epoch: 0 [371328/387873]    Loss: 0.001760   Batch Acc: 92.19
[Train] Epoch: 0 [371456/387873]    Loss: 0.002461   Batch Acc: 89.06
[Train] Epoch: 0 [371584/387873]    Loss: 0.002451   Batch Acc: 84.38
[Train] Epoch: 0 [371712/387873]    Loss: 0.002610   Batch Acc: 84.38
[Train] Epoch: 0 [371840/387873]    Loss: 0.002152   Batch Acc: 90.62
[Train] Epoch: 0 [371968/387873]    Loss: 0.001502   Batch Acc: 94.53
[Train] Epoch: 0 [372096/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 0 [372224/387873]    Loss: 0.002314   Batch Acc: 85.94
[Train] Epoch: 0 [372352/387873]    Loss: 0.002211   Batch Acc: 85.94
[Train] Epoch: 0 [372480/387873]    Loss: 0.002079   Batch Acc: 88.28
[Train] Epoch: 0 [372608/387873]    Loss: 0.001647   Batch Acc: 92.97
[Train] Epoch: 0 [372736/387873]    Loss: 0.002119   Batch Acc: 89.06
[Train] Epoch: 0 [372864/387873]    Loss: 0.002608   Batch Acc: 80.47
[Train] Epoch: 0 [372992/387873]    Loss: 0.001763   Batch Acc: 93.75
[Train] Epoch: 0 [373120/387873]    Loss: 0.002278   Batch Acc: 88.28
[Train] Epoch: 0 [373248/387873]    Loss: 0.001816   Batch Acc: 91.41
[Train] Epoch: 0 [373376/387873]    Loss: 0.002029   Batch Acc: 91.41
[Train] Epoch: 0 [373504/387873]    Loss: 0.002605   Batch Acc: 88.28
[Train] Epoch: 0 [373632/387873]    Loss: 0.002465   Batch Acc: 86.72
[Train] Epoch: 0 [373760/387873]    Loss: 0.001810   Batch Acc: 92.97
[Train] Epoch: 0 [373888/387873]    Loss: 0.002360   Batch Acc: 87.50
[Train] Epoch: 0 [374016/387873]    Loss: 0.002139   Batch Acc: 89.84
[Train] Epoch: 0 [374144/387873]    Loss: 0.002384   Batch Acc: 86.72
[Train] Epoch: 0 [374272/387873]    Loss: 0.001791   Batch Acc: 92.97
[Train] Epoch: 0 [374400/387873]    Loss: 0.002382   Batch Acc: 84.38
[Train] Epoch: 0 [374528/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 0 [374656/387873]    Loss: 0.002122   Batch Acc: 91.41
[Train] Epoch: 0 [374784/387873]    Loss: 0.001827   Batch Acc: 89.84
[Train] Epoch: 0 [374912/387873]    Loss: 0.002180   Batch Acc: 88.28
[Train] Epoch: 0 [375040/387873]    Loss: 0.002483   Batch Acc: 88.28
[Train] Epoch: 0 [375168/387873]    Loss: 0.002340   Batch Acc: 84.38
[Train] Epoch: 0 [375296/387873]    Loss: 0.002370   Batch Acc: 86.72
[Train] Epoch: 0 [375424/387873]    Loss: 0.002371   Batch Acc: 85.94
[Train] Epoch: 0 [375552/387873]    Loss: 0.002168   Batch Acc: 88.28
[Train] Epoch: 0 [375680/387873]    Loss: 0.002017   Batch Acc: 89.06
[Train] Epoch: 0 [375808/387873]    Loss: 0.002643   Batch Acc: 84.38
[Train] Epoch: 0 [375936/387873]    Loss: 0.002541   Batch Acc: 84.38
[Train] Epoch: 0 [376064/387873]    Loss: 0.001946   Batch Acc: 91.41
[Train] Epoch: 0 [376192/387873]    Loss: 0.002497   Batch Acc: 87.50
[Train] Epoch: 0 [376320/387873]    Loss: 0.002373   Batch Acc: 85.94
[Train] Epoch: 0 [376448/387873]    Loss: 0.002499   Batch Acc: 86.72
[Train] Epoch: 0 [376576/387873]    Loss: 0.002847   Batch Acc: 81.25
[Train] Epoch: 0 [376704/387873]    Loss: 0.002163   Batch Acc: 89.06
[Train] Epoch: 0 [376832/387873]    Loss: 0.002451   Batch Acc: 88.28
[Train] Epoch: 0 [376960/387873]    Loss: 0.002251   Batch Acc: 86.72
[Train] Epoch: 0 [377088/387873]    Loss: 0.001880   Batch Acc: 90.62
[Train] Epoch: 0 [377216/387873]    Loss: 0.002130   Batch Acc: 85.94
[Train] Epoch: 0 [377344/387873]    Loss: 0.001945   Batch Acc: 90.62
[Train] Epoch: 0 [377472/387873]    Loss: 0.001955   Batch Acc: 91.41
[Train] Epoch: 0 [377600/387873]    Loss: 0.002238   Batch Acc: 86.72
[Train] Epoch: 0 [377728/387873]    Loss: 0.002105   Batch Acc: 91.41
[Train] Epoch: 0 [377856/387873]    Loss: 0.002589   Batch Acc: 85.16
[Train] Epoch: 0 [377984/387873]    Loss: 0.002036   Batch Acc: 86.72
[Train] Epoch: 0 [378112/387873]    Loss: 0.002416   Batch Acc: 87.50
[Train] Epoch: 0 [378240/387873]    Loss: 0.002112   Batch Acc: 86.72
[Train] Epoch: 0 [378368/387873]    Loss: 0.001876   Batch Acc: 88.28
[Train] Epoch: 0 [378496/387873]    Loss: 0.001975   Batch Acc: 89.06
[Train] Epoch: 0 [378624/387873]    Loss: 0.002785   Batch Acc: 84.38
[Train] Epoch: 0 [378752/387873]    Loss: 0.001736   Batch Acc: 92.19
[Train] Epoch: 0 [378880/387873]    Loss: 0.002418   Batch Acc: 88.28
[Train] Epoch: 0 [379008/387873]    Loss: 0.002168   Batch Acc: 90.62
[Train] Epoch: 0 [379136/387873]    Loss: 0.002135   Batch Acc: 88.28
[Train] Epoch: 0 [379264/387873]    Loss: 0.002448   Batch Acc: 85.94
[Train] Epoch: 0 [379392/387873]    Loss: 0.002267   Batch Acc: 86.72
[Train] Epoch: 0 [379520/387873]    Loss: 0.002391   Batch Acc: 89.06
[Train] Epoch: 0 [379648/387873]    Loss: 0.001676   Batch Acc: 92.97
[Train] Epoch: 0 [379776/387873]    Loss: 0.002343   Batch Acc: 87.50
[Train] Epoch: 0 [379904/387873]    Loss: 0.002303   Batch Acc: 90.62
[Train] Epoch: 0 [380032/387873]    Loss: 0.002000   Batch Acc: 87.50
[Train] Epoch: 0 [380160/387873]    Loss: 0.002619   Batch Acc: 88.28
[Train] Epoch: 0 [380288/387873]    Loss: 0.002791   Batch Acc: 83.59
[Train] Epoch: 0 [380416/387873]    Loss: 0.002463   Batch Acc: 86.72
[Train] Epoch: 0 [380544/387873]    Loss: 0.001676   Batch Acc: 92.97
[Train] Epoch: 0 [380672/387873]    Loss: 0.002222   Batch Acc: 89.84
[Train] Epoch: 0 [380800/387873]    Loss: 0.002211   Batch Acc: 84.38
[Train] Epoch: 0 [380928/387873]    Loss: 0.002205   Batch Acc: 89.06
[Train] Epoch: 0 [381056/387873]    Loss: 0.002375   Batch Acc: 88.28
[Train] Epoch: 0 [381184/387873]    Loss: 0.001982   Batch Acc: 89.06
[Train] Epoch: 0 [381312/387873]    Loss: 0.001784   Batch Acc: 92.97
[Train] Epoch: 0 [381440/387873]    Loss: 0.002010   Batch Acc: 91.41
[Train] Epoch: 0 [381568/387873]    Loss: 0.002452   Batch Acc: 86.72
[Train] Epoch: 0 [381696/387873]    Loss: 0.002465   Batch Acc: 84.38
[Train] Epoch: 0 [381824/387873]    Loss: 0.001866   Batch Acc: 90.62
[Train] Epoch: 0 [381952/387873]    Loss: 0.002812   Batch Acc: 84.38
[Train] Epoch: 0 [382080/387873]    Loss: 0.002152   Batch Acc: 88.28
[Train] Epoch: 0 [382208/387873]    Loss: 0.002788   Batch Acc: 85.94
[Train] Epoch: 0 [382336/387873]    Loss: 0.001888   Batch Acc: 89.06
[Train] Epoch: 0 [382464/387873]    Loss: 0.001959   Batch Acc: 89.06
[Train] Epoch: 0 [382592/387873]    Loss: 0.002396   Batch Acc: 85.16
[Train] Epoch: 0 [382720/387873]    Loss: 0.002024   Batch Acc: 89.84
[Train] Epoch: 0 [382848/387873]    Loss: 0.001965   Batch Acc: 88.28
[Train] Epoch: 0 [382976/387873]    Loss: 0.002915   Batch Acc: 79.69
[Train] Epoch: 0 [383104/387873]    Loss: 0.001790   Batch Acc: 89.84
[Train] Epoch: 0 [383232/387873]    Loss: 0.002082   Batch Acc: 90.62
[Train] Epoch: 0 [383360/387873]    Loss: 0.002220   Batch Acc: 87.50
[Train] Epoch: 0 [383488/387873]    Loss: 0.002023   Batch Acc: 89.84
[Train] Epoch: 0 [383616/387873]    Loss: 0.002576   Batch Acc: 85.94
[Train] Epoch: 0 [383744/387873]    Loss: 0.002252   Batch Acc: 90.62
[Train] Epoch: 0 [383872/387873]    Loss: 0.002086   Batch Acc: 88.28
[Train] Epoch: 0 [384000/387873]    Loss: 0.002651   Batch Acc: 86.72
[Train] Epoch: 0 [384128/387873]    Loss: 0.002057   Batch Acc: 89.06
[Train] Epoch: 0 [384256/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 0 [384384/387873]    Loss: 0.002197   Batch Acc: 90.62
[Train] Epoch: 0 [384512/387873]    Loss: 0.002203   Batch Acc: 88.28
[Train] Epoch: 0 [384640/387873]    Loss: 0.002157   Batch Acc: 87.50
[Train] Epoch: 0 [384768/387873]    Loss: 0.002351   Batch Acc: 86.72
[Train] Epoch: 0 [384896/387873]    Loss: 0.001977   Batch Acc: 89.84
[Train] Epoch: 0 [385024/387873]    Loss: 0.002418   Batch Acc: 85.16
[Train] Epoch: 0 [385152/387873]    Loss: 0.001495   Batch Acc: 93.75
[Train] Epoch: 0 [385280/387873]    Loss: 0.002508   Batch Acc: 87.50
[Train] Epoch: 0 [385408/387873]    Loss: 0.002103   Batch Acc: 90.62
[Train] Epoch: 0 [385536/387873]    Loss: 0.001998   Batch Acc: 92.97
[Train] Epoch: 0 [385664/387873]    Loss: 0.001982   Batch Acc: 92.97
[Train] Epoch: 0 [385792/387873]    Loss: 0.002616   Batch Acc: 85.94
[Train] Epoch: 0 [385920/387873]    Loss: 0.002324   Batch Acc: 85.16
[Train] Epoch: 0 [386048/387873]    Loss: 0.002185   Batch Acc: 88.28
[Train] Epoch: 0 [386176/387873]    Loss: 0.002261   Batch Acc: 87.50
[Train] Epoch: 0 [386304/387873]    Loss: 0.002154   Batch Acc: 88.28
[Train] Epoch: 0 [386432/387873]    Loss: 0.002247   Batch Acc: 86.72
[Train] Epoch: 0 [386560/387873]    Loss: 0.002269   Batch Acc: 86.72
[Train] Epoch: 0 [386688/387873]    Loss: 0.002650   Batch Acc: 85.94
[Train] Epoch: 0 [386816/387873]    Loss: 0.002701   Batch Acc: 85.16
[Train] Epoch: 0 [386944/387873]    Loss: 0.002379   Batch Acc: 88.28
[Train] Epoch: 0 [387072/387873]    Loss: 0.002194   Batch Acc: 90.62
[Train] Epoch: 0 [387200/387873]    Loss: 0.002065   Batch Acc: 89.06
[Train] Epoch: 0 [387328/387873]    Loss: 0.001938   Batch Acc: 90.62
[Train] Epoch: 0 [387456/387873]    Loss: 0.002038   Batch Acc: 87.50
[Train] Epoch: 0 [387584/387873]    Loss: 0.002193   Batch Acc: 87.50
[Train] Epoch: 0 [387712/387873]    Loss: 0.002421   Batch Acc: 85.94
[Train] Epoch: 0 [387840/387873]    Loss: 0.002253   Batch Acc: 86.72
[Train] Epoch: 0 [100023/387873]    Loss: 0.008117   Batch Acc: 90.91
Validation Done: [128/84203]
Validation Done: [256/84203]
Validation Done: [384/84203]
Validation Done: [512/84203]
Validation Done: [640/84203]
Validation Done: [768/84203]
Validation Done: [896/84203]
Validation Done: [1024/84203]
Validation Done: [1152/84203]
Validation Done: [1280/84203]
Validation Done: [1408/84203]
Validation Done: [1536/84203]
Validation Done: [1664/84203]
Validation Done: [1792/84203]
Validation Done: [1920/84203]
Validation Done: [2048/84203]
Validation Done: [2176/84203]
Validation Done: [2304/84203]
Validation Done: [2432/84203]
Validation Done: [2560/84203]
Validation Done: [2688/84203]
Validation Done: [2816/84203]
Validation Done: [2944/84203]
Validation Done: [3072/84203]
Validation Done: [3200/84203]
Validation Done: [3328/84203]
Validation Done: [3456/84203]
Validation Done: [3584/84203]
Validation Done: [3712/84203]
Validation Done: [3840/84203]
Validation Done: [3968/84203]
Validation Done: [4096/84203]
Validation Done: [4224/84203]
Validation Done: [4352/84203]
Validation Done: [4480/84203]
Validation Done: [4608/84203]
Validation Done: [4736/84203]
Validation Done: [4864/84203]
Validation Done: [4992/84203]
Validation Done: [5120/84203]
Validation Done: [5248/84203]
Validation Done: [5376/84203]
Validation Done: [5504/84203]
Validation Done: [5632/84203]
Validation Done: [5760/84203]
Validation Done: [5888/84203]
Validation Done: [6016/84203]
Validation Done: [6144/84203]
Validation Done: [6272/84203]
Validation Done: [6400/84203]
Validation Done: [6528/84203]
Validation Done: [6656/84203]
Validation Done: [6784/84203]
Validation Done: [6912/84203]
Validation Done: [7040/84203]
Validation Done: [7168/84203]
Validation Done: [7296/84203]
Validation Done: [7424/84203]
Validation Done: [7552/84203]
Validation Done: [7680/84203]
Validation Done: [7808/84203]
Validation Done: [7936/84203]
Validation Done: [8064/84203]
Validation Done: [8192/84203]
Validation Done: [8320/84203]
Validation Done: [8448/84203]
Validation Done: [8576/84203]
Validation Done: [8704/84203]
Validation Done: [8832/84203]
Validation Done: [8960/84203]
Validation Done: [9088/84203]
Validation Done: [9216/84203]
Validation Done: [9344/84203]
Validation Done: [9472/84203]
Validation Done: [9600/84203]
Validation Done: [9728/84203]
Validation Done: [9856/84203]
Validation Done: [9984/84203]
Validation Done: [10112/84203]
Validation Done: [10240/84203]
Validation Done: [10368/84203]
Validation Done: [10496/84203]
Validation Done: [10624/84203]
Validation Done: [10752/84203]
Validation Done: [10880/84203]
Validation Done: [11008/84203]
Validation Done: [11136/84203]
Validation Done: [11264/84203]
Validation Done: [11392/84203]
Validation Done: [11520/84203]
Validation Done: [11648/84203]
Validation Done: [11776/84203]
Validation Done: [11904/84203]
Validation Done: [12032/84203]
Validation Done: [12160/84203]
Validation Done: [12288/84203]
Validation Done: [12416/84203]
Validation Done: [12544/84203]
Validation Done: [12672/84203]
Validation Done: [12800/84203]
Validation Done: [12928/84203]
Validation Done: [13056/84203]
Validation Done: [13184/84203]
Validation Done: [13312/84203]
Validation Done: [13440/84203]
Validation Done: [13568/84203]
Validation Done: [13696/84203]
Validation Done: [13824/84203]
Validation Done: [13952/84203]
Validation Done: [14080/84203]
Validation Done: [14208/84203]
Validation Done: [14336/84203]
Validation Done: [14464/84203]
Validation Done: [14592/84203]
Validation Done: [14720/84203]
Validation Done: [14848/84203]
Validation Done: [14976/84203]
Validation Done: [15104/84203]
Validation Done: [15232/84203]
Validation Done: [15360/84203]
Validation Done: [15488/84203]
Validation Done: [15616/84203]
Validation Done: [15744/84203]
Validation Done: [15872/84203]
Validation Done: [16000/84203]
Validation Done: [16128/84203]
Validation Done: [16256/84203]
Validation Done: [16384/84203]
Validation Done: [16512/84203]
Validation Done: [16640/84203]
Validation Done: [16768/84203]
Validation Done: [16896/84203]
Validation Done: [17024/84203]
Validation Done: [17152/84203]
Validation Done: [17280/84203]
Validation Done: [17408/84203]
Validation Done: [17536/84203]
Validation Done: [17664/84203]
Validation Done: [17792/84203]
Validation Done: [17920/84203]
Validation Done: [18048/84203]
Validation Done: [18176/84203]
Validation Done: [18304/84203]
Validation Done: [18432/84203]
Validation Done: [18560/84203]
Validation Done: [18688/84203]
Validation Done: [18816/84203]
Validation Done: [18944/84203]
Validation Done: [19072/84203]
Validation Done: [19200/84203]
Validation Done: [19328/84203]
Validation Done: [19456/84203]
Validation Done: [19584/84203]
Validation Done: [19712/84203]
Validation Done: [19840/84203]
Validation Done: [19968/84203]
Validation Done: [20096/84203]
Validation Done: [20224/84203]
Validation Done: [20352/84203]
Validation Done: [20480/84203]
Validation Done: [20608/84203]
Validation Done: [20736/84203]
Validation Done: [20864/84203]
Validation Done: [20992/84203]
Validation Done: [21120/84203]
Validation Done: [21248/84203]
Validation Done: [21376/84203]
Validation Done: [21504/84203]
Validation Done: [21632/84203]
Validation Done: [21760/84203]
Validation Done: [21888/84203]
Validation Done: [22016/84203]
Validation Done: [22144/84203]
Validation Done: [22272/84203]
Validation Done: [22400/84203]
Validation Done: [22528/84203]
Validation Done: [22656/84203]
Validation Done: [22784/84203]
Validation Done: [22912/84203]
Validation Done: [23040/84203]
Validation Done: [23168/84203]
Validation Done: [23296/84203]
Validation Done: [23424/84203]
Validation Done: [23552/84203]
Validation Done: [23680/84203]
Validation Done: [23808/84203]
Validation Done: [23936/84203]
Validation Done: [24064/84203]
Validation Done: [24192/84203]
Validation Done: [24320/84203]
Validation Done: [24448/84203]
Validation Done: [24576/84203]
Validation Done: [24704/84203]
Validation Done: [24832/84203]
Validation Done: [24960/84203]
Validation Done: [25088/84203]
Validation Done: [25216/84203]
Validation Done: [25344/84203]
Validation Done: [25472/84203]
Validation Done: [25600/84203]
Validation Done: [25728/84203]
Validation Done: [25856/84203]
Validation Done: [25984/84203]
Validation Done: [26112/84203]
Validation Done: [26240/84203]
Validation Done: [26368/84203]
Validation Done: [26496/84203]
Validation Done: [26624/84203]
Validation Done: [26752/84203]
Validation Done: [26880/84203]
Validation Done: [27008/84203]
Validation Done: [27136/84203]
Validation Done: [27264/84203]
Validation Done: [27392/84203]
Validation Done: [27520/84203]
Validation Done: [27648/84203]
Validation Done: [27776/84203]
Validation Done: [27904/84203]
Validation Done: [28032/84203]
Validation Done: [28160/84203]
Validation Done: [28288/84203]
Validation Done: [28416/84203]
Validation Done: [28544/84203]
Validation Done: [28672/84203]
Validation Done: [28800/84203]
Validation Done: [28928/84203]
Validation Done: [29056/84203]
Validation Done: [29184/84203]
Validation Done: [29312/84203]
Validation Done: [29440/84203]
Validation Done: [29568/84203]
Validation Done: [29696/84203]
Validation Done: [29824/84203]
Validation Done: [29952/84203]
Validation Done: [30080/84203]
Validation Done: [30208/84203]
Validation Done: [30336/84203]
Validation Done: [30464/84203]
Validation Done: [30592/84203]
Validation Done: [30720/84203]
Validation Done: [30848/84203]
Validation Done: [30976/84203]
Validation Done: [31104/84203]
Validation Done: [31232/84203]
Validation Done: [31360/84203]
Validation Done: [31488/84203]
Validation Done: [31616/84203]
Validation Done: [31744/84203]
Validation Done: [31872/84203]
Validation Done: [32000/84203]
Validation Done: [32128/84203]
Validation Done: [32256/84203]
Validation Done: [32384/84203]
Validation Done: [32512/84203]
Validation Done: [32640/84203]
Validation Done: [32768/84203]
Validation Done: [32896/84203]
Validation Done: [33024/84203]
Validation Done: [33152/84203]
Validation Done: [33280/84203]
Validation Done: [33408/84203]
Validation Done: [33536/84203]
Validation Done: [33664/84203]
Validation Done: [33792/84203]
Validation Done: [33920/84203]
Validation Done: [34048/84203]
Validation Done: [34176/84203]
Validation Done: [34304/84203]
Validation Done: [34432/84203]
Validation Done: [34560/84203]
Validation Done: [34688/84203]
Validation Done: [34816/84203]
Validation Done: [34944/84203]
Validation Done: [35072/84203]
Validation Done: [35200/84203]
Validation Done: [35328/84203]
Validation Done: [35456/84203]
Validation Done: [35584/84203]
Validation Done: [35712/84203]
Validation Done: [35840/84203]
Validation Done: [35968/84203]
Validation Done: [36096/84203]
Validation Done: [36224/84203]
Validation Done: [36352/84203]
Validation Done: [36480/84203]
Validation Done: [36608/84203]
Validation Done: [36736/84203]
Validation Done: [36864/84203]
Validation Done: [36992/84203]
Validation Done: [37120/84203]
Validation Done: [37248/84203]
Validation Done: [37376/84203]
Validation Done: [37504/84203]
Validation Done: [37632/84203]
Validation Done: [37760/84203]
Validation Done: [37888/84203]
Validation Done: [38016/84203]
Validation Done: [38144/84203]
Validation Done: [38272/84203]
Validation Done: [38400/84203]
Validation Done: [38528/84203]
Validation Done: [38656/84203]
Validation Done: [38784/84203]
Validation Done: [38912/84203]
Validation Done: [39040/84203]
Validation Done: [39168/84203]
Validation Done: [39296/84203]
Validation Done: [39424/84203]
Validation Done: [39552/84203]
Validation Done: [39680/84203]
Validation Done: [39808/84203]
Validation Done: [39936/84203]
Validation Done: [40064/84203]
Validation Done: [40192/84203]
Validation Done: [40320/84203]
Validation Done: [40448/84203]
Validation Done: [40576/84203]
Validation Done: [40704/84203]
Validation Done: [40832/84203]
Validation Done: [40960/84203]
Validation Done: [41088/84203]
Validation Done: [41216/84203]
Validation Done: [41344/84203]
Validation Done: [41472/84203]
Validation Done: [41600/84203]
Validation Done: [41728/84203]
Validation Done: [41856/84203]
Validation Done: [41984/84203]
Validation Done: [42112/84203]
Validation Done: [42240/84203]
Validation Done: [42368/84203]
Validation Done: [42496/84203]
Validation Done: [42624/84203]
Validation Done: [42752/84203]
Validation Done: [42880/84203]
Validation Done: [43008/84203]
Validation Done: [43136/84203]
Validation Done: [43264/84203]
Validation Done: [43392/84203]
Validation Done: [43520/84203]
Validation Done: [43648/84203]
Validation Done: [43776/84203]
Validation Done: [43904/84203]
Validation Done: [44032/84203]
Validation Done: [44160/84203]
Validation Done: [44288/84203]
Validation Done: [44416/84203]
Validation Done: [44544/84203]
Validation Done: [44672/84203]
Validation Done: [44800/84203]
Validation Done: [44928/84203]
Validation Done: [45056/84203]
Validation Done: [45184/84203]
Validation Done: [45312/84203]
Validation Done: [45440/84203]
Validation Done: [45568/84203]
Validation Done: [45696/84203]
Validation Done: [45824/84203]
Validation Done: [45952/84203]
Validation Done: [46080/84203]
Validation Done: [46208/84203]
Validation Done: [46336/84203]
Validation Done: [46464/84203]
Validation Done: [46592/84203]
Validation Done: [46720/84203]
Validation Done: [46848/84203]
Validation Done: [46976/84203]
Validation Done: [47104/84203]
Validation Done: [47232/84203]
Validation Done: [47360/84203]
Validation Done: [47488/84203]
Validation Done: [47616/84203]
Validation Done: [47744/84203]
Validation Done: [47872/84203]
Validation Done: [48000/84203]
Validation Done: [48128/84203]
Validation Done: [48256/84203]
Validation Done: [48384/84203]
Validation Done: [48512/84203]
Validation Done: [48640/84203]
Validation Done: [48768/84203]
Validation Done: [48896/84203]
Validation Done: [49024/84203]
Validation Done: [49152/84203]
Validation Done: [49280/84203]
Validation Done: [49408/84203]
Validation Done: [49536/84203]
Validation Done: [49664/84203]
Validation Done: [49792/84203]
Validation Done: [49920/84203]
Validation Done: [50048/84203]
Validation Done: [50176/84203]
Validation Done: [50304/84203]
Validation Done: [50432/84203]
Validation Done: [50560/84203]
Validation Done: [50688/84203]
Validation Done: [50816/84203]
Validation Done: [50944/84203]
Validation Done: [51072/84203]
Validation Done: [51200/84203]
Validation Done: [51328/84203]
Validation Done: [51456/84203]
Validation Done: [51584/84203]
Validation Done: [51712/84203]
Validation Done: [51840/84203]
Validation Done: [51968/84203]
Validation Done: [52096/84203]
Validation Done: [52224/84203]
Validation Done: [52352/84203]
Validation Done: [52480/84203]
Validation Done: [52608/84203]
Validation Done: [52736/84203]
Validation Done: [52864/84203]
Validation Done: [52992/84203]
Validation Done: [53120/84203]
Validation Done: [53248/84203]
Validation Done: [53376/84203]
Validation Done: [53504/84203]
Validation Done: [53632/84203]
Validation Done: [53760/84203]
Validation Done: [53888/84203]
Validation Done: [54016/84203]
Validation Done: [54144/84203]
Validation Done: [54272/84203]
Validation Done: [54400/84203]
Validation Done: [54528/84203]
Validation Done: [54656/84203]
Validation Done: [54784/84203]
Validation Done: [54912/84203]
Validation Done: [55040/84203]
Validation Done: [55168/84203]
Validation Done: [55296/84203]
Validation Done: [55424/84203]
Validation Done: [55552/84203]
Validation Done: [55680/84203]
Validation Done: [55808/84203]
Validation Done: [55936/84203]
Validation Done: [56064/84203]
Validation Done: [56192/84203]
Validation Done: [56320/84203]
Validation Done: [56448/84203]
Validation Done: [56576/84203]
Validation Done: [56704/84203]
Validation Done: [56832/84203]
Validation Done: [56960/84203]
Validation Done: [57088/84203]
Validation Done: [57216/84203]
Validation Done: [57344/84203]
Validation Done: [57472/84203]
Validation Done: [57600/84203]
Validation Done: [57728/84203]
Validation Done: [57856/84203]
Validation Done: [57984/84203]
Validation Done: [58112/84203]
Validation Done: [58240/84203]
Validation Done: [58368/84203]
Validation Done: [58496/84203]
Validation Done: [58624/84203]
Validation Done: [58752/84203]
Validation Done: [58880/84203]
Validation Done: [59008/84203]
Validation Done: [59136/84203]
Validation Done: [59264/84203]
Validation Done: [59392/84203]
Validation Done: [59520/84203]
Validation Done: [59648/84203]
Validation Done: [59776/84203]
Validation Done: [59904/84203]
Validation Done: [60032/84203]
Validation Done: [60160/84203]
Validation Done: [60288/84203]
Validation Done: [60416/84203]
Validation Done: [60544/84203]
Validation Done: [60672/84203]
Validation Done: [60800/84203]
Validation Done: [60928/84203]
Validation Done: [61056/84203]
Validation Done: [61184/84203]
Validation Done: [61312/84203]
Validation Done: [61440/84203]
Validation Done: [61568/84203]
Validation Done: [61696/84203]
Validation Done: [61824/84203]
Validation Done: [61952/84203]
Validation Done: [62080/84203]
Validation Done: [62208/84203]
Validation Done: [62336/84203]
Validation Done: [62464/84203]
Validation Done: [62592/84203]
Validation Done: [62720/84203]
Validation Done: [62848/84203]
Validation Done: [62976/84203]
Validation Done: [63104/84203]
Validation Done: [63232/84203]
Validation Done: [63360/84203]
Validation Done: [63488/84203]
Validation Done: [63616/84203]
Validation Done: [63744/84203]
Validation Done: [63872/84203]
Validation Done: [64000/84203]
Validation Done: [64128/84203]
Validation Done: [64256/84203]
Validation Done: [64384/84203]
Validation Done: [64512/84203]
Validation Done: [64640/84203]
Validation Done: [64768/84203]
Validation Done: [64896/84203]
Validation Done: [65024/84203]
Validation Done: [65152/84203]
Validation Done: [65280/84203]
Validation Done: [65408/84203]
Validation Done: [65536/84203]
Validation Done: [65664/84203]
Validation Done: [65792/84203]
Validation Done: [65920/84203]
Validation Done: [66048/84203]
Validation Done: [66176/84203]
Validation Done: [66304/84203]
Validation Done: [66432/84203]
Validation Done: [66560/84203]
Validation Done: [66688/84203]
Validation Done: [66816/84203]
Validation Done: [66944/84203]
Validation Done: [67072/84203]
Validation Done: [67200/84203]
Validation Done: [67328/84203]
Validation Done: [67456/84203]
Validation Done: [67584/84203]
Validation Done: [67712/84203]
Validation Done: [67840/84203]
Validation Done: [67968/84203]
Validation Done: [68096/84203]
Validation Done: [68224/84203]
Validation Done: [68352/84203]
Validation Done: [68480/84203]
Validation Done: [68608/84203]
Validation Done: [68736/84203]
Validation Done: [68864/84203]
Validation Done: [68992/84203]
Validation Done: [69120/84203]
Validation Done: [69248/84203]
Validation Done: [69376/84203]
Validation Done: [69504/84203]
Validation Done: [69632/84203]
Validation Done: [69760/84203]
Validation Done: [69888/84203]
Validation Done: [70016/84203]
Validation Done: [70144/84203]
Validation Done: [70272/84203]
Validation Done: [70400/84203]
Validation Done: [70528/84203]
Validation Done: [70656/84203]
Validation Done: [70784/84203]
Validation Done: [70912/84203]
Validation Done: [71040/84203]
Validation Done: [71168/84203]
Validation Done: [71296/84203]
Validation Done: [71424/84203]
Validation Done: [71552/84203]
Validation Done: [71680/84203]
Validation Done: [71808/84203]
Validation Done: [71936/84203]
Validation Done: [72064/84203]
Validation Done: [72192/84203]
Validation Done: [72320/84203]
Validation Done: [72448/84203]
Validation Done: [72576/84203]
Validation Done: [72704/84203]
Validation Done: [72832/84203]
Validation Done: [72960/84203]
Validation Done: [73088/84203]
Validation Done: [73216/84203]
Validation Done: [73344/84203]
Validation Done: [73472/84203]
Validation Done: [73600/84203]
Validation Done: [73728/84203]
Validation Done: [73856/84203]
Validation Done: [73984/84203]
Validation Done: [74112/84203]
Validation Done: [74240/84203]
Validation Done: [74368/84203]
Validation Done: [74496/84203]
Validation Done: [74624/84203]
Validation Done: [74752/84203]
Validation Done: [74880/84203]
Validation Done: [75008/84203]
Validation Done: [75136/84203]
Validation Done: [75264/84203]
Validation Done: [75392/84203]
Validation Done: [75520/84203]
Validation Done: [75648/84203]
Validation Done: [75776/84203]
Validation Done: [75904/84203]
Validation Done: [76032/84203]
Validation Done: [76160/84203]
Validation Done: [76288/84203]
Validation Done: [76416/84203]
Validation Done: [76544/84203]
Validation Done: [76672/84203]
Validation Done: [76800/84203]
Validation Done: [76928/84203]
Validation Done: [77056/84203]
Validation Done: [77184/84203]
Validation Done: [77312/84203]
Validation Done: [77440/84203]
Validation Done: [77568/84203]
Validation Done: [77696/84203]
Validation Done: [77824/84203]
Validation Done: [77952/84203]
Validation Done: [78080/84203]
Validation Done: [78208/84203]
Validation Done: [78336/84203]
Validation Done: [78464/84203]
Validation Done: [78592/84203]
Validation Done: [78720/84203]
Validation Done: [78848/84203]
Validation Done: [78976/84203]
Validation Done: [79104/84203]
Validation Done: [79232/84203]
Validation Done: [79360/84203]
Validation Done: [79488/84203]
Validation Done: [79616/84203]
Validation Done: [79744/84203]
Validation Done: [79872/84203]
Validation Done: [80000/84203]
Validation Done: [80128/84203]
Validation Done: [80256/84203]
Validation Done: [80384/84203]
Validation Done: [80512/84203]
Validation Done: [80640/84203]
Validation Done: [80768/84203]
Validation Done: [80896/84203]
Validation Done: [81024/84203]
Validation Done: [81152/84203]
Validation Done: [81280/84203]
Validation Done: [81408/84203]
Validation Done: [81536/84203]
Validation Done: [81664/84203]
Validation Done: [81792/84203]
Validation Done: [81920/84203]
Validation Done: [82048/84203]
Validation Done: [82176/84203]
Validation Done: [82304/84203]
Validation Done: [82432/84203]
Validation Done: [82560/84203]
Validation Done: [82688/84203]
Validation Done: [82816/84203]
Validation Done: [82944/84203]
Validation Done: [83072/84203]
Validation Done: [83200/84203]
Validation Done: [83328/84203]
Validation Done: [83456/84203]
Validation Done: [83584/84203]
Validation Done: [83712/84203]
Validation Done: [83840/84203]
Validation Done: [83968/84203]
Validation Done: [84096/84203]
Validation Done: [70406/84203]
[Test] Epoch: 0 Test set: Average loss: 0.0022, Accuracy: 74665/84203 (88.67%)
{'accuracy': 0.8867261261475244, 'normal': {'precision': 0.8705463182897862, 'recall': 0.7781867081888315, 'support': 28258, 'f1-score': 0.8217795881759409}, 'macro avg': {'precision': 0.8821031474386685, 'recall': 0.8598682222685153, 'support': 84203, 'f1-score': 0.8693798017476042}, 'cancer': {'precision': 0.8936599765875507, 'recall': 0.9415497363481992, 'support': 55945, 'f1-score': 0.9169800153192675}, 'weighted avg': {'precision': 0.885903177469013, 'recall': 0.8867261261475244, 'support': 84203, 'f1-score': 0.8850313475732713}}
[Train] Epoch: 1 [128/387873]    Loss: 0.002322   Batch Acc: 87.50
[Train] Epoch: 1 [256/387873]    Loss: 0.002318   Batch Acc: 89.06
[Train] Epoch: 1 [384/387873]    Loss: 0.002485   Batch Acc: 85.16
[Train] Epoch: 1 [512/387873]    Loss: 0.002350   Batch Acc: 85.94
[Train] Epoch: 1 [640/387873]    Loss: 0.002115   Batch Acc: 89.84
[Train] Epoch: 1 [768/387873]    Loss: 0.001688   Batch Acc: 92.19
[Train] Epoch: 1 [896/387873]    Loss: 0.002031   Batch Acc: 88.28
[Train] Epoch: 1 [1024/387873]    Loss: 0.002123   Batch Acc: 87.50
[Train] Epoch: 1 [1152/387873]    Loss: 0.002130   Batch Acc: 89.06
[Train] Epoch: 1 [1280/387873]    Loss: 0.002707   Batch Acc: 85.16
[Train] Epoch: 1 [1408/387873]    Loss: 0.002059   Batch Acc: 89.06
[Train] Epoch: 1 [1536/387873]    Loss: 0.001926   Batch Acc: 87.50
[Train] Epoch: 1 [1664/387873]    Loss: 0.002443   Batch Acc: 87.50
[Train] Epoch: 1 [1792/387873]    Loss: 0.002130   Batch Acc: 89.06
[Train] Epoch: 1 [1920/387873]    Loss: 0.002136   Batch Acc: 86.72
[Train] Epoch: 1 [2048/387873]    Loss: 0.002179   Batch Acc: 87.50
[Train] Epoch: 1 [2176/387873]    Loss: 0.002388   Batch Acc: 89.06
[Train] Epoch: 1 [2304/387873]    Loss: 0.002151   Batch Acc: 88.28
[Train] Epoch: 1 [2432/387873]    Loss: 0.001904   Batch Acc: 92.97
[Train] Epoch: 1 [2560/387873]    Loss: 0.002265   Batch Acc: 89.84
[Train] Epoch: 1 [2688/387873]    Loss: 0.002259   Batch Acc: 84.38
[Train] Epoch: 1 [2816/387873]    Loss: 0.001797   Batch Acc: 92.19
[Train] Epoch: 1 [2944/387873]    Loss: 0.002128   Batch Acc: 87.50
[Train] Epoch: 1 [3072/387873]    Loss: 0.002561   Batch Acc: 85.94
[Train] Epoch: 1 [3200/387873]    Loss: 0.001911   Batch Acc: 86.72
[Train] Epoch: 1 [3328/387873]    Loss: 0.001935   Batch Acc: 89.06
[Train] Epoch: 1 [3456/387873]    Loss: 0.002549   Batch Acc: 86.72
[Train] Epoch: 1 [3584/387873]    Loss: 0.001858   Batch Acc: 90.62
[Train] Epoch: 1 [3712/387873]    Loss: 0.002192   Batch Acc: 87.50
[Train] Epoch: 1 [3840/387873]    Loss: 0.002000   Batch Acc: 89.06
[Train] Epoch: 1 [3968/387873]    Loss: 0.001995   Batch Acc: 91.41
[Train] Epoch: 1 [4096/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 1 [4224/387873]    Loss: 0.002632   Batch Acc: 83.59
[Train] Epoch: 1 [4352/387873]    Loss: 0.002505   Batch Acc: 85.16
[Train] Epoch: 1 [4480/387873]    Loss: 0.002657   Batch Acc: 86.72
[Train] Epoch: 1 [4608/387873]    Loss: 0.001897   Batch Acc: 90.62
[Train] Epoch: 1 [4736/387873]    Loss: 0.002623   Batch Acc: 82.81
[Train] Epoch: 1 [4864/387873]    Loss: 0.001873   Batch Acc: 92.19
[Train] Epoch: 1 [4992/387873]    Loss: 0.002704   Batch Acc: 87.50
[Train] Epoch: 1 [5120/387873]    Loss: 0.002031   Batch Acc: 87.50
[Train] Epoch: 1 [5248/387873]    Loss: 0.002291   Batch Acc: 85.94
[Train] Epoch: 1 [5376/387873]    Loss: 0.002768   Batch Acc: 84.38
[Train] Epoch: 1 [5504/387873]    Loss: 0.001704   Batch Acc: 94.53
[Train] Epoch: 1 [5632/387873]    Loss: 0.001826   Batch Acc: 90.62
[Train] Epoch: 1 [5760/387873]    Loss: 0.002973   Batch Acc: 80.47
[Train] Epoch: 1 [5888/387873]    Loss: 0.002322   Batch Acc: 89.84
[Train] Epoch: 1 [6016/387873]    Loss: 0.001864   Batch Acc: 90.62
[Train] Epoch: 1 [6144/387873]    Loss: 0.001615   Batch Acc: 92.97
[Train] Epoch: 1 [6272/387873]    Loss: 0.002185   Batch Acc: 87.50
[Train] Epoch: 1 [6400/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 1 [6528/387873]    Loss: 0.002600   Batch Acc: 86.72
[Train] Epoch: 1 [6656/387873]    Loss: 0.002423   Batch Acc: 84.38
[Train] Epoch: 1 [6784/387873]    Loss: 0.002120   Batch Acc: 85.94
[Train] Epoch: 1 [6912/387873]    Loss: 0.001827   Batch Acc: 92.97
[Train] Epoch: 1 [7040/387873]    Loss: 0.002083   Batch Acc: 86.72
[Train] Epoch: 1 [7168/387873]    Loss: 0.002103   Batch Acc: 86.72
[Train] Epoch: 1 [7296/387873]    Loss: 0.002792   Batch Acc: 82.03
[Train] Epoch: 1 [7424/387873]    Loss: 0.002388   Batch Acc: 90.62
[Train] Epoch: 1 [7552/387873]    Loss: 0.002232   Batch Acc: 87.50
[Train] Epoch: 1 [7680/387873]    Loss: 0.002236   Batch Acc: 87.50
[Train] Epoch: 1 [7808/387873]    Loss: 0.002513   Batch Acc: 86.72
[Train] Epoch: 1 [7936/387873]    Loss: 0.002029   Batch Acc: 90.62
[Train] Epoch: 1 [8064/387873]    Loss: 0.002434   Batch Acc: 89.06
[Train] Epoch: 1 [8192/387873]    Loss: 0.002020   Batch Acc: 88.28
[Train] Epoch: 1 [8320/387873]    Loss: 0.001638   Batch Acc: 92.97
[Train] Epoch: 1 [8448/387873]    Loss: 0.001843   Batch Acc: 90.62
[Train] Epoch: 1 [8576/387873]    Loss: 0.002468   Batch Acc: 89.06
[Train] Epoch: 1 [8704/387873]    Loss: 0.001827   Batch Acc: 91.41
[Train] Epoch: 1 [8832/387873]    Loss: 0.002609   Batch Acc: 85.16
[Train] Epoch: 1 [8960/387873]    Loss: 0.002059   Batch Acc: 90.62
[Train] Epoch: 1 [9088/387873]    Loss: 0.002489   Batch Acc: 89.06
[Train] Epoch: 1 [9216/387873]    Loss: 0.002478   Batch Acc: 85.16
[Train] Epoch: 1 [9344/387873]    Loss: 0.002215   Batch Acc: 88.28
[Train] Epoch: 1 [9472/387873]    Loss: 0.003156   Batch Acc: 82.81
[Train] Epoch: 1 [9600/387873]    Loss: 0.002045   Batch Acc: 91.41
[Train] Epoch: 1 [9728/387873]    Loss: 0.002177   Batch Acc: 92.19
[Train] Epoch: 1 [9856/387873]    Loss: 0.001942   Batch Acc: 91.41
[Train] Epoch: 1 [9984/387873]    Loss: 0.002280   Batch Acc: 88.28
[Train] Epoch: 1 [10112/387873]    Loss: 0.001447   Batch Acc: 95.31
[Train] Epoch: 1 [10240/387873]    Loss: 0.002485   Batch Acc: 85.16
[Train] Epoch: 1 [10368/387873]    Loss: 0.002014   Batch Acc: 90.62
[Train] Epoch: 1 [10496/387873]    Loss: 0.002701   Batch Acc: 86.72
[Train] Epoch: 1 [10624/387873]    Loss: 0.002084   Batch Acc: 89.84
[Train] Epoch: 1 [10752/387873]    Loss: 0.003151   Batch Acc: 79.69
[Train] Epoch: 1 [10880/387873]    Loss: 0.002208   Batch Acc: 85.16
[Train] Epoch: 1 [11008/387873]    Loss: 0.002590   Batch Acc: 85.94
[Train] Epoch: 1 [11136/387873]    Loss: 0.002153   Batch Acc: 89.06
[Train] Epoch: 1 [11264/387873]    Loss: 0.002496   Batch Acc: 83.59
[Train] Epoch: 1 [11392/387873]    Loss: 0.002309   Batch Acc: 86.72
[Train] Epoch: 1 [11520/387873]    Loss: 0.001804   Batch Acc: 91.41
[Train] Epoch: 1 [11648/387873]    Loss: 0.002221   Batch Acc: 85.94
[Train] Epoch: 1 [11776/387873]    Loss: 0.002176   Batch Acc: 90.62
[Train] Epoch: 1 [11904/387873]    Loss: 0.002151   Batch Acc: 85.94
[Train] Epoch: 1 [12032/387873]    Loss: 0.002236   Batch Acc: 87.50
[Train] Epoch: 1 [12160/387873]    Loss: 0.001868   Batch Acc: 89.06
[Train] Epoch: 1 [12288/387873]    Loss: 0.002389   Batch Acc: 89.06
[Train] Epoch: 1 [12416/387873]    Loss: 0.002045   Batch Acc: 88.28
[Train] Epoch: 1 [12544/387873]    Loss: 0.001899   Batch Acc: 89.84
[Train] Epoch: 1 [12672/387873]    Loss: 0.001817   Batch Acc: 92.19
[Train] Epoch: 1 [12800/387873]    Loss: 0.002468   Batch Acc: 85.16
[Train] Epoch: 1 [12928/387873]    Loss: 0.002522   Batch Acc: 86.72
[Train] Epoch: 1 [13056/387873]    Loss: 0.002408   Batch Acc: 85.94
[Train] Epoch: 1 [13184/387873]    Loss: 0.001979   Batch Acc: 92.19
[Train] Epoch: 1 [13312/387873]    Loss: 0.002533   Batch Acc: 88.28
[Train] Epoch: 1 [13440/387873]    Loss: 0.002774   Batch Acc: 83.59
[Train] Epoch: 1 [13568/387873]    Loss: 0.002238   Batch Acc: 85.94
[Train] Epoch: 1 [13696/387873]    Loss: 0.002094   Batch Acc: 88.28
[Train] Epoch: 1 [13824/387873]    Loss: 0.002315   Batch Acc: 89.84
[Train] Epoch: 1 [13952/387873]    Loss: 0.002225   Batch Acc: 89.06
[Train] Epoch: 1 [14080/387873]    Loss: 0.002516   Batch Acc: 85.16
[Train] Epoch: 1 [14208/387873]    Loss: 0.002799   Batch Acc: 82.81
[Train] Epoch: 1 [14336/387873]    Loss: 0.002430   Batch Acc: 85.16
[Train] Epoch: 1 [14464/387873]    Loss: 0.002491   Batch Acc: 85.94
[Train] Epoch: 1 [14592/387873]    Loss: 0.002039   Batch Acc: 87.50
[Train] Epoch: 1 [14720/387873]    Loss: 0.002353   Batch Acc: 89.84
[Train] Epoch: 1 [14848/387873]    Loss: 0.002206   Batch Acc: 88.28
[Train] Epoch: 1 [14976/387873]    Loss: 0.002105   Batch Acc: 89.84
[Train] Epoch: 1 [15104/387873]    Loss: 0.002384   Batch Acc: 85.94
[Train] Epoch: 1 [15232/387873]    Loss: 0.001724   Batch Acc: 91.41
[Train] Epoch: 1 [15360/387873]    Loss: 0.002134   Batch Acc: 90.62
[Train] Epoch: 1 [15488/387873]    Loss: 0.002246   Batch Acc: 87.50
[Train] Epoch: 1 [15616/387873]    Loss: 0.002569   Batch Acc: 85.94
[Train] Epoch: 1 [15744/387873]    Loss: 0.002897   Batch Acc: 82.81
[Train] Epoch: 1 [15872/387873]    Loss: 0.001846   Batch Acc: 89.06
[Train] Epoch: 1 [16000/387873]    Loss: 0.002478   Batch Acc: 89.06
[Train] Epoch: 1 [16128/387873]    Loss: 0.002125   Batch Acc: 88.28
[Train] Epoch: 1 [16256/387873]    Loss: 0.002247   Batch Acc: 83.59
[Train] Epoch: 1 [16384/387873]    Loss: 0.002187   Batch Acc: 84.38
[Train] Epoch: 1 [16512/387873]    Loss: 0.002003   Batch Acc: 90.62
[Train] Epoch: 1 [16640/387873]    Loss: 0.002376   Batch Acc: 87.50
[Train] Epoch: 1 [16768/387873]    Loss: 0.002201   Batch Acc: 87.50
[Train] Epoch: 1 [16896/387873]    Loss: 0.002016   Batch Acc: 89.06
[Train] Epoch: 1 [17024/387873]    Loss: 0.002448   Batch Acc: 85.16
[Train] Epoch: 1 [17152/387873]    Loss: 0.001838   Batch Acc: 91.41
[Train] Epoch: 1 [17280/387873]    Loss: 0.001995   Batch Acc: 89.06
[Train] Epoch: 1 [17408/387873]    Loss: 0.002804   Batch Acc: 80.47
[Train] Epoch: 1 [17536/387873]    Loss: 0.002115   Batch Acc: 89.06
[Train] Epoch: 1 [17664/387873]    Loss: 0.002063   Batch Acc: 89.84
[Train] Epoch: 1 [17792/387873]    Loss: 0.001993   Batch Acc: 90.62
[Train] Epoch: 1 [17920/387873]    Loss: 0.002181   Batch Acc: 87.50
[Train] Epoch: 1 [18048/387873]    Loss: 0.001861   Batch Acc: 89.84
[Train] Epoch: 1 [18176/387873]    Loss: 0.002533   Batch Acc: 85.16
[Train] Epoch: 1 [18304/387873]    Loss: 0.002265   Batch Acc: 85.16
[Train] Epoch: 1 [18432/387873]    Loss: 0.001579   Batch Acc: 91.41
[Train] Epoch: 1 [18560/387873]    Loss: 0.001980   Batch Acc: 91.41
[Train] Epoch: 1 [18688/387873]    Loss: 0.002132   Batch Acc: 89.84
[Train] Epoch: 1 [18816/387873]    Loss: 0.002481   Batch Acc: 88.28
[Train] Epoch: 1 [18944/387873]    Loss: 0.002674   Batch Acc: 88.28
[Train] Epoch: 1 [19072/387873]    Loss: 0.001948   Batch Acc: 89.84
[Train] Epoch: 1 [19200/387873]    Loss: 0.002815   Batch Acc: 85.16
[Train] Epoch: 1 [19328/387873]    Loss: 0.002245   Batch Acc: 88.28
[Train] Epoch: 1 [19456/387873]    Loss: 0.002352   Batch Acc: 87.50
[Train] Epoch: 1 [19584/387873]    Loss: 0.001935   Batch Acc: 90.62
[Train] Epoch: 1 [19712/387873]    Loss: 0.002020   Batch Acc: 87.50
[Train] Epoch: 1 [19840/387873]    Loss: 0.002022   Batch Acc: 91.41
[Train] Epoch: 1 [19968/387873]    Loss: 0.002373   Batch Acc: 88.28
[Train] Epoch: 1 [20096/387873]    Loss: 0.002574   Batch Acc: 88.28
[Train] Epoch: 1 [20224/387873]    Loss: 0.001871   Batch Acc: 91.41
[Train] Epoch: 1 [20352/387873]    Loss: 0.003136   Batch Acc: 83.59
[Train] Epoch: 1 [20480/387873]    Loss: 0.001817   Batch Acc: 92.19
[Train] Epoch: 1 [20608/387873]    Loss: 0.002360   Batch Acc: 89.06
[Train] Epoch: 1 [20736/387873]    Loss: 0.001566   Batch Acc: 92.19
[Train] Epoch: 1 [20864/387873]    Loss: 0.002528   Batch Acc: 87.50
[Train] Epoch: 1 [20992/387873]    Loss: 0.002096   Batch Acc: 92.19
[Train] Epoch: 1 [21120/387873]    Loss: 0.002052   Batch Acc: 91.41
[Train] Epoch: 1 [21248/387873]    Loss: 0.002616   Batch Acc: 84.38
[Train] Epoch: 1 [21376/387873]    Loss: 0.002240   Batch Acc: 85.94
[Train] Epoch: 1 [21504/387873]    Loss: 0.002773   Batch Acc: 85.16
[Train] Epoch: 1 [21632/387873]    Loss: 0.002245   Batch Acc: 87.50
[Train] Epoch: 1 [21760/387873]    Loss: 0.002254   Batch Acc: 89.06
[Train] Epoch: 1 [21888/387873]    Loss: 0.002247   Batch Acc: 87.50
[Train] Epoch: 1 [22016/387873]    Loss: 0.002432   Batch Acc: 86.72
[Train] Epoch: 1 [22144/387873]    Loss: 0.002456   Batch Acc: 86.72
[Train] Epoch: 1 [22272/387873]    Loss: 0.002844   Batch Acc: 87.50
[Train] Epoch: 1 [22400/387873]    Loss: 0.002158   Batch Acc: 89.06
[Train] Epoch: 1 [22528/387873]    Loss: 0.001631   Batch Acc: 91.41
[Train] Epoch: 1 [22656/387873]    Loss: 0.002447   Batch Acc: 90.62
[Train] Epoch: 1 [22784/387873]    Loss: 0.002080   Batch Acc: 89.84
[Train] Epoch: 1 [22912/387873]    Loss: 0.002147   Batch Acc: 89.06
[Train] Epoch: 1 [23040/387873]    Loss: 0.001998   Batch Acc: 89.06
[Train] Epoch: 1 [23168/387873]    Loss: 0.002999   Batch Acc: 80.47
[Train] Epoch: 1 [23296/387873]    Loss: 0.001875   Batch Acc: 89.84
[Train] Epoch: 1 [23424/387873]    Loss: 0.002357   Batch Acc: 87.50
[Train] Epoch: 1 [23552/387873]    Loss: 0.002128   Batch Acc: 88.28
[Train] Epoch: 1 [23680/387873]    Loss: 0.002287   Batch Acc: 86.72
[Train] Epoch: 1 [23808/387873]    Loss: 0.001925   Batch Acc: 87.50
[Train] Epoch: 1 [23936/387873]    Loss: 0.002165   Batch Acc: 89.84
[Train] Epoch: 1 [24064/387873]    Loss: 0.002428   Batch Acc: 90.62
[Train] Epoch: 1 [24192/387873]    Loss: 0.002396   Batch Acc: 86.72
[Train] Epoch: 1 [24320/387873]    Loss: 0.002544   Batch Acc: 84.38
[Train] Epoch: 1 [24448/387873]    Loss: 0.001992   Batch Acc: 91.41
[Train] Epoch: 1 [24576/387873]    Loss: 0.001615   Batch Acc: 93.75
[Train] Epoch: 1 [24704/387873]    Loss: 0.002001   Batch Acc: 89.06
[Train] Epoch: 1 [24832/387873]    Loss: 0.002435   Batch Acc: 87.50
[Train] Epoch: 1 [24960/387873]    Loss: 0.002663   Batch Acc: 86.72
[Train] Epoch: 1 [25088/387873]    Loss: 0.002414   Batch Acc: 89.06
[Train] Epoch: 1 [25216/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 1 [25344/387873]    Loss: 0.002171   Batch Acc: 90.62
[Train] Epoch: 1 [25472/387873]    Loss: 0.002547   Batch Acc: 85.94
[Train] Epoch: 1 [25600/387873]    Loss: 0.001851   Batch Acc: 93.75
[Train] Epoch: 1 [25728/387873]    Loss: 0.002435   Batch Acc: 84.38
[Train] Epoch: 1 [25856/387873]    Loss: 0.002141   Batch Acc: 91.41
[Train] Epoch: 1 [25984/387873]    Loss: 0.001884   Batch Acc: 90.62
[Train] Epoch: 1 [26112/387873]    Loss: 0.002922   Batch Acc: 82.81
[Train] Epoch: 1 [26240/387873]    Loss: 0.002593   Batch Acc: 85.94
[Train] Epoch: 1 [26368/387873]    Loss: 0.001916   Batch Acc: 89.06
[Train] Epoch: 1 [26496/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 1 [26624/387873]    Loss: 0.001747   Batch Acc: 92.97
[Train] Epoch: 1 [26752/387873]    Loss: 0.002625   Batch Acc: 82.03
[Train] Epoch: 1 [26880/387873]    Loss: 0.002023   Batch Acc: 90.62
[Train] Epoch: 1 [27008/387873]    Loss: 0.002190   Batch Acc: 85.94
[Train] Epoch: 1 [27136/387873]    Loss: 0.002238   Batch Acc: 87.50
[Train] Epoch: 1 [27264/387873]    Loss: 0.001596   Batch Acc: 92.19
[Train] Epoch: 1 [27392/387873]    Loss: 0.002388   Batch Acc: 87.50
[Train] Epoch: 1 [27520/387873]    Loss: 0.001931   Batch Acc: 90.62
[Train] Epoch: 1 [27648/387873]    Loss: 0.001780   Batch Acc: 92.19
[Train] Epoch: 1 [27776/387873]    Loss: 0.001831   Batch Acc: 92.19
[Train] Epoch: 1 [27904/387873]    Loss: 0.003046   Batch Acc: 80.47
[Train] Epoch: 1 [28032/387873]    Loss: 0.002364   Batch Acc: 86.72
[Train] Epoch: 1 [28160/387873]    Loss: 0.002183   Batch Acc: 87.50
[Train] Epoch: 1 [28288/387873]    Loss: 0.001811   Batch Acc: 90.62
[Train] Epoch: 1 [28416/387873]    Loss: 0.001923   Batch Acc: 87.50
[Train] Epoch: 1 [28544/387873]    Loss: 0.001979   Batch Acc: 89.06
[Train] Epoch: 1 [28672/387873]    Loss: 0.002595   Batch Acc: 87.50
[Train] Epoch: 1 [28800/387873]    Loss: 0.002109   Batch Acc: 89.06
[Train] Epoch: 1 [28928/387873]    Loss: 0.002636   Batch Acc: 83.59
[Train] Epoch: 1 [29056/387873]    Loss: 0.002215   Batch Acc: 87.50
[Train] Epoch: 1 [29184/387873]    Loss: 0.002432   Batch Acc: 85.94
[Train] Epoch: 1 [29312/387873]    Loss: 0.002134   Batch Acc: 90.62
[Train] Epoch: 1 [29440/387873]    Loss: 0.002122   Batch Acc: 88.28
[Train] Epoch: 1 [29568/387873]    Loss: 0.001968   Batch Acc: 86.72
[Train] Epoch: 1 [29696/387873]    Loss: 0.002645   Batch Acc: 86.72
[Train] Epoch: 1 [29824/387873]    Loss: 0.002052   Batch Acc: 85.94
[Train] Epoch: 1 [29952/387873]    Loss: 0.001949   Batch Acc: 88.28
[Train] Epoch: 1 [30080/387873]    Loss: 0.001837   Batch Acc: 89.84
[Train] Epoch: 1 [30208/387873]    Loss: 0.002365   Batch Acc: 87.50
[Train] Epoch: 1 [30336/387873]    Loss: 0.002259   Batch Acc: 88.28
[Train] Epoch: 1 [30464/387873]    Loss: 0.002317   Batch Acc: 88.28
[Train] Epoch: 1 [30592/387873]    Loss: 0.001841   Batch Acc: 92.19
[Train] Epoch: 1 [30720/387873]    Loss: 0.001932   Batch Acc: 91.41
[Train] Epoch: 1 [30848/387873]    Loss: 0.002074   Batch Acc: 88.28
[Train] Epoch: 1 [30976/387873]    Loss: 0.001747   Batch Acc: 91.41
[Train] Epoch: 1 [31104/387873]    Loss: 0.002554   Batch Acc: 85.94
[Train] Epoch: 1 [31232/387873]    Loss: 0.002154   Batch Acc: 87.50
[Train] Epoch: 1 [31360/387873]    Loss: 0.002000   Batch Acc: 89.06
[Train] Epoch: 1 [31488/387873]    Loss: 0.002184   Batch Acc: 88.28
[Train] Epoch: 1 [31616/387873]    Loss: 0.001634   Batch Acc: 92.19
[Train] Epoch: 1 [31744/387873]    Loss: 0.002332   Batch Acc: 88.28
[Train] Epoch: 1 [31872/387873]    Loss: 0.001910   Batch Acc: 90.62
[Train] Epoch: 1 [32000/387873]    Loss: 0.002236   Batch Acc: 86.72
[Train] Epoch: 1 [32128/387873]    Loss: 0.002439   Batch Acc: 85.16
[Train] Epoch: 1 [32256/387873]    Loss: 0.001914   Batch Acc: 90.62
[Train] Epoch: 1 [32384/387873]    Loss: 0.002238   Batch Acc: 88.28
[Train] Epoch: 1 [32512/387873]    Loss: 0.001905   Batch Acc: 88.28
[Train] Epoch: 1 [32640/387873]    Loss: 0.002675   Batch Acc: 84.38
[Train] Epoch: 1 [32768/387873]    Loss: 0.001763   Batch Acc: 90.62
[Train] Epoch: 1 [32896/387873]    Loss: 0.002160   Batch Acc: 88.28
[Train] Epoch: 1 [33024/387873]    Loss: 0.002345   Batch Acc: 85.16
[Train] Epoch: 1 [33152/387873]    Loss: 0.002222   Batch Acc: 90.62
[Train] Epoch: 1 [33280/387873]    Loss: 0.001983   Batch Acc: 89.06
[Train] Epoch: 1 [33408/387873]    Loss: 0.002436   Batch Acc: 85.94
[Train] Epoch: 1 [33536/387873]    Loss: 0.002160   Batch Acc: 90.62
[Train] Epoch: 1 [33664/387873]    Loss: 0.002510   Batch Acc: 85.94
[Train] Epoch: 1 [33792/387873]    Loss: 0.002168   Batch Acc: 88.28
[Train] Epoch: 1 [33920/387873]    Loss: 0.002341   Batch Acc: 89.06
[Train] Epoch: 1 [34048/387873]    Loss: 0.002558   Batch Acc: 86.72
[Train] Epoch: 1 [34176/387873]    Loss: 0.003329   Batch Acc: 78.91
[Train] Epoch: 1 [34304/387873]    Loss: 0.001637   Batch Acc: 91.41
[Train] Epoch: 1 [34432/387873]    Loss: 0.001939   Batch Acc: 89.06
[Train] Epoch: 1 [34560/387873]    Loss: 0.002456   Batch Acc: 83.59
[Train] Epoch: 1 [34688/387873]    Loss: 0.002679   Batch Acc: 87.50
[Train] Epoch: 1 [34816/387873]    Loss: 0.002547   Batch Acc: 88.28
[Train] Epoch: 1 [34944/387873]    Loss: 0.001972   Batch Acc: 90.62
[Train] Epoch: 1 [35072/387873]    Loss: 0.002351   Batch Acc: 89.06
[Train] Epoch: 1 [35200/387873]    Loss: 0.002254   Batch Acc: 87.50
[Train] Epoch: 1 [35328/387873]    Loss: 0.002139   Batch Acc: 89.06
[Train] Epoch: 1 [35456/387873]    Loss: 0.002502   Batch Acc: 87.50
[Train] Epoch: 1 [35584/387873]    Loss: 0.001766   Batch Acc: 92.19
[Train] Epoch: 1 [35712/387873]    Loss: 0.002083   Batch Acc: 90.62
[Train] Epoch: 1 [35840/387873]    Loss: 0.002367   Batch Acc: 87.50
[Train] Epoch: 1 [35968/387873]    Loss: 0.001619   Batch Acc: 96.09
[Train] Epoch: 1 [36096/387873]    Loss: 0.002121   Batch Acc: 88.28
[Train] Epoch: 1 [36224/387873]    Loss: 0.001972   Batch Acc: 89.84
[Train] Epoch: 1 [36352/387873]    Loss: 0.001634   Batch Acc: 92.19
[Train] Epoch: 1 [36480/387873]    Loss: 0.002810   Batch Acc: 83.59
[Train] Epoch: 1 [36608/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 1 [36736/387873]    Loss: 0.002181   Batch Acc: 89.84
[Train] Epoch: 1 [36864/387873]    Loss: 0.002306   Batch Acc: 88.28
[Train] Epoch: 1 [36992/387873]    Loss: 0.002406   Batch Acc: 86.72
[Train] Epoch: 1 [37120/387873]    Loss: 0.001898   Batch Acc: 90.62
[Train] Epoch: 1 [37248/387873]    Loss: 0.002105   Batch Acc: 89.06
[Train] Epoch: 1 [37376/387873]    Loss: 0.001892   Batch Acc: 91.41
[Train] Epoch: 1 [37504/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 1 [37632/387873]    Loss: 0.002268   Batch Acc: 89.06
[Train] Epoch: 1 [37760/387873]    Loss: 0.002288   Batch Acc: 88.28
[Train] Epoch: 1 [37888/387873]    Loss: 0.002572   Batch Acc: 88.28
[Train] Epoch: 1 [38016/387873]    Loss: 0.002621   Batch Acc: 85.16
[Train] Epoch: 1 [38144/387873]    Loss: 0.002008   Batch Acc: 91.41
[Train] Epoch: 1 [38272/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 1 [38400/387873]    Loss: 0.001763   Batch Acc: 88.28
[Train] Epoch: 1 [38528/387873]    Loss: 0.002120   Batch Acc: 89.84
[Train] Epoch: 1 [38656/387873]    Loss: 0.002462   Batch Acc: 87.50
[Train] Epoch: 1 [38784/387873]    Loss: 0.002446   Batch Acc: 89.06
[Train] Epoch: 1 [38912/387873]    Loss: 0.002328   Batch Acc: 87.50
[Train] Epoch: 1 [39040/387873]    Loss: 0.002284   Batch Acc: 91.41
[Train] Epoch: 1 [39168/387873]    Loss: 0.001931   Batch Acc: 92.19
[Train] Epoch: 1 [39296/387873]    Loss: 0.002163   Batch Acc: 85.94
[Train] Epoch: 1 [39424/387873]    Loss: 0.002242   Batch Acc: 90.62
[Train] Epoch: 1 [39552/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 1 [39680/387873]    Loss: 0.001704   Batch Acc: 92.97
[Train] Epoch: 1 [39808/387873]    Loss: 0.001915   Batch Acc: 86.72
[Train] Epoch: 1 [39936/387873]    Loss: 0.002016   Batch Acc: 89.06
[Train] Epoch: 1 [40064/387873]    Loss: 0.002097   Batch Acc: 85.94
[Train] Epoch: 1 [40192/387873]    Loss: 0.002268   Batch Acc: 91.41
[Train] Epoch: 1 [40320/387873]    Loss: 0.002104   Batch Acc: 92.97
[Train] Epoch: 1 [40448/387873]    Loss: 0.002079   Batch Acc: 89.06
[Train] Epoch: 1 [40576/387873]    Loss: 0.002169   Batch Acc: 87.50
[Train] Epoch: 1 [40704/387873]    Loss: 0.002086   Batch Acc: 89.06
[Train] Epoch: 1 [40832/387873]    Loss: 0.002781   Batch Acc: 84.38
[Train] Epoch: 1 [40960/387873]    Loss: 0.002228   Batch Acc: 89.06
[Train] Epoch: 1 [41088/387873]    Loss: 0.002322   Batch Acc: 85.94
[Train] Epoch: 1 [41216/387873]    Loss: 0.002482   Batch Acc: 86.72
[Train] Epoch: 1 [41344/387873]    Loss: 0.001748   Batch Acc: 91.41
[Train] Epoch: 1 [41472/387873]    Loss: 0.002248   Batch Acc: 92.97
[Train] Epoch: 1 [41600/387873]    Loss: 0.002103   Batch Acc: 86.72
[Train] Epoch: 1 [41728/387873]    Loss: 0.002334   Batch Acc: 87.50
[Train] Epoch: 1 [41856/387873]    Loss: 0.002219   Batch Acc: 85.94
[Train] Epoch: 1 [41984/387873]    Loss: 0.002133   Batch Acc: 89.06
[Train] Epoch: 1 [42112/387873]    Loss: 0.001958   Batch Acc: 89.84
[Train] Epoch: 1 [42240/387873]    Loss: 0.002082   Batch Acc: 90.62
[Train] Epoch: 1 [42368/387873]    Loss: 0.002130   Batch Acc: 89.06
[Train] Epoch: 1 [42496/387873]    Loss: 0.002152   Batch Acc: 86.72
[Train] Epoch: 1 [42624/387873]    Loss: 0.002505   Batch Acc: 84.38
[Train] Epoch: 1 [42752/387873]    Loss: 0.002263   Batch Acc: 89.84
[Train] Epoch: 1 [42880/387873]    Loss: 0.001467   Batch Acc: 93.75
[Train] Epoch: 1 [43008/387873]    Loss: 0.002392   Batch Acc: 87.50
[Train] Epoch: 1 [43136/387873]    Loss: 0.002498   Batch Acc: 86.72
[Train] Epoch: 1 [43264/387873]    Loss: 0.001711   Batch Acc: 92.19
[Train] Epoch: 1 [43392/387873]    Loss: 0.002090   Batch Acc: 89.06
[Train] Epoch: 1 [43520/387873]    Loss: 0.002174   Batch Acc: 90.62
[Train] Epoch: 1 [43648/387873]    Loss: 0.002064   Batch Acc: 87.50
[Train] Epoch: 1 [43776/387873]    Loss: 0.001882   Batch Acc: 90.62
[Train] Epoch: 1 [43904/387873]    Loss: 0.003134   Batch Acc: 84.38
[Train] Epoch: 1 [44032/387873]    Loss: 0.002468   Batch Acc: 87.50
[Train] Epoch: 1 [44160/387873]    Loss: 0.002366   Batch Acc: 87.50
[Train] Epoch: 1 [44288/387873]    Loss: 0.002036   Batch Acc: 89.06
[Train] Epoch: 1 [44416/387873]    Loss: 0.001914   Batch Acc: 93.75
[Train] Epoch: 1 [44544/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 1 [44672/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 1 [44800/387873]    Loss: 0.002026   Batch Acc: 89.84
[Train] Epoch: 1 [44928/387873]    Loss: 0.002075   Batch Acc: 89.84
[Train] Epoch: 1 [45056/387873]    Loss: 0.002122   Batch Acc: 87.50
[Train] Epoch: 1 [45184/387873]    Loss: 0.002410   Batch Acc: 85.94
[Train] Epoch: 1 [45312/387873]    Loss: 0.002088   Batch Acc: 90.62
[Train] Epoch: 1 [45440/387873]    Loss: 0.001836   Batch Acc: 89.84
[Train] Epoch: 1 [45568/387873]    Loss: 0.001993   Batch Acc: 90.62
[Train] Epoch: 1 [45696/387873]    Loss: 0.002285   Batch Acc: 89.84
[Train] Epoch: 1 [45824/387873]    Loss: 0.002322   Batch Acc: 86.72
[Train] Epoch: 1 [45952/387873]    Loss: 0.001750   Batch Acc: 93.75
[Train] Epoch: 1 [46080/387873]    Loss: 0.002079   Batch Acc: 86.72
[Train] Epoch: 1 [46208/387873]    Loss: 0.002120   Batch Acc: 88.28
[Train] Epoch: 1 [46336/387873]    Loss: 0.002163   Batch Acc: 89.84
[Train] Epoch: 1 [46464/387873]    Loss: 0.001699   Batch Acc: 94.53
[Train] Epoch: 1 [46592/387873]    Loss: 0.002349   Batch Acc: 89.06
[Train] Epoch: 1 [46720/387873]    Loss: 0.002699   Batch Acc: 85.16
[Train] Epoch: 1 [46848/387873]    Loss: 0.002282   Batch Acc: 85.94
[Train] Epoch: 1 [46976/387873]    Loss: 0.002084   Batch Acc: 87.50
[Train] Epoch: 1 [47104/387873]    Loss: 0.002212   Batch Acc: 88.28
[Train] Epoch: 1 [47232/387873]    Loss: 0.001914   Batch Acc: 93.75
[Train] Epoch: 1 [47360/387873]    Loss: 0.002386   Batch Acc: 87.50
[Train] Epoch: 1 [47488/387873]    Loss: 0.002155   Batch Acc: 87.50
[Train] Epoch: 1 [47616/387873]    Loss: 0.001809   Batch Acc: 90.62
[Train] Epoch: 1 [47744/387873]    Loss: 0.001709   Batch Acc: 90.62
[Train] Epoch: 1 [47872/387873]    Loss: 0.001660   Batch Acc: 92.19
[Train] Epoch: 1 [48000/387873]    Loss: 0.002456   Batch Acc: 89.06
[Train] Epoch: 1 [48128/387873]    Loss: 0.002762   Batch Acc: 85.94
[Train] Epoch: 1 [48256/387873]    Loss: 0.002125   Batch Acc: 89.84
[Train] Epoch: 1 [48384/387873]    Loss: 0.002960   Batch Acc: 83.59
[Train] Epoch: 1 [48512/387873]    Loss: 0.002278   Batch Acc: 88.28
[Train] Epoch: 1 [48640/387873]    Loss: 0.002278   Batch Acc: 87.50
[Train] Epoch: 1 [48768/387873]    Loss: 0.002077   Batch Acc: 90.62
[Train] Epoch: 1 [48896/387873]    Loss: 0.002517   Batch Acc: 86.72
[Train] Epoch: 1 [49024/387873]    Loss: 0.002598   Batch Acc: 89.06
[Train] Epoch: 1 [49152/387873]    Loss: 0.002631   Batch Acc: 85.94
[Train] Epoch: 1 [49280/387873]    Loss: 0.002399   Batch Acc: 86.72
[Train] Epoch: 1 [49408/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 1 [49536/387873]    Loss: 0.002374   Batch Acc: 85.16
[Train] Epoch: 1 [49664/387873]    Loss: 0.002637   Batch Acc: 86.72
[Train] Epoch: 1 [49792/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 1 [49920/387873]    Loss: 0.002478   Batch Acc: 85.94
[Train] Epoch: 1 [50048/387873]    Loss: 0.001932   Batch Acc: 92.19
[Train] Epoch: 1 [50176/387873]    Loss: 0.002700   Batch Acc: 82.81
[Train] Epoch: 1 [50304/387873]    Loss: 0.002670   Batch Acc: 84.38
[Train] Epoch: 1 [50432/387873]    Loss: 0.002181   Batch Acc: 88.28
[Train] Epoch: 1 [50560/387873]    Loss: 0.002917   Batch Acc: 81.25
[Train] Epoch: 1 [50688/387873]    Loss: 0.001505   Batch Acc: 93.75
[Train] Epoch: 1 [50816/387873]    Loss: 0.002215   Batch Acc: 88.28
[Train] Epoch: 1 [50944/387873]    Loss: 0.002301   Batch Acc: 86.72
[Train] Epoch: 1 [51072/387873]    Loss: 0.002191   Batch Acc: 87.50
[Train] Epoch: 1 [51200/387873]    Loss: 0.002048   Batch Acc: 90.62
[Train] Epoch: 1 [51328/387873]    Loss: 0.001982   Batch Acc: 89.84
[Train] Epoch: 1 [51456/387873]    Loss: 0.002866   Batch Acc: 83.59
[Train] Epoch: 1 [51584/387873]    Loss: 0.002030   Batch Acc: 92.19
[Train] Epoch: 1 [51712/387873]    Loss: 0.002166   Batch Acc: 90.62
[Train] Epoch: 1 [51840/387873]    Loss: 0.002040   Batch Acc: 89.06
[Train] Epoch: 1 [51968/387873]    Loss: 0.002279   Batch Acc: 89.84
[Train] Epoch: 1 [52096/387873]    Loss: 0.002353   Batch Acc: 84.38
[Train] Epoch: 1 [52224/387873]    Loss: 0.001810   Batch Acc: 90.62
[Train] Epoch: 1 [52352/387873]    Loss: 0.002075   Batch Acc: 87.50
[Train] Epoch: 1 [52480/387873]    Loss: 0.001877   Batch Acc: 89.84
[Train] Epoch: 1 [52608/387873]    Loss: 0.002172   Batch Acc: 89.84
[Train] Epoch: 1 [52736/387873]    Loss: 0.001910   Batch Acc: 89.84
[Train] Epoch: 1 [52864/387873]    Loss: 0.002816   Batch Acc: 84.38
[Train] Epoch: 1 [52992/387873]    Loss: 0.002116   Batch Acc: 89.84
[Train] Epoch: 1 [53120/387873]    Loss: 0.002051   Batch Acc: 89.06
[Train] Epoch: 1 [53248/387873]    Loss: 0.001903   Batch Acc: 92.97
[Train] Epoch: 1 [53376/387873]    Loss: 0.001926   Batch Acc: 90.62
[Train] Epoch: 1 [53504/387873]    Loss: 0.002376   Batch Acc: 86.72
[Train] Epoch: 1 [53632/387873]    Loss: 0.001933   Batch Acc: 89.06
[Train] Epoch: 1 [53760/387873]    Loss: 0.001479   Batch Acc: 95.31
[Train] Epoch: 1 [53888/387873]    Loss: 0.002165   Batch Acc: 86.72
[Train] Epoch: 1 [54016/387873]    Loss: 0.002008   Batch Acc: 89.84
[Train] Epoch: 1 [54144/387873]    Loss: 0.002018   Batch Acc: 90.62
[Train] Epoch: 1 [54272/387873]    Loss: 0.001981   Batch Acc: 92.19
[Train] Epoch: 1 [54400/387873]    Loss: 0.002320   Batch Acc: 88.28
[Train] Epoch: 1 [54528/387873]    Loss: 0.002129   Batch Acc: 89.84
[Train] Epoch: 1 [54656/387873]    Loss: 0.001945   Batch Acc: 91.41
[Train] Epoch: 1 [54784/387873]    Loss: 0.002307   Batch Acc: 85.94
[Train] Epoch: 1 [54912/387873]    Loss: 0.001717   Batch Acc: 91.41
[Train] Epoch: 1 [55040/387873]    Loss: 0.002142   Batch Acc: 89.06
[Train] Epoch: 1 [55168/387873]    Loss: 0.001718   Batch Acc: 90.62
[Train] Epoch: 1 [55296/387873]    Loss: 0.002393   Batch Acc: 86.72
[Train] Epoch: 1 [55424/387873]    Loss: 0.002421   Batch Acc: 85.16
[Train] Epoch: 1 [55552/387873]    Loss: 0.002440   Batch Acc: 86.72
[Train] Epoch: 1 [55680/387873]    Loss: 0.002351   Batch Acc: 88.28
[Train] Epoch: 1 [55808/387873]    Loss: 0.002403   Batch Acc: 86.72
[Train] Epoch: 1 [55936/387873]    Loss: 0.002211   Batch Acc: 89.84
[Train] Epoch: 1 [56064/387873]    Loss: 0.002660   Batch Acc: 85.94
[Train] Epoch: 1 [56192/387873]    Loss: 0.002690   Batch Acc: 86.72
[Train] Epoch: 1 [56320/387873]    Loss: 0.001467   Batch Acc: 92.97
[Train] Epoch: 1 [56448/387873]    Loss: 0.002322   Batch Acc: 86.72
[Train] Epoch: 1 [56576/387873]    Loss: 0.002279   Batch Acc: 89.84
[Train] Epoch: 1 [56704/387873]    Loss: 0.001953   Batch Acc: 88.28
[Train] Epoch: 1 [56832/387873]    Loss: 0.001987   Batch Acc: 90.62
[Train] Epoch: 1 [56960/387873]    Loss: 0.001937   Batch Acc: 87.50
[Train] Epoch: 1 [57088/387873]    Loss: 0.002001   Batch Acc: 91.41
[Train] Epoch: 1 [57216/387873]    Loss: 0.002994   Batch Acc: 82.81
[Train] Epoch: 1 [57344/387873]    Loss: 0.002386   Batch Acc: 84.38
[Train] Epoch: 1 [57472/387873]    Loss: 0.002675   Batch Acc: 88.28
[Train] Epoch: 1 [57600/387873]    Loss: 0.002190   Batch Acc: 86.72
[Train] Epoch: 1 [57728/387873]    Loss: 0.002052   Batch Acc: 89.84
[Train] Epoch: 1 [57856/387873]    Loss: 0.002545   Batch Acc: 86.72
[Train] Epoch: 1 [57984/387873]    Loss: 0.002086   Batch Acc: 87.50
[Train] Epoch: 1 [58112/387873]    Loss: 0.001713   Batch Acc: 90.62
[Train] Epoch: 1 [58240/387873]    Loss: 0.002475   Batch Acc: 84.38
[Train] Epoch: 1 [58368/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 1 [58496/387873]    Loss: 0.002154   Batch Acc: 87.50
[Train] Epoch: 1 [58624/387873]    Loss: 0.002164   Batch Acc: 90.62
[Train] Epoch: 1 [58752/387873]    Loss: 0.001899   Batch Acc: 90.62
[Train] Epoch: 1 [58880/387873]    Loss: 0.002560   Batch Acc: 86.72
[Train] Epoch: 1 [59008/387873]    Loss: 0.002126   Batch Acc: 90.62
[Train] Epoch: 1 [59136/387873]    Loss: 0.002285   Batch Acc: 89.84
[Train] Epoch: 1 [59264/387873]    Loss: 0.001962   Batch Acc: 89.84
[Train] Epoch: 1 [59392/387873]    Loss: 0.001715   Batch Acc: 91.41
[Train] Epoch: 1 [59520/387873]    Loss: 0.001864   Batch Acc: 91.41
[Train] Epoch: 1 [59648/387873]    Loss: 0.001685   Batch Acc: 92.19
[Train] Epoch: 1 [59776/387873]    Loss: 0.001821   Batch Acc: 88.28
[Train] Epoch: 1 [59904/387873]    Loss: 0.002525   Batch Acc: 84.38
[Train] Epoch: 1 [60032/387873]    Loss: 0.002357   Batch Acc: 86.72
[Train] Epoch: 1 [60160/387873]    Loss: 0.002266   Batch Acc: 89.84
[Train] Epoch: 1 [60288/387873]    Loss: 0.002094   Batch Acc: 87.50
[Train] Epoch: 1 [60416/387873]    Loss: 0.002355   Batch Acc: 86.72
[Train] Epoch: 1 [60544/387873]    Loss: 0.002048   Batch Acc: 90.62
[Train] Epoch: 1 [60672/387873]    Loss: 0.002453   Batch Acc: 84.38
[Train] Epoch: 1 [60800/387873]    Loss: 0.001983   Batch Acc: 89.84
[Train] Epoch: 1 [60928/387873]    Loss: 0.001736   Batch Acc: 92.97
[Train] Epoch: 1 [61056/387873]    Loss: 0.002361   Batch Acc: 85.94
[Train] Epoch: 1 [61184/387873]    Loss: 0.002163   Batch Acc: 84.38
[Train] Epoch: 1 [61312/387873]    Loss: 0.001941   Batch Acc: 90.62
[Train] Epoch: 1 [61440/387873]    Loss: 0.002285   Batch Acc: 86.72
[Train] Epoch: 1 [61568/387873]    Loss: 0.002571   Batch Acc: 84.38
[Train] Epoch: 1 [61696/387873]    Loss: 0.002681   Batch Acc: 86.72
[Train] Epoch: 1 [61824/387873]    Loss: 0.002016   Batch Acc: 91.41
[Train] Epoch: 1 [61952/387873]    Loss: 0.002154   Batch Acc: 85.94
[Train] Epoch: 1 [62080/387873]    Loss: 0.002270   Batch Acc: 85.94
[Train] Epoch: 1 [62208/387873]    Loss: 0.002158   Batch Acc: 89.06
[Train] Epoch: 1 [62336/387873]    Loss: 0.002033   Batch Acc: 89.84
[Train] Epoch: 1 [62464/387873]    Loss: 0.002342   Batch Acc: 86.72
[Train] Epoch: 1 [62592/387873]    Loss: 0.002032   Batch Acc: 90.62
[Train] Epoch: 1 [62720/387873]    Loss: 0.002383   Batch Acc: 88.28
[Train] Epoch: 1 [62848/387873]    Loss: 0.002343   Batch Acc: 87.50
[Train] Epoch: 1 [62976/387873]    Loss: 0.001830   Batch Acc: 90.62
[Train] Epoch: 1 [63104/387873]    Loss: 0.002772   Batch Acc: 84.38
[Train] Epoch: 1 [63232/387873]    Loss: 0.002204   Batch Acc: 87.50
[Train] Epoch: 1 [63360/387873]    Loss: 0.002163   Batch Acc: 89.84
[Train] Epoch: 1 [63488/387873]    Loss: 0.001749   Batch Acc: 93.75
[Train] Epoch: 1 [63616/387873]    Loss: 0.002305   Batch Acc: 91.41
[Train] Epoch: 1 [63744/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 1 [63872/387873]    Loss: 0.002147   Batch Acc: 89.06
[Train] Epoch: 1 [64000/387873]    Loss: 0.002093   Batch Acc: 88.28
[Train] Epoch: 1 [64128/387873]    Loss: 0.002227   Batch Acc: 85.94
[Train] Epoch: 1 [64256/387873]    Loss: 0.002187   Batch Acc: 87.50
[Train] Epoch: 1 [64384/387873]    Loss: 0.002055   Batch Acc: 89.84
[Train] Epoch: 1 [64512/387873]    Loss: 0.001779   Batch Acc: 89.84
[Train] Epoch: 1 [64640/387873]    Loss: 0.002515   Batch Acc: 84.38
[Train] Epoch: 1 [64768/387873]    Loss: 0.002530   Batch Acc: 86.72
[Train] Epoch: 1 [64896/387873]    Loss: 0.001792   Batch Acc: 90.62
[Train] Epoch: 1 [65024/387873]    Loss: 0.002302   Batch Acc: 89.84
[Train] Epoch: 1 [65152/387873]    Loss: 0.001538   Batch Acc: 96.09
[Train] Epoch: 1 [65280/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 1 [65408/387873]    Loss: 0.001767   Batch Acc: 92.19
[Train] Epoch: 1 [65536/387873]    Loss: 0.002254   Batch Acc: 89.06
[Train] Epoch: 1 [65664/387873]    Loss: 0.001930   Batch Acc: 89.06
[Train] Epoch: 1 [65792/387873]    Loss: 0.003030   Batch Acc: 84.38
[Train] Epoch: 1 [65920/387873]    Loss: 0.002354   Batch Acc: 86.72
[Train] Epoch: 1 [66048/387873]    Loss: 0.002423   Batch Acc: 89.06
[Train] Epoch: 1 [66176/387873]    Loss: 0.002681   Batch Acc: 85.16
[Train] Epoch: 1 [66304/387873]    Loss: 0.001912   Batch Acc: 90.62
[Train] Epoch: 1 [66432/387873]    Loss: 0.002313   Batch Acc: 86.72
[Train] Epoch: 1 [66560/387873]    Loss: 0.001907   Batch Acc: 90.62
[Train] Epoch: 1 [66688/387873]    Loss: 0.002510   Batch Acc: 89.06
[Train] Epoch: 1 [66816/387873]    Loss: 0.002035   Batch Acc: 87.50
[Train] Epoch: 1 [66944/387873]    Loss: 0.001963   Batch Acc: 91.41
[Train] Epoch: 1 [67072/387873]    Loss: 0.001624   Batch Acc: 92.19
[Train] Epoch: 1 [67200/387873]    Loss: 0.002498   Batch Acc: 88.28
[Train] Epoch: 1 [67328/387873]    Loss: 0.001626   Batch Acc: 92.19
[Train] Epoch: 1 [67456/387873]    Loss: 0.002364   Batch Acc: 88.28
[Train] Epoch: 1 [67584/387873]    Loss: 0.002205   Batch Acc: 86.72
[Train] Epoch: 1 [67712/387873]    Loss: 0.002135   Batch Acc: 89.06
[Train] Epoch: 1 [67840/387873]    Loss: 0.001843   Batch Acc: 88.28
[Train] Epoch: 1 [67968/387873]    Loss: 0.001849   Batch Acc: 93.75
[Train] Epoch: 1 [68096/387873]    Loss: 0.002523   Batch Acc: 83.59
[Train] Epoch: 1 [68224/387873]    Loss: 0.002144   Batch Acc: 89.06
[Train] Epoch: 1 [68352/387873]    Loss: 0.002324   Batch Acc: 85.94
[Train] Epoch: 1 [68480/387873]    Loss: 0.002217   Batch Acc: 85.94
[Train] Epoch: 1 [68608/387873]    Loss: 0.002653   Batch Acc: 84.38
[Train] Epoch: 1 [68736/387873]    Loss: 0.002046   Batch Acc: 89.84
[Train] Epoch: 1 [68864/387873]    Loss: 0.002007   Batch Acc: 90.62
[Train] Epoch: 1 [68992/387873]    Loss: 0.002110   Batch Acc: 89.06
[Train] Epoch: 1 [69120/387873]    Loss: 0.001825   Batch Acc: 91.41
[Train] Epoch: 1 [69248/387873]    Loss: 0.002357   Batch Acc: 89.06
[Train] Epoch: 1 [69376/387873]    Loss: 0.002145   Batch Acc: 89.84
[Train] Epoch: 1 [69504/387873]    Loss: 0.002697   Batch Acc: 83.59
[Train] Epoch: 1 [69632/387873]    Loss: 0.002095   Batch Acc: 87.50
[Train] Epoch: 1 [69760/387873]    Loss: 0.002359   Batch Acc: 86.72
[Train] Epoch: 1 [69888/387873]    Loss: 0.001822   Batch Acc: 89.84
[Train] Epoch: 1 [70016/387873]    Loss: 0.002331   Batch Acc: 89.06
[Train] Epoch: 1 [70144/387873]    Loss: 0.002123   Batch Acc: 89.06
[Train] Epoch: 1 [70272/387873]    Loss: 0.001820   Batch Acc: 90.62
[Train] Epoch: 1 [70400/387873]    Loss: 0.001783   Batch Acc: 90.62
[Train] Epoch: 1 [70528/387873]    Loss: 0.002300   Batch Acc: 84.38
[Train] Epoch: 1 [70656/387873]    Loss: 0.001541   Batch Acc: 93.75
[Train] Epoch: 1 [70784/387873]    Loss: 0.001753   Batch Acc: 92.19
[Train] Epoch: 1 [70912/387873]    Loss: 0.001898   Batch Acc: 89.06
[Train] Epoch: 1 [71040/387873]    Loss: 0.002508   Batch Acc: 84.38
[Train] Epoch: 1 [71168/387873]    Loss: 0.002707   Batch Acc: 86.72
[Train] Epoch: 1 [71296/387873]    Loss: 0.002360   Batch Acc: 85.16
[Train] Epoch: 1 [71424/387873]    Loss: 0.002185   Batch Acc: 89.06
[Train] Epoch: 1 [71552/387873]    Loss: 0.002006   Batch Acc: 89.84
[Train] Epoch: 1 [71680/387873]    Loss: 0.001851   Batch Acc: 89.84
[Train] Epoch: 1 [71808/387873]    Loss: 0.002156   Batch Acc: 89.84
[Train] Epoch: 1 [71936/387873]    Loss: 0.001997   Batch Acc: 86.72
[Train] Epoch: 1 [72064/387873]    Loss: 0.002729   Batch Acc: 85.16
[Train] Epoch: 1 [72192/387873]    Loss: 0.002536   Batch Acc: 84.38
[Train] Epoch: 1 [72320/387873]    Loss: 0.001722   Batch Acc: 90.62
[Train] Epoch: 1 [72448/387873]    Loss: 0.002070   Batch Acc: 88.28
[Train] Epoch: 1 [72576/387873]    Loss: 0.002249   Batch Acc: 87.50
[Train] Epoch: 1 [72704/387873]    Loss: 0.001937   Batch Acc: 88.28
[Train] Epoch: 1 [72832/387873]    Loss: 0.002089   Batch Acc: 84.38
[Train] Epoch: 1 [72960/387873]    Loss: 0.002517   Batch Acc: 84.38
[Train] Epoch: 1 [73088/387873]    Loss: 0.002643   Batch Acc: 85.16
[Train] Epoch: 1 [73216/387873]    Loss: 0.002273   Batch Acc: 85.94
[Train] Epoch: 1 [73344/387873]    Loss: 0.002219   Batch Acc: 88.28
[Train] Epoch: 1 [73472/387873]    Loss: 0.002739   Batch Acc: 86.72
[Train] Epoch: 1 [73600/387873]    Loss: 0.002363   Batch Acc: 85.94
[Train] Epoch: 1 [73728/387873]    Loss: 0.001789   Batch Acc: 92.19
[Train] Epoch: 1 [73856/387873]    Loss: 0.002327   Batch Acc: 88.28
[Train] Epoch: 1 [73984/387873]    Loss: 0.002197   Batch Acc: 90.62
[Train] Epoch: 1 [74112/387873]    Loss: 0.002139   Batch Acc: 86.72
[Train] Epoch: 1 [74240/387873]    Loss: 0.002441   Batch Acc: 85.94
[Train] Epoch: 1 [74368/387873]    Loss: 0.002374   Batch Acc: 85.94
[Train] Epoch: 1 [74496/387873]    Loss: 0.002415   Batch Acc: 89.06
[Train] Epoch: 1 [74624/387873]    Loss: 0.001927   Batch Acc: 89.84
[Train] Epoch: 1 [74752/387873]    Loss: 0.001934   Batch Acc: 89.84
[Train] Epoch: 1 [74880/387873]    Loss: 0.001997   Batch Acc: 89.06
[Train] Epoch: 1 [75008/387873]    Loss: 0.002571   Batch Acc: 85.94
[Train] Epoch: 1 [75136/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 1 [75264/387873]    Loss: 0.001746   Batch Acc: 92.19
[Train] Epoch: 1 [75392/387873]    Loss: 0.003036   Batch Acc: 82.81
[Train] Epoch: 1 [75520/387873]    Loss: 0.001650   Batch Acc: 92.97
[Train] Epoch: 1 [75648/387873]    Loss: 0.002090   Batch Acc: 88.28
[Train] Epoch: 1 [75776/387873]    Loss: 0.002134   Batch Acc: 88.28
[Train] Epoch: 1 [75904/387873]    Loss: 0.002513   Batch Acc: 85.16
[Train] Epoch: 1 [76032/387873]    Loss: 0.001709   Batch Acc: 90.62
[Train] Epoch: 1 [76160/387873]    Loss: 0.002034   Batch Acc: 86.72
[Train] Epoch: 1 [76288/387873]    Loss: 0.001999   Batch Acc: 92.97
[Train] Epoch: 1 [76416/387873]    Loss: 0.002348   Batch Acc: 88.28
[Train] Epoch: 1 [76544/387873]    Loss: 0.001745   Batch Acc: 90.62
[Train] Epoch: 1 [76672/387873]    Loss: 0.002334   Batch Acc: 85.16
[Train] Epoch: 1 [76800/387873]    Loss: 0.002202   Batch Acc: 88.28
[Train] Epoch: 1 [76928/387873]    Loss: 0.001824   Batch Acc: 92.97
[Train] Epoch: 1 [77056/387873]    Loss: 0.002503   Batch Acc: 84.38
[Train] Epoch: 1 [77184/387873]    Loss: 0.002353   Batch Acc: 87.50
[Train] Epoch: 1 [77312/387873]    Loss: 0.002047   Batch Acc: 91.41
[Train] Epoch: 1 [77440/387873]    Loss: 0.001905   Batch Acc: 90.62
[Train] Epoch: 1 [77568/387873]    Loss: 0.001964   Batch Acc: 90.62
[Train] Epoch: 1 [77696/387873]    Loss: 0.002196   Batch Acc: 85.94
[Train] Epoch: 1 [77824/387873]    Loss: 0.002694   Batch Acc: 84.38
[Train] Epoch: 1 [77952/387873]    Loss: 0.002413   Batch Acc: 85.16
[Train] Epoch: 1 [78080/387873]    Loss: 0.002410   Batch Acc: 88.28
[Train] Epoch: 1 [78208/387873]    Loss: 0.001493   Batch Acc: 94.53
[Train] Epoch: 1 [78336/387873]    Loss: 0.001767   Batch Acc: 90.62
[Train] Epoch: 1 [78464/387873]    Loss: 0.002105   Batch Acc: 85.16
[Train] Epoch: 1 [78592/387873]    Loss: 0.002419   Batch Acc: 87.50
[Train] Epoch: 1 [78720/387873]    Loss: 0.001871   Batch Acc: 91.41
[Train] Epoch: 1 [78848/387873]    Loss: 0.002156   Batch Acc: 89.06
[Train] Epoch: 1 [78976/387873]    Loss: 0.001841   Batch Acc: 91.41
[Train] Epoch: 1 [79104/387873]    Loss: 0.002691   Batch Acc: 83.59
[Train] Epoch: 1 [79232/387873]    Loss: 0.001965   Batch Acc: 88.28
[Train] Epoch: 1 [79360/387873]    Loss: 0.001610   Batch Acc: 93.75
[Train] Epoch: 1 [79488/387873]    Loss: 0.002341   Batch Acc: 85.94
[Train] Epoch: 1 [79616/387873]    Loss: 0.002195   Batch Acc: 90.62
[Train] Epoch: 1 [79744/387873]    Loss: 0.001897   Batch Acc: 94.53
[Train] Epoch: 1 [79872/387873]    Loss: 0.002717   Batch Acc: 87.50
[Train] Epoch: 1 [80000/387873]    Loss: 0.001981   Batch Acc: 89.06
[Train] Epoch: 1 [80128/387873]    Loss: 0.002465   Batch Acc: 85.94
[Train] Epoch: 1 [80256/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 1 [80384/387873]    Loss: 0.002130   Batch Acc: 86.72
[Train] Epoch: 1 [80512/387873]    Loss: 0.002974   Batch Acc: 83.59
[Train] Epoch: 1 [80640/387873]    Loss: 0.002672   Batch Acc: 88.28
[Train] Epoch: 1 [80768/387873]    Loss: 0.002395   Batch Acc: 90.62
[Train] Epoch: 1 [80896/387873]    Loss: 0.002237   Batch Acc: 86.72
[Train] Epoch: 1 [81024/387873]    Loss: 0.002017   Batch Acc: 87.50
[Train] Epoch: 1 [81152/387873]    Loss: 0.002607   Batch Acc: 82.03
[Train] Epoch: 1 [81280/387873]    Loss: 0.002315   Batch Acc: 86.72
[Train] Epoch: 1 [81408/387873]    Loss: 0.002295   Batch Acc: 88.28
[Train] Epoch: 1 [81536/387873]    Loss: 0.001995   Batch Acc: 90.62
[Train] Epoch: 1 [81664/387873]    Loss: 0.001914   Batch Acc: 91.41
[Train] Epoch: 1 [81792/387873]    Loss: 0.001930   Batch Acc: 90.62
[Train] Epoch: 1 [81920/387873]    Loss: 0.002922   Batch Acc: 86.72
[Train] Epoch: 1 [82048/387873]    Loss: 0.002707   Batch Acc: 80.47
[Train] Epoch: 1 [82176/387873]    Loss: 0.002203   Batch Acc: 89.84
[Train] Epoch: 1 [82304/387873]    Loss: 0.002220   Batch Acc: 89.06
[Train] Epoch: 1 [82432/387873]    Loss: 0.001795   Batch Acc: 93.75
[Train] Epoch: 1 [82560/387873]    Loss: 0.002494   Batch Acc: 87.50
[Train] Epoch: 1 [82688/387873]    Loss: 0.002280   Batch Acc: 85.94
[Train] Epoch: 1 [82816/387873]    Loss: 0.002436   Batch Acc: 82.81
[Train] Epoch: 1 [82944/387873]    Loss: 0.002305   Batch Acc: 87.50
[Train] Epoch: 1 [83072/387873]    Loss: 0.002153   Batch Acc: 90.62
[Train] Epoch: 1 [83200/387873]    Loss: 0.001829   Batch Acc: 91.41
[Train] Epoch: 1 [83328/387873]    Loss: 0.002283   Batch Acc: 87.50
[Train] Epoch: 1 [83456/387873]    Loss: 0.001663   Batch Acc: 89.06
[Train] Epoch: 1 [83584/387873]    Loss: 0.002499   Batch Acc: 84.38
[Train] Epoch: 1 [83712/387873]    Loss: 0.002320   Batch Acc: 89.06
[Train] Epoch: 1 [83840/387873]    Loss: 0.002279   Batch Acc: 89.84
[Train] Epoch: 1 [83968/387873]    Loss: 0.002300   Batch Acc: 85.94
[Train] Epoch: 1 [84096/387873]    Loss: 0.002370   Batch Acc: 88.28
[Train] Epoch: 1 [84224/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 1 [84352/387873]    Loss: 0.002820   Batch Acc: 80.47
[Train] Epoch: 1 [84480/387873]    Loss: 0.002128   Batch Acc: 86.72
[Train] Epoch: 1 [84608/387873]    Loss: 0.001679   Batch Acc: 91.41
[Train] Epoch: 1 [84736/387873]    Loss: 0.001811   Batch Acc: 92.19
[Train] Epoch: 1 [84864/387873]    Loss: 0.002448   Batch Acc: 89.06
[Train] Epoch: 1 [84992/387873]    Loss: 0.001869   Batch Acc: 92.97
[Train] Epoch: 1 [85120/387873]    Loss: 0.002006   Batch Acc: 91.41
[Train] Epoch: 1 [85248/387873]    Loss: 0.001571   Batch Acc: 92.97
[Train] Epoch: 1 [85376/387873]    Loss: 0.002333   Batch Acc: 89.84
[Train] Epoch: 1 [85504/387873]    Loss: 0.002209   Batch Acc: 91.41
[Train] Epoch: 1 [85632/387873]    Loss: 0.001864   Batch Acc: 92.19
[Train] Epoch: 1 [85760/387873]    Loss: 0.002628   Batch Acc: 85.94
[Train] Epoch: 1 [85888/387873]    Loss: 0.002208   Batch Acc: 87.50
[Train] Epoch: 1 [86016/387873]    Loss: 0.002239   Batch Acc: 89.06
[Train] Epoch: 1 [86144/387873]    Loss: 0.002566   Batch Acc: 85.16
[Train] Epoch: 1 [86272/387873]    Loss: 0.002106   Batch Acc: 87.50
[Train] Epoch: 1 [86400/387873]    Loss: 0.002433   Batch Acc: 86.72
[Train] Epoch: 1 [86528/387873]    Loss: 0.002331   Batch Acc: 86.72
[Train] Epoch: 1 [86656/387873]    Loss: 0.002115   Batch Acc: 89.06
[Train] Epoch: 1 [86784/387873]    Loss: 0.002451   Batch Acc: 85.94
[Train] Epoch: 1 [86912/387873]    Loss: 0.001790   Batch Acc: 92.97
[Train] Epoch: 1 [87040/387873]    Loss: 0.002426   Batch Acc: 85.94
[Train] Epoch: 1 [87168/387873]    Loss: 0.002017   Batch Acc: 86.72
[Train] Epoch: 1 [87296/387873]    Loss: 0.001988   Batch Acc: 91.41
[Train] Epoch: 1 [87424/387873]    Loss: 0.002157   Batch Acc: 88.28
[Train] Epoch: 1 [87552/387873]    Loss: 0.001891   Batch Acc: 90.62
[Train] Epoch: 1 [87680/387873]    Loss: 0.002475   Batch Acc: 89.84
[Train] Epoch: 1 [87808/387873]    Loss: 0.002056   Batch Acc: 91.41
[Train] Epoch: 1 [87936/387873]    Loss: 0.002030   Batch Acc: 89.84
[Train] Epoch: 1 [88064/387873]    Loss: 0.002190   Batch Acc: 85.94
[Train] Epoch: 1 [88192/387873]    Loss: 0.002385   Batch Acc: 86.72
[Train] Epoch: 1 [88320/387873]    Loss: 0.002563   Batch Acc: 86.72
[Train] Epoch: 1 [88448/387873]    Loss: 0.002197   Batch Acc: 89.84
[Train] Epoch: 1 [88576/387873]    Loss: 0.002238   Batch Acc: 88.28
[Train] Epoch: 1 [88704/387873]    Loss: 0.002354   Batch Acc: 87.50
[Train] Epoch: 1 [88832/387873]    Loss: 0.001849   Batch Acc: 92.19
[Train] Epoch: 1 [88960/387873]    Loss: 0.001786   Batch Acc: 90.62
[Train] Epoch: 1 [89088/387873]    Loss: 0.002415   Batch Acc: 87.50
[Train] Epoch: 1 [89216/387873]    Loss: 0.001939   Batch Acc: 87.50
[Train] Epoch: 1 [89344/387873]    Loss: 0.002285   Batch Acc: 89.06
[Train] Epoch: 1 [89472/387873]    Loss: 0.002189   Batch Acc: 88.28
[Train] Epoch: 1 [89600/387873]    Loss: 0.002078   Batch Acc: 90.62
[Train] Epoch: 1 [89728/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 1 [89856/387873]    Loss: 0.002229   Batch Acc: 87.50
[Train] Epoch: 1 [89984/387873]    Loss: 0.001656   Batch Acc: 94.53
[Train] Epoch: 1 [90112/387873]    Loss: 0.002048   Batch Acc: 89.84
[Train] Epoch: 1 [90240/387873]    Loss: 0.002596   Batch Acc: 85.16
[Train] Epoch: 1 [90368/387873]    Loss: 0.002178   Batch Acc: 90.62
[Train] Epoch: 1 [90496/387873]    Loss: 0.002429   Batch Acc: 86.72
[Train] Epoch: 1 [90624/387873]    Loss: 0.001675   Batch Acc: 94.53
[Train] Epoch: 1 [90752/387873]    Loss: 0.002007   Batch Acc: 91.41
[Train] Epoch: 1 [90880/387873]    Loss: 0.002964   Batch Acc: 82.81
[Train] Epoch: 1 [91008/387873]    Loss: 0.002195   Batch Acc: 87.50
[Train] Epoch: 1 [91136/387873]    Loss: 0.002314   Batch Acc: 85.94
[Train] Epoch: 1 [91264/387873]    Loss: 0.001928   Batch Acc: 92.97
[Train] Epoch: 1 [91392/387873]    Loss: 0.002219   Batch Acc: 89.84
[Train] Epoch: 1 [91520/387873]    Loss: 0.002387   Batch Acc: 89.06
[Train] Epoch: 1 [91648/387873]    Loss: 0.002294   Batch Acc: 89.06
[Train] Epoch: 1 [91776/387873]    Loss: 0.002002   Batch Acc: 85.94
[Train] Epoch: 1 [91904/387873]    Loss: 0.002300   Batch Acc: 87.50
[Train] Epoch: 1 [92032/387873]    Loss: 0.002579   Batch Acc: 87.50
[Train] Epoch: 1 [92160/387873]    Loss: 0.001880   Batch Acc: 88.28
[Train] Epoch: 1 [92288/387873]    Loss: 0.001886   Batch Acc: 92.19
[Train] Epoch: 1 [92416/387873]    Loss: 0.002549   Batch Acc: 83.59
[Train] Epoch: 1 [92544/387873]    Loss: 0.002027   Batch Acc: 91.41
[Train] Epoch: 1 [92672/387873]    Loss: 0.002259   Batch Acc: 91.41
[Train] Epoch: 1 [92800/387873]    Loss: 0.002227   Batch Acc: 87.50
[Train] Epoch: 1 [92928/387873]    Loss: 0.002122   Batch Acc: 91.41
[Train] Epoch: 1 [93056/387873]    Loss: 0.002402   Batch Acc: 86.72
[Train] Epoch: 1 [93184/387873]    Loss: 0.002273   Batch Acc: 87.50
[Train] Epoch: 1 [93312/387873]    Loss: 0.002760   Batch Acc: 85.16
[Train] Epoch: 1 [93440/387873]    Loss: 0.002179   Batch Acc: 87.50
[Train] Epoch: 1 [93568/387873]    Loss: 0.001649   Batch Acc: 94.53
[Train] Epoch: 1 [93696/387873]    Loss: 0.001851   Batch Acc: 89.06
[Train] Epoch: 1 [93824/387873]    Loss: 0.001830   Batch Acc: 89.84
[Train] Epoch: 1 [93952/387873]    Loss: 0.002631   Batch Acc: 87.50
[Train] Epoch: 1 [94080/387873]    Loss: 0.002100   Batch Acc: 88.28
[Train] Epoch: 1 [94208/387873]    Loss: 0.001916   Batch Acc: 89.06
[Train] Epoch: 1 [94336/387873]    Loss: 0.002180   Batch Acc: 89.06
[Train] Epoch: 1 [94464/387873]    Loss: 0.002026   Batch Acc: 87.50
[Train] Epoch: 1 [94592/387873]    Loss: 0.001978   Batch Acc: 90.62
[Train] Epoch: 1 [94720/387873]    Loss: 0.002222   Batch Acc: 89.84
[Train] Epoch: 1 [94848/387873]    Loss: 0.002485   Batch Acc: 85.16
[Train] Epoch: 1 [94976/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 1 [95104/387873]    Loss: 0.002465   Batch Acc: 84.38
[Train] Epoch: 1 [95232/387873]    Loss: 0.002295   Batch Acc: 87.50
[Train] Epoch: 1 [95360/387873]    Loss: 0.002444   Batch Acc: 87.50
[Train] Epoch: 1 [95488/387873]    Loss: 0.002658   Batch Acc: 87.50
[Train] Epoch: 1 [95616/387873]    Loss: 0.002007   Batch Acc: 86.72
[Train] Epoch: 1 [95744/387873]    Loss: 0.002992   Batch Acc: 84.38
[Train] Epoch: 1 [95872/387873]    Loss: 0.002665   Batch Acc: 86.72
[Train] Epoch: 1 [96000/387873]    Loss: 0.002240   Batch Acc: 89.06
[Train] Epoch: 1 [96128/387873]    Loss: 0.002136   Batch Acc: 89.84
[Train] Epoch: 1 [96256/387873]    Loss: 0.002199   Batch Acc: 91.41
[Train] Epoch: 1 [96384/387873]    Loss: 0.002168   Batch Acc: 91.41
[Train] Epoch: 1 [96512/387873]    Loss: 0.002161   Batch Acc: 85.94
[Train] Epoch: 1 [96640/387873]    Loss: 0.002464   Batch Acc: 87.50
[Train] Epoch: 1 [96768/387873]    Loss: 0.001683   Batch Acc: 91.41
[Train] Epoch: 1 [96896/387873]    Loss: 0.002165   Batch Acc: 88.28
[Train] Epoch: 1 [97024/387873]    Loss: 0.003124   Batch Acc: 79.69
[Train] Epoch: 1 [97152/387873]    Loss: 0.001560   Batch Acc: 92.97
[Train] Epoch: 1 [97280/387873]    Loss: 0.002647   Batch Acc: 83.59
[Train] Epoch: 1 [97408/387873]    Loss: 0.002077   Batch Acc: 90.62
[Train] Epoch: 1 [97536/387873]    Loss: 0.002349   Batch Acc: 86.72
[Train] Epoch: 1 [97664/387873]    Loss: 0.002266   Batch Acc: 88.28
[Train] Epoch: 1 [97792/387873]    Loss: 0.002626   Batch Acc: 86.72
[Train] Epoch: 1 [97920/387873]    Loss: 0.001642   Batch Acc: 93.75
[Train] Epoch: 1 [98048/387873]    Loss: 0.002324   Batch Acc: 89.06
[Train] Epoch: 1 [98176/387873]    Loss: 0.001791   Batch Acc: 92.19
[Train] Epoch: 1 [98304/387873]    Loss: 0.002041   Batch Acc: 89.84
[Train] Epoch: 1 [98432/387873]    Loss: 0.002093   Batch Acc: 90.62
[Train] Epoch: 1 [98560/387873]    Loss: 0.002462   Batch Acc: 85.16
[Train] Epoch: 1 [98688/387873]    Loss: 0.002145   Batch Acc: 88.28
[Train] Epoch: 1 [98816/387873]    Loss: 0.002558   Batch Acc: 85.94
[Train] Epoch: 1 [98944/387873]    Loss: 0.002231   Batch Acc: 88.28
[Train] Epoch: 1 [99072/387873]    Loss: 0.001938   Batch Acc: 89.84
[Train] Epoch: 1 [99200/387873]    Loss: 0.002152   Batch Acc: 88.28
[Train] Epoch: 1 [99328/387873]    Loss: 0.001941   Batch Acc: 91.41
[Train] Epoch: 1 [99456/387873]    Loss: 0.002068   Batch Acc: 89.84
[Train] Epoch: 1 [99584/387873]    Loss: 0.002597   Batch Acc: 87.50
[Train] Epoch: 1 [99712/387873]    Loss: 0.002165   Batch Acc: 88.28
[Train] Epoch: 1 [99840/387873]    Loss: 0.002022   Batch Acc: 90.62
[Train] Epoch: 1 [99968/387873]    Loss: 0.002136   Batch Acc: 88.28
[Train] Epoch: 1 [100096/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 1 [100224/387873]    Loss: 0.002580   Batch Acc: 85.16
[Train] Epoch: 1 [100352/387873]    Loss: 0.002807   Batch Acc: 85.16
[Train] Epoch: 1 [100480/387873]    Loss: 0.001476   Batch Acc: 92.97
[Train] Epoch: 1 [100608/387873]    Loss: 0.002427   Batch Acc: 85.16
[Train] Epoch: 1 [100736/387873]    Loss: 0.002260   Batch Acc: 85.16
[Train] Epoch: 1 [100864/387873]    Loss: 0.001851   Batch Acc: 91.41
[Train] Epoch: 1 [100992/387873]    Loss: 0.002098   Batch Acc: 89.84
[Train] Epoch: 1 [101120/387873]    Loss: 0.002761   Batch Acc: 82.03
[Train] Epoch: 1 [101248/387873]    Loss: 0.002849   Batch Acc: 82.03
[Train] Epoch: 1 [101376/387873]    Loss: 0.002170   Batch Acc: 89.06
[Train] Epoch: 1 [101504/387873]    Loss: 0.001856   Batch Acc: 88.28
[Train] Epoch: 1 [101632/387873]    Loss: 0.002395   Batch Acc: 89.06
[Train] Epoch: 1 [101760/387873]    Loss: 0.002145   Batch Acc: 85.16
[Train] Epoch: 1 [101888/387873]    Loss: 0.002139   Batch Acc: 90.62
[Train] Epoch: 1 [102016/387873]    Loss: 0.002366   Batch Acc: 87.50
[Train] Epoch: 1 [102144/387873]    Loss: 0.001994   Batch Acc: 92.19
[Train] Epoch: 1 [102272/387873]    Loss: 0.002475   Batch Acc: 88.28
[Train] Epoch: 1 [102400/387873]    Loss: 0.002735   Batch Acc: 85.16
[Train] Epoch: 1 [102528/387873]    Loss: 0.002374   Batch Acc: 85.94
[Train] Epoch: 1 [102656/387873]    Loss: 0.002397   Batch Acc: 87.50
[Train] Epoch: 1 [102784/387873]    Loss: 0.002180   Batch Acc: 90.62
[Train] Epoch: 1 [102912/387873]    Loss: 0.002200   Batch Acc: 85.94
[Train] Epoch: 1 [103040/387873]    Loss: 0.002177   Batch Acc: 86.72
[Train] Epoch: 1 [103168/387873]    Loss: 0.001627   Batch Acc: 91.41
[Train] Epoch: 1 [103296/387873]    Loss: 0.002121   Batch Acc: 88.28
[Train] Epoch: 1 [103424/387873]    Loss: 0.001933   Batch Acc: 91.41
[Train] Epoch: 1 [103552/387873]    Loss: 0.002154   Batch Acc: 89.84
[Train] Epoch: 1 [103680/387873]    Loss: 0.001571   Batch Acc: 92.97
[Train] Epoch: 1 [103808/387873]    Loss: 0.002189   Batch Acc: 89.84
[Train] Epoch: 1 [103936/387873]    Loss: 0.001827   Batch Acc: 89.84
[Train] Epoch: 1 [104064/387873]    Loss: 0.002553   Batch Acc: 86.72
[Train] Epoch: 1 [104192/387873]    Loss: 0.001926   Batch Acc: 89.06
[Train] Epoch: 1 [104320/387873]    Loss: 0.002046   Batch Acc: 90.62
[Train] Epoch: 1 [104448/387873]    Loss: 0.002503   Batch Acc: 83.59
[Train] Epoch: 1 [104576/387873]    Loss: 0.002117   Batch Acc: 89.84
[Train] Epoch: 1 [104704/387873]    Loss: 0.002601   Batch Acc: 83.59
[Train] Epoch: 1 [104832/387873]    Loss: 0.002266   Batch Acc: 85.94
[Train] Epoch: 1 [104960/387873]    Loss: 0.002171   Batch Acc: 87.50
[Train] Epoch: 1 [105088/387873]    Loss: 0.002303   Batch Acc: 87.50
[Train] Epoch: 1 [105216/387873]    Loss: 0.001994   Batch Acc: 88.28
[Train] Epoch: 1 [105344/387873]    Loss: 0.002114   Batch Acc: 88.28
[Train] Epoch: 1 [105472/387873]    Loss: 0.002299   Batch Acc: 85.94
[Train] Epoch: 1 [105600/387873]    Loss: 0.002414   Batch Acc: 86.72
[Train] Epoch: 1 [105728/387873]    Loss: 0.002007   Batch Acc: 87.50
[Train] Epoch: 1 [105856/387873]    Loss: 0.003069   Batch Acc: 81.25
[Train] Epoch: 1 [105984/387873]    Loss: 0.002014   Batch Acc: 86.72
[Train] Epoch: 1 [106112/387873]    Loss: 0.002628   Batch Acc: 82.81
[Train] Epoch: 1 [106240/387873]    Loss: 0.002163   Batch Acc: 87.50
[Train] Epoch: 1 [106368/387873]    Loss: 0.001833   Batch Acc: 90.62
[Train] Epoch: 1 [106496/387873]    Loss: 0.002083   Batch Acc: 89.06
[Train] Epoch: 1 [106624/387873]    Loss: 0.001786   Batch Acc: 92.97
[Train] Epoch: 1 [106752/387873]    Loss: 0.002200   Batch Acc: 87.50
[Train] Epoch: 1 [106880/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 1 [107008/387873]    Loss: 0.002698   Batch Acc: 84.38
[Train] Epoch: 1 [107136/387873]    Loss: 0.002355   Batch Acc: 85.16
[Train] Epoch: 1 [107264/387873]    Loss: 0.001704   Batch Acc: 92.97
[Train] Epoch: 1 [107392/387873]    Loss: 0.001964   Batch Acc: 91.41
[Train] Epoch: 1 [107520/387873]    Loss: 0.001791   Batch Acc: 92.19
[Train] Epoch: 1 [107648/387873]    Loss: 0.001808   Batch Acc: 90.62
[Train] Epoch: 1 [107776/387873]    Loss: 0.001967   Batch Acc: 89.06
[Train] Epoch: 1 [107904/387873]    Loss: 0.002365   Batch Acc: 82.81
[Train] Epoch: 1 [108032/387873]    Loss: 0.002361   Batch Acc: 85.16
[Train] Epoch: 1 [108160/387873]    Loss: 0.002517   Batch Acc: 82.81
[Train] Epoch: 1 [108288/387873]    Loss: 0.002087   Batch Acc: 89.06
[Train] Epoch: 1 [108416/387873]    Loss: 0.002175   Batch Acc: 90.62
[Train] Epoch: 1 [108544/387873]    Loss: 0.002196   Batch Acc: 87.50
[Train] Epoch: 1 [108672/387873]    Loss: 0.002789   Batch Acc: 80.47
[Train] Epoch: 1 [108800/387873]    Loss: 0.002118   Batch Acc: 85.16
[Train] Epoch: 1 [108928/387873]    Loss: 0.002950   Batch Acc: 82.81
[Train] Epoch: 1 [109056/387873]    Loss: 0.001926   Batch Acc: 89.06
[Train] Epoch: 1 [109184/387873]    Loss: 0.002189   Batch Acc: 91.41
[Train] Epoch: 1 [109312/387873]    Loss: 0.002457   Batch Acc: 82.03
[Train] Epoch: 1 [109440/387873]    Loss: 0.002047   Batch Acc: 90.62
[Train] Epoch: 1 [109568/387873]    Loss: 0.001870   Batch Acc: 89.84
[Train] Epoch: 1 [109696/387873]    Loss: 0.002682   Batch Acc: 82.03
[Train] Epoch: 1 [109824/387873]    Loss: 0.002480   Batch Acc: 85.94
[Train] Epoch: 1 [109952/387873]    Loss: 0.001995   Batch Acc: 88.28
[Train] Epoch: 1 [110080/387873]    Loss: 0.002275   Batch Acc: 87.50
[Train] Epoch: 1 [110208/387873]    Loss: 0.002362   Batch Acc: 88.28
[Train] Epoch: 1 [110336/387873]    Loss: 0.002250   Batch Acc: 88.28
[Train] Epoch: 1 [110464/387873]    Loss: 0.002422   Batch Acc: 85.16
[Train] Epoch: 1 [110592/387873]    Loss: 0.002396   Batch Acc: 89.06
[Train] Epoch: 1 [110720/387873]    Loss: 0.001930   Batch Acc: 90.62
[Train] Epoch: 1 [110848/387873]    Loss: 0.002060   Batch Acc: 90.62
[Train] Epoch: 1 [110976/387873]    Loss: 0.002321   Batch Acc: 88.28
[Train] Epoch: 1 [111104/387873]    Loss: 0.002140   Batch Acc: 89.84
[Train] Epoch: 1 [111232/387873]    Loss: 0.002649   Batch Acc: 84.38
[Train] Epoch: 1 [111360/387873]    Loss: 0.002448   Batch Acc: 87.50
[Train] Epoch: 1 [111488/387873]    Loss: 0.002368   Batch Acc: 86.72
[Train] Epoch: 1 [111616/387873]    Loss: 0.001777   Batch Acc: 89.84
[Train] Epoch: 1 [111744/387873]    Loss: 0.002325   Batch Acc: 88.28
[Train] Epoch: 1 [111872/387873]    Loss: 0.002072   Batch Acc: 88.28
[Train] Epoch: 1 [112000/387873]    Loss: 0.002631   Batch Acc: 81.25
[Train] Epoch: 1 [112128/387873]    Loss: 0.002118   Batch Acc: 90.62
[Train] Epoch: 1 [112256/387873]    Loss: 0.002072   Batch Acc: 91.41
[Train] Epoch: 1 [112384/387873]    Loss: 0.001780   Batch Acc: 89.84
[Train] Epoch: 1 [112512/387873]    Loss: 0.001527   Batch Acc: 92.19
[Train] Epoch: 1 [112640/387873]    Loss: 0.001828   Batch Acc: 89.84
[Train] Epoch: 1 [112768/387873]    Loss: 0.002315   Batch Acc: 88.28
[Train] Epoch: 1 [112896/387873]    Loss: 0.002837   Batch Acc: 85.94
[Train] Epoch: 1 [113024/387873]    Loss: 0.002398   Batch Acc: 87.50
[Train] Epoch: 1 [113152/387873]    Loss: 0.002039   Batch Acc: 90.62
[Train] Epoch: 1 [113280/387873]    Loss: 0.002068   Batch Acc: 86.72
[Train] Epoch: 1 [113408/387873]    Loss: 0.002597   Batch Acc: 85.16
[Train] Epoch: 1 [113536/387873]    Loss: 0.002071   Batch Acc: 89.06
[Train] Epoch: 1 [113664/387873]    Loss: 0.001675   Batch Acc: 89.84
[Train] Epoch: 1 [113792/387873]    Loss: 0.001756   Batch Acc: 89.84
[Train] Epoch: 1 [113920/387873]    Loss: 0.001784   Batch Acc: 93.75
[Train] Epoch: 1 [114048/387873]    Loss: 0.002273   Batch Acc: 89.84
[Train] Epoch: 1 [114176/387873]    Loss: 0.002052   Batch Acc: 91.41
[Train] Epoch: 1 [114304/387873]    Loss: 0.002324   Batch Acc: 86.72
[Train] Epoch: 1 [114432/387873]    Loss: 0.001978   Batch Acc: 90.62
[Train] Epoch: 1 [114560/387873]    Loss: 0.002182   Batch Acc: 88.28
[Train] Epoch: 1 [114688/387873]    Loss: 0.002214   Batch Acc: 89.06
[Train] Epoch: 1 [114816/387873]    Loss: 0.002004   Batch Acc: 89.06
[Train] Epoch: 1 [114944/387873]    Loss: 0.001933   Batch Acc: 92.97
[Train] Epoch: 1 [115072/387873]    Loss: 0.001947   Batch Acc: 89.84
[Train] Epoch: 1 [115200/387873]    Loss: 0.002235   Batch Acc: 89.84
[Train] Epoch: 1 [115328/387873]    Loss: 0.001731   Batch Acc: 91.41
[Train] Epoch: 1 [115456/387873]    Loss: 0.002269   Batch Acc: 88.28
[Train] Epoch: 1 [115584/387873]    Loss: 0.002640   Batch Acc: 82.81
[Train] Epoch: 1 [115712/387873]    Loss: 0.001782   Batch Acc: 92.19
[Train] Epoch: 1 [115840/387873]    Loss: 0.002345   Batch Acc: 86.72
[Train] Epoch: 1 [115968/387873]    Loss: 0.002021   Batch Acc: 89.84
[Train] Epoch: 1 [116096/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 1 [116224/387873]    Loss: 0.002694   Batch Acc: 85.94
[Train] Epoch: 1 [116352/387873]    Loss: 0.002117   Batch Acc: 91.41
[Train] Epoch: 1 [116480/387873]    Loss: 0.002276   Batch Acc: 87.50
[Train] Epoch: 1 [116608/387873]    Loss: 0.001735   Batch Acc: 92.97
[Train] Epoch: 1 [116736/387873]    Loss: 0.001542   Batch Acc: 90.62
[Train] Epoch: 1 [116864/387873]    Loss: 0.001711   Batch Acc: 92.97
[Train] Epoch: 1 [116992/387873]    Loss: 0.002545   Batch Acc: 86.72
[Train] Epoch: 1 [117120/387873]    Loss: 0.001714   Batch Acc: 92.19
[Train] Epoch: 1 [117248/387873]    Loss: 0.002552   Batch Acc: 88.28
[Train] Epoch: 1 [117376/387873]    Loss: 0.001690   Batch Acc: 90.62
[Train] Epoch: 1 [117504/387873]    Loss: 0.001983   Batch Acc: 89.06
[Train] Epoch: 1 [117632/387873]    Loss: 0.001994   Batch Acc: 89.84
[Train] Epoch: 1 [117760/387873]    Loss: 0.002206   Batch Acc: 89.06
[Train] Epoch: 1 [117888/387873]    Loss: 0.002414   Batch Acc: 86.72
[Train] Epoch: 1 [118016/387873]    Loss: 0.001746   Batch Acc: 90.62
[Train] Epoch: 1 [118144/387873]    Loss: 0.002158   Batch Acc: 89.06
[Train] Epoch: 1 [118272/387873]    Loss: 0.002130   Batch Acc: 87.50
[Train] Epoch: 1 [118400/387873]    Loss: 0.002428   Batch Acc: 87.50
[Train] Epoch: 1 [118528/387873]    Loss: 0.002588   Batch Acc: 85.16
[Train] Epoch: 1 [118656/387873]    Loss: 0.002190   Batch Acc: 89.06
[Train] Epoch: 1 [118784/387873]    Loss: 0.001887   Batch Acc: 89.06
[Train] Epoch: 1 [118912/387873]    Loss: 0.002102   Batch Acc: 90.62
[Train] Epoch: 1 [119040/387873]    Loss: 0.002459   Batch Acc: 84.38
[Train] Epoch: 1 [119168/387873]    Loss: 0.002182   Batch Acc: 87.50
[Train] Epoch: 1 [119296/387873]    Loss: 0.001826   Batch Acc: 95.31
[Train] Epoch: 1 [119424/387873]    Loss: 0.002210   Batch Acc: 89.06
[Train] Epoch: 1 [119552/387873]    Loss: 0.001996   Batch Acc: 91.41
[Train] Epoch: 1 [119680/387873]    Loss: 0.002040   Batch Acc: 89.84
[Train] Epoch: 1 [119808/387873]    Loss: 0.001874   Batch Acc: 90.62
[Train] Epoch: 1 [119936/387873]    Loss: 0.002502   Batch Acc: 88.28
[Train] Epoch: 1 [120064/387873]    Loss: 0.002037   Batch Acc: 92.97
[Train] Epoch: 1 [120192/387873]    Loss: 0.002439   Batch Acc: 85.94
[Train] Epoch: 1 [120320/387873]    Loss: 0.002465   Batch Acc: 86.72
[Train] Epoch: 1 [120448/387873]    Loss: 0.001722   Batch Acc: 90.62
[Train] Epoch: 1 [120576/387873]    Loss: 0.001787   Batch Acc: 91.41
[Train] Epoch: 1 [120704/387873]    Loss: 0.001934   Batch Acc: 89.06
[Train] Epoch: 1 [120832/387873]    Loss: 0.002026   Batch Acc: 88.28
[Train] Epoch: 1 [120960/387873]    Loss: 0.002192   Batch Acc: 89.84
[Train] Epoch: 1 [121088/387873]    Loss: 0.002433   Batch Acc: 89.06
[Train] Epoch: 1 [121216/387873]    Loss: 0.002576   Batch Acc: 86.72
[Train] Epoch: 1 [121344/387873]    Loss: 0.001672   Batch Acc: 91.41
[Train] Epoch: 1 [121472/387873]    Loss: 0.001729   Batch Acc: 91.41
[Train] Epoch: 1 [121600/387873]    Loss: 0.002147   Batch Acc: 87.50
[Train] Epoch: 1 [121728/387873]    Loss: 0.002233   Batch Acc: 85.16
[Train] Epoch: 1 [121856/387873]    Loss: 0.001777   Batch Acc: 89.84
[Train] Epoch: 1 [121984/387873]    Loss: 0.002175   Batch Acc: 89.84
[Train] Epoch: 1 [122112/387873]    Loss: 0.002246   Batch Acc: 89.06
[Train] Epoch: 1 [122240/387873]    Loss: 0.001878   Batch Acc: 92.97
[Train] Epoch: 1 [122368/387873]    Loss: 0.002247   Batch Acc: 87.50
[Train] Epoch: 1 [122496/387873]    Loss: 0.002241   Batch Acc: 88.28
[Train] Epoch: 1 [122624/387873]    Loss: 0.002522   Batch Acc: 86.72
[Train] Epoch: 1 [122752/387873]    Loss: 0.001904   Batch Acc: 92.19
[Train] Epoch: 1 [122880/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 1 [123008/387873]    Loss: 0.001642   Batch Acc: 90.62
[Train] Epoch: 1 [123136/387873]    Loss: 0.001648   Batch Acc: 89.84
[Train] Epoch: 1 [123264/387873]    Loss: 0.001697   Batch Acc: 92.97
[Train] Epoch: 1 [123392/387873]    Loss: 0.002130   Batch Acc: 89.84
[Train] Epoch: 1 [123520/387873]    Loss: 0.002585   Batch Acc: 86.72
[Train] Epoch: 1 [123648/387873]    Loss: 0.002193   Batch Acc: 88.28
[Train] Epoch: 1 [123776/387873]    Loss: 0.001686   Batch Acc: 93.75
[Train] Epoch: 1 [123904/387873]    Loss: 0.001539   Batch Acc: 92.97
[Train] Epoch: 1 [124032/387873]    Loss: 0.002109   Batch Acc: 88.28
[Train] Epoch: 1 [124160/387873]    Loss: 0.001979   Batch Acc: 90.62
[Train] Epoch: 1 [124288/387873]    Loss: 0.002146   Batch Acc: 90.62
[Train] Epoch: 1 [124416/387873]    Loss: 0.002020   Batch Acc: 92.97
[Train] Epoch: 1 [124544/387873]    Loss: 0.002450   Batch Acc: 89.84
[Train] Epoch: 1 [124672/387873]    Loss: 0.001972   Batch Acc: 89.06
[Train] Epoch: 1 [124800/387873]    Loss: 0.001893   Batch Acc: 89.06
[Train] Epoch: 1 [124928/387873]    Loss: 0.001933   Batch Acc: 91.41
[Train] Epoch: 1 [125056/387873]    Loss: 0.001947   Batch Acc: 89.06
[Train] Epoch: 1 [125184/387873]    Loss: 0.002084   Batch Acc: 87.50
[Train] Epoch: 1 [125312/387873]    Loss: 0.002946   Batch Acc: 85.16
[Train] Epoch: 1 [125440/387873]    Loss: 0.002107   Batch Acc: 91.41
[Train] Epoch: 1 [125568/387873]    Loss: 0.001914   Batch Acc: 91.41
[Train] Epoch: 1 [125696/387873]    Loss: 0.002788   Batch Acc: 79.69
[Train] Epoch: 1 [125824/387873]    Loss: 0.001841   Batch Acc: 88.28
[Train] Epoch: 1 [125952/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 1 [126080/387873]    Loss: 0.002690   Batch Acc: 85.94
[Train] Epoch: 1 [126208/387873]    Loss: 0.002467   Batch Acc: 82.81
[Train] Epoch: 1 [126336/387873]    Loss: 0.002775   Batch Acc: 82.81
[Train] Epoch: 1 [126464/387873]    Loss: 0.001677   Batch Acc: 92.19
[Train] Epoch: 1 [126592/387873]    Loss: 0.001794   Batch Acc: 90.62
[Train] Epoch: 1 [126720/387873]    Loss: 0.002147   Batch Acc: 87.50
[Train] Epoch: 1 [126848/387873]    Loss: 0.001735   Batch Acc: 92.19
[Train] Epoch: 1 [126976/387873]    Loss: 0.002234   Batch Acc: 90.62
[Train] Epoch: 1 [127104/387873]    Loss: 0.001996   Batch Acc: 92.97
[Train] Epoch: 1 [127232/387873]    Loss: 0.002319   Batch Acc: 89.84
[Train] Epoch: 1 [127360/387873]    Loss: 0.001641   Batch Acc: 93.75
[Train] Epoch: 1 [127488/387873]    Loss: 0.001819   Batch Acc: 90.62
[Train] Epoch: 1 [127616/387873]    Loss: 0.002232   Batch Acc: 87.50
[Train] Epoch: 1 [127744/387873]    Loss: 0.002075   Batch Acc: 87.50
[Train] Epoch: 1 [127872/387873]    Loss: 0.002308   Batch Acc: 87.50
[Train] Epoch: 1 [128000/387873]    Loss: 0.001761   Batch Acc: 91.41
[Train] Epoch: 1 [128128/387873]    Loss: 0.002338   Batch Acc: 89.84
[Train] Epoch: 1 [128256/387873]    Loss: 0.001931   Batch Acc: 90.62
[Train] Epoch: 1 [128384/387873]    Loss: 0.002715   Batch Acc: 86.72
[Train] Epoch: 1 [128512/387873]    Loss: 0.001922   Batch Acc: 90.62
[Train] Epoch: 1 [128640/387873]    Loss: 0.002149   Batch Acc: 88.28
[Train] Epoch: 1 [128768/387873]    Loss: 0.002351   Batch Acc: 86.72
[Train] Epoch: 1 [128896/387873]    Loss: 0.002317   Batch Acc: 85.16
[Train] Epoch: 1 [129024/387873]    Loss: 0.001677   Batch Acc: 89.84
[Train] Epoch: 1 [129152/387873]    Loss: 0.002075   Batch Acc: 90.62
[Train] Epoch: 1 [129280/387873]    Loss: 0.002162   Batch Acc: 92.19
[Train] Epoch: 1 [129408/387873]    Loss: 0.002200   Batch Acc: 86.72
[Train] Epoch: 1 [129536/387873]    Loss: 0.002165   Batch Acc: 89.84
[Train] Epoch: 1 [129664/387873]    Loss: 0.002399   Batch Acc: 87.50
[Train] Epoch: 1 [129792/387873]    Loss: 0.001972   Batch Acc: 90.62
[Train] Epoch: 1 [129920/387873]    Loss: 0.002439   Batch Acc: 86.72
[Train] Epoch: 1 [130048/387873]    Loss: 0.001934   Batch Acc: 89.06
[Train] Epoch: 1 [130176/387873]    Loss: 0.001957   Batch Acc: 88.28
[Train] Epoch: 1 [130304/387873]    Loss: 0.001747   Batch Acc: 92.19
[Train] Epoch: 1 [130432/387873]    Loss: 0.002459   Batch Acc: 87.50
[Train] Epoch: 1 [130560/387873]    Loss: 0.001253   Batch Acc: 96.88
[Train] Epoch: 1 [130688/387873]    Loss: 0.001923   Batch Acc: 90.62
[Train] Epoch: 1 [130816/387873]    Loss: 0.002321   Batch Acc: 86.72
[Train] Epoch: 1 [130944/387873]    Loss: 0.002436   Batch Acc: 88.28
[Train] Epoch: 1 [131072/387873]    Loss: 0.001924   Batch Acc: 91.41
[Train] Epoch: 1 [131200/387873]    Loss: 0.002165   Batch Acc: 90.62
[Train] Epoch: 1 [131328/387873]    Loss: 0.002002   Batch Acc: 90.62
[Train] Epoch: 1 [131456/387873]    Loss: 0.002272   Batch Acc: 83.59
[Train] Epoch: 1 [131584/387873]    Loss: 0.001954   Batch Acc: 89.06
[Train] Epoch: 1 [131712/387873]    Loss: 0.001822   Batch Acc: 90.62
[Train] Epoch: 1 [131840/387873]    Loss: 0.001841   Batch Acc: 90.62
[Train] Epoch: 1 [131968/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 1 [132096/387873]    Loss: 0.001858   Batch Acc: 89.84
[Train] Epoch: 1 [132224/387873]    Loss: 0.002248   Batch Acc: 89.84
[Train] Epoch: 1 [132352/387873]    Loss: 0.002341   Batch Acc: 87.50
[Train] Epoch: 1 [132480/387873]    Loss: 0.002081   Batch Acc: 91.41
[Train] Epoch: 1 [132608/387873]    Loss: 0.002530   Batch Acc: 87.50
[Train] Epoch: 1 [132736/387873]    Loss: 0.002348   Batch Acc: 86.72
[Train] Epoch: 1 [132864/387873]    Loss: 0.002466   Batch Acc: 85.94
[Train] Epoch: 1 [132992/387873]    Loss: 0.001943   Batch Acc: 89.06
[Train] Epoch: 1 [133120/387873]    Loss: 0.002913   Batch Acc: 80.47
[Train] Epoch: 1 [133248/387873]    Loss: 0.002229   Batch Acc: 85.16
[Train] Epoch: 1 [133376/387873]    Loss: 0.002243   Batch Acc: 89.84
[Train] Epoch: 1 [133504/387873]    Loss: 0.001952   Batch Acc: 92.19
[Train] Epoch: 1 [133632/387873]    Loss: 0.002559   Batch Acc: 86.72
[Train] Epoch: 1 [133760/387873]    Loss: 0.002053   Batch Acc: 89.84
[Train] Epoch: 1 [133888/387873]    Loss: 0.001997   Batch Acc: 89.84
[Train] Epoch: 1 [134016/387873]    Loss: 0.001596   Batch Acc: 93.75
[Train] Epoch: 1 [134144/387873]    Loss: 0.001916   Batch Acc: 90.62
[Train] Epoch: 1 [134272/387873]    Loss: 0.002390   Batch Acc: 88.28
[Train] Epoch: 1 [134400/387873]    Loss: 0.002016   Batch Acc: 89.84
[Train] Epoch: 1 [134528/387873]    Loss: 0.001952   Batch Acc: 87.50
[Train] Epoch: 1 [134656/387873]    Loss: 0.002017   Batch Acc: 88.28
[Train] Epoch: 1 [134784/387873]    Loss: 0.002646   Batch Acc: 83.59
[Train] Epoch: 1 [134912/387873]    Loss: 0.002360   Batch Acc: 86.72
[Train] Epoch: 1 [135040/387873]    Loss: 0.002341   Batch Acc: 84.38
[Train] Epoch: 1 [135168/387873]    Loss: 0.002345   Batch Acc: 87.50
[Train] Epoch: 1 [135296/387873]    Loss: 0.001967   Batch Acc: 90.62
[Train] Epoch: 1 [135424/387873]    Loss: 0.001798   Batch Acc: 93.75
[Train] Epoch: 1 [135552/387873]    Loss: 0.002284   Batch Acc: 87.50
[Train] Epoch: 1 [135680/387873]    Loss: 0.001868   Batch Acc: 90.62
[Train] Epoch: 1 [135808/387873]    Loss: 0.003068   Batch Acc: 80.47
[Train] Epoch: 1 [135936/387873]    Loss: 0.002267   Batch Acc: 85.16
[Train] Epoch: 1 [136064/387873]    Loss: 0.002092   Batch Acc: 90.62
[Train] Epoch: 1 [136192/387873]    Loss: 0.002341   Batch Acc: 86.72
[Train] Epoch: 1 [136320/387873]    Loss: 0.001953   Batch Acc: 90.62
[Train] Epoch: 1 [136448/387873]    Loss: 0.001653   Batch Acc: 91.41
[Train] Epoch: 1 [136576/387873]    Loss: 0.002372   Batch Acc: 87.50
[Train] Epoch: 1 [136704/387873]    Loss: 0.001899   Batch Acc: 89.06
[Train] Epoch: 1 [136832/387873]    Loss: 0.002197   Batch Acc: 85.94
[Train] Epoch: 1 [136960/387873]    Loss: 0.002557   Batch Acc: 83.59
[Train] Epoch: 1 [137088/387873]    Loss: 0.001991   Batch Acc: 91.41
[Train] Epoch: 1 [137216/387873]    Loss: 0.002196   Batch Acc: 91.41
[Train] Epoch: 1 [137344/387873]    Loss: 0.002282   Batch Acc: 88.28
[Train] Epoch: 1 [137472/387873]    Loss: 0.002786   Batch Acc: 83.59
[Train] Epoch: 1 [137600/387873]    Loss: 0.002399   Batch Acc: 87.50
[Train] Epoch: 1 [137728/387873]    Loss: 0.002532   Batch Acc: 85.94
[Train] Epoch: 1 [137856/387873]    Loss: 0.001787   Batch Acc: 92.19
[Train] Epoch: 1 [137984/387873]    Loss: 0.002198   Batch Acc: 91.41
[Train] Epoch: 1 [138112/387873]    Loss: 0.001878   Batch Acc: 92.19
[Train] Epoch: 1 [138240/387873]    Loss: 0.002027   Batch Acc: 90.62
[Train] Epoch: 1 [138368/387873]    Loss: 0.002077   Batch Acc: 88.28
[Train] Epoch: 1 [138496/387873]    Loss: 0.002274   Batch Acc: 85.94
[Train] Epoch: 1 [138624/387873]    Loss: 0.002307   Batch Acc: 89.84
[Train] Epoch: 1 [138752/387873]    Loss: 0.002292   Batch Acc: 89.06
[Train] Epoch: 1 [138880/387873]    Loss: 0.002293   Batch Acc: 87.50
[Train] Epoch: 1 [139008/387873]    Loss: 0.002118   Batch Acc: 85.94
[Train] Epoch: 1 [139136/387873]    Loss: 0.001987   Batch Acc: 89.84
[Train] Epoch: 1 [139264/387873]    Loss: 0.002451   Batch Acc: 83.59
[Train] Epoch: 1 [139392/387873]    Loss: 0.002265   Batch Acc: 88.28
[Train] Epoch: 1 [139520/387873]    Loss: 0.002438   Batch Acc: 89.06
[Train] Epoch: 1 [139648/387873]    Loss: 0.001867   Batch Acc: 93.75
[Train] Epoch: 1 [139776/387873]    Loss: 0.001943   Batch Acc: 91.41
[Train] Epoch: 1 [139904/387873]    Loss: 0.002896   Batch Acc: 82.81
[Train] Epoch: 1 [140032/387873]    Loss: 0.002159   Batch Acc: 89.84
[Train] Epoch: 1 [140160/387873]    Loss: 0.002672   Batch Acc: 85.16
[Train] Epoch: 1 [140288/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 1 [140416/387873]    Loss: 0.002776   Batch Acc: 85.94
[Train] Epoch: 1 [140544/387873]    Loss: 0.002407   Batch Acc: 85.94
[Train] Epoch: 1 [140672/387873]    Loss: 0.002055   Batch Acc: 89.84
[Train] Epoch: 1 [140800/387873]    Loss: 0.002050   Batch Acc: 91.41
[Train] Epoch: 1 [140928/387873]    Loss: 0.002531   Batch Acc: 85.16
[Train] Epoch: 1 [141056/387873]    Loss: 0.002521   Batch Acc: 83.59
[Train] Epoch: 1 [141184/387873]    Loss: 0.002636   Batch Acc: 82.03
[Train] Epoch: 1 [141312/387873]    Loss: 0.002101   Batch Acc: 89.84
[Train] Epoch: 1 [141440/387873]    Loss: 0.002138   Batch Acc: 89.06
[Train] Epoch: 1 [141568/387873]    Loss: 0.002171   Batch Acc: 87.50
[Train] Epoch: 1 [141696/387873]    Loss: 0.002214   Batch Acc: 87.50
[Train] Epoch: 1 [141824/387873]    Loss: 0.001827   Batch Acc: 89.06
[Train] Epoch: 1 [141952/387873]    Loss: 0.002737   Batch Acc: 81.25
[Train] Epoch: 1 [142080/387873]    Loss: 0.002608   Batch Acc: 85.94
[Train] Epoch: 1 [142208/387873]    Loss: 0.001996   Batch Acc: 89.06
[Train] Epoch: 1 [142336/387873]    Loss: 0.001930   Batch Acc: 89.84
[Train] Epoch: 1 [142464/387873]    Loss: 0.002163   Batch Acc: 89.06
[Train] Epoch: 1 [142592/387873]    Loss: 0.002141   Batch Acc: 87.50
[Train] Epoch: 1 [142720/387873]    Loss: 0.002137   Batch Acc: 90.62
[Train] Epoch: 1 [142848/387873]    Loss: 0.001956   Batch Acc: 89.84
[Train] Epoch: 1 [142976/387873]    Loss: 0.002126   Batch Acc: 90.62
[Train] Epoch: 1 [143104/387873]    Loss: 0.002297   Batch Acc: 83.59
[Train] Epoch: 1 [143232/387873]    Loss: 0.002769   Batch Acc: 85.94
[Train] Epoch: 1 [143360/387873]    Loss: 0.002433   Batch Acc: 85.16
[Train] Epoch: 1 [143488/387873]    Loss: 0.001753   Batch Acc: 92.19
[Train] Epoch: 1 [143616/387873]    Loss: 0.002449   Batch Acc: 86.72
[Train] Epoch: 1 [143744/387873]    Loss: 0.002352   Batch Acc: 88.28
[Train] Epoch: 1 [143872/387873]    Loss: 0.001731   Batch Acc: 91.41
[Train] Epoch: 1 [144000/387873]    Loss: 0.002622   Batch Acc: 85.16
[Train] Epoch: 1 [144128/387873]    Loss: 0.002244   Batch Acc: 85.94
[Train] Epoch: 1 [144256/387873]    Loss: 0.002132   Batch Acc: 88.28
[Train] Epoch: 1 [144384/387873]    Loss: 0.001970   Batch Acc: 90.62
[Train] Epoch: 1 [144512/387873]    Loss: 0.002207   Batch Acc: 92.19
[Train] Epoch: 1 [144640/387873]    Loss: 0.002120   Batch Acc: 89.06
[Train] Epoch: 1 [144768/387873]    Loss: 0.001975   Batch Acc: 88.28
[Train] Epoch: 1 [144896/387873]    Loss: 0.002785   Batch Acc: 82.03
[Train] Epoch: 1 [145024/387873]    Loss: 0.001918   Batch Acc: 88.28
[Train] Epoch: 1 [145152/387873]    Loss: 0.002192   Batch Acc: 88.28
[Train] Epoch: 1 [145280/387873]    Loss: 0.002331   Batch Acc: 88.28
[Train] Epoch: 1 [145408/387873]    Loss: 0.002315   Batch Acc: 87.50
[Train] Epoch: 1 [145536/387873]    Loss: 0.001905   Batch Acc: 90.62
[Train] Epoch: 1 [145664/387873]    Loss: 0.002075   Batch Acc: 88.28
[Train] Epoch: 1 [145792/387873]    Loss: 0.002298   Batch Acc: 89.06
[Train] Epoch: 1 [145920/387873]    Loss: 0.001876   Batch Acc: 92.97
[Train] Epoch: 1 [146048/387873]    Loss: 0.001851   Batch Acc: 88.28
[Train] Epoch: 1 [146176/387873]    Loss: 0.002032   Batch Acc: 89.06
[Train] Epoch: 1 [146304/387873]    Loss: 0.001524   Batch Acc: 92.97
[Train] Epoch: 1 [146432/387873]    Loss: 0.002130   Batch Acc: 91.41
[Train] Epoch: 1 [146560/387873]    Loss: 0.001598   Batch Acc: 94.53
[Train] Epoch: 1 [146688/387873]    Loss: 0.002046   Batch Acc: 91.41
[Train] Epoch: 1 [146816/387873]    Loss: 0.002382   Batch Acc: 85.16
[Train] Epoch: 1 [146944/387873]    Loss: 0.002115   Batch Acc: 88.28
[Train] Epoch: 1 [147072/387873]    Loss: 0.001792   Batch Acc: 91.41
[Train] Epoch: 1 [147200/387873]    Loss: 0.002049   Batch Acc: 90.62
[Train] Epoch: 1 [147328/387873]    Loss: 0.001949   Batch Acc: 90.62
[Train] Epoch: 1 [147456/387873]    Loss: 0.002627   Batch Acc: 85.94
[Train] Epoch: 1 [147584/387873]    Loss: 0.002924   Batch Acc: 83.59
[Train] Epoch: 1 [147712/387873]    Loss: 0.002523   Batch Acc: 85.94
[Train] Epoch: 1 [147840/387873]    Loss: 0.002789   Batch Acc: 82.81
[Train] Epoch: 1 [147968/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 1 [148096/387873]    Loss: 0.001900   Batch Acc: 92.19
[Train] Epoch: 1 [148224/387873]    Loss: 0.002156   Batch Acc: 86.72
[Train] Epoch: 1 [148352/387873]    Loss: 0.002316   Batch Acc: 90.62
[Train] Epoch: 1 [148480/387873]    Loss: 0.002607   Batch Acc: 85.16
[Train] Epoch: 1 [148608/387873]    Loss: 0.001888   Batch Acc: 86.72
[Train] Epoch: 1 [148736/387873]    Loss: 0.001851   Batch Acc: 90.62
[Train] Epoch: 1 [148864/387873]    Loss: 0.002341   Batch Acc: 85.16
[Train] Epoch: 1 [148992/387873]    Loss: 0.001741   Batch Acc: 94.53
[Train] Epoch: 1 [149120/387873]    Loss: 0.001829   Batch Acc: 89.84
[Train] Epoch: 1 [149248/387873]    Loss: 0.001892   Batch Acc: 92.97
[Train] Epoch: 1 [149376/387873]    Loss: 0.001822   Batch Acc: 89.84
[Train] Epoch: 1 [149504/387873]    Loss: 0.002506   Batch Acc: 86.72
[Train] Epoch: 1 [149632/387873]    Loss: 0.002218   Batch Acc: 85.94
[Train] Epoch: 1 [149760/387873]    Loss: 0.002402   Batch Acc: 85.16
[Train] Epoch: 1 [149888/387873]    Loss: 0.003065   Batch Acc: 80.47
[Train] Epoch: 1 [150016/387873]    Loss: 0.001873   Batch Acc: 90.62
[Train] Epoch: 1 [150144/387873]    Loss: 0.001791   Batch Acc: 90.62
[Train] Epoch: 1 [150272/387873]    Loss: 0.001761   Batch Acc: 92.19
[Train] Epoch: 1 [150400/387873]    Loss: 0.002574   Batch Acc: 84.38
[Train] Epoch: 1 [150528/387873]    Loss: 0.001640   Batch Acc: 93.75
[Train] Epoch: 1 [150656/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 1 [150784/387873]    Loss: 0.002496   Batch Acc: 84.38
[Train] Epoch: 1 [150912/387873]    Loss: 0.002217   Batch Acc: 88.28
[Train] Epoch: 1 [151040/387873]    Loss: 0.001982   Batch Acc: 89.84
[Train] Epoch: 1 [151168/387873]    Loss: 0.001888   Batch Acc: 92.97
[Train] Epoch: 1 [151296/387873]    Loss: 0.001959   Batch Acc: 89.06
[Train] Epoch: 1 [151424/387873]    Loss: 0.001960   Batch Acc: 89.84
[Train] Epoch: 1 [151552/387873]    Loss: 0.002086   Batch Acc: 89.84
[Train] Epoch: 1 [151680/387873]    Loss: 0.002320   Batch Acc: 85.94
[Train] Epoch: 1 [151808/387873]    Loss: 0.002108   Batch Acc: 89.84
[Train] Epoch: 1 [151936/387873]    Loss: 0.001896   Batch Acc: 89.06
[Train] Epoch: 1 [152064/387873]    Loss: 0.002384   Batch Acc: 87.50
[Train] Epoch: 1 [152192/387873]    Loss: 0.002076   Batch Acc: 90.62
[Train] Epoch: 1 [152320/387873]    Loss: 0.001940   Batch Acc: 91.41
[Train] Epoch: 1 [152448/387873]    Loss: 0.001931   Batch Acc: 89.84
[Train] Epoch: 1 [152576/387873]    Loss: 0.002046   Batch Acc: 92.19
[Train] Epoch: 1 [152704/387873]    Loss: 0.003115   Batch Acc: 83.59
[Train] Epoch: 1 [152832/387873]    Loss: 0.002030   Batch Acc: 90.62
[Train] Epoch: 1 [152960/387873]    Loss: 0.002453   Batch Acc: 85.16
[Train] Epoch: 1 [153088/387873]    Loss: 0.002008   Batch Acc: 87.50
[Train] Epoch: 1 [153216/387873]    Loss: 0.002311   Batch Acc: 87.50
[Train] Epoch: 1 [153344/387873]    Loss: 0.001708   Batch Acc: 92.19
[Train] Epoch: 1 [153472/387873]    Loss: 0.002303   Batch Acc: 84.38
[Train] Epoch: 1 [153600/387873]    Loss: 0.002412   Batch Acc: 85.94
[Train] Epoch: 1 [153728/387873]    Loss: 0.001983   Batch Acc: 92.19
[Train] Epoch: 1 [153856/387873]    Loss: 0.002453   Batch Acc: 86.72
[Train] Epoch: 1 [153984/387873]    Loss: 0.002859   Batch Acc: 82.81
[Train] Epoch: 1 [154112/387873]    Loss: 0.001901   Batch Acc: 86.72
[Train] Epoch: 1 [154240/387873]    Loss: 0.001788   Batch Acc: 90.62
[Train] Epoch: 1 [154368/387873]    Loss: 0.002057   Batch Acc: 88.28
[Train] Epoch: 1 [154496/387873]    Loss: 0.002202   Batch Acc: 90.62
[Train] Epoch: 1 [154624/387873]    Loss: 0.002126   Batch Acc: 89.84
[Train] Epoch: 1 [154752/387873]    Loss: 0.002142   Batch Acc: 87.50
[Train] Epoch: 1 [154880/387873]    Loss: 0.001801   Batch Acc: 92.97
[Train] Epoch: 1 [155008/387873]    Loss: 0.002129   Batch Acc: 88.28
[Train] Epoch: 1 [155136/387873]    Loss: 0.002132   Batch Acc: 89.06
[Train] Epoch: 1 [155264/387873]    Loss: 0.001683   Batch Acc: 93.75
[Train] Epoch: 1 [155392/387873]    Loss: 0.001775   Batch Acc: 89.06
[Train] Epoch: 1 [155520/387873]    Loss: 0.002036   Batch Acc: 88.28
[Train] Epoch: 1 [155648/387873]    Loss: 0.002705   Batch Acc: 85.94
[Train] Epoch: 1 [155776/387873]    Loss: 0.001984   Batch Acc: 89.84
[Train] Epoch: 1 [155904/387873]    Loss: 0.001786   Batch Acc: 89.84
[Train] Epoch: 1 [156032/387873]    Loss: 0.001868   Batch Acc: 90.62
[Train] Epoch: 1 [156160/387873]    Loss: 0.002034   Batch Acc: 91.41
[Train] Epoch: 1 [156288/387873]    Loss: 0.002254   Batch Acc: 86.72
[Train] Epoch: 1 [156416/387873]    Loss: 0.002058   Batch Acc: 89.06
[Train] Epoch: 1 [156544/387873]    Loss: 0.001784   Batch Acc: 91.41
[Train] Epoch: 1 [156672/387873]    Loss: 0.002860   Batch Acc: 81.25
[Train] Epoch: 1 [156800/387873]    Loss: 0.001858   Batch Acc: 91.41
[Train] Epoch: 1 [156928/387873]    Loss: 0.001691   Batch Acc: 91.41
[Train] Epoch: 1 [157056/387873]    Loss: 0.002592   Batch Acc: 86.72
[Train] Epoch: 1 [157184/387873]    Loss: 0.002208   Batch Acc: 88.28
[Train] Epoch: 1 [157312/387873]    Loss: 0.001830   Batch Acc: 91.41
[Train] Epoch: 1 [157440/387873]    Loss: 0.002464   Batch Acc: 87.50
[Train] Epoch: 1 [157568/387873]    Loss: 0.001694   Batch Acc: 91.41
[Train] Epoch: 1 [157696/387873]    Loss: 0.001974   Batch Acc: 90.62
[Train] Epoch: 1 [157824/387873]    Loss: 0.002537   Batch Acc: 85.94
[Train] Epoch: 1 [157952/387873]    Loss: 0.001833   Batch Acc: 92.19
[Train] Epoch: 1 [158080/387873]    Loss: 0.002289   Batch Acc: 89.06
[Train] Epoch: 1 [158208/387873]    Loss: 0.001857   Batch Acc: 90.62
[Train] Epoch: 1 [158336/387873]    Loss: 0.002377   Batch Acc: 88.28
[Train] Epoch: 1 [158464/387873]    Loss: 0.001489   Batch Acc: 92.97
[Train] Epoch: 1 [158592/387873]    Loss: 0.002870   Batch Acc: 82.81
[Train] Epoch: 1 [158720/387873]    Loss: 0.001844   Batch Acc: 89.06
[Train] Epoch: 1 [158848/387873]    Loss: 0.002432   Batch Acc: 85.16
[Train] Epoch: 1 [158976/387873]    Loss: 0.001668   Batch Acc: 92.97
[Train] Epoch: 1 [159104/387873]    Loss: 0.002825   Batch Acc: 82.03
[Train] Epoch: 1 [159232/387873]    Loss: 0.001557   Batch Acc: 92.97
[Train] Epoch: 1 [159360/387873]    Loss: 0.002736   Batch Acc: 84.38
[Train] Epoch: 1 [159488/387873]    Loss: 0.002268   Batch Acc: 84.38
[Train] Epoch: 1 [159616/387873]    Loss: 0.001963   Batch Acc: 89.06
[Train] Epoch: 1 [159744/387873]    Loss: 0.002126   Batch Acc: 88.28
[Train] Epoch: 1 [159872/387873]    Loss: 0.001827   Batch Acc: 89.84
[Train] Epoch: 1 [160000/387873]    Loss: 0.002127   Batch Acc: 89.84
[Train] Epoch: 1 [160128/387873]    Loss: 0.001945   Batch Acc: 91.41
[Train] Epoch: 1 [160256/387873]    Loss: 0.002192   Batch Acc: 87.50
[Train] Epoch: 1 [160384/387873]    Loss: 0.001980   Batch Acc: 89.84
[Train] Epoch: 1 [160512/387873]    Loss: 0.001785   Batch Acc: 91.41
[Train] Epoch: 1 [160640/387873]    Loss: 0.002247   Batch Acc: 87.50
[Train] Epoch: 1 [160768/387873]    Loss: 0.003183   Batch Acc: 81.25
[Train] Epoch: 1 [160896/387873]    Loss: 0.002091   Batch Acc: 89.06
[Train] Epoch: 1 [161024/387873]    Loss: 0.002551   Batch Acc: 89.06
[Train] Epoch: 1 [161152/387873]    Loss: 0.002004   Batch Acc: 91.41
[Train] Epoch: 1 [161280/387873]    Loss: 0.001785   Batch Acc: 92.19
[Train] Epoch: 1 [161408/387873]    Loss: 0.002286   Batch Acc: 88.28
[Train] Epoch: 1 [161536/387873]    Loss: 0.001877   Batch Acc: 90.62
[Train] Epoch: 1 [161664/387873]    Loss: 0.002355   Batch Acc: 87.50
[Train] Epoch: 1 [161792/387873]    Loss: 0.002066   Batch Acc: 88.28
[Train] Epoch: 1 [161920/387873]    Loss: 0.002022   Batch Acc: 91.41
[Train] Epoch: 1 [162048/387873]    Loss: 0.002111   Batch Acc: 89.06
[Train] Epoch: 1 [162176/387873]    Loss: 0.002749   Batch Acc: 85.16
[Train] Epoch: 1 [162304/387873]    Loss: 0.001787   Batch Acc: 89.84
[Train] Epoch: 1 [162432/387873]    Loss: 0.002769   Batch Acc: 85.16
[Train] Epoch: 1 [162560/387873]    Loss: 0.002177   Batch Acc: 89.06
[Train] Epoch: 1 [162688/387873]    Loss: 0.002352   Batch Acc: 89.06
[Train] Epoch: 1 [162816/387873]    Loss: 0.001906   Batch Acc: 90.62
[Train] Epoch: 1 [162944/387873]    Loss: 0.002394   Batch Acc: 88.28
[Train] Epoch: 1 [163072/387873]    Loss: 0.002253   Batch Acc: 87.50
[Train] Epoch: 1 [163200/387873]    Loss: 0.001697   Batch Acc: 92.19
[Train] Epoch: 1 [163328/387873]    Loss: 0.001856   Batch Acc: 92.19
[Train] Epoch: 1 [163456/387873]    Loss: 0.001899   Batch Acc: 91.41
[Train] Epoch: 1 [163584/387873]    Loss: 0.002637   Batch Acc: 85.16
[Train] Epoch: 1 [163712/387873]    Loss: 0.001912   Batch Acc: 86.72
[Train] Epoch: 1 [163840/387873]    Loss: 0.002037   Batch Acc: 92.19
[Train] Epoch: 1 [163968/387873]    Loss: 0.001771   Batch Acc: 91.41
[Train] Epoch: 1 [164096/387873]    Loss: 0.002291   Batch Acc: 87.50
[Train] Epoch: 1 [164224/387873]    Loss: 0.002364   Batch Acc: 88.28
[Train] Epoch: 1 [164352/387873]    Loss: 0.001722   Batch Acc: 93.75
[Train] Epoch: 1 [164480/387873]    Loss: 0.002023   Batch Acc: 92.19
[Train] Epoch: 1 [164608/387873]    Loss: 0.001978   Batch Acc: 89.84
[Train] Epoch: 1 [164736/387873]    Loss: 0.002375   Batch Acc: 87.50
[Train] Epoch: 1 [164864/387873]    Loss: 0.002129   Batch Acc: 85.16
[Train] Epoch: 1 [164992/387873]    Loss: 0.001835   Batch Acc: 89.84
[Train] Epoch: 1 [165120/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 1 [165248/387873]    Loss: 0.001997   Batch Acc: 87.50
[Train] Epoch: 1 [165376/387873]    Loss: 0.001913   Batch Acc: 91.41
[Train] Epoch: 1 [165504/387873]    Loss: 0.002199   Batch Acc: 89.84
[Train] Epoch: 1 [165632/387873]    Loss: 0.002317   Batch Acc: 86.72
[Train] Epoch: 1 [165760/387873]    Loss: 0.002447   Batch Acc: 85.94
[Train] Epoch: 1 [165888/387873]    Loss: 0.001925   Batch Acc: 90.62
[Train] Epoch: 1 [166016/387873]    Loss: 0.002402   Batch Acc: 87.50
[Train] Epoch: 1 [166144/387873]    Loss: 0.002379   Batch Acc: 87.50
[Train] Epoch: 1 [166272/387873]    Loss: 0.002100   Batch Acc: 86.72
[Train] Epoch: 1 [166400/387873]    Loss: 0.002118   Batch Acc: 89.84
[Train] Epoch: 1 [166528/387873]    Loss: 0.001861   Batch Acc: 92.97
[Train] Epoch: 1 [166656/387873]    Loss: 0.001880   Batch Acc: 92.97
[Train] Epoch: 1 [166784/387873]    Loss: 0.002293   Batch Acc: 89.06
[Train] Epoch: 1 [166912/387873]    Loss: 0.002523   Batch Acc: 85.16
[Train] Epoch: 1 [167040/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 1 [167168/387873]    Loss: 0.002450   Batch Acc: 85.94
[Train] Epoch: 1 [167296/387873]    Loss: 0.001838   Batch Acc: 92.19
[Train] Epoch: 1 [167424/387873]    Loss: 0.002473   Batch Acc: 87.50
[Train] Epoch: 1 [167552/387873]    Loss: 0.001555   Batch Acc: 93.75
[Train] Epoch: 1 [167680/387873]    Loss: 0.001668   Batch Acc: 94.53
[Train] Epoch: 1 [167808/387873]    Loss: 0.001654   Batch Acc: 92.19
[Train] Epoch: 1 [167936/387873]    Loss: 0.002263   Batch Acc: 86.72
[Train] Epoch: 1 [168064/387873]    Loss: 0.002118   Batch Acc: 89.06
[Train] Epoch: 1 [168192/387873]    Loss: 0.002807   Batch Acc: 85.16
[Train] Epoch: 1 [168320/387873]    Loss: 0.002076   Batch Acc: 88.28
[Train] Epoch: 1 [168448/387873]    Loss: 0.001777   Batch Acc: 92.19
[Train] Epoch: 1 [168576/387873]    Loss: 0.001534   Batch Acc: 92.97
[Train] Epoch: 1 [168704/387873]    Loss: 0.002262   Batch Acc: 85.16
[Train] Epoch: 1 [168832/387873]    Loss: 0.002549   Batch Acc: 84.38
[Train] Epoch: 1 [168960/387873]    Loss: 0.002023   Batch Acc: 89.06
[Train] Epoch: 1 [169088/387873]    Loss: 0.002042   Batch Acc: 89.84
[Train] Epoch: 1 [169216/387873]    Loss: 0.002044   Batch Acc: 89.84
[Train] Epoch: 1 [169344/387873]    Loss: 0.001897   Batch Acc: 91.41
[Train] Epoch: 1 [169472/387873]    Loss: 0.002055   Batch Acc: 89.06
[Train] Epoch: 1 [169600/387873]    Loss: 0.002274   Batch Acc: 89.06
[Train] Epoch: 1 [169728/387873]    Loss: 0.002180   Batch Acc: 87.50
[Train] Epoch: 1 [169856/387873]    Loss: 0.002639   Batch Acc: 84.38
[Train] Epoch: 1 [169984/387873]    Loss: 0.001871   Batch Acc: 91.41
[Train] Epoch: 1 [170112/387873]    Loss: 0.002111   Batch Acc: 88.28
[Train] Epoch: 1 [170240/387873]    Loss: 0.002219   Batch Acc: 89.84
[Train] Epoch: 1 [170368/387873]    Loss: 0.002291   Batch Acc: 89.84
[Train] Epoch: 1 [170496/387873]    Loss: 0.001850   Batch Acc: 86.72
[Train] Epoch: 1 [170624/387873]    Loss: 0.002382   Batch Acc: 85.94
[Train] Epoch: 1 [170752/387873]    Loss: 0.002043   Batch Acc: 89.06
[Train] Epoch: 1 [170880/387873]    Loss: 0.001693   Batch Acc: 92.19
[Train] Epoch: 1 [171008/387873]    Loss: 0.002275   Batch Acc: 85.94
[Train] Epoch: 1 [171136/387873]    Loss: 0.002278   Batch Acc: 89.06
[Train] Epoch: 1 [171264/387873]    Loss: 0.002473   Batch Acc: 82.81
[Train] Epoch: 1 [171392/387873]    Loss: 0.002046   Batch Acc: 84.38
[Train] Epoch: 1 [171520/387873]    Loss: 0.001693   Batch Acc: 91.41
[Train] Epoch: 1 [171648/387873]    Loss: 0.002029   Batch Acc: 88.28
[Train] Epoch: 1 [171776/387873]    Loss: 0.001706   Batch Acc: 89.06
[Train] Epoch: 1 [171904/387873]    Loss: 0.002182   Batch Acc: 86.72
[Train] Epoch: 1 [172032/387873]    Loss: 0.002076   Batch Acc: 90.62
[Train] Epoch: 1 [172160/387873]    Loss: 0.002309   Batch Acc: 89.06
[Train] Epoch: 1 [172288/387873]    Loss: 0.002387   Batch Acc: 86.72
[Train] Epoch: 1 [172416/387873]    Loss: 0.001692   Batch Acc: 91.41
[Train] Epoch: 1 [172544/387873]    Loss: 0.002560   Batch Acc: 86.72
[Train] Epoch: 1 [172672/387873]    Loss: 0.002185   Batch Acc: 86.72
[Train] Epoch: 1 [172800/387873]    Loss: 0.002227   Batch Acc: 89.84
[Train] Epoch: 1 [172928/387873]    Loss: 0.002182   Batch Acc: 85.94
[Train] Epoch: 1 [173056/387873]    Loss: 0.003277   Batch Acc: 79.69
[Train] Epoch: 1 [173184/387873]    Loss: 0.002815   Batch Acc: 84.38
[Train] Epoch: 1 [173312/387873]    Loss: 0.002023   Batch Acc: 87.50
[Train] Epoch: 1 [173440/387873]    Loss: 0.002735   Batch Acc: 84.38
[Train] Epoch: 1 [173568/387873]    Loss: 0.002152   Batch Acc: 87.50
[Train] Epoch: 1 [173696/387873]    Loss: 0.001821   Batch Acc: 89.84
[Train] Epoch: 1 [173824/387873]    Loss: 0.002319   Batch Acc: 85.94
[Train] Epoch: 1 [173952/387873]    Loss: 0.002085   Batch Acc: 86.72
[Train] Epoch: 1 [174080/387873]    Loss: 0.002292   Batch Acc: 89.06
[Train] Epoch: 1 [174208/387873]    Loss: 0.001903   Batch Acc: 92.19
[Train] Epoch: 1 [174336/387873]    Loss: 0.003451   Batch Acc: 81.25
[Train] Epoch: 1 [174464/387873]    Loss: 0.002283   Batch Acc: 85.16
[Train] Epoch: 1 [174592/387873]    Loss: 0.002052   Batch Acc: 91.41
[Train] Epoch: 1 [174720/387873]    Loss: 0.002234   Batch Acc: 87.50
[Train] Epoch: 1 [174848/387873]    Loss: 0.002596   Batch Acc: 86.72
[Train] Epoch: 1 [174976/387873]    Loss: 0.001430   Batch Acc: 93.75
[Train] Epoch: 1 [175104/387873]    Loss: 0.002336   Batch Acc: 88.28
[Train] Epoch: 1 [175232/387873]    Loss: 0.002190   Batch Acc: 88.28
[Train] Epoch: 1 [175360/387873]    Loss: 0.001977   Batch Acc: 89.84
[Train] Epoch: 1 [175488/387873]    Loss: 0.002166   Batch Acc: 89.84
[Train] Epoch: 1 [175616/387873]    Loss: 0.002033   Batch Acc: 88.28
[Train] Epoch: 1 [175744/387873]    Loss: 0.001737   Batch Acc: 91.41
[Train] Epoch: 1 [175872/387873]    Loss: 0.002118   Batch Acc: 91.41
[Train] Epoch: 1 [176000/387873]    Loss: 0.002052   Batch Acc: 90.62
[Train] Epoch: 1 [176128/387873]    Loss: 0.002306   Batch Acc: 90.62
[Train] Epoch: 1 [176256/387873]    Loss: 0.002295   Batch Acc: 86.72
[Train] Epoch: 1 [176384/387873]    Loss: 0.002621   Batch Acc: 83.59
[Train] Epoch: 1 [176512/387873]    Loss: 0.002384   Batch Acc: 85.94
[Train] Epoch: 1 [176640/387873]    Loss: 0.002866   Batch Acc: 84.38
[Train] Epoch: 1 [176768/387873]    Loss: 0.002279   Batch Acc: 87.50
[Train] Epoch: 1 [176896/387873]    Loss: 0.001732   Batch Acc: 95.31
[Train] Epoch: 1 [177024/387873]    Loss: 0.002405   Batch Acc: 85.16
[Train] Epoch: 1 [177152/387873]    Loss: 0.002776   Batch Acc: 85.16
[Train] Epoch: 1 [177280/387873]    Loss: 0.002186   Batch Acc: 86.72
[Train] Epoch: 1 [177408/387873]    Loss: 0.002098   Batch Acc: 90.62
[Train] Epoch: 1 [177536/387873]    Loss: 0.002151   Batch Acc: 88.28
[Train] Epoch: 1 [177664/387873]    Loss: 0.001971   Batch Acc: 89.84
[Train] Epoch: 1 [177792/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 1 [177920/387873]    Loss: 0.002720   Batch Acc: 85.16
[Train] Epoch: 1 [178048/387873]    Loss: 0.002411   Batch Acc: 88.28
[Train] Epoch: 1 [178176/387873]    Loss: 0.002153   Batch Acc: 89.84
[Train] Epoch: 1 [178304/387873]    Loss: 0.002591   Batch Acc: 86.72
[Train] Epoch: 1 [178432/387873]    Loss: 0.002444   Batch Acc: 84.38
[Train] Epoch: 1 [178560/387873]    Loss: 0.001801   Batch Acc: 89.84
[Train] Epoch: 1 [178688/387873]    Loss: 0.001633   Batch Acc: 91.41
[Train] Epoch: 1 [178816/387873]    Loss: 0.001720   Batch Acc: 92.19
[Train] Epoch: 1 [178944/387873]    Loss: 0.001760   Batch Acc: 92.19
[Train] Epoch: 1 [179072/387873]    Loss: 0.002419   Batch Acc: 90.62
[Train] Epoch: 1 [179200/387873]    Loss: 0.002318   Batch Acc: 85.94
[Train] Epoch: 1 [179328/387873]    Loss: 0.002419   Batch Acc: 87.50
[Train] Epoch: 1 [179456/387873]    Loss: 0.002308   Batch Acc: 87.50
[Train] Epoch: 1 [179584/387873]    Loss: 0.002095   Batch Acc: 88.28
[Train] Epoch: 1 [179712/387873]    Loss: 0.002169   Batch Acc: 87.50
[Train] Epoch: 1 [179840/387873]    Loss: 0.001949   Batch Acc: 92.97
[Train] Epoch: 1 [179968/387873]    Loss: 0.002051   Batch Acc: 89.84
[Train] Epoch: 1 [180096/387873]    Loss: 0.002053   Batch Acc: 90.62
[Train] Epoch: 1 [180224/387873]    Loss: 0.001779   Batch Acc: 91.41
[Train] Epoch: 1 [180352/387873]    Loss: 0.002115   Batch Acc: 89.06
[Train] Epoch: 1 [180480/387873]    Loss: 0.002185   Batch Acc: 89.06
[Train] Epoch: 1 [180608/387873]    Loss: 0.002760   Batch Acc: 85.94
[Train] Epoch: 1 [180736/387873]    Loss: 0.002614   Batch Acc: 82.81
[Train] Epoch: 1 [180864/387873]    Loss: 0.002726   Batch Acc: 89.06
[Train] Epoch: 1 [180992/387873]    Loss: 0.002292   Batch Acc: 85.16
[Train] Epoch: 1 [181120/387873]    Loss: 0.002059   Batch Acc: 90.62
[Train] Epoch: 1 [181248/387873]    Loss: 0.001922   Batch Acc: 88.28
[Train] Epoch: 1 [181376/387873]    Loss: 0.002201   Batch Acc: 91.41
[Train] Epoch: 1 [181504/387873]    Loss: 0.002512   Batch Acc: 86.72
[Train] Epoch: 1 [181632/387873]    Loss: 0.002012   Batch Acc: 87.50
[Train] Epoch: 1 [181760/387873]    Loss: 0.002171   Batch Acc: 89.84
[Train] Epoch: 1 [181888/387873]    Loss: 0.002345   Batch Acc: 88.28
[Train] Epoch: 1 [182016/387873]    Loss: 0.001756   Batch Acc: 89.84
[Train] Epoch: 1 [182144/387873]    Loss: 0.002171   Batch Acc: 86.72
[Train] Epoch: 1 [182272/387873]    Loss: 0.001886   Batch Acc: 89.84
[Train] Epoch: 1 [182400/387873]    Loss: 0.001978   Batch Acc: 89.06
[Train] Epoch: 1 [182528/387873]    Loss: 0.002135   Batch Acc: 87.50
[Train] Epoch: 1 [182656/387873]    Loss: 0.002737   Batch Acc: 81.25
[Train] Epoch: 1 [182784/387873]    Loss: 0.001878   Batch Acc: 90.62
[Train] Epoch: 1 [182912/387873]    Loss: 0.001976   Batch Acc: 89.06
[Train] Epoch: 1 [183040/387873]    Loss: 0.001752   Batch Acc: 90.62
[Train] Epoch: 1 [183168/387873]    Loss: 0.002339   Batch Acc: 88.28
[Train] Epoch: 1 [183296/387873]    Loss: 0.002194   Batch Acc: 89.06
[Train] Epoch: 1 [183424/387873]    Loss: 0.002227   Batch Acc: 89.84
[Train] Epoch: 1 [183552/387873]    Loss: 0.002572   Batch Acc: 81.25
[Train] Epoch: 1 [183680/387873]    Loss: 0.002828   Batch Acc: 83.59
[Train] Epoch: 1 [183808/387873]    Loss: 0.002178   Batch Acc: 89.06
[Train] Epoch: 1 [183936/387873]    Loss: 0.002211   Batch Acc: 88.28
[Train] Epoch: 1 [184064/387873]    Loss: 0.002708   Batch Acc: 86.72
[Train] Epoch: 1 [184192/387873]    Loss: 0.001903   Batch Acc: 89.84
[Train] Epoch: 1 [184320/387873]    Loss: 0.002284   Batch Acc: 85.16
[Train] Epoch: 1 [184448/387873]    Loss: 0.001962   Batch Acc: 87.50
[Train] Epoch: 1 [184576/387873]    Loss: 0.002060   Batch Acc: 90.62
[Train] Epoch: 1 [184704/387873]    Loss: 0.002160   Batch Acc: 86.72
[Train] Epoch: 1 [184832/387873]    Loss: 0.002671   Batch Acc: 82.03
[Train] Epoch: 1 [184960/387873]    Loss: 0.001656   Batch Acc: 91.41
[Train] Epoch: 1 [185088/387873]    Loss: 0.002386   Batch Acc: 89.06
[Train] Epoch: 1 [185216/387873]    Loss: 0.001417   Batch Acc: 93.75
[Train] Epoch: 1 [185344/387873]    Loss: 0.002232   Batch Acc: 87.50
[Train] Epoch: 1 [185472/387873]    Loss: 0.001904   Batch Acc: 88.28
[Train] Epoch: 1 [185600/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 1 [185728/387873]    Loss: 0.002096   Batch Acc: 88.28
[Train] Epoch: 1 [185856/387873]    Loss: 0.001940   Batch Acc: 90.62
[Train] Epoch: 1 [185984/387873]    Loss: 0.002238   Batch Acc: 87.50
[Train] Epoch: 1 [186112/387873]    Loss: 0.002238   Batch Acc: 88.28
[Train] Epoch: 1 [186240/387873]    Loss: 0.001743   Batch Acc: 90.62
[Train] Epoch: 1 [186368/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 1 [186496/387873]    Loss: 0.002047   Batch Acc: 87.50
[Train] Epoch: 1 [186624/387873]    Loss: 0.002067   Batch Acc: 91.41
[Train] Epoch: 1 [186752/387873]    Loss: 0.002398   Batch Acc: 89.06
[Train] Epoch: 1 [186880/387873]    Loss: 0.001910   Batch Acc: 91.41
[Train] Epoch: 1 [187008/387873]    Loss: 0.001991   Batch Acc: 88.28
[Train] Epoch: 1 [187136/387873]    Loss: 0.002308   Batch Acc: 89.06
[Train] Epoch: 1 [187264/387873]    Loss: 0.002722   Batch Acc: 86.72
[Train] Epoch: 1 [187392/387873]    Loss: 0.002073   Batch Acc: 88.28
[Train] Epoch: 1 [187520/387873]    Loss: 0.002277   Batch Acc: 86.72
[Train] Epoch: 1 [187648/387873]    Loss: 0.002411   Batch Acc: 83.59
[Train] Epoch: 1 [187776/387873]    Loss: 0.002013   Batch Acc: 90.62
[Train] Epoch: 1 [187904/387873]    Loss: 0.002336   Batch Acc: 86.72
[Train] Epoch: 1 [188032/387873]    Loss: 0.002118   Batch Acc: 89.06
[Train] Epoch: 1 [188160/387873]    Loss: 0.002311   Batch Acc: 86.72
[Train] Epoch: 1 [188288/387873]    Loss: 0.002312   Batch Acc: 85.16
[Train] Epoch: 1 [188416/387873]    Loss: 0.002229   Batch Acc: 85.94
[Train] Epoch: 1 [188544/387873]    Loss: 0.001954   Batch Acc: 90.62
[Train] Epoch: 1 [188672/387873]    Loss: 0.002166   Batch Acc: 91.41
[Train] Epoch: 1 [188800/387873]    Loss: 0.002111   Batch Acc: 90.62
[Train] Epoch: 1 [188928/387873]    Loss: 0.002207   Batch Acc: 86.72
[Train] Epoch: 1 [189056/387873]    Loss: 0.002059   Batch Acc: 89.84
[Train] Epoch: 1 [189184/387873]    Loss: 0.002213   Batch Acc: 89.06
[Train] Epoch: 1 [189312/387873]    Loss: 0.002149   Batch Acc: 88.28
[Train] Epoch: 1 [189440/387873]    Loss: 0.002193   Batch Acc: 91.41
[Train] Epoch: 1 [189568/387873]    Loss: 0.002255   Batch Acc: 85.94
[Train] Epoch: 1 [189696/387873]    Loss: 0.002168   Batch Acc: 88.28
[Train] Epoch: 1 [189824/387873]    Loss: 0.002313   Batch Acc: 89.06
[Train] Epoch: 1 [189952/387873]    Loss: 0.001719   Batch Acc: 92.19
[Train] Epoch: 1 [190080/387873]    Loss: 0.001737   Batch Acc: 91.41
[Train] Epoch: 1 [190208/387873]    Loss: 0.003330   Batch Acc: 82.81
[Train] Epoch: 1 [190336/387873]    Loss: 0.002157   Batch Acc: 88.28
[Train] Epoch: 1 [190464/387873]    Loss: 0.002193   Batch Acc: 88.28
[Train] Epoch: 1 [190592/387873]    Loss: 0.002041   Batch Acc: 88.28
[Train] Epoch: 1 [190720/387873]    Loss: 0.002578   Batch Acc: 85.94
[Train] Epoch: 1 [190848/387873]    Loss: 0.001941   Batch Acc: 91.41
[Train] Epoch: 1 [190976/387873]    Loss: 0.002794   Batch Acc: 85.94
[Train] Epoch: 1 [191104/387873]    Loss: 0.002515   Batch Acc: 84.38
[Train] Epoch: 1 [191232/387873]    Loss: 0.002668   Batch Acc: 85.16
[Train] Epoch: 1 [191360/387873]    Loss: 0.001962   Batch Acc: 88.28
[Train] Epoch: 1 [191488/387873]    Loss: 0.002594   Batch Acc: 86.72
[Train] Epoch: 1 [191616/387873]    Loss: 0.001935   Batch Acc: 89.84
[Train] Epoch: 1 [191744/387873]    Loss: 0.001816   Batch Acc: 90.62
[Train] Epoch: 1 [191872/387873]    Loss: 0.002124   Batch Acc: 88.28
[Train] Epoch: 1 [192000/387873]    Loss: 0.001869   Batch Acc: 89.06
[Train] Epoch: 1 [192128/387873]    Loss: 0.002145   Batch Acc: 88.28
[Train] Epoch: 1 [192256/387873]    Loss: 0.002070   Batch Acc: 88.28
[Train] Epoch: 1 [192384/387873]    Loss: 0.002405   Batch Acc: 87.50
[Train] Epoch: 1 [192512/387873]    Loss: 0.001982   Batch Acc: 89.06
[Train] Epoch: 1 [192640/387873]    Loss: 0.001898   Batch Acc: 89.84
[Train] Epoch: 1 [192768/387873]    Loss: 0.002505   Batch Acc: 86.72
[Train] Epoch: 1 [192896/387873]    Loss: 0.002097   Batch Acc: 89.84
[Train] Epoch: 1 [193024/387873]    Loss: 0.002824   Batch Acc: 81.25
[Train] Epoch: 1 [193152/387873]    Loss: 0.002788   Batch Acc: 83.59
[Train] Epoch: 1 [193280/387873]    Loss: 0.002180   Batch Acc: 92.19
[Train] Epoch: 1 [193408/387873]    Loss: 0.002421   Batch Acc: 88.28
[Train] Epoch: 1 [193536/387873]    Loss: 0.002005   Batch Acc: 89.84
[Train] Epoch: 1 [193664/387873]    Loss: 0.001975   Batch Acc: 89.06
[Train] Epoch: 1 [193792/387873]    Loss: 0.001694   Batch Acc: 93.75
[Train] Epoch: 1 [193920/387873]    Loss: 0.002678   Batch Acc: 83.59
[Train] Epoch: 1 [194048/387873]    Loss: 0.001971   Batch Acc: 87.50
[Train] Epoch: 1 [194176/387873]    Loss: 0.001737   Batch Acc: 91.41
[Train] Epoch: 1 [194304/387873]    Loss: 0.002190   Batch Acc: 89.84
[Train] Epoch: 1 [194432/387873]    Loss: 0.001733   Batch Acc: 92.19
[Train] Epoch: 1 [194560/387873]    Loss: 0.001974   Batch Acc: 89.84
[Train] Epoch: 1 [194688/387873]    Loss: 0.002838   Batch Acc: 82.03
[Train] Epoch: 1 [194816/387873]    Loss: 0.001893   Batch Acc: 89.06
[Train] Epoch: 1 [194944/387873]    Loss: 0.001938   Batch Acc: 92.19
[Train] Epoch: 1 [195072/387873]    Loss: 0.002600   Batch Acc: 86.72
[Train] Epoch: 1 [195200/387873]    Loss: 0.002225   Batch Acc: 88.28
[Train] Epoch: 1 [195328/387873]    Loss: 0.002587   Batch Acc: 83.59
[Train] Epoch: 1 [195456/387873]    Loss: 0.002462   Batch Acc: 85.94
[Train] Epoch: 1 [195584/387873]    Loss: 0.002081   Batch Acc: 89.84
[Train] Epoch: 1 [195712/387873]    Loss: 0.001887   Batch Acc: 92.19
[Train] Epoch: 1 [195840/387873]    Loss: 0.002017   Batch Acc: 89.84
[Train] Epoch: 1 [195968/387873]    Loss: 0.002056   Batch Acc: 89.06
[Train] Epoch: 1 [196096/387873]    Loss: 0.002475   Batch Acc: 87.50
[Train] Epoch: 1 [196224/387873]    Loss: 0.001851   Batch Acc: 89.84
[Train] Epoch: 1 [196352/387873]    Loss: 0.001942   Batch Acc: 91.41
[Train] Epoch: 1 [196480/387873]    Loss: 0.002682   Batch Acc: 85.16
[Train] Epoch: 1 [196608/387873]    Loss: 0.002046   Batch Acc: 89.06
[Train] Epoch: 1 [196736/387873]    Loss: 0.002471   Batch Acc: 88.28
[Train] Epoch: 1 [196864/387873]    Loss: 0.002083   Batch Acc: 89.84
[Train] Epoch: 1 [196992/387873]    Loss: 0.001625   Batch Acc: 92.19
[Train] Epoch: 1 [197120/387873]    Loss: 0.001945   Batch Acc: 92.19
[Train] Epoch: 1 [197248/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 1 [197376/387873]    Loss: 0.002200   Batch Acc: 87.50
[Train] Epoch: 1 [197504/387873]    Loss: 0.002252   Batch Acc: 88.28
[Train] Epoch: 1 [197632/387873]    Loss: 0.002192   Batch Acc: 89.06
[Train] Epoch: 1 [197760/387873]    Loss: 0.001958   Batch Acc: 94.53
[Train] Epoch: 1 [197888/387873]    Loss: 0.001964   Batch Acc: 91.41
[Train] Epoch: 1 [198016/387873]    Loss: 0.002428   Batch Acc: 89.84
[Train] Epoch: 1 [198144/387873]    Loss: 0.002046   Batch Acc: 88.28
[Train] Epoch: 1 [198272/387873]    Loss: 0.002449   Batch Acc: 86.72
[Train] Epoch: 1 [198400/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 1 [198528/387873]    Loss: 0.001851   Batch Acc: 89.84
[Train] Epoch: 1 [198656/387873]    Loss: 0.001783   Batch Acc: 92.19
[Train] Epoch: 1 [198784/387873]    Loss: 0.002183   Batch Acc: 89.06
[Train] Epoch: 1 [198912/387873]    Loss: 0.002064   Batch Acc: 89.06
[Train] Epoch: 1 [199040/387873]    Loss: 0.002178   Batch Acc: 90.62
[Train] Epoch: 1 [199168/387873]    Loss: 0.001750   Batch Acc: 89.06
[Train] Epoch: 1 [199296/387873]    Loss: 0.001979   Batch Acc: 91.41
[Train] Epoch: 1 [199424/387873]    Loss: 0.002110   Batch Acc: 91.41
[Train] Epoch: 1 [199552/387873]    Loss: 0.002291   Batch Acc: 88.28
[Train] Epoch: 1 [199680/387873]    Loss: 0.002069   Batch Acc: 86.72
[Train] Epoch: 1 [199808/387873]    Loss: 0.002081   Batch Acc: 85.94
[Train] Epoch: 1 [199936/387873]    Loss: 0.002503   Batch Acc: 84.38
[Train] Epoch: 1 [200064/387873]    Loss: 0.001939   Batch Acc: 87.50
[Train] Epoch: 1 [200192/387873]    Loss: 0.002101   Batch Acc: 85.16
[Train] Epoch: 1 [200320/387873]    Loss: 0.002427   Batch Acc: 85.16
[Train] Epoch: 1 [200448/387873]    Loss: 0.001780   Batch Acc: 88.28
[Train] Epoch: 1 [200576/387873]    Loss: 0.002178   Batch Acc: 85.16
[Train] Epoch: 1 [200704/387873]    Loss: 0.002283   Batch Acc: 87.50
[Train] Epoch: 1 [200832/387873]    Loss: 0.003249   Batch Acc: 82.03
[Train] Epoch: 1 [200960/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 1 [201088/387873]    Loss: 0.002133   Batch Acc: 88.28
[Train] Epoch: 1 [201216/387873]    Loss: 0.001915   Batch Acc: 89.84
[Train] Epoch: 1 [201344/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 1 [201472/387873]    Loss: 0.002236   Batch Acc: 89.84
[Train] Epoch: 1 [201600/387873]    Loss: 0.001524   Batch Acc: 96.09
[Train] Epoch: 1 [201728/387873]    Loss: 0.002257   Batch Acc: 88.28
[Train] Epoch: 1 [201856/387873]    Loss: 0.001945   Batch Acc: 87.50
[Train] Epoch: 1 [201984/387873]    Loss: 0.002074   Batch Acc: 89.84
[Train] Epoch: 1 [202112/387873]    Loss: 0.002328   Batch Acc: 88.28
[Train] Epoch: 1 [202240/387873]    Loss: 0.001990   Batch Acc: 91.41
[Train] Epoch: 1 [202368/387873]    Loss: 0.001309   Batch Acc: 96.09
[Train] Epoch: 1 [202496/387873]    Loss: 0.002004   Batch Acc: 89.06
[Train] Epoch: 1 [202624/387873]    Loss: 0.001680   Batch Acc: 91.41
[Train] Epoch: 1 [202752/387873]    Loss: 0.002343   Batch Acc: 87.50
[Train] Epoch: 1 [202880/387873]    Loss: 0.002193   Batch Acc: 91.41
[Train] Epoch: 1 [203008/387873]    Loss: 0.001929   Batch Acc: 85.16
[Train] Epoch: 1 [203136/387873]    Loss: 0.001986   Batch Acc: 87.50
[Train] Epoch: 1 [203264/387873]    Loss: 0.002064   Batch Acc: 91.41
[Train] Epoch: 1 [203392/387873]    Loss: 0.001996   Batch Acc: 89.84
[Train] Epoch: 1 [203520/387873]    Loss: 0.002321   Batch Acc: 88.28
[Train] Epoch: 1 [203648/387873]    Loss: 0.002236   Batch Acc: 89.06
[Train] Epoch: 1 [203776/387873]    Loss: 0.001622   Batch Acc: 91.41
[Train] Epoch: 1 [203904/387873]    Loss: 0.002737   Batch Acc: 83.59
[Train] Epoch: 1 [204032/387873]    Loss: 0.002017   Batch Acc: 90.62
[Train] Epoch: 1 [204160/387873]    Loss: 0.002177   Batch Acc: 89.84
[Train] Epoch: 1 [204288/387873]    Loss: 0.001947   Batch Acc: 92.19
[Train] Epoch: 1 [204416/387873]    Loss: 0.002225   Batch Acc: 89.06
[Train] Epoch: 1 [204544/387873]    Loss: 0.002254   Batch Acc: 89.06
[Train] Epoch: 1 [204672/387873]    Loss: 0.002851   Batch Acc: 84.38
[Train] Epoch: 1 [204800/387873]    Loss: 0.001706   Batch Acc: 92.97
[Train] Epoch: 1 [204928/387873]    Loss: 0.001910   Batch Acc: 89.84
[Train] Epoch: 1 [205056/387873]    Loss: 0.002115   Batch Acc: 91.41
[Train] Epoch: 1 [205184/387873]    Loss: 0.002218   Batch Acc: 89.06
[Train] Epoch: 1 [205312/387873]    Loss: 0.002073   Batch Acc: 86.72
[Train] Epoch: 1 [205440/387873]    Loss: 0.002149   Batch Acc: 89.84
[Train] Epoch: 1 [205568/387873]    Loss: 0.002329   Batch Acc: 87.50
[Train] Epoch: 1 [205696/387873]    Loss: 0.002218   Batch Acc: 89.06
[Train] Epoch: 1 [205824/387873]    Loss: 0.002404   Batch Acc: 86.72
[Train] Epoch: 1 [205952/387873]    Loss: 0.002508   Batch Acc: 87.50
[Train] Epoch: 1 [206080/387873]    Loss: 0.001931   Batch Acc: 91.41
[Train] Epoch: 1 [206208/387873]    Loss: 0.001682   Batch Acc: 92.19
[Train] Epoch: 1 [206336/387873]    Loss: 0.002506   Batch Acc: 87.50
[Train] Epoch: 1 [206464/387873]    Loss: 0.002178   Batch Acc: 91.41
[Train] Epoch: 1 [206592/387873]    Loss: 0.002046   Batch Acc: 90.62
[Train] Epoch: 1 [206720/387873]    Loss: 0.002506   Batch Acc: 86.72
[Train] Epoch: 1 [206848/387873]    Loss: 0.002804   Batch Acc: 86.72
[Train] Epoch: 1 [206976/387873]    Loss: 0.001984   Batch Acc: 86.72
[Train] Epoch: 1 [207104/387873]    Loss: 0.002673   Batch Acc: 82.03
[Train] Epoch: 1 [207232/387873]    Loss: 0.002226   Batch Acc: 89.84
[Train] Epoch: 1 [207360/387873]    Loss: 0.001547   Batch Acc: 92.97
[Train] Epoch: 1 [207488/387873]    Loss: 0.002004   Batch Acc: 89.06
[Train] Epoch: 1 [207616/387873]    Loss: 0.002197   Batch Acc: 85.94
[Train] Epoch: 1 [207744/387873]    Loss: 0.001748   Batch Acc: 93.75
[Train] Epoch: 1 [207872/387873]    Loss: 0.002967   Batch Acc: 83.59
[Train] Epoch: 1 [208000/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 1 [208128/387873]    Loss: 0.002055   Batch Acc: 90.62
[Train] Epoch: 1 [208256/387873]    Loss: 0.002120   Batch Acc: 87.50
[Train] Epoch: 1 [208384/387873]    Loss: 0.001581   Batch Acc: 92.19
[Train] Epoch: 1 [208512/387873]    Loss: 0.001814   Batch Acc: 90.62
[Train] Epoch: 1 [208640/387873]    Loss: 0.001742   Batch Acc: 89.84
[Train] Epoch: 1 [208768/387873]    Loss: 0.002247   Batch Acc: 88.28
[Train] Epoch: 1 [208896/387873]    Loss: 0.001905   Batch Acc: 88.28
[Train] Epoch: 1 [209024/387873]    Loss: 0.002140   Batch Acc: 90.62
[Train] Epoch: 1 [209152/387873]    Loss: 0.001848   Batch Acc: 92.97
[Train] Epoch: 1 [209280/387873]    Loss: 0.002549   Batch Acc: 88.28
[Train] Epoch: 1 [209408/387873]    Loss: 0.002182   Batch Acc: 85.94
[Train] Epoch: 1 [209536/387873]    Loss: 0.002085   Batch Acc: 88.28
[Train] Epoch: 1 [209664/387873]    Loss: 0.002507   Batch Acc: 85.94
[Train] Epoch: 1 [209792/387873]    Loss: 0.002012   Batch Acc: 89.06
[Train] Epoch: 1 [209920/387873]    Loss: 0.001828   Batch Acc: 90.62
[Train] Epoch: 1 [210048/387873]    Loss: 0.001776   Batch Acc: 89.84
[Train] Epoch: 1 [210176/387873]    Loss: 0.002392   Batch Acc: 87.50
[Train] Epoch: 1 [210304/387873]    Loss: 0.002181   Batch Acc: 89.06
[Train] Epoch: 1 [210432/387873]    Loss: 0.002283   Batch Acc: 85.16
[Train] Epoch: 1 [210560/387873]    Loss: 0.001722   Batch Acc: 89.84
[Train] Epoch: 1 [210688/387873]    Loss: 0.001756   Batch Acc: 92.19
[Train] Epoch: 1 [210816/387873]    Loss: 0.001985   Batch Acc: 90.62
[Train] Epoch: 1 [210944/387873]    Loss: 0.002400   Batch Acc: 88.28
[Train] Epoch: 1 [211072/387873]    Loss: 0.002243   Batch Acc: 89.06
[Train] Epoch: 1 [211200/387873]    Loss: 0.002655   Batch Acc: 85.94
[Train] Epoch: 1 [211328/387873]    Loss: 0.001781   Batch Acc: 88.28
[Train] Epoch: 1 [211456/387873]    Loss: 0.002117   Batch Acc: 86.72
[Train] Epoch: 1 [211584/387873]    Loss: 0.002213   Batch Acc: 89.84
[Train] Epoch: 1 [211712/387873]    Loss: 0.001757   Batch Acc: 91.41
[Train] Epoch: 1 [211840/387873]    Loss: 0.002263   Batch Acc: 89.06
[Train] Epoch: 1 [211968/387873]    Loss: 0.002344   Batch Acc: 88.28
[Train] Epoch: 1 [212096/387873]    Loss: 0.002306   Batch Acc: 87.50
[Train] Epoch: 1 [212224/387873]    Loss: 0.001836   Batch Acc: 90.62
[Train] Epoch: 1 [212352/387873]    Loss: 0.002644   Batch Acc: 85.94
[Train] Epoch: 1 [212480/387873]    Loss: 0.002103   Batch Acc: 87.50
[Train] Epoch: 1 [212608/387873]    Loss: 0.001854   Batch Acc: 92.97
[Train] Epoch: 1 [212736/387873]    Loss: 0.001749   Batch Acc: 91.41
[Train] Epoch: 1 [212864/387873]    Loss: 0.002545   Batch Acc: 86.72
[Train] Epoch: 1 [212992/387873]    Loss: 0.001999   Batch Acc: 91.41
[Train] Epoch: 1 [213120/387873]    Loss: 0.002054   Batch Acc: 90.62
[Train] Epoch: 1 [213248/387873]    Loss: 0.002322   Batch Acc: 87.50
[Train] Epoch: 1 [213376/387873]    Loss: 0.002401   Batch Acc: 86.72
[Train] Epoch: 1 [213504/387873]    Loss: 0.002668   Batch Acc: 82.03
[Train] Epoch: 1 [213632/387873]    Loss: 0.002292   Batch Acc: 85.94
[Train] Epoch: 1 [213760/387873]    Loss: 0.001791   Batch Acc: 92.97
[Train] Epoch: 1 [213888/387873]    Loss: 0.001815   Batch Acc: 91.41
[Train] Epoch: 1 [214016/387873]    Loss: 0.002010   Batch Acc: 86.72
[Train] Epoch: 1 [214144/387873]    Loss: 0.001730   Batch Acc: 92.19
[Train] Epoch: 1 [214272/387873]    Loss: 0.002176   Batch Acc: 87.50
[Train] Epoch: 1 [214400/387873]    Loss: 0.001988   Batch Acc: 87.50
[Train] Epoch: 1 [214528/387873]    Loss: 0.002051   Batch Acc: 89.06
[Train] Epoch: 1 [214656/387873]    Loss: 0.002460   Batch Acc: 88.28
[Train] Epoch: 1 [214784/387873]    Loss: 0.002437   Batch Acc: 83.59
[Train] Epoch: 1 [214912/387873]    Loss: 0.001739   Batch Acc: 92.19
[Train] Epoch: 1 [215040/387873]    Loss: 0.001943   Batch Acc: 92.97
[Train] Epoch: 1 [215168/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 1 [215296/387873]    Loss: 0.002034   Batch Acc: 88.28
[Train] Epoch: 1 [215424/387873]    Loss: 0.002272   Batch Acc: 90.62
[Train] Epoch: 1 [215552/387873]    Loss: 0.002595   Batch Acc: 84.38
[Train] Epoch: 1 [215680/387873]    Loss: 0.002702   Batch Acc: 85.94
[Train] Epoch: 1 [215808/387873]    Loss: 0.002153   Batch Acc: 88.28
[Train] Epoch: 1 [215936/387873]    Loss: 0.002208   Batch Acc: 88.28
[Train] Epoch: 1 [216064/387873]    Loss: 0.001865   Batch Acc: 89.06
[Train] Epoch: 1 [216192/387873]    Loss: 0.001934   Batch Acc: 92.19
[Train] Epoch: 1 [216320/387873]    Loss: 0.001906   Batch Acc: 90.62
[Train] Epoch: 1 [216448/387873]    Loss: 0.001926   Batch Acc: 91.41
[Train] Epoch: 1 [216576/387873]    Loss: 0.001981   Batch Acc: 90.62
[Train] Epoch: 1 [216704/387873]    Loss: 0.002183   Batch Acc: 86.72
[Train] Epoch: 1 [216832/387873]    Loss: 0.002306   Batch Acc: 89.06
[Train] Epoch: 1 [216960/387873]    Loss: 0.002099   Batch Acc: 88.28
[Train] Epoch: 1 [217088/387873]    Loss: 0.002002   Batch Acc: 88.28
[Train] Epoch: 1 [217216/387873]    Loss: 0.001713   Batch Acc: 92.19
[Train] Epoch: 1 [217344/387873]    Loss: 0.001412   Batch Acc: 92.19
[Train] Epoch: 1 [217472/387873]    Loss: 0.002286   Batch Acc: 85.94
[Train] Epoch: 1 [217600/387873]    Loss: 0.002146   Batch Acc: 89.06
[Train] Epoch: 1 [217728/387873]    Loss: 0.001844   Batch Acc: 90.62
[Train] Epoch: 1 [217856/387873]    Loss: 0.001877   Batch Acc: 90.62
[Train] Epoch: 1 [217984/387873]    Loss: 0.002696   Batch Acc: 87.50
[Train] Epoch: 1 [218112/387873]    Loss: 0.002602   Batch Acc: 86.72
[Train] Epoch: 1 [218240/387873]    Loss: 0.002069   Batch Acc: 87.50
[Train] Epoch: 1 [218368/387873]    Loss: 0.002267   Batch Acc: 86.72
[Train] Epoch: 1 [218496/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 1 [218624/387873]    Loss: 0.002385   Batch Acc: 88.28
[Train] Epoch: 1 [218752/387873]    Loss: 0.002279   Batch Acc: 89.06
[Train] Epoch: 1 [218880/387873]    Loss: 0.001846   Batch Acc: 87.50
[Train] Epoch: 1 [219008/387873]    Loss: 0.002417   Batch Acc: 85.16
[Train] Epoch: 1 [219136/387873]    Loss: 0.001965   Batch Acc: 88.28
[Train] Epoch: 1 [219264/387873]    Loss: 0.002130   Batch Acc: 85.94
[Train] Epoch: 1 [219392/387873]    Loss: 0.001900   Batch Acc: 89.84
[Train] Epoch: 1 [219520/387873]    Loss: 0.002275   Batch Acc: 89.06
[Train] Epoch: 1 [219648/387873]    Loss: 0.002105   Batch Acc: 87.50
[Train] Epoch: 1 [219776/387873]    Loss: 0.002297   Batch Acc: 88.28
[Train] Epoch: 1 [219904/387873]    Loss: 0.002445   Batch Acc: 87.50
[Train] Epoch: 1 [220032/387873]    Loss: 0.001986   Batch Acc: 88.28
[Train] Epoch: 1 [220160/387873]    Loss: 0.002114   Batch Acc: 89.06
[Train] Epoch: 1 [220288/387873]    Loss: 0.001538   Batch Acc: 94.53
[Train] Epoch: 1 [220416/387873]    Loss: 0.002159   Batch Acc: 87.50
[Train] Epoch: 1 [220544/387873]    Loss: 0.002272   Batch Acc: 86.72
[Train] Epoch: 1 [220672/387873]    Loss: 0.001640   Batch Acc: 92.19
[Train] Epoch: 1 [220800/387873]    Loss: 0.002688   Batch Acc: 78.91
[Train] Epoch: 1 [220928/387873]    Loss: 0.002210   Batch Acc: 89.06
[Train] Epoch: 1 [221056/387873]    Loss: 0.001674   Batch Acc: 90.62
[Train] Epoch: 1 [221184/387873]    Loss: 0.001752   Batch Acc: 94.53
[Train] Epoch: 1 [221312/387873]    Loss: 0.002286   Batch Acc: 85.16
[Train] Epoch: 1 [221440/387873]    Loss: 0.002033   Batch Acc: 89.06
[Train] Epoch: 1 [221568/387873]    Loss: 0.002146   Batch Acc: 89.84
[Train] Epoch: 1 [221696/387873]    Loss: 0.002537   Batch Acc: 85.16
[Train] Epoch: 1 [221824/387873]    Loss: 0.002597   Batch Acc: 87.50
[Train] Epoch: 1 [221952/387873]    Loss: 0.002072   Batch Acc: 88.28
[Train] Epoch: 1 [222080/387873]    Loss: 0.002195   Batch Acc: 89.84
[Train] Epoch: 1 [222208/387873]    Loss: 0.002427   Batch Acc: 86.72
[Train] Epoch: 1 [222336/387873]    Loss: 0.002158   Batch Acc: 87.50
[Train] Epoch: 1 [222464/387873]    Loss: 0.002469   Batch Acc: 87.50
[Train] Epoch: 1 [222592/387873]    Loss: 0.001962   Batch Acc: 88.28
[Train] Epoch: 1 [222720/387873]    Loss: 0.002451   Batch Acc: 85.16
[Train] Epoch: 1 [222848/387873]    Loss: 0.002609   Batch Acc: 85.94
[Train] Epoch: 1 [222976/387873]    Loss: 0.001815   Batch Acc: 87.50
[Train] Epoch: 1 [223104/387873]    Loss: 0.001943   Batch Acc: 89.84
[Train] Epoch: 1 [223232/387873]    Loss: 0.002340   Batch Acc: 85.16
[Train] Epoch: 1 [223360/387873]    Loss: 0.001913   Batch Acc: 91.41
[Train] Epoch: 1 [223488/387873]    Loss: 0.002140   Batch Acc: 86.72
[Train] Epoch: 1 [223616/387873]    Loss: 0.001771   Batch Acc: 92.97
[Train] Epoch: 1 [223744/387873]    Loss: 0.002053   Batch Acc: 89.06
[Train] Epoch: 1 [223872/387873]    Loss: 0.002755   Batch Acc: 85.16
[Train] Epoch: 1 [224000/387873]    Loss: 0.002091   Batch Acc: 88.28
[Train] Epoch: 1 [224128/387873]    Loss: 0.001911   Batch Acc: 89.06
[Train] Epoch: 1 [224256/387873]    Loss: 0.001819   Batch Acc: 89.84
[Train] Epoch: 1 [224384/387873]    Loss: 0.002053   Batch Acc: 91.41
[Train] Epoch: 1 [224512/387873]    Loss: 0.002036   Batch Acc: 89.06
[Train] Epoch: 1 [224640/387873]    Loss: 0.002050   Batch Acc: 89.84
[Train] Epoch: 1 [224768/387873]    Loss: 0.001822   Batch Acc: 89.84
[Train] Epoch: 1 [224896/387873]    Loss: 0.001831   Batch Acc: 90.62
[Train] Epoch: 1 [225024/387873]    Loss: 0.002786   Batch Acc: 85.16
[Train] Epoch: 1 [225152/387873]    Loss: 0.001653   Batch Acc: 93.75
[Train] Epoch: 1 [225280/387873]    Loss: 0.001913   Batch Acc: 92.19
[Train] Epoch: 1 [225408/387873]    Loss: 0.002094   Batch Acc: 91.41
[Train] Epoch: 1 [225536/387873]    Loss: 0.001669   Batch Acc: 93.75
[Train] Epoch: 1 [225664/387873]    Loss: 0.001932   Batch Acc: 89.06
[Train] Epoch: 1 [225792/387873]    Loss: 0.002220   Batch Acc: 85.94
[Train] Epoch: 1 [225920/387873]    Loss: 0.002356   Batch Acc: 92.19
[Train] Epoch: 1 [226048/387873]    Loss: 0.001735   Batch Acc: 92.97
[Train] Epoch: 1 [226176/387873]    Loss: 0.001698   Batch Acc: 92.19
[Train] Epoch: 1 [226304/387873]    Loss: 0.002917   Batch Acc: 85.16
[Train] Epoch: 1 [226432/387873]    Loss: 0.002777   Batch Acc: 85.16
[Train] Epoch: 1 [226560/387873]    Loss: 0.002282   Batch Acc: 85.94
[Train] Epoch: 1 [226688/387873]    Loss: 0.001899   Batch Acc: 91.41
[Train] Epoch: 1 [226816/387873]    Loss: 0.002328   Batch Acc: 87.50
[Train] Epoch: 1 [226944/387873]    Loss: 0.002373   Batch Acc: 86.72
[Train] Epoch: 1 [227072/387873]    Loss: 0.002339   Batch Acc: 84.38
[Train] Epoch: 1 [227200/387873]    Loss: 0.001656   Batch Acc: 94.53
[Train] Epoch: 1 [227328/387873]    Loss: 0.002476   Batch Acc: 84.38
[Train] Epoch: 1 [227456/387873]    Loss: 0.001791   Batch Acc: 91.41
[Train] Epoch: 1 [227584/387873]    Loss: 0.001769   Batch Acc: 91.41
[Train] Epoch: 1 [227712/387873]    Loss: 0.002124   Batch Acc: 86.72
[Train] Epoch: 1 [227840/387873]    Loss: 0.001686   Batch Acc: 92.97
[Train] Epoch: 1 [227968/387873]    Loss: 0.002304   Batch Acc: 90.62
[Train] Epoch: 1 [228096/387873]    Loss: 0.002076   Batch Acc: 90.62
[Train] Epoch: 1 [228224/387873]    Loss: 0.001782   Batch Acc: 90.62
[Train] Epoch: 1 [228352/387873]    Loss: 0.002613   Batch Acc: 84.38
[Train] Epoch: 1 [228480/387873]    Loss: 0.002319   Batch Acc: 84.38
[Train] Epoch: 1 [228608/387873]    Loss: 0.001852   Batch Acc: 90.62
[Train] Epoch: 1 [228736/387873]    Loss: 0.001894   Batch Acc: 94.53
[Train] Epoch: 1 [228864/387873]    Loss: 0.002651   Batch Acc: 85.94
[Train] Epoch: 1 [228992/387873]    Loss: 0.001895   Batch Acc: 88.28
[Train] Epoch: 1 [229120/387873]    Loss: 0.002193   Batch Acc: 86.72
[Train] Epoch: 1 [229248/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 1 [229376/387873]    Loss: 0.002625   Batch Acc: 88.28
[Train] Epoch: 1 [229504/387873]    Loss: 0.002515   Batch Acc: 85.16
[Train] Epoch: 1 [229632/387873]    Loss: 0.002125   Batch Acc: 89.06
[Train] Epoch: 1 [229760/387873]    Loss: 0.002153   Batch Acc: 86.72
[Train] Epoch: 1 [229888/387873]    Loss: 0.001932   Batch Acc: 87.50
[Train] Epoch: 1 [230016/387873]    Loss: 0.001308   Batch Acc: 95.31
[Train] Epoch: 1 [230144/387873]    Loss: 0.001667   Batch Acc: 89.06
[Train] Epoch: 1 [230272/387873]    Loss: 0.002072   Batch Acc: 89.84
[Train] Epoch: 1 [230400/387873]    Loss: 0.001971   Batch Acc: 90.62
[Train] Epoch: 1 [230528/387873]    Loss: 0.001981   Batch Acc: 89.06
[Train] Epoch: 1 [230656/387873]    Loss: 0.001677   Batch Acc: 90.62
[Train] Epoch: 1 [230784/387873]    Loss: 0.002261   Batch Acc: 87.50
[Train] Epoch: 1 [230912/387873]    Loss: 0.001814   Batch Acc: 90.62
[Train] Epoch: 1 [231040/387873]    Loss: 0.002246   Batch Acc: 87.50
[Train] Epoch: 1 [231168/387873]    Loss: 0.001967   Batch Acc: 89.84
[Train] Epoch: 1 [231296/387873]    Loss: 0.001900   Batch Acc: 89.84
[Train] Epoch: 1 [231424/387873]    Loss: 0.001828   Batch Acc: 91.41
[Train] Epoch: 1 [231552/387873]    Loss: 0.002160   Batch Acc: 87.50
[Train] Epoch: 1 [231680/387873]    Loss: 0.001759   Batch Acc: 89.84
[Train] Epoch: 1 [231808/387873]    Loss: 0.003137   Batch Acc: 82.03
[Train] Epoch: 1 [231936/387873]    Loss: 0.002256   Batch Acc: 88.28
[Train] Epoch: 1 [232064/387873]    Loss: 0.001608   Batch Acc: 90.62
[Train] Epoch: 1 [232192/387873]    Loss: 0.002622   Batch Acc: 82.03
[Train] Epoch: 1 [232320/387873]    Loss: 0.002097   Batch Acc: 85.16
[Train] Epoch: 1 [232448/387873]    Loss: 0.002839   Batch Acc: 82.81
[Train] Epoch: 1 [232576/387873]    Loss: 0.002604   Batch Acc: 84.38
[Train] Epoch: 1 [232704/387873]    Loss: 0.002177   Batch Acc: 89.06
[Train] Epoch: 1 [232832/387873]    Loss: 0.001933   Batch Acc: 90.62
[Train] Epoch: 1 [232960/387873]    Loss: 0.002147   Batch Acc: 90.62
[Train] Epoch: 1 [233088/387873]    Loss: 0.002187   Batch Acc: 89.84
[Train] Epoch: 1 [233216/387873]    Loss: 0.001902   Batch Acc: 89.06
[Train] Epoch: 1 [233344/387873]    Loss: 0.002022   Batch Acc: 87.50
[Train] Epoch: 1 [233472/387873]    Loss: 0.002206   Batch Acc: 90.62
[Train] Epoch: 1 [233600/387873]    Loss: 0.002062   Batch Acc: 92.19
[Train] Epoch: 1 [233728/387873]    Loss: 0.002233   Batch Acc: 86.72
[Train] Epoch: 1 [233856/387873]    Loss: 0.002105   Batch Acc: 88.28
[Train] Epoch: 1 [233984/387873]    Loss: 0.002435   Batch Acc: 85.16
[Train] Epoch: 1 [234112/387873]    Loss: 0.001793   Batch Acc: 92.19
[Train] Epoch: 1 [234240/387873]    Loss: 0.002281   Batch Acc: 84.38
[Train] Epoch: 1 [234368/387873]    Loss: 0.002022   Batch Acc: 87.50
[Train] Epoch: 1 [234496/387873]    Loss: 0.002003   Batch Acc: 87.50
[Train] Epoch: 1 [234624/387873]    Loss: 0.002169   Batch Acc: 89.84
[Train] Epoch: 1 [234752/387873]    Loss: 0.002290   Batch Acc: 88.28
[Train] Epoch: 1 [234880/387873]    Loss: 0.002524   Batch Acc: 82.03
[Train] Epoch: 1 [235008/387873]    Loss: 0.001696   Batch Acc: 91.41
[Train] Epoch: 1 [235136/387873]    Loss: 0.001887   Batch Acc: 90.62
[Train] Epoch: 1 [235264/387873]    Loss: 0.002399   Batch Acc: 86.72
[Train] Epoch: 1 [235392/387873]    Loss: 0.001900   Batch Acc: 92.97
[Train] Epoch: 1 [235520/387873]    Loss: 0.001406   Batch Acc: 95.31
[Train] Epoch: 1 [235648/387873]    Loss: 0.002287   Batch Acc: 85.16
[Train] Epoch: 1 [235776/387873]    Loss: 0.001913   Batch Acc: 89.84
[Train] Epoch: 1 [235904/387873]    Loss: 0.002147   Batch Acc: 85.94
[Train] Epoch: 1 [236032/387873]    Loss: 0.002023   Batch Acc: 92.19
[Train] Epoch: 1 [236160/387873]    Loss: 0.002225   Batch Acc: 86.72
[Train] Epoch: 1 [236288/387873]    Loss: 0.001642   Batch Acc: 94.53
[Train] Epoch: 1 [236416/387873]    Loss: 0.002421   Batch Acc: 87.50
[Train] Epoch: 1 [236544/387873]    Loss: 0.002786   Batch Acc: 87.50
[Train] Epoch: 1 [236672/387873]    Loss: 0.001584   Batch Acc: 91.41
[Train] Epoch: 1 [236800/387873]    Loss: 0.002426   Batch Acc: 87.50
[Train] Epoch: 1 [236928/387873]    Loss: 0.001841   Batch Acc: 92.19
[Train] Epoch: 1 [237056/387873]    Loss: 0.001978   Batch Acc: 91.41
[Train] Epoch: 1 [237184/387873]    Loss: 0.002329   Batch Acc: 86.72
[Train] Epoch: 1 [237312/387873]    Loss: 0.002163   Batch Acc: 87.50
[Train] Epoch: 1 [237440/387873]    Loss: 0.002111   Batch Acc: 86.72
[Train] Epoch: 1 [237568/387873]    Loss: 0.002014   Batch Acc: 89.06
[Train] Epoch: 1 [237696/387873]    Loss: 0.001909   Batch Acc: 89.84
[Train] Epoch: 1 [237824/387873]    Loss: 0.002297   Batch Acc: 85.16
[Train] Epoch: 1 [237952/387873]    Loss: 0.001804   Batch Acc: 89.84
[Train] Epoch: 1 [238080/387873]    Loss: 0.002424   Batch Acc: 85.94
[Train] Epoch: 1 [238208/387873]    Loss: 0.002329   Batch Acc: 89.84
[Train] Epoch: 1 [238336/387873]    Loss: 0.002446   Batch Acc: 85.16
[Train] Epoch: 1 [238464/387873]    Loss: 0.001934   Batch Acc: 90.62
[Train] Epoch: 1 [238592/387873]    Loss: 0.001666   Batch Acc: 92.97
[Train] Epoch: 1 [238720/387873]    Loss: 0.001937   Batch Acc: 90.62
[Train] Epoch: 1 [238848/387873]    Loss: 0.002527   Batch Acc: 84.38
[Train] Epoch: 1 [238976/387873]    Loss: 0.002024   Batch Acc: 90.62
[Train] Epoch: 1 [239104/387873]    Loss: 0.002053   Batch Acc: 90.62
[Train] Epoch: 1 [239232/387873]    Loss: 0.001678   Batch Acc: 91.41
[Train] Epoch: 1 [239360/387873]    Loss: 0.001933   Batch Acc: 89.84
[Train] Epoch: 1 [239488/387873]    Loss: 0.002113   Batch Acc: 86.72
[Train] Epoch: 1 [239616/387873]    Loss: 0.001746   Batch Acc: 89.84
[Train] Epoch: 1 [239744/387873]    Loss: 0.002329   Batch Acc: 88.28
[Train] Epoch: 1 [239872/387873]    Loss: 0.001836   Batch Acc: 89.84
[Train] Epoch: 1 [240000/387873]    Loss: 0.002025   Batch Acc: 89.84
[Train] Epoch: 1 [240128/387873]    Loss: 0.002235   Batch Acc: 85.94
[Train] Epoch: 1 [240256/387873]    Loss: 0.002407   Batch Acc: 85.94
[Train] Epoch: 1 [240384/387873]    Loss: 0.001640   Batch Acc: 95.31
[Train] Epoch: 1 [240512/387873]    Loss: 0.001745   Batch Acc: 92.97
[Train] Epoch: 1 [240640/387873]    Loss: 0.002178   Batch Acc: 89.84
[Train] Epoch: 1 [240768/387873]    Loss: 0.002381   Batch Acc: 86.72
[Train] Epoch: 1 [240896/387873]    Loss: 0.002823   Batch Acc: 83.59
[Train] Epoch: 1 [241024/387873]    Loss: 0.002206   Batch Acc: 90.62
[Train] Epoch: 1 [241152/387873]    Loss: 0.002056   Batch Acc: 89.06
[Train] Epoch: 1 [241280/387873]    Loss: 0.001883   Batch Acc: 91.41
[Train] Epoch: 1 [241408/387873]    Loss: 0.002117   Batch Acc: 88.28
[Train] Epoch: 1 [241536/387873]    Loss: 0.001873   Batch Acc: 89.84
[Train] Epoch: 1 [241664/387873]    Loss: 0.001835   Batch Acc: 91.41
[Train] Epoch: 1 [241792/387873]    Loss: 0.002393   Batch Acc: 89.06
[Train] Epoch: 1 [241920/387873]    Loss: 0.001935   Batch Acc: 89.84
[Train] Epoch: 1 [242048/387873]    Loss: 0.002698   Batch Acc: 85.16
[Train] Epoch: 1 [242176/387873]    Loss: 0.001927   Batch Acc: 90.62
[Train] Epoch: 1 [242304/387873]    Loss: 0.001828   Batch Acc: 89.84
[Train] Epoch: 1 [242432/387873]    Loss: 0.001794   Batch Acc: 90.62
[Train] Epoch: 1 [242560/387873]    Loss: 0.001871   Batch Acc: 88.28
[Train] Epoch: 1 [242688/387873]    Loss: 0.002575   Batch Acc: 86.72
[Train] Epoch: 1 [242816/387873]    Loss: 0.002072   Batch Acc: 87.50
[Train] Epoch: 1 [242944/387873]    Loss: 0.002142   Batch Acc: 89.06
[Train] Epoch: 1 [243072/387873]    Loss: 0.002422   Batch Acc: 88.28
[Train] Epoch: 1 [243200/387873]    Loss: 0.001876   Batch Acc: 89.84
[Train] Epoch: 1 [243328/387873]    Loss: 0.001682   Batch Acc: 92.19
[Train] Epoch: 1 [243456/387873]    Loss: 0.002003   Batch Acc: 88.28
[Train] Epoch: 1 [243584/387873]    Loss: 0.001410   Batch Acc: 92.97
[Train] Epoch: 1 [243712/387873]    Loss: 0.001973   Batch Acc: 91.41
[Train] Epoch: 1 [243840/387873]    Loss: 0.002126   Batch Acc: 87.50
[Train] Epoch: 1 [243968/387873]    Loss: 0.002306   Batch Acc: 89.06
[Train] Epoch: 1 [244096/387873]    Loss: 0.002127   Batch Acc: 88.28
[Train] Epoch: 1 [244224/387873]    Loss: 0.001901   Batch Acc: 90.62
[Train] Epoch: 1 [244352/387873]    Loss: 0.002699   Batch Acc: 85.94
[Train] Epoch: 1 [244480/387873]    Loss: 0.002082   Batch Acc: 90.62
[Train] Epoch: 1 [244608/387873]    Loss: 0.001817   Batch Acc: 90.62
[Train] Epoch: 1 [244736/387873]    Loss: 0.001849   Batch Acc: 94.53
[Train] Epoch: 1 [244864/387873]    Loss: 0.002007   Batch Acc: 89.06
[Train] Epoch: 1 [244992/387873]    Loss: 0.001837   Batch Acc: 88.28
[Train] Epoch: 1 [245120/387873]    Loss: 0.002098   Batch Acc: 89.06
[Train] Epoch: 1 [245248/387873]    Loss: 0.001837   Batch Acc: 92.97
[Train] Epoch: 1 [245376/387873]    Loss: 0.001811   Batch Acc: 89.06
[Train] Epoch: 1 [245504/387873]    Loss: 0.002194   Batch Acc: 88.28
[Train] Epoch: 1 [245632/387873]    Loss: 0.002796   Batch Acc: 82.81
[Train] Epoch: 1 [245760/387873]    Loss: 0.001651   Batch Acc: 91.41
[Train] Epoch: 1 [245888/387873]    Loss: 0.002103   Batch Acc: 87.50
[Train] Epoch: 1 [246016/387873]    Loss: 0.001695   Batch Acc: 92.19
[Train] Epoch: 1 [246144/387873]    Loss: 0.002185   Batch Acc: 89.06
[Train] Epoch: 1 [246272/387873]    Loss: 0.002232   Batch Acc: 86.72
[Train] Epoch: 1 [246400/387873]    Loss: 0.001894   Batch Acc: 88.28
[Train] Epoch: 1 [246528/387873]    Loss: 0.001666   Batch Acc: 93.75
[Train] Epoch: 1 [246656/387873]    Loss: 0.002229   Batch Acc: 86.72
[Train] Epoch: 1 [246784/387873]    Loss: 0.002077   Batch Acc: 88.28
[Train] Epoch: 1 [246912/387873]    Loss: 0.002404   Batch Acc: 85.16
[Train] Epoch: 1 [247040/387873]    Loss: 0.002594   Batch Acc: 83.59
[Train] Epoch: 1 [247168/387873]    Loss: 0.001980   Batch Acc: 90.62
[Train] Epoch: 1 [247296/387873]    Loss: 0.002907   Batch Acc: 82.03
[Train] Epoch: 1 [247424/387873]    Loss: 0.001892   Batch Acc: 88.28
[Train] Epoch: 1 [247552/387873]    Loss: 0.002190   Batch Acc: 88.28
[Train] Epoch: 1 [247680/387873]    Loss: 0.001826   Batch Acc: 89.84
[Train] Epoch: 1 [247808/387873]    Loss: 0.001728   Batch Acc: 90.62
[Train] Epoch: 1 [247936/387873]    Loss: 0.002012   Batch Acc: 87.50
[Train] Epoch: 1 [248064/387873]    Loss: 0.002161   Batch Acc: 89.06
[Train] Epoch: 1 [248192/387873]    Loss: 0.001885   Batch Acc: 89.84
[Train] Epoch: 1 [248320/387873]    Loss: 0.001603   Batch Acc: 94.53
[Train] Epoch: 1 [248448/387873]    Loss: 0.002269   Batch Acc: 90.62
[Train] Epoch: 1 [248576/387873]    Loss: 0.001454   Batch Acc: 92.97
[Train] Epoch: 1 [248704/387873]    Loss: 0.002488   Batch Acc: 85.94
[Train] Epoch: 1 [248832/387873]    Loss: 0.001966   Batch Acc: 87.50
[Train] Epoch: 1 [248960/387873]    Loss: 0.002041   Batch Acc: 89.06
[Train] Epoch: 1 [249088/387873]    Loss: 0.002153   Batch Acc: 89.06
[Train] Epoch: 1 [249216/387873]    Loss: 0.001974   Batch Acc: 87.50
[Train] Epoch: 1 [249344/387873]    Loss: 0.001953   Batch Acc: 89.06
[Train] Epoch: 1 [249472/387873]    Loss: 0.001670   Batch Acc: 92.19
[Train] Epoch: 1 [249600/387873]    Loss: 0.002596   Batch Acc: 87.50
[Train] Epoch: 1 [249728/387873]    Loss: 0.001939   Batch Acc: 90.62
[Train] Epoch: 1 [249856/387873]    Loss: 0.001743   Batch Acc: 89.84
[Train] Epoch: 1 [249984/387873]    Loss: 0.001890   Batch Acc: 92.19
[Train] Epoch: 1 [250112/387873]    Loss: 0.002195   Batch Acc: 90.62
[Train] Epoch: 1 [250240/387873]    Loss: 0.002156   Batch Acc: 86.72
[Train] Epoch: 1 [250368/387873]    Loss: 0.002351   Batch Acc: 86.72
[Train] Epoch: 1 [250496/387873]    Loss: 0.002689   Batch Acc: 85.94
[Train] Epoch: 1 [250624/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 1 [250752/387873]    Loss: 0.002289   Batch Acc: 88.28
[Train] Epoch: 1 [250880/387873]    Loss: 0.002934   Batch Acc: 80.47
[Train] Epoch: 1 [251008/387873]    Loss: 0.002235   Batch Acc: 86.72
[Train] Epoch: 1 [251136/387873]    Loss: 0.002508   Batch Acc: 84.38
[Train] Epoch: 1 [251264/387873]    Loss: 0.001987   Batch Acc: 89.06
[Train] Epoch: 1 [251392/387873]    Loss: 0.002351   Batch Acc: 90.62
[Train] Epoch: 1 [251520/387873]    Loss: 0.002560   Batch Acc: 86.72
[Train] Epoch: 1 [251648/387873]    Loss: 0.001871   Batch Acc: 89.06
[Train] Epoch: 1 [251776/387873]    Loss: 0.002213   Batch Acc: 85.94
[Train] Epoch: 1 [251904/387873]    Loss: 0.001819   Batch Acc: 92.19
[Train] Epoch: 1 [252032/387873]    Loss: 0.001879   Batch Acc: 93.75
[Train] Epoch: 1 [252160/387873]    Loss: 0.003156   Batch Acc: 82.03
[Train] Epoch: 1 [252288/387873]    Loss: 0.002289   Batch Acc: 89.06
[Train] Epoch: 1 [252416/387873]    Loss: 0.002317   Batch Acc: 87.50
[Train] Epoch: 1 [252544/387873]    Loss: 0.002582   Batch Acc: 85.16
[Train] Epoch: 1 [252672/387873]    Loss: 0.002273   Batch Acc: 86.72
[Train] Epoch: 1 [252800/387873]    Loss: 0.002393   Batch Acc: 87.50
[Train] Epoch: 1 [252928/387873]    Loss: 0.002033   Batch Acc: 91.41
[Train] Epoch: 1 [253056/387873]    Loss: 0.002851   Batch Acc: 87.50
[Train] Epoch: 1 [253184/387873]    Loss: 0.002454   Batch Acc: 87.50
[Train] Epoch: 1 [253312/387873]    Loss: 0.002331   Batch Acc: 85.94
[Train] Epoch: 1 [253440/387873]    Loss: 0.001906   Batch Acc: 90.62
[Train] Epoch: 1 [253568/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 1 [253696/387873]    Loss: 0.002043   Batch Acc: 89.84
[Train] Epoch: 1 [253824/387873]    Loss: 0.001758   Batch Acc: 92.19
[Train] Epoch: 1 [253952/387873]    Loss: 0.001807   Batch Acc: 91.41
[Train] Epoch: 1 [254080/387873]    Loss: 0.002012   Batch Acc: 89.84
[Train] Epoch: 1 [254208/387873]    Loss: 0.002064   Batch Acc: 91.41
[Train] Epoch: 1 [254336/387873]    Loss: 0.001905   Batch Acc: 90.62
[Train] Epoch: 1 [254464/387873]    Loss: 0.002564   Batch Acc: 85.16
[Train] Epoch: 1 [254592/387873]    Loss: 0.002058   Batch Acc: 90.62
[Train] Epoch: 1 [254720/387873]    Loss: 0.002129   Batch Acc: 86.72
[Train] Epoch: 1 [254848/387873]    Loss: 0.001977   Batch Acc: 89.06
[Train] Epoch: 1 [254976/387873]    Loss: 0.002014   Batch Acc: 89.84
[Train] Epoch: 1 [255104/387873]    Loss: 0.002683   Batch Acc: 85.16
[Train] Epoch: 1 [255232/387873]    Loss: 0.002110   Batch Acc: 89.06
[Train] Epoch: 1 [255360/387873]    Loss: 0.001901   Batch Acc: 92.19
[Train] Epoch: 1 [255488/387873]    Loss: 0.002447   Batch Acc: 83.59
[Train] Epoch: 1 [255616/387873]    Loss: 0.002134   Batch Acc: 86.72
[Train] Epoch: 1 [255744/387873]    Loss: 0.001817   Batch Acc: 89.06
[Train] Epoch: 1 [255872/387873]    Loss: 0.001674   Batch Acc: 92.19
[Train] Epoch: 1 [256000/387873]    Loss: 0.001990   Batch Acc: 87.50
[Train] Epoch: 1 [256128/387873]    Loss: 0.002140   Batch Acc: 87.50
[Train] Epoch: 1 [256256/387873]    Loss: 0.001601   Batch Acc: 92.19
[Train] Epoch: 1 [256384/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 1 [256512/387873]    Loss: 0.001842   Batch Acc: 89.06
[Train] Epoch: 1 [256640/387873]    Loss: 0.002243   Batch Acc: 86.72
[Train] Epoch: 1 [256768/387873]    Loss: 0.002214   Batch Acc: 87.50
[Train] Epoch: 1 [256896/387873]    Loss: 0.001830   Batch Acc: 89.06
[Train] Epoch: 1 [257024/387873]    Loss: 0.002219   Batch Acc: 89.06
[Train] Epoch: 1 [257152/387873]    Loss: 0.002151   Batch Acc: 85.16
[Train] Epoch: 1 [257280/387873]    Loss: 0.001793   Batch Acc: 94.53
[Train] Epoch: 1 [257408/387873]    Loss: 0.002222   Batch Acc: 87.50
[Train] Epoch: 1 [257536/387873]    Loss: 0.002602   Batch Acc: 81.25
[Train] Epoch: 1 [257664/387873]    Loss: 0.001538   Batch Acc: 92.97
[Train] Epoch: 1 [257792/387873]    Loss: 0.002203   Batch Acc: 86.72
[Train] Epoch: 1 [257920/387873]    Loss: 0.001876   Batch Acc: 91.41
[Train] Epoch: 1 [258048/387873]    Loss: 0.002087   Batch Acc: 89.84
[Train] Epoch: 1 [258176/387873]    Loss: 0.002495   Batch Acc: 87.50
[Train] Epoch: 1 [258304/387873]    Loss: 0.002885   Batch Acc: 82.81
[Train] Epoch: 1 [258432/387873]    Loss: 0.002556   Batch Acc: 85.94
[Train] Epoch: 1 [258560/387873]    Loss: 0.001764   Batch Acc: 91.41
[Train] Epoch: 1 [258688/387873]    Loss: 0.002605   Batch Acc: 87.50
[Train] Epoch: 1 [258816/387873]    Loss: 0.002077   Batch Acc: 89.06
[Train] Epoch: 1 [258944/387873]    Loss: 0.002167   Batch Acc: 89.84
[Train] Epoch: 1 [259072/387873]    Loss: 0.002429   Batch Acc: 86.72
[Train] Epoch: 1 [259200/387873]    Loss: 0.002679   Batch Acc: 88.28
[Train] Epoch: 1 [259328/387873]    Loss: 0.002487   Batch Acc: 90.62
[Train] Epoch: 1 [259456/387873]    Loss: 0.002427   Batch Acc: 88.28
[Train] Epoch: 1 [259584/387873]    Loss: 0.001922   Batch Acc: 87.50
[Train] Epoch: 1 [259712/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 1 [259840/387873]    Loss: 0.002209   Batch Acc: 89.06
[Train] Epoch: 1 [259968/387873]    Loss: 0.001510   Batch Acc: 96.09
[Train] Epoch: 1 [260096/387873]    Loss: 0.002154   Batch Acc: 88.28
[Train] Epoch: 1 [260224/387873]    Loss: 0.001882   Batch Acc: 89.84
[Train] Epoch: 1 [260352/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 1 [260480/387873]    Loss: 0.002566   Batch Acc: 85.94
[Train] Epoch: 1 [260608/387873]    Loss: 0.001862   Batch Acc: 91.41
[Train] Epoch: 1 [260736/387873]    Loss: 0.002329   Batch Acc: 85.16
[Train] Epoch: 1 [260864/387873]    Loss: 0.002173   Batch Acc: 86.72
[Train] Epoch: 1 [260992/387873]    Loss: 0.001860   Batch Acc: 92.97
[Train] Epoch: 1 [261120/387873]    Loss: 0.002304   Batch Acc: 86.72
[Train] Epoch: 1 [261248/387873]    Loss: 0.002533   Batch Acc: 86.72
[Train] Epoch: 1 [261376/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 1 [261504/387873]    Loss: 0.001838   Batch Acc: 90.62
[Train] Epoch: 1 [261632/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 1 [261760/387873]    Loss: 0.002305   Batch Acc: 89.06
[Train] Epoch: 1 [261888/387873]    Loss: 0.001959   Batch Acc: 89.84
[Train] Epoch: 1 [262016/387873]    Loss: 0.002152   Batch Acc: 88.28
[Train] Epoch: 1 [262144/387873]    Loss: 0.002061   Batch Acc: 89.06
[Train] Epoch: 1 [262272/387873]    Loss: 0.001816   Batch Acc: 89.84
[Train] Epoch: 1 [262400/387873]    Loss: 0.001742   Batch Acc: 91.41
[Train] Epoch: 1 [262528/387873]    Loss: 0.002062   Batch Acc: 88.28
[Train] Epoch: 1 [262656/387873]    Loss: 0.002164   Batch Acc: 88.28
[Train] Epoch: 1 [262784/387873]    Loss: 0.002249   Batch Acc: 89.06
[Train] Epoch: 1 [262912/387873]    Loss: 0.002096   Batch Acc: 88.28
[Train] Epoch: 1 [263040/387873]    Loss: 0.002104   Batch Acc: 87.50
[Train] Epoch: 1 [263168/387873]    Loss: 0.002318   Batch Acc: 85.94
[Train] Epoch: 1 [263296/387873]    Loss: 0.002093   Batch Acc: 87.50
[Train] Epoch: 1 [263424/387873]    Loss: 0.002625   Batch Acc: 85.16
[Train] Epoch: 1 [263552/387873]    Loss: 0.002628   Batch Acc: 83.59
[Train] Epoch: 1 [263680/387873]    Loss: 0.001596   Batch Acc: 92.19
[Train] Epoch: 1 [263808/387873]    Loss: 0.001427   Batch Acc: 93.75
[Train] Epoch: 1 [263936/387873]    Loss: 0.001987   Batch Acc: 89.06
[Train] Epoch: 1 [264064/387873]    Loss: 0.001937   Batch Acc: 90.62
[Train] Epoch: 1 [264192/387873]    Loss: 0.001809   Batch Acc: 92.97
[Train] Epoch: 1 [264320/387873]    Loss: 0.002167   Batch Acc: 89.06
[Train] Epoch: 1 [264448/387873]    Loss: 0.002837   Batch Acc: 83.59
[Train] Epoch: 1 [264576/387873]    Loss: 0.002338   Batch Acc: 89.84
[Train] Epoch: 1 [264704/387873]    Loss: 0.002141   Batch Acc: 89.06
[Train] Epoch: 1 [264832/387873]    Loss: 0.001687   Batch Acc: 89.84
[Train] Epoch: 1 [264960/387873]    Loss: 0.002215   Batch Acc: 90.62
[Train] Epoch: 1 [265088/387873]    Loss: 0.001792   Batch Acc: 92.19
[Train] Epoch: 1 [265216/387873]    Loss: 0.002191   Batch Acc: 89.06
[Train] Epoch: 1 [265344/387873]    Loss: 0.001902   Batch Acc: 91.41
[Train] Epoch: 1 [265472/387873]    Loss: 0.002811   Batch Acc: 85.94
[Train] Epoch: 1 [265600/387873]    Loss: 0.001817   Batch Acc: 91.41
[Train] Epoch: 1 [265728/387873]    Loss: 0.002232   Batch Acc: 86.72
[Train] Epoch: 1 [265856/387873]    Loss: 0.001841   Batch Acc: 91.41
[Train] Epoch: 1 [265984/387873]    Loss: 0.001767   Batch Acc: 91.41
[Train] Epoch: 1 [266112/387873]    Loss: 0.002151   Batch Acc: 87.50
[Train] Epoch: 1 [266240/387873]    Loss: 0.001844   Batch Acc: 89.84
[Train] Epoch: 1 [266368/387873]    Loss: 0.002691   Batch Acc: 85.16
[Train] Epoch: 1 [266496/387873]    Loss: 0.002407   Batch Acc: 85.16
[Train] Epoch: 1 [266624/387873]    Loss: 0.002399   Batch Acc: 84.38
[Train] Epoch: 1 [266752/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 1 [266880/387873]    Loss: 0.002397   Batch Acc: 88.28
[Train] Epoch: 1 [267008/387873]    Loss: 0.002067   Batch Acc: 86.72
[Train] Epoch: 1 [267136/387873]    Loss: 0.002206   Batch Acc: 85.94
[Train] Epoch: 1 [267264/387873]    Loss: 0.001988   Batch Acc: 90.62
[Train] Epoch: 1 [267392/387873]    Loss: 0.002238   Batch Acc: 87.50
[Train] Epoch: 1 [267520/387873]    Loss: 0.001921   Batch Acc: 88.28
[Train] Epoch: 1 [267648/387873]    Loss: 0.002305   Batch Acc: 89.84
[Train] Epoch: 1 [267776/387873]    Loss: 0.002509   Batch Acc: 84.38
[Train] Epoch: 1 [267904/387873]    Loss: 0.001810   Batch Acc: 90.62
[Train] Epoch: 1 [268032/387873]    Loss: 0.002026   Batch Acc: 87.50
[Train] Epoch: 1 [268160/387873]    Loss: 0.002069   Batch Acc: 88.28
[Train] Epoch: 1 [268288/387873]    Loss: 0.001651   Batch Acc: 93.75
[Train] Epoch: 1 [268416/387873]    Loss: 0.002617   Batch Acc: 88.28
[Train] Epoch: 1 [268544/387873]    Loss: 0.002352   Batch Acc: 87.50
[Train] Epoch: 1 [268672/387873]    Loss: 0.002421   Batch Acc: 85.16
[Train] Epoch: 1 [268800/387873]    Loss: 0.002325   Batch Acc: 83.59
[Train] Epoch: 1 [268928/387873]    Loss: 0.001678   Batch Acc: 92.19
[Train] Epoch: 1 [269056/387873]    Loss: 0.001931   Batch Acc: 92.19
[Train] Epoch: 1 [269184/387873]    Loss: 0.001917   Batch Acc: 91.41
[Train] Epoch: 1 [269312/387873]    Loss: 0.002065   Batch Acc: 89.84
[Train] Epoch: 1 [269440/387873]    Loss: 0.002161   Batch Acc: 86.72
[Train] Epoch: 1 [269568/387873]    Loss: 0.002395   Batch Acc: 86.72
[Train] Epoch: 1 [269696/387873]    Loss: 0.002440   Batch Acc: 85.94
[Train] Epoch: 1 [269824/387873]    Loss: 0.002087   Batch Acc: 89.84
[Train] Epoch: 1 [269952/387873]    Loss: 0.001948   Batch Acc: 91.41
[Train] Epoch: 1 [270080/387873]    Loss: 0.002916   Batch Acc: 81.25
[Train] Epoch: 1 [270208/387873]    Loss: 0.002120   Batch Acc: 86.72
[Train] Epoch: 1 [270336/387873]    Loss: 0.002094   Batch Acc: 88.28
[Train] Epoch: 1 [270464/387873]    Loss: 0.001767   Batch Acc: 89.84
[Train] Epoch: 1 [270592/387873]    Loss: 0.002228   Batch Acc: 84.38
[Train] Epoch: 1 [270720/387873]    Loss: 0.002177   Batch Acc: 87.50
[Train] Epoch: 1 [270848/387873]    Loss: 0.001932   Batch Acc: 91.41
[Train] Epoch: 1 [270976/387873]    Loss: 0.002085   Batch Acc: 89.06
[Train] Epoch: 1 [271104/387873]    Loss: 0.001812   Batch Acc: 91.41
[Train] Epoch: 1 [271232/387873]    Loss: 0.002679   Batch Acc: 86.72
[Train] Epoch: 1 [271360/387873]    Loss: 0.001938   Batch Acc: 89.06
[Train] Epoch: 1 [271488/387873]    Loss: 0.001768   Batch Acc: 92.97
[Train] Epoch: 1 [271616/387873]    Loss: 0.002473   Batch Acc: 86.72
[Train] Epoch: 1 [271744/387873]    Loss: 0.002123   Batch Acc: 88.28
[Train] Epoch: 1 [271872/387873]    Loss: 0.002238   Batch Acc: 90.62
[Train] Epoch: 1 [272000/387873]    Loss: 0.001801   Batch Acc: 90.62
[Train] Epoch: 1 [272128/387873]    Loss: 0.002304   Batch Acc: 85.16
[Train] Epoch: 1 [272256/387873]    Loss: 0.001927   Batch Acc: 91.41
[Train] Epoch: 1 [272384/387873]    Loss: 0.001809   Batch Acc: 90.62
[Train] Epoch: 1 [272512/387873]    Loss: 0.001760   Batch Acc: 91.41
[Train] Epoch: 1 [272640/387873]    Loss: 0.001555   Batch Acc: 90.62
[Train] Epoch: 1 [272768/387873]    Loss: 0.002355   Batch Acc: 85.16
[Train] Epoch: 1 [272896/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 1 [273024/387873]    Loss: 0.002228   Batch Acc: 84.38
[Train] Epoch: 1 [273152/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 1 [273280/387873]    Loss: 0.001585   Batch Acc: 92.97
[Train] Epoch: 1 [273408/387873]    Loss: 0.001814   Batch Acc: 88.28
[Train] Epoch: 1 [273536/387873]    Loss: 0.001750   Batch Acc: 92.19
[Train] Epoch: 1 [273664/387873]    Loss: 0.001781   Batch Acc: 92.19
[Train] Epoch: 1 [273792/387873]    Loss: 0.001566   Batch Acc: 91.41
[Train] Epoch: 1 [273920/387873]    Loss: 0.002287   Batch Acc: 86.72
[Train] Epoch: 1 [274048/387873]    Loss: 0.002353   Batch Acc: 86.72
[Train] Epoch: 1 [274176/387873]    Loss: 0.002249   Batch Acc: 88.28
[Train] Epoch: 1 [274304/387873]    Loss: 0.001141   Batch Acc: 96.09
[Train] Epoch: 1 [274432/387873]    Loss: 0.001678   Batch Acc: 92.97
[Train] Epoch: 1 [274560/387873]    Loss: 0.002399   Batch Acc: 85.94
[Train] Epoch: 1 [274688/387873]    Loss: 0.001872   Batch Acc: 88.28
[Train] Epoch: 1 [274816/387873]    Loss: 0.002203   Batch Acc: 85.94
[Train] Epoch: 1 [274944/387873]    Loss: 0.002291   Batch Acc: 86.72
[Train] Epoch: 1 [275072/387873]    Loss: 0.002002   Batch Acc: 86.72
[Train] Epoch: 1 [275200/387873]    Loss: 0.001319   Batch Acc: 96.09
[Train] Epoch: 1 [275328/387873]    Loss: 0.002216   Batch Acc: 89.84
[Train] Epoch: 1 [275456/387873]    Loss: 0.002800   Batch Acc: 82.81
[Train] Epoch: 1 [275584/387873]    Loss: 0.001671   Batch Acc: 90.62
[Train] Epoch: 1 [275712/387873]    Loss: 0.002307   Batch Acc: 87.50
[Train] Epoch: 1 [275840/387873]    Loss: 0.002418   Batch Acc: 86.72
[Train] Epoch: 1 [275968/387873]    Loss: 0.002785   Batch Acc: 81.25
[Train] Epoch: 1 [276096/387873]    Loss: 0.002418   Batch Acc: 89.84
[Train] Epoch: 1 [276224/387873]    Loss: 0.001638   Batch Acc: 92.97
[Train] Epoch: 1 [276352/387873]    Loss: 0.002425   Batch Acc: 83.59
[Train] Epoch: 1 [276480/387873]    Loss: 0.001615   Batch Acc: 90.62
[Train] Epoch: 1 [276608/387873]    Loss: 0.002126   Batch Acc: 90.62
[Train] Epoch: 1 [276736/387873]    Loss: 0.002090   Batch Acc: 89.84
[Train] Epoch: 1 [276864/387873]    Loss: 0.001979   Batch Acc: 89.06
[Train] Epoch: 1 [276992/387873]    Loss: 0.002241   Batch Acc: 85.94
[Train] Epoch: 1 [277120/387873]    Loss: 0.002805   Batch Acc: 85.94
[Train] Epoch: 1 [277248/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 1 [277376/387873]    Loss: 0.001740   Batch Acc: 92.19
[Train] Epoch: 1 [277504/387873]    Loss: 0.002185   Batch Acc: 86.72
[Train] Epoch: 1 [277632/387873]    Loss: 0.002186   Batch Acc: 85.94
[Train] Epoch: 1 [277760/387873]    Loss: 0.002778   Batch Acc: 83.59
[Train] Epoch: 1 [277888/387873]    Loss: 0.001357   Batch Acc: 94.53
[Train] Epoch: 1 [278016/387873]    Loss: 0.001698   Batch Acc: 89.06
[Train] Epoch: 1 [278144/387873]    Loss: 0.001750   Batch Acc: 90.62
[Train] Epoch: 1 [278272/387873]    Loss: 0.002028   Batch Acc: 87.50
[Train] Epoch: 1 [278400/387873]    Loss: 0.001982   Batch Acc: 87.50
[Train] Epoch: 1 [278528/387873]    Loss: 0.002217   Batch Acc: 85.94
[Train] Epoch: 1 [278656/387873]    Loss: 0.002488   Batch Acc: 85.16
[Train] Epoch: 1 [278784/387873]    Loss: 0.002472   Batch Acc: 82.81
[Train] Epoch: 1 [278912/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 1 [279040/387873]    Loss: 0.001664   Batch Acc: 94.53
[Train] Epoch: 1 [279168/387873]    Loss: 0.001817   Batch Acc: 89.84
[Train] Epoch: 1 [279296/387873]    Loss: 0.001571   Batch Acc: 93.75
[Train] Epoch: 1 [279424/387873]    Loss: 0.001725   Batch Acc: 89.84
[Train] Epoch: 1 [279552/387873]    Loss: 0.002012   Batch Acc: 89.84
[Train] Epoch: 1 [279680/387873]    Loss: 0.002146   Batch Acc: 87.50
[Train] Epoch: 1 [279808/387873]    Loss: 0.002884   Batch Acc: 82.81
[Train] Epoch: 1 [279936/387873]    Loss: 0.002405   Batch Acc: 88.28
[Train] Epoch: 1 [280064/387873]    Loss: 0.002142   Batch Acc: 88.28
[Train] Epoch: 1 [280192/387873]    Loss: 0.001930   Batch Acc: 89.06
[Train] Epoch: 1 [280320/387873]    Loss: 0.002313   Batch Acc: 87.50
[Train] Epoch: 1 [280448/387873]    Loss: 0.002247   Batch Acc: 92.19
[Train] Epoch: 1 [280576/387873]    Loss: 0.001475   Batch Acc: 95.31
[Train] Epoch: 1 [280704/387873]    Loss: 0.002203   Batch Acc: 89.06
[Train] Epoch: 1 [280832/387873]    Loss: 0.002147   Batch Acc: 92.19
[Train] Epoch: 1 [280960/387873]    Loss: 0.001844   Batch Acc: 90.62
[Train] Epoch: 1 [281088/387873]    Loss: 0.002199   Batch Acc: 87.50
[Train] Epoch: 1 [281216/387873]    Loss: 0.002698   Batch Acc: 78.91
[Train] Epoch: 1 [281344/387873]    Loss: 0.001965   Batch Acc: 88.28
[Train] Epoch: 1 [281472/387873]    Loss: 0.002178   Batch Acc: 89.06
[Train] Epoch: 1 [281600/387873]    Loss: 0.002317   Batch Acc: 85.16
[Train] Epoch: 1 [281728/387873]    Loss: 0.002089   Batch Acc: 86.72
[Train] Epoch: 1 [281856/387873]    Loss: 0.001449   Batch Acc: 93.75
[Train] Epoch: 1 [281984/387873]    Loss: 0.002029   Batch Acc: 89.84
[Train] Epoch: 1 [282112/387873]    Loss: 0.002007   Batch Acc: 89.06
[Train] Epoch: 1 [282240/387873]    Loss: 0.002542   Batch Acc: 87.50
[Train] Epoch: 1 [282368/387873]    Loss: 0.002164   Batch Acc: 88.28
[Train] Epoch: 1 [282496/387873]    Loss: 0.001978   Batch Acc: 89.84
[Train] Epoch: 1 [282624/387873]    Loss: 0.001925   Batch Acc: 91.41
[Train] Epoch: 1 [282752/387873]    Loss: 0.002019   Batch Acc: 89.06
[Train] Epoch: 1 [282880/387873]    Loss: 0.002687   Batch Acc: 82.03
[Train] Epoch: 1 [283008/387873]    Loss: 0.002137   Batch Acc: 88.28
[Train] Epoch: 1 [283136/387873]    Loss: 0.002608   Batch Acc: 81.25
[Train] Epoch: 1 [283264/387873]    Loss: 0.001365   Batch Acc: 93.75
[Train] Epoch: 1 [283392/387873]    Loss: 0.001974   Batch Acc: 89.06
[Train] Epoch: 1 [283520/387873]    Loss: 0.002745   Batch Acc: 82.81
[Train] Epoch: 1 [283648/387873]    Loss: 0.002706   Batch Acc: 82.03
[Train] Epoch: 1 [283776/387873]    Loss: 0.002463   Batch Acc: 84.38
[Train] Epoch: 1 [283904/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 1 [284032/387873]    Loss: 0.002171   Batch Acc: 92.19
[Train] Epoch: 1 [284160/387873]    Loss: 0.002580   Batch Acc: 85.94
[Train] Epoch: 1 [284288/387873]    Loss: 0.002411   Batch Acc: 86.72
[Train] Epoch: 1 [284416/387873]    Loss: 0.002054   Batch Acc: 88.28
[Train] Epoch: 1 [284544/387873]    Loss: 0.001625   Batch Acc: 90.62
[Train] Epoch: 1 [284672/387873]    Loss: 0.001534   Batch Acc: 96.09
[Train] Epoch: 1 [284800/387873]    Loss: 0.002201   Batch Acc: 89.84
[Train] Epoch: 1 [284928/387873]    Loss: 0.002220   Batch Acc: 87.50
[Train] Epoch: 1 [285056/387873]    Loss: 0.001987   Batch Acc: 89.84
[Train] Epoch: 1 [285184/387873]    Loss: 0.001773   Batch Acc: 92.19
[Train] Epoch: 1 [285312/387873]    Loss: 0.001468   Batch Acc: 93.75
[Train] Epoch: 1 [285440/387873]    Loss: 0.002542   Batch Acc: 83.59
[Train] Epoch: 1 [285568/387873]    Loss: 0.001527   Batch Acc: 93.75
[Train] Epoch: 1 [285696/387873]    Loss: 0.002255   Batch Acc: 89.84
[Train] Epoch: 1 [285824/387873]    Loss: 0.002113   Batch Acc: 85.16
[Train] Epoch: 1 [285952/387873]    Loss: 0.002171   Batch Acc: 87.50
[Train] Epoch: 1 [286080/387873]    Loss: 0.002199   Batch Acc: 90.62
[Train] Epoch: 1 [286208/387873]    Loss: 0.002003   Batch Acc: 91.41
[Train] Epoch: 1 [286336/387873]    Loss: 0.001917   Batch Acc: 92.97
[Train] Epoch: 1 [286464/387873]    Loss: 0.001982   Batch Acc: 92.97
[Train] Epoch: 1 [286592/387873]    Loss: 0.002111   Batch Acc: 89.06
[Train] Epoch: 1 [286720/387873]    Loss: 0.001290   Batch Acc: 96.09
[Train] Epoch: 1 [286848/387873]    Loss: 0.002228   Batch Acc: 85.16
[Train] Epoch: 1 [286976/387873]    Loss: 0.002014   Batch Acc: 87.50
[Train] Epoch: 1 [287104/387873]    Loss: 0.001791   Batch Acc: 91.41
[Train] Epoch: 1 [287232/387873]    Loss: 0.002217   Batch Acc: 86.72
[Train] Epoch: 1 [287360/387873]    Loss: 0.001951   Batch Acc: 90.62
[Train] Epoch: 1 [287488/387873]    Loss: 0.001551   Batch Acc: 92.19
[Train] Epoch: 1 [287616/387873]    Loss: 0.002054   Batch Acc: 89.06
[Train] Epoch: 1 [287744/387873]    Loss: 0.002188   Batch Acc: 85.94
[Train] Epoch: 1 [287872/387873]    Loss: 0.002030   Batch Acc: 89.06
[Train] Epoch: 1 [288000/387873]    Loss: 0.002282   Batch Acc: 85.16
[Train] Epoch: 1 [288128/387873]    Loss: 0.001863   Batch Acc: 89.06
[Train] Epoch: 1 [288256/387873]    Loss: 0.001768   Batch Acc: 89.84
[Train] Epoch: 1 [288384/387873]    Loss: 0.002070   Batch Acc: 91.41
[Train] Epoch: 1 [288512/387873]    Loss: 0.001731   Batch Acc: 91.41
[Train] Epoch: 1 [288640/387873]    Loss: 0.001336   Batch Acc: 95.31
[Train] Epoch: 1 [288768/387873]    Loss: 0.002188   Batch Acc: 88.28
[Train] Epoch: 1 [288896/387873]    Loss: 0.002206   Batch Acc: 87.50
[Train] Epoch: 1 [289024/387873]    Loss: 0.002240   Batch Acc: 88.28
[Train] Epoch: 1 [289152/387873]    Loss: 0.002264   Batch Acc: 86.72
[Train] Epoch: 1 [289280/387873]    Loss: 0.001738   Batch Acc: 92.19
[Train] Epoch: 1 [289408/387873]    Loss: 0.001877   Batch Acc: 89.84
[Train] Epoch: 1 [289536/387873]    Loss: 0.002028   Batch Acc: 92.19
[Train] Epoch: 1 [289664/387873]    Loss: 0.002043   Batch Acc: 88.28
[Train] Epoch: 1 [289792/387873]    Loss: 0.002082   Batch Acc: 89.84
[Train] Epoch: 1 [289920/387873]    Loss: 0.002436   Batch Acc: 85.94
[Train] Epoch: 1 [290048/387873]    Loss: 0.001842   Batch Acc: 89.84
[Train] Epoch: 1 [290176/387873]    Loss: 0.002146   Batch Acc: 89.84
[Train] Epoch: 1 [290304/387873]    Loss: 0.002564   Batch Acc: 85.16
[Train] Epoch: 1 [290432/387873]    Loss: 0.001845   Batch Acc: 89.06
[Train] Epoch: 1 [290560/387873]    Loss: 0.001977   Batch Acc: 88.28
[Train] Epoch: 1 [290688/387873]    Loss: 0.002099   Batch Acc: 90.62
[Train] Epoch: 1 [290816/387873]    Loss: 0.002206   Batch Acc: 85.94
[Train] Epoch: 1 [290944/387873]    Loss: 0.001439   Batch Acc: 94.53
[Train] Epoch: 1 [291072/387873]    Loss: 0.001490   Batch Acc: 94.53
[Train] Epoch: 1 [291200/387873]    Loss: 0.001987   Batch Acc: 87.50
[Train] Epoch: 1 [291328/387873]    Loss: 0.002610   Batch Acc: 85.94
[Train] Epoch: 1 [291456/387873]    Loss: 0.002147   Batch Acc: 88.28
[Train] Epoch: 1 [291584/387873]    Loss: 0.001749   Batch Acc: 92.97
[Train] Epoch: 1 [291712/387873]    Loss: 0.001600   Batch Acc: 91.41
[Train] Epoch: 1 [291840/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 1 [291968/387873]    Loss: 0.001444   Batch Acc: 92.97
[Train] Epoch: 1 [292096/387873]    Loss: 0.001942   Batch Acc: 89.06
[Train] Epoch: 1 [292224/387873]    Loss: 0.002574   Batch Acc: 85.94
[Train] Epoch: 1 [292352/387873]    Loss: 0.002075   Batch Acc: 87.50
[Train] Epoch: 1 [292480/387873]    Loss: 0.001918   Batch Acc: 91.41
[Train] Epoch: 1 [292608/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 1 [292736/387873]    Loss: 0.001898   Batch Acc: 88.28
[Train] Epoch: 1 [292864/387873]    Loss: 0.002117   Batch Acc: 90.62
[Train] Epoch: 1 [292992/387873]    Loss: 0.001804   Batch Acc: 93.75
[Train] Epoch: 1 [293120/387873]    Loss: 0.002309   Batch Acc: 86.72
[Train] Epoch: 1 [293248/387873]    Loss: 0.002307   Batch Acc: 86.72
[Train] Epoch: 1 [293376/387873]    Loss: 0.002209   Batch Acc: 87.50
[Train] Epoch: 1 [293504/387873]    Loss: 0.002667   Batch Acc: 81.25
[Train] Epoch: 1 [293632/387873]    Loss: 0.002037   Batch Acc: 88.28
[Train] Epoch: 1 [293760/387873]    Loss: 0.002629   Batch Acc: 85.94
[Train] Epoch: 1 [293888/387873]    Loss: 0.002395   Batch Acc: 85.16
[Train] Epoch: 1 [294016/387873]    Loss: 0.002342   Batch Acc: 88.28
[Train] Epoch: 1 [294144/387873]    Loss: 0.002695   Batch Acc: 82.81
[Train] Epoch: 1 [294272/387873]    Loss: 0.001871   Batch Acc: 90.62
[Train] Epoch: 1 [294400/387873]    Loss: 0.001937   Batch Acc: 90.62
[Train] Epoch: 1 [294528/387873]    Loss: 0.001673   Batch Acc: 92.19
[Train] Epoch: 1 [294656/387873]    Loss: 0.002188   Batch Acc: 86.72
[Train] Epoch: 1 [294784/387873]    Loss: 0.002058   Batch Acc: 90.62
[Train] Epoch: 1 [294912/387873]    Loss: 0.001947   Batch Acc: 89.06
[Train] Epoch: 1 [295040/387873]    Loss: 0.001936   Batch Acc: 92.19
[Train] Epoch: 1 [295168/387873]    Loss: 0.002269   Batch Acc: 83.59
[Train] Epoch: 1 [295296/387873]    Loss: 0.001822   Batch Acc: 89.84
[Train] Epoch: 1 [295424/387873]    Loss: 0.001831   Batch Acc: 90.62
[Train] Epoch: 1 [295552/387873]    Loss: 0.001765   Batch Acc: 92.97
[Train] Epoch: 1 [295680/387873]    Loss: 0.001732   Batch Acc: 91.41
[Train] Epoch: 1 [295808/387873]    Loss: 0.001745   Batch Acc: 93.75
[Train] Epoch: 1 [295936/387873]    Loss: 0.002217   Batch Acc: 88.28
[Train] Epoch: 1 [296064/387873]    Loss: 0.001847   Batch Acc: 89.06
[Train] Epoch: 1 [296192/387873]    Loss: 0.002585   Batch Acc: 85.94
[Train] Epoch: 1 [296320/387873]    Loss: 0.002688   Batch Acc: 85.16
[Train] Epoch: 1 [296448/387873]    Loss: 0.002399   Batch Acc: 88.28
[Train] Epoch: 1 [296576/387873]    Loss: 0.002457   Batch Acc: 85.94
[Train] Epoch: 1 [296704/387873]    Loss: 0.001846   Batch Acc: 89.84
[Train] Epoch: 1 [296832/387873]    Loss: 0.002288   Batch Acc: 85.94
[Train] Epoch: 1 [296960/387873]    Loss: 0.001510   Batch Acc: 92.97
[Train] Epoch: 1 [297088/387873]    Loss: 0.001801   Batch Acc: 92.97
[Train] Epoch: 1 [297216/387873]    Loss: 0.002678   Batch Acc: 82.03
[Train] Epoch: 1 [297344/387873]    Loss: 0.002121   Batch Acc: 89.84
[Train] Epoch: 1 [297472/387873]    Loss: 0.001869   Batch Acc: 91.41
[Train] Epoch: 1 [297600/387873]    Loss: 0.002009   Batch Acc: 91.41
[Train] Epoch: 1 [297728/387873]    Loss: 0.001947   Batch Acc: 89.84
[Train] Epoch: 1 [297856/387873]    Loss: 0.001806   Batch Acc: 91.41
[Train] Epoch: 1 [297984/387873]    Loss: 0.001929   Batch Acc: 90.62
[Train] Epoch: 1 [298112/387873]    Loss: 0.002067   Batch Acc: 85.94
[Train] Epoch: 1 [298240/387873]    Loss: 0.002349   Batch Acc: 83.59
[Train] Epoch: 1 [298368/387873]    Loss: 0.002200   Batch Acc: 86.72
[Train] Epoch: 1 [298496/387873]    Loss: 0.002198   Batch Acc: 85.94
[Train] Epoch: 1 [298624/387873]    Loss: 0.001935   Batch Acc: 89.06
[Train] Epoch: 1 [298752/387873]    Loss: 0.002135   Batch Acc: 89.84
[Train] Epoch: 1 [298880/387873]    Loss: 0.001626   Batch Acc: 92.19
[Train] Epoch: 1 [299008/387873]    Loss: 0.001991   Batch Acc: 90.62
[Train] Epoch: 1 [299136/387873]    Loss: 0.001854   Batch Acc: 92.19
[Train] Epoch: 1 [299264/387873]    Loss: 0.001667   Batch Acc: 93.75
[Train] Epoch: 1 [299392/387873]    Loss: 0.002317   Batch Acc: 85.16
[Train] Epoch: 1 [299520/387873]    Loss: 0.002469   Batch Acc: 87.50
[Train] Epoch: 1 [299648/387873]    Loss: 0.001563   Batch Acc: 91.41
[Train] Epoch: 1 [299776/387873]    Loss: 0.002210   Batch Acc: 87.50
[Train] Epoch: 1 [299904/387873]    Loss: 0.002153   Batch Acc: 87.50
[Train] Epoch: 1 [300032/387873]    Loss: 0.001988   Batch Acc: 89.84
[Train] Epoch: 1 [300160/387873]    Loss: 0.001721   Batch Acc: 87.50
[Train] Epoch: 1 [300288/387873]    Loss: 0.001887   Batch Acc: 91.41
[Train] Epoch: 1 [300416/387873]    Loss: 0.002310   Batch Acc: 86.72
[Train] Epoch: 1 [300544/387873]    Loss: 0.002376   Batch Acc: 87.50
[Train] Epoch: 1 [300672/387873]    Loss: 0.001803   Batch Acc: 92.97
[Train] Epoch: 1 [300800/387873]    Loss: 0.001754   Batch Acc: 92.19
[Train] Epoch: 1 [300928/387873]    Loss: 0.002447   Batch Acc: 87.50
[Train] Epoch: 1 [301056/387873]    Loss: 0.002121   Batch Acc: 85.94
[Train] Epoch: 1 [301184/387873]    Loss: 0.002405   Batch Acc: 85.16
[Train] Epoch: 1 [301312/387873]    Loss: 0.001805   Batch Acc: 90.62
[Train] Epoch: 1 [301440/387873]    Loss: 0.001544   Batch Acc: 93.75
[Train] Epoch: 1 [301568/387873]    Loss: 0.002132   Batch Acc: 86.72
[Train] Epoch: 1 [301696/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 1 [301824/387873]    Loss: 0.001884   Batch Acc: 88.28
[Train] Epoch: 1 [301952/387873]    Loss: 0.002275   Batch Acc: 88.28
[Train] Epoch: 1 [302080/387873]    Loss: 0.002081   Batch Acc: 89.06
[Train] Epoch: 1 [302208/387873]    Loss: 0.002134   Batch Acc: 89.06
[Train] Epoch: 1 [302336/387873]    Loss: 0.002092   Batch Acc: 91.41
[Train] Epoch: 1 [302464/387873]    Loss: 0.001740   Batch Acc: 90.62
[Train] Epoch: 1 [302592/387873]    Loss: 0.001859   Batch Acc: 90.62
[Train] Epoch: 1 [302720/387873]    Loss: 0.002241   Batch Acc: 88.28
[Train] Epoch: 1 [302848/387873]    Loss: 0.002126   Batch Acc: 86.72
[Train] Epoch: 1 [302976/387873]    Loss: 0.002089   Batch Acc: 88.28
[Train] Epoch: 1 [303104/387873]    Loss: 0.002059   Batch Acc: 90.62
[Train] Epoch: 1 [303232/387873]    Loss: 0.001772   Batch Acc: 92.19
[Train] Epoch: 1 [303360/387873]    Loss: 0.001787   Batch Acc: 90.62
[Train] Epoch: 1 [303488/387873]    Loss: 0.001996   Batch Acc: 89.84
[Train] Epoch: 1 [303616/387873]    Loss: 0.002011   Batch Acc: 88.28
[Train] Epoch: 1 [303744/387873]    Loss: 0.002424   Batch Acc: 87.50
[Train] Epoch: 1 [303872/387873]    Loss: 0.001989   Batch Acc: 89.84
[Train] Epoch: 1 [304000/387873]    Loss: 0.002393   Batch Acc: 87.50
[Train] Epoch: 1 [304128/387873]    Loss: 0.002351   Batch Acc: 85.94
[Train] Epoch: 1 [304256/387873]    Loss: 0.001686   Batch Acc: 89.06
[Train] Epoch: 1 [304384/387873]    Loss: 0.001910   Batch Acc: 88.28
[Train] Epoch: 1 [304512/387873]    Loss: 0.002419   Batch Acc: 84.38
[Train] Epoch: 1 [304640/387873]    Loss: 0.001989   Batch Acc: 89.84
[Train] Epoch: 1 [304768/387873]    Loss: 0.002314   Batch Acc: 85.16
[Train] Epoch: 1 [304896/387873]    Loss: 0.001940   Batch Acc: 89.06
[Train] Epoch: 1 [305024/387873]    Loss: 0.002438   Batch Acc: 85.94
[Train] Epoch: 1 [305152/387873]    Loss: 0.001479   Batch Acc: 93.75
[Train] Epoch: 1 [305280/387873]    Loss: 0.002143   Batch Acc: 89.06
[Train] Epoch: 1 [305408/387873]    Loss: 0.002779   Batch Acc: 82.81
[Train] Epoch: 1 [305536/387873]    Loss: 0.002110   Batch Acc: 88.28
[Train] Epoch: 1 [305664/387873]    Loss: 0.002151   Batch Acc: 85.94
[Train] Epoch: 1 [305792/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 1 [305920/387873]    Loss: 0.002310   Batch Acc: 86.72
[Train] Epoch: 1 [306048/387873]    Loss: 0.001932   Batch Acc: 88.28
[Train] Epoch: 1 [306176/387873]    Loss: 0.001981   Batch Acc: 90.62
[Train] Epoch: 1 [306304/387873]    Loss: 0.001952   Batch Acc: 89.84
[Train] Epoch: 1 [306432/387873]    Loss: 0.001757   Batch Acc: 92.97
[Train] Epoch: 1 [306560/387873]    Loss: 0.002178   Batch Acc: 86.72
[Train] Epoch: 1 [306688/387873]    Loss: 0.002364   Batch Acc: 88.28
[Train] Epoch: 1 [306816/387873]    Loss: 0.002040   Batch Acc: 88.28
[Train] Epoch: 1 [306944/387873]    Loss: 0.002297   Batch Acc: 86.72
[Train] Epoch: 1 [307072/387873]    Loss: 0.002413   Batch Acc: 82.81
[Train] Epoch: 1 [307200/387873]    Loss: 0.001802   Batch Acc: 89.06
[Train] Epoch: 1 [307328/387873]    Loss: 0.001835   Batch Acc: 93.75
[Train] Epoch: 1 [307456/387873]    Loss: 0.001930   Batch Acc: 91.41
[Train] Epoch: 1 [307584/387873]    Loss: 0.002118   Batch Acc: 87.50
[Train] Epoch: 1 [307712/387873]    Loss: 0.002245   Batch Acc: 89.06
[Train] Epoch: 1 [307840/387873]    Loss: 0.002207   Batch Acc: 88.28
[Train] Epoch: 1 [307968/387873]    Loss: 0.001857   Batch Acc: 91.41
[Train] Epoch: 1 [308096/387873]    Loss: 0.001487   Batch Acc: 94.53
[Train] Epoch: 1 [308224/387873]    Loss: 0.001775   Batch Acc: 93.75
[Train] Epoch: 1 [308352/387873]    Loss: 0.001891   Batch Acc: 91.41
[Train] Epoch: 1 [308480/387873]    Loss: 0.001669   Batch Acc: 92.97
[Train] Epoch: 1 [308608/387873]    Loss: 0.002142   Batch Acc: 88.28
[Train] Epoch: 1 [308736/387873]    Loss: 0.001986   Batch Acc: 89.06
[Train] Epoch: 1 [308864/387873]    Loss: 0.002156   Batch Acc: 88.28
[Train] Epoch: 1 [308992/387873]    Loss: 0.002255   Batch Acc: 86.72
[Train] Epoch: 1 [309120/387873]    Loss: 0.002338   Batch Acc: 89.06
[Train] Epoch: 1 [309248/387873]    Loss: 0.001800   Batch Acc: 92.97
[Train] Epoch: 1 [309376/387873]    Loss: 0.001622   Batch Acc: 91.41
[Train] Epoch: 1 [309504/387873]    Loss: 0.002326   Batch Acc: 88.28
[Train] Epoch: 1 [309632/387873]    Loss: 0.002554   Batch Acc: 85.16
[Train] Epoch: 1 [309760/387873]    Loss: 0.002188   Batch Acc: 85.94
[Train] Epoch: 1 [309888/387873]    Loss: 0.001899   Batch Acc: 90.62
[Train] Epoch: 1 [310016/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 1 [310144/387873]    Loss: 0.001950   Batch Acc: 90.62
[Train] Epoch: 1 [310272/387873]    Loss: 0.001978   Batch Acc: 89.06
[Train] Epoch: 1 [310400/387873]    Loss: 0.001700   Batch Acc: 92.97
[Train] Epoch: 1 [310528/387873]    Loss: 0.001995   Batch Acc: 89.06
[Train] Epoch: 1 [310656/387873]    Loss: 0.002747   Batch Acc: 85.16
[Train] Epoch: 1 [310784/387873]    Loss: 0.002096   Batch Acc: 89.84
[Train] Epoch: 1 [310912/387873]    Loss: 0.001579   Batch Acc: 92.19
[Train] Epoch: 1 [311040/387873]    Loss: 0.002755   Batch Acc: 82.81
[Train] Epoch: 1 [311168/387873]    Loss: 0.002076   Batch Acc: 88.28
[Train] Epoch: 1 [311296/387873]    Loss: 0.002605   Batch Acc: 84.38
[Train] Epoch: 1 [311424/387873]    Loss: 0.002183   Batch Acc: 89.84
[Train] Epoch: 1 [311552/387873]    Loss: 0.002070   Batch Acc: 86.72
[Train] Epoch: 1 [311680/387873]    Loss: 0.002658   Batch Acc: 82.81
[Train] Epoch: 1 [311808/387873]    Loss: 0.001912   Batch Acc: 89.06
[Train] Epoch: 1 [311936/387873]    Loss: 0.001979   Batch Acc: 89.06
[Train] Epoch: 1 [312064/387873]    Loss: 0.002401   Batch Acc: 85.94
[Train] Epoch: 1 [312192/387873]    Loss: 0.001922   Batch Acc: 90.62
[Train] Epoch: 1 [312320/387873]    Loss: 0.001969   Batch Acc: 90.62
[Train] Epoch: 1 [312448/387873]    Loss: 0.002056   Batch Acc: 87.50
[Train] Epoch: 1 [312576/387873]    Loss: 0.002007   Batch Acc: 88.28
[Train] Epoch: 1 [312704/387873]    Loss: 0.002514   Batch Acc: 85.94
[Train] Epoch: 1 [312832/387873]    Loss: 0.001786   Batch Acc: 89.84
[Train] Epoch: 1 [312960/387873]    Loss: 0.002125   Batch Acc: 89.84
[Train] Epoch: 1 [313088/387873]    Loss: 0.002260   Batch Acc: 88.28
[Train] Epoch: 1 [313216/387873]    Loss: 0.002883   Batch Acc: 79.69
[Train] Epoch: 1 [313344/387873]    Loss: 0.002307   Batch Acc: 88.28
[Train] Epoch: 1 [313472/387873]    Loss: 0.002079   Batch Acc: 90.62
[Train] Epoch: 1 [313600/387873]    Loss: 0.001679   Batch Acc: 92.19
[Train] Epoch: 1 [313728/387873]    Loss: 0.001848   Batch Acc: 89.84
[Train] Epoch: 1 [313856/387873]    Loss: 0.002044   Batch Acc: 89.06
[Train] Epoch: 1 [313984/387873]    Loss: 0.002100   Batch Acc: 89.84
[Train] Epoch: 1 [314112/387873]    Loss: 0.002084   Batch Acc: 87.50
[Train] Epoch: 1 [314240/387873]    Loss: 0.002947   Batch Acc: 87.50
[Train] Epoch: 1 [314368/387873]    Loss: 0.001609   Batch Acc: 93.75
[Train] Epoch: 1 [314496/387873]    Loss: 0.001694   Batch Acc: 90.62
[Train] Epoch: 1 [314624/387873]    Loss: 0.001927   Batch Acc: 89.06
[Train] Epoch: 1 [314752/387873]    Loss: 0.002124   Batch Acc: 90.62
[Train] Epoch: 1 [314880/387873]    Loss: 0.002452   Batch Acc: 89.06
[Train] Epoch: 1 [315008/387873]    Loss: 0.001768   Batch Acc: 91.41
[Train] Epoch: 1 [315136/387873]    Loss: 0.001793   Batch Acc: 92.19
[Train] Epoch: 1 [315264/387873]    Loss: 0.001860   Batch Acc: 90.62
[Train] Epoch: 1 [315392/387873]    Loss: 0.002135   Batch Acc: 89.06
[Train] Epoch: 1 [315520/387873]    Loss: 0.001561   Batch Acc: 92.19
[Train] Epoch: 1 [315648/387873]    Loss: 0.001884   Batch Acc: 88.28
[Train] Epoch: 1 [315776/387873]    Loss: 0.003181   Batch Acc: 81.25
[Train] Epoch: 1 [315904/387873]    Loss: 0.001650   Batch Acc: 91.41
[Train] Epoch: 1 [316032/387873]    Loss: 0.001670   Batch Acc: 90.62
[Train] Epoch: 1 [316160/387873]    Loss: 0.001571   Batch Acc: 94.53
[Train] Epoch: 1 [316288/387873]    Loss: 0.002165   Batch Acc: 90.62
[Train] Epoch: 1 [316416/387873]    Loss: 0.002511   Batch Acc: 84.38
[Train] Epoch: 1 [316544/387873]    Loss: 0.001936   Batch Acc: 91.41
[Train] Epoch: 1 [316672/387873]    Loss: 0.002444   Batch Acc: 89.06
[Train] Epoch: 1 [316800/387873]    Loss: 0.002049   Batch Acc: 90.62
[Train] Epoch: 1 [316928/387873]    Loss: 0.002004   Batch Acc: 90.62
[Train] Epoch: 1 [317056/387873]    Loss: 0.002103   Batch Acc: 91.41
[Train] Epoch: 1 [317184/387873]    Loss: 0.001922   Batch Acc: 89.06
[Train] Epoch: 1 [317312/387873]    Loss: 0.001505   Batch Acc: 91.41
[Train] Epoch: 1 [317440/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 1 [317568/387873]    Loss: 0.002315   Batch Acc: 89.06
[Train] Epoch: 1 [317696/387873]    Loss: 0.001784   Batch Acc: 90.62
[Train] Epoch: 1 [317824/387873]    Loss: 0.002293   Batch Acc: 86.72
[Train] Epoch: 1 [317952/387873]    Loss: 0.002005   Batch Acc: 90.62
[Train] Epoch: 1 [318080/387873]    Loss: 0.001992   Batch Acc: 91.41
[Train] Epoch: 1 [318208/387873]    Loss: 0.001677   Batch Acc: 91.41
[Train] Epoch: 1 [318336/387873]    Loss: 0.002693   Batch Acc: 84.38
[Train] Epoch: 1 [318464/387873]    Loss: 0.002169   Batch Acc: 90.62
[Train] Epoch: 1 [318592/387873]    Loss: 0.002443   Batch Acc: 86.72
[Train] Epoch: 1 [318720/387873]    Loss: 0.002178   Batch Acc: 87.50
[Train] Epoch: 1 [318848/387873]    Loss: 0.002174   Batch Acc: 87.50
[Train] Epoch: 1 [318976/387873]    Loss: 0.002237   Batch Acc: 89.84
[Train] Epoch: 1 [319104/387873]    Loss: 0.001936   Batch Acc: 90.62
[Train] Epoch: 1 [319232/387873]    Loss: 0.001670   Batch Acc: 93.75
[Train] Epoch: 1 [319360/387873]    Loss: 0.002456   Batch Acc: 85.94
[Train] Epoch: 1 [319488/387873]    Loss: 0.002239   Batch Acc: 85.94
[Train] Epoch: 1 [319616/387873]    Loss: 0.001909   Batch Acc: 90.62
[Train] Epoch: 1 [319744/387873]    Loss: 0.002354   Batch Acc: 86.72
[Train] Epoch: 1 [319872/387873]    Loss: 0.002176   Batch Acc: 87.50
[Train] Epoch: 1 [320000/387873]    Loss: 0.002549   Batch Acc: 85.16
[Train] Epoch: 1 [320128/387873]    Loss: 0.002432   Batch Acc: 82.81
[Train] Epoch: 1 [320256/387873]    Loss: 0.001889   Batch Acc: 89.84
[Train] Epoch: 1 [320384/387873]    Loss: 0.002393   Batch Acc: 85.16
[Train] Epoch: 1 [320512/387873]    Loss: 0.002246   Batch Acc: 89.06
[Train] Epoch: 1 [320640/387873]    Loss: 0.002399   Batch Acc: 84.38
[Train] Epoch: 1 [320768/387873]    Loss: 0.002094   Batch Acc: 86.72
[Train] Epoch: 1 [320896/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 1 [321024/387873]    Loss: 0.002821   Batch Acc: 83.59
[Train] Epoch: 1 [321152/387873]    Loss: 0.001727   Batch Acc: 94.53
[Train] Epoch: 1 [321280/387873]    Loss: 0.002290   Batch Acc: 89.84
[Train] Epoch: 1 [321408/387873]    Loss: 0.002378   Batch Acc: 87.50
[Train] Epoch: 1 [321536/387873]    Loss: 0.002170   Batch Acc: 89.84
[Train] Epoch: 1 [321664/387873]    Loss: 0.001970   Batch Acc: 89.84
[Train] Epoch: 1 [321792/387873]    Loss: 0.001807   Batch Acc: 89.84
[Train] Epoch: 1 [321920/387873]    Loss: 0.001958   Batch Acc: 89.06
[Train] Epoch: 1 [322048/387873]    Loss: 0.001771   Batch Acc: 91.41
[Train] Epoch: 1 [322176/387873]    Loss: 0.001729   Batch Acc: 92.19
[Train] Epoch: 1 [322304/387873]    Loss: 0.001678   Batch Acc: 91.41
[Train] Epoch: 1 [322432/387873]    Loss: 0.002174   Batch Acc: 86.72
[Train] Epoch: 1 [322560/387873]    Loss: 0.001885   Batch Acc: 89.84
[Train] Epoch: 1 [322688/387873]    Loss: 0.001805   Batch Acc: 92.97
[Train] Epoch: 1 [322816/387873]    Loss: 0.002374   Batch Acc: 87.50
[Train] Epoch: 1 [322944/387873]    Loss: 0.002043   Batch Acc: 86.72
[Train] Epoch: 1 [323072/387873]    Loss: 0.002013   Batch Acc: 87.50
[Train] Epoch: 1 [323200/387873]    Loss: 0.002119   Batch Acc: 89.84
[Train] Epoch: 1 [323328/387873]    Loss: 0.001997   Batch Acc: 89.84
[Train] Epoch: 1 [323456/387873]    Loss: 0.002553   Batch Acc: 85.94
[Train] Epoch: 1 [323584/387873]    Loss: 0.001809   Batch Acc: 89.06
[Train] Epoch: 1 [323712/387873]    Loss: 0.001864   Batch Acc: 92.19
[Train] Epoch: 1 [323840/387873]    Loss: 0.002133   Batch Acc: 88.28
[Train] Epoch: 1 [323968/387873]    Loss: 0.001766   Batch Acc: 91.41
[Train] Epoch: 1 [324096/387873]    Loss: 0.001852   Batch Acc: 92.19
[Train] Epoch: 1 [324224/387873]    Loss: 0.001645   Batch Acc: 92.97
[Train] Epoch: 1 [324352/387873]    Loss: 0.001900   Batch Acc: 92.97
[Train] Epoch: 1 [324480/387873]    Loss: 0.001945   Batch Acc: 89.06
[Train] Epoch: 1 [324608/387873]    Loss: 0.002591   Batch Acc: 82.03
[Train] Epoch: 1 [324736/387873]    Loss: 0.002455   Batch Acc: 84.38
[Train] Epoch: 1 [324864/387873]    Loss: 0.001871   Batch Acc: 90.62
[Train] Epoch: 1 [324992/387873]    Loss: 0.002161   Batch Acc: 88.28
[Train] Epoch: 1 [325120/387873]    Loss: 0.001851   Batch Acc: 92.19
[Train] Epoch: 1 [325248/387873]    Loss: 0.001922   Batch Acc: 90.62
[Train] Epoch: 1 [325376/387873]    Loss: 0.001799   Batch Acc: 90.62
[Train] Epoch: 1 [325504/387873]    Loss: 0.002140   Batch Acc: 88.28
[Train] Epoch: 1 [325632/387873]    Loss: 0.002137   Batch Acc: 87.50
[Train] Epoch: 1 [325760/387873]    Loss: 0.003106   Batch Acc: 82.81
[Train] Epoch: 1 [325888/387873]    Loss: 0.001966   Batch Acc: 89.84
[Train] Epoch: 1 [326016/387873]    Loss: 0.001694   Batch Acc: 94.53
[Train] Epoch: 1 [326144/387873]    Loss: 0.002392   Batch Acc: 87.50
[Train] Epoch: 1 [326272/387873]    Loss: 0.002097   Batch Acc: 88.28
[Train] Epoch: 1 [326400/387873]    Loss: 0.001997   Batch Acc: 92.19
[Train] Epoch: 1 [326528/387873]    Loss: 0.002102   Batch Acc: 89.06
[Train] Epoch: 1 [326656/387873]    Loss: 0.001885   Batch Acc: 88.28
[Train] Epoch: 1 [326784/387873]    Loss: 0.002234   Batch Acc: 88.28
[Train] Epoch: 1 [326912/387873]    Loss: 0.001734   Batch Acc: 92.19
[Train] Epoch: 1 [327040/387873]    Loss: 0.001806   Batch Acc: 92.19
[Train] Epoch: 1 [327168/387873]    Loss: 0.002538   Batch Acc: 85.16
[Train] Epoch: 1 [327296/387873]    Loss: 0.001821   Batch Acc: 89.84
[Train] Epoch: 1 [327424/387873]    Loss: 0.001895   Batch Acc: 89.84
[Train] Epoch: 1 [327552/387873]    Loss: 0.002136   Batch Acc: 85.94
[Train] Epoch: 1 [327680/387873]    Loss: 0.002088   Batch Acc: 89.06
[Train] Epoch: 1 [327808/387873]    Loss: 0.001448   Batch Acc: 96.88
[Train] Epoch: 1 [327936/387873]    Loss: 0.002060   Batch Acc: 86.72
[Train] Epoch: 1 [328064/387873]    Loss: 0.002117   Batch Acc: 91.41
[Train] Epoch: 1 [328192/387873]    Loss: 0.001567   Batch Acc: 93.75
[Train] Epoch: 1 [328320/387873]    Loss: 0.002168   Batch Acc: 87.50
[Train] Epoch: 1 [328448/387873]    Loss: 0.001971   Batch Acc: 91.41
[Train] Epoch: 1 [328576/387873]    Loss: 0.001555   Batch Acc: 94.53
[Train] Epoch: 1 [328704/387873]    Loss: 0.001608   Batch Acc: 92.19
[Train] Epoch: 1 [328832/387873]    Loss: 0.001296   Batch Acc: 95.31
[Train] Epoch: 1 [328960/387873]    Loss: 0.002069   Batch Acc: 89.06
[Train] Epoch: 1 [329088/387873]    Loss: 0.002158   Batch Acc: 87.50
[Train] Epoch: 1 [329216/387873]    Loss: 0.001848   Batch Acc: 92.97
[Train] Epoch: 1 [329344/387873]    Loss: 0.001607   Batch Acc: 93.75
[Train] Epoch: 1 [329472/387873]    Loss: 0.002179   Batch Acc: 86.72
[Train] Epoch: 1 [329600/387873]    Loss: 0.001220   Batch Acc: 97.66
[Train] Epoch: 1 [329728/387873]    Loss: 0.002261   Batch Acc: 87.50
[Train] Epoch: 1 [329856/387873]    Loss: 0.002027   Batch Acc: 88.28
[Train] Epoch: 1 [329984/387873]    Loss: 0.001456   Batch Acc: 94.53
[Train] Epoch: 1 [330112/387873]    Loss: 0.002582   Batch Acc: 85.16
[Train] Epoch: 1 [330240/387873]    Loss: 0.001934   Batch Acc: 89.84
[Train] Epoch: 1 [330368/387873]    Loss: 0.002528   Batch Acc: 85.94
[Train] Epoch: 1 [330496/387873]    Loss: 0.002579   Batch Acc: 84.38
[Train] Epoch: 1 [330624/387873]    Loss: 0.002053   Batch Acc: 88.28
[Train] Epoch: 1 [330752/387873]    Loss: 0.002690   Batch Acc: 85.16
[Train] Epoch: 1 [330880/387873]    Loss: 0.001901   Batch Acc: 89.84
[Train] Epoch: 1 [331008/387873]    Loss: 0.001999   Batch Acc: 92.19
[Train] Epoch: 1 [331136/387873]    Loss: 0.001817   Batch Acc: 89.06
[Train] Epoch: 1 [331264/387873]    Loss: 0.002127   Batch Acc: 91.41
[Train] Epoch: 1 [331392/387873]    Loss: 0.001817   Batch Acc: 94.53
[Train] Epoch: 1 [331520/387873]    Loss: 0.002211   Batch Acc: 87.50
[Train] Epoch: 1 [331648/387873]    Loss: 0.002002   Batch Acc: 85.94
[Train] Epoch: 1 [331776/387873]    Loss: 0.001982   Batch Acc: 91.41
[Train] Epoch: 1 [331904/387873]    Loss: 0.001761   Batch Acc: 92.19
[Train] Epoch: 1 [332032/387873]    Loss: 0.002156   Batch Acc: 89.84
[Train] Epoch: 1 [332160/387873]    Loss: 0.002158   Batch Acc: 85.16
[Train] Epoch: 1 [332288/387873]    Loss: 0.002280   Batch Acc: 82.81
[Train] Epoch: 1 [332416/387873]    Loss: 0.002504   Batch Acc: 85.94
[Train] Epoch: 1 [332544/387873]    Loss: 0.002247   Batch Acc: 84.38
[Train] Epoch: 1 [332672/387873]    Loss: 0.002087   Batch Acc: 90.62
[Train] Epoch: 1 [332800/387873]    Loss: 0.001961   Batch Acc: 89.84
[Train] Epoch: 1 [332928/387873]    Loss: 0.002247   Batch Acc: 85.94
[Train] Epoch: 1 [333056/387873]    Loss: 0.001440   Batch Acc: 93.75
[Train] Epoch: 1 [333184/387873]    Loss: 0.002225   Batch Acc: 85.94
[Train] Epoch: 1 [333312/387873]    Loss: 0.001621   Batch Acc: 92.19
[Train] Epoch: 1 [333440/387873]    Loss: 0.001669   Batch Acc: 93.75
[Train] Epoch: 1 [333568/387873]    Loss: 0.002166   Batch Acc: 89.06
[Train] Epoch: 1 [333696/387873]    Loss: 0.001826   Batch Acc: 90.62
[Train] Epoch: 1 [333824/387873]    Loss: 0.002294   Batch Acc: 86.72
[Train] Epoch: 1 [333952/387873]    Loss: 0.002052   Batch Acc: 89.06
[Train] Epoch: 1 [334080/387873]    Loss: 0.001910   Batch Acc: 89.84
[Train] Epoch: 1 [334208/387873]    Loss: 0.001857   Batch Acc: 92.19
[Train] Epoch: 1 [334336/387873]    Loss: 0.002597   Batch Acc: 84.38
[Train] Epoch: 1 [334464/387873]    Loss: 0.002004   Batch Acc: 89.84
[Train] Epoch: 1 [334592/387873]    Loss: 0.001624   Batch Acc: 93.75
[Train] Epoch: 1 [334720/387873]    Loss: 0.002141   Batch Acc: 89.84
[Train] Epoch: 1 [334848/387873]    Loss: 0.002054   Batch Acc: 90.62
[Train] Epoch: 1 [334976/387873]    Loss: 0.002398   Batch Acc: 86.72
[Train] Epoch: 1 [335104/387873]    Loss: 0.002340   Batch Acc: 87.50
[Train] Epoch: 1 [335232/387873]    Loss: 0.002339   Batch Acc: 88.28
[Train] Epoch: 1 [335360/387873]    Loss: 0.002414   Batch Acc: 85.94
[Train] Epoch: 1 [335488/387873]    Loss: 0.002353   Batch Acc: 88.28
[Train] Epoch: 1 [335616/387873]    Loss: 0.001644   Batch Acc: 94.53
[Train] Epoch: 1 [335744/387873]    Loss: 0.002297   Batch Acc: 89.06
[Train] Epoch: 1 [335872/387873]    Loss: 0.001817   Batch Acc: 89.84
[Train] Epoch: 1 [336000/387873]    Loss: 0.001364   Batch Acc: 94.53
[Train] Epoch: 1 [336128/387873]    Loss: 0.001548   Batch Acc: 92.19
[Train] Epoch: 1 [336256/387873]    Loss: 0.002232   Batch Acc: 86.72
[Train] Epoch: 1 [336384/387873]    Loss: 0.001849   Batch Acc: 90.62
[Train] Epoch: 1 [336512/387873]    Loss: 0.002150   Batch Acc: 89.06
[Train] Epoch: 1 [336640/387873]    Loss: 0.002299   Batch Acc: 85.16
[Train] Epoch: 1 [336768/387873]    Loss: 0.002472   Batch Acc: 88.28
[Train] Epoch: 1 [336896/387873]    Loss: 0.002274   Batch Acc: 88.28
[Train] Epoch: 1 [337024/387873]    Loss: 0.001863   Batch Acc: 89.06
[Train] Epoch: 1 [337152/387873]    Loss: 0.002111   Batch Acc: 89.06
[Train] Epoch: 1 [337280/387873]    Loss: 0.002205   Batch Acc: 90.62
[Train] Epoch: 1 [337408/387873]    Loss: 0.001878   Batch Acc: 92.19
[Train] Epoch: 1 [337536/387873]    Loss: 0.002192   Batch Acc: 89.06
[Train] Epoch: 1 [337664/387873]    Loss: 0.002385   Batch Acc: 87.50
[Train] Epoch: 1 [337792/387873]    Loss: 0.002026   Batch Acc: 89.06
[Train] Epoch: 1 [337920/387873]    Loss: 0.002440   Batch Acc: 87.50
[Train] Epoch: 1 [338048/387873]    Loss: 0.002438   Batch Acc: 89.06
[Train] Epoch: 1 [338176/387873]    Loss: 0.001439   Batch Acc: 93.75
[Train] Epoch: 1 [338304/387873]    Loss: 0.001890   Batch Acc: 90.62
[Train] Epoch: 1 [338432/387873]    Loss: 0.002363   Batch Acc: 84.38
[Train] Epoch: 1 [338560/387873]    Loss: 0.002184   Batch Acc: 90.62
[Train] Epoch: 1 [338688/387873]    Loss: 0.001965   Batch Acc: 89.84
[Train] Epoch: 1 [338816/387873]    Loss: 0.002551   Batch Acc: 86.72
[Train] Epoch: 1 [338944/387873]    Loss: 0.001725   Batch Acc: 92.19
[Train] Epoch: 1 [339072/387873]    Loss: 0.001966   Batch Acc: 89.06
[Train] Epoch: 1 [339200/387873]    Loss: 0.001873   Batch Acc: 92.19
[Train] Epoch: 1 [339328/387873]    Loss: 0.001823   Batch Acc: 89.84
[Train] Epoch: 1 [339456/387873]    Loss: 0.002837   Batch Acc: 83.59
[Train] Epoch: 1 [339584/387873]    Loss: 0.001894   Batch Acc: 90.62
[Train] Epoch: 1 [339712/387873]    Loss: 0.002048   Batch Acc: 89.84
[Train] Epoch: 1 [339840/387873]    Loss: 0.001994   Batch Acc: 88.28
[Train] Epoch: 1 [339968/387873]    Loss: 0.001944   Batch Acc: 86.72
[Train] Epoch: 1 [340096/387873]    Loss: 0.002405   Batch Acc: 86.72
[Train] Epoch: 1 [340224/387873]    Loss: 0.002194   Batch Acc: 86.72
[Train] Epoch: 1 [340352/387873]    Loss: 0.001901   Batch Acc: 88.28
[Train] Epoch: 1 [340480/387873]    Loss: 0.001943   Batch Acc: 89.84
[Train] Epoch: 1 [340608/387873]    Loss: 0.002362   Batch Acc: 87.50
[Train] Epoch: 1 [340736/387873]    Loss: 0.002114   Batch Acc: 85.16
[Train] Epoch: 1 [340864/387873]    Loss: 0.002313   Batch Acc: 85.94
[Train] Epoch: 1 [340992/387873]    Loss: 0.001463   Batch Acc: 93.75
[Train] Epoch: 1 [341120/387873]    Loss: 0.002415   Batch Acc: 86.72
[Train] Epoch: 1 [341248/387873]    Loss: 0.001793   Batch Acc: 91.41
[Train] Epoch: 1 [341376/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 1 [341504/387873]    Loss: 0.002223   Batch Acc: 90.62
[Train] Epoch: 1 [341632/387873]    Loss: 0.001629   Batch Acc: 91.41
[Train] Epoch: 1 [341760/387873]    Loss: 0.002810   Batch Acc: 87.50
[Train] Epoch: 1 [341888/387873]    Loss: 0.002875   Batch Acc: 82.81
[Train] Epoch: 1 [342016/387873]    Loss: 0.001924   Batch Acc: 89.84
[Train] Epoch: 1 [342144/387873]    Loss: 0.001978   Batch Acc: 92.19
[Train] Epoch: 1 [342272/387873]    Loss: 0.002437   Batch Acc: 85.16
[Train] Epoch: 1 [342400/387873]    Loss: 0.002293   Batch Acc: 85.16
[Train] Epoch: 1 [342528/387873]    Loss: 0.001775   Batch Acc: 91.41
[Train] Epoch: 1 [342656/387873]    Loss: 0.001593   Batch Acc: 92.97
[Train] Epoch: 1 [342784/387873]    Loss: 0.001608   Batch Acc: 92.97
[Train] Epoch: 1 [342912/387873]    Loss: 0.002047   Batch Acc: 89.06
[Train] Epoch: 1 [343040/387873]    Loss: 0.002428   Batch Acc: 86.72
[Train] Epoch: 1 [343168/387873]    Loss: 0.002461   Batch Acc: 85.16
[Train] Epoch: 1 [343296/387873]    Loss: 0.002404   Batch Acc: 86.72
[Train] Epoch: 1 [343424/387873]    Loss: 0.002232   Batch Acc: 89.06
[Train] Epoch: 1 [343552/387873]    Loss: 0.001874   Batch Acc: 89.06
[Train] Epoch: 1 [343680/387873]    Loss: 0.002557   Batch Acc: 84.38
[Train] Epoch: 1 [343808/387873]    Loss: 0.001917   Batch Acc: 91.41
[Train] Epoch: 1 [343936/387873]    Loss: 0.001782   Batch Acc: 89.84
[Train] Epoch: 1 [344064/387873]    Loss: 0.002090   Batch Acc: 89.06
[Train] Epoch: 1 [344192/387873]    Loss: 0.002154   Batch Acc: 86.72
[Train] Epoch: 1 [344320/387873]    Loss: 0.001749   Batch Acc: 90.62
[Train] Epoch: 1 [344448/387873]    Loss: 0.002165   Batch Acc: 87.50
[Train] Epoch: 1 [344576/387873]    Loss: 0.001656   Batch Acc: 91.41
[Train] Epoch: 1 [344704/387873]    Loss: 0.002243   Batch Acc: 86.72
[Train] Epoch: 1 [344832/387873]    Loss: 0.002326   Batch Acc: 88.28
[Train] Epoch: 1 [344960/387873]    Loss: 0.002196   Batch Acc: 89.06
[Train] Epoch: 1 [345088/387873]    Loss: 0.001934   Batch Acc: 89.06
[Train] Epoch: 1 [345216/387873]    Loss: 0.002266   Batch Acc: 89.84
[Train] Epoch: 1 [345344/387873]    Loss: 0.001823   Batch Acc: 90.62
[Train] Epoch: 1 [345472/387873]    Loss: 0.002011   Batch Acc: 89.84
[Train] Epoch: 1 [345600/387873]    Loss: 0.001999   Batch Acc: 87.50
[Train] Epoch: 1 [345728/387873]    Loss: 0.002292   Batch Acc: 88.28
[Train] Epoch: 1 [345856/387873]    Loss: 0.002463   Batch Acc: 87.50
[Train] Epoch: 1 [345984/387873]    Loss: 0.001624   Batch Acc: 91.41
[Train] Epoch: 1 [346112/387873]    Loss: 0.001627   Batch Acc: 93.75
[Train] Epoch: 1 [346240/387873]    Loss: 0.001884   Batch Acc: 91.41
[Train] Epoch: 1 [346368/387873]    Loss: 0.001829   Batch Acc: 90.62
[Train] Epoch: 1 [346496/387873]    Loss: 0.002184   Batch Acc: 87.50
[Train] Epoch: 1 [346624/387873]    Loss: 0.002115   Batch Acc: 85.94
[Train] Epoch: 1 [346752/387873]    Loss: 0.002345   Batch Acc: 87.50
[Train] Epoch: 1 [346880/387873]    Loss: 0.002620   Batch Acc: 82.03
[Train] Epoch: 1 [347008/387873]    Loss: 0.002180   Batch Acc: 86.72
[Train] Epoch: 1 [347136/387873]    Loss: 0.002211   Batch Acc: 87.50
[Train] Epoch: 1 [347264/387873]    Loss: 0.002091   Batch Acc: 90.62
[Train] Epoch: 1 [347392/387873]    Loss: 0.001849   Batch Acc: 91.41
[Train] Epoch: 1 [347520/387873]    Loss: 0.001795   Batch Acc: 91.41
[Train] Epoch: 1 [347648/387873]    Loss: 0.001513   Batch Acc: 92.19
[Train] Epoch: 1 [347776/387873]    Loss: 0.002225   Batch Acc: 88.28
[Train] Epoch: 1 [347904/387873]    Loss: 0.002197   Batch Acc: 86.72
[Train] Epoch: 1 [348032/387873]    Loss: 0.001930   Batch Acc: 88.28
[Train] Epoch: 1 [348160/387873]    Loss: 0.002539   Batch Acc: 86.72
[Train] Epoch: 1 [348288/387873]    Loss: 0.001979   Batch Acc: 86.72
[Train] Epoch: 1 [348416/387873]    Loss: 0.001977   Batch Acc: 90.62
[Train] Epoch: 1 [348544/387873]    Loss: 0.002212   Batch Acc: 89.84
[Train] Epoch: 1 [348672/387873]    Loss: 0.002187   Batch Acc: 88.28
[Train] Epoch: 1 [348800/387873]    Loss: 0.001396   Batch Acc: 93.75
[Train] Epoch: 1 [348928/387873]    Loss: 0.001881   Batch Acc: 89.84
[Train] Epoch: 1 [349056/387873]    Loss: 0.002182   Batch Acc: 86.72
[Train] Epoch: 1 [349184/387873]    Loss: 0.002274   Batch Acc: 86.72
[Train] Epoch: 1 [349312/387873]    Loss: 0.002134   Batch Acc: 87.50
[Train] Epoch: 1 [349440/387873]    Loss: 0.001730   Batch Acc: 92.19
[Train] Epoch: 1 [349568/387873]    Loss: 0.002252   Batch Acc: 88.28
[Train] Epoch: 1 [349696/387873]    Loss: 0.002142   Batch Acc: 86.72
[Train] Epoch: 1 [349824/387873]    Loss: 0.001987   Batch Acc: 90.62
[Train] Epoch: 1 [349952/387873]    Loss: 0.001977   Batch Acc: 89.06
[Train] Epoch: 1 [350080/387873]    Loss: 0.001985   Batch Acc: 88.28
[Train] Epoch: 1 [350208/387873]    Loss: 0.001803   Batch Acc: 90.62
[Train] Epoch: 1 [350336/387873]    Loss: 0.002140   Batch Acc: 88.28
[Train] Epoch: 1 [350464/387873]    Loss: 0.001975   Batch Acc: 88.28
[Train] Epoch: 1 [350592/387873]    Loss: 0.002062   Batch Acc: 87.50
[Train] Epoch: 1 [350720/387873]    Loss: 0.001815   Batch Acc: 92.19
[Train] Epoch: 1 [350848/387873]    Loss: 0.002109   Batch Acc: 88.28
[Train] Epoch: 1 [350976/387873]    Loss: 0.001577   Batch Acc: 92.19
[Train] Epoch: 1 [351104/387873]    Loss: 0.002002   Batch Acc: 90.62
[Train] Epoch: 1 [351232/387873]    Loss: 0.001672   Batch Acc: 90.62
[Train] Epoch: 1 [351360/387873]    Loss: 0.001456   Batch Acc: 95.31
[Train] Epoch: 1 [351488/387873]    Loss: 0.002234   Batch Acc: 88.28
[Train] Epoch: 1 [351616/387873]    Loss: 0.001899   Batch Acc: 89.84
[Train] Epoch: 1 [351744/387873]    Loss: 0.001957   Batch Acc: 90.62
[Train] Epoch: 1 [351872/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 1 [352000/387873]    Loss: 0.001741   Batch Acc: 94.53
[Train] Epoch: 1 [352128/387873]    Loss: 0.002019   Batch Acc: 90.62
[Train] Epoch: 1 [352256/387873]    Loss: 0.002482   Batch Acc: 85.16
[Train] Epoch: 1 [352384/387873]    Loss: 0.002292   Batch Acc: 88.28
[Train] Epoch: 1 [352512/387873]    Loss: 0.002043   Batch Acc: 89.06
[Train] Epoch: 1 [352640/387873]    Loss: 0.001815   Batch Acc: 92.97
[Train] Epoch: 1 [352768/387873]    Loss: 0.001635   Batch Acc: 93.75
[Train] Epoch: 1 [352896/387873]    Loss: 0.001540   Batch Acc: 93.75
[Train] Epoch: 1 [353024/387873]    Loss: 0.001837   Batch Acc: 89.06
[Train] Epoch: 1 [353152/387873]    Loss: 0.001955   Batch Acc: 90.62
[Train] Epoch: 1 [353280/387873]    Loss: 0.002250   Batch Acc: 89.06
[Train] Epoch: 1 [353408/387873]    Loss: 0.002607   Batch Acc: 82.03
[Train] Epoch: 1 [353536/387873]    Loss: 0.002216   Batch Acc: 86.72
[Train] Epoch: 1 [353664/387873]    Loss: 0.002092   Batch Acc: 86.72
[Train] Epoch: 1 [353792/387873]    Loss: 0.002017   Batch Acc: 89.84
[Train] Epoch: 1 [353920/387873]    Loss: 0.001755   Batch Acc: 92.97
[Train] Epoch: 1 [354048/387873]    Loss: 0.002228   Batch Acc: 87.50
[Train] Epoch: 1 [354176/387873]    Loss: 0.001951   Batch Acc: 89.84
[Train] Epoch: 1 [354304/387873]    Loss: 0.002335   Batch Acc: 88.28
[Train] Epoch: 1 [354432/387873]    Loss: 0.002022   Batch Acc: 87.50
[Train] Epoch: 1 [354560/387873]    Loss: 0.002276   Batch Acc: 88.28
[Train] Epoch: 1 [354688/387873]    Loss: 0.002345   Batch Acc: 86.72
[Train] Epoch: 1 [354816/387873]    Loss: 0.001678   Batch Acc: 91.41
[Train] Epoch: 1 [354944/387873]    Loss: 0.002368   Batch Acc: 89.06
[Train] Epoch: 1 [355072/387873]    Loss: 0.001990   Batch Acc: 89.06
[Train] Epoch: 1 [355200/387873]    Loss: 0.002468   Batch Acc: 87.50
[Train] Epoch: 1 [355328/387873]    Loss: 0.002364   Batch Acc: 86.72
[Train] Epoch: 1 [355456/387873]    Loss: 0.001787   Batch Acc: 89.06
[Train] Epoch: 1 [355584/387873]    Loss: 0.002355   Batch Acc: 85.94
[Train] Epoch: 1 [355712/387873]    Loss: 0.002706   Batch Acc: 82.81
[Train] Epoch: 1 [355840/387873]    Loss: 0.002091   Batch Acc: 89.84
[Train] Epoch: 1 [355968/387873]    Loss: 0.002558   Batch Acc: 85.94
[Train] Epoch: 1 [356096/387873]    Loss: 0.002349   Batch Acc: 85.94
[Train] Epoch: 1 [356224/387873]    Loss: 0.001845   Batch Acc: 90.62
[Train] Epoch: 1 [356352/387873]    Loss: 0.002102   Batch Acc: 86.72
[Train] Epoch: 1 [356480/387873]    Loss: 0.002326   Batch Acc: 85.16
[Train] Epoch: 1 [356608/387873]    Loss: 0.001753   Batch Acc: 91.41
[Train] Epoch: 1 [356736/387873]    Loss: 0.001578   Batch Acc: 92.97
[Train] Epoch: 1 [356864/387873]    Loss: 0.001636   Batch Acc: 92.19
[Train] Epoch: 1 [356992/387873]    Loss: 0.001609   Batch Acc: 94.53
[Train] Epoch: 1 [357120/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 1 [357248/387873]    Loss: 0.001954   Batch Acc: 89.84
[Train] Epoch: 1 [357376/387873]    Loss: 0.002344   Batch Acc: 84.38
[Train] Epoch: 1 [357504/387873]    Loss: 0.001728   Batch Acc: 89.84
[Train] Epoch: 1 [357632/387873]    Loss: 0.002735   Batch Acc: 85.16
[Train] Epoch: 1 [357760/387873]    Loss: 0.001997   Batch Acc: 91.41
[Train] Epoch: 1 [357888/387873]    Loss: 0.001899   Batch Acc: 91.41
[Train] Epoch: 1 [358016/387873]    Loss: 0.002023   Batch Acc: 89.84
[Train] Epoch: 1 [358144/387873]    Loss: 0.002000   Batch Acc: 92.97
[Train] Epoch: 1 [358272/387873]    Loss: 0.002422   Batch Acc: 86.72
[Train] Epoch: 1 [358400/387873]    Loss: 0.001885   Batch Acc: 86.72
[Train] Epoch: 1 [358528/387873]    Loss: 0.001986   Batch Acc: 89.06
[Train] Epoch: 1 [358656/387873]    Loss: 0.002193   Batch Acc: 88.28
[Train] Epoch: 1 [358784/387873]    Loss: 0.002401   Batch Acc: 89.06
[Train] Epoch: 1 [358912/387873]    Loss: 0.002277   Batch Acc: 88.28
[Train] Epoch: 1 [359040/387873]    Loss: 0.002521   Batch Acc: 85.94
[Train] Epoch: 1 [359168/387873]    Loss: 0.002420   Batch Acc: 87.50
[Train] Epoch: 1 [359296/387873]    Loss: 0.002084   Batch Acc: 89.84
[Train] Epoch: 1 [359424/387873]    Loss: 0.002194   Batch Acc: 86.72
[Train] Epoch: 1 [359552/387873]    Loss: 0.001737   Batch Acc: 92.19
[Train] Epoch: 1 [359680/387873]    Loss: 0.001672   Batch Acc: 91.41
[Train] Epoch: 1 [359808/387873]    Loss: 0.002497   Batch Acc: 85.94
[Train] Epoch: 1 [359936/387873]    Loss: 0.002697   Batch Acc: 85.16
[Train] Epoch: 1 [360064/387873]    Loss: 0.001888   Batch Acc: 90.62
[Train] Epoch: 1 [360192/387873]    Loss: 0.002030   Batch Acc: 89.06
[Train] Epoch: 1 [360320/387873]    Loss: 0.001914   Batch Acc: 89.06
[Train] Epoch: 1 [360448/387873]    Loss: 0.002224   Batch Acc: 87.50
[Train] Epoch: 1 [360576/387873]    Loss: 0.001907   Batch Acc: 89.06
[Train] Epoch: 1 [360704/387873]    Loss: 0.002264   Batch Acc: 89.06
[Train] Epoch: 1 [360832/387873]    Loss: 0.002254   Batch Acc: 86.72
[Train] Epoch: 1 [360960/387873]    Loss: 0.002010   Batch Acc: 89.06
[Train] Epoch: 1 [361088/387873]    Loss: 0.001980   Batch Acc: 89.84
[Train] Epoch: 1 [361216/387873]    Loss: 0.002187   Batch Acc: 90.62
[Train] Epoch: 1 [361344/387873]    Loss: 0.001971   Batch Acc: 89.84
[Train] Epoch: 1 [361472/387873]    Loss: 0.001976   Batch Acc: 90.62
[Train] Epoch: 1 [361600/387873]    Loss: 0.002085   Batch Acc: 89.84
[Train] Epoch: 1 [361728/387873]    Loss: 0.001758   Batch Acc: 90.62
[Train] Epoch: 1 [361856/387873]    Loss: 0.001701   Batch Acc: 90.62
[Train] Epoch: 1 [361984/387873]    Loss: 0.002382   Batch Acc: 85.94
[Train] Epoch: 1 [362112/387873]    Loss: 0.002314   Batch Acc: 87.50
[Train] Epoch: 1 [362240/387873]    Loss: 0.002016   Batch Acc: 89.06
[Train] Epoch: 1 [362368/387873]    Loss: 0.001983   Batch Acc: 89.06
[Train] Epoch: 1 [362496/387873]    Loss: 0.002293   Batch Acc: 85.16
[Train] Epoch: 1 [362624/387873]    Loss: 0.002191   Batch Acc: 88.28
[Train] Epoch: 1 [362752/387873]    Loss: 0.001841   Batch Acc: 90.62
[Train] Epoch: 1 [362880/387873]    Loss: 0.001980   Batch Acc: 90.62
[Train] Epoch: 1 [363008/387873]    Loss: 0.002074   Batch Acc: 89.06
[Train] Epoch: 1 [363136/387873]    Loss: 0.001953   Batch Acc: 89.06
[Train] Epoch: 1 [363264/387873]    Loss: 0.001991   Batch Acc: 87.50
[Train] Epoch: 1 [363392/387873]    Loss: 0.002046   Batch Acc: 88.28
[Train] Epoch: 1 [363520/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 1 [363648/387873]    Loss: 0.001744   Batch Acc: 89.84
[Train] Epoch: 1 [363776/387873]    Loss: 0.001967   Batch Acc: 89.84
[Train] Epoch: 1 [363904/387873]    Loss: 0.002022   Batch Acc: 88.28
[Train] Epoch: 1 [364032/387873]    Loss: 0.002027   Batch Acc: 90.62
[Train] Epoch: 1 [364160/387873]    Loss: 0.002547   Batch Acc: 88.28
[Train] Epoch: 1 [364288/387873]    Loss: 0.002424   Batch Acc: 85.94
[Train] Epoch: 1 [364416/387873]    Loss: 0.002481   Batch Acc: 85.94
[Train] Epoch: 1 [364544/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 1 [364672/387873]    Loss: 0.001639   Batch Acc: 92.19
[Train] Epoch: 1 [364800/387873]    Loss: 0.002268   Batch Acc: 85.16
[Train] Epoch: 1 [364928/387873]    Loss: 0.001763   Batch Acc: 93.75
[Train] Epoch: 1 [365056/387873]    Loss: 0.002239   Batch Acc: 89.06
[Train] Epoch: 1 [365184/387873]    Loss: 0.001783   Batch Acc: 89.06
[Train] Epoch: 1 [365312/387873]    Loss: 0.001756   Batch Acc: 91.41
[Train] Epoch: 1 [365440/387873]    Loss: 0.002033   Batch Acc: 87.50
[Train] Epoch: 1 [365568/387873]    Loss: 0.001619   Batch Acc: 92.19
[Train] Epoch: 1 [365696/387873]    Loss: 0.002065   Batch Acc: 90.62
[Train] Epoch: 1 [365824/387873]    Loss: 0.001894   Batch Acc: 87.50
[Train] Epoch: 1 [365952/387873]    Loss: 0.002373   Batch Acc: 85.94
[Train] Epoch: 1 [366080/387873]    Loss: 0.001875   Batch Acc: 90.62
[Train] Epoch: 1 [366208/387873]    Loss: 0.001567   Batch Acc: 92.97
[Train] Epoch: 1 [366336/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 1 [366464/387873]    Loss: 0.001990   Batch Acc: 89.06
[Train] Epoch: 1 [366592/387873]    Loss: 0.002370   Batch Acc: 88.28
[Train] Epoch: 1 [366720/387873]    Loss: 0.001945   Batch Acc: 89.84
[Train] Epoch: 1 [366848/387873]    Loss: 0.001783   Batch Acc: 90.62
[Train] Epoch: 1 [366976/387873]    Loss: 0.002347   Batch Acc: 85.16
[Train] Epoch: 1 [367104/387873]    Loss: 0.001783   Batch Acc: 92.19
[Train] Epoch: 1 [367232/387873]    Loss: 0.001543   Batch Acc: 93.75
[Train] Epoch: 1 [367360/387873]    Loss: 0.001957   Batch Acc: 90.62
[Train] Epoch: 1 [367488/387873]    Loss: 0.002453   Batch Acc: 87.50
[Train] Epoch: 1 [367616/387873]    Loss: 0.002231   Batch Acc: 85.94
[Train] Epoch: 1 [367744/387873]    Loss: 0.001684   Batch Acc: 92.19
[Train] Epoch: 1 [367872/387873]    Loss: 0.002033   Batch Acc: 86.72
[Train] Epoch: 1 [368000/387873]    Loss: 0.002494   Batch Acc: 84.38
[Train] Epoch: 1 [368128/387873]    Loss: 0.001790   Batch Acc: 89.06
[Train] Epoch: 1 [368256/387873]    Loss: 0.002752   Batch Acc: 83.59
[Train] Epoch: 1 [368384/387873]    Loss: 0.001853   Batch Acc: 92.19
[Train] Epoch: 1 [368512/387873]    Loss: 0.002288   Batch Acc: 86.72
[Train] Epoch: 1 [368640/387873]    Loss: 0.001817   Batch Acc: 92.19
[Train] Epoch: 1 [368768/387873]    Loss: 0.001746   Batch Acc: 89.06
[Train] Epoch: 1 [368896/387873]    Loss: 0.002441   Batch Acc: 84.38
[Train] Epoch: 1 [369024/387873]    Loss: 0.001890   Batch Acc: 89.84
[Train] Epoch: 1 [369152/387873]    Loss: 0.001902   Batch Acc: 91.41
[Train] Epoch: 1 [369280/387873]    Loss: 0.002049   Batch Acc: 89.06
[Train] Epoch: 1 [369408/387873]    Loss: 0.002537   Batch Acc: 82.81
[Train] Epoch: 1 [369536/387873]    Loss: 0.001691   Batch Acc: 92.19
[Train] Epoch: 1 [369664/387873]    Loss: 0.002440   Batch Acc: 85.94
[Train] Epoch: 1 [369792/387873]    Loss: 0.001986   Batch Acc: 92.19
[Train] Epoch: 1 [369920/387873]    Loss: 0.002388   Batch Acc: 85.16
[Train] Epoch: 1 [370048/387873]    Loss: 0.001499   Batch Acc: 93.75
[Train] Epoch: 1 [370176/387873]    Loss: 0.002390   Batch Acc: 86.72
[Train] Epoch: 1 [370304/387873]    Loss: 0.001593   Batch Acc: 92.97
[Train] Epoch: 1 [370432/387873]    Loss: 0.002263   Batch Acc: 86.72
[Train] Epoch: 1 [370560/387873]    Loss: 0.001913   Batch Acc: 90.62
[Train] Epoch: 1 [370688/387873]    Loss: 0.001759   Batch Acc: 95.31
[Train] Epoch: 1 [370816/387873]    Loss: 0.001971   Batch Acc: 89.06
[Train] Epoch: 1 [370944/387873]    Loss: 0.002233   Batch Acc: 85.16
[Train] Epoch: 1 [371072/387873]    Loss: 0.002481   Batch Acc: 82.81
[Train] Epoch: 1 [371200/387873]    Loss: 0.002046   Batch Acc: 90.62
[Train] Epoch: 1 [371328/387873]    Loss: 0.002460   Batch Acc: 86.72
[Train] Epoch: 1 [371456/387873]    Loss: 0.001931   Batch Acc: 92.97
[Train] Epoch: 1 [371584/387873]    Loss: 0.001659   Batch Acc: 91.41
[Train] Epoch: 1 [371712/387873]    Loss: 0.002347   Batch Acc: 85.94
[Train] Epoch: 1 [371840/387873]    Loss: 0.002064   Batch Acc: 89.84
[Train] Epoch: 1 [371968/387873]    Loss: 0.001540   Batch Acc: 92.19
[Train] Epoch: 1 [372096/387873]    Loss: 0.002774   Batch Acc: 82.81
[Train] Epoch: 1 [372224/387873]    Loss: 0.002428   Batch Acc: 85.16
[Train] Epoch: 1 [372352/387873]    Loss: 0.002185   Batch Acc: 90.62
[Train] Epoch: 1 [372480/387873]    Loss: 0.001686   Batch Acc: 92.19
[Train] Epoch: 1 [372608/387873]    Loss: 0.002067   Batch Acc: 89.06
[Train] Epoch: 1 [372736/387873]    Loss: 0.002346   Batch Acc: 86.72
[Train] Epoch: 1 [372864/387873]    Loss: 0.002371   Batch Acc: 86.72
[Train] Epoch: 1 [372992/387873]    Loss: 0.001938   Batch Acc: 92.19
[Train] Epoch: 1 [373120/387873]    Loss: 0.002122   Batch Acc: 91.41
[Train] Epoch: 1 [373248/387873]    Loss: 0.002116   Batch Acc: 87.50
[Train] Epoch: 1 [373376/387873]    Loss: 0.002103   Batch Acc: 89.84
[Train] Epoch: 1 [373504/387873]    Loss: 0.002277   Batch Acc: 89.06
[Train] Epoch: 1 [373632/387873]    Loss: 0.002869   Batch Acc: 82.03
[Train] Epoch: 1 [373760/387873]    Loss: 0.001885   Batch Acc: 88.28
[Train] Epoch: 1 [373888/387873]    Loss: 0.001991   Batch Acc: 91.41
[Train] Epoch: 1 [374016/387873]    Loss: 0.001831   Batch Acc: 92.19
[Train] Epoch: 1 [374144/387873]    Loss: 0.002054   Batch Acc: 88.28
[Train] Epoch: 1 [374272/387873]    Loss: 0.002016   Batch Acc: 90.62
[Train] Epoch: 1 [374400/387873]    Loss: 0.002457   Batch Acc: 86.72
[Train] Epoch: 1 [374528/387873]    Loss: 0.001818   Batch Acc: 92.97
[Train] Epoch: 1 [374656/387873]    Loss: 0.001850   Batch Acc: 89.84
[Train] Epoch: 1 [374784/387873]    Loss: 0.002301   Batch Acc: 89.84
[Train] Epoch: 1 [374912/387873]    Loss: 0.001711   Batch Acc: 92.97
[Train] Epoch: 1 [375040/387873]    Loss: 0.002133   Batch Acc: 87.50
[Train] Epoch: 1 [375168/387873]    Loss: 0.001860   Batch Acc: 93.75
[Train] Epoch: 1 [375296/387873]    Loss: 0.002065   Batch Acc: 90.62
[Train] Epoch: 1 [375424/387873]    Loss: 0.002348   Batch Acc: 88.28
[Train] Epoch: 1 [375552/387873]    Loss: 0.002360   Batch Acc: 86.72
[Train] Epoch: 1 [375680/387873]    Loss: 0.001702   Batch Acc: 89.84
[Train] Epoch: 1 [375808/387873]    Loss: 0.001613   Batch Acc: 91.41
[Train] Epoch: 1 [375936/387873]    Loss: 0.002711   Batch Acc: 82.03
[Train] Epoch: 1 [376064/387873]    Loss: 0.001989   Batch Acc: 88.28
[Train] Epoch: 1 [376192/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 1 [376320/387873]    Loss: 0.001998   Batch Acc: 89.84
[Train] Epoch: 1 [376448/387873]    Loss: 0.002078   Batch Acc: 89.06
[Train] Epoch: 1 [376576/387873]    Loss: 0.002287   Batch Acc: 88.28
[Train] Epoch: 1 [376704/387873]    Loss: 0.002016   Batch Acc: 90.62
[Train] Epoch: 1 [376832/387873]    Loss: 0.002249   Batch Acc: 88.28
[Train] Epoch: 1 [376960/387873]    Loss: 0.002073   Batch Acc: 88.28
[Train] Epoch: 1 [377088/387873]    Loss: 0.002329   Batch Acc: 88.28
[Train] Epoch: 1 [377216/387873]    Loss: 0.002189   Batch Acc: 86.72
[Train] Epoch: 1 [377344/387873]    Loss: 0.002006   Batch Acc: 88.28
[Train] Epoch: 1 [377472/387873]    Loss: 0.002184   Batch Acc: 88.28
[Train] Epoch: 1 [377600/387873]    Loss: 0.002242   Batch Acc: 85.94
[Train] Epoch: 1 [377728/387873]    Loss: 0.002196   Batch Acc: 87.50
[Train] Epoch: 1 [377856/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 1 [377984/387873]    Loss: 0.001801   Batch Acc: 92.19
[Train] Epoch: 1 [378112/387873]    Loss: 0.001799   Batch Acc: 88.28
[Train] Epoch: 1 [378240/387873]    Loss: 0.002455   Batch Acc: 88.28
[Train] Epoch: 1 [378368/387873]    Loss: 0.001942   Batch Acc: 92.97
[Train] Epoch: 1 [378496/387873]    Loss: 0.001930   Batch Acc: 90.62
[Train] Epoch: 1 [378624/387873]    Loss: 0.002031   Batch Acc: 89.84
[Train] Epoch: 1 [378752/387873]    Loss: 0.001830   Batch Acc: 91.41
[Train] Epoch: 1 [378880/387873]    Loss: 0.002860   Batch Acc: 80.47
[Train] Epoch: 1 [379008/387873]    Loss: 0.001800   Batch Acc: 95.31
[Train] Epoch: 1 [379136/387873]    Loss: 0.001918   Batch Acc: 91.41
[Train] Epoch: 1 [379264/387873]    Loss: 0.001770   Batch Acc: 89.84
[Train] Epoch: 1 [379392/387873]    Loss: 0.002018   Batch Acc: 85.94
[Train] Epoch: 1 [379520/387873]    Loss: 0.002054   Batch Acc: 89.06
[Train] Epoch: 1 [379648/387873]    Loss: 0.001814   Batch Acc: 89.84
[Train] Epoch: 1 [379776/387873]    Loss: 0.002665   Batch Acc: 82.81
[Train] Epoch: 1 [379904/387873]    Loss: 0.002041   Batch Acc: 87.50
[Train] Epoch: 1 [380032/387873]    Loss: 0.002757   Batch Acc: 85.94
[Train] Epoch: 1 [380160/387873]    Loss: 0.001706   Batch Acc: 91.41
[Train] Epoch: 1 [380288/387873]    Loss: 0.002036   Batch Acc: 88.28
[Train] Epoch: 1 [380416/387873]    Loss: 0.002514   Batch Acc: 84.38
[Train] Epoch: 1 [380544/387873]    Loss: 0.002207   Batch Acc: 89.84
[Train] Epoch: 1 [380672/387873]    Loss: 0.002434   Batch Acc: 88.28
[Train] Epoch: 1 [380800/387873]    Loss: 0.002094   Batch Acc: 90.62
[Train] Epoch: 1 [380928/387873]    Loss: 0.001944   Batch Acc: 89.06
[Train] Epoch: 1 [381056/387873]    Loss: 0.002189   Batch Acc: 86.72
[Train] Epoch: 1 [381184/387873]    Loss: 0.001766   Batch Acc: 91.41
[Train] Epoch: 1 [381312/387873]    Loss: 0.002167   Batch Acc: 87.50
[Train] Epoch: 1 [381440/387873]    Loss: 0.001765   Batch Acc: 91.41
[Train] Epoch: 1 [381568/387873]    Loss: 0.002545   Batch Acc: 85.94
[Train] Epoch: 1 [381696/387873]    Loss: 0.001928   Batch Acc: 89.06
[Train] Epoch: 1 [381824/387873]    Loss: 0.003594   Batch Acc: 77.34
[Train] Epoch: 1 [381952/387873]    Loss: 0.002162   Batch Acc: 89.06
[Train] Epoch: 1 [382080/387873]    Loss: 0.002277   Batch Acc: 87.50
[Train] Epoch: 1 [382208/387873]    Loss: 0.002303   Batch Acc: 87.50
[Train] Epoch: 1 [382336/387873]    Loss: 0.001719   Batch Acc: 91.41
[Train] Epoch: 1 [382464/387873]    Loss: 0.002617   Batch Acc: 85.16
[Train] Epoch: 1 [382592/387873]    Loss: 0.002345   Batch Acc: 83.59
[Train] Epoch: 1 [382720/387873]    Loss: 0.002421   Batch Acc: 84.38
[Train] Epoch: 1 [382848/387873]    Loss: 0.002384   Batch Acc: 87.50
[Train] Epoch: 1 [382976/387873]    Loss: 0.001763   Batch Acc: 91.41
[Train] Epoch: 1 [383104/387873]    Loss: 0.001654   Batch Acc: 91.41
[Train] Epoch: 1 [383232/387873]    Loss: 0.001954   Batch Acc: 86.72
[Train] Epoch: 1 [383360/387873]    Loss: 0.001965   Batch Acc: 89.84
[Train] Epoch: 1 [383488/387873]    Loss: 0.001497   Batch Acc: 94.53
[Train] Epoch: 1 [383616/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 1 [383744/387873]    Loss: 0.002294   Batch Acc: 86.72
[Train] Epoch: 1 [383872/387873]    Loss: 0.002383   Batch Acc: 84.38
[Train] Epoch: 1 [384000/387873]    Loss: 0.002406   Batch Acc: 87.50
[Train] Epoch: 1 [384128/387873]    Loss: 0.001784   Batch Acc: 90.62
[Train] Epoch: 1 [384256/387873]    Loss: 0.001722   Batch Acc: 93.75
[Train] Epoch: 1 [384384/387873]    Loss: 0.001538   Batch Acc: 92.19
[Train] Epoch: 1 [384512/387873]    Loss: 0.001921   Batch Acc: 91.41
[Train] Epoch: 1 [384640/387873]    Loss: 0.002520   Batch Acc: 85.16
[Train] Epoch: 1 [384768/387873]    Loss: 0.002213   Batch Acc: 90.62
[Train] Epoch: 1 [384896/387873]    Loss: 0.002610   Batch Acc: 85.94
[Train] Epoch: 1 [385024/387873]    Loss: 0.001954   Batch Acc: 86.72
[Train] Epoch: 1 [385152/387873]    Loss: 0.002464   Batch Acc: 89.06
[Train] Epoch: 1 [385280/387873]    Loss: 0.002217   Batch Acc: 88.28
[Train] Epoch: 1 [385408/387873]    Loss: 0.001503   Batch Acc: 93.75
[Train] Epoch: 1 [385536/387873]    Loss: 0.002049   Batch Acc: 87.50
[Train] Epoch: 1 [385664/387873]    Loss: 0.001787   Batch Acc: 92.19
[Train] Epoch: 1 [385792/387873]    Loss: 0.002047   Batch Acc: 89.84
[Train] Epoch: 1 [385920/387873]    Loss: 0.002167   Batch Acc: 88.28
[Train] Epoch: 1 [386048/387873]    Loss: 0.002090   Batch Acc: 89.06
[Train] Epoch: 1 [386176/387873]    Loss: 0.002817   Batch Acc: 85.94
[Train] Epoch: 1 [386304/387873]    Loss: 0.001949   Batch Acc: 90.62
[Train] Epoch: 1 [386432/387873]    Loss: 0.002197   Batch Acc: 87.50
[Train] Epoch: 1 [386560/387873]    Loss: 0.002143   Batch Acc: 89.06
[Train] Epoch: 1 [386688/387873]    Loss: 0.001775   Batch Acc: 89.84
[Train] Epoch: 1 [386816/387873]    Loss: 0.002073   Batch Acc: 90.62
[Train] Epoch: 1 [386944/387873]    Loss: 0.001895   Batch Acc: 89.84
[Train] Epoch: 1 [387072/387873]    Loss: 0.002179   Batch Acc: 88.28
[Train] Epoch: 1 [387200/387873]    Loss: 0.002255   Batch Acc: 88.28
[Train] Epoch: 1 [387328/387873]    Loss: 0.002032   Batch Acc: 91.41
[Train] Epoch: 1 [387456/387873]    Loss: 0.002343   Batch Acc: 89.06
[Train] Epoch: 1 [387584/387873]    Loss: 0.002229   Batch Acc: 87.50
[Train] Epoch: 1 [387712/387873]    Loss: 0.002792   Batch Acc: 85.16
[Train] Epoch: 1 [387840/387873]    Loss: 0.001823   Batch Acc: 89.84
[Train] Epoch: 1 [100023/387873]    Loss: 0.012383   Batch Acc: 81.82
Validation Done: [128/84203]
Validation Done: [256/84203]
Validation Done: [384/84203]
Validation Done: [512/84203]
Validation Done: [640/84203]
Validation Done: [768/84203]
Validation Done: [896/84203]
Validation Done: [1024/84203]
Validation Done: [1152/84203]
Validation Done: [1280/84203]
Validation Done: [1408/84203]
Validation Done: [1536/84203]
Validation Done: [1664/84203]
Validation Done: [1792/84203]
Validation Done: [1920/84203]
Validation Done: [2048/84203]
Validation Done: [2176/84203]
Validation Done: [2304/84203]
Validation Done: [2432/84203]
Validation Done: [2560/84203]
Validation Done: [2688/84203]
Validation Done: [2816/84203]
Validation Done: [2944/84203]
Validation Done: [3072/84203]
Validation Done: [3200/84203]
Validation Done: [3328/84203]
Validation Done: [3456/84203]
Validation Done: [3584/84203]
Validation Done: [3712/84203]
Validation Done: [3840/84203]
Validation Done: [3968/84203]
Validation Done: [4096/84203]
Validation Done: [4224/84203]
Validation Done: [4352/84203]
Validation Done: [4480/84203]
Validation Done: [4608/84203]
Validation Done: [4736/84203]
Validation Done: [4864/84203]
Validation Done: [4992/84203]
Validation Done: [5120/84203]
Validation Done: [5248/84203]
Validation Done: [5376/84203]
Validation Done: [5504/84203]
Validation Done: [5632/84203]
Validation Done: [5760/84203]
Validation Done: [5888/84203]
Validation Done: [6016/84203]
Validation Done: [6144/84203]
Validation Done: [6272/84203]
Validation Done: [6400/84203]
Validation Done: [6528/84203]
Validation Done: [6656/84203]
Validation Done: [6784/84203]
Validation Done: [6912/84203]
Validation Done: [7040/84203]
Validation Done: [7168/84203]
Validation Done: [7296/84203]
Validation Done: [7424/84203]
Validation Done: [7552/84203]
Validation Done: [7680/84203]
Validation Done: [7808/84203]
Validation Done: [7936/84203]
Validation Done: [8064/84203]
Validation Done: [8192/84203]
Validation Done: [8320/84203]
Validation Done: [8448/84203]
Validation Done: [8576/84203]
Validation Done: [8704/84203]
Validation Done: [8832/84203]
Validation Done: [8960/84203]
Validation Done: [9088/84203]
Validation Done: [9216/84203]
Validation Done: [9344/84203]
Validation Done: [9472/84203]
Validation Done: [9600/84203]
Validation Done: [9728/84203]
Validation Done: [9856/84203]
Validation Done: [9984/84203]
Validation Done: [10112/84203]
Validation Done: [10240/84203]
Validation Done: [10368/84203]
Validation Done: [10496/84203]
Validation Done: [10624/84203]
Validation Done: [10752/84203]
Validation Done: [10880/84203]
Validation Done: [11008/84203]
Validation Done: [11136/84203]
Validation Done: [11264/84203]
Validation Done: [11392/84203]
Validation Done: [11520/84203]
Validation Done: [11648/84203]
Validation Done: [11776/84203]
Validation Done: [11904/84203]
Validation Done: [12032/84203]
Validation Done: [12160/84203]
Validation Done: [12288/84203]
Validation Done: [12416/84203]
Validation Done: [12544/84203]
Validation Done: [12672/84203]
Validation Done: [12800/84203]
Validation Done: [12928/84203]
Validation Done: [13056/84203]
Validation Done: [13184/84203]
Validation Done: [13312/84203]
Validation Done: [13440/84203]
Validation Done: [13568/84203]
Validation Done: [13696/84203]
Validation Done: [13824/84203]
Validation Done: [13952/84203]
Validation Done: [14080/84203]
Validation Done: [14208/84203]
Validation Done: [14336/84203]
Validation Done: [14464/84203]
Validation Done: [14592/84203]
Validation Done: [14720/84203]
Validation Done: [14848/84203]
Validation Done: [14976/84203]
Validation Done: [15104/84203]
Validation Done: [15232/84203]
Validation Done: [15360/84203]
Validation Done: [15488/84203]
Validation Done: [15616/84203]
Validation Done: [15744/84203]
Validation Done: [15872/84203]
Validation Done: [16000/84203]
Validation Done: [16128/84203]
Validation Done: [16256/84203]
Validation Done: [16384/84203]
Validation Done: [16512/84203]
Validation Done: [16640/84203]
Validation Done: [16768/84203]
Validation Done: [16896/84203]
Validation Done: [17024/84203]
Validation Done: [17152/84203]
Validation Done: [17280/84203]
Validation Done: [17408/84203]
Validation Done: [17536/84203]
Validation Done: [17664/84203]
Validation Done: [17792/84203]
Validation Done: [17920/84203]
Validation Done: [18048/84203]
Validation Done: [18176/84203]
Validation Done: [18304/84203]
Validation Done: [18432/84203]
Validation Done: [18560/84203]
Validation Done: [18688/84203]
Validation Done: [18816/84203]
Validation Done: [18944/84203]
Validation Done: [19072/84203]
Validation Done: [19200/84203]
Validation Done: [19328/84203]
Validation Done: [19456/84203]
Validation Done: [19584/84203]
Validation Done: [19712/84203]
Validation Done: [19840/84203]
Validation Done: [19968/84203]
Validation Done: [20096/84203]
Validation Done: [20224/84203]
Validation Done: [20352/84203]
Validation Done: [20480/84203]
Validation Done: [20608/84203]
Validation Done: [20736/84203]
Validation Done: [20864/84203]
Validation Done: [20992/84203]
Validation Done: [21120/84203]
Validation Done: [21248/84203]
Validation Done: [21376/84203]
Validation Done: [21504/84203]
Validation Done: [21632/84203]
Validation Done: [21760/84203]
Validation Done: [21888/84203]
Validation Done: [22016/84203]
Validation Done: [22144/84203]
Validation Done: [22272/84203]
Validation Done: [22400/84203]
Validation Done: [22528/84203]
Validation Done: [22656/84203]
Validation Done: [22784/84203]
Validation Done: [22912/84203]
Validation Done: [23040/84203]
Validation Done: [23168/84203]
Validation Done: [23296/84203]
Validation Done: [23424/84203]
Validation Done: [23552/84203]
Validation Done: [23680/84203]
Validation Done: [23808/84203]
Validation Done: [23936/84203]
Validation Done: [24064/84203]
Validation Done: [24192/84203]
Validation Done: [24320/84203]
Validation Done: [24448/84203]
Validation Done: [24576/84203]
Validation Done: [24704/84203]
Validation Done: [24832/84203]
Validation Done: [24960/84203]
Validation Done: [25088/84203]
Validation Done: [25216/84203]
Validation Done: [25344/84203]
Validation Done: [25472/84203]
Validation Done: [25600/84203]
Validation Done: [25728/84203]
Validation Done: [25856/84203]
Validation Done: [25984/84203]
Validation Done: [26112/84203]
Validation Done: [26240/84203]
Validation Done: [26368/84203]
Validation Done: [26496/84203]
Validation Done: [26624/84203]
Validation Done: [26752/84203]
Validation Done: [26880/84203]
Validation Done: [27008/84203]
Validation Done: [27136/84203]
Validation Done: [27264/84203]
Validation Done: [27392/84203]
Validation Done: [27520/84203]
Validation Done: [27648/84203]
Validation Done: [27776/84203]
Validation Done: [27904/84203]
Validation Done: [28032/84203]
Validation Done: [28160/84203]
Validation Done: [28288/84203]
Validation Done: [28416/84203]
Validation Done: [28544/84203]
Validation Done: [28672/84203]
Validation Done: [28800/84203]
Validation Done: [28928/84203]
Validation Done: [29056/84203]
Validation Done: [29184/84203]
Validation Done: [29312/84203]
Validation Done: [29440/84203]
Validation Done: [29568/84203]
Validation Done: [29696/84203]
Validation Done: [29824/84203]
Validation Done: [29952/84203]
Validation Done: [30080/84203]
Validation Done: [30208/84203]
Validation Done: [30336/84203]
Validation Done: [30464/84203]
Validation Done: [30592/84203]
Validation Done: [30720/84203]
Validation Done: [30848/84203]
Validation Done: [30976/84203]
Validation Done: [31104/84203]
Validation Done: [31232/84203]
Validation Done: [31360/84203]
Validation Done: [31488/84203]
Validation Done: [31616/84203]
Validation Done: [31744/84203]
Validation Done: [31872/84203]
Validation Done: [32000/84203]
Validation Done: [32128/84203]
Validation Done: [32256/84203]
Validation Done: [32384/84203]
Validation Done: [32512/84203]
Validation Done: [32640/84203]
Validation Done: [32768/84203]
Validation Done: [32896/84203]
Validation Done: [33024/84203]
Validation Done: [33152/84203]
Validation Done: [33280/84203]
Validation Done: [33408/84203]
Validation Done: [33536/84203]
Validation Done: [33664/84203]
Validation Done: [33792/84203]
Validation Done: [33920/84203]
Validation Done: [34048/84203]
Validation Done: [34176/84203]
Validation Done: [34304/84203]
Validation Done: [34432/84203]
Validation Done: [34560/84203]
Validation Done: [34688/84203]
Validation Done: [34816/84203]
Validation Done: [34944/84203]
Validation Done: [35072/84203]
Validation Done: [35200/84203]
Validation Done: [35328/84203]
Validation Done: [35456/84203]
Validation Done: [35584/84203]
Validation Done: [35712/84203]
Validation Done: [35840/84203]
Validation Done: [35968/84203]
Validation Done: [36096/84203]
Validation Done: [36224/84203]
Validation Done: [36352/84203]
Validation Done: [36480/84203]
Validation Done: [36608/84203]
Validation Done: [36736/84203]
Validation Done: [36864/84203]
Validation Done: [36992/84203]
Validation Done: [37120/84203]
Validation Done: [37248/84203]
Validation Done: [37376/84203]
Validation Done: [37504/84203]
Validation Done: [37632/84203]
Validation Done: [37760/84203]
Validation Done: [37888/84203]
Validation Done: [38016/84203]
Validation Done: [38144/84203]
Validation Done: [38272/84203]
Validation Done: [38400/84203]
Validation Done: [38528/84203]
Validation Done: [38656/84203]
Validation Done: [38784/84203]
Validation Done: [38912/84203]
Validation Done: [39040/84203]
Validation Done: [39168/84203]
Validation Done: [39296/84203]
Validation Done: [39424/84203]
Validation Done: [39552/84203]
Validation Done: [39680/84203]
Validation Done: [39808/84203]
Validation Done: [39936/84203]
Validation Done: [40064/84203]
Validation Done: [40192/84203]
Validation Done: [40320/84203]
Validation Done: [40448/84203]
Validation Done: [40576/84203]
Validation Done: [40704/84203]
Validation Done: [40832/84203]
Validation Done: [40960/84203]
Validation Done: [41088/84203]
Validation Done: [41216/84203]
Validation Done: [41344/84203]
Validation Done: [41472/84203]
Validation Done: [41600/84203]
Validation Done: [41728/84203]
Validation Done: [41856/84203]
Validation Done: [41984/84203]
Validation Done: [42112/84203]
Validation Done: [42240/84203]
Validation Done: [42368/84203]
Validation Done: [42496/84203]
Validation Done: [42624/84203]
Validation Done: [42752/84203]
Validation Done: [42880/84203]
Validation Done: [43008/84203]
Validation Done: [43136/84203]
Validation Done: [43264/84203]
Validation Done: [43392/84203]
Validation Done: [43520/84203]
Validation Done: [43648/84203]
Validation Done: [43776/84203]
Validation Done: [43904/84203]
Validation Done: [44032/84203]
Validation Done: [44160/84203]
Validation Done: [44288/84203]
Validation Done: [44416/84203]
Validation Done: [44544/84203]
Validation Done: [44672/84203]
Validation Done: [44800/84203]
Validation Done: [44928/84203]
Validation Done: [45056/84203]
Validation Done: [45184/84203]
Validation Done: [45312/84203]
Validation Done: [45440/84203]
Validation Done: [45568/84203]
Validation Done: [45696/84203]
Validation Done: [45824/84203]
Validation Done: [45952/84203]
Validation Done: [46080/84203]
Validation Done: [46208/84203]
Validation Done: [46336/84203]
Validation Done: [46464/84203]
Validation Done: [46592/84203]
Validation Done: [46720/84203]
Validation Done: [46848/84203]
Validation Done: [46976/84203]
Validation Done: [47104/84203]
Validation Done: [47232/84203]
Validation Done: [47360/84203]
Validation Done: [47488/84203]
Validation Done: [47616/84203]
Validation Done: [47744/84203]
Validation Done: [47872/84203]
Validation Done: [48000/84203]
Validation Done: [48128/84203]
Validation Done: [48256/84203]
Validation Done: [48384/84203]
Validation Done: [48512/84203]
Validation Done: [48640/84203]
Validation Done: [48768/84203]
Validation Done: [48896/84203]
Validation Done: [49024/84203]
Validation Done: [49152/84203]
Validation Done: [49280/84203]
Validation Done: [49408/84203]
Validation Done: [49536/84203]
Validation Done: [49664/84203]
Validation Done: [49792/84203]
Validation Done: [49920/84203]
Validation Done: [50048/84203]
Validation Done: [50176/84203]
Validation Done: [50304/84203]
Validation Done: [50432/84203]
Validation Done: [50560/84203]
Validation Done: [50688/84203]
Validation Done: [50816/84203]
Validation Done: [50944/84203]
Validation Done: [51072/84203]
Validation Done: [51200/84203]
Validation Done: [51328/84203]
Validation Done: [51456/84203]
Validation Done: [51584/84203]
Validation Done: [51712/84203]
Validation Done: [51840/84203]
Validation Done: [51968/84203]
Validation Done: [52096/84203]
Validation Done: [52224/84203]
Validation Done: [52352/84203]
Validation Done: [52480/84203]
Validation Done: [52608/84203]
Validation Done: [52736/84203]
Validation Done: [52864/84203]
Validation Done: [52992/84203]
Validation Done: [53120/84203]
Validation Done: [53248/84203]
Validation Done: [53376/84203]
Validation Done: [53504/84203]
Validation Done: [53632/84203]
Validation Done: [53760/84203]
Validation Done: [53888/84203]
Validation Done: [54016/84203]
Validation Done: [54144/84203]
Validation Done: [54272/84203]
Validation Done: [54400/84203]
Validation Done: [54528/84203]
Validation Done: [54656/84203]
Validation Done: [54784/84203]
Validation Done: [54912/84203]
Validation Done: [55040/84203]
Validation Done: [55168/84203]
Validation Done: [55296/84203]
Validation Done: [55424/84203]
Validation Done: [55552/84203]
Validation Done: [55680/84203]
Validation Done: [55808/84203]
Validation Done: [55936/84203]
Validation Done: [56064/84203]
Validation Done: [56192/84203]
Validation Done: [56320/84203]
Validation Done: [56448/84203]
Validation Done: [56576/84203]
Validation Done: [56704/84203]
Validation Done: [56832/84203]
Validation Done: [56960/84203]
Validation Done: [57088/84203]
Validation Done: [57216/84203]
Validation Done: [57344/84203]
Validation Done: [57472/84203]
Validation Done: [57600/84203]
Validation Done: [57728/84203]
Validation Done: [57856/84203]
Validation Done: [57984/84203]
Validation Done: [58112/84203]
Validation Done: [58240/84203]
Validation Done: [58368/84203]
Validation Done: [58496/84203]
Validation Done: [58624/84203]
Validation Done: [58752/84203]
Validation Done: [58880/84203]
Validation Done: [59008/84203]
Validation Done: [59136/84203]
Validation Done: [59264/84203]
Validation Done: [59392/84203]
Validation Done: [59520/84203]
Validation Done: [59648/84203]
Validation Done: [59776/84203]
Validation Done: [59904/84203]
Validation Done: [60032/84203]
Validation Done: [60160/84203]
Validation Done: [60288/84203]
Validation Done: [60416/84203]
Validation Done: [60544/84203]
Validation Done: [60672/84203]
Validation Done: [60800/84203]
Validation Done: [60928/84203]
Validation Done: [61056/84203]
Validation Done: [61184/84203]
Validation Done: [61312/84203]
Validation Done: [61440/84203]
Validation Done: [61568/84203]
Validation Done: [61696/84203]
Validation Done: [61824/84203]
Validation Done: [61952/84203]
Validation Done: [62080/84203]
Validation Done: [62208/84203]
Validation Done: [62336/84203]
Validation Done: [62464/84203]
Validation Done: [62592/84203]
Validation Done: [62720/84203]
Validation Done: [62848/84203]
Validation Done: [62976/84203]
Validation Done: [63104/84203]
Validation Done: [63232/84203]
Validation Done: [63360/84203]
Validation Done: [63488/84203]
Validation Done: [63616/84203]
Validation Done: [63744/84203]
Validation Done: [63872/84203]
Validation Done: [64000/84203]
Validation Done: [64128/84203]
Validation Done: [64256/84203]
Validation Done: [64384/84203]
Validation Done: [64512/84203]
Validation Done: [64640/84203]
Validation Done: [64768/84203]
Validation Done: [64896/84203]
Validation Done: [65024/84203]
Validation Done: [65152/84203]
Validation Done: [65280/84203]
Validation Done: [65408/84203]
Validation Done: [65536/84203]
Validation Done: [65664/84203]
Validation Done: [65792/84203]
Validation Done: [65920/84203]
Validation Done: [66048/84203]
Validation Done: [66176/84203]
Validation Done: [66304/84203]
Validation Done: [66432/84203]
Validation Done: [66560/84203]
Validation Done: [66688/84203]
Validation Done: [66816/84203]
Validation Done: [66944/84203]
Validation Done: [67072/84203]
Validation Done: [67200/84203]
Validation Done: [67328/84203]
Validation Done: [67456/84203]
Validation Done: [67584/84203]
Validation Done: [67712/84203]
Validation Done: [67840/84203]
Validation Done: [67968/84203]
Validation Done: [68096/84203]
Validation Done: [68224/84203]
Validation Done: [68352/84203]
Validation Done: [68480/84203]
Validation Done: [68608/84203]
Validation Done: [68736/84203]
Validation Done: [68864/84203]
Validation Done: [68992/84203]
Validation Done: [69120/84203]
Validation Done: [69248/84203]
Validation Done: [69376/84203]
Validation Done: [69504/84203]
Validation Done: [69632/84203]
Validation Done: [69760/84203]
Validation Done: [69888/84203]
Validation Done: [70016/84203]
Validation Done: [70144/84203]
Validation Done: [70272/84203]
Validation Done: [70400/84203]
Validation Done: [70528/84203]
Validation Done: [70656/84203]
Validation Done: [70784/84203]
Validation Done: [70912/84203]
Validation Done: [71040/84203]
Validation Done: [71168/84203]
Validation Done: [71296/84203]
Validation Done: [71424/84203]
Validation Done: [71552/84203]
Validation Done: [71680/84203]
Validation Done: [71808/84203]
Validation Done: [71936/84203]
Validation Done: [72064/84203]
Validation Done: [72192/84203]
Validation Done: [72320/84203]
Validation Done: [72448/84203]
Validation Done: [72576/84203]
Validation Done: [72704/84203]
Validation Done: [72832/84203]
Validation Done: [72960/84203]
Validation Done: [73088/84203]
Validation Done: [73216/84203]
Validation Done: [73344/84203]
Validation Done: [73472/84203]
Validation Done: [73600/84203]
Validation Done: [73728/84203]
Validation Done: [73856/84203]
Validation Done: [73984/84203]
Validation Done: [74112/84203]
Validation Done: [74240/84203]
Validation Done: [74368/84203]
Validation Done: [74496/84203]
Validation Done: [74624/84203]
Validation Done: [74752/84203]
Validation Done: [74880/84203]
Validation Done: [75008/84203]
Validation Done: [75136/84203]
Validation Done: [75264/84203]
Validation Done: [75392/84203]
Validation Done: [75520/84203]
Validation Done: [75648/84203]
Validation Done: [75776/84203]
Validation Done: [75904/84203]
Validation Done: [76032/84203]
Validation Done: [76160/84203]
Validation Done: [76288/84203]
Validation Done: [76416/84203]
Validation Done: [76544/84203]
Validation Done: [76672/84203]
Validation Done: [76800/84203]
Validation Done: [76928/84203]
Validation Done: [77056/84203]
Validation Done: [77184/84203]
Validation Done: [77312/84203]
Validation Done: [77440/84203]
Validation Done: [77568/84203]
Validation Done: [77696/84203]
Validation Done: [77824/84203]
Validation Done: [77952/84203]
Validation Done: [78080/84203]
Validation Done: [78208/84203]
Validation Done: [78336/84203]
Validation Done: [78464/84203]
Validation Done: [78592/84203]
Validation Done: [78720/84203]
Validation Done: [78848/84203]
Validation Done: [78976/84203]
Validation Done: [79104/84203]
Validation Done: [79232/84203]
Validation Done: [79360/84203]
Validation Done: [79488/84203]
Validation Done: [79616/84203]
Validation Done: [79744/84203]
Validation Done: [79872/84203]
Validation Done: [80000/84203]
Validation Done: [80128/84203]
Validation Done: [80256/84203]
Validation Done: [80384/84203]
Validation Done: [80512/84203]
Validation Done: [80640/84203]
Validation Done: [80768/84203]
Validation Done: [80896/84203]
Validation Done: [81024/84203]
Validation Done: [81152/84203]
Validation Done: [81280/84203]
Validation Done: [81408/84203]
Validation Done: [81536/84203]
Validation Done: [81664/84203]
Validation Done: [81792/84203]
Validation Done: [81920/84203]
Validation Done: [82048/84203]
Validation Done: [82176/84203]
Validation Done: [82304/84203]
Validation Done: [82432/84203]
Validation Done: [82560/84203]
Validation Done: [82688/84203]
Validation Done: [82816/84203]
Validation Done: [82944/84203]
Validation Done: [83072/84203]
Validation Done: [83200/84203]
Validation Done: [83328/84203]
Validation Done: [83456/84203]
Validation Done: [83584/84203]
Validation Done: [83712/84203]
Validation Done: [83840/84203]
Validation Done: [83968/84203]
Validation Done: [84096/84203]
Validation Done: [70406/84203]
[Test] Epoch: 1 Test set: Average loss: 0.0021, Accuracy: 75129/84203 (89.22%)
{'accuracy': 0.8922366186477917, 'normal': {'precision': 0.8668068833652007, 'recall': 0.8021445254441221, 'support': 28258, 'f1-score': 0.8332230554330247}, 'macro avg': {'precision': 0.8852491688629356, 'recall': 0.869943475520345, 'support': 84203, 'f1-score': 0.8768125838753923}, 'cancer': {'precision': 0.9036914543606704, 'recall': 0.9377424255965681, 'support': 55945, 'f1-score': 0.9204021123177599}, 'weighted avg': {'precision': 0.89131322309587, 'recall': 0.8922366186477917, 'support': 84203, 'f1-score': 0.8911453662463746}}
[Train] Epoch: 2 [128/387873]    Loss: 0.001889   Batch Acc: 89.84
[Train] Epoch: 2 [256/387873]    Loss: 0.001820   Batch Acc: 91.41
[Train] Epoch: 2 [384/387873]    Loss: 0.002033   Batch Acc: 87.50
[Train] Epoch: 2 [512/387873]    Loss: 0.001800   Batch Acc: 91.41
[Train] Epoch: 2 [640/387873]    Loss: 0.002007   Batch Acc: 89.84
[Train] Epoch: 2 [768/387873]    Loss: 0.002639   Batch Acc: 84.38
[Train] Epoch: 2 [896/387873]    Loss: 0.002151   Batch Acc: 88.28
[Train] Epoch: 2 [1024/387873]    Loss: 0.001898   Batch Acc: 90.62
[Train] Epoch: 2 [1152/387873]    Loss: 0.001962   Batch Acc: 88.28
[Train] Epoch: 2 [1280/387873]    Loss: 0.002697   Batch Acc: 81.25
[Train] Epoch: 2 [1408/387873]    Loss: 0.002276   Batch Acc: 85.94
[Train] Epoch: 2 [1536/387873]    Loss: 0.001863   Batch Acc: 89.84
[Train] Epoch: 2 [1664/387873]    Loss: 0.001983   Batch Acc: 89.84
[Train] Epoch: 2 [1792/387873]    Loss: 0.002132   Batch Acc: 89.84
[Train] Epoch: 2 [1920/387873]    Loss: 0.001558   Batch Acc: 90.62
[Train] Epoch: 2 [2048/387873]    Loss: 0.001890   Batch Acc: 92.19
[Train] Epoch: 2 [2176/387873]    Loss: 0.001538   Batch Acc: 93.75
[Train] Epoch: 2 [2304/387873]    Loss: 0.001923   Batch Acc: 89.06
[Train] Epoch: 2 [2432/387873]    Loss: 0.001788   Batch Acc: 90.62
[Train] Epoch: 2 [2560/387873]    Loss: 0.001682   Batch Acc: 93.75
[Train] Epoch: 2 [2688/387873]    Loss: 0.001638   Batch Acc: 90.62
[Train] Epoch: 2 [2816/387873]    Loss: 0.001703   Batch Acc: 90.62
[Train] Epoch: 2 [2944/387873]    Loss: 0.001667   Batch Acc: 91.41
[Train] Epoch: 2 [3072/387873]    Loss: 0.001689   Batch Acc: 92.19
[Train] Epoch: 2 [3200/387873]    Loss: 0.002296   Batch Acc: 88.28
[Train] Epoch: 2 [3328/387873]    Loss: 0.002519   Batch Acc: 86.72
[Train] Epoch: 2 [3456/387873]    Loss: 0.001990   Batch Acc: 89.06
[Train] Epoch: 2 [3584/387873]    Loss: 0.001866   Batch Acc: 92.19
[Train] Epoch: 2 [3712/387873]    Loss: 0.001863   Batch Acc: 89.84
[Train] Epoch: 2 [3840/387873]    Loss: 0.002333   Batch Acc: 87.50
[Train] Epoch: 2 [3968/387873]    Loss: 0.001974   Batch Acc: 88.28
[Train] Epoch: 2 [4096/387873]    Loss: 0.002058   Batch Acc: 92.19
[Train] Epoch: 2 [4224/387873]    Loss: 0.002375   Batch Acc: 86.72
[Train] Epoch: 2 [4352/387873]    Loss: 0.002137   Batch Acc: 86.72
[Train] Epoch: 2 [4480/387873]    Loss: 0.002034   Batch Acc: 85.94
[Train] Epoch: 2 [4608/387873]    Loss: 0.002803   Batch Acc: 83.59
[Train] Epoch: 2 [4736/387873]    Loss: 0.001782   Batch Acc: 92.19
[Train] Epoch: 2 [4864/387873]    Loss: 0.003039   Batch Acc: 82.03
[Train] Epoch: 2 [4992/387873]    Loss: 0.002155   Batch Acc: 89.06
[Train] Epoch: 2 [5120/387873]    Loss: 0.002436   Batch Acc: 86.72
[Train] Epoch: 2 [5248/387873]    Loss: 0.002393   Batch Acc: 83.59
[Train] Epoch: 2 [5376/387873]    Loss: 0.002071   Batch Acc: 85.94
[Train] Epoch: 2 [5504/387873]    Loss: 0.002061   Batch Acc: 87.50
[Train] Epoch: 2 [5632/387873]    Loss: 0.001842   Batch Acc: 92.97
[Train] Epoch: 2 [5760/387873]    Loss: 0.001861   Batch Acc: 91.41
[Train] Epoch: 2 [5888/387873]    Loss: 0.001907   Batch Acc: 89.84
[Train] Epoch: 2 [6016/387873]    Loss: 0.002527   Batch Acc: 86.72
[Train] Epoch: 2 [6144/387873]    Loss: 0.001717   Batch Acc: 92.19
[Train] Epoch: 2 [6272/387873]    Loss: 0.002142   Batch Acc: 88.28
[Train] Epoch: 2 [6400/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 2 [6528/387873]    Loss: 0.002134   Batch Acc: 87.50
[Train] Epoch: 2 [6656/387873]    Loss: 0.001654   Batch Acc: 92.97
[Train] Epoch: 2 [6784/387873]    Loss: 0.002233   Batch Acc: 85.94
[Train] Epoch: 2 [6912/387873]    Loss: 0.001863   Batch Acc: 90.62
[Train] Epoch: 2 [7040/387873]    Loss: 0.002084   Batch Acc: 87.50
[Train] Epoch: 2 [7168/387873]    Loss: 0.002175   Batch Acc: 85.94
[Train] Epoch: 2 [7296/387873]    Loss: 0.001537   Batch Acc: 93.75
[Train] Epoch: 2 [7424/387873]    Loss: 0.002003   Batch Acc: 88.28
[Train] Epoch: 2 [7552/387873]    Loss: 0.002412   Batch Acc: 89.06
[Train] Epoch: 2 [7680/387873]    Loss: 0.002394   Batch Acc: 86.72
[Train] Epoch: 2 [7808/387873]    Loss: 0.002031   Batch Acc: 89.84
[Train] Epoch: 2 [7936/387873]    Loss: 0.002390   Batch Acc: 87.50
[Train] Epoch: 2 [8064/387873]    Loss: 0.001651   Batch Acc: 91.41
[Train] Epoch: 2 [8192/387873]    Loss: 0.002243   Batch Acc: 88.28
[Train] Epoch: 2 [8320/387873]    Loss: 0.002045   Batch Acc: 88.28
[Train] Epoch: 2 [8448/387873]    Loss: 0.002279   Batch Acc: 85.94
[Train] Epoch: 2 [8576/387873]    Loss: 0.002459   Batch Acc: 86.72
[Train] Epoch: 2 [8704/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 2 [8832/387873]    Loss: 0.001828   Batch Acc: 88.28
[Train] Epoch: 2 [8960/387873]    Loss: 0.001717   Batch Acc: 92.19
[Train] Epoch: 2 [9088/387873]    Loss: 0.002320   Batch Acc: 84.38
[Train] Epoch: 2 [9216/387873]    Loss: 0.002134   Batch Acc: 88.28
[Train] Epoch: 2 [9344/387873]    Loss: 0.002050   Batch Acc: 90.62
[Train] Epoch: 2 [9472/387873]    Loss: 0.001666   Batch Acc: 92.19
[Train] Epoch: 2 [9600/387873]    Loss: 0.002086   Batch Acc: 90.62
[Train] Epoch: 2 [9728/387873]    Loss: 0.001691   Batch Acc: 92.19
[Train] Epoch: 2 [9856/387873]    Loss: 0.001990   Batch Acc: 89.06
[Train] Epoch: 2 [9984/387873]    Loss: 0.001828   Batch Acc: 90.62
[Train] Epoch: 2 [10112/387873]    Loss: 0.001984   Batch Acc: 89.84
[Train] Epoch: 2 [10240/387873]    Loss: 0.002092   Batch Acc: 89.84
[Train] Epoch: 2 [10368/387873]    Loss: 0.002012   Batch Acc: 92.19
[Train] Epoch: 2 [10496/387873]    Loss: 0.002113   Batch Acc: 89.06
[Train] Epoch: 2 [10624/387873]    Loss: 0.002443   Batch Acc: 84.38
[Train] Epoch: 2 [10752/387873]    Loss: 0.002198   Batch Acc: 89.06
[Train] Epoch: 2 [10880/387873]    Loss: 0.002093   Batch Acc: 89.84
[Train] Epoch: 2 [11008/387873]    Loss: 0.001698   Batch Acc: 92.97
[Train] Epoch: 2 [11136/387873]    Loss: 0.002458   Batch Acc: 85.94
[Train] Epoch: 2 [11264/387873]    Loss: 0.002128   Batch Acc: 87.50
[Train] Epoch: 2 [11392/387873]    Loss: 0.002195   Batch Acc: 86.72
[Train] Epoch: 2 [11520/387873]    Loss: 0.001408   Batch Acc: 93.75
[Train] Epoch: 2 [11648/387873]    Loss: 0.002397   Batch Acc: 86.72
[Train] Epoch: 2 [11776/387873]    Loss: 0.002240   Batch Acc: 87.50
[Train] Epoch: 2 [11904/387873]    Loss: 0.001625   Batch Acc: 91.41
[Train] Epoch: 2 [12032/387873]    Loss: 0.002737   Batch Acc: 82.03
[Train] Epoch: 2 [12160/387873]    Loss: 0.001754   Batch Acc: 93.75
[Train] Epoch: 2 [12288/387873]    Loss: 0.002062   Batch Acc: 88.28
[Train] Epoch: 2 [12416/387873]    Loss: 0.002404   Batch Acc: 85.94
[Train] Epoch: 2 [12544/387873]    Loss: 0.002195   Batch Acc: 89.06
[Train] Epoch: 2 [12672/387873]    Loss: 0.002273   Batch Acc: 88.28
[Train] Epoch: 2 [12800/387873]    Loss: 0.002078   Batch Acc: 88.28
[Train] Epoch: 2 [12928/387873]    Loss: 0.001830   Batch Acc: 89.06
[Train] Epoch: 2 [13056/387873]    Loss: 0.002365   Batch Acc: 85.94
[Train] Epoch: 2 [13184/387873]    Loss: 0.002015   Batch Acc: 90.62
[Train] Epoch: 2 [13312/387873]    Loss: 0.002146   Batch Acc: 89.84
[Train] Epoch: 2 [13440/387873]    Loss: 0.002257   Batch Acc: 86.72
[Train] Epoch: 2 [13568/387873]    Loss: 0.002049   Batch Acc: 89.06
[Train] Epoch: 2 [13696/387873]    Loss: 0.001770   Batch Acc: 91.41
[Train] Epoch: 2 [13824/387873]    Loss: 0.002480   Batch Acc: 88.28
[Train] Epoch: 2 [13952/387873]    Loss: 0.001816   Batch Acc: 92.19
[Train] Epoch: 2 [14080/387873]    Loss: 0.002181   Batch Acc: 89.06
[Train] Epoch: 2 [14208/387873]    Loss: 0.001629   Batch Acc: 91.41
[Train] Epoch: 2 [14336/387873]    Loss: 0.002002   Batch Acc: 87.50
[Train] Epoch: 2 [14464/387873]    Loss: 0.002020   Batch Acc: 90.62
[Train] Epoch: 2 [14592/387873]    Loss: 0.001607   Batch Acc: 90.62
[Train] Epoch: 2 [14720/387873]    Loss: 0.002183   Batch Acc: 89.84
[Train] Epoch: 2 [14848/387873]    Loss: 0.001905   Batch Acc: 90.62
[Train] Epoch: 2 [14976/387873]    Loss: 0.001759   Batch Acc: 92.19
[Train] Epoch: 2 [15104/387873]    Loss: 0.001453   Batch Acc: 96.09
[Train] Epoch: 2 [15232/387873]    Loss: 0.001904   Batch Acc: 91.41
[Train] Epoch: 2 [15360/387873]    Loss: 0.001579   Batch Acc: 91.41
[Train] Epoch: 2 [15488/387873]    Loss: 0.002261   Batch Acc: 85.94
[Train] Epoch: 2 [15616/387873]    Loss: 0.002158   Batch Acc: 90.62
[Train] Epoch: 2 [15744/387873]    Loss: 0.001508   Batch Acc: 92.19
[Train] Epoch: 2 [15872/387873]    Loss: 0.001992   Batch Acc: 89.06
[Train] Epoch: 2 [16000/387873]    Loss: 0.002391   Batch Acc: 86.72
[Train] Epoch: 2 [16128/387873]    Loss: 0.001927   Batch Acc: 92.97
[Train] Epoch: 2 [16256/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 2 [16384/387873]    Loss: 0.002408   Batch Acc: 84.38
[Train] Epoch: 2 [16512/387873]    Loss: 0.002051   Batch Acc: 88.28
[Train] Epoch: 2 [16640/387873]    Loss: 0.001609   Batch Acc: 92.19
[Train] Epoch: 2 [16768/387873]    Loss: 0.002132   Batch Acc: 89.84
[Train] Epoch: 2 [16896/387873]    Loss: 0.002230   Batch Acc: 85.94
[Train] Epoch: 2 [17024/387873]    Loss: 0.002406   Batch Acc: 88.28
[Train] Epoch: 2 [17152/387873]    Loss: 0.002113   Batch Acc: 87.50
[Train] Epoch: 2 [17280/387873]    Loss: 0.001781   Batch Acc: 90.62
[Train] Epoch: 2 [17408/387873]    Loss: 0.002398   Batch Acc: 84.38
[Train] Epoch: 2 [17536/387873]    Loss: 0.001441   Batch Acc: 95.31
[Train] Epoch: 2 [17664/387873]    Loss: 0.002422   Batch Acc: 84.38
[Train] Epoch: 2 [17792/387873]    Loss: 0.001717   Batch Acc: 90.62
[Train] Epoch: 2 [17920/387873]    Loss: 0.002015   Batch Acc: 92.19
[Train] Epoch: 2 [18048/387873]    Loss: 0.002088   Batch Acc: 88.28
[Train] Epoch: 2 [18176/387873]    Loss: 0.001944   Batch Acc: 89.84
[Train] Epoch: 2 [18304/387873]    Loss: 0.001624   Batch Acc: 92.97
[Train] Epoch: 2 [18432/387873]    Loss: 0.002146   Batch Acc: 89.06
[Train] Epoch: 2 [18560/387873]    Loss: 0.001933   Batch Acc: 91.41
[Train] Epoch: 2 [18688/387873]    Loss: 0.002254   Batch Acc: 86.72
[Train] Epoch: 2 [18816/387873]    Loss: 0.002083   Batch Acc: 89.06
[Train] Epoch: 2 [18944/387873]    Loss: 0.001230   Batch Acc: 96.09
[Train] Epoch: 2 [19072/387873]    Loss: 0.002002   Batch Acc: 86.72
[Train] Epoch: 2 [19200/387873]    Loss: 0.002015   Batch Acc: 90.62
[Train] Epoch: 2 [19328/387873]    Loss: 0.002112   Batch Acc: 88.28
[Train] Epoch: 2 [19456/387873]    Loss: 0.002459   Batch Acc: 83.59
[Train] Epoch: 2 [19584/387873]    Loss: 0.001944   Batch Acc: 88.28
[Train] Epoch: 2 [19712/387873]    Loss: 0.002593   Batch Acc: 85.94
[Train] Epoch: 2 [19840/387873]    Loss: 0.002338   Batch Acc: 87.50
[Train] Epoch: 2 [19968/387873]    Loss: 0.001890   Batch Acc: 89.84
[Train] Epoch: 2 [20096/387873]    Loss: 0.002156   Batch Acc: 89.06
[Train] Epoch: 2 [20224/387873]    Loss: 0.001789   Batch Acc: 89.06
[Train] Epoch: 2 [20352/387873]    Loss: 0.001931   Batch Acc: 89.84
[Train] Epoch: 2 [20480/387873]    Loss: 0.001906   Batch Acc: 90.62
[Train] Epoch: 2 [20608/387873]    Loss: 0.002347   Batch Acc: 89.84
[Train] Epoch: 2 [20736/387873]    Loss: 0.002298   Batch Acc: 88.28
[Train] Epoch: 2 [20864/387873]    Loss: 0.001804   Batch Acc: 90.62
[Train] Epoch: 2 [20992/387873]    Loss: 0.002982   Batch Acc: 83.59
[Train] Epoch: 2 [21120/387873]    Loss: 0.001912   Batch Acc: 90.62
[Train] Epoch: 2 [21248/387873]    Loss: 0.002236   Batch Acc: 89.06
[Train] Epoch: 2 [21376/387873]    Loss: 0.001497   Batch Acc: 93.75
[Train] Epoch: 2 [21504/387873]    Loss: 0.001798   Batch Acc: 89.84
[Train] Epoch: 2 [21632/387873]    Loss: 0.002492   Batch Acc: 83.59
[Train] Epoch: 2 [21760/387873]    Loss: 0.002001   Batch Acc: 89.06
[Train] Epoch: 2 [21888/387873]    Loss: 0.002268   Batch Acc: 87.50
[Train] Epoch: 2 [22016/387873]    Loss: 0.001751   Batch Acc: 89.84
[Train] Epoch: 2 [22144/387873]    Loss: 0.002105   Batch Acc: 90.62
[Train] Epoch: 2 [22272/387873]    Loss: 0.002147   Batch Acc: 89.84
[Train] Epoch: 2 [22400/387873]    Loss: 0.002174   Batch Acc: 90.62
[Train] Epoch: 2 [22528/387873]    Loss: 0.002452   Batch Acc: 81.25
[Train] Epoch: 2 [22656/387873]    Loss: 0.001814   Batch Acc: 89.84
[Train] Epoch: 2 [22784/387873]    Loss: 0.002133   Batch Acc: 86.72
[Train] Epoch: 2 [22912/387873]    Loss: 0.001966   Batch Acc: 89.06
[Train] Epoch: 2 [23040/387873]    Loss: 0.002106   Batch Acc: 90.62
[Train] Epoch: 2 [23168/387873]    Loss: 0.002559   Batch Acc: 85.94
[Train] Epoch: 2 [23296/387873]    Loss: 0.001670   Batch Acc: 92.97
[Train] Epoch: 2 [23424/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 2 [23552/387873]    Loss: 0.002280   Batch Acc: 85.94
[Train] Epoch: 2 [23680/387873]    Loss: 0.001596   Batch Acc: 92.19
[Train] Epoch: 2 [23808/387873]    Loss: 0.002080   Batch Acc: 88.28
[Train] Epoch: 2 [23936/387873]    Loss: 0.002250   Batch Acc: 89.84
[Train] Epoch: 2 [24064/387873]    Loss: 0.001954   Batch Acc: 87.50
[Train] Epoch: 2 [24192/387873]    Loss: 0.002028   Batch Acc: 89.06
[Train] Epoch: 2 [24320/387873]    Loss: 0.002434   Batch Acc: 87.50
[Train] Epoch: 2 [24448/387873]    Loss: 0.001614   Batch Acc: 93.75
[Train] Epoch: 2 [24576/387873]    Loss: 0.001970   Batch Acc: 89.06
[Train] Epoch: 2 [24704/387873]    Loss: 0.001833   Batch Acc: 89.84
[Train] Epoch: 2 [24832/387873]    Loss: 0.002071   Batch Acc: 89.06
[Train] Epoch: 2 [24960/387873]    Loss: 0.002372   Batch Acc: 86.72
[Train] Epoch: 2 [25088/387873]    Loss: 0.002253   Batch Acc: 84.38
[Train] Epoch: 2 [25216/387873]    Loss: 0.002149   Batch Acc: 86.72
[Train] Epoch: 2 [25344/387873]    Loss: 0.002124   Batch Acc: 87.50
[Train] Epoch: 2 [25472/387873]    Loss: 0.002167   Batch Acc: 88.28
[Train] Epoch: 2 [25600/387873]    Loss: 0.002131   Batch Acc: 90.62
[Train] Epoch: 2 [25728/387873]    Loss: 0.002118   Batch Acc: 90.62
[Train] Epoch: 2 [25856/387873]    Loss: 0.001870   Batch Acc: 92.97
[Train] Epoch: 2 [25984/387873]    Loss: 0.002111   Batch Acc: 89.06
[Train] Epoch: 2 [26112/387873]    Loss: 0.003163   Batch Acc: 82.03
[Train] Epoch: 2 [26240/387873]    Loss: 0.001926   Batch Acc: 90.62
[Train] Epoch: 2 [26368/387873]    Loss: 0.001540   Batch Acc: 92.19
[Train] Epoch: 2 [26496/387873]    Loss: 0.001818   Batch Acc: 93.75
[Train] Epoch: 2 [26624/387873]    Loss: 0.001652   Batch Acc: 89.84
[Train] Epoch: 2 [26752/387873]    Loss: 0.002262   Batch Acc: 85.94
[Train] Epoch: 2 [26880/387873]    Loss: 0.001954   Batch Acc: 92.19
[Train] Epoch: 2 [27008/387873]    Loss: 0.001757   Batch Acc: 92.19
[Train] Epoch: 2 [27136/387873]    Loss: 0.001970   Batch Acc: 92.19
[Train] Epoch: 2 [27264/387873]    Loss: 0.001869   Batch Acc: 91.41
[Train] Epoch: 2 [27392/387873]    Loss: 0.002584   Batch Acc: 86.72
[Train] Epoch: 2 [27520/387873]    Loss: 0.001918   Batch Acc: 93.75
[Train] Epoch: 2 [27648/387873]    Loss: 0.002384   Batch Acc: 85.94
[Train] Epoch: 2 [27776/387873]    Loss: 0.001590   Batch Acc: 95.31
[Train] Epoch: 2 [27904/387873]    Loss: 0.002088   Batch Acc: 87.50
[Train] Epoch: 2 [28032/387873]    Loss: 0.002181   Batch Acc: 88.28
[Train] Epoch: 2 [28160/387873]    Loss: 0.001633   Batch Acc: 93.75
[Train] Epoch: 2 [28288/387873]    Loss: 0.002450   Batch Acc: 86.72
[Train] Epoch: 2 [28416/387873]    Loss: 0.002746   Batch Acc: 88.28
[Train] Epoch: 2 [28544/387873]    Loss: 0.001838   Batch Acc: 92.19
[Train] Epoch: 2 [28672/387873]    Loss: 0.001650   Batch Acc: 89.84
[Train] Epoch: 2 [28800/387873]    Loss: 0.001866   Batch Acc: 90.62
[Train] Epoch: 2 [28928/387873]    Loss: 0.002470   Batch Acc: 85.16
[Train] Epoch: 2 [29056/387873]    Loss: 0.002164   Batch Acc: 85.16
[Train] Epoch: 2 [29184/387873]    Loss: 0.002113   Batch Acc: 90.62
[Train] Epoch: 2 [29312/387873]    Loss: 0.002084   Batch Acc: 87.50
[Train] Epoch: 2 [29440/387873]    Loss: 0.001796   Batch Acc: 92.19
[Train] Epoch: 2 [29568/387873]    Loss: 0.002156   Batch Acc: 87.50
[Train] Epoch: 2 [29696/387873]    Loss: 0.002100   Batch Acc: 89.06
[Train] Epoch: 2 [29824/387873]    Loss: 0.002231   Batch Acc: 85.94
[Train] Epoch: 2 [29952/387873]    Loss: 0.001949   Batch Acc: 87.50
[Train] Epoch: 2 [30080/387873]    Loss: 0.002348   Batch Acc: 88.28
[Train] Epoch: 2 [30208/387873]    Loss: 0.002289   Batch Acc: 89.06
[Train] Epoch: 2 [30336/387873]    Loss: 0.001963   Batch Acc: 89.84
[Train] Epoch: 2 [30464/387873]    Loss: 0.002314   Batch Acc: 85.94
[Train] Epoch: 2 [30592/387873]    Loss: 0.002112   Batch Acc: 88.28
[Train] Epoch: 2 [30720/387873]    Loss: 0.001731   Batch Acc: 93.75
[Train] Epoch: 2 [30848/387873]    Loss: 0.002369   Batch Acc: 88.28
[Train] Epoch: 2 [30976/387873]    Loss: 0.002195   Batch Acc: 85.94
[Train] Epoch: 2 [31104/387873]    Loss: 0.001679   Batch Acc: 90.62
[Train] Epoch: 2 [31232/387873]    Loss: 0.002279   Batch Acc: 86.72
[Train] Epoch: 2 [31360/387873]    Loss: 0.001804   Batch Acc: 92.19
[Train] Epoch: 2 [31488/387873]    Loss: 0.002410   Batch Acc: 86.72
[Train] Epoch: 2 [31616/387873]    Loss: 0.002353   Batch Acc: 88.28
[Train] Epoch: 2 [31744/387873]    Loss: 0.002451   Batch Acc: 87.50
[Train] Epoch: 2 [31872/387873]    Loss: 0.001745   Batch Acc: 92.97
[Train] Epoch: 2 [32000/387873]    Loss: 0.001998   Batch Acc: 88.28
[Train] Epoch: 2 [32128/387873]    Loss: 0.002241   Batch Acc: 88.28
[Train] Epoch: 2 [32256/387873]    Loss: 0.001996   Batch Acc: 93.75
[Train] Epoch: 2 [32384/387873]    Loss: 0.002173   Batch Acc: 89.06
[Train] Epoch: 2 [32512/387873]    Loss: 0.002136   Batch Acc: 88.28
[Train] Epoch: 2 [32640/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 2 [32768/387873]    Loss: 0.002266   Batch Acc: 87.50
[Train] Epoch: 2 [32896/387873]    Loss: 0.001895   Batch Acc: 88.28
[Train] Epoch: 2 [33024/387873]    Loss: 0.001965   Batch Acc: 90.62
[Train] Epoch: 2 [33152/387873]    Loss: 0.002501   Batch Acc: 87.50
[Train] Epoch: 2 [33280/387873]    Loss: 0.002364   Batch Acc: 84.38
[Train] Epoch: 2 [33408/387873]    Loss: 0.002242   Batch Acc: 85.94
[Train] Epoch: 2 [33536/387873]    Loss: 0.002127   Batch Acc: 88.28
[Train] Epoch: 2 [33664/387873]    Loss: 0.001915   Batch Acc: 89.84
[Train] Epoch: 2 [33792/387873]    Loss: 0.002343   Batch Acc: 86.72
[Train] Epoch: 2 [33920/387873]    Loss: 0.002198   Batch Acc: 85.94
[Train] Epoch: 2 [34048/387873]    Loss: 0.002232   Batch Acc: 87.50
[Train] Epoch: 2 [34176/387873]    Loss: 0.001930   Batch Acc: 88.28
[Train] Epoch: 2 [34304/387873]    Loss: 0.002400   Batch Acc: 85.16
[Train] Epoch: 2 [34432/387873]    Loss: 0.002229   Batch Acc: 90.62
[Train] Epoch: 2 [34560/387873]    Loss: 0.002116   Batch Acc: 89.06
[Train] Epoch: 2 [34688/387873]    Loss: 0.002428   Batch Acc: 90.62
[Train] Epoch: 2 [34816/387873]    Loss: 0.002353   Batch Acc: 86.72
[Train] Epoch: 2 [34944/387873]    Loss: 0.002473   Batch Acc: 87.50
[Train] Epoch: 2 [35072/387873]    Loss: 0.001680   Batch Acc: 90.62
[Train] Epoch: 2 [35200/387873]    Loss: 0.002282   Batch Acc: 90.62
[Train] Epoch: 2 [35328/387873]    Loss: 0.002087   Batch Acc: 89.84
[Train] Epoch: 2 [35456/387873]    Loss: 0.001968   Batch Acc: 91.41
[Train] Epoch: 2 [35584/387873]    Loss: 0.002178   Batch Acc: 87.50
[Train] Epoch: 2 [35712/387873]    Loss: 0.002126   Batch Acc: 89.06
[Train] Epoch: 2 [35840/387873]    Loss: 0.002635   Batch Acc: 85.16
[Train] Epoch: 2 [35968/387873]    Loss: 0.001489   Batch Acc: 95.31
[Train] Epoch: 2 [36096/387873]    Loss: 0.001785   Batch Acc: 89.06
[Train] Epoch: 2 [36224/387873]    Loss: 0.002084   Batch Acc: 90.62
[Train] Epoch: 2 [36352/387873]    Loss: 0.002051   Batch Acc: 88.28
[Train] Epoch: 2 [36480/387873]    Loss: 0.001894   Batch Acc: 91.41
[Train] Epoch: 2 [36608/387873]    Loss: 0.002499   Batch Acc: 87.50
[Train] Epoch: 2 [36736/387873]    Loss: 0.002452   Batch Acc: 85.16
[Train] Epoch: 2 [36864/387873]    Loss: 0.002417   Batch Acc: 85.94
[Train] Epoch: 2 [36992/387873]    Loss: 0.001311   Batch Acc: 95.31
[Train] Epoch: 2 [37120/387873]    Loss: 0.002013   Batch Acc: 89.06
[Train] Epoch: 2 [37248/387873]    Loss: 0.002212   Batch Acc: 90.62
[Train] Epoch: 2 [37376/387873]    Loss: 0.001789   Batch Acc: 92.19
[Train] Epoch: 2 [37504/387873]    Loss: 0.001937   Batch Acc: 90.62
[Train] Epoch: 2 [37632/387873]    Loss: 0.002297   Batch Acc: 83.59
[Train] Epoch: 2 [37760/387873]    Loss: 0.002022   Batch Acc: 89.84
[Train] Epoch: 2 [37888/387873]    Loss: 0.002187   Batch Acc: 87.50
[Train] Epoch: 2 [38016/387873]    Loss: 0.001939   Batch Acc: 89.84
[Train] Epoch: 2 [38144/387873]    Loss: 0.002670   Batch Acc: 87.50
[Train] Epoch: 2 [38272/387873]    Loss: 0.002108   Batch Acc: 90.62
[Train] Epoch: 2 [38400/387873]    Loss: 0.001813   Batch Acc: 92.97
[Train] Epoch: 2 [38528/387873]    Loss: 0.001785   Batch Acc: 92.19
[Train] Epoch: 2 [38656/387873]    Loss: 0.001724   Batch Acc: 90.62
[Train] Epoch: 2 [38784/387873]    Loss: 0.002063   Batch Acc: 87.50
[Train] Epoch: 2 [38912/387873]    Loss: 0.002076   Batch Acc: 90.62
[Train] Epoch: 2 [39040/387873]    Loss: 0.001759   Batch Acc: 92.19
[Train] Epoch: 2 [39168/387873]    Loss: 0.002187   Batch Acc: 88.28
[Train] Epoch: 2 [39296/387873]    Loss: 0.001419   Batch Acc: 93.75
[Train] Epoch: 2 [39424/387873]    Loss: 0.001931   Batch Acc: 87.50
[Train] Epoch: 2 [39552/387873]    Loss: 0.002575   Batch Acc: 85.94
[Train] Epoch: 2 [39680/387873]    Loss: 0.001813   Batch Acc: 89.84
[Train] Epoch: 2 [39808/387873]    Loss: 0.001565   Batch Acc: 91.41
[Train] Epoch: 2 [39936/387873]    Loss: 0.001832   Batch Acc: 92.97
[Train] Epoch: 2 [40064/387873]    Loss: 0.002250   Batch Acc: 87.50
[Train] Epoch: 2 [40192/387873]    Loss: 0.001441   Batch Acc: 94.53
[Train] Epoch: 2 [40320/387873]    Loss: 0.002129   Batch Acc: 86.72
[Train] Epoch: 2 [40448/387873]    Loss: 0.002208   Batch Acc: 89.06
[Train] Epoch: 2 [40576/387873]    Loss: 0.002074   Batch Acc: 92.97
[Train] Epoch: 2 [40704/387873]    Loss: 0.002967   Batch Acc: 84.38
[Train] Epoch: 2 [40832/387873]    Loss: 0.002802   Batch Acc: 81.25
[Train] Epoch: 2 [40960/387873]    Loss: 0.001919   Batch Acc: 88.28
[Train] Epoch: 2 [41088/387873]    Loss: 0.002275   Batch Acc: 90.62
[Train] Epoch: 2 [41216/387873]    Loss: 0.001777   Batch Acc: 89.06
[Train] Epoch: 2 [41344/387873]    Loss: 0.002363   Batch Acc: 87.50
[Train] Epoch: 2 [41472/387873]    Loss: 0.002161   Batch Acc: 87.50
[Train] Epoch: 2 [41600/387873]    Loss: 0.002148   Batch Acc: 88.28
[Train] Epoch: 2 [41728/387873]    Loss: 0.002382   Batch Acc: 86.72
[Train] Epoch: 2 [41856/387873]    Loss: 0.001971   Batch Acc: 91.41
[Train] Epoch: 2 [41984/387873]    Loss: 0.001843   Batch Acc: 91.41
[Train] Epoch: 2 [42112/387873]    Loss: 0.001988   Batch Acc: 90.62
[Train] Epoch: 2 [42240/387873]    Loss: 0.001627   Batch Acc: 93.75
[Train] Epoch: 2 [42368/387873]    Loss: 0.001552   Batch Acc: 94.53
[Train] Epoch: 2 [42496/387873]    Loss: 0.002398   Batch Acc: 85.16
[Train] Epoch: 2 [42624/387873]    Loss: 0.001735   Batch Acc: 92.97
[Train] Epoch: 2 [42752/387873]    Loss: 0.001557   Batch Acc: 91.41
[Train] Epoch: 2 [42880/387873]    Loss: 0.001260   Batch Acc: 95.31
[Train] Epoch: 2 [43008/387873]    Loss: 0.002336   Batch Acc: 85.94
[Train] Epoch: 2 [43136/387873]    Loss: 0.002144   Batch Acc: 87.50
[Train] Epoch: 2 [43264/387873]    Loss: 0.001805   Batch Acc: 91.41
[Train] Epoch: 2 [43392/387873]    Loss: 0.002513   Batch Acc: 87.50
[Train] Epoch: 2 [43520/387873]    Loss: 0.002073   Batch Acc: 85.16
[Train] Epoch: 2 [43648/387873]    Loss: 0.002268   Batch Acc: 85.94
[Train] Epoch: 2 [43776/387873]    Loss: 0.001615   Batch Acc: 93.75
[Train] Epoch: 2 [43904/387873]    Loss: 0.001399   Batch Acc: 93.75
[Train] Epoch: 2 [44032/387873]    Loss: 0.001808   Batch Acc: 87.50
[Train] Epoch: 2 [44160/387873]    Loss: 0.002162   Batch Acc: 89.06
[Train] Epoch: 2 [44288/387873]    Loss: 0.001858   Batch Acc: 94.53
[Train] Epoch: 2 [44416/387873]    Loss: 0.001860   Batch Acc: 89.84
[Train] Epoch: 2 [44544/387873]    Loss: 0.002355   Batch Acc: 85.16
[Train] Epoch: 2 [44672/387873]    Loss: 0.002236   Batch Acc: 89.84
[Train] Epoch: 2 [44800/387873]    Loss: 0.001851   Batch Acc: 89.84
[Train] Epoch: 2 [44928/387873]    Loss: 0.001559   Batch Acc: 94.53
[Train] Epoch: 2 [45056/387873]    Loss: 0.002207   Batch Acc: 87.50
[Train] Epoch: 2 [45184/387873]    Loss: 0.002538   Batch Acc: 85.16
[Train] Epoch: 2 [45312/387873]    Loss: 0.001691   Batch Acc: 90.62
[Train] Epoch: 2 [45440/387873]    Loss: 0.002193   Batch Acc: 89.06
[Train] Epoch: 2 [45568/387873]    Loss: 0.002288   Batch Acc: 88.28
[Train] Epoch: 2 [45696/387873]    Loss: 0.001911   Batch Acc: 90.62
[Train] Epoch: 2 [45824/387873]    Loss: 0.002236   Batch Acc: 88.28
[Train] Epoch: 2 [45952/387873]    Loss: 0.001923   Batch Acc: 90.62
[Train] Epoch: 2 [46080/387873]    Loss: 0.002177   Batch Acc: 88.28
[Train] Epoch: 2 [46208/387873]    Loss: 0.001910   Batch Acc: 91.41
[Train] Epoch: 2 [46336/387873]    Loss: 0.001980   Batch Acc: 92.19
[Train] Epoch: 2 [46464/387873]    Loss: 0.002423   Batch Acc: 85.16
[Train] Epoch: 2 [46592/387873]    Loss: 0.001486   Batch Acc: 93.75
[Train] Epoch: 2 [46720/387873]    Loss: 0.002355   Batch Acc: 87.50
[Train] Epoch: 2 [46848/387873]    Loss: 0.001797   Batch Acc: 90.62
[Train] Epoch: 2 [46976/387873]    Loss: 0.002053   Batch Acc: 88.28
[Train] Epoch: 2 [47104/387873]    Loss: 0.002577   Batch Acc: 88.28
[Train] Epoch: 2 [47232/387873]    Loss: 0.002361   Batch Acc: 85.16
[Train] Epoch: 2 [47360/387873]    Loss: 0.001836   Batch Acc: 92.19
[Train] Epoch: 2 [47488/387873]    Loss: 0.002127   Batch Acc: 89.06
[Train] Epoch: 2 [47616/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 2 [47744/387873]    Loss: 0.002257   Batch Acc: 87.50
[Train] Epoch: 2 [47872/387873]    Loss: 0.002501   Batch Acc: 87.50
[Train] Epoch: 2 [48000/387873]    Loss: 0.002304   Batch Acc: 90.62
[Train] Epoch: 2 [48128/387873]    Loss: 0.002299   Batch Acc: 89.06
[Train] Epoch: 2 [48256/387873]    Loss: 0.002134   Batch Acc: 88.28
[Train] Epoch: 2 [48384/387873]    Loss: 0.002060   Batch Acc: 90.62
[Train] Epoch: 2 [48512/387873]    Loss: 0.001748   Batch Acc: 92.19
[Train] Epoch: 2 [48640/387873]    Loss: 0.002192   Batch Acc: 86.72
[Train] Epoch: 2 [48768/387873]    Loss: 0.001911   Batch Acc: 91.41
[Train] Epoch: 2 [48896/387873]    Loss: 0.001870   Batch Acc: 91.41
[Train] Epoch: 2 [49024/387873]    Loss: 0.002236   Batch Acc: 89.84
[Train] Epoch: 2 [49152/387873]    Loss: 0.002166   Batch Acc: 88.28
[Train] Epoch: 2 [49280/387873]    Loss: 0.002204   Batch Acc: 86.72
[Train] Epoch: 2 [49408/387873]    Loss: 0.001646   Batch Acc: 94.53
[Train] Epoch: 2 [49536/387873]    Loss: 0.001874   Batch Acc: 90.62
[Train] Epoch: 2 [49664/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 2 [49792/387873]    Loss: 0.002317   Batch Acc: 87.50
[Train] Epoch: 2 [49920/387873]    Loss: 0.002265   Batch Acc: 85.16
[Train] Epoch: 2 [50048/387873]    Loss: 0.001726   Batch Acc: 92.19
[Train] Epoch: 2 [50176/387873]    Loss: 0.002001   Batch Acc: 91.41
[Train] Epoch: 2 [50304/387873]    Loss: 0.002167   Batch Acc: 88.28
[Train] Epoch: 2 [50432/387873]    Loss: 0.002051   Batch Acc: 88.28
[Train] Epoch: 2 [50560/387873]    Loss: 0.001843   Batch Acc: 90.62
[Train] Epoch: 2 [50688/387873]    Loss: 0.002101   Batch Acc: 91.41
[Train] Epoch: 2 [50816/387873]    Loss: 0.002278   Batch Acc: 86.72
[Train] Epoch: 2 [50944/387873]    Loss: 0.002788   Batch Acc: 86.72
[Train] Epoch: 2 [51072/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 2 [51200/387873]    Loss: 0.002046   Batch Acc: 89.84
[Train] Epoch: 2 [51328/387873]    Loss: 0.001606   Batch Acc: 90.62
[Train] Epoch: 2 [51456/387873]    Loss: 0.001941   Batch Acc: 89.84
[Train] Epoch: 2 [51584/387873]    Loss: 0.002547   Batch Acc: 85.16
[Train] Epoch: 2 [51712/387873]    Loss: 0.002537   Batch Acc: 85.16
[Train] Epoch: 2 [51840/387873]    Loss: 0.002239   Batch Acc: 87.50
[Train] Epoch: 2 [51968/387873]    Loss: 0.001920   Batch Acc: 92.19
[Train] Epoch: 2 [52096/387873]    Loss: 0.002079   Batch Acc: 86.72
[Train] Epoch: 2 [52224/387873]    Loss: 0.001595   Batch Acc: 93.75
[Train] Epoch: 2 [52352/387873]    Loss: 0.002325   Batch Acc: 88.28
[Train] Epoch: 2 [52480/387873]    Loss: 0.001883   Batch Acc: 89.84
[Train] Epoch: 2 [52608/387873]    Loss: 0.001667   Batch Acc: 90.62
[Train] Epoch: 2 [52736/387873]    Loss: 0.002292   Batch Acc: 86.72
[Train] Epoch: 2 [52864/387873]    Loss: 0.002380   Batch Acc: 85.16
[Train] Epoch: 2 [52992/387873]    Loss: 0.002216   Batch Acc: 88.28
[Train] Epoch: 2 [53120/387873]    Loss: 0.001939   Batch Acc: 87.50
[Train] Epoch: 2 [53248/387873]    Loss: 0.003016   Batch Acc: 85.94
[Train] Epoch: 2 [53376/387873]    Loss: 0.002502   Batch Acc: 84.38
[Train] Epoch: 2 [53504/387873]    Loss: 0.001779   Batch Acc: 93.75
[Train] Epoch: 2 [53632/387873]    Loss: 0.002267   Batch Acc: 87.50
[Train] Epoch: 2 [53760/387873]    Loss: 0.001988   Batch Acc: 89.06
[Train] Epoch: 2 [53888/387873]    Loss: 0.001939   Batch Acc: 88.28
[Train] Epoch: 2 [54016/387873]    Loss: 0.001916   Batch Acc: 88.28
[Train] Epoch: 2 [54144/387873]    Loss: 0.001846   Batch Acc: 92.19
[Train] Epoch: 2 [54272/387873]    Loss: 0.001770   Batch Acc: 92.19
[Train] Epoch: 2 [54400/387873]    Loss: 0.002134   Batch Acc: 89.06
[Train] Epoch: 2 [54528/387873]    Loss: 0.002193   Batch Acc: 89.84
[Train] Epoch: 2 [54656/387873]    Loss: 0.002373   Batch Acc: 87.50
[Train] Epoch: 2 [54784/387873]    Loss: 0.002680   Batch Acc: 83.59
[Train] Epoch: 2 [54912/387873]    Loss: 0.002253   Batch Acc: 85.94
[Train] Epoch: 2 [55040/387873]    Loss: 0.001786   Batch Acc: 93.75
[Train] Epoch: 2 [55168/387873]    Loss: 0.001881   Batch Acc: 89.84
[Train] Epoch: 2 [55296/387873]    Loss: 0.001903   Batch Acc: 91.41
[Train] Epoch: 2 [55424/387873]    Loss: 0.001972   Batch Acc: 89.06
[Train] Epoch: 2 [55552/387873]    Loss: 0.002214   Batch Acc: 86.72
[Train] Epoch: 2 [55680/387873]    Loss: 0.002318   Batch Acc: 90.62
[Train] Epoch: 2 [55808/387873]    Loss: 0.001954   Batch Acc: 89.06
[Train] Epoch: 2 [55936/387873]    Loss: 0.002031   Batch Acc: 86.72
[Train] Epoch: 2 [56064/387873]    Loss: 0.002091   Batch Acc: 89.06
[Train] Epoch: 2 [56192/387873]    Loss: 0.001782   Batch Acc: 92.19
[Train] Epoch: 2 [56320/387873]    Loss: 0.002188   Batch Acc: 86.72
[Train] Epoch: 2 [56448/387873]    Loss: 0.002150   Batch Acc: 88.28
[Train] Epoch: 2 [56576/387873]    Loss: 0.002141   Batch Acc: 89.06
[Train] Epoch: 2 [56704/387873]    Loss: 0.002195   Batch Acc: 87.50
[Train] Epoch: 2 [56832/387873]    Loss: 0.001599   Batch Acc: 91.41
[Train] Epoch: 2 [56960/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 2 [57088/387873]    Loss: 0.002072   Batch Acc: 90.62
[Train] Epoch: 2 [57216/387873]    Loss: 0.001774   Batch Acc: 89.84
[Train] Epoch: 2 [57344/387873]    Loss: 0.001791   Batch Acc: 91.41
[Train] Epoch: 2 [57472/387873]    Loss: 0.001859   Batch Acc: 91.41
[Train] Epoch: 2 [57600/387873]    Loss: 0.001631   Batch Acc: 92.97
[Train] Epoch: 2 [57728/387873]    Loss: 0.002041   Batch Acc: 88.28
[Train] Epoch: 2 [57856/387873]    Loss: 0.001821   Batch Acc: 89.84
[Train] Epoch: 2 [57984/387873]    Loss: 0.002337   Batch Acc: 89.06
[Train] Epoch: 2 [58112/387873]    Loss: 0.002201   Batch Acc: 87.50
[Train] Epoch: 2 [58240/387873]    Loss: 0.001849   Batch Acc: 92.19
[Train] Epoch: 2 [58368/387873]    Loss: 0.002665   Batch Acc: 83.59
[Train] Epoch: 2 [58496/387873]    Loss: 0.002241   Batch Acc: 86.72
[Train] Epoch: 2 [58624/387873]    Loss: 0.002525   Batch Acc: 86.72
[Train] Epoch: 2 [58752/387873]    Loss: 0.001724   Batch Acc: 92.19
[Train] Epoch: 2 [58880/387873]    Loss: 0.002816   Batch Acc: 84.38
[Train] Epoch: 2 [59008/387873]    Loss: 0.001987   Batch Acc: 90.62
[Train] Epoch: 2 [59136/387873]    Loss: 0.002223   Batch Acc: 89.84
[Train] Epoch: 2 [59264/387873]    Loss: 0.001453   Batch Acc: 92.97
[Train] Epoch: 2 [59392/387873]    Loss: 0.002229   Batch Acc: 87.50
[Train] Epoch: 2 [59520/387873]    Loss: 0.002024   Batch Acc: 89.06
[Train] Epoch: 2 [59648/387873]    Loss: 0.001758   Batch Acc: 92.97
[Train] Epoch: 2 [59776/387873]    Loss: 0.002518   Batch Acc: 85.16
[Train] Epoch: 2 [59904/387873]    Loss: 0.001886   Batch Acc: 92.19
[Train] Epoch: 2 [60032/387873]    Loss: 0.002451   Batch Acc: 85.94
[Train] Epoch: 2 [60160/387873]    Loss: 0.001573   Batch Acc: 92.19
[Train] Epoch: 2 [60288/387873]    Loss: 0.001642   Batch Acc: 94.53
[Train] Epoch: 2 [60416/387873]    Loss: 0.001991   Batch Acc: 92.19
[Train] Epoch: 2 [60544/387873]    Loss: 0.002496   Batch Acc: 83.59
[Train] Epoch: 2 [60672/387873]    Loss: 0.002162   Batch Acc: 87.50
[Train] Epoch: 2 [60800/387873]    Loss: 0.002242   Batch Acc: 86.72
[Train] Epoch: 2 [60928/387873]    Loss: 0.002312   Batch Acc: 85.16
[Train] Epoch: 2 [61056/387873]    Loss: 0.001409   Batch Acc: 94.53
[Train] Epoch: 2 [61184/387873]    Loss: 0.001999   Batch Acc: 90.62
[Train] Epoch: 2 [61312/387873]    Loss: 0.001812   Batch Acc: 91.41
[Train] Epoch: 2 [61440/387873]    Loss: 0.002711   Batch Acc: 88.28
[Train] Epoch: 2 [61568/387873]    Loss: 0.001827   Batch Acc: 90.62
[Train] Epoch: 2 [61696/387873]    Loss: 0.001767   Batch Acc: 89.84
[Train] Epoch: 2 [61824/387873]    Loss: 0.001995   Batch Acc: 89.84
[Train] Epoch: 2 [61952/387873]    Loss: 0.001594   Batch Acc: 93.75
[Train] Epoch: 2 [62080/387873]    Loss: 0.001918   Batch Acc: 89.84
[Train] Epoch: 2 [62208/387873]    Loss: 0.001997   Batch Acc: 90.62
[Train] Epoch: 2 [62336/387873]    Loss: 0.001826   Batch Acc: 89.06
[Train] Epoch: 2 [62464/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 2 [62592/387873]    Loss: 0.001772   Batch Acc: 92.97
[Train] Epoch: 2 [62720/387873]    Loss: 0.002136   Batch Acc: 87.50
[Train] Epoch: 2 [62848/387873]    Loss: 0.002403   Batch Acc: 88.28
[Train] Epoch: 2 [62976/387873]    Loss: 0.002372   Batch Acc: 86.72
[Train] Epoch: 2 [63104/387873]    Loss: 0.002216   Batch Acc: 86.72
[Train] Epoch: 2 [63232/387873]    Loss: 0.002147   Batch Acc: 89.84
[Train] Epoch: 2 [63360/387873]    Loss: 0.002200   Batch Acc: 87.50
[Train] Epoch: 2 [63488/387873]    Loss: 0.002389   Batch Acc: 89.06
[Train] Epoch: 2 [63616/387873]    Loss: 0.002084   Batch Acc: 92.19
[Train] Epoch: 2 [63744/387873]    Loss: 0.001817   Batch Acc: 90.62
[Train] Epoch: 2 [63872/387873]    Loss: 0.002235   Batch Acc: 87.50
[Train] Epoch: 2 [64000/387873]    Loss: 0.001950   Batch Acc: 91.41
[Train] Epoch: 2 [64128/387873]    Loss: 0.002284   Batch Acc: 89.84
[Train] Epoch: 2 [64256/387873]    Loss: 0.002200   Batch Acc: 89.06
[Train] Epoch: 2 [64384/387873]    Loss: 0.002107   Batch Acc: 89.06
[Train] Epoch: 2 [64512/387873]    Loss: 0.002272   Batch Acc: 86.72
[Train] Epoch: 2 [64640/387873]    Loss: 0.002226   Batch Acc: 87.50
[Train] Epoch: 2 [64768/387873]    Loss: 0.002477   Batch Acc: 85.94
[Train] Epoch: 2 [64896/387873]    Loss: 0.001686   Batch Acc: 92.19
[Train] Epoch: 2 [65024/387873]    Loss: 0.001861   Batch Acc: 87.50
[Train] Epoch: 2 [65152/387873]    Loss: 0.002927   Batch Acc: 81.25
[Train] Epoch: 2 [65280/387873]    Loss: 0.001747   Batch Acc: 91.41
[Train] Epoch: 2 [65408/387873]    Loss: 0.001786   Batch Acc: 94.53
[Train] Epoch: 2 [65536/387873]    Loss: 0.002021   Batch Acc: 89.84
[Train] Epoch: 2 [65664/387873]    Loss: 0.001998   Batch Acc: 88.28
[Train] Epoch: 2 [65792/387873]    Loss: 0.002099   Batch Acc: 89.84
[Train] Epoch: 2 [65920/387873]    Loss: 0.002496   Batch Acc: 85.94
[Train] Epoch: 2 [66048/387873]    Loss: 0.002302   Batch Acc: 85.94
[Train] Epoch: 2 [66176/387873]    Loss: 0.001538   Batch Acc: 92.19
[Train] Epoch: 2 [66304/387873]    Loss: 0.001267   Batch Acc: 95.31
[Train] Epoch: 2 [66432/387873]    Loss: 0.001715   Batch Acc: 92.97
[Train] Epoch: 2 [66560/387873]    Loss: 0.002070   Batch Acc: 90.62
[Train] Epoch: 2 [66688/387873]    Loss: 0.002306   Batch Acc: 82.03
[Train] Epoch: 2 [66816/387873]    Loss: 0.001990   Batch Acc: 89.06
[Train] Epoch: 2 [66944/387873]    Loss: 0.002468   Batch Acc: 87.50
[Train] Epoch: 2 [67072/387873]    Loss: 0.001649   Batch Acc: 91.41
[Train] Epoch: 2 [67200/387873]    Loss: 0.002121   Batch Acc: 85.94
[Train] Epoch: 2 [67328/387873]    Loss: 0.001850   Batch Acc: 90.62
[Train] Epoch: 2 [67456/387873]    Loss: 0.001403   Batch Acc: 93.75
[Train] Epoch: 2 [67584/387873]    Loss: 0.002495   Batch Acc: 85.94
[Train] Epoch: 2 [67712/387873]    Loss: 0.002353   Batch Acc: 85.16
[Train] Epoch: 2 [67840/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 2 [67968/387873]    Loss: 0.002198   Batch Acc: 86.72
[Train] Epoch: 2 [68096/387873]    Loss: 0.001841   Batch Acc: 90.62
[Train] Epoch: 2 [68224/387873]    Loss: 0.002458   Batch Acc: 86.72
[Train] Epoch: 2 [68352/387873]    Loss: 0.001765   Batch Acc: 94.53
[Train] Epoch: 2 [68480/387873]    Loss: 0.002486   Batch Acc: 85.94
[Train] Epoch: 2 [68608/387873]    Loss: 0.002502   Batch Acc: 86.72
[Train] Epoch: 2 [68736/387873]    Loss: 0.001646   Batch Acc: 92.97
[Train] Epoch: 2 [68864/387873]    Loss: 0.002069   Batch Acc: 86.72
[Train] Epoch: 2 [68992/387873]    Loss: 0.002007   Batch Acc: 89.84
[Train] Epoch: 2 [69120/387873]    Loss: 0.002482   Batch Acc: 85.94
[Train] Epoch: 2 [69248/387873]    Loss: 0.002437   Batch Acc: 85.94
[Train] Epoch: 2 [69376/387873]    Loss: 0.001802   Batch Acc: 91.41
[Train] Epoch: 2 [69504/387873]    Loss: 0.001841   Batch Acc: 89.84
[Train] Epoch: 2 [69632/387873]    Loss: 0.001412   Batch Acc: 95.31
[Train] Epoch: 2 [69760/387873]    Loss: 0.001725   Batch Acc: 92.19
[Train] Epoch: 2 [69888/387873]    Loss: 0.002615   Batch Acc: 84.38
[Train] Epoch: 2 [70016/387873]    Loss: 0.001954   Batch Acc: 89.84
[Train] Epoch: 2 [70144/387873]    Loss: 0.001901   Batch Acc: 91.41
[Train] Epoch: 2 [70272/387873]    Loss: 0.001642   Batch Acc: 90.62
[Train] Epoch: 2 [70400/387873]    Loss: 0.001852   Batch Acc: 90.62
[Train] Epoch: 2 [70528/387873]    Loss: 0.001841   Batch Acc: 91.41
[Train] Epoch: 2 [70656/387873]    Loss: 0.002452   Batch Acc: 89.84
[Train] Epoch: 2 [70784/387873]    Loss: 0.002572   Batch Acc: 85.94
[Train] Epoch: 2 [70912/387873]    Loss: 0.002499   Batch Acc: 83.59
[Train] Epoch: 2 [71040/387873]    Loss: 0.001865   Batch Acc: 90.62
[Train] Epoch: 2 [71168/387873]    Loss: 0.001412   Batch Acc: 93.75
[Train] Epoch: 2 [71296/387873]    Loss: 0.002024   Batch Acc: 88.28
[Train] Epoch: 2 [71424/387873]    Loss: 0.002245   Batch Acc: 87.50
[Train] Epoch: 2 [71552/387873]    Loss: 0.001893   Batch Acc: 91.41
[Train] Epoch: 2 [71680/387873]    Loss: 0.001928   Batch Acc: 89.84
[Train] Epoch: 2 [71808/387873]    Loss: 0.001592   Batch Acc: 93.75
[Train] Epoch: 2 [71936/387873]    Loss: 0.002228   Batch Acc: 89.84
[Train] Epoch: 2 [72064/387873]    Loss: 0.001791   Batch Acc: 93.75
[Train] Epoch: 2 [72192/387873]    Loss: 0.002351   Batch Acc: 85.94
[Train] Epoch: 2 [72320/387873]    Loss: 0.002032   Batch Acc: 83.59
[Train] Epoch: 2 [72448/387873]    Loss: 0.002049   Batch Acc: 89.06
[Train] Epoch: 2 [72576/387873]    Loss: 0.002172   Batch Acc: 91.41
[Train] Epoch: 2 [72704/387873]    Loss: 0.001727   Batch Acc: 92.19
[Train] Epoch: 2 [72832/387873]    Loss: 0.001919   Batch Acc: 92.19
[Train] Epoch: 2 [72960/387873]    Loss: 0.001712   Batch Acc: 91.41
[Train] Epoch: 2 [73088/387873]    Loss: 0.002493   Batch Acc: 82.81
[Train] Epoch: 2 [73216/387873]    Loss: 0.002443   Batch Acc: 87.50
[Train] Epoch: 2 [73344/387873]    Loss: 0.002173   Batch Acc: 86.72
[Train] Epoch: 2 [73472/387873]    Loss: 0.002187   Batch Acc: 88.28
[Train] Epoch: 2 [73600/387873]    Loss: 0.002466   Batch Acc: 85.94
[Train] Epoch: 2 [73728/387873]    Loss: 0.001739   Batch Acc: 90.62
[Train] Epoch: 2 [73856/387873]    Loss: 0.002211   Batch Acc: 86.72
[Train] Epoch: 2 [73984/387873]    Loss: 0.002222   Batch Acc: 88.28
[Train] Epoch: 2 [74112/387873]    Loss: 0.001827   Batch Acc: 91.41
[Train] Epoch: 2 [74240/387873]    Loss: 0.001837   Batch Acc: 89.84
[Train] Epoch: 2 [74368/387873]    Loss: 0.001777   Batch Acc: 89.06
[Train] Epoch: 2 [74496/387873]    Loss: 0.002071   Batch Acc: 89.84
[Train] Epoch: 2 [74624/387873]    Loss: 0.002078   Batch Acc: 86.72
[Train] Epoch: 2 [74752/387873]    Loss: 0.001830   Batch Acc: 90.62
[Train] Epoch: 2 [74880/387873]    Loss: 0.001448   Batch Acc: 92.97
[Train] Epoch: 2 [75008/387873]    Loss: 0.002144   Batch Acc: 89.06
[Train] Epoch: 2 [75136/387873]    Loss: 0.002027   Batch Acc: 88.28
[Train] Epoch: 2 [75264/387873]    Loss: 0.001947   Batch Acc: 89.06
[Train] Epoch: 2 [75392/387873]    Loss: 0.002480   Batch Acc: 85.16
[Train] Epoch: 2 [75520/387873]    Loss: 0.002355   Batch Acc: 85.94
[Train] Epoch: 2 [75648/387873]    Loss: 0.001850   Batch Acc: 89.84
[Train] Epoch: 2 [75776/387873]    Loss: 0.002258   Batch Acc: 87.50
[Train] Epoch: 2 [75904/387873]    Loss: 0.001751   Batch Acc: 90.62
[Train] Epoch: 2 [76032/387873]    Loss: 0.002272   Batch Acc: 85.94
[Train] Epoch: 2 [76160/387873]    Loss: 0.002038   Batch Acc: 90.62
[Train] Epoch: 2 [76288/387873]    Loss: 0.001847   Batch Acc: 89.06
[Train] Epoch: 2 [76416/387873]    Loss: 0.002247   Batch Acc: 89.84
[Train] Epoch: 2 [76544/387873]    Loss: 0.001962   Batch Acc: 90.62
[Train] Epoch: 2 [76672/387873]    Loss: 0.002445   Batch Acc: 84.38
[Train] Epoch: 2 [76800/387873]    Loss: 0.002279   Batch Acc: 87.50
[Train] Epoch: 2 [76928/387873]    Loss: 0.001942   Batch Acc: 90.62
[Train] Epoch: 2 [77056/387873]    Loss: 0.001867   Batch Acc: 90.62
[Train] Epoch: 2 [77184/387873]    Loss: 0.001619   Batch Acc: 91.41
[Train] Epoch: 2 [77312/387873]    Loss: 0.002075   Batch Acc: 89.84
[Train] Epoch: 2 [77440/387873]    Loss: 0.002398   Batch Acc: 88.28
[Train] Epoch: 2 [77568/387873]    Loss: 0.002210   Batch Acc: 87.50
[Train] Epoch: 2 [77696/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 2 [77824/387873]    Loss: 0.002033   Batch Acc: 90.62
[Train] Epoch: 2 [77952/387873]    Loss: 0.002072   Batch Acc: 86.72
[Train] Epoch: 2 [78080/387873]    Loss: 0.001786   Batch Acc: 92.19
[Train] Epoch: 2 [78208/387873]    Loss: 0.002007   Batch Acc: 89.06
[Train] Epoch: 2 [78336/387873]    Loss: 0.001477   Batch Acc: 95.31
[Train] Epoch: 2 [78464/387873]    Loss: 0.002147   Batch Acc: 87.50
[Train] Epoch: 2 [78592/387873]    Loss: 0.002152   Batch Acc: 90.62
[Train] Epoch: 2 [78720/387873]    Loss: 0.002419   Batch Acc: 88.28
[Train] Epoch: 2 [78848/387873]    Loss: 0.002196   Batch Acc: 87.50
[Train] Epoch: 2 [78976/387873]    Loss: 0.001844   Batch Acc: 92.19
[Train] Epoch: 2 [79104/387873]    Loss: 0.001784   Batch Acc: 92.19
[Train] Epoch: 2 [79232/387873]    Loss: 0.002451   Batch Acc: 87.50
[Train] Epoch: 2 [79360/387873]    Loss: 0.002062   Batch Acc: 91.41
[Train] Epoch: 2 [79488/387873]    Loss: 0.001740   Batch Acc: 90.62
[Train] Epoch: 2 [79616/387873]    Loss: 0.001808   Batch Acc: 89.06
[Train] Epoch: 2 [79744/387873]    Loss: 0.002297   Batch Acc: 88.28
[Train] Epoch: 2 [79872/387873]    Loss: 0.002212   Batch Acc: 89.06
[Train] Epoch: 2 [80000/387873]    Loss: 0.002404   Batch Acc: 86.72
[Train] Epoch: 2 [80128/387873]    Loss: 0.001838   Batch Acc: 92.19
[Train] Epoch: 2 [80256/387873]    Loss: 0.002237   Batch Acc: 87.50
[Train] Epoch: 2 [80384/387873]    Loss: 0.001884   Batch Acc: 89.06
[Train] Epoch: 2 [80512/387873]    Loss: 0.002302   Batch Acc: 84.38
[Train] Epoch: 2 [80640/387873]    Loss: 0.001454   Batch Acc: 95.31
[Train] Epoch: 2 [80768/387873]    Loss: 0.002098   Batch Acc: 89.06
[Train] Epoch: 2 [80896/387873]    Loss: 0.002296   Batch Acc: 89.06
[Train] Epoch: 2 [81024/387873]    Loss: 0.002197   Batch Acc: 88.28
[Train] Epoch: 2 [81152/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 2 [81280/387873]    Loss: 0.001607   Batch Acc: 92.97
[Train] Epoch: 2 [81408/387873]    Loss: 0.002272   Batch Acc: 87.50
[Train] Epoch: 2 [81536/387873]    Loss: 0.001969   Batch Acc: 89.06
[Train] Epoch: 2 [81664/387873]    Loss: 0.002022   Batch Acc: 91.41
[Train] Epoch: 2 [81792/387873]    Loss: 0.002144   Batch Acc: 89.06
[Train] Epoch: 2 [81920/387873]    Loss: 0.001843   Batch Acc: 89.84
[Train] Epoch: 2 [82048/387873]    Loss: 0.001656   Batch Acc: 91.41
[Train] Epoch: 2 [82176/387873]    Loss: 0.001947   Batch Acc: 92.97
[Train] Epoch: 2 [82304/387873]    Loss: 0.002333   Batch Acc: 85.94
[Train] Epoch: 2 [82432/387873]    Loss: 0.001532   Batch Acc: 92.97
[Train] Epoch: 2 [82560/387873]    Loss: 0.001891   Batch Acc: 92.19
[Train] Epoch: 2 [82688/387873]    Loss: 0.002174   Batch Acc: 86.72
[Train] Epoch: 2 [82816/387873]    Loss: 0.001658   Batch Acc: 93.75
[Train] Epoch: 2 [82944/387873]    Loss: 0.002283   Batch Acc: 86.72
[Train] Epoch: 2 [83072/387873]    Loss: 0.001950   Batch Acc: 86.72
[Train] Epoch: 2 [83200/387873]    Loss: 0.002039   Batch Acc: 89.84
[Train] Epoch: 2 [83328/387873]    Loss: 0.001378   Batch Acc: 93.75
[Train] Epoch: 2 [83456/387873]    Loss: 0.002098   Batch Acc: 89.84
[Train] Epoch: 2 [83584/387873]    Loss: 0.002028   Batch Acc: 90.62
[Train] Epoch: 2 [83712/387873]    Loss: 0.002095   Batch Acc: 90.62
[Train] Epoch: 2 [83840/387873]    Loss: 0.001861   Batch Acc: 88.28
[Train] Epoch: 2 [83968/387873]    Loss: 0.001786   Batch Acc: 91.41
[Train] Epoch: 2 [84096/387873]    Loss: 0.001637   Batch Acc: 93.75
[Train] Epoch: 2 [84224/387873]    Loss: 0.002194   Batch Acc: 85.94
[Train] Epoch: 2 [84352/387873]    Loss: 0.001890   Batch Acc: 89.06
[Train] Epoch: 2 [84480/387873]    Loss: 0.002374   Batch Acc: 89.84
[Train] Epoch: 2 [84608/387873]    Loss: 0.002572   Batch Acc: 85.16
[Train] Epoch: 2 [84736/387873]    Loss: 0.001880   Batch Acc: 89.84
[Train] Epoch: 2 [84864/387873]    Loss: 0.001757   Batch Acc: 90.62
[Train] Epoch: 2 [84992/387873]    Loss: 0.001877   Batch Acc: 91.41
[Train] Epoch: 2 [85120/387873]    Loss: 0.002080   Batch Acc: 90.62
[Train] Epoch: 2 [85248/387873]    Loss: 0.001551   Batch Acc: 93.75
[Train] Epoch: 2 [85376/387873]    Loss: 0.001922   Batch Acc: 89.84
[Train] Epoch: 2 [85504/387873]    Loss: 0.002257   Batch Acc: 87.50
[Train] Epoch: 2 [85632/387873]    Loss: 0.002199   Batch Acc: 87.50
[Train] Epoch: 2 [85760/387873]    Loss: 0.001921   Batch Acc: 89.06
[Train] Epoch: 2 [85888/387873]    Loss: 0.002210   Batch Acc: 88.28
[Train] Epoch: 2 [86016/387873]    Loss: 0.001751   Batch Acc: 92.19
[Train] Epoch: 2 [86144/387873]    Loss: 0.002339   Batch Acc: 84.38
[Train] Epoch: 2 [86272/387873]    Loss: 0.002472   Batch Acc: 86.72
[Train] Epoch: 2 [86400/387873]    Loss: 0.001798   Batch Acc: 88.28
[Train] Epoch: 2 [86528/387873]    Loss: 0.002413   Batch Acc: 84.38
[Train] Epoch: 2 [86656/387873]    Loss: 0.002229   Batch Acc: 87.50
[Train] Epoch: 2 [86784/387873]    Loss: 0.001924   Batch Acc: 89.06
[Train] Epoch: 2 [86912/387873]    Loss: 0.002375   Batch Acc: 87.50
[Train] Epoch: 2 [87040/387873]    Loss: 0.001752   Batch Acc: 92.97
[Train] Epoch: 2 [87168/387873]    Loss: 0.002189   Batch Acc: 90.62
[Train] Epoch: 2 [87296/387873]    Loss: 0.001987   Batch Acc: 88.28
[Train] Epoch: 2 [87424/387873]    Loss: 0.002581   Batch Acc: 85.16
[Train] Epoch: 2 [87552/387873]    Loss: 0.002249   Batch Acc: 85.94
[Train] Epoch: 2 [87680/387873]    Loss: 0.002043   Batch Acc: 90.62
[Train] Epoch: 2 [87808/387873]    Loss: 0.002223   Batch Acc: 88.28
[Train] Epoch: 2 [87936/387873]    Loss: 0.001836   Batch Acc: 91.41
[Train] Epoch: 2 [88064/387873]    Loss: 0.001830   Batch Acc: 89.84
[Train] Epoch: 2 [88192/387873]    Loss: 0.001836   Batch Acc: 91.41
[Train] Epoch: 2 [88320/387873]    Loss: 0.002044   Batch Acc: 88.28
[Train] Epoch: 2 [88448/387873]    Loss: 0.002511   Batch Acc: 88.28
[Train] Epoch: 2 [88576/387873]    Loss: 0.001914   Batch Acc: 92.19
[Train] Epoch: 2 [88704/387873]    Loss: 0.002210   Batch Acc: 89.84
[Train] Epoch: 2 [88832/387873]    Loss: 0.001935   Batch Acc: 92.19
[Train] Epoch: 2 [88960/387873]    Loss: 0.002626   Batch Acc: 84.38
[Train] Epoch: 2 [89088/387873]    Loss: 0.002786   Batch Acc: 81.25
[Train] Epoch: 2 [89216/387873]    Loss: 0.002423   Batch Acc: 83.59
[Train] Epoch: 2 [89344/387873]    Loss: 0.001460   Batch Acc: 92.97
[Train] Epoch: 2 [89472/387873]    Loss: 0.002049   Batch Acc: 86.72
[Train] Epoch: 2 [89600/387873]    Loss: 0.002321   Batch Acc: 88.28
[Train] Epoch: 2 [89728/387873]    Loss: 0.002517   Batch Acc: 88.28
[Train] Epoch: 2 [89856/387873]    Loss: 0.001965   Batch Acc: 91.41
[Train] Epoch: 2 [89984/387873]    Loss: 0.001896   Batch Acc: 90.62
[Train] Epoch: 2 [90112/387873]    Loss: 0.002425   Batch Acc: 87.50
[Train] Epoch: 2 [90240/387873]    Loss: 0.001890   Batch Acc: 90.62
[Train] Epoch: 2 [90368/387873]    Loss: 0.001754   Batch Acc: 87.50
[Train] Epoch: 2 [90496/387873]    Loss: 0.001749   Batch Acc: 92.97
[Train] Epoch: 2 [90624/387873]    Loss: 0.001795   Batch Acc: 90.62
[Train] Epoch: 2 [90752/387873]    Loss: 0.002464   Batch Acc: 85.94
[Train] Epoch: 2 [90880/387873]    Loss: 0.002036   Batch Acc: 88.28
[Train] Epoch: 2 [91008/387873]    Loss: 0.001832   Batch Acc: 91.41
[Train] Epoch: 2 [91136/387873]    Loss: 0.001889   Batch Acc: 89.06
[Train] Epoch: 2 [91264/387873]    Loss: 0.001175   Batch Acc: 94.53
[Train] Epoch: 2 [91392/387873]    Loss: 0.002202   Batch Acc: 89.06
[Train] Epoch: 2 [91520/387873]    Loss: 0.001653   Batch Acc: 93.75
[Train] Epoch: 2 [91648/387873]    Loss: 0.001728   Batch Acc: 91.41
[Train] Epoch: 2 [91776/387873]    Loss: 0.001782   Batch Acc: 90.62
[Train] Epoch: 2 [91904/387873]    Loss: 0.002226   Batch Acc: 88.28
[Train] Epoch: 2 [92032/387873]    Loss: 0.002337   Batch Acc: 87.50
[Train] Epoch: 2 [92160/387873]    Loss: 0.002830   Batch Acc: 82.03
[Train] Epoch: 2 [92288/387873]    Loss: 0.002118   Batch Acc: 89.06
[Train] Epoch: 2 [92416/387873]    Loss: 0.002090   Batch Acc: 88.28
[Train] Epoch: 2 [92544/387873]    Loss: 0.001840   Batch Acc: 90.62
[Train] Epoch: 2 [92672/387873]    Loss: 0.002306   Batch Acc: 85.16
[Train] Epoch: 2 [92800/387873]    Loss: 0.001566   Batch Acc: 90.62
[Train] Epoch: 2 [92928/387873]    Loss: 0.001825   Batch Acc: 89.06
[Train] Epoch: 2 [93056/387873]    Loss: 0.001940   Batch Acc: 89.84
[Train] Epoch: 2 [93184/387873]    Loss: 0.001907   Batch Acc: 90.62
[Train] Epoch: 2 [93312/387873]    Loss: 0.001961   Batch Acc: 90.62
[Train] Epoch: 2 [93440/387873]    Loss: 0.002860   Batch Acc: 85.94
[Train] Epoch: 2 [93568/387873]    Loss: 0.003097   Batch Acc: 82.81
[Train] Epoch: 2 [93696/387873]    Loss: 0.001886   Batch Acc: 89.84
[Train] Epoch: 2 [93824/387873]    Loss: 0.002079   Batch Acc: 86.72
[Train] Epoch: 2 [93952/387873]    Loss: 0.001861   Batch Acc: 89.06
[Train] Epoch: 2 [94080/387873]    Loss: 0.001888   Batch Acc: 89.06
[Train] Epoch: 2 [94208/387873]    Loss: 0.002059   Batch Acc: 91.41
[Train] Epoch: 2 [94336/387873]    Loss: 0.001654   Batch Acc: 95.31
[Train] Epoch: 2 [94464/387873]    Loss: 0.002221   Batch Acc: 90.62
[Train] Epoch: 2 [94592/387873]    Loss: 0.001741   Batch Acc: 92.19
[Train] Epoch: 2 [94720/387873]    Loss: 0.002104   Batch Acc: 89.06
[Train] Epoch: 2 [94848/387873]    Loss: 0.002464   Batch Acc: 88.28
[Train] Epoch: 2 [94976/387873]    Loss: 0.002359   Batch Acc: 87.50
[Train] Epoch: 2 [95104/387873]    Loss: 0.001904   Batch Acc: 91.41
[Train] Epoch: 2 [95232/387873]    Loss: 0.002007   Batch Acc: 88.28
[Train] Epoch: 2 [95360/387873]    Loss: 0.002135   Batch Acc: 88.28
[Train] Epoch: 2 [95488/387873]    Loss: 0.001440   Batch Acc: 94.53
[Train] Epoch: 2 [95616/387873]    Loss: 0.002020   Batch Acc: 89.06
[Train] Epoch: 2 [95744/387873]    Loss: 0.002382   Batch Acc: 81.25
[Train] Epoch: 2 [95872/387873]    Loss: 0.002276   Batch Acc: 86.72
[Train] Epoch: 2 [96000/387873]    Loss: 0.001955   Batch Acc: 90.62
[Train] Epoch: 2 [96128/387873]    Loss: 0.002532   Batch Acc: 85.16
[Train] Epoch: 2 [96256/387873]    Loss: 0.001983   Batch Acc: 88.28
[Train] Epoch: 2 [96384/387873]    Loss: 0.002165   Batch Acc: 87.50
[Train] Epoch: 2 [96512/387873]    Loss: 0.002391   Batch Acc: 85.16
[Train] Epoch: 2 [96640/387873]    Loss: 0.001747   Batch Acc: 92.19
[Train] Epoch: 2 [96768/387873]    Loss: 0.002026   Batch Acc: 89.06
[Train] Epoch: 2 [96896/387873]    Loss: 0.002697   Batch Acc: 82.81
[Train] Epoch: 2 [97024/387873]    Loss: 0.001511   Batch Acc: 94.53
[Train] Epoch: 2 [97152/387873]    Loss: 0.002216   Batch Acc: 85.94
[Train] Epoch: 2 [97280/387873]    Loss: 0.002039   Batch Acc: 88.28
[Train] Epoch: 2 [97408/387873]    Loss: 0.001716   Batch Acc: 89.84
[Train] Epoch: 2 [97536/387873]    Loss: 0.002112   Batch Acc: 91.41
[Train] Epoch: 2 [97664/387873]    Loss: 0.002078   Batch Acc: 89.84
[Train] Epoch: 2 [97792/387873]    Loss: 0.002206   Batch Acc: 87.50
[Train] Epoch: 2 [97920/387873]    Loss: 0.001568   Batch Acc: 92.97
[Train] Epoch: 2 [98048/387873]    Loss: 0.002435   Batch Acc: 89.84
[Train] Epoch: 2 [98176/387873]    Loss: 0.002080   Batch Acc: 90.62
[Train] Epoch: 2 [98304/387873]    Loss: 0.001737   Batch Acc: 89.84
[Train] Epoch: 2 [98432/387873]    Loss: 0.002423   Batch Acc: 86.72
[Train] Epoch: 2 [98560/387873]    Loss: 0.002310   Batch Acc: 88.28
[Train] Epoch: 2 [98688/387873]    Loss: 0.001910   Batch Acc: 91.41
[Train] Epoch: 2 [98816/387873]    Loss: 0.003239   Batch Acc: 81.25
[Train] Epoch: 2 [98944/387873]    Loss: 0.002069   Batch Acc: 85.16
[Train] Epoch: 2 [99072/387873]    Loss: 0.002460   Batch Acc: 85.94
[Train] Epoch: 2 [99200/387873]    Loss: 0.002364   Batch Acc: 85.94
[Train] Epoch: 2 [99328/387873]    Loss: 0.001925   Batch Acc: 89.06
[Train] Epoch: 2 [99456/387873]    Loss: 0.001574   Batch Acc: 95.31
[Train] Epoch: 2 [99584/387873]    Loss: 0.002511   Batch Acc: 85.16
[Train] Epoch: 2 [99712/387873]    Loss: 0.002397   Batch Acc: 89.84
[Train] Epoch: 2 [99840/387873]    Loss: 0.002027   Batch Acc: 89.06
[Train] Epoch: 2 [99968/387873]    Loss: 0.001878   Batch Acc: 87.50
[Train] Epoch: 2 [100096/387873]    Loss: 0.002229   Batch Acc: 85.94
[Train] Epoch: 2 [100224/387873]    Loss: 0.002339   Batch Acc: 87.50
[Train] Epoch: 2 [100352/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 2 [100480/387873]    Loss: 0.001977   Batch Acc: 92.97
[Train] Epoch: 2 [100608/387873]    Loss: 0.002598   Batch Acc: 85.16
[Train] Epoch: 2 [100736/387873]    Loss: 0.002048   Batch Acc: 89.06
[Train] Epoch: 2 [100864/387873]    Loss: 0.002047   Batch Acc: 89.06
[Train] Epoch: 2 [100992/387873]    Loss: 0.001849   Batch Acc: 90.62
[Train] Epoch: 2 [101120/387873]    Loss: 0.002626   Batch Acc: 87.50
[Train] Epoch: 2 [101248/387873]    Loss: 0.002485   Batch Acc: 86.72
[Train] Epoch: 2 [101376/387873]    Loss: 0.002058   Batch Acc: 89.06
[Train] Epoch: 2 [101504/387873]    Loss: 0.002738   Batch Acc: 83.59
[Train] Epoch: 2 [101632/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 2 [101760/387873]    Loss: 0.002208   Batch Acc: 88.28
[Train] Epoch: 2 [101888/387873]    Loss: 0.001861   Batch Acc: 91.41
[Train] Epoch: 2 [102016/387873]    Loss: 0.002858   Batch Acc: 87.50
[Train] Epoch: 2 [102144/387873]    Loss: 0.001793   Batch Acc: 90.62
[Train] Epoch: 2 [102272/387873]    Loss: 0.002192   Batch Acc: 85.94
[Train] Epoch: 2 [102400/387873]    Loss: 0.002179   Batch Acc: 88.28
[Train] Epoch: 2 [102528/387873]    Loss: 0.002150   Batch Acc: 89.06
[Train] Epoch: 2 [102656/387873]    Loss: 0.002499   Batch Acc: 85.16
[Train] Epoch: 2 [102784/387873]    Loss: 0.002057   Batch Acc: 90.62
[Train] Epoch: 2 [102912/387873]    Loss: 0.001851   Batch Acc: 89.84
[Train] Epoch: 2 [103040/387873]    Loss: 0.002276   Batch Acc: 85.94
[Train] Epoch: 2 [103168/387873]    Loss: 0.002585   Batch Acc: 85.94
[Train] Epoch: 2 [103296/387873]    Loss: 0.001995   Batch Acc: 89.84
[Train] Epoch: 2 [103424/387873]    Loss: 0.001816   Batch Acc: 91.41
[Train] Epoch: 2 [103552/387873]    Loss: 0.002161   Batch Acc: 90.62
[Train] Epoch: 2 [103680/387873]    Loss: 0.001999   Batch Acc: 88.28
[Train] Epoch: 2 [103808/387873]    Loss: 0.002019   Batch Acc: 88.28
[Train] Epoch: 2 [103936/387873]    Loss: 0.002092   Batch Acc: 89.06
[Train] Epoch: 2 [104064/387873]    Loss: 0.001644   Batch Acc: 92.97
[Train] Epoch: 2 [104192/387873]    Loss: 0.002145   Batch Acc: 89.84
[Train] Epoch: 2 [104320/387873]    Loss: 0.001793   Batch Acc: 91.41
[Train] Epoch: 2 [104448/387873]    Loss: 0.001924   Batch Acc: 90.62
[Train] Epoch: 2 [104576/387873]    Loss: 0.001687   Batch Acc: 91.41
[Train] Epoch: 2 [104704/387873]    Loss: 0.001991   Batch Acc: 90.62
[Train] Epoch: 2 [104832/387873]    Loss: 0.002561   Batch Acc: 82.81
[Train] Epoch: 2 [104960/387873]    Loss: 0.002087   Batch Acc: 86.72
[Train] Epoch: 2 [105088/387873]    Loss: 0.001602   Batch Acc: 94.53
[Train] Epoch: 2 [105216/387873]    Loss: 0.001762   Batch Acc: 89.06
[Train] Epoch: 2 [105344/387873]    Loss: 0.002302   Batch Acc: 84.38
[Train] Epoch: 2 [105472/387873]    Loss: 0.001902   Batch Acc: 90.62
[Train] Epoch: 2 [105600/387873]    Loss: 0.002092   Batch Acc: 89.84
[Train] Epoch: 2 [105728/387873]    Loss: 0.002739   Batch Acc: 84.38
[Train] Epoch: 2 [105856/387873]    Loss: 0.001951   Batch Acc: 89.06
[Train] Epoch: 2 [105984/387873]    Loss: 0.002164   Batch Acc: 88.28
[Train] Epoch: 2 [106112/387873]    Loss: 0.001946   Batch Acc: 90.62
[Train] Epoch: 2 [106240/387873]    Loss: 0.002161   Batch Acc: 87.50
[Train] Epoch: 2 [106368/387873]    Loss: 0.002136   Batch Acc: 89.06
[Train] Epoch: 2 [106496/387873]    Loss: 0.001219   Batch Acc: 96.88
[Train] Epoch: 2 [106624/387873]    Loss: 0.001589   Batch Acc: 92.97
[Train] Epoch: 2 [106752/387873]    Loss: 0.002389   Batch Acc: 82.81
[Train] Epoch: 2 [106880/387873]    Loss: 0.001652   Batch Acc: 94.53
[Train] Epoch: 2 [107008/387873]    Loss: 0.001830   Batch Acc: 89.84
[Train] Epoch: 2 [107136/387873]    Loss: 0.002405   Batch Acc: 85.16
[Train] Epoch: 2 [107264/387873]    Loss: 0.002357   Batch Acc: 86.72
[Train] Epoch: 2 [107392/387873]    Loss: 0.002313   Batch Acc: 86.72
[Train] Epoch: 2 [107520/387873]    Loss: 0.001996   Batch Acc: 91.41
[Train] Epoch: 2 [107648/387873]    Loss: 0.001909   Batch Acc: 92.19
[Train] Epoch: 2 [107776/387873]    Loss: 0.001939   Batch Acc: 89.84
[Train] Epoch: 2 [107904/387873]    Loss: 0.001595   Batch Acc: 91.41
[Train] Epoch: 2 [108032/387873]    Loss: 0.001999   Batch Acc: 89.84
[Train] Epoch: 2 [108160/387873]    Loss: 0.001535   Batch Acc: 94.53
[Train] Epoch: 2 [108288/387873]    Loss: 0.002771   Batch Acc: 84.38
[Train] Epoch: 2 [108416/387873]    Loss: 0.002305   Batch Acc: 87.50
[Train] Epoch: 2 [108544/387873]    Loss: 0.002398   Batch Acc: 90.62
[Train] Epoch: 2 [108672/387873]    Loss: 0.002450   Batch Acc: 84.38
[Train] Epoch: 2 [108800/387873]    Loss: 0.002576   Batch Acc: 86.72
[Train] Epoch: 2 [108928/387873]    Loss: 0.002084   Batch Acc: 91.41
[Train] Epoch: 2 [109056/387873]    Loss: 0.001775   Batch Acc: 92.97
[Train] Epoch: 2 [109184/387873]    Loss: 0.002483   Batch Acc: 86.72
[Train] Epoch: 2 [109312/387873]    Loss: 0.002060   Batch Acc: 87.50
[Train] Epoch: 2 [109440/387873]    Loss: 0.002588   Batch Acc: 87.50
[Train] Epoch: 2 [109568/387873]    Loss: 0.002261   Batch Acc: 86.72
[Train] Epoch: 2 [109696/387873]    Loss: 0.001972   Batch Acc: 91.41
[Train] Epoch: 2 [109824/387873]    Loss: 0.001828   Batch Acc: 89.06
[Train] Epoch: 2 [109952/387873]    Loss: 0.001756   Batch Acc: 89.06
[Train] Epoch: 2 [110080/387873]    Loss: 0.002018   Batch Acc: 87.50
[Train] Epoch: 2 [110208/387873]    Loss: 0.002642   Batch Acc: 86.72
[Train] Epoch: 2 [110336/387873]    Loss: 0.002211   Batch Acc: 89.06
[Train] Epoch: 2 [110464/387873]    Loss: 0.001501   Batch Acc: 94.53
[Train] Epoch: 2 [110592/387873]    Loss: 0.002203   Batch Acc: 87.50
[Train] Epoch: 2 [110720/387873]    Loss: 0.001852   Batch Acc: 90.62
[Train] Epoch: 2 [110848/387873]    Loss: 0.001814   Batch Acc: 87.50
[Train] Epoch: 2 [110976/387873]    Loss: 0.001915   Batch Acc: 93.75
[Train] Epoch: 2 [111104/387873]    Loss: 0.001804   Batch Acc: 89.84
[Train] Epoch: 2 [111232/387873]    Loss: 0.001704   Batch Acc: 89.84
[Train] Epoch: 2 [111360/387873]    Loss: 0.001922   Batch Acc: 92.19
[Train] Epoch: 2 [111488/387873]    Loss: 0.001720   Batch Acc: 92.97
[Train] Epoch: 2 [111616/387873]    Loss: 0.002042   Batch Acc: 92.19
[Train] Epoch: 2 [111744/387873]    Loss: 0.001714   Batch Acc: 92.19
[Train] Epoch: 2 [111872/387873]    Loss: 0.002188   Batch Acc: 88.28
[Train] Epoch: 2 [112000/387873]    Loss: 0.002677   Batch Acc: 88.28
[Train] Epoch: 2 [112128/387873]    Loss: 0.002311   Batch Acc: 88.28
[Train] Epoch: 2 [112256/387873]    Loss: 0.001880   Batch Acc: 89.06
[Train] Epoch: 2 [112384/387873]    Loss: 0.001985   Batch Acc: 92.19
[Train] Epoch: 2 [112512/387873]    Loss: 0.001951   Batch Acc: 87.50
[Train] Epoch: 2 [112640/387873]    Loss: 0.002137   Batch Acc: 89.84
[Train] Epoch: 2 [112768/387873]    Loss: 0.001591   Batch Acc: 93.75
[Train] Epoch: 2 [112896/387873]    Loss: 0.001577   Batch Acc: 95.31
[Train] Epoch: 2 [113024/387873]    Loss: 0.002741   Batch Acc: 85.94
[Train] Epoch: 2 [113152/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 2 [113280/387873]    Loss: 0.002235   Batch Acc: 89.84
[Train] Epoch: 2 [113408/387873]    Loss: 0.002430   Batch Acc: 87.50
[Train] Epoch: 2 [113536/387873]    Loss: 0.001712   Batch Acc: 91.41
[Train] Epoch: 2 [113664/387873]    Loss: 0.002826   Batch Acc: 84.38
[Train] Epoch: 2 [113792/387873]    Loss: 0.002447   Batch Acc: 88.28
[Train] Epoch: 2 [113920/387873]    Loss: 0.002607   Batch Acc: 87.50
[Train] Epoch: 2 [114048/387873]    Loss: 0.001993   Batch Acc: 90.62
[Train] Epoch: 2 [114176/387873]    Loss: 0.001781   Batch Acc: 91.41
[Train] Epoch: 2 [114304/387873]    Loss: 0.001901   Batch Acc: 91.41
[Train] Epoch: 2 [114432/387873]    Loss: 0.001932   Batch Acc: 90.62
[Train] Epoch: 2 [114560/387873]    Loss: 0.001713   Batch Acc: 90.62
[Train] Epoch: 2 [114688/387873]    Loss: 0.001909   Batch Acc: 89.84
[Train] Epoch: 2 [114816/387873]    Loss: 0.001926   Batch Acc: 90.62
[Train] Epoch: 2 [114944/387873]    Loss: 0.001880   Batch Acc: 89.84
[Train] Epoch: 2 [115072/387873]    Loss: 0.001902   Batch Acc: 87.50
[Train] Epoch: 2 [115200/387873]    Loss: 0.002041   Batch Acc: 87.50
[Train] Epoch: 2 [115328/387873]    Loss: 0.001686   Batch Acc: 92.19
[Train] Epoch: 2 [115456/387873]    Loss: 0.002187   Batch Acc: 85.16
[Train] Epoch: 2 [115584/387873]    Loss: 0.001995   Batch Acc: 92.97
[Train] Epoch: 2 [115712/387873]    Loss: 0.001653   Batch Acc: 92.97
[Train] Epoch: 2 [115840/387873]    Loss: 0.002135   Batch Acc: 87.50
[Train] Epoch: 2 [115968/387873]    Loss: 0.002495   Batch Acc: 86.72
[Train] Epoch: 2 [116096/387873]    Loss: 0.002048   Batch Acc: 90.62
[Train] Epoch: 2 [116224/387873]    Loss: 0.002494   Batch Acc: 85.16
[Train] Epoch: 2 [116352/387873]    Loss: 0.001928   Batch Acc: 87.50
[Train] Epoch: 2 [116480/387873]    Loss: 0.002548   Batch Acc: 84.38
[Train] Epoch: 2 [116608/387873]    Loss: 0.002110   Batch Acc: 88.28
[Train] Epoch: 2 [116736/387873]    Loss: 0.002002   Batch Acc: 91.41
[Train] Epoch: 2 [116864/387873]    Loss: 0.001609   Batch Acc: 91.41
[Train] Epoch: 2 [116992/387873]    Loss: 0.001371   Batch Acc: 93.75
[Train] Epoch: 2 [117120/387873]    Loss: 0.002372   Batch Acc: 87.50
[Train] Epoch: 2 [117248/387873]    Loss: 0.002014   Batch Acc: 90.62
[Train] Epoch: 2 [117376/387873]    Loss: 0.001806   Batch Acc: 89.06
[Train] Epoch: 2 [117504/387873]    Loss: 0.002547   Batch Acc: 83.59
[Train] Epoch: 2 [117632/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 2 [117760/387873]    Loss: 0.002024   Batch Acc: 88.28
[Train] Epoch: 2 [117888/387873]    Loss: 0.001911   Batch Acc: 87.50
[Train] Epoch: 2 [118016/387873]    Loss: 0.002120   Batch Acc: 89.84
[Train] Epoch: 2 [118144/387873]    Loss: 0.002455   Batch Acc: 83.59
[Train] Epoch: 2 [118272/387873]    Loss: 0.002013   Batch Acc: 89.06
[Train] Epoch: 2 [118400/387873]    Loss: 0.002174   Batch Acc: 89.06
[Train] Epoch: 2 [118528/387873]    Loss: 0.002535   Batch Acc: 87.50
[Train] Epoch: 2 [118656/387873]    Loss: 0.001898   Batch Acc: 92.19
[Train] Epoch: 2 [118784/387873]    Loss: 0.002236   Batch Acc: 85.16
[Train] Epoch: 2 [118912/387873]    Loss: 0.002093   Batch Acc: 90.62
[Train] Epoch: 2 [119040/387873]    Loss: 0.002828   Batch Acc: 82.03
[Train] Epoch: 2 [119168/387873]    Loss: 0.001597   Batch Acc: 92.19
[Train] Epoch: 2 [119296/387873]    Loss: 0.001688   Batch Acc: 90.62
[Train] Epoch: 2 [119424/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 2 [119552/387873]    Loss: 0.001922   Batch Acc: 89.84
[Train] Epoch: 2 [119680/387873]    Loss: 0.001793   Batch Acc: 92.97
[Train] Epoch: 2 [119808/387873]    Loss: 0.001683   Batch Acc: 91.41
[Train] Epoch: 2 [119936/387873]    Loss: 0.002496   Batch Acc: 87.50
[Train] Epoch: 2 [120064/387873]    Loss: 0.001910   Batch Acc: 89.84
[Train] Epoch: 2 [120192/387873]    Loss: 0.001881   Batch Acc: 91.41
[Train] Epoch: 2 [120320/387873]    Loss: 0.001812   Batch Acc: 91.41
[Train] Epoch: 2 [120448/387873]    Loss: 0.001619   Batch Acc: 92.97
[Train] Epoch: 2 [120576/387873]    Loss: 0.002109   Batch Acc: 87.50
[Train] Epoch: 2 [120704/387873]    Loss: 0.002009   Batch Acc: 91.41
[Train] Epoch: 2 [120832/387873]    Loss: 0.002408   Batch Acc: 84.38
[Train] Epoch: 2 [120960/387873]    Loss: 0.002286   Batch Acc: 87.50
[Train] Epoch: 2 [121088/387873]    Loss: 0.002222   Batch Acc: 89.84
[Train] Epoch: 2 [121216/387873]    Loss: 0.002137   Batch Acc: 90.62
[Train] Epoch: 2 [121344/387873]    Loss: 0.002387   Batch Acc: 85.94
[Train] Epoch: 2 [121472/387873]    Loss: 0.002385   Batch Acc: 85.16
[Train] Epoch: 2 [121600/387873]    Loss: 0.001688   Batch Acc: 92.19
[Train] Epoch: 2 [121728/387873]    Loss: 0.002099   Batch Acc: 86.72
[Train] Epoch: 2 [121856/387873]    Loss: 0.001815   Batch Acc: 90.62
[Train] Epoch: 2 [121984/387873]    Loss: 0.002682   Batch Acc: 80.47
[Train] Epoch: 2 [122112/387873]    Loss: 0.002003   Batch Acc: 91.41
[Train] Epoch: 2 [122240/387873]    Loss: 0.002309   Batch Acc: 85.94
[Train] Epoch: 2 [122368/387873]    Loss: 0.001660   Batch Acc: 92.19
[Train] Epoch: 2 [122496/387873]    Loss: 0.002083   Batch Acc: 89.84
[Train] Epoch: 2 [122624/387873]    Loss: 0.002493   Batch Acc: 85.94
[Train] Epoch: 2 [122752/387873]    Loss: 0.001691   Batch Acc: 91.41
[Train] Epoch: 2 [122880/387873]    Loss: 0.002674   Batch Acc: 84.38
[Train] Epoch: 2 [123008/387873]    Loss: 0.002173   Batch Acc: 88.28
[Train] Epoch: 2 [123136/387873]    Loss: 0.002800   Batch Acc: 85.94
[Train] Epoch: 2 [123264/387873]    Loss: 0.001825   Batch Acc: 89.84
[Train] Epoch: 2 [123392/387873]    Loss: 0.001251   Batch Acc: 95.31
[Train] Epoch: 2 [123520/387873]    Loss: 0.001653   Batch Acc: 92.19
[Train] Epoch: 2 [123648/387873]    Loss: 0.002091   Batch Acc: 87.50
[Train] Epoch: 2 [123776/387873]    Loss: 0.002340   Batch Acc: 88.28
[Train] Epoch: 2 [123904/387873]    Loss: 0.002195   Batch Acc: 89.84
[Train] Epoch: 2 [124032/387873]    Loss: 0.002261   Batch Acc: 86.72
[Train] Epoch: 2 [124160/387873]    Loss: 0.002127   Batch Acc: 89.06
[Train] Epoch: 2 [124288/387873]    Loss: 0.001948   Batch Acc: 89.84
[Train] Epoch: 2 [124416/387873]    Loss: 0.002230   Batch Acc: 88.28
[Train] Epoch: 2 [124544/387873]    Loss: 0.001618   Batch Acc: 91.41
[Train] Epoch: 2 [124672/387873]    Loss: 0.001873   Batch Acc: 90.62
[Train] Epoch: 2 [124800/387873]    Loss: 0.001934   Batch Acc: 92.97
[Train] Epoch: 2 [124928/387873]    Loss: 0.001878   Batch Acc: 91.41
[Train] Epoch: 2 [125056/387873]    Loss: 0.002207   Batch Acc: 86.72
[Train] Epoch: 2 [125184/387873]    Loss: 0.001819   Batch Acc: 91.41
[Train] Epoch: 2 [125312/387873]    Loss: 0.002330   Batch Acc: 87.50
[Train] Epoch: 2 [125440/387873]    Loss: 0.002113   Batch Acc: 86.72
[Train] Epoch: 2 [125568/387873]    Loss: 0.002108   Batch Acc: 90.62
[Train] Epoch: 2 [125696/387873]    Loss: 0.001865   Batch Acc: 91.41
[Train] Epoch: 2 [125824/387873]    Loss: 0.002352   Batch Acc: 88.28
[Train] Epoch: 2 [125952/387873]    Loss: 0.001886   Batch Acc: 89.06
[Train] Epoch: 2 [126080/387873]    Loss: 0.002079   Batch Acc: 89.06
[Train] Epoch: 2 [126208/387873]    Loss: 0.001832   Batch Acc: 92.19
[Train] Epoch: 2 [126336/387873]    Loss: 0.002361   Batch Acc: 86.72
[Train] Epoch: 2 [126464/387873]    Loss: 0.002123   Batch Acc: 90.62
[Train] Epoch: 2 [126592/387873]    Loss: 0.002051   Batch Acc: 87.50
[Train] Epoch: 2 [126720/387873]    Loss: 0.002102   Batch Acc: 89.06
[Train] Epoch: 2 [126848/387873]    Loss: 0.002357   Batch Acc: 89.06
[Train] Epoch: 2 [126976/387873]    Loss: 0.001614   Batch Acc: 92.19
[Train] Epoch: 2 [127104/387873]    Loss: 0.002220   Batch Acc: 89.06
[Train] Epoch: 2 [127232/387873]    Loss: 0.001627   Batch Acc: 92.19
[Train] Epoch: 2 [127360/387873]    Loss: 0.001596   Batch Acc: 91.41
[Train] Epoch: 2 [127488/387873]    Loss: 0.002310   Batch Acc: 87.50
[Train] Epoch: 2 [127616/387873]    Loss: 0.001458   Batch Acc: 93.75
[Train] Epoch: 2 [127744/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 2 [127872/387873]    Loss: 0.001961   Batch Acc: 89.06
[Train] Epoch: 2 [128000/387873]    Loss: 0.001836   Batch Acc: 85.94
[Train] Epoch: 2 [128128/387873]    Loss: 0.002173   Batch Acc: 89.06
[Train] Epoch: 2 [128256/387873]    Loss: 0.002551   Batch Acc: 84.38
[Train] Epoch: 2 [128384/387873]    Loss: 0.002046   Batch Acc: 89.84
[Train] Epoch: 2 [128512/387873]    Loss: 0.002002   Batch Acc: 89.84
[Train] Epoch: 2 [128640/387873]    Loss: 0.002124   Batch Acc: 89.84
[Train] Epoch: 2 [128768/387873]    Loss: 0.002477   Batch Acc: 88.28
[Train] Epoch: 2 [128896/387873]    Loss: 0.002019   Batch Acc: 89.84
[Train] Epoch: 2 [129024/387873]    Loss: 0.002318   Batch Acc: 89.06
[Train] Epoch: 2 [129152/387873]    Loss: 0.002109   Batch Acc: 89.84
[Train] Epoch: 2 [129280/387873]    Loss: 0.002207   Batch Acc: 85.94
[Train] Epoch: 2 [129408/387873]    Loss: 0.001699   Batch Acc: 89.06
[Train] Epoch: 2 [129536/387873]    Loss: 0.001814   Batch Acc: 91.41
[Train] Epoch: 2 [129664/387873]    Loss: 0.001991   Batch Acc: 89.06
[Train] Epoch: 2 [129792/387873]    Loss: 0.002383   Batch Acc: 85.94
[Train] Epoch: 2 [129920/387873]    Loss: 0.001734   Batch Acc: 92.97
[Train] Epoch: 2 [130048/387873]    Loss: 0.002006   Batch Acc: 91.41
[Train] Epoch: 2 [130176/387873]    Loss: 0.002139   Batch Acc: 87.50
[Train] Epoch: 2 [130304/387873]    Loss: 0.002675   Batch Acc: 85.94
[Train] Epoch: 2 [130432/387873]    Loss: 0.002407   Batch Acc: 85.94
[Train] Epoch: 2 [130560/387873]    Loss: 0.001899   Batch Acc: 92.19
[Train] Epoch: 2 [130688/387873]    Loss: 0.002061   Batch Acc: 90.62
[Train] Epoch: 2 [130816/387873]    Loss: 0.001965   Batch Acc: 88.28
[Train] Epoch: 2 [130944/387873]    Loss: 0.002656   Batch Acc: 82.03
[Train] Epoch: 2 [131072/387873]    Loss: 0.001946   Batch Acc: 89.84
[Train] Epoch: 2 [131200/387873]    Loss: 0.002012   Batch Acc: 88.28
[Train] Epoch: 2 [131328/387873]    Loss: 0.001648   Batch Acc: 92.97
[Train] Epoch: 2 [131456/387873]    Loss: 0.002294   Batch Acc: 86.72
[Train] Epoch: 2 [131584/387873]    Loss: 0.001793   Batch Acc: 89.06
[Train] Epoch: 2 [131712/387873]    Loss: 0.002059   Batch Acc: 88.28
[Train] Epoch: 2 [131840/387873]    Loss: 0.002650   Batch Acc: 86.72
[Train] Epoch: 2 [131968/387873]    Loss: 0.002013   Batch Acc: 88.28
[Train] Epoch: 2 [132096/387873]    Loss: 0.001844   Batch Acc: 91.41
[Train] Epoch: 2 [132224/387873]    Loss: 0.002108   Batch Acc: 88.28
[Train] Epoch: 2 [132352/387873]    Loss: 0.002378   Batch Acc: 89.06
[Train] Epoch: 2 [132480/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 2 [132608/387873]    Loss: 0.001858   Batch Acc: 93.75
[Train] Epoch: 2 [132736/387873]    Loss: 0.002687   Batch Acc: 84.38
[Train] Epoch: 2 [132864/387873]    Loss: 0.002566   Batch Acc: 82.81
[Train] Epoch: 2 [132992/387873]    Loss: 0.001867   Batch Acc: 89.84
[Train] Epoch: 2 [133120/387873]    Loss: 0.001837   Batch Acc: 89.06
[Train] Epoch: 2 [133248/387873]    Loss: 0.001732   Batch Acc: 91.41
[Train] Epoch: 2 [133376/387873]    Loss: 0.002303   Batch Acc: 89.84
[Train] Epoch: 2 [133504/387873]    Loss: 0.001694   Batch Acc: 89.84
[Train] Epoch: 2 [133632/387873]    Loss: 0.002338   Batch Acc: 85.16
[Train] Epoch: 2 [133760/387873]    Loss: 0.002450   Batch Acc: 83.59
[Train] Epoch: 2 [133888/387873]    Loss: 0.001852   Batch Acc: 91.41
[Train] Epoch: 2 [134016/387873]    Loss: 0.002060   Batch Acc: 92.19
[Train] Epoch: 2 [134144/387873]    Loss: 0.001665   Batch Acc: 90.62
[Train] Epoch: 2 [134272/387873]    Loss: 0.002340   Batch Acc: 88.28
[Train] Epoch: 2 [134400/387873]    Loss: 0.002693   Batch Acc: 82.03
[Train] Epoch: 2 [134528/387873]    Loss: 0.002046   Batch Acc: 87.50
[Train] Epoch: 2 [134656/387873]    Loss: 0.002029   Batch Acc: 88.28
[Train] Epoch: 2 [134784/387873]    Loss: 0.002174   Batch Acc: 86.72
[Train] Epoch: 2 [134912/387873]    Loss: 0.001789   Batch Acc: 89.06
[Train] Epoch: 2 [135040/387873]    Loss: 0.001859   Batch Acc: 88.28
[Train] Epoch: 2 [135168/387873]    Loss: 0.002137   Batch Acc: 89.06
[Train] Epoch: 2 [135296/387873]    Loss: 0.002020   Batch Acc: 87.50
[Train] Epoch: 2 [135424/387873]    Loss: 0.001836   Batch Acc: 88.28
[Train] Epoch: 2 [135552/387873]    Loss: 0.001272   Batch Acc: 95.31
[Train] Epoch: 2 [135680/387873]    Loss: 0.002088   Batch Acc: 87.50
[Train] Epoch: 2 [135808/387873]    Loss: 0.001814   Batch Acc: 92.19
[Train] Epoch: 2 [135936/387873]    Loss: 0.001950   Batch Acc: 89.06
[Train] Epoch: 2 [136064/387873]    Loss: 0.002575   Batch Acc: 85.16
[Train] Epoch: 2 [136192/387873]    Loss: 0.001630   Batch Acc: 92.97
[Train] Epoch: 2 [136320/387873]    Loss: 0.001921   Batch Acc: 91.41
[Train] Epoch: 2 [136448/387873]    Loss: 0.001804   Batch Acc: 89.06
[Train] Epoch: 2 [136576/387873]    Loss: 0.001807   Batch Acc: 90.62
[Train] Epoch: 2 [136704/387873]    Loss: 0.001779   Batch Acc: 89.84
[Train] Epoch: 2 [136832/387873]    Loss: 0.002579   Batch Acc: 86.72
[Train] Epoch: 2 [136960/387873]    Loss: 0.002389   Batch Acc: 88.28
[Train] Epoch: 2 [137088/387873]    Loss: 0.002100   Batch Acc: 87.50
[Train] Epoch: 2 [137216/387873]    Loss: 0.002096   Batch Acc: 89.84
[Train] Epoch: 2 [137344/387873]    Loss: 0.002460   Batch Acc: 83.59
[Train] Epoch: 2 [137472/387873]    Loss: 0.002344   Batch Acc: 85.16
[Train] Epoch: 2 [137600/387873]    Loss: 0.001706   Batch Acc: 91.41
[Train] Epoch: 2 [137728/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 2 [137856/387873]    Loss: 0.001808   Batch Acc: 89.84
[Train] Epoch: 2 [137984/387873]    Loss: 0.002569   Batch Acc: 86.72
[Train] Epoch: 2 [138112/387873]    Loss: 0.001722   Batch Acc: 92.97
[Train] Epoch: 2 [138240/387873]    Loss: 0.002108   Batch Acc: 87.50
[Train] Epoch: 2 [138368/387873]    Loss: 0.001961   Batch Acc: 92.19
[Train] Epoch: 2 [138496/387873]    Loss: 0.002311   Batch Acc: 87.50
[Train] Epoch: 2 [138624/387873]    Loss: 0.001922   Batch Acc: 88.28
[Train] Epoch: 2 [138752/387873]    Loss: 0.001706   Batch Acc: 90.62
[Train] Epoch: 2 [138880/387873]    Loss: 0.001699   Batch Acc: 89.06
[Train] Epoch: 2 [139008/387873]    Loss: 0.002201   Batch Acc: 89.06
[Train] Epoch: 2 [139136/387873]    Loss: 0.002323   Batch Acc: 86.72
[Train] Epoch: 2 [139264/387873]    Loss: 0.001938   Batch Acc: 90.62
[Train] Epoch: 2 [139392/387873]    Loss: 0.002092   Batch Acc: 88.28
[Train] Epoch: 2 [139520/387873]    Loss: 0.001887   Batch Acc: 89.84
[Train] Epoch: 2 [139648/387873]    Loss: 0.001476   Batch Acc: 92.97
[Train] Epoch: 2 [139776/387873]    Loss: 0.001917   Batch Acc: 92.19
[Train] Epoch: 2 [139904/387873]    Loss: 0.002045   Batch Acc: 91.41
[Train] Epoch: 2 [140032/387873]    Loss: 0.002346   Batch Acc: 86.72
[Train] Epoch: 2 [140160/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 2 [140288/387873]    Loss: 0.002051   Batch Acc: 89.06
[Train] Epoch: 2 [140416/387873]    Loss: 0.002130   Batch Acc: 88.28
[Train] Epoch: 2 [140544/387873]    Loss: 0.002839   Batch Acc: 84.38
[Train] Epoch: 2 [140672/387873]    Loss: 0.002131   Batch Acc: 89.84
[Train] Epoch: 2 [140800/387873]    Loss: 0.002537   Batch Acc: 85.94
[Train] Epoch: 2 [140928/387873]    Loss: 0.001296   Batch Acc: 95.31
[Train] Epoch: 2 [141056/387873]    Loss: 0.001883   Batch Acc: 92.97
[Train] Epoch: 2 [141184/387873]    Loss: 0.001882   Batch Acc: 90.62
[Train] Epoch: 2 [141312/387873]    Loss: 0.002451   Batch Acc: 85.16
[Train] Epoch: 2 [141440/387873]    Loss: 0.002050   Batch Acc: 89.84
[Train] Epoch: 2 [141568/387873]    Loss: 0.002275   Batch Acc: 89.06
[Train] Epoch: 2 [141696/387873]    Loss: 0.002208   Batch Acc: 89.06
[Train] Epoch: 2 [141824/387873]    Loss: 0.001919   Batch Acc: 89.06
[Train] Epoch: 2 [141952/387873]    Loss: 0.002095   Batch Acc: 89.06
[Train] Epoch: 2 [142080/387873]    Loss: 0.002183   Batch Acc: 87.50
[Train] Epoch: 2 [142208/387873]    Loss: 0.002642   Batch Acc: 85.16
[Train] Epoch: 2 [142336/387873]    Loss: 0.002136   Batch Acc: 88.28
[Train] Epoch: 2 [142464/387873]    Loss: 0.002004   Batch Acc: 89.84
[Train] Epoch: 2 [142592/387873]    Loss: 0.002235   Batch Acc: 86.72
[Train] Epoch: 2 [142720/387873]    Loss: 0.002059   Batch Acc: 90.62
[Train] Epoch: 2 [142848/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 2 [142976/387873]    Loss: 0.002136   Batch Acc: 89.06
[Train] Epoch: 2 [143104/387873]    Loss: 0.002535   Batch Acc: 86.72
[Train] Epoch: 2 [143232/387873]    Loss: 0.002169   Batch Acc: 90.62
[Train] Epoch: 2 [143360/387873]    Loss: 0.001693   Batch Acc: 89.84
[Train] Epoch: 2 [143488/387873]    Loss: 0.002263   Batch Acc: 86.72
[Train] Epoch: 2 [143616/387873]    Loss: 0.002245   Batch Acc: 89.06
[Train] Epoch: 2 [143744/387873]    Loss: 0.001901   Batch Acc: 89.06
[Train] Epoch: 2 [143872/387873]    Loss: 0.002086   Batch Acc: 89.84
[Train] Epoch: 2 [144000/387873]    Loss: 0.001916   Batch Acc: 90.62
[Train] Epoch: 2 [144128/387873]    Loss: 0.001668   Batch Acc: 92.19
[Train] Epoch: 2 [144256/387873]    Loss: 0.002606   Batch Acc: 84.38
[Train] Epoch: 2 [144384/387873]    Loss: 0.002184   Batch Acc: 89.84
[Train] Epoch: 2 [144512/387873]    Loss: 0.002012   Batch Acc: 89.06
[Train] Epoch: 2 [144640/387873]    Loss: 0.002009   Batch Acc: 90.62
[Train] Epoch: 2 [144768/387873]    Loss: 0.002177   Batch Acc: 88.28
[Train] Epoch: 2 [144896/387873]    Loss: 0.002343   Batch Acc: 88.28
[Train] Epoch: 2 [145024/387873]    Loss: 0.002096   Batch Acc: 87.50
[Train] Epoch: 2 [145152/387873]    Loss: 0.001858   Batch Acc: 89.84
[Train] Epoch: 2 [145280/387873]    Loss: 0.002901   Batch Acc: 82.03
[Train] Epoch: 2 [145408/387873]    Loss: 0.002394   Batch Acc: 86.72
[Train] Epoch: 2 [145536/387873]    Loss: 0.001828   Batch Acc: 90.62
[Train] Epoch: 2 [145664/387873]    Loss: 0.002285   Batch Acc: 86.72
[Train] Epoch: 2 [145792/387873]    Loss: 0.001838   Batch Acc: 88.28
[Train] Epoch: 2 [145920/387873]    Loss: 0.001843   Batch Acc: 92.97
[Train] Epoch: 2 [146048/387873]    Loss: 0.002705   Batch Acc: 84.38
[Train] Epoch: 2 [146176/387873]    Loss: 0.002839   Batch Acc: 85.94
[Train] Epoch: 2 [146304/387873]    Loss: 0.001897   Batch Acc: 91.41
[Train] Epoch: 2 [146432/387873]    Loss: 0.002005   Batch Acc: 87.50
[Train] Epoch: 2 [146560/387873]    Loss: 0.002127   Batch Acc: 90.62
[Train] Epoch: 2 [146688/387873]    Loss: 0.001980   Batch Acc: 87.50
[Train] Epoch: 2 [146816/387873]    Loss: 0.001951   Batch Acc: 90.62
[Train] Epoch: 2 [146944/387873]    Loss: 0.002453   Batch Acc: 89.06
[Train] Epoch: 2 [147072/387873]    Loss: 0.001852   Batch Acc: 90.62
[Train] Epoch: 2 [147200/387873]    Loss: 0.002209   Batch Acc: 90.62
[Train] Epoch: 2 [147328/387873]    Loss: 0.001878   Batch Acc: 91.41
[Train] Epoch: 2 [147456/387873]    Loss: 0.001943   Batch Acc: 91.41
[Train] Epoch: 2 [147584/387873]    Loss: 0.002295   Batch Acc: 89.84
[Train] Epoch: 2 [147712/387873]    Loss: 0.001876   Batch Acc: 91.41
[Train] Epoch: 2 [147840/387873]    Loss: 0.001834   Batch Acc: 89.06
[Train] Epoch: 2 [147968/387873]    Loss: 0.002565   Batch Acc: 85.16
[Train] Epoch: 2 [148096/387873]    Loss: 0.001572   Batch Acc: 90.62
[Train] Epoch: 2 [148224/387873]    Loss: 0.001815   Batch Acc: 88.28
[Train] Epoch: 2 [148352/387873]    Loss: 0.002647   Batch Acc: 80.47
[Train] Epoch: 2 [148480/387873]    Loss: 0.002376   Batch Acc: 85.94
[Train] Epoch: 2 [148608/387873]    Loss: 0.001816   Batch Acc: 94.53
[Train] Epoch: 2 [148736/387873]    Loss: 0.002201   Batch Acc: 89.06
[Train] Epoch: 2 [148864/387873]    Loss: 0.002014   Batch Acc: 89.84
[Train] Epoch: 2 [148992/387873]    Loss: 0.002375   Batch Acc: 89.06
[Train] Epoch: 2 [149120/387873]    Loss: 0.001759   Batch Acc: 87.50
[Train] Epoch: 2 [149248/387873]    Loss: 0.001885   Batch Acc: 90.62
[Train] Epoch: 2 [149376/387873]    Loss: 0.002346   Batch Acc: 87.50
[Train] Epoch: 2 [149504/387873]    Loss: 0.002700   Batch Acc: 83.59
[Train] Epoch: 2 [149632/387873]    Loss: 0.002042   Batch Acc: 89.84
[Train] Epoch: 2 [149760/387873]    Loss: 0.002263   Batch Acc: 87.50
[Train] Epoch: 2 [149888/387873]    Loss: 0.002276   Batch Acc: 87.50
[Train] Epoch: 2 [150016/387873]    Loss: 0.002059   Batch Acc: 86.72
[Train] Epoch: 2 [150144/387873]    Loss: 0.001514   Batch Acc: 91.41
[Train] Epoch: 2 [150272/387873]    Loss: 0.002450   Batch Acc: 89.06
[Train] Epoch: 2 [150400/387873]    Loss: 0.002278   Batch Acc: 85.16
[Train] Epoch: 2 [150528/387873]    Loss: 0.001915   Batch Acc: 91.41
[Train] Epoch: 2 [150656/387873]    Loss: 0.001881   Batch Acc: 92.19
[Train] Epoch: 2 [150784/387873]    Loss: 0.002080   Batch Acc: 87.50
[Train] Epoch: 2 [150912/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 2 [151040/387873]    Loss: 0.002196   Batch Acc: 89.06
[Train] Epoch: 2 [151168/387873]    Loss: 0.002048   Batch Acc: 89.06
[Train] Epoch: 2 [151296/387873]    Loss: 0.001837   Batch Acc: 89.84
[Train] Epoch: 2 [151424/387873]    Loss: 0.002091   Batch Acc: 88.28
[Train] Epoch: 2 [151552/387873]    Loss: 0.002227   Batch Acc: 85.94
[Train] Epoch: 2 [151680/387873]    Loss: 0.001755   Batch Acc: 89.84
[Train] Epoch: 2 [151808/387873]    Loss: 0.002233   Batch Acc: 89.84
[Train] Epoch: 2 [151936/387873]    Loss: 0.002141   Batch Acc: 89.84
[Train] Epoch: 2 [152064/387873]    Loss: 0.002041   Batch Acc: 89.06
[Train] Epoch: 2 [152192/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 2 [152320/387873]    Loss: 0.001563   Batch Acc: 92.19
[Train] Epoch: 2 [152448/387873]    Loss: 0.002516   Batch Acc: 83.59
[Train] Epoch: 2 [152576/387873]    Loss: 0.002348   Batch Acc: 86.72
[Train] Epoch: 2 [152704/387873]    Loss: 0.002028   Batch Acc: 91.41
[Train] Epoch: 2 [152832/387873]    Loss: 0.001464   Batch Acc: 94.53
[Train] Epoch: 2 [152960/387873]    Loss: 0.001763   Batch Acc: 90.62
[Train] Epoch: 2 [153088/387873]    Loss: 0.001822   Batch Acc: 92.19
[Train] Epoch: 2 [153216/387873]    Loss: 0.002259   Batch Acc: 84.38
[Train] Epoch: 2 [153344/387873]    Loss: 0.002207   Batch Acc: 92.97
[Train] Epoch: 2 [153472/387873]    Loss: 0.001820   Batch Acc: 89.84
[Train] Epoch: 2 [153600/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 2 [153728/387873]    Loss: 0.002161   Batch Acc: 89.84
[Train] Epoch: 2 [153856/387873]    Loss: 0.001816   Batch Acc: 91.41
[Train] Epoch: 2 [153984/387873]    Loss: 0.002241   Batch Acc: 86.72
[Train] Epoch: 2 [154112/387873]    Loss: 0.002066   Batch Acc: 88.28
[Train] Epoch: 2 [154240/387873]    Loss: 0.001911   Batch Acc: 91.41
[Train] Epoch: 2 [154368/387873]    Loss: 0.001777   Batch Acc: 91.41
[Train] Epoch: 2 [154496/387873]    Loss: 0.002228   Batch Acc: 86.72
[Train] Epoch: 2 [154624/387873]    Loss: 0.003057   Batch Acc: 84.38
[Train] Epoch: 2 [154752/387873]    Loss: 0.001859   Batch Acc: 87.50
[Train] Epoch: 2 [154880/387873]    Loss: 0.002332   Batch Acc: 86.72
[Train] Epoch: 2 [155008/387873]    Loss: 0.001829   Batch Acc: 92.19
[Train] Epoch: 2 [155136/387873]    Loss: 0.002384   Batch Acc: 85.94
[Train] Epoch: 2 [155264/387873]    Loss: 0.002153   Batch Acc: 87.50
[Train] Epoch: 2 [155392/387873]    Loss: 0.002183   Batch Acc: 86.72
[Train] Epoch: 2 [155520/387873]    Loss: 0.001621   Batch Acc: 92.19
[Train] Epoch: 2 [155648/387873]    Loss: 0.002202   Batch Acc: 88.28
[Train] Epoch: 2 [155776/387873]    Loss: 0.001743   Batch Acc: 91.41
[Train] Epoch: 2 [155904/387873]    Loss: 0.002775   Batch Acc: 85.16
[Train] Epoch: 2 [156032/387873]    Loss: 0.002089   Batch Acc: 88.28
[Train] Epoch: 2 [156160/387873]    Loss: 0.001804   Batch Acc: 91.41
[Train] Epoch: 2 [156288/387873]    Loss: 0.002288   Batch Acc: 89.84
[Train] Epoch: 2 [156416/387873]    Loss: 0.002360   Batch Acc: 86.72
[Train] Epoch: 2 [156544/387873]    Loss: 0.002144   Batch Acc: 88.28
[Train] Epoch: 2 [156672/387873]    Loss: 0.002493   Batch Acc: 85.94
[Train] Epoch: 2 [156800/387873]    Loss: 0.002327   Batch Acc: 86.72
[Train] Epoch: 2 [156928/387873]    Loss: 0.002105   Batch Acc: 84.38
[Train] Epoch: 2 [157056/387873]    Loss: 0.002445   Batch Acc: 88.28
[Train] Epoch: 2 [157184/387873]    Loss: 0.001934   Batch Acc: 90.62
[Train] Epoch: 2 [157312/387873]    Loss: 0.002795   Batch Acc: 85.16
[Train] Epoch: 2 [157440/387873]    Loss: 0.002010   Batch Acc: 88.28
[Train] Epoch: 2 [157568/387873]    Loss: 0.001811   Batch Acc: 89.84
[Train] Epoch: 2 [157696/387873]    Loss: 0.002252   Batch Acc: 86.72
[Train] Epoch: 2 [157824/387873]    Loss: 0.001970   Batch Acc: 89.06
[Train] Epoch: 2 [157952/387873]    Loss: 0.002385   Batch Acc: 85.94
[Train] Epoch: 2 [158080/387873]    Loss: 0.001600   Batch Acc: 91.41
[Train] Epoch: 2 [158208/387873]    Loss: 0.002076   Batch Acc: 91.41
[Train] Epoch: 2 [158336/387873]    Loss: 0.001777   Batch Acc: 92.19
[Train] Epoch: 2 [158464/387873]    Loss: 0.001856   Batch Acc: 93.75
[Train] Epoch: 2 [158592/387873]    Loss: 0.002230   Batch Acc: 89.84
[Train] Epoch: 2 [158720/387873]    Loss: 0.001762   Batch Acc: 91.41
[Train] Epoch: 2 [158848/387873]    Loss: 0.001781   Batch Acc: 88.28
[Train] Epoch: 2 [158976/387873]    Loss: 0.002499   Batch Acc: 83.59
[Train] Epoch: 2 [159104/387873]    Loss: 0.001740   Batch Acc: 93.75
[Train] Epoch: 2 [159232/387873]    Loss: 0.001834   Batch Acc: 89.84
[Train] Epoch: 2 [159360/387873]    Loss: 0.002033   Batch Acc: 90.62
[Train] Epoch: 2 [159488/387873]    Loss: 0.001933   Batch Acc: 86.72
[Train] Epoch: 2 [159616/387873]    Loss: 0.002016   Batch Acc: 90.62
[Train] Epoch: 2 [159744/387873]    Loss: 0.002263   Batch Acc: 88.28
[Train] Epoch: 2 [159872/387873]    Loss: 0.002211   Batch Acc: 87.50
[Train] Epoch: 2 [160000/387873]    Loss: 0.002290   Batch Acc: 87.50
[Train] Epoch: 2 [160128/387873]    Loss: 0.001889   Batch Acc: 90.62
[Train] Epoch: 2 [160256/387873]    Loss: 0.002143   Batch Acc: 88.28
[Train] Epoch: 2 [160384/387873]    Loss: 0.002402   Batch Acc: 86.72
[Train] Epoch: 2 [160512/387873]    Loss: 0.001954   Batch Acc: 92.19
[Train] Epoch: 2 [160640/387873]    Loss: 0.002706   Batch Acc: 85.16
[Train] Epoch: 2 [160768/387873]    Loss: 0.001959   Batch Acc: 92.97
[Train] Epoch: 2 [160896/387873]    Loss: 0.002058   Batch Acc: 89.06
[Train] Epoch: 2 [161024/387873]    Loss: 0.002210   Batch Acc: 87.50
[Train] Epoch: 2 [161152/387873]    Loss: 0.001886   Batch Acc: 89.84
[Train] Epoch: 2 [161280/387873]    Loss: 0.002023   Batch Acc: 87.50
[Train] Epoch: 2 [161408/387873]    Loss: 0.002616   Batch Acc: 83.59
[Train] Epoch: 2 [161536/387873]    Loss: 0.001964   Batch Acc: 89.84
[Train] Epoch: 2 [161664/387873]    Loss: 0.001967   Batch Acc: 92.19
[Train] Epoch: 2 [161792/387873]    Loss: 0.002104   Batch Acc: 92.19
[Train] Epoch: 2 [161920/387873]    Loss: 0.001942   Batch Acc: 90.62
[Train] Epoch: 2 [162048/387873]    Loss: 0.002037   Batch Acc: 89.06
[Train] Epoch: 2 [162176/387873]    Loss: 0.002088   Batch Acc: 89.06
[Train] Epoch: 2 [162304/387873]    Loss: 0.001863   Batch Acc: 89.84
[Train] Epoch: 2 [162432/387873]    Loss: 0.002398   Batch Acc: 89.06
[Train] Epoch: 2 [162560/387873]    Loss: 0.001603   Batch Acc: 92.19
[Train] Epoch: 2 [162688/387873]    Loss: 0.002997   Batch Acc: 84.38
[Train] Epoch: 2 [162816/387873]    Loss: 0.002029   Batch Acc: 90.62
[Train] Epoch: 2 [162944/387873]    Loss: 0.001498   Batch Acc: 93.75
[Train] Epoch: 2 [163072/387873]    Loss: 0.001858   Batch Acc: 92.97
[Train] Epoch: 2 [163200/387873]    Loss: 0.002371   Batch Acc: 86.72
[Train] Epoch: 2 [163328/387873]    Loss: 0.002340   Batch Acc: 89.06
[Train] Epoch: 2 [163456/387873]    Loss: 0.002728   Batch Acc: 85.16
[Train] Epoch: 2 [163584/387873]    Loss: 0.002145   Batch Acc: 85.94
[Train] Epoch: 2 [163712/387873]    Loss: 0.002010   Batch Acc: 89.84
[Train] Epoch: 2 [163840/387873]    Loss: 0.001872   Batch Acc: 91.41
[Train] Epoch: 2 [163968/387873]    Loss: 0.001672   Batch Acc: 90.62
[Train] Epoch: 2 [164096/387873]    Loss: 0.001998   Batch Acc: 88.28
[Train] Epoch: 2 [164224/387873]    Loss: 0.002268   Batch Acc: 87.50
[Train] Epoch: 2 [164352/387873]    Loss: 0.001975   Batch Acc: 90.62
[Train] Epoch: 2 [164480/387873]    Loss: 0.003331   Batch Acc: 80.47
[Train] Epoch: 2 [164608/387873]    Loss: 0.002074   Batch Acc: 91.41
[Train] Epoch: 2 [164736/387873]    Loss: 0.002190   Batch Acc: 86.72
[Train] Epoch: 2 [164864/387873]    Loss: 0.002680   Batch Acc: 85.16
[Train] Epoch: 2 [164992/387873]    Loss: 0.002021   Batch Acc: 87.50
[Train] Epoch: 2 [165120/387873]    Loss: 0.001833   Batch Acc: 92.19
[Train] Epoch: 2 [165248/387873]    Loss: 0.002467   Batch Acc: 82.81
[Train] Epoch: 2 [165376/387873]    Loss: 0.001567   Batch Acc: 94.53
[Train] Epoch: 2 [165504/387873]    Loss: 0.002318   Batch Acc: 85.94
[Train] Epoch: 2 [165632/387873]    Loss: 0.002650   Batch Acc: 82.03
[Train] Epoch: 2 [165760/387873]    Loss: 0.001707   Batch Acc: 91.41
[Train] Epoch: 2 [165888/387873]    Loss: 0.002498   Batch Acc: 86.72
[Train] Epoch: 2 [166016/387873]    Loss: 0.002200   Batch Acc: 91.41
[Train] Epoch: 2 [166144/387873]    Loss: 0.001933   Batch Acc: 90.62
[Train] Epoch: 2 [166272/387873]    Loss: 0.001943   Batch Acc: 90.62
[Train] Epoch: 2 [166400/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 2 [166528/387873]    Loss: 0.002040   Batch Acc: 88.28
[Train] Epoch: 2 [166656/387873]    Loss: 0.002081   Batch Acc: 87.50
[Train] Epoch: 2 [166784/387873]    Loss: 0.002328   Batch Acc: 89.06
[Train] Epoch: 2 [166912/387873]    Loss: 0.001943   Batch Acc: 89.84
[Train] Epoch: 2 [167040/387873]    Loss: 0.002284   Batch Acc: 88.28
[Train] Epoch: 2 [167168/387873]    Loss: 0.002112   Batch Acc: 89.84
[Train] Epoch: 2 [167296/387873]    Loss: 0.002538   Batch Acc: 85.94
[Train] Epoch: 2 [167424/387873]    Loss: 0.002001   Batch Acc: 89.06
[Train] Epoch: 2 [167552/387873]    Loss: 0.002141   Batch Acc: 88.28
[Train] Epoch: 2 [167680/387873]    Loss: 0.001654   Batch Acc: 94.53
[Train] Epoch: 2 [167808/387873]    Loss: 0.001816   Batch Acc: 89.06
[Train] Epoch: 2 [167936/387873]    Loss: 0.002427   Batch Acc: 85.94
[Train] Epoch: 2 [168064/387873]    Loss: 0.001924   Batch Acc: 90.62
[Train] Epoch: 2 [168192/387873]    Loss: 0.001760   Batch Acc: 90.62
[Train] Epoch: 2 [168320/387873]    Loss: 0.001989   Batch Acc: 91.41
[Train] Epoch: 2 [168448/387873]    Loss: 0.001976   Batch Acc: 85.94
[Train] Epoch: 2 [168576/387873]    Loss: 0.001686   Batch Acc: 92.19
[Train] Epoch: 2 [168704/387873]    Loss: 0.001744   Batch Acc: 91.41
[Train] Epoch: 2 [168832/387873]    Loss: 0.002246   Batch Acc: 88.28
[Train] Epoch: 2 [168960/387873]    Loss: 0.001778   Batch Acc: 92.97
[Train] Epoch: 2 [169088/387873]    Loss: 0.001840   Batch Acc: 91.41
[Train] Epoch: 2 [169216/387873]    Loss: 0.001705   Batch Acc: 94.53
[Train] Epoch: 2 [169344/387873]    Loss: 0.001698   Batch Acc: 93.75
[Train] Epoch: 2 [169472/387873]    Loss: 0.002167   Batch Acc: 91.41
[Train] Epoch: 2 [169600/387873]    Loss: 0.001528   Batch Acc: 93.75
[Train] Epoch: 2 [169728/387873]    Loss: 0.002189   Batch Acc: 89.06
[Train] Epoch: 2 [169856/387873]    Loss: 0.001702   Batch Acc: 93.75
[Train] Epoch: 2 [169984/387873]    Loss: 0.001908   Batch Acc: 91.41
[Train] Epoch: 2 [170112/387873]    Loss: 0.002148   Batch Acc: 87.50
[Train] Epoch: 2 [170240/387873]    Loss: 0.001541   Batch Acc: 91.41
[Train] Epoch: 2 [170368/387873]    Loss: 0.002424   Batch Acc: 87.50
[Train] Epoch: 2 [170496/387873]    Loss: 0.001819   Batch Acc: 88.28
[Train] Epoch: 2 [170624/387873]    Loss: 0.001810   Batch Acc: 89.84
[Train] Epoch: 2 [170752/387873]    Loss: 0.002290   Batch Acc: 86.72
[Train] Epoch: 2 [170880/387873]    Loss: 0.002071   Batch Acc: 88.28
[Train] Epoch: 2 [171008/387873]    Loss: 0.002007   Batch Acc: 90.62
[Train] Epoch: 2 [171136/387873]    Loss: 0.002329   Batch Acc: 86.72
[Train] Epoch: 2 [171264/387873]    Loss: 0.002305   Batch Acc: 85.94
[Train] Epoch: 2 [171392/387873]    Loss: 0.001760   Batch Acc: 92.97
[Train] Epoch: 2 [171520/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 2 [171648/387873]    Loss: 0.001794   Batch Acc: 88.28
[Train] Epoch: 2 [171776/387873]    Loss: 0.002216   Batch Acc: 86.72
[Train] Epoch: 2 [171904/387873]    Loss: 0.001992   Batch Acc: 89.84
[Train] Epoch: 2 [172032/387873]    Loss: 0.001677   Batch Acc: 92.97
[Train] Epoch: 2 [172160/387873]    Loss: 0.001509   Batch Acc: 94.53
[Train] Epoch: 2 [172288/387873]    Loss: 0.001735   Batch Acc: 91.41
[Train] Epoch: 2 [172416/387873]    Loss: 0.001327   Batch Acc: 92.97
[Train] Epoch: 2 [172544/387873]    Loss: 0.001970   Batch Acc: 89.06
[Train] Epoch: 2 [172672/387873]    Loss: 0.002304   Batch Acc: 88.28
[Train] Epoch: 2 [172800/387873]    Loss: 0.001892   Batch Acc: 92.97
[Train] Epoch: 2 [172928/387873]    Loss: 0.002027   Batch Acc: 88.28
[Train] Epoch: 2 [173056/387873]    Loss: 0.001734   Batch Acc: 91.41
[Train] Epoch: 2 [173184/387873]    Loss: 0.002227   Batch Acc: 83.59
[Train] Epoch: 2 [173312/387873]    Loss: 0.002325   Batch Acc: 87.50
[Train] Epoch: 2 [173440/387873]    Loss: 0.001930   Batch Acc: 90.62
[Train] Epoch: 2 [173568/387873]    Loss: 0.002088   Batch Acc: 89.06
[Train] Epoch: 2 [173696/387873]    Loss: 0.002095   Batch Acc: 91.41
[Train] Epoch: 2 [173824/387873]    Loss: 0.002163   Batch Acc: 91.41
[Train] Epoch: 2 [173952/387873]    Loss: 0.001936   Batch Acc: 88.28
[Train] Epoch: 2 [174080/387873]    Loss: 0.001567   Batch Acc: 94.53
[Train] Epoch: 2 [174208/387873]    Loss: 0.001989   Batch Acc: 89.06
[Train] Epoch: 2 [174336/387873]    Loss: 0.002055   Batch Acc: 89.84
[Train] Epoch: 2 [174464/387873]    Loss: 0.001996   Batch Acc: 89.84
[Train] Epoch: 2 [174592/387873]    Loss: 0.001734   Batch Acc: 89.84
[Train] Epoch: 2 [174720/387873]    Loss: 0.001737   Batch Acc: 91.41
[Train] Epoch: 2 [174848/387873]    Loss: 0.001880   Batch Acc: 91.41
[Train] Epoch: 2 [174976/387873]    Loss: 0.001741   Batch Acc: 90.62
[Train] Epoch: 2 [175104/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 2 [175232/387873]    Loss: 0.003008   Batch Acc: 82.81
[Train] Epoch: 2 [175360/387873]    Loss: 0.001719   Batch Acc: 89.84
[Train] Epoch: 2 [175488/387873]    Loss: 0.002469   Batch Acc: 83.59
[Train] Epoch: 2 [175616/387873]    Loss: 0.002470   Batch Acc: 91.41
[Train] Epoch: 2 [175744/387873]    Loss: 0.001767   Batch Acc: 89.06
[Train] Epoch: 2 [175872/387873]    Loss: 0.002070   Batch Acc: 88.28
[Train] Epoch: 2 [176000/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 2 [176128/387873]    Loss: 0.002116   Batch Acc: 87.50
[Train] Epoch: 2 [176256/387873]    Loss: 0.002188   Batch Acc: 85.94
[Train] Epoch: 2 [176384/387873]    Loss: 0.001796   Batch Acc: 89.06
[Train] Epoch: 2 [176512/387873]    Loss: 0.002278   Batch Acc: 84.38
[Train] Epoch: 2 [176640/387873]    Loss: 0.001746   Batch Acc: 89.84
[Train] Epoch: 2 [176768/387873]    Loss: 0.001489   Batch Acc: 94.53
[Train] Epoch: 2 [176896/387873]    Loss: 0.002096   Batch Acc: 87.50
[Train] Epoch: 2 [177024/387873]    Loss: 0.001868   Batch Acc: 91.41
[Train] Epoch: 2 [177152/387873]    Loss: 0.002041   Batch Acc: 91.41
[Train] Epoch: 2 [177280/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 2 [177408/387873]    Loss: 0.001719   Batch Acc: 92.97
[Train] Epoch: 2 [177536/387873]    Loss: 0.001907   Batch Acc: 89.84
[Train] Epoch: 2 [177664/387873]    Loss: 0.002162   Batch Acc: 87.50
[Train] Epoch: 2 [177792/387873]    Loss: 0.002285   Batch Acc: 90.62
[Train] Epoch: 2 [177920/387873]    Loss: 0.002024   Batch Acc: 92.97
[Train] Epoch: 2 [178048/387873]    Loss: 0.002746   Batch Acc: 85.16
[Train] Epoch: 2 [178176/387873]    Loss: 0.002230   Batch Acc: 86.72
[Train] Epoch: 2 [178304/387873]    Loss: 0.002068   Batch Acc: 88.28
[Train] Epoch: 2 [178432/387873]    Loss: 0.002421   Batch Acc: 86.72
[Train] Epoch: 2 [178560/387873]    Loss: 0.002183   Batch Acc: 86.72
[Train] Epoch: 2 [178688/387873]    Loss: 0.002074   Batch Acc: 88.28
[Train] Epoch: 2 [178816/387873]    Loss: 0.001821   Batch Acc: 92.97
[Train] Epoch: 2 [178944/387873]    Loss: 0.002846   Batch Acc: 88.28
[Train] Epoch: 2 [179072/387873]    Loss: 0.001733   Batch Acc: 90.62
[Train] Epoch: 2 [179200/387873]    Loss: 0.001834   Batch Acc: 94.53
[Train] Epoch: 2 [179328/387873]    Loss: 0.001890   Batch Acc: 89.84
[Train] Epoch: 2 [179456/387873]    Loss: 0.001815   Batch Acc: 89.06
[Train] Epoch: 2 [179584/387873]    Loss: 0.001869   Batch Acc: 91.41
[Train] Epoch: 2 [179712/387873]    Loss: 0.001698   Batch Acc: 92.19
[Train] Epoch: 2 [179840/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 2 [179968/387873]    Loss: 0.001939   Batch Acc: 89.84
[Train] Epoch: 2 [180096/387873]    Loss: 0.002267   Batch Acc: 87.50
[Train] Epoch: 2 [180224/387873]    Loss: 0.002177   Batch Acc: 91.41
[Train] Epoch: 2 [180352/387873]    Loss: 0.002136   Batch Acc: 89.06
[Train] Epoch: 2 [180480/387873]    Loss: 0.001640   Batch Acc: 91.41
[Train] Epoch: 2 [180608/387873]    Loss: 0.002661   Batch Acc: 82.03
[Train] Epoch: 2 [180736/387873]    Loss: 0.002042   Batch Acc: 88.28
[Train] Epoch: 2 [180864/387873]    Loss: 0.002799   Batch Acc: 84.38
[Train] Epoch: 2 [180992/387873]    Loss: 0.002493   Batch Acc: 84.38
[Train] Epoch: 2 [181120/387873]    Loss: 0.001519   Batch Acc: 91.41
[Train] Epoch: 2 [181248/387873]    Loss: 0.002310   Batch Acc: 88.28
[Train] Epoch: 2 [181376/387873]    Loss: 0.001699   Batch Acc: 91.41
[Train] Epoch: 2 [181504/387873]    Loss: 0.001963   Batch Acc: 88.28
[Train] Epoch: 2 [181632/387873]    Loss: 0.001635   Batch Acc: 94.53
[Train] Epoch: 2 [181760/387873]    Loss: 0.001777   Batch Acc: 90.62
[Train] Epoch: 2 [181888/387873]    Loss: 0.001817   Batch Acc: 89.84
[Train] Epoch: 2 [182016/387873]    Loss: 0.001839   Batch Acc: 92.19
[Train] Epoch: 2 [182144/387873]    Loss: 0.001790   Batch Acc: 90.62
[Train] Epoch: 2 [182272/387873]    Loss: 0.002214   Batch Acc: 88.28
[Train] Epoch: 2 [182400/387873]    Loss: 0.001797   Batch Acc: 91.41
[Train] Epoch: 2 [182528/387873]    Loss: 0.002103   Batch Acc: 88.28
[Train] Epoch: 2 [182656/387873]    Loss: 0.001831   Batch Acc: 89.84
[Train] Epoch: 2 [182784/387873]    Loss: 0.001916   Batch Acc: 90.62
[Train] Epoch: 2 [182912/387873]    Loss: 0.001753   Batch Acc: 92.97
[Train] Epoch: 2 [183040/387873]    Loss: 0.002468   Batch Acc: 87.50
[Train] Epoch: 2 [183168/387873]    Loss: 0.002233   Batch Acc: 85.94
[Train] Epoch: 2 [183296/387873]    Loss: 0.001753   Batch Acc: 90.62
[Train] Epoch: 2 [183424/387873]    Loss: 0.001732   Batch Acc: 90.62
[Train] Epoch: 2 [183552/387873]    Loss: 0.002428   Batch Acc: 84.38
[Train] Epoch: 2 [183680/387873]    Loss: 0.001650   Batch Acc: 91.41
[Train] Epoch: 2 [183808/387873]    Loss: 0.002125   Batch Acc: 90.62
[Train] Epoch: 2 [183936/387873]    Loss: 0.002762   Batch Acc: 85.16
[Train] Epoch: 2 [184064/387873]    Loss: 0.001643   Batch Acc: 92.19
[Train] Epoch: 2 [184192/387873]    Loss: 0.001724   Batch Acc: 89.84
[Train] Epoch: 2 [184320/387873]    Loss: 0.002189   Batch Acc: 90.62
[Train] Epoch: 2 [184448/387873]    Loss: 0.002288   Batch Acc: 90.62
[Train] Epoch: 2 [184576/387873]    Loss: 0.002175   Batch Acc: 88.28
[Train] Epoch: 2 [184704/387873]    Loss: 0.002794   Batch Acc: 83.59
[Train] Epoch: 2 [184832/387873]    Loss: 0.001866   Batch Acc: 92.97
[Train] Epoch: 2 [184960/387873]    Loss: 0.002410   Batch Acc: 85.94
[Train] Epoch: 2 [185088/387873]    Loss: 0.002147   Batch Acc: 90.62
[Train] Epoch: 2 [185216/387873]    Loss: 0.001732   Batch Acc: 91.41
[Train] Epoch: 2 [185344/387873]    Loss: 0.002324   Batch Acc: 86.72
[Train] Epoch: 2 [185472/387873]    Loss: 0.002049   Batch Acc: 89.06
[Train] Epoch: 2 [185600/387873]    Loss: 0.002968   Batch Acc: 78.91
[Train] Epoch: 2 [185728/387873]    Loss: 0.001706   Batch Acc: 89.84
[Train] Epoch: 2 [185856/387873]    Loss: 0.001516   Batch Acc: 93.75
[Train] Epoch: 2 [185984/387873]    Loss: 0.001699   Batch Acc: 90.62
[Train] Epoch: 2 [186112/387873]    Loss: 0.002311   Batch Acc: 87.50
[Train] Epoch: 2 [186240/387873]    Loss: 0.002048   Batch Acc: 90.62
[Train] Epoch: 2 [186368/387873]    Loss: 0.001781   Batch Acc: 90.62
[Train] Epoch: 2 [186496/387873]    Loss: 0.002126   Batch Acc: 89.06
[Train] Epoch: 2 [186624/387873]    Loss: 0.002046   Batch Acc: 89.06
[Train] Epoch: 2 [186752/387873]    Loss: 0.002385   Batch Acc: 89.06
[Train] Epoch: 2 [186880/387873]    Loss: 0.002620   Batch Acc: 82.81
[Train] Epoch: 2 [187008/387873]    Loss: 0.001777   Batch Acc: 89.06
[Train] Epoch: 2 [187136/387873]    Loss: 0.001975   Batch Acc: 89.06
[Train] Epoch: 2 [187264/387873]    Loss: 0.002167   Batch Acc: 86.72
[Train] Epoch: 2 [187392/387873]    Loss: 0.002011   Batch Acc: 88.28
[Train] Epoch: 2 [187520/387873]    Loss: 0.002334   Batch Acc: 84.38
[Train] Epoch: 2 [187648/387873]    Loss: 0.001710   Batch Acc: 92.97
[Train] Epoch: 2 [187776/387873]    Loss: 0.002205   Batch Acc: 88.28
[Train] Epoch: 2 [187904/387873]    Loss: 0.001882   Batch Acc: 92.19
[Train] Epoch: 2 [188032/387873]    Loss: 0.001763   Batch Acc: 88.28
[Train] Epoch: 2 [188160/387873]    Loss: 0.002733   Batch Acc: 82.81
[Train] Epoch: 2 [188288/387873]    Loss: 0.002201   Batch Acc: 89.84
[Train] Epoch: 2 [188416/387873]    Loss: 0.001883   Batch Acc: 92.97
[Train] Epoch: 2 [188544/387873]    Loss: 0.002174   Batch Acc: 89.84
[Train] Epoch: 2 [188672/387873]    Loss: 0.001690   Batch Acc: 92.19
[Train] Epoch: 2 [188800/387873]    Loss: 0.001525   Batch Acc: 92.97
[Train] Epoch: 2 [188928/387873]    Loss: 0.002400   Batch Acc: 86.72
[Train] Epoch: 2 [189056/387873]    Loss: 0.001624   Batch Acc: 92.97
[Train] Epoch: 2 [189184/387873]    Loss: 0.001879   Batch Acc: 89.06
[Train] Epoch: 2 [189312/387873]    Loss: 0.001735   Batch Acc: 90.62
[Train] Epoch: 2 [189440/387873]    Loss: 0.001819   Batch Acc: 90.62
[Train] Epoch: 2 [189568/387873]    Loss: 0.002979   Batch Acc: 84.38
[Train] Epoch: 2 [189696/387873]    Loss: 0.001965   Batch Acc: 88.28
[Train] Epoch: 2 [189824/387873]    Loss: 0.001965   Batch Acc: 87.50
[Train] Epoch: 2 [189952/387873]    Loss: 0.001894   Batch Acc: 91.41
[Train] Epoch: 2 [190080/387873]    Loss: 0.001962   Batch Acc: 90.62
[Train] Epoch: 2 [190208/387873]    Loss: 0.002086   Batch Acc: 87.50
[Train] Epoch: 2 [190336/387873]    Loss: 0.002178   Batch Acc: 89.06
[Train] Epoch: 2 [190464/387873]    Loss: 0.002399   Batch Acc: 89.06
[Train] Epoch: 2 [190592/387873]    Loss: 0.002334   Batch Acc: 85.16
[Train] Epoch: 2 [190720/387873]    Loss: 0.001680   Batch Acc: 91.41
[Train] Epoch: 2 [190848/387873]    Loss: 0.001953   Batch Acc: 92.19
[Train] Epoch: 2 [190976/387873]    Loss: 0.001549   Batch Acc: 94.53
[Train] Epoch: 2 [191104/387873]    Loss: 0.001869   Batch Acc: 94.53
[Train] Epoch: 2 [191232/387873]    Loss: 0.002585   Batch Acc: 82.81
[Train] Epoch: 2 [191360/387873]    Loss: 0.002143   Batch Acc: 87.50
[Train] Epoch: 2 [191488/387873]    Loss: 0.002588   Batch Acc: 85.16
[Train] Epoch: 2 [191616/387873]    Loss: 0.002192   Batch Acc: 89.84
[Train] Epoch: 2 [191744/387873]    Loss: 0.002399   Batch Acc: 85.94
[Train] Epoch: 2 [191872/387873]    Loss: 0.002535   Batch Acc: 82.81
[Train] Epoch: 2 [192000/387873]    Loss: 0.001454   Batch Acc: 94.53
[Train] Epoch: 2 [192128/387873]    Loss: 0.001809   Batch Acc: 92.19
[Train] Epoch: 2 [192256/387873]    Loss: 0.001759   Batch Acc: 91.41
[Train] Epoch: 2 [192384/387873]    Loss: 0.002029   Batch Acc: 91.41
[Train] Epoch: 2 [192512/387873]    Loss: 0.002005   Batch Acc: 90.62
[Train] Epoch: 2 [192640/387873]    Loss: 0.001743   Batch Acc: 90.62
[Train] Epoch: 2 [192768/387873]    Loss: 0.002505   Batch Acc: 83.59
[Train] Epoch: 2 [192896/387873]    Loss: 0.002249   Batch Acc: 86.72
[Train] Epoch: 2 [193024/387873]    Loss: 0.002431   Batch Acc: 84.38
[Train] Epoch: 2 [193152/387873]    Loss: 0.002176   Batch Acc: 87.50
[Train] Epoch: 2 [193280/387873]    Loss: 0.001966   Batch Acc: 91.41
[Train] Epoch: 2 [193408/387873]    Loss: 0.001975   Batch Acc: 91.41
[Train] Epoch: 2 [193536/387873]    Loss: 0.001813   Batch Acc: 92.97
[Train] Epoch: 2 [193664/387873]    Loss: 0.002213   Batch Acc: 89.06
[Train] Epoch: 2 [193792/387873]    Loss: 0.002598   Batch Acc: 84.38
[Train] Epoch: 2 [193920/387873]    Loss: 0.001784   Batch Acc: 89.06
[Train] Epoch: 2 [194048/387873]    Loss: 0.001743   Batch Acc: 90.62
[Train] Epoch: 2 [194176/387873]    Loss: 0.001723   Batch Acc: 89.84
[Train] Epoch: 2 [194304/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 2 [194432/387873]    Loss: 0.002034   Batch Acc: 89.84
[Train] Epoch: 2 [194560/387873]    Loss: 0.001764   Batch Acc: 92.19
[Train] Epoch: 2 [194688/387873]    Loss: 0.002806   Batch Acc: 85.94
[Train] Epoch: 2 [194816/387873]    Loss: 0.002439   Batch Acc: 85.94
[Train] Epoch: 2 [194944/387873]    Loss: 0.002229   Batch Acc: 86.72
[Train] Epoch: 2 [195072/387873]    Loss: 0.001779   Batch Acc: 89.84
[Train] Epoch: 2 [195200/387873]    Loss: 0.001338   Batch Acc: 96.09
[Train] Epoch: 2 [195328/387873]    Loss: 0.002227   Batch Acc: 86.72
[Train] Epoch: 2 [195456/387873]    Loss: 0.001910   Batch Acc: 89.06
[Train] Epoch: 2 [195584/387873]    Loss: 0.001745   Batch Acc: 90.62
[Train] Epoch: 2 [195712/387873]    Loss: 0.002417   Batch Acc: 85.16
[Train] Epoch: 2 [195840/387873]    Loss: 0.002220   Batch Acc: 85.94
[Train] Epoch: 2 [195968/387873]    Loss: 0.002157   Batch Acc: 86.72
[Train] Epoch: 2 [196096/387873]    Loss: 0.001732   Batch Acc: 90.62
[Train] Epoch: 2 [196224/387873]    Loss: 0.001855   Batch Acc: 91.41
[Train] Epoch: 2 [196352/387873]    Loss: 0.001452   Batch Acc: 93.75
[Train] Epoch: 2 [196480/387873]    Loss: 0.002086   Batch Acc: 85.94
[Train] Epoch: 2 [196608/387873]    Loss: 0.001470   Batch Acc: 95.31
[Train] Epoch: 2 [196736/387873]    Loss: 0.002103   Batch Acc: 88.28
[Train] Epoch: 2 [196864/387873]    Loss: 0.002289   Batch Acc: 86.72
[Train] Epoch: 2 [196992/387873]    Loss: 0.001951   Batch Acc: 91.41
[Train] Epoch: 2 [197120/387873]    Loss: 0.002713   Batch Acc: 82.03
[Train] Epoch: 2 [197248/387873]    Loss: 0.002398   Batch Acc: 86.72
[Train] Epoch: 2 [197376/387873]    Loss: 0.002000   Batch Acc: 89.84
[Train] Epoch: 2 [197504/387873]    Loss: 0.001988   Batch Acc: 88.28
[Train] Epoch: 2 [197632/387873]    Loss: 0.002428   Batch Acc: 86.72
[Train] Epoch: 2 [197760/387873]    Loss: 0.002128   Batch Acc: 85.94
[Train] Epoch: 2 [197888/387873]    Loss: 0.001636   Batch Acc: 93.75
[Train] Epoch: 2 [198016/387873]    Loss: 0.002101   Batch Acc: 86.72
[Train] Epoch: 2 [198144/387873]    Loss: 0.002003   Batch Acc: 89.84
[Train] Epoch: 2 [198272/387873]    Loss: 0.002117   Batch Acc: 90.62
[Train] Epoch: 2 [198400/387873]    Loss: 0.001887   Batch Acc: 90.62
[Train] Epoch: 2 [198528/387873]    Loss: 0.002458   Batch Acc: 89.06
[Train] Epoch: 2 [198656/387873]    Loss: 0.002326   Batch Acc: 84.38
[Train] Epoch: 2 [198784/387873]    Loss: 0.002067   Batch Acc: 89.06
[Train] Epoch: 2 [198912/387873]    Loss: 0.001785   Batch Acc: 92.97
[Train] Epoch: 2 [199040/387873]    Loss: 0.001828   Batch Acc: 91.41
[Train] Epoch: 2 [199168/387873]    Loss: 0.001830   Batch Acc: 90.62
[Train] Epoch: 2 [199296/387873]    Loss: 0.002618   Batch Acc: 84.38
[Train] Epoch: 2 [199424/387873]    Loss: 0.002021   Batch Acc: 89.84
[Train] Epoch: 2 [199552/387873]    Loss: 0.002192   Batch Acc: 92.19
[Train] Epoch: 2 [199680/387873]    Loss: 0.002409   Batch Acc: 85.16
[Train] Epoch: 2 [199808/387873]    Loss: 0.002342   Batch Acc: 88.28
[Train] Epoch: 2 [199936/387873]    Loss: 0.002228   Batch Acc: 90.62
[Train] Epoch: 2 [200064/387873]    Loss: 0.001903   Batch Acc: 89.84
[Train] Epoch: 2 [200192/387873]    Loss: 0.001985   Batch Acc: 90.62
[Train] Epoch: 2 [200320/387873]    Loss: 0.002255   Batch Acc: 85.16
[Train] Epoch: 2 [200448/387873]    Loss: 0.002226   Batch Acc: 85.16
[Train] Epoch: 2 [200576/387873]    Loss: 0.002274   Batch Acc: 87.50
[Train] Epoch: 2 [200704/387873]    Loss: 0.001658   Batch Acc: 94.53
[Train] Epoch: 2 [200832/387873]    Loss: 0.002013   Batch Acc: 90.62
[Train] Epoch: 2 [200960/387873]    Loss: 0.002002   Batch Acc: 88.28
[Train] Epoch: 2 [201088/387873]    Loss: 0.002011   Batch Acc: 89.06
[Train] Epoch: 2 [201216/387873]    Loss: 0.002633   Batch Acc: 84.38
[Train] Epoch: 2 [201344/387873]    Loss: 0.001981   Batch Acc: 88.28
[Train] Epoch: 2 [201472/387873]    Loss: 0.001675   Batch Acc: 90.62
[Train] Epoch: 2 [201600/387873]    Loss: 0.002216   Batch Acc: 89.06
[Train] Epoch: 2 [201728/387873]    Loss: 0.002224   Batch Acc: 87.50
[Train] Epoch: 2 [201856/387873]    Loss: 0.002675   Batch Acc: 82.03
[Train] Epoch: 2 [201984/387873]    Loss: 0.001716   Batch Acc: 92.97
[Train] Epoch: 2 [202112/387873]    Loss: 0.002341   Batch Acc: 85.16
[Train] Epoch: 2 [202240/387873]    Loss: 0.001466   Batch Acc: 92.19
[Train] Epoch: 2 [202368/387873]    Loss: 0.001923   Batch Acc: 90.62
[Train] Epoch: 2 [202496/387873]    Loss: 0.002354   Batch Acc: 85.16
[Train] Epoch: 2 [202624/387873]    Loss: 0.002333   Batch Acc: 87.50
[Train] Epoch: 2 [202752/387873]    Loss: 0.001848   Batch Acc: 90.62
[Train] Epoch: 2 [202880/387873]    Loss: 0.002153   Batch Acc: 85.16
[Train] Epoch: 2 [203008/387873]    Loss: 0.001606   Batch Acc: 92.97
[Train] Epoch: 2 [203136/387873]    Loss: 0.002207   Batch Acc: 86.72
[Train] Epoch: 2 [203264/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 2 [203392/387873]    Loss: 0.002497   Batch Acc: 88.28
[Train] Epoch: 2 [203520/387873]    Loss: 0.001795   Batch Acc: 92.19
[Train] Epoch: 2 [203648/387873]    Loss: 0.002194   Batch Acc: 85.94
[Train] Epoch: 2 [203776/387873]    Loss: 0.001969   Batch Acc: 89.84
[Train] Epoch: 2 [203904/387873]    Loss: 0.002209   Batch Acc: 90.62
[Train] Epoch: 2 [204032/387873]    Loss: 0.002546   Batch Acc: 88.28
[Train] Epoch: 2 [204160/387873]    Loss: 0.002497   Batch Acc: 88.28
[Train] Epoch: 2 [204288/387873]    Loss: 0.002285   Batch Acc: 85.94
[Train] Epoch: 2 [204416/387873]    Loss: 0.002170   Batch Acc: 90.62
[Train] Epoch: 2 [204544/387873]    Loss: 0.002049   Batch Acc: 90.62
[Train] Epoch: 2 [204672/387873]    Loss: 0.002048   Batch Acc: 89.06
[Train] Epoch: 2 [204800/387873]    Loss: 0.002710   Batch Acc: 88.28
[Train] Epoch: 2 [204928/387873]    Loss: 0.001727   Batch Acc: 91.41
[Train] Epoch: 2 [205056/387873]    Loss: 0.001699   Batch Acc: 92.19
[Train] Epoch: 2 [205184/387873]    Loss: 0.002207   Batch Acc: 89.06
[Train] Epoch: 2 [205312/387873]    Loss: 0.001719   Batch Acc: 92.19
[Train] Epoch: 2 [205440/387873]    Loss: 0.002180   Batch Acc: 89.06
[Train] Epoch: 2 [205568/387873]    Loss: 0.001454   Batch Acc: 93.75
[Train] Epoch: 2 [205696/387873]    Loss: 0.002745   Batch Acc: 86.72
[Train] Epoch: 2 [205824/387873]    Loss: 0.002226   Batch Acc: 88.28
[Train] Epoch: 2 [205952/387873]    Loss: 0.002160   Batch Acc: 88.28
[Train] Epoch: 2 [206080/387873]    Loss: 0.001770   Batch Acc: 92.19
[Train] Epoch: 2 [206208/387873]    Loss: 0.002073   Batch Acc: 86.72
[Train] Epoch: 2 [206336/387873]    Loss: 0.002434   Batch Acc: 85.94
[Train] Epoch: 2 [206464/387873]    Loss: 0.002063   Batch Acc: 89.84
[Train] Epoch: 2 [206592/387873]    Loss: 0.001966   Batch Acc: 90.62
[Train] Epoch: 2 [206720/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 2 [206848/387873]    Loss: 0.002243   Batch Acc: 89.84
[Train] Epoch: 2 [206976/387873]    Loss: 0.001840   Batch Acc: 89.06
[Train] Epoch: 2 [207104/387873]    Loss: 0.001759   Batch Acc: 89.84
[Train] Epoch: 2 [207232/387873]    Loss: 0.001826   Batch Acc: 89.06
[Train] Epoch: 2 [207360/387873]    Loss: 0.002108   Batch Acc: 89.84
[Train] Epoch: 2 [207488/387873]    Loss: 0.001899   Batch Acc: 89.84
[Train] Epoch: 2 [207616/387873]    Loss: 0.002067   Batch Acc: 90.62
[Train] Epoch: 2 [207744/387873]    Loss: 0.002836   Batch Acc: 84.38
[Train] Epoch: 2 [207872/387873]    Loss: 0.001364   Batch Acc: 92.19
[Train] Epoch: 2 [208000/387873]    Loss: 0.002442   Batch Acc: 85.16
[Train] Epoch: 2 [208128/387873]    Loss: 0.002211   Batch Acc: 87.50
[Train] Epoch: 2 [208256/387873]    Loss: 0.002135   Batch Acc: 86.72
[Train] Epoch: 2 [208384/387873]    Loss: 0.002374   Batch Acc: 87.50
[Train] Epoch: 2 [208512/387873]    Loss: 0.002197   Batch Acc: 86.72
[Train] Epoch: 2 [208640/387873]    Loss: 0.001658   Batch Acc: 92.19
[Train] Epoch: 2 [208768/387873]    Loss: 0.002039   Batch Acc: 87.50
[Train] Epoch: 2 [208896/387873]    Loss: 0.001918   Batch Acc: 88.28
[Train] Epoch: 2 [209024/387873]    Loss: 0.001697   Batch Acc: 90.62
[Train] Epoch: 2 [209152/387873]    Loss: 0.002213   Batch Acc: 85.94
[Train] Epoch: 2 [209280/387873]    Loss: 0.001775   Batch Acc: 94.53
[Train] Epoch: 2 [209408/387873]    Loss: 0.001912   Batch Acc: 92.19
[Train] Epoch: 2 [209536/387873]    Loss: 0.002124   Batch Acc: 89.06
[Train] Epoch: 2 [209664/387873]    Loss: 0.001957   Batch Acc: 88.28
[Train] Epoch: 2 [209792/387873]    Loss: 0.001919   Batch Acc: 90.62
[Train] Epoch: 2 [209920/387873]    Loss: 0.002021   Batch Acc: 92.19
[Train] Epoch: 2 [210048/387873]    Loss: 0.001643   Batch Acc: 94.53
[Train] Epoch: 2 [210176/387873]    Loss: 0.002203   Batch Acc: 88.28
[Train] Epoch: 2 [210304/387873]    Loss: 0.002202   Batch Acc: 89.06
[Train] Epoch: 2 [210432/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 2 [210560/387873]    Loss: 0.002034   Batch Acc: 88.28
[Train] Epoch: 2 [210688/387873]    Loss: 0.001774   Batch Acc: 91.41
[Train] Epoch: 2 [210816/387873]    Loss: 0.002476   Batch Acc: 82.81
[Train] Epoch: 2 [210944/387873]    Loss: 0.001493   Batch Acc: 94.53
[Train] Epoch: 2 [211072/387873]    Loss: 0.001691   Batch Acc: 92.97
[Train] Epoch: 2 [211200/387873]    Loss: 0.002242   Batch Acc: 88.28
[Train] Epoch: 2 [211328/387873]    Loss: 0.001961   Batch Acc: 89.06
[Train] Epoch: 2 [211456/387873]    Loss: 0.001850   Batch Acc: 89.06
[Train] Epoch: 2 [211584/387873]    Loss: 0.001628   Batch Acc: 92.97
[Train] Epoch: 2 [211712/387873]    Loss: 0.001688   Batch Acc: 92.97
[Train] Epoch: 2 [211840/387873]    Loss: 0.001369   Batch Acc: 94.53
[Train] Epoch: 2 [211968/387873]    Loss: 0.002201   Batch Acc: 86.72
[Train] Epoch: 2 [212096/387873]    Loss: 0.002125   Batch Acc: 88.28
[Train] Epoch: 2 [212224/387873]    Loss: 0.002132   Batch Acc: 88.28
[Train] Epoch: 2 [212352/387873]    Loss: 0.001733   Batch Acc: 92.19
[Train] Epoch: 2 [212480/387873]    Loss: 0.001523   Batch Acc: 90.62
[Train] Epoch: 2 [212608/387873]    Loss: 0.002223   Batch Acc: 89.06
[Train] Epoch: 2 [212736/387873]    Loss: 0.002174   Batch Acc: 89.84
[Train] Epoch: 2 [212864/387873]    Loss: 0.001934   Batch Acc: 90.62
[Train] Epoch: 2 [212992/387873]    Loss: 0.002264   Batch Acc: 88.28
[Train] Epoch: 2 [213120/387873]    Loss: 0.002159   Batch Acc: 87.50
[Train] Epoch: 2 [213248/387873]    Loss: 0.002843   Batch Acc: 84.38
[Train] Epoch: 2 [213376/387873]    Loss: 0.001202   Batch Acc: 93.75
[Train] Epoch: 2 [213504/387873]    Loss: 0.002266   Batch Acc: 85.94
[Train] Epoch: 2 [213632/387873]    Loss: 0.002894   Batch Acc: 85.16
[Train] Epoch: 2 [213760/387873]    Loss: 0.002701   Batch Acc: 84.38
[Train] Epoch: 2 [213888/387873]    Loss: 0.002048   Batch Acc: 91.41
[Train] Epoch: 2 [214016/387873]    Loss: 0.002194   Batch Acc: 89.84
[Train] Epoch: 2 [214144/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 2 [214272/387873]    Loss: 0.002532   Batch Acc: 86.72
[Train] Epoch: 2 [214400/387873]    Loss: 0.001868   Batch Acc: 90.62
[Train] Epoch: 2 [214528/387873]    Loss: 0.001671   Batch Acc: 93.75
[Train] Epoch: 2 [214656/387873]    Loss: 0.002063   Batch Acc: 89.84
[Train] Epoch: 2 [214784/387873]    Loss: 0.001619   Batch Acc: 93.75
[Train] Epoch: 2 [214912/387873]    Loss: 0.001688   Batch Acc: 89.06
[Train] Epoch: 2 [215040/387873]    Loss: 0.001801   Batch Acc: 90.62
[Train] Epoch: 2 [215168/387873]    Loss: 0.002001   Batch Acc: 90.62
[Train] Epoch: 2 [215296/387873]    Loss: 0.001805   Batch Acc: 90.62
[Train] Epoch: 2 [215424/387873]    Loss: 0.002137   Batch Acc: 87.50
[Train] Epoch: 2 [215552/387873]    Loss: 0.002128   Batch Acc: 89.84
[Train] Epoch: 2 [215680/387873]    Loss: 0.001743   Batch Acc: 89.84
[Train] Epoch: 2 [215808/387873]    Loss: 0.003369   Batch Acc: 78.91
[Train] Epoch: 2 [215936/387873]    Loss: 0.001807   Batch Acc: 92.19
[Train] Epoch: 2 [216064/387873]    Loss: 0.002236   Batch Acc: 89.84
[Train] Epoch: 2 [216192/387873]    Loss: 0.002265   Batch Acc: 85.94
[Train] Epoch: 2 [216320/387873]    Loss: 0.001702   Batch Acc: 91.41
[Train] Epoch: 2 [216448/387873]    Loss: 0.002515   Batch Acc: 83.59
[Train] Epoch: 2 [216576/387873]    Loss: 0.002158   Batch Acc: 86.72
[Train] Epoch: 2 [216704/387873]    Loss: 0.002287   Batch Acc: 86.72
[Train] Epoch: 2 [216832/387873]    Loss: 0.002480   Batch Acc: 86.72
[Train] Epoch: 2 [216960/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 2 [217088/387873]    Loss: 0.002102   Batch Acc: 90.62
[Train] Epoch: 2 [217216/387873]    Loss: 0.001949   Batch Acc: 91.41
[Train] Epoch: 2 [217344/387873]    Loss: 0.002020   Batch Acc: 86.72
[Train] Epoch: 2 [217472/387873]    Loss: 0.002098   Batch Acc: 88.28
[Train] Epoch: 2 [217600/387873]    Loss: 0.001889   Batch Acc: 87.50
[Train] Epoch: 2 [217728/387873]    Loss: 0.001857   Batch Acc: 92.19
[Train] Epoch: 2 [217856/387873]    Loss: 0.001637   Batch Acc: 90.62
[Train] Epoch: 2 [217984/387873]    Loss: 0.001572   Batch Acc: 92.97
[Train] Epoch: 2 [218112/387873]    Loss: 0.001749   Batch Acc: 92.19
[Train] Epoch: 2 [218240/387873]    Loss: 0.002007   Batch Acc: 89.84
[Train] Epoch: 2 [218368/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 2 [218496/387873]    Loss: 0.001751   Batch Acc: 90.62
[Train] Epoch: 2 [218624/387873]    Loss: 0.002412   Batch Acc: 85.94
[Train] Epoch: 2 [218752/387873]    Loss: 0.001718   Batch Acc: 95.31
[Train] Epoch: 2 [218880/387873]    Loss: 0.002165   Batch Acc: 87.50
[Train] Epoch: 2 [219008/387873]    Loss: 0.001620   Batch Acc: 94.53
[Train] Epoch: 2 [219136/387873]    Loss: 0.002350   Batch Acc: 85.16
[Train] Epoch: 2 [219264/387873]    Loss: 0.002065   Batch Acc: 89.06
[Train] Epoch: 2 [219392/387873]    Loss: 0.002237   Batch Acc: 85.94
[Train] Epoch: 2 [219520/387873]    Loss: 0.002310   Batch Acc: 85.94
[Train] Epoch: 2 [219648/387873]    Loss: 0.002138   Batch Acc: 85.94
[Train] Epoch: 2 [219776/387873]    Loss: 0.002274   Batch Acc: 85.94
[Train] Epoch: 2 [219904/387873]    Loss: 0.002652   Batch Acc: 85.94
[Train] Epoch: 2 [220032/387873]    Loss: 0.001806   Batch Acc: 92.19
[Train] Epoch: 2 [220160/387873]    Loss: 0.002530   Batch Acc: 82.03
[Train] Epoch: 2 [220288/387873]    Loss: 0.002098   Batch Acc: 89.06
[Train] Epoch: 2 [220416/387873]    Loss: 0.001745   Batch Acc: 91.41
[Train] Epoch: 2 [220544/387873]    Loss: 0.002235   Batch Acc: 89.06
[Train] Epoch: 2 [220672/387873]    Loss: 0.002231   Batch Acc: 84.38
[Train] Epoch: 2 [220800/387873]    Loss: 0.002245   Batch Acc: 89.06
[Train] Epoch: 2 [220928/387873]    Loss: 0.001792   Batch Acc: 90.62
[Train] Epoch: 2 [221056/387873]    Loss: 0.001579   Batch Acc: 91.41
[Train] Epoch: 2 [221184/387873]    Loss: 0.001424   Batch Acc: 95.31
[Train] Epoch: 2 [221312/387873]    Loss: 0.002127   Batch Acc: 89.06
[Train] Epoch: 2 [221440/387873]    Loss: 0.001866   Batch Acc: 88.28
[Train] Epoch: 2 [221568/387873]    Loss: 0.001903   Batch Acc: 89.06
[Train] Epoch: 2 [221696/387873]    Loss: 0.001960   Batch Acc: 92.19
[Train] Epoch: 2 [221824/387873]    Loss: 0.002437   Batch Acc: 85.94
[Train] Epoch: 2 [221952/387873]    Loss: 0.002654   Batch Acc: 82.03
[Train] Epoch: 2 [222080/387873]    Loss: 0.001548   Batch Acc: 95.31
[Train] Epoch: 2 [222208/387873]    Loss: 0.001796   Batch Acc: 91.41
[Train] Epoch: 2 [222336/387873]    Loss: 0.002035   Batch Acc: 88.28
[Train] Epoch: 2 [222464/387873]    Loss: 0.002018   Batch Acc: 89.84
[Train] Epoch: 2 [222592/387873]    Loss: 0.001659   Batch Acc: 92.19
[Train] Epoch: 2 [222720/387873]    Loss: 0.002430   Batch Acc: 86.72
[Train] Epoch: 2 [222848/387873]    Loss: 0.001946   Batch Acc: 91.41
[Train] Epoch: 2 [222976/387873]    Loss: 0.002379   Batch Acc: 87.50
[Train] Epoch: 2 [223104/387873]    Loss: 0.001567   Batch Acc: 95.31
[Train] Epoch: 2 [223232/387873]    Loss: 0.002848   Batch Acc: 84.38
[Train] Epoch: 2 [223360/387873]    Loss: 0.001663   Batch Acc: 89.84
[Train] Epoch: 2 [223488/387873]    Loss: 0.001814   Batch Acc: 90.62
[Train] Epoch: 2 [223616/387873]    Loss: 0.001862   Batch Acc: 92.97
[Train] Epoch: 2 [223744/387873]    Loss: 0.001628   Batch Acc: 93.75
[Train] Epoch: 2 [223872/387873]    Loss: 0.001419   Batch Acc: 92.97
[Train] Epoch: 2 [224000/387873]    Loss: 0.002062   Batch Acc: 89.84
[Train] Epoch: 2 [224128/387873]    Loss: 0.001668   Batch Acc: 95.31
[Train] Epoch: 2 [224256/387873]    Loss: 0.002143   Batch Acc: 89.06
[Train] Epoch: 2 [224384/387873]    Loss: 0.001865   Batch Acc: 91.41
[Train] Epoch: 2 [224512/387873]    Loss: 0.001970   Batch Acc: 88.28
[Train] Epoch: 2 [224640/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 2 [224768/387873]    Loss: 0.001510   Batch Acc: 95.31
[Train] Epoch: 2 [224896/387873]    Loss: 0.002012   Batch Acc: 88.28
[Train] Epoch: 2 [225024/387873]    Loss: 0.001928   Batch Acc: 87.50
[Train] Epoch: 2 [225152/387873]    Loss: 0.001551   Batch Acc: 92.97
[Train] Epoch: 2 [225280/387873]    Loss: 0.001648   Batch Acc: 92.19
[Train] Epoch: 2 [225408/387873]    Loss: 0.001593   Batch Acc: 90.62
[Train] Epoch: 2 [225536/387873]    Loss: 0.001329   Batch Acc: 95.31
[Train] Epoch: 2 [225664/387873]    Loss: 0.001388   Batch Acc: 92.97
[Train] Epoch: 2 [225792/387873]    Loss: 0.002249   Batch Acc: 91.41
[Train] Epoch: 2 [225920/387873]    Loss: 0.002197   Batch Acc: 89.06
[Train] Epoch: 2 [226048/387873]    Loss: 0.002159   Batch Acc: 86.72
[Train] Epoch: 2 [226176/387873]    Loss: 0.002236   Batch Acc: 86.72
[Train] Epoch: 2 [226304/387873]    Loss: 0.001392   Batch Acc: 94.53
[Train] Epoch: 2 [226432/387873]    Loss: 0.001599   Batch Acc: 92.97
[Train] Epoch: 2 [226560/387873]    Loss: 0.001872   Batch Acc: 89.84
[Train] Epoch: 2 [226688/387873]    Loss: 0.001797   Batch Acc: 92.19
[Train] Epoch: 2 [226816/387873]    Loss: 0.001890   Batch Acc: 89.84
[Train] Epoch: 2 [226944/387873]    Loss: 0.001928   Batch Acc: 89.06
[Train] Epoch: 2 [227072/387873]    Loss: 0.002021   Batch Acc: 89.06
[Train] Epoch: 2 [227200/387873]    Loss: 0.001873   Batch Acc: 89.84
[Train] Epoch: 2 [227328/387873]    Loss: 0.001412   Batch Acc: 94.53
[Train] Epoch: 2 [227456/387873]    Loss: 0.001877   Batch Acc: 89.06
[Train] Epoch: 2 [227584/387873]    Loss: 0.001922   Batch Acc: 92.19
[Train] Epoch: 2 [227712/387873]    Loss: 0.001871   Batch Acc: 90.62
[Train] Epoch: 2 [227840/387873]    Loss: 0.001395   Batch Acc: 92.19
[Train] Epoch: 2 [227968/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 2 [228096/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 2 [228224/387873]    Loss: 0.001904   Batch Acc: 89.06
[Train] Epoch: 2 [228352/387873]    Loss: 0.001843   Batch Acc: 89.84
[Train] Epoch: 2 [228480/387873]    Loss: 0.001493   Batch Acc: 92.97
[Train] Epoch: 2 [228608/387873]    Loss: 0.001741   Batch Acc: 89.06
[Train] Epoch: 2 [228736/387873]    Loss: 0.002539   Batch Acc: 86.72
[Train] Epoch: 2 [228864/387873]    Loss: 0.002227   Batch Acc: 87.50
[Train] Epoch: 2 [228992/387873]    Loss: 0.002353   Batch Acc: 89.06
[Train] Epoch: 2 [229120/387873]    Loss: 0.002033   Batch Acc: 87.50
[Train] Epoch: 2 [229248/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 2 [229376/387873]    Loss: 0.002200   Batch Acc: 84.38
[Train] Epoch: 2 [229504/387873]    Loss: 0.001683   Batch Acc: 91.41
[Train] Epoch: 2 [229632/387873]    Loss: 0.002177   Batch Acc: 91.41
[Train] Epoch: 2 [229760/387873]    Loss: 0.002026   Batch Acc: 90.62
[Train] Epoch: 2 [229888/387873]    Loss: 0.002201   Batch Acc: 88.28
[Train] Epoch: 2 [230016/387873]    Loss: 0.001795   Batch Acc: 91.41
[Train] Epoch: 2 [230144/387873]    Loss: 0.001725   Batch Acc: 93.75
[Train] Epoch: 2 [230272/387873]    Loss: 0.001534   Batch Acc: 91.41
[Train] Epoch: 2 [230400/387873]    Loss: 0.001878   Batch Acc: 90.62
[Train] Epoch: 2 [230528/387873]    Loss: 0.001713   Batch Acc: 94.53
[Train] Epoch: 2 [230656/387873]    Loss: 0.001688   Batch Acc: 91.41
[Train] Epoch: 2 [230784/387873]    Loss: 0.002331   Batch Acc: 86.72
[Train] Epoch: 2 [230912/387873]    Loss: 0.001745   Batch Acc: 92.97
[Train] Epoch: 2 [231040/387873]    Loss: 0.002209   Batch Acc: 88.28
[Train] Epoch: 2 [231168/387873]    Loss: 0.001830   Batch Acc: 89.06
[Train] Epoch: 2 [231296/387873]    Loss: 0.002202   Batch Acc: 88.28
[Train] Epoch: 2 [231424/387873]    Loss: 0.001990   Batch Acc: 86.72
[Train] Epoch: 2 [231552/387873]    Loss: 0.001490   Batch Acc: 92.19
[Train] Epoch: 2 [231680/387873]    Loss: 0.001750   Batch Acc: 90.62
[Train] Epoch: 2 [231808/387873]    Loss: 0.002076   Batch Acc: 92.19
[Train] Epoch: 2 [231936/387873]    Loss: 0.001921   Batch Acc: 90.62
[Train] Epoch: 2 [232064/387873]    Loss: 0.002341   Batch Acc: 87.50
[Train] Epoch: 2 [232192/387873]    Loss: 0.001923   Batch Acc: 89.84
[Train] Epoch: 2 [232320/387873]    Loss: 0.001704   Batch Acc: 91.41
[Train] Epoch: 2 [232448/387873]    Loss: 0.001749   Batch Acc: 92.19
[Train] Epoch: 2 [232576/387873]    Loss: 0.002409   Batch Acc: 86.72
[Train] Epoch: 2 [232704/387873]    Loss: 0.001715   Batch Acc: 91.41
[Train] Epoch: 2 [232832/387873]    Loss: 0.002075   Batch Acc: 88.28
[Train] Epoch: 2 [232960/387873]    Loss: 0.001939   Batch Acc: 87.50
[Train] Epoch: 2 [233088/387873]    Loss: 0.001982   Batch Acc: 88.28
[Train] Epoch: 2 [233216/387873]    Loss: 0.001746   Batch Acc: 90.62
[Train] Epoch: 2 [233344/387873]    Loss: 0.002021   Batch Acc: 89.84
[Train] Epoch: 2 [233472/387873]    Loss: 0.002404   Batch Acc: 86.72
[Train] Epoch: 2 [233600/387873]    Loss: 0.003221   Batch Acc: 82.03
[Train] Epoch: 2 [233728/387873]    Loss: 0.002176   Batch Acc: 90.62
[Train] Epoch: 2 [233856/387873]    Loss: 0.002150   Batch Acc: 88.28
[Train] Epoch: 2 [233984/387873]    Loss: 0.002324   Batch Acc: 83.59
[Train] Epoch: 2 [234112/387873]    Loss: 0.001957   Batch Acc: 90.62
[Train] Epoch: 2 [234240/387873]    Loss: 0.002120   Batch Acc: 89.84
[Train] Epoch: 2 [234368/387873]    Loss: 0.001947   Batch Acc: 89.84
[Train] Epoch: 2 [234496/387873]    Loss: 0.002187   Batch Acc: 88.28
[Train] Epoch: 2 [234624/387873]    Loss: 0.002016   Batch Acc: 89.84
[Train] Epoch: 2 [234752/387873]    Loss: 0.002171   Batch Acc: 89.84
[Train] Epoch: 2 [234880/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 2 [235008/387873]    Loss: 0.002039   Batch Acc: 89.06
[Train] Epoch: 2 [235136/387873]    Loss: 0.002077   Batch Acc: 89.06
[Train] Epoch: 2 [235264/387873]    Loss: 0.001993   Batch Acc: 90.62
[Train] Epoch: 2 [235392/387873]    Loss: 0.001847   Batch Acc: 89.84
[Train] Epoch: 2 [235520/387873]    Loss: 0.001527   Batch Acc: 92.19
[Train] Epoch: 2 [235648/387873]    Loss: 0.001891   Batch Acc: 88.28
[Train] Epoch: 2 [235776/387873]    Loss: 0.002083   Batch Acc: 87.50
[Train] Epoch: 2 [235904/387873]    Loss: 0.002106   Batch Acc: 90.62
[Train] Epoch: 2 [236032/387873]    Loss: 0.002125   Batch Acc: 89.06
[Train] Epoch: 2 [236160/387873]    Loss: 0.001930   Batch Acc: 89.84
[Train] Epoch: 2 [236288/387873]    Loss: 0.002310   Batch Acc: 87.50
[Train] Epoch: 2 [236416/387873]    Loss: 0.002573   Batch Acc: 84.38
[Train] Epoch: 2 [236544/387873]    Loss: 0.002234   Batch Acc: 89.06
[Train] Epoch: 2 [236672/387873]    Loss: 0.001746   Batch Acc: 88.28
[Train] Epoch: 2 [236800/387873]    Loss: 0.002216   Batch Acc: 88.28
[Train] Epoch: 2 [236928/387873]    Loss: 0.002029   Batch Acc: 85.16
[Train] Epoch: 2 [237056/387873]    Loss: 0.001822   Batch Acc: 91.41
[Train] Epoch: 2 [237184/387873]    Loss: 0.002067   Batch Acc: 89.84
[Train] Epoch: 2 [237312/387873]    Loss: 0.002149   Batch Acc: 89.06
[Train] Epoch: 2 [237440/387873]    Loss: 0.001738   Batch Acc: 92.97
[Train] Epoch: 2 [237568/387873]    Loss: 0.001747   Batch Acc: 89.06
[Train] Epoch: 2 [237696/387873]    Loss: 0.002199   Batch Acc: 88.28
[Train] Epoch: 2 [237824/387873]    Loss: 0.002451   Batch Acc: 87.50
[Train] Epoch: 2 [237952/387873]    Loss: 0.001954   Batch Acc: 90.62
[Train] Epoch: 2 [238080/387873]    Loss: 0.002603   Batch Acc: 89.06
[Train] Epoch: 2 [238208/387873]    Loss: 0.001557   Batch Acc: 92.97
[Train] Epoch: 2 [238336/387873]    Loss: 0.001911   Batch Acc: 88.28
[Train] Epoch: 2 [238464/387873]    Loss: 0.001969   Batch Acc: 92.19
[Train] Epoch: 2 [238592/387873]    Loss: 0.002291   Batch Acc: 85.16
[Train] Epoch: 2 [238720/387873]    Loss: 0.002065   Batch Acc: 88.28
[Train] Epoch: 2 [238848/387873]    Loss: 0.002006   Batch Acc: 90.62
[Train] Epoch: 2 [238976/387873]    Loss: 0.002170   Batch Acc: 88.28
[Train] Epoch: 2 [239104/387873]    Loss: 0.001535   Batch Acc: 91.41
[Train] Epoch: 2 [239232/387873]    Loss: 0.002306   Batch Acc: 84.38
[Train] Epoch: 2 [239360/387873]    Loss: 0.001973   Batch Acc: 89.06
[Train] Epoch: 2 [239488/387873]    Loss: 0.002009   Batch Acc: 90.62
[Train] Epoch: 2 [239616/387873]    Loss: 0.001864   Batch Acc: 91.41
[Train] Epoch: 2 [239744/387873]    Loss: 0.002000   Batch Acc: 88.28
[Train] Epoch: 2 [239872/387873]    Loss: 0.001867   Batch Acc: 92.19
[Train] Epoch: 2 [240000/387873]    Loss: 0.001746   Batch Acc: 90.62
[Train] Epoch: 2 [240128/387873]    Loss: 0.001979   Batch Acc: 89.84
[Train] Epoch: 2 [240256/387873]    Loss: 0.001899   Batch Acc: 89.84
[Train] Epoch: 2 [240384/387873]    Loss: 0.002257   Batch Acc: 85.94
[Train] Epoch: 2 [240512/387873]    Loss: 0.002121   Batch Acc: 89.84
[Train] Epoch: 2 [240640/387873]    Loss: 0.002802   Batch Acc: 85.16
[Train] Epoch: 2 [240768/387873]    Loss: 0.001481   Batch Acc: 92.19
[Train] Epoch: 2 [240896/387873]    Loss: 0.002173   Batch Acc: 89.06
[Train] Epoch: 2 [241024/387873]    Loss: 0.002028   Batch Acc: 91.41
[Train] Epoch: 2 [241152/387873]    Loss: 0.001569   Batch Acc: 94.53
[Train] Epoch: 2 [241280/387873]    Loss: 0.002077   Batch Acc: 90.62
[Train] Epoch: 2 [241408/387873]    Loss: 0.001500   Batch Acc: 93.75
[Train] Epoch: 2 [241536/387873]    Loss: 0.001701   Batch Acc: 92.97
[Train] Epoch: 2 [241664/387873]    Loss: 0.002072   Batch Acc: 88.28
[Train] Epoch: 2 [241792/387873]    Loss: 0.001966   Batch Acc: 89.84
[Train] Epoch: 2 [241920/387873]    Loss: 0.001768   Batch Acc: 89.84
[Train] Epoch: 2 [242048/387873]    Loss: 0.002076   Batch Acc: 90.62
[Train] Epoch: 2 [242176/387873]    Loss: 0.002071   Batch Acc: 89.06
[Train] Epoch: 2 [242304/387873]    Loss: 0.002041   Batch Acc: 88.28
[Train] Epoch: 2 [242432/387873]    Loss: 0.002358   Batch Acc: 89.06
[Train] Epoch: 2 [242560/387873]    Loss: 0.002313   Batch Acc: 89.84
[Train] Epoch: 2 [242688/387873]    Loss: 0.001912   Batch Acc: 90.62
[Train] Epoch: 2 [242816/387873]    Loss: 0.001904   Batch Acc: 90.62
[Train] Epoch: 2 [242944/387873]    Loss: 0.001934   Batch Acc: 86.72
[Train] Epoch: 2 [243072/387873]    Loss: 0.002644   Batch Acc: 85.94
[Train] Epoch: 2 [243200/387873]    Loss: 0.002331   Batch Acc: 85.94
[Train] Epoch: 2 [243328/387873]    Loss: 0.001990   Batch Acc: 89.84
[Train] Epoch: 2 [243456/387873]    Loss: 0.002387   Batch Acc: 86.72
[Train] Epoch: 2 [243584/387873]    Loss: 0.001753   Batch Acc: 91.41
[Train] Epoch: 2 [243712/387873]    Loss: 0.002604   Batch Acc: 85.16
[Train] Epoch: 2 [243840/387873]    Loss: 0.002279   Batch Acc: 85.94
[Train] Epoch: 2 [243968/387873]    Loss: 0.001801   Batch Acc: 90.62
[Train] Epoch: 2 [244096/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 2 [244224/387873]    Loss: 0.002184   Batch Acc: 86.72
[Train] Epoch: 2 [244352/387873]    Loss: 0.001971   Batch Acc: 91.41
[Train] Epoch: 2 [244480/387873]    Loss: 0.002108   Batch Acc: 90.62
[Train] Epoch: 2 [244608/387873]    Loss: 0.001943   Batch Acc: 90.62
[Train] Epoch: 2 [244736/387873]    Loss: 0.002913   Batch Acc: 83.59
[Train] Epoch: 2 [244864/387873]    Loss: 0.002048   Batch Acc: 89.06
[Train] Epoch: 2 [244992/387873]    Loss: 0.001896   Batch Acc: 91.41
[Train] Epoch: 2 [245120/387873]    Loss: 0.002193   Batch Acc: 88.28
[Train] Epoch: 2 [245248/387873]    Loss: 0.002190   Batch Acc: 88.28
[Train] Epoch: 2 [245376/387873]    Loss: 0.001964   Batch Acc: 91.41
[Train] Epoch: 2 [245504/387873]    Loss: 0.002062   Batch Acc: 90.62
[Train] Epoch: 2 [245632/387873]    Loss: 0.002120   Batch Acc: 86.72
[Train] Epoch: 2 [245760/387873]    Loss: 0.001814   Batch Acc: 92.19
[Train] Epoch: 2 [245888/387873]    Loss: 0.001649   Batch Acc: 90.62
[Train] Epoch: 2 [246016/387873]    Loss: 0.002079   Batch Acc: 83.59
[Train] Epoch: 2 [246144/387873]    Loss: 0.002683   Batch Acc: 86.72
[Train] Epoch: 2 [246272/387873]    Loss: 0.002229   Batch Acc: 88.28
[Train] Epoch: 2 [246400/387873]    Loss: 0.002146   Batch Acc: 89.84
[Train] Epoch: 2 [246528/387873]    Loss: 0.002066   Batch Acc: 92.19
[Train] Epoch: 2 [246656/387873]    Loss: 0.002301   Batch Acc: 86.72
[Train] Epoch: 2 [246784/387873]    Loss: 0.002189   Batch Acc: 89.84
[Train] Epoch: 2 [246912/387873]    Loss: 0.001590   Batch Acc: 91.41
[Train] Epoch: 2 [247040/387873]    Loss: 0.002028   Batch Acc: 88.28
[Train] Epoch: 2 [247168/387873]    Loss: 0.001938   Batch Acc: 85.94
[Train] Epoch: 2 [247296/387873]    Loss: 0.002064   Batch Acc: 90.62
[Train] Epoch: 2 [247424/387873]    Loss: 0.001883   Batch Acc: 90.62
[Train] Epoch: 2 [247552/387873]    Loss: 0.002194   Batch Acc: 87.50
[Train] Epoch: 2 [247680/387873]    Loss: 0.001777   Batch Acc: 89.84
[Train] Epoch: 2 [247808/387873]    Loss: 0.002103   Batch Acc: 89.06
[Train] Epoch: 2 [247936/387873]    Loss: 0.001760   Batch Acc: 92.97
[Train] Epoch: 2 [248064/387873]    Loss: 0.001827   Batch Acc: 91.41
[Train] Epoch: 2 [248192/387873]    Loss: 0.002249   Batch Acc: 87.50
[Train] Epoch: 2 [248320/387873]    Loss: 0.002167   Batch Acc: 86.72
[Train] Epoch: 2 [248448/387873]    Loss: 0.002486   Batch Acc: 82.81
[Train] Epoch: 2 [248576/387873]    Loss: 0.002451   Batch Acc: 89.06
[Train] Epoch: 2 [248704/387873]    Loss: 0.001362   Batch Acc: 92.19
[Train] Epoch: 2 [248832/387873]    Loss: 0.001409   Batch Acc: 94.53
[Train] Epoch: 2 [248960/387873]    Loss: 0.001607   Batch Acc: 95.31
[Train] Epoch: 2 [249088/387873]    Loss: 0.001489   Batch Acc: 95.31
[Train] Epoch: 2 [249216/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 2 [249344/387873]    Loss: 0.002749   Batch Acc: 82.81
[Train] Epoch: 2 [249472/387873]    Loss: 0.001898   Batch Acc: 89.84
[Train] Epoch: 2 [249600/387873]    Loss: 0.002166   Batch Acc: 87.50
[Train] Epoch: 2 [249728/387873]    Loss: 0.002128   Batch Acc: 89.06
[Train] Epoch: 2 [249856/387873]    Loss: 0.002249   Batch Acc: 85.94
[Train] Epoch: 2 [249984/387873]    Loss: 0.001831   Batch Acc: 89.84
[Train] Epoch: 2 [250112/387873]    Loss: 0.001818   Batch Acc: 90.62
[Train] Epoch: 2 [250240/387873]    Loss: 0.001782   Batch Acc: 92.19
[Train] Epoch: 2 [250368/387873]    Loss: 0.002017   Batch Acc: 87.50
[Train] Epoch: 2 [250496/387873]    Loss: 0.002452   Batch Acc: 87.50
[Train] Epoch: 2 [250624/387873]    Loss: 0.002078   Batch Acc: 89.06
[Train] Epoch: 2 [250752/387873]    Loss: 0.001625   Batch Acc: 94.53
[Train] Epoch: 2 [250880/387873]    Loss: 0.001881   Batch Acc: 92.19
[Train] Epoch: 2 [251008/387873]    Loss: 0.001944   Batch Acc: 86.72
[Train] Epoch: 2 [251136/387873]    Loss: 0.001986   Batch Acc: 89.06
[Train] Epoch: 2 [251264/387873]    Loss: 0.001737   Batch Acc: 93.75
[Train] Epoch: 2 [251392/387873]    Loss: 0.002439   Batch Acc: 86.72
[Train] Epoch: 2 [251520/387873]    Loss: 0.002027   Batch Acc: 87.50
[Train] Epoch: 2 [251648/387873]    Loss: 0.002748   Batch Acc: 79.69
[Train] Epoch: 2 [251776/387873]    Loss: 0.001589   Batch Acc: 92.97
[Train] Epoch: 2 [251904/387873]    Loss: 0.001660   Batch Acc: 93.75
[Train] Epoch: 2 [252032/387873]    Loss: 0.002651   Batch Acc: 83.59
[Train] Epoch: 2 [252160/387873]    Loss: 0.002580   Batch Acc: 85.16
[Train] Epoch: 2 [252288/387873]    Loss: 0.001911   Batch Acc: 89.84
[Train] Epoch: 2 [252416/387873]    Loss: 0.002209   Batch Acc: 88.28
[Train] Epoch: 2 [252544/387873]    Loss: 0.002606   Batch Acc: 86.72
[Train] Epoch: 2 [252672/387873]    Loss: 0.001695   Batch Acc: 90.62
[Train] Epoch: 2 [252800/387873]    Loss: 0.002043   Batch Acc: 89.06
[Train] Epoch: 2 [252928/387873]    Loss: 0.001684   Batch Acc: 88.28
[Train] Epoch: 2 [253056/387873]    Loss: 0.002832   Batch Acc: 83.59
[Train] Epoch: 2 [253184/387873]    Loss: 0.002208   Batch Acc: 89.84
[Train] Epoch: 2 [253312/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 2 [253440/387873]    Loss: 0.002191   Batch Acc: 88.28
[Train] Epoch: 2 [253568/387873]    Loss: 0.002056   Batch Acc: 89.84
[Train] Epoch: 2 [253696/387873]    Loss: 0.001754   Batch Acc: 89.84
[Train] Epoch: 2 [253824/387873]    Loss: 0.002104   Batch Acc: 89.84
[Train] Epoch: 2 [253952/387873]    Loss: 0.002119   Batch Acc: 89.06
[Train] Epoch: 2 [254080/387873]    Loss: 0.001684   Batch Acc: 92.97
[Train] Epoch: 2 [254208/387873]    Loss: 0.002098   Batch Acc: 89.84
[Train] Epoch: 2 [254336/387873]    Loss: 0.001734   Batch Acc: 91.41
[Train] Epoch: 2 [254464/387873]    Loss: 0.001714   Batch Acc: 93.75
[Train] Epoch: 2 [254592/387873]    Loss: 0.001714   Batch Acc: 89.84
[Train] Epoch: 2 [254720/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 2 [254848/387873]    Loss: 0.001953   Batch Acc: 89.84
[Train] Epoch: 2 [254976/387873]    Loss: 0.002026   Batch Acc: 86.72
[Train] Epoch: 2 [255104/387873]    Loss: 0.001658   Batch Acc: 91.41
[Train] Epoch: 2 [255232/387873]    Loss: 0.002231   Batch Acc: 87.50
[Train] Epoch: 2 [255360/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 2 [255488/387873]    Loss: 0.002107   Batch Acc: 89.06
[Train] Epoch: 2 [255616/387873]    Loss: 0.001693   Batch Acc: 90.62
[Train] Epoch: 2 [255744/387873]    Loss: 0.002079   Batch Acc: 91.41
[Train] Epoch: 2 [255872/387873]    Loss: 0.002405   Batch Acc: 85.94
[Train] Epoch: 2 [256000/387873]    Loss: 0.002260   Batch Acc: 89.06
[Train] Epoch: 2 [256128/387873]    Loss: 0.001792   Batch Acc: 90.62
[Train] Epoch: 2 [256256/387873]    Loss: 0.002014   Batch Acc: 87.50
[Train] Epoch: 2 [256384/387873]    Loss: 0.002012   Batch Acc: 92.19
[Train] Epoch: 2 [256512/387873]    Loss: 0.001878   Batch Acc: 89.84
[Train] Epoch: 2 [256640/387873]    Loss: 0.002329   Batch Acc: 86.72
[Train] Epoch: 2 [256768/387873]    Loss: 0.002094   Batch Acc: 88.28
[Train] Epoch: 2 [256896/387873]    Loss: 0.002244   Batch Acc: 87.50
[Train] Epoch: 2 [257024/387873]    Loss: 0.001845   Batch Acc: 91.41
[Train] Epoch: 2 [257152/387873]    Loss: 0.002011   Batch Acc: 88.28
[Train] Epoch: 2 [257280/387873]    Loss: 0.001345   Batch Acc: 95.31
[Train] Epoch: 2 [257408/387873]    Loss: 0.002246   Batch Acc: 88.28
[Train] Epoch: 2 [257536/387873]    Loss: 0.002041   Batch Acc: 87.50
[Train] Epoch: 2 [257664/387873]    Loss: 0.002785   Batch Acc: 84.38
[Train] Epoch: 2 [257792/387873]    Loss: 0.002262   Batch Acc: 86.72
[Train] Epoch: 2 [257920/387873]    Loss: 0.001804   Batch Acc: 91.41
[Train] Epoch: 2 [258048/387873]    Loss: 0.001563   Batch Acc: 90.62
[Train] Epoch: 2 [258176/387873]    Loss: 0.002485   Batch Acc: 85.94
[Train] Epoch: 2 [258304/387873]    Loss: 0.001990   Batch Acc: 90.62
[Train] Epoch: 2 [258432/387873]    Loss: 0.001955   Batch Acc: 91.41
[Train] Epoch: 2 [258560/387873]    Loss: 0.001477   Batch Acc: 96.09
[Train] Epoch: 2 [258688/387873]    Loss: 0.001432   Batch Acc: 95.31
[Train] Epoch: 2 [258816/387873]    Loss: 0.001704   Batch Acc: 92.97
[Train] Epoch: 2 [258944/387873]    Loss: 0.002201   Batch Acc: 87.50
[Train] Epoch: 2 [259072/387873]    Loss: 0.001931   Batch Acc: 89.06
[Train] Epoch: 2 [259200/387873]    Loss: 0.002383   Batch Acc: 86.72
[Train] Epoch: 2 [259328/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 2 [259456/387873]    Loss: 0.002341   Batch Acc: 89.06
[Train] Epoch: 2 [259584/387873]    Loss: 0.002309   Batch Acc: 87.50
[Train] Epoch: 2 [259712/387873]    Loss: 0.001775   Batch Acc: 89.84
[Train] Epoch: 2 [259840/387873]    Loss: 0.002020   Batch Acc: 89.06
[Train] Epoch: 2 [259968/387873]    Loss: 0.002268   Batch Acc: 86.72
[Train] Epoch: 2 [260096/387873]    Loss: 0.001827   Batch Acc: 90.62
[Train] Epoch: 2 [260224/387873]    Loss: 0.002406   Batch Acc: 88.28
[Train] Epoch: 2 [260352/387873]    Loss: 0.001949   Batch Acc: 91.41
[Train] Epoch: 2 [260480/387873]    Loss: 0.001761   Batch Acc: 90.62
[Train] Epoch: 2 [260608/387873]    Loss: 0.001864   Batch Acc: 89.84
[Train] Epoch: 2 [260736/387873]    Loss: 0.002365   Batch Acc: 85.16
[Train] Epoch: 2 [260864/387873]    Loss: 0.002151   Batch Acc: 86.72
[Train] Epoch: 2 [260992/387873]    Loss: 0.001699   Batch Acc: 90.62
[Train] Epoch: 2 [261120/387873]    Loss: 0.002127   Batch Acc: 92.19
[Train] Epoch: 2 [261248/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 2 [261376/387873]    Loss: 0.001555   Batch Acc: 92.19
[Train] Epoch: 2 [261504/387873]    Loss: 0.001747   Batch Acc: 93.75
[Train] Epoch: 2 [261632/387873]    Loss: 0.001771   Batch Acc: 91.41
[Train] Epoch: 2 [261760/387873]    Loss: 0.001904   Batch Acc: 91.41
[Train] Epoch: 2 [261888/387873]    Loss: 0.002734   Batch Acc: 89.06
[Train] Epoch: 2 [262016/387873]    Loss: 0.001835   Batch Acc: 91.41
[Train] Epoch: 2 [262144/387873]    Loss: 0.001573   Batch Acc: 92.97
[Train] Epoch: 2 [262272/387873]    Loss: 0.002631   Batch Acc: 82.81
[Train] Epoch: 2 [262400/387873]    Loss: 0.002088   Batch Acc: 89.06
[Train] Epoch: 2 [262528/387873]    Loss: 0.002022   Batch Acc: 87.50
[Train] Epoch: 2 [262656/387873]    Loss: 0.001999   Batch Acc: 86.72
[Train] Epoch: 2 [262784/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 2 [262912/387873]    Loss: 0.002479   Batch Acc: 88.28
[Train] Epoch: 2 [263040/387873]    Loss: 0.002152   Batch Acc: 89.06
[Train] Epoch: 2 [263168/387873]    Loss: 0.002117   Batch Acc: 90.62
[Train] Epoch: 2 [263296/387873]    Loss: 0.001749   Batch Acc: 92.19
[Train] Epoch: 2 [263424/387873]    Loss: 0.001975   Batch Acc: 89.06
[Train] Epoch: 2 [263552/387873]    Loss: 0.001666   Batch Acc: 91.41
[Train] Epoch: 2 [263680/387873]    Loss: 0.002332   Batch Acc: 84.38
[Train] Epoch: 2 [263808/387873]    Loss: 0.001982   Batch Acc: 89.06
[Train] Epoch: 2 [263936/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 2 [264064/387873]    Loss: 0.001246   Batch Acc: 95.31
[Train] Epoch: 2 [264192/387873]    Loss: 0.002373   Batch Acc: 87.50
[Train] Epoch: 2 [264320/387873]    Loss: 0.002416   Batch Acc: 85.94
[Train] Epoch: 2 [264448/387873]    Loss: 0.002160   Batch Acc: 86.72
[Train] Epoch: 2 [264576/387873]    Loss: 0.001683   Batch Acc: 90.62
[Train] Epoch: 2 [264704/387873]    Loss: 0.002629   Batch Acc: 88.28
[Train] Epoch: 2 [264832/387873]    Loss: 0.001609   Batch Acc: 92.97
[Train] Epoch: 2 [264960/387873]    Loss: 0.002010   Batch Acc: 91.41
[Train] Epoch: 2 [265088/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 2 [265216/387873]    Loss: 0.002058   Batch Acc: 88.28
[Train] Epoch: 2 [265344/387873]    Loss: 0.002173   Batch Acc: 87.50
[Train] Epoch: 2 [265472/387873]    Loss: 0.001412   Batch Acc: 92.97
[Train] Epoch: 2 [265600/387873]    Loss: 0.001252   Batch Acc: 94.53
[Train] Epoch: 2 [265728/387873]    Loss: 0.002488   Batch Acc: 83.59
[Train] Epoch: 2 [265856/387873]    Loss: 0.002235   Batch Acc: 87.50
[Train] Epoch: 2 [265984/387873]    Loss: 0.002273   Batch Acc: 88.28
[Train] Epoch: 2 [266112/387873]    Loss: 0.002965   Batch Acc: 82.81
[Train] Epoch: 2 [266240/387873]    Loss: 0.001927   Batch Acc: 91.41
[Train] Epoch: 2 [266368/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 2 [266496/387873]    Loss: 0.002085   Batch Acc: 88.28
[Train] Epoch: 2 [266624/387873]    Loss: 0.001822   Batch Acc: 87.50
[Train] Epoch: 2 [266752/387873]    Loss: 0.001922   Batch Acc: 92.19
[Train] Epoch: 2 [266880/387873]    Loss: 0.001826   Batch Acc: 90.62
[Train] Epoch: 2 [267008/387873]    Loss: 0.002489   Batch Acc: 84.38
[Train] Epoch: 2 [267136/387873]    Loss: 0.002327   Batch Acc: 86.72
[Train] Epoch: 2 [267264/387873]    Loss: 0.001856   Batch Acc: 87.50
[Train] Epoch: 2 [267392/387873]    Loss: 0.001913   Batch Acc: 89.84
[Train] Epoch: 2 [267520/387873]    Loss: 0.001661   Batch Acc: 91.41
[Train] Epoch: 2 [267648/387873]    Loss: 0.001754   Batch Acc: 89.84
[Train] Epoch: 2 [267776/387873]    Loss: 0.002427   Batch Acc: 87.50
[Train] Epoch: 2 [267904/387873]    Loss: 0.002222   Batch Acc: 86.72
[Train] Epoch: 2 [268032/387873]    Loss: 0.002000   Batch Acc: 90.62
[Train] Epoch: 2 [268160/387873]    Loss: 0.001977   Batch Acc: 92.19
[Train] Epoch: 2 [268288/387873]    Loss: 0.001350   Batch Acc: 92.97
[Train] Epoch: 2 [268416/387873]    Loss: 0.001710   Batch Acc: 91.41
[Train] Epoch: 2 [268544/387873]    Loss: 0.001756   Batch Acc: 90.62
[Train] Epoch: 2 [268672/387873]    Loss: 0.002045   Batch Acc: 86.72
[Train] Epoch: 2 [268800/387873]    Loss: 0.001959   Batch Acc: 89.06
[Train] Epoch: 2 [268928/387873]    Loss: 0.001394   Batch Acc: 94.53
[Train] Epoch: 2 [269056/387873]    Loss: 0.001723   Batch Acc: 92.19
[Train] Epoch: 2 [269184/387873]    Loss: 0.002283   Batch Acc: 87.50
[Train] Epoch: 2 [269312/387873]    Loss: 0.002358   Batch Acc: 89.06
[Train] Epoch: 2 [269440/387873]    Loss: 0.002859   Batch Acc: 82.81
[Train] Epoch: 2 [269568/387873]    Loss: 0.001359   Batch Acc: 95.31
[Train] Epoch: 2 [269696/387873]    Loss: 0.001826   Batch Acc: 90.62
[Train] Epoch: 2 [269824/387873]    Loss: 0.002304   Batch Acc: 86.72
[Train] Epoch: 2 [269952/387873]    Loss: 0.001909   Batch Acc: 89.84
[Train] Epoch: 2 [270080/387873]    Loss: 0.002052   Batch Acc: 86.72
[Train] Epoch: 2 [270208/387873]    Loss: 0.002091   Batch Acc: 87.50
[Train] Epoch: 2 [270336/387873]    Loss: 0.002402   Batch Acc: 86.72
[Train] Epoch: 2 [270464/387873]    Loss: 0.001750   Batch Acc: 89.84
[Train] Epoch: 2 [270592/387873]    Loss: 0.002204   Batch Acc: 86.72
[Train] Epoch: 2 [270720/387873]    Loss: 0.002138   Batch Acc: 88.28
[Train] Epoch: 2 [270848/387873]    Loss: 0.001469   Batch Acc: 92.97
[Train] Epoch: 2 [270976/387873]    Loss: 0.002690   Batch Acc: 84.38
[Train] Epoch: 2 [271104/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 2 [271232/387873]    Loss: 0.001902   Batch Acc: 90.62
[Train] Epoch: 2 [271360/387873]    Loss: 0.002146   Batch Acc: 86.72
[Train] Epoch: 2 [271488/387873]    Loss: 0.001758   Batch Acc: 92.97
[Train] Epoch: 2 [271616/387873]    Loss: 0.002292   Batch Acc: 85.94
[Train] Epoch: 2 [271744/387873]    Loss: 0.002217   Batch Acc: 85.94
[Train] Epoch: 2 [271872/387873]    Loss: 0.001917   Batch Acc: 89.06
[Train] Epoch: 2 [272000/387873]    Loss: 0.002000   Batch Acc: 89.84
[Train] Epoch: 2 [272128/387873]    Loss: 0.001884   Batch Acc: 89.06
[Train] Epoch: 2 [272256/387873]    Loss: 0.002149   Batch Acc: 88.28
[Train] Epoch: 2 [272384/387873]    Loss: 0.001706   Batch Acc: 92.19
[Train] Epoch: 2 [272512/387873]    Loss: 0.001503   Batch Acc: 92.97
[Train] Epoch: 2 [272640/387873]    Loss: 0.001543   Batch Acc: 94.53
[Train] Epoch: 2 [272768/387873]    Loss: 0.001734   Batch Acc: 92.97
[Train] Epoch: 2 [272896/387873]    Loss: 0.002365   Batch Acc: 87.50
[Train] Epoch: 2 [273024/387873]    Loss: 0.002353   Batch Acc: 85.94
[Train] Epoch: 2 [273152/387873]    Loss: 0.002243   Batch Acc: 86.72
[Train] Epoch: 2 [273280/387873]    Loss: 0.001645   Batch Acc: 91.41
[Train] Epoch: 2 [273408/387873]    Loss: 0.001847   Batch Acc: 91.41
[Train] Epoch: 2 [273536/387873]    Loss: 0.002038   Batch Acc: 87.50
[Train] Epoch: 2 [273664/387873]    Loss: 0.001664   Batch Acc: 93.75
[Train] Epoch: 2 [273792/387873]    Loss: 0.001795   Batch Acc: 89.06
[Train] Epoch: 2 [273920/387873]    Loss: 0.002182   Batch Acc: 90.62
[Train] Epoch: 2 [274048/387873]    Loss: 0.001745   Batch Acc: 92.97
[Train] Epoch: 2 [274176/387873]    Loss: 0.001816   Batch Acc: 91.41
[Train] Epoch: 2 [274304/387873]    Loss: 0.002320   Batch Acc: 89.06
[Train] Epoch: 2 [274432/387873]    Loss: 0.002830   Batch Acc: 83.59
[Train] Epoch: 2 [274560/387873]    Loss: 0.002232   Batch Acc: 89.84
[Train] Epoch: 2 [274688/387873]    Loss: 0.002974   Batch Acc: 83.59
[Train] Epoch: 2 [274816/387873]    Loss: 0.002301   Batch Acc: 86.72
[Train] Epoch: 2 [274944/387873]    Loss: 0.001811   Batch Acc: 90.62
[Train] Epoch: 2 [275072/387873]    Loss: 0.002011   Batch Acc: 89.84
[Train] Epoch: 2 [275200/387873]    Loss: 0.002172   Batch Acc: 87.50
[Train] Epoch: 2 [275328/387873]    Loss: 0.001779   Batch Acc: 92.19
[Train] Epoch: 2 [275456/387873]    Loss: 0.002003   Batch Acc: 89.06
[Train] Epoch: 2 [275584/387873]    Loss: 0.002443   Batch Acc: 85.16
[Train] Epoch: 2 [275712/387873]    Loss: 0.001695   Batch Acc: 92.97
[Train] Epoch: 2 [275840/387873]    Loss: 0.002632   Batch Acc: 86.72
[Train] Epoch: 2 [275968/387873]    Loss: 0.001889   Batch Acc: 90.62
[Train] Epoch: 2 [276096/387873]    Loss: 0.001856   Batch Acc: 91.41
[Train] Epoch: 2 [276224/387873]    Loss: 0.002254   Batch Acc: 85.94
[Train] Epoch: 2 [276352/387873]    Loss: 0.001880   Batch Acc: 91.41
[Train] Epoch: 2 [276480/387873]    Loss: 0.002547   Batch Acc: 84.38
[Train] Epoch: 2 [276608/387873]    Loss: 0.001953   Batch Acc: 88.28
[Train] Epoch: 2 [276736/387873]    Loss: 0.002038   Batch Acc: 86.72
[Train] Epoch: 2 [276864/387873]    Loss: 0.002186   Batch Acc: 88.28
[Train] Epoch: 2 [276992/387873]    Loss: 0.002040   Batch Acc: 89.06
[Train] Epoch: 2 [277120/387873]    Loss: 0.002117   Batch Acc: 87.50
[Train] Epoch: 2 [277248/387873]    Loss: 0.001719   Batch Acc: 92.19
[Train] Epoch: 2 [277376/387873]    Loss: 0.001743   Batch Acc: 90.62
[Train] Epoch: 2 [277504/387873]    Loss: 0.001589   Batch Acc: 94.53
[Train] Epoch: 2 [277632/387873]    Loss: 0.001945   Batch Acc: 91.41
[Train] Epoch: 2 [277760/387873]    Loss: 0.002362   Batch Acc: 87.50
[Train] Epoch: 2 [277888/387873]    Loss: 0.002001   Batch Acc: 89.84
[Train] Epoch: 2 [278016/387873]    Loss: 0.001204   Batch Acc: 95.31
[Train] Epoch: 2 [278144/387873]    Loss: 0.002289   Batch Acc: 88.28
[Train] Epoch: 2 [278272/387873]    Loss: 0.001989   Batch Acc: 90.62
[Train] Epoch: 2 [278400/387873]    Loss: 0.002204   Batch Acc: 89.84
[Train] Epoch: 2 [278528/387873]    Loss: 0.001758   Batch Acc: 89.84
[Train] Epoch: 2 [278656/387873]    Loss: 0.002179   Batch Acc: 85.94
[Train] Epoch: 2 [278784/387873]    Loss: 0.001953   Batch Acc: 89.84
[Train] Epoch: 2 [278912/387873]    Loss: 0.003232   Batch Acc: 80.47
[Train] Epoch: 2 [279040/387873]    Loss: 0.001206   Batch Acc: 96.09
[Train] Epoch: 2 [279168/387873]    Loss: 0.001880   Batch Acc: 89.84
[Train] Epoch: 2 [279296/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 2 [279424/387873]    Loss: 0.002079   Batch Acc: 88.28
[Train] Epoch: 2 [279552/387873]    Loss: 0.001716   Batch Acc: 91.41
[Train] Epoch: 2 [279680/387873]    Loss: 0.001820   Batch Acc: 92.19
[Train] Epoch: 2 [279808/387873]    Loss: 0.002043   Batch Acc: 91.41
[Train] Epoch: 2 [279936/387873]    Loss: 0.002432   Batch Acc: 82.81
[Train] Epoch: 2 [280064/387873]    Loss: 0.002231   Batch Acc: 87.50
[Train] Epoch: 2 [280192/387873]    Loss: 0.001964   Batch Acc: 92.19
[Train] Epoch: 2 [280320/387873]    Loss: 0.002054   Batch Acc: 88.28
[Train] Epoch: 2 [280448/387873]    Loss: 0.001939   Batch Acc: 89.06
[Train] Epoch: 2 [280576/387873]    Loss: 0.002058   Batch Acc: 89.84
[Train] Epoch: 2 [280704/387873]    Loss: 0.001807   Batch Acc: 92.19
[Train] Epoch: 2 [280832/387873]    Loss: 0.001939   Batch Acc: 89.84
[Train] Epoch: 2 [280960/387873]    Loss: 0.002298   Batch Acc: 87.50
[Train] Epoch: 2 [281088/387873]    Loss: 0.002417   Batch Acc: 89.06
[Train] Epoch: 2 [281216/387873]    Loss: 0.001768   Batch Acc: 92.19
[Train] Epoch: 2 [281344/387873]    Loss: 0.002531   Batch Acc: 82.81
[Train] Epoch: 2 [281472/387873]    Loss: 0.001741   Batch Acc: 92.19
[Train] Epoch: 2 [281600/387873]    Loss: 0.001874   Batch Acc: 91.41
[Train] Epoch: 2 [281728/387873]    Loss: 0.002118   Batch Acc: 89.06
[Train] Epoch: 2 [281856/387873]    Loss: 0.001957   Batch Acc: 90.62
[Train] Epoch: 2 [281984/387873]    Loss: 0.002317   Batch Acc: 86.72
[Train] Epoch: 2 [282112/387873]    Loss: 0.001475   Batch Acc: 95.31
[Train] Epoch: 2 [282240/387873]    Loss: 0.002045   Batch Acc: 86.72
[Train] Epoch: 2 [282368/387873]    Loss: 0.001856   Batch Acc: 91.41
[Train] Epoch: 2 [282496/387873]    Loss: 0.001734   Batch Acc: 89.84
[Train] Epoch: 2 [282624/387873]    Loss: 0.002280   Batch Acc: 87.50
[Train] Epoch: 2 [282752/387873]    Loss: 0.001861   Batch Acc: 92.97
[Train] Epoch: 2 [282880/387873]    Loss: 0.002173   Batch Acc: 89.06
[Train] Epoch: 2 [283008/387873]    Loss: 0.002332   Batch Acc: 85.16
[Train] Epoch: 2 [283136/387873]    Loss: 0.002033   Batch Acc: 89.84
[Train] Epoch: 2 [283264/387873]    Loss: 0.002201   Batch Acc: 86.72
[Train] Epoch: 2 [283392/387873]    Loss: 0.001856   Batch Acc: 92.97
[Train] Epoch: 2 [283520/387873]    Loss: 0.002175   Batch Acc: 89.06
[Train] Epoch: 2 [283648/387873]    Loss: 0.002167   Batch Acc: 88.28
[Train] Epoch: 2 [283776/387873]    Loss: 0.002260   Batch Acc: 85.94
[Train] Epoch: 2 [283904/387873]    Loss: 0.001734   Batch Acc: 92.97
[Train] Epoch: 2 [284032/387873]    Loss: 0.001971   Batch Acc: 88.28
[Train] Epoch: 2 [284160/387873]    Loss: 0.002219   Batch Acc: 87.50
[Train] Epoch: 2 [284288/387873]    Loss: 0.001713   Batch Acc: 89.84
[Train] Epoch: 2 [284416/387873]    Loss: 0.002209   Batch Acc: 90.62
[Train] Epoch: 2 [284544/387873]    Loss: 0.002206   Batch Acc: 85.94
[Train] Epoch: 2 [284672/387873]    Loss: 0.001404   Batch Acc: 96.09
[Train] Epoch: 2 [284800/387873]    Loss: 0.001934   Batch Acc: 87.50
[Train] Epoch: 2 [284928/387873]    Loss: 0.002135   Batch Acc: 88.28
[Train] Epoch: 2 [285056/387873]    Loss: 0.001974   Batch Acc: 90.62
[Train] Epoch: 2 [285184/387873]    Loss: 0.001972   Batch Acc: 91.41
[Train] Epoch: 2 [285312/387873]    Loss: 0.002104   Batch Acc: 87.50
[Train] Epoch: 2 [285440/387873]    Loss: 0.001777   Batch Acc: 92.19
[Train] Epoch: 2 [285568/387873]    Loss: 0.002005   Batch Acc: 89.06
[Train] Epoch: 2 [285696/387873]    Loss: 0.001937   Batch Acc: 89.84
[Train] Epoch: 2 [285824/387873]    Loss: 0.002076   Batch Acc: 88.28
[Train] Epoch: 2 [285952/387873]    Loss: 0.001590   Batch Acc: 92.97
[Train] Epoch: 2 [286080/387873]    Loss: 0.002082   Batch Acc: 87.50
[Train] Epoch: 2 [286208/387873]    Loss: 0.001684   Batch Acc: 90.62
[Train] Epoch: 2 [286336/387873]    Loss: 0.002017   Batch Acc: 90.62
[Train] Epoch: 2 [286464/387873]    Loss: 0.001973   Batch Acc: 88.28
[Train] Epoch: 2 [286592/387873]    Loss: 0.001592   Batch Acc: 90.62
[Train] Epoch: 2 [286720/387873]    Loss: 0.001189   Batch Acc: 95.31
[Train] Epoch: 2 [286848/387873]    Loss: 0.001851   Batch Acc: 90.62
[Train] Epoch: 2 [286976/387873]    Loss: 0.001890   Batch Acc: 90.62
[Train] Epoch: 2 [287104/387873]    Loss: 0.001704   Batch Acc: 92.97
[Train] Epoch: 2 [287232/387873]    Loss: 0.002133   Batch Acc: 85.94
[Train] Epoch: 2 [287360/387873]    Loss: 0.002078   Batch Acc: 89.84
[Train] Epoch: 2 [287488/387873]    Loss: 0.001922   Batch Acc: 86.72
[Train] Epoch: 2 [287616/387873]    Loss: 0.001600   Batch Acc: 92.19
[Train] Epoch: 2 [287744/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 2 [287872/387873]    Loss: 0.001883   Batch Acc: 90.62
[Train] Epoch: 2 [288000/387873]    Loss: 0.002062   Batch Acc: 90.62
[Train] Epoch: 2 [288128/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 2 [288256/387873]    Loss: 0.001856   Batch Acc: 85.16
[Train] Epoch: 2 [288384/387873]    Loss: 0.001936   Batch Acc: 92.97
[Train] Epoch: 2 [288512/387873]    Loss: 0.002181   Batch Acc: 89.84
[Train] Epoch: 2 [288640/387873]    Loss: 0.002369   Batch Acc: 85.16
[Train] Epoch: 2 [288768/387873]    Loss: 0.002250   Batch Acc: 87.50
[Train] Epoch: 2 [288896/387873]    Loss: 0.002252   Batch Acc: 85.94
[Train] Epoch: 2 [289024/387873]    Loss: 0.002081   Batch Acc: 89.06
[Train] Epoch: 2 [289152/387873]    Loss: 0.002287   Batch Acc: 85.94
[Train] Epoch: 2 [289280/387873]    Loss: 0.002319   Batch Acc: 89.84
[Train] Epoch: 2 [289408/387873]    Loss: 0.001954   Batch Acc: 89.84
[Train] Epoch: 2 [289536/387873]    Loss: 0.001808   Batch Acc: 90.62
[Train] Epoch: 2 [289664/387873]    Loss: 0.001884   Batch Acc: 89.06
[Train] Epoch: 2 [289792/387873]    Loss: 0.001532   Batch Acc: 92.97
[Train] Epoch: 2 [289920/387873]    Loss: 0.002053   Batch Acc: 87.50
[Train] Epoch: 2 [290048/387873]    Loss: 0.001758   Batch Acc: 92.19
[Train] Epoch: 2 [290176/387873]    Loss: 0.003069   Batch Acc: 84.38
[Train] Epoch: 2 [290304/387873]    Loss: 0.002200   Batch Acc: 87.50
[Train] Epoch: 2 [290432/387873]    Loss: 0.002171   Batch Acc: 88.28
[Train] Epoch: 2 [290560/387873]    Loss: 0.002131   Batch Acc: 86.72
[Train] Epoch: 2 [290688/387873]    Loss: 0.001917   Batch Acc: 87.50
[Train] Epoch: 2 [290816/387873]    Loss: 0.001799   Batch Acc: 92.19
[Train] Epoch: 2 [290944/387873]    Loss: 0.002213   Batch Acc: 87.50
[Train] Epoch: 2 [291072/387873]    Loss: 0.001708   Batch Acc: 91.41
[Train] Epoch: 2 [291200/387873]    Loss: 0.001950   Batch Acc: 89.06
[Train] Epoch: 2 [291328/387873]    Loss: 0.002276   Batch Acc: 85.94
[Train] Epoch: 2 [291456/387873]    Loss: 0.002001   Batch Acc: 89.06
[Train] Epoch: 2 [291584/387873]    Loss: 0.001683   Batch Acc: 92.19
[Train] Epoch: 2 [291712/387873]    Loss: 0.001805   Batch Acc: 91.41
[Train] Epoch: 2 [291840/387873]    Loss: 0.001867   Batch Acc: 89.06
[Train] Epoch: 2 [291968/387873]    Loss: 0.001850   Batch Acc: 89.84
[Train] Epoch: 2 [292096/387873]    Loss: 0.002173   Batch Acc: 90.62
[Train] Epoch: 2 [292224/387873]    Loss: 0.002547   Batch Acc: 86.72
[Train] Epoch: 2 [292352/387873]    Loss: 0.002755   Batch Acc: 84.38
[Train] Epoch: 2 [292480/387873]    Loss: 0.002198   Batch Acc: 88.28
[Train] Epoch: 2 [292608/387873]    Loss: 0.001729   Batch Acc: 92.19
[Train] Epoch: 2 [292736/387873]    Loss: 0.001914   Batch Acc: 88.28
[Train] Epoch: 2 [292864/387873]    Loss: 0.001488   Batch Acc: 94.53
[Train] Epoch: 2 [292992/387873]    Loss: 0.002043   Batch Acc: 88.28
[Train] Epoch: 2 [293120/387873]    Loss: 0.001906   Batch Acc: 88.28
[Train] Epoch: 2 [293248/387873]    Loss: 0.001566   Batch Acc: 94.53
[Train] Epoch: 2 [293376/387873]    Loss: 0.001739   Batch Acc: 92.97
[Train] Epoch: 2 [293504/387873]    Loss: 0.002182   Batch Acc: 90.62
[Train] Epoch: 2 [293632/387873]    Loss: 0.001901   Batch Acc: 89.84
[Train] Epoch: 2 [293760/387873]    Loss: 0.002257   Batch Acc: 88.28
[Train] Epoch: 2 [293888/387873]    Loss: 0.002753   Batch Acc: 88.28
[Train] Epoch: 2 [294016/387873]    Loss: 0.001911   Batch Acc: 87.50
[Train] Epoch: 2 [294144/387873]    Loss: 0.001905   Batch Acc: 92.97
[Train] Epoch: 2 [294272/387873]    Loss: 0.002385   Batch Acc: 86.72
[Train] Epoch: 2 [294400/387873]    Loss: 0.002214   Batch Acc: 87.50
[Train] Epoch: 2 [294528/387873]    Loss: 0.001770   Batch Acc: 89.84
[Train] Epoch: 2 [294656/387873]    Loss: 0.002037   Batch Acc: 91.41
[Train] Epoch: 2 [294784/387873]    Loss: 0.002108   Batch Acc: 89.06
[Train] Epoch: 2 [294912/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 2 [295040/387873]    Loss: 0.001959   Batch Acc: 90.62
[Train] Epoch: 2 [295168/387873]    Loss: 0.001544   Batch Acc: 93.75
[Train] Epoch: 2 [295296/387873]    Loss: 0.002382   Batch Acc: 88.28
[Train] Epoch: 2 [295424/387873]    Loss: 0.001801   Batch Acc: 90.62
[Train] Epoch: 2 [295552/387873]    Loss: 0.002398   Batch Acc: 88.28
[Train] Epoch: 2 [295680/387873]    Loss: 0.001931   Batch Acc: 86.72
[Train] Epoch: 2 [295808/387873]    Loss: 0.002100   Batch Acc: 90.62
[Train] Epoch: 2 [295936/387873]    Loss: 0.002060   Batch Acc: 90.62
[Train] Epoch: 2 [296064/387873]    Loss: 0.001459   Batch Acc: 95.31
[Train] Epoch: 2 [296192/387873]    Loss: 0.001991   Batch Acc: 87.50
[Train] Epoch: 2 [296320/387873]    Loss: 0.001981   Batch Acc: 89.06
[Train] Epoch: 2 [296448/387873]    Loss: 0.001826   Batch Acc: 89.06
[Train] Epoch: 2 [296576/387873]    Loss: 0.002837   Batch Acc: 83.59
[Train] Epoch: 2 [296704/387873]    Loss: 0.002206   Batch Acc: 88.28
[Train] Epoch: 2 [296832/387873]    Loss: 0.002539   Batch Acc: 87.50
[Train] Epoch: 2 [296960/387873]    Loss: 0.002039   Batch Acc: 92.19
[Train] Epoch: 2 [297088/387873]    Loss: 0.002272   Batch Acc: 87.50
[Train] Epoch: 2 [297216/387873]    Loss: 0.001820   Batch Acc: 90.62
[Train] Epoch: 2 [297344/387873]    Loss: 0.001494   Batch Acc: 93.75
[Train] Epoch: 2 [297472/387873]    Loss: 0.001711   Batch Acc: 92.19
[Train] Epoch: 2 [297600/387873]    Loss: 0.001977   Batch Acc: 91.41
[Train] Epoch: 2 [297728/387873]    Loss: 0.002046   Batch Acc: 90.62
[Train] Epoch: 2 [297856/387873]    Loss: 0.001757   Batch Acc: 90.62
[Train] Epoch: 2 [297984/387873]    Loss: 0.002105   Batch Acc: 89.06
[Train] Epoch: 2 [298112/387873]    Loss: 0.002207   Batch Acc: 87.50
[Train] Epoch: 2 [298240/387873]    Loss: 0.001869   Batch Acc: 89.84
[Train] Epoch: 2 [298368/387873]    Loss: 0.001936   Batch Acc: 90.62
[Train] Epoch: 2 [298496/387873]    Loss: 0.002201   Batch Acc: 88.28
[Train] Epoch: 2 [298624/387873]    Loss: 0.001707   Batch Acc: 92.97
[Train] Epoch: 2 [298752/387873]    Loss: 0.002082   Batch Acc: 89.06
[Train] Epoch: 2 [298880/387873]    Loss: 0.002179   Batch Acc: 87.50
[Train] Epoch: 2 [299008/387873]    Loss: 0.002186   Batch Acc: 87.50
[Train] Epoch: 2 [299136/387873]    Loss: 0.001668   Batch Acc: 91.41
[Train] Epoch: 2 [299264/387873]    Loss: 0.001667   Batch Acc: 93.75
[Train] Epoch: 2 [299392/387873]    Loss: 0.002250   Batch Acc: 87.50
[Train] Epoch: 2 [299520/387873]    Loss: 0.001463   Batch Acc: 93.75
[Train] Epoch: 2 [299648/387873]    Loss: 0.002097   Batch Acc: 89.06
[Train] Epoch: 2 [299776/387873]    Loss: 0.002203   Batch Acc: 87.50
[Train] Epoch: 2 [299904/387873]    Loss: 0.002454   Batch Acc: 86.72
[Train] Epoch: 2 [300032/387873]    Loss: 0.001896   Batch Acc: 90.62
[Train] Epoch: 2 [300160/387873]    Loss: 0.001823   Batch Acc: 90.62
[Train] Epoch: 2 [300288/387873]    Loss: 0.002016   Batch Acc: 90.62
[Train] Epoch: 2 [300416/387873]    Loss: 0.001828   Batch Acc: 91.41
[Train] Epoch: 2 [300544/387873]    Loss: 0.003012   Batch Acc: 82.03
[Train] Epoch: 2 [300672/387873]    Loss: 0.002422   Batch Acc: 87.50
[Train] Epoch: 2 [300800/387873]    Loss: 0.001760   Batch Acc: 90.62
[Train] Epoch: 2 [300928/387873]    Loss: 0.001906   Batch Acc: 89.06
[Train] Epoch: 2 [301056/387873]    Loss: 0.002087   Batch Acc: 89.84
[Train] Epoch: 2 [301184/387873]    Loss: 0.002099   Batch Acc: 89.84
[Train] Epoch: 2 [301312/387873]    Loss: 0.002622   Batch Acc: 85.16
[Train] Epoch: 2 [301440/387873]    Loss: 0.001949   Batch Acc: 89.84
[Train] Epoch: 2 [301568/387873]    Loss: 0.001701   Batch Acc: 89.84
[Train] Epoch: 2 [301696/387873]    Loss: 0.002799   Batch Acc: 85.94
[Train] Epoch: 2 [301824/387873]    Loss: 0.002055   Batch Acc: 89.84
[Train] Epoch: 2 [301952/387873]    Loss: 0.002233   Batch Acc: 86.72
[Train] Epoch: 2 [302080/387873]    Loss: 0.001784   Batch Acc: 89.84
[Train] Epoch: 2 [302208/387873]    Loss: 0.002209   Batch Acc: 88.28
[Train] Epoch: 2 [302336/387873]    Loss: 0.002086   Batch Acc: 89.84
[Train] Epoch: 2 [302464/387873]    Loss: 0.001826   Batch Acc: 89.06
[Train] Epoch: 2 [302592/387873]    Loss: 0.002014   Batch Acc: 87.50
[Train] Epoch: 2 [302720/387873]    Loss: 0.001816   Batch Acc: 89.84
[Train] Epoch: 2 [302848/387873]    Loss: 0.002005   Batch Acc: 89.84
[Train] Epoch: 2 [302976/387873]    Loss: 0.001882   Batch Acc: 91.41
[Train] Epoch: 2 [303104/387873]    Loss: 0.002303   Batch Acc: 85.16
[Train] Epoch: 2 [303232/387873]    Loss: 0.002188   Batch Acc: 91.41
[Train] Epoch: 2 [303360/387873]    Loss: 0.001771   Batch Acc: 92.97
[Train] Epoch: 2 [303488/387873]    Loss: 0.002010   Batch Acc: 89.06
[Train] Epoch: 2 [303616/387873]    Loss: 0.001601   Batch Acc: 93.75
[Train] Epoch: 2 [303744/387873]    Loss: 0.001723   Batch Acc: 92.19
[Train] Epoch: 2 [303872/387873]    Loss: 0.002038   Batch Acc: 88.28
[Train] Epoch: 2 [304000/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 2 [304128/387873]    Loss: 0.001871   Batch Acc: 90.62
[Train] Epoch: 2 [304256/387873]    Loss: 0.002027   Batch Acc: 89.06
[Train] Epoch: 2 [304384/387873]    Loss: 0.002772   Batch Acc: 83.59
[Train] Epoch: 2 [304512/387873]    Loss: 0.001971   Batch Acc: 89.06
[Train] Epoch: 2 [304640/387873]    Loss: 0.002149   Batch Acc: 87.50
[Train] Epoch: 2 [304768/387873]    Loss: 0.002039   Batch Acc: 87.50
[Train] Epoch: 2 [304896/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 2 [305024/387873]    Loss: 0.001977   Batch Acc: 89.84
[Train] Epoch: 2 [305152/387873]    Loss: 0.002227   Batch Acc: 87.50
[Train] Epoch: 2 [305280/387873]    Loss: 0.002178   Batch Acc: 85.94
[Train] Epoch: 2 [305408/387873]    Loss: 0.002758   Batch Acc: 82.81
[Train] Epoch: 2 [305536/387873]    Loss: 0.002077   Batch Acc: 89.84
[Train] Epoch: 2 [305664/387873]    Loss: 0.001580   Batch Acc: 92.19
[Train] Epoch: 2 [305792/387873]    Loss: 0.001803   Batch Acc: 90.62
[Train] Epoch: 2 [305920/387873]    Loss: 0.001814   Batch Acc: 90.62
[Train] Epoch: 2 [306048/387873]    Loss: 0.002219   Batch Acc: 85.16
[Train] Epoch: 2 [306176/387873]    Loss: 0.001925   Batch Acc: 89.84
[Train] Epoch: 2 [306304/387873]    Loss: 0.002164   Batch Acc: 88.28
[Train] Epoch: 2 [306432/387873]    Loss: 0.001687   Batch Acc: 92.97
[Train] Epoch: 2 [306560/387873]    Loss: 0.002514   Batch Acc: 85.16
[Train] Epoch: 2 [306688/387873]    Loss: 0.002006   Batch Acc: 89.84
[Train] Epoch: 2 [306816/387873]    Loss: 0.001930   Batch Acc: 89.84
[Train] Epoch: 2 [306944/387873]    Loss: 0.002322   Batch Acc: 88.28
[Train] Epoch: 2 [307072/387873]    Loss: 0.002250   Batch Acc: 87.50
[Train] Epoch: 2 [307200/387873]    Loss: 0.001821   Batch Acc: 91.41
[Train] Epoch: 2 [307328/387873]    Loss: 0.002315   Batch Acc: 84.38
[Train] Epoch: 2 [307456/387873]    Loss: 0.001818   Batch Acc: 92.19
[Train] Epoch: 2 [307584/387873]    Loss: 0.002146   Batch Acc: 87.50
[Train] Epoch: 2 [307712/387873]    Loss: 0.001876   Batch Acc: 90.62
[Train] Epoch: 2 [307840/387873]    Loss: 0.002202   Batch Acc: 90.62
[Train] Epoch: 2 [307968/387873]    Loss: 0.001512   Batch Acc: 92.19
[Train] Epoch: 2 [308096/387873]    Loss: 0.001686   Batch Acc: 92.97
[Train] Epoch: 2 [308224/387873]    Loss: 0.001968   Batch Acc: 89.06
[Train] Epoch: 2 [308352/387873]    Loss: 0.002020   Batch Acc: 87.50
[Train] Epoch: 2 [308480/387873]    Loss: 0.002344   Batch Acc: 86.72
[Train] Epoch: 2 [308608/387873]    Loss: 0.001698   Batch Acc: 90.62
[Train] Epoch: 2 [308736/387873]    Loss: 0.001469   Batch Acc: 92.97
[Train] Epoch: 2 [308864/387873]    Loss: 0.002315   Batch Acc: 87.50
[Train] Epoch: 2 [308992/387873]    Loss: 0.001738   Batch Acc: 94.53
[Train] Epoch: 2 [309120/387873]    Loss: 0.001983   Batch Acc: 92.97
[Train] Epoch: 2 [309248/387873]    Loss: 0.002423   Batch Acc: 86.72
[Train] Epoch: 2 [309376/387873]    Loss: 0.001802   Batch Acc: 89.06
[Train] Epoch: 2 [309504/387873]    Loss: 0.002026   Batch Acc: 91.41
[Train] Epoch: 2 [309632/387873]    Loss: 0.001685   Batch Acc: 94.53
[Train] Epoch: 2 [309760/387873]    Loss: 0.002256   Batch Acc: 89.06
[Train] Epoch: 2 [309888/387873]    Loss: 0.002102   Batch Acc: 88.28
[Train] Epoch: 2 [310016/387873]    Loss: 0.002218   Batch Acc: 84.38
[Train] Epoch: 2 [310144/387873]    Loss: 0.001750   Batch Acc: 92.97
[Train] Epoch: 2 [310272/387873]    Loss: 0.001826   Batch Acc: 90.62
[Train] Epoch: 2 [310400/387873]    Loss: 0.001924   Batch Acc: 89.84
[Train] Epoch: 2 [310528/387873]    Loss: 0.002304   Batch Acc: 88.28
[Train] Epoch: 2 [310656/387873]    Loss: 0.002057   Batch Acc: 89.06
[Train] Epoch: 2 [310784/387873]    Loss: 0.002459   Batch Acc: 85.94
[Train] Epoch: 2 [310912/387873]    Loss: 0.002528   Batch Acc: 85.94
[Train] Epoch: 2 [311040/387873]    Loss: 0.002097   Batch Acc: 86.72
[Train] Epoch: 2 [311168/387873]    Loss: 0.002219   Batch Acc: 89.06
[Train] Epoch: 2 [311296/387873]    Loss: 0.002622   Batch Acc: 87.50
[Train] Epoch: 2 [311424/387873]    Loss: 0.001973   Batch Acc: 89.84
[Train] Epoch: 2 [311552/387873]    Loss: 0.001654   Batch Acc: 89.84
[Train] Epoch: 2 [311680/387873]    Loss: 0.002111   Batch Acc: 87.50
[Train] Epoch: 2 [311808/387873]    Loss: 0.001676   Batch Acc: 92.19
[Train] Epoch: 2 [311936/387873]    Loss: 0.001968   Batch Acc: 91.41
[Train] Epoch: 2 [312064/387873]    Loss: 0.001774   Batch Acc: 93.75
[Train] Epoch: 2 [312192/387873]    Loss: 0.002044   Batch Acc: 92.19
[Train] Epoch: 2 [312320/387873]    Loss: 0.001915   Batch Acc: 91.41
[Train] Epoch: 2 [312448/387873]    Loss: 0.001763   Batch Acc: 89.84
[Train] Epoch: 2 [312576/387873]    Loss: 0.001499   Batch Acc: 93.75
[Train] Epoch: 2 [312704/387873]    Loss: 0.002066   Batch Acc: 90.62
[Train] Epoch: 2 [312832/387873]    Loss: 0.002079   Batch Acc: 86.72
[Train] Epoch: 2 [312960/387873]    Loss: 0.002049   Batch Acc: 86.72
[Train] Epoch: 2 [313088/387873]    Loss: 0.001705   Batch Acc: 90.62
[Train] Epoch: 2 [313216/387873]    Loss: 0.002028   Batch Acc: 86.72
[Train] Epoch: 2 [313344/387873]    Loss: 0.001810   Batch Acc: 90.62
[Train] Epoch: 2 [313472/387873]    Loss: 0.001770   Batch Acc: 92.19
[Train] Epoch: 2 [313600/387873]    Loss: 0.001831   Batch Acc: 92.97
[Train] Epoch: 2 [313728/387873]    Loss: 0.001774   Batch Acc: 90.62
[Train] Epoch: 2 [313856/387873]    Loss: 0.001830   Batch Acc: 90.62
[Train] Epoch: 2 [313984/387873]    Loss: 0.001745   Batch Acc: 93.75
[Train] Epoch: 2 [314112/387873]    Loss: 0.001998   Batch Acc: 90.62
[Train] Epoch: 2 [314240/387873]    Loss: 0.001758   Batch Acc: 89.84
[Train] Epoch: 2 [314368/387873]    Loss: 0.001630   Batch Acc: 92.97
[Train] Epoch: 2 [314496/387873]    Loss: 0.001666   Batch Acc: 92.19
[Train] Epoch: 2 [314624/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 2 [314752/387873]    Loss: 0.002484   Batch Acc: 84.38
[Train] Epoch: 2 [314880/387873]    Loss: 0.002189   Batch Acc: 88.28
[Train] Epoch: 2 [315008/387873]    Loss: 0.001703   Batch Acc: 92.97
[Train] Epoch: 2 [315136/387873]    Loss: 0.001753   Batch Acc: 90.62
[Train] Epoch: 2 [315264/387873]    Loss: 0.001872   Batch Acc: 89.84
[Train] Epoch: 2 [315392/387873]    Loss: 0.002008   Batch Acc: 90.62
[Train] Epoch: 2 [315520/387873]    Loss: 0.001742   Batch Acc: 89.84
[Train] Epoch: 2 [315648/387873]    Loss: 0.002057   Batch Acc: 88.28
[Train] Epoch: 2 [315776/387873]    Loss: 0.002170   Batch Acc: 87.50
[Train] Epoch: 2 [315904/387873]    Loss: 0.002012   Batch Acc: 88.28
[Train] Epoch: 2 [316032/387873]    Loss: 0.002465   Batch Acc: 85.16
[Train] Epoch: 2 [316160/387873]    Loss: 0.002842   Batch Acc: 85.94
[Train] Epoch: 2 [316288/387873]    Loss: 0.002530   Batch Acc: 85.16
[Train] Epoch: 2 [316416/387873]    Loss: 0.001793   Batch Acc: 92.19
[Train] Epoch: 2 [316544/387873]    Loss: 0.002004   Batch Acc: 92.97
[Train] Epoch: 2 [316672/387873]    Loss: 0.002040   Batch Acc: 85.94
[Train] Epoch: 2 [316800/387873]    Loss: 0.002363   Batch Acc: 84.38
[Train] Epoch: 2 [316928/387873]    Loss: 0.001702   Batch Acc: 91.41
[Train] Epoch: 2 [317056/387873]    Loss: 0.001788   Batch Acc: 89.84
[Train] Epoch: 2 [317184/387873]    Loss: 0.001874   Batch Acc: 91.41
[Train] Epoch: 2 [317312/387873]    Loss: 0.002862   Batch Acc: 81.25
[Train] Epoch: 2 [317440/387873]    Loss: 0.001819   Batch Acc: 91.41
[Train] Epoch: 2 [317568/387873]    Loss: 0.002640   Batch Acc: 85.16
[Train] Epoch: 2 [317696/387873]    Loss: 0.001776   Batch Acc: 90.62
[Train] Epoch: 2 [317824/387873]    Loss: 0.002784   Batch Acc: 82.81
[Train] Epoch: 2 [317952/387873]    Loss: 0.001749   Batch Acc: 89.84
[Train] Epoch: 2 [318080/387873]    Loss: 0.001413   Batch Acc: 93.75
[Train] Epoch: 2 [318208/387873]    Loss: 0.002511   Batch Acc: 85.16
[Train] Epoch: 2 [318336/387873]    Loss: 0.002288   Batch Acc: 87.50
[Train] Epoch: 2 [318464/387873]    Loss: 0.002137   Batch Acc: 88.28
[Train] Epoch: 2 [318592/387873]    Loss: 0.002003   Batch Acc: 86.72
[Train] Epoch: 2 [318720/387873]    Loss: 0.002446   Batch Acc: 86.72
[Train] Epoch: 2 [318848/387873]    Loss: 0.001393   Batch Acc: 96.09
[Train] Epoch: 2 [318976/387873]    Loss: 0.002119   Batch Acc: 89.06
[Train] Epoch: 2 [319104/387873]    Loss: 0.001832   Batch Acc: 89.84
[Train] Epoch: 2 [319232/387873]    Loss: 0.002076   Batch Acc: 90.62
[Train] Epoch: 2 [319360/387873]    Loss: 0.002270   Batch Acc: 89.06
[Train] Epoch: 2 [319488/387873]    Loss: 0.001565   Batch Acc: 93.75
[Train] Epoch: 2 [319616/387873]    Loss: 0.001994   Batch Acc: 89.84
[Train] Epoch: 2 [319744/387873]    Loss: 0.002014   Batch Acc: 89.06
[Train] Epoch: 2 [319872/387873]    Loss: 0.001918   Batch Acc: 87.50
[Train] Epoch: 2 [320000/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 2 [320128/387873]    Loss: 0.002191   Batch Acc: 91.41
[Train] Epoch: 2 [320256/387873]    Loss: 0.001609   Batch Acc: 92.97
[Train] Epoch: 2 [320384/387873]    Loss: 0.002193   Batch Acc: 88.28
[Train] Epoch: 2 [320512/387873]    Loss: 0.002062   Batch Acc: 90.62
[Train] Epoch: 2 [320640/387873]    Loss: 0.002341   Batch Acc: 85.94
[Train] Epoch: 2 [320768/387873]    Loss: 0.002397   Batch Acc: 89.06
[Train] Epoch: 2 [320896/387873]    Loss: 0.002070   Batch Acc: 87.50
[Train] Epoch: 2 [321024/387873]    Loss: 0.002258   Batch Acc: 89.84
[Train] Epoch: 2 [321152/387873]    Loss: 0.001636   Batch Acc: 92.19
[Train] Epoch: 2 [321280/387873]    Loss: 0.001686   Batch Acc: 93.75
[Train] Epoch: 2 [321408/387873]    Loss: 0.002029   Batch Acc: 87.50
[Train] Epoch: 2 [321536/387873]    Loss: 0.002360   Batch Acc: 88.28
[Train] Epoch: 2 [321664/387873]    Loss: 0.001879   Batch Acc: 89.06
[Train] Epoch: 2 [321792/387873]    Loss: 0.002135   Batch Acc: 89.84
[Train] Epoch: 2 [321920/387873]    Loss: 0.002055   Batch Acc: 89.84
[Train] Epoch: 2 [322048/387873]    Loss: 0.002404   Batch Acc: 85.16
[Train] Epoch: 2 [322176/387873]    Loss: 0.002046   Batch Acc: 88.28
[Train] Epoch: 2 [322304/387873]    Loss: 0.002285   Batch Acc: 87.50
[Train] Epoch: 2 [322432/387873]    Loss: 0.001878   Batch Acc: 87.50
[Train] Epoch: 2 [322560/387873]    Loss: 0.001902   Batch Acc: 90.62
[Train] Epoch: 2 [322688/387873]    Loss: 0.002486   Batch Acc: 83.59
[Train] Epoch: 2 [322816/387873]    Loss: 0.001705   Batch Acc: 92.19
[Train] Epoch: 2 [322944/387873]    Loss: 0.002040   Batch Acc: 89.84
[Train] Epoch: 2 [323072/387873]    Loss: 0.002734   Batch Acc: 84.38
[Train] Epoch: 2 [323200/387873]    Loss: 0.001907   Batch Acc: 89.06
[Train] Epoch: 2 [323328/387873]    Loss: 0.002145   Batch Acc: 90.62
[Train] Epoch: 2 [323456/387873]    Loss: 0.001743   Batch Acc: 89.06
[Train] Epoch: 2 [323584/387873]    Loss: 0.001997   Batch Acc: 89.06
[Train] Epoch: 2 [323712/387873]    Loss: 0.001995   Batch Acc: 89.84
[Train] Epoch: 2 [323840/387873]    Loss: 0.001936   Batch Acc: 92.19
[Train] Epoch: 2 [323968/387873]    Loss: 0.001999   Batch Acc: 90.62
[Train] Epoch: 2 [324096/387873]    Loss: 0.002539   Batch Acc: 89.84
[Train] Epoch: 2 [324224/387873]    Loss: 0.002013   Batch Acc: 88.28
[Train] Epoch: 2 [324352/387873]    Loss: 0.001859   Batch Acc: 89.06
[Train] Epoch: 2 [324480/387873]    Loss: 0.002017   Batch Acc: 90.62
[Train] Epoch: 2 [324608/387873]    Loss: 0.002526   Batch Acc: 87.50
[Train] Epoch: 2 [324736/387873]    Loss: 0.001924   Batch Acc: 90.62
[Train] Epoch: 2 [324864/387873]    Loss: 0.001762   Batch Acc: 88.28
[Train] Epoch: 2 [324992/387873]    Loss: 0.002386   Batch Acc: 87.50
[Train] Epoch: 2 [325120/387873]    Loss: 0.001671   Batch Acc: 90.62
[Train] Epoch: 2 [325248/387873]    Loss: 0.002288   Batch Acc: 87.50
[Train] Epoch: 2 [325376/387873]    Loss: 0.002607   Batch Acc: 85.16
[Train] Epoch: 2 [325504/387873]    Loss: 0.002589   Batch Acc: 86.72
[Train] Epoch: 2 [325632/387873]    Loss: 0.002292   Batch Acc: 84.38
[Train] Epoch: 2 [325760/387873]    Loss: 0.002489   Batch Acc: 85.16
[Train] Epoch: 2 [325888/387873]    Loss: 0.002308   Batch Acc: 89.06
[Train] Epoch: 2 [326016/387873]    Loss: 0.001526   Batch Acc: 92.97
[Train] Epoch: 2 [326144/387873]    Loss: 0.002200   Batch Acc: 86.72
[Train] Epoch: 2 [326272/387873]    Loss: 0.001750   Batch Acc: 93.75
[Train] Epoch: 2 [326400/387873]    Loss: 0.002209   Batch Acc: 89.84
[Train] Epoch: 2 [326528/387873]    Loss: 0.002020   Batch Acc: 91.41
[Train] Epoch: 2 [326656/387873]    Loss: 0.002337   Batch Acc: 89.06
[Train] Epoch: 2 [326784/387873]    Loss: 0.001991   Batch Acc: 88.28
[Train] Epoch: 2 [326912/387873]    Loss: 0.002027   Batch Acc: 89.84
[Train] Epoch: 2 [327040/387873]    Loss: 0.001890   Batch Acc: 86.72
[Train] Epoch: 2 [327168/387873]    Loss: 0.001762   Batch Acc: 92.19
[Train] Epoch: 2 [327296/387873]    Loss: 0.001937   Batch Acc: 89.06
[Train] Epoch: 2 [327424/387873]    Loss: 0.002553   Batch Acc: 83.59
[Train] Epoch: 2 [327552/387873]    Loss: 0.002215   Batch Acc: 88.28
[Train] Epoch: 2 [327680/387873]    Loss: 0.002163   Batch Acc: 89.06
[Train] Epoch: 2 [327808/387873]    Loss: 0.001884   Batch Acc: 89.84
[Train] Epoch: 2 [327936/387873]    Loss: 0.001886   Batch Acc: 87.50
[Train] Epoch: 2 [328064/387873]    Loss: 0.002079   Batch Acc: 89.06
[Train] Epoch: 2 [328192/387873]    Loss: 0.002171   Batch Acc: 88.28
[Train] Epoch: 2 [328320/387873]    Loss: 0.002047   Batch Acc: 86.72
[Train] Epoch: 2 [328448/387873]    Loss: 0.001850   Batch Acc: 89.06
[Train] Epoch: 2 [328576/387873]    Loss: 0.002142   Batch Acc: 85.94
[Train] Epoch: 2 [328704/387873]    Loss: 0.001909   Batch Acc: 89.84
[Train] Epoch: 2 [328832/387873]    Loss: 0.002284   Batch Acc: 88.28
[Train] Epoch: 2 [328960/387873]    Loss: 0.001280   Batch Acc: 92.97
[Train] Epoch: 2 [329088/387873]    Loss: 0.001671   Batch Acc: 92.97
[Train] Epoch: 2 [329216/387873]    Loss: 0.001679   Batch Acc: 95.31
[Train] Epoch: 2 [329344/387873]    Loss: 0.002109   Batch Acc: 86.72
[Train] Epoch: 2 [329472/387873]    Loss: 0.001774   Batch Acc: 92.19
[Train] Epoch: 2 [329600/387873]    Loss: 0.001523   Batch Acc: 90.62
[Train] Epoch: 2 [329728/387873]    Loss: 0.002346   Batch Acc: 87.50
[Train] Epoch: 2 [329856/387873]    Loss: 0.001890   Batch Acc: 91.41
[Train] Epoch: 2 [329984/387873]    Loss: 0.002111   Batch Acc: 87.50
[Train] Epoch: 2 [330112/387873]    Loss: 0.002038   Batch Acc: 87.50
[Train] Epoch: 2 [330240/387873]    Loss: 0.002025   Batch Acc: 87.50
[Train] Epoch: 2 [330368/387873]    Loss: 0.001371   Batch Acc: 96.09
[Train] Epoch: 2 [330496/387873]    Loss: 0.001574   Batch Acc: 91.41
[Train] Epoch: 2 [330624/387873]    Loss: 0.002079   Batch Acc: 86.72
[Train] Epoch: 2 [330752/387873]    Loss: 0.001638   Batch Acc: 91.41
[Train] Epoch: 2 [330880/387873]    Loss: 0.001620   Batch Acc: 92.19
[Train] Epoch: 2 [331008/387873]    Loss: 0.002203   Batch Acc: 87.50
[Train] Epoch: 2 [331136/387873]    Loss: 0.002267   Batch Acc: 86.72
[Train] Epoch: 2 [331264/387873]    Loss: 0.002018   Batch Acc: 89.84
[Train] Epoch: 2 [331392/387873]    Loss: 0.002684   Batch Acc: 84.38
[Train] Epoch: 2 [331520/387873]    Loss: 0.001669   Batch Acc: 92.97
[Train] Epoch: 2 [331648/387873]    Loss: 0.002903   Batch Acc: 82.03
[Train] Epoch: 2 [331776/387873]    Loss: 0.002136   Batch Acc: 90.62
[Train] Epoch: 2 [331904/387873]    Loss: 0.002047   Batch Acc: 89.06
[Train] Epoch: 2 [332032/387873]    Loss: 0.002470   Batch Acc: 86.72
[Train] Epoch: 2 [332160/387873]    Loss: 0.002760   Batch Acc: 83.59
[Train] Epoch: 2 [332288/387873]    Loss: 0.001644   Batch Acc: 91.41
[Train] Epoch: 2 [332416/387873]    Loss: 0.001949   Batch Acc: 92.19
[Train] Epoch: 2 [332544/387873]    Loss: 0.001412   Batch Acc: 94.53
[Train] Epoch: 2 [332672/387873]    Loss: 0.001795   Batch Acc: 90.62
[Train] Epoch: 2 [332800/387873]    Loss: 0.002255   Batch Acc: 87.50
[Train] Epoch: 2 [332928/387873]    Loss: 0.001997   Batch Acc: 91.41
[Train] Epoch: 2 [333056/387873]    Loss: 0.001874   Batch Acc: 91.41
[Train] Epoch: 2 [333184/387873]    Loss: 0.002668   Batch Acc: 86.72
[Train] Epoch: 2 [333312/387873]    Loss: 0.001430   Batch Acc: 94.53
[Train] Epoch: 2 [333440/387873]    Loss: 0.002304   Batch Acc: 84.38
[Train] Epoch: 2 [333568/387873]    Loss: 0.002432   Batch Acc: 85.94
[Train] Epoch: 2 [333696/387873]    Loss: 0.001724   Batch Acc: 92.19
[Train] Epoch: 2 [333824/387873]    Loss: 0.002165   Batch Acc: 89.06
[Train] Epoch: 2 [333952/387873]    Loss: 0.001564   Batch Acc: 92.97
[Train] Epoch: 2 [334080/387873]    Loss: 0.001547   Batch Acc: 94.53
[Train] Epoch: 2 [334208/387873]    Loss: 0.001625   Batch Acc: 90.62
[Train] Epoch: 2 [334336/387873]    Loss: 0.002370   Batch Acc: 85.16
[Train] Epoch: 2 [334464/387873]    Loss: 0.002579   Batch Acc: 83.59
[Train] Epoch: 2 [334592/387873]    Loss: 0.001702   Batch Acc: 92.19
[Train] Epoch: 2 [334720/387873]    Loss: 0.002300   Batch Acc: 88.28
[Train] Epoch: 2 [334848/387873]    Loss: 0.001535   Batch Acc: 92.19
[Train] Epoch: 2 [334976/387873]    Loss: 0.001859   Batch Acc: 89.84
[Train] Epoch: 2 [335104/387873]    Loss: 0.002050   Batch Acc: 90.62
[Train] Epoch: 2 [335232/387873]    Loss: 0.002357   Batch Acc: 88.28
[Train] Epoch: 2 [335360/387873]    Loss: 0.002576   Batch Acc: 84.38
[Train] Epoch: 2 [335488/387873]    Loss: 0.002580   Batch Acc: 85.16
[Train] Epoch: 2 [335616/387873]    Loss: 0.002091   Batch Acc: 89.84
[Train] Epoch: 2 [335744/387873]    Loss: 0.002371   Batch Acc: 86.72
[Train] Epoch: 2 [335872/387873]    Loss: 0.002136   Batch Acc: 88.28
[Train] Epoch: 2 [336000/387873]    Loss: 0.002069   Batch Acc: 89.06
[Train] Epoch: 2 [336128/387873]    Loss: 0.002047   Batch Acc: 85.94
[Train] Epoch: 2 [336256/387873]    Loss: 0.001949   Batch Acc: 87.50
[Train] Epoch: 2 [336384/387873]    Loss: 0.002631   Batch Acc: 86.72
[Train] Epoch: 2 [336512/387873]    Loss: 0.001622   Batch Acc: 93.75
[Train] Epoch: 2 [336640/387873]    Loss: 0.001662   Batch Acc: 91.41
[Train] Epoch: 2 [336768/387873]    Loss: 0.002029   Batch Acc: 87.50
[Train] Epoch: 2 [336896/387873]    Loss: 0.001679   Batch Acc: 90.62
[Train] Epoch: 2 [337024/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 2 [337152/387873]    Loss: 0.002249   Batch Acc: 87.50
[Train] Epoch: 2 [337280/387873]    Loss: 0.002330   Batch Acc: 84.38
[Train] Epoch: 2 [337408/387873]    Loss: 0.002035   Batch Acc: 92.97
[Train] Epoch: 2 [337536/387873]    Loss: 0.002332   Batch Acc: 86.72
[Train] Epoch: 2 [337664/387873]    Loss: 0.001582   Batch Acc: 92.19
[Train] Epoch: 2 [337792/387873]    Loss: 0.002814   Batch Acc: 82.81
[Train] Epoch: 2 [337920/387873]    Loss: 0.001991   Batch Acc: 87.50
[Train] Epoch: 2 [338048/387873]    Loss: 0.002241   Batch Acc: 91.41
[Train] Epoch: 2 [338176/387873]    Loss: 0.001492   Batch Acc: 92.97
[Train] Epoch: 2 [338304/387873]    Loss: 0.002239   Batch Acc: 89.06
[Train] Epoch: 2 [338432/387873]    Loss: 0.001766   Batch Acc: 89.84
[Train] Epoch: 2 [338560/387873]    Loss: 0.001627   Batch Acc: 92.97
[Train] Epoch: 2 [338688/387873]    Loss: 0.001747   Batch Acc: 89.84
[Train] Epoch: 2 [338816/387873]    Loss: 0.002134   Batch Acc: 88.28
[Train] Epoch: 2 [338944/387873]    Loss: 0.002019   Batch Acc: 91.41
[Train] Epoch: 2 [339072/387873]    Loss: 0.001660   Batch Acc: 92.19
[Train] Epoch: 2 [339200/387873]    Loss: 0.001983   Batch Acc: 89.84
[Train] Epoch: 2 [339328/387873]    Loss: 0.002195   Batch Acc: 87.50
[Train] Epoch: 2 [339456/387873]    Loss: 0.002016   Batch Acc: 89.84
[Train] Epoch: 2 [339584/387873]    Loss: 0.001999   Batch Acc: 89.06
[Train] Epoch: 2 [339712/387873]    Loss: 0.002402   Batch Acc: 85.16
[Train] Epoch: 2 [339840/387873]    Loss: 0.002100   Batch Acc: 88.28
[Train] Epoch: 2 [339968/387873]    Loss: 0.001984   Batch Acc: 90.62
[Train] Epoch: 2 [340096/387873]    Loss: 0.002137   Batch Acc: 87.50
[Train] Epoch: 2 [340224/387873]    Loss: 0.002059   Batch Acc: 90.62
[Train] Epoch: 2 [340352/387873]    Loss: 0.001472   Batch Acc: 94.53
[Train] Epoch: 2 [340480/387873]    Loss: 0.001589   Batch Acc: 92.97
[Train] Epoch: 2 [340608/387873]    Loss: 0.002222   Batch Acc: 86.72
[Train] Epoch: 2 [340736/387873]    Loss: 0.001966   Batch Acc: 88.28
[Train] Epoch: 2 [340864/387873]    Loss: 0.001527   Batch Acc: 90.62
[Train] Epoch: 2 [340992/387873]    Loss: 0.002088   Batch Acc: 90.62
[Train] Epoch: 2 [341120/387873]    Loss: 0.002001   Batch Acc: 92.97
[Train] Epoch: 2 [341248/387873]    Loss: 0.002208   Batch Acc: 85.94
[Train] Epoch: 2 [341376/387873]    Loss: 0.002320   Batch Acc: 89.06
[Train] Epoch: 2 [341504/387873]    Loss: 0.002007   Batch Acc: 88.28
[Train] Epoch: 2 [341632/387873]    Loss: 0.001905   Batch Acc: 91.41
[Train] Epoch: 2 [341760/387873]    Loss: 0.001486   Batch Acc: 91.41
[Train] Epoch: 2 [341888/387873]    Loss: 0.001735   Batch Acc: 93.75
[Train] Epoch: 2 [342016/387873]    Loss: 0.001780   Batch Acc: 89.84
[Train] Epoch: 2 [342144/387873]    Loss: 0.002033   Batch Acc: 87.50
[Train] Epoch: 2 [342272/387873]    Loss: 0.002377   Batch Acc: 85.94
[Train] Epoch: 2 [342400/387873]    Loss: 0.002317   Batch Acc: 90.62
[Train] Epoch: 2 [342528/387873]    Loss: 0.001892   Batch Acc: 89.84
[Train] Epoch: 2 [342656/387873]    Loss: 0.001599   Batch Acc: 94.53
[Train] Epoch: 2 [342784/387873]    Loss: 0.001983   Batch Acc: 89.06
[Train] Epoch: 2 [342912/387873]    Loss: 0.002166   Batch Acc: 86.72
[Train] Epoch: 2 [343040/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 2 [343168/387873]    Loss: 0.002507   Batch Acc: 85.16
[Train] Epoch: 2 [343296/387873]    Loss: 0.001820   Batch Acc: 91.41
[Train] Epoch: 2 [343424/387873]    Loss: 0.001718   Batch Acc: 92.19
[Train] Epoch: 2 [343552/387873]    Loss: 0.002454   Batch Acc: 88.28
[Train] Epoch: 2 [343680/387873]    Loss: 0.002153   Batch Acc: 87.50
[Train] Epoch: 2 [343808/387873]    Loss: 0.001706   Batch Acc: 92.97
[Train] Epoch: 2 [343936/387873]    Loss: 0.002448   Batch Acc: 85.94
[Train] Epoch: 2 [344064/387873]    Loss: 0.001795   Batch Acc: 89.06
[Train] Epoch: 2 [344192/387873]    Loss: 0.001967   Batch Acc: 89.06
[Train] Epoch: 2 [344320/387873]    Loss: 0.001735   Batch Acc: 91.41
[Train] Epoch: 2 [344448/387873]    Loss: 0.001712   Batch Acc: 92.19
[Train] Epoch: 2 [344576/387873]    Loss: 0.002280   Batch Acc: 88.28
[Train] Epoch: 2 [344704/387873]    Loss: 0.002418   Batch Acc: 87.50
[Train] Epoch: 2 [344832/387873]    Loss: 0.002269   Batch Acc: 87.50
[Train] Epoch: 2 [344960/387873]    Loss: 0.001626   Batch Acc: 89.84
[Train] Epoch: 2 [345088/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 2 [345216/387873]    Loss: 0.002208   Batch Acc: 86.72
[Train] Epoch: 2 [345344/387873]    Loss: 0.001683   Batch Acc: 90.62
[Train] Epoch: 2 [345472/387873]    Loss: 0.002139   Batch Acc: 90.62
[Train] Epoch: 2 [345600/387873]    Loss: 0.002152   Batch Acc: 89.06
[Train] Epoch: 2 [345728/387873]    Loss: 0.002088   Batch Acc: 88.28
[Train] Epoch: 2 [345856/387873]    Loss: 0.001976   Batch Acc: 89.84
[Train] Epoch: 2 [345984/387873]    Loss: 0.001836   Batch Acc: 91.41
[Train] Epoch: 2 [346112/387873]    Loss: 0.002158   Batch Acc: 89.06
[Train] Epoch: 2 [346240/387873]    Loss: 0.002219   Batch Acc: 89.84
[Train] Epoch: 2 [346368/387873]    Loss: 0.001810   Batch Acc: 89.84
[Train] Epoch: 2 [346496/387873]    Loss: 0.002224   Batch Acc: 83.59
[Train] Epoch: 2 [346624/387873]    Loss: 0.001889   Batch Acc: 89.06
[Train] Epoch: 2 [346752/387873]    Loss: 0.002483   Batch Acc: 87.50
[Train] Epoch: 2 [346880/387873]    Loss: 0.002044   Batch Acc: 89.06
[Train] Epoch: 2 [347008/387873]    Loss: 0.001989   Batch Acc: 88.28
[Train] Epoch: 2 [347136/387873]    Loss: 0.002287   Batch Acc: 85.94
[Train] Epoch: 2 [347264/387873]    Loss: 0.002089   Batch Acc: 89.84
[Train] Epoch: 2 [347392/387873]    Loss: 0.001642   Batch Acc: 93.75
[Train] Epoch: 2 [347520/387873]    Loss: 0.002122   Batch Acc: 89.84
[Train] Epoch: 2 [347648/387873]    Loss: 0.002305   Batch Acc: 87.50
[Train] Epoch: 2 [347776/387873]    Loss: 0.001856   Batch Acc: 89.84
[Train] Epoch: 2 [347904/387873]    Loss: 0.002085   Batch Acc: 90.62
[Train] Epoch: 2 [348032/387873]    Loss: 0.001842   Batch Acc: 90.62
[Train] Epoch: 2 [348160/387873]    Loss: 0.002368   Batch Acc: 85.94
[Train] Epoch: 2 [348288/387873]    Loss: 0.001991   Batch Acc: 90.62
[Train] Epoch: 2 [348416/387873]    Loss: 0.001900   Batch Acc: 89.84
[Train] Epoch: 2 [348544/387873]    Loss: 0.001851   Batch Acc: 91.41
[Train] Epoch: 2 [348672/387873]    Loss: 0.001770   Batch Acc: 91.41
[Train] Epoch: 2 [348800/387873]    Loss: 0.002345   Batch Acc: 84.38
[Train] Epoch: 2 [348928/387873]    Loss: 0.002369   Batch Acc: 85.94
[Train] Epoch: 2 [349056/387873]    Loss: 0.001930   Batch Acc: 89.06
[Train] Epoch: 2 [349184/387873]    Loss: 0.001838   Batch Acc: 90.62
[Train] Epoch: 2 [349312/387873]    Loss: 0.001757   Batch Acc: 89.06
[Train] Epoch: 2 [349440/387873]    Loss: 0.001887   Batch Acc: 93.75
[Train] Epoch: 2 [349568/387873]    Loss: 0.002019   Batch Acc: 88.28
[Train] Epoch: 2 [349696/387873]    Loss: 0.002383   Batch Acc: 84.38
[Train] Epoch: 2 [349824/387873]    Loss: 0.001511   Batch Acc: 92.97
[Train] Epoch: 2 [349952/387873]    Loss: 0.001555   Batch Acc: 91.41
[Train] Epoch: 2 [350080/387873]    Loss: 0.001823   Batch Acc: 92.19
[Train] Epoch: 2 [350208/387873]    Loss: 0.002254   Batch Acc: 89.06
[Train] Epoch: 2 [350336/387873]    Loss: 0.002481   Batch Acc: 81.25
[Train] Epoch: 2 [350464/387873]    Loss: 0.001639   Batch Acc: 89.84
[Train] Epoch: 2 [350592/387873]    Loss: 0.001691   Batch Acc: 92.97
[Train] Epoch: 2 [350720/387873]    Loss: 0.002233   Batch Acc: 88.28
[Train] Epoch: 2 [350848/387873]    Loss: 0.001712   Batch Acc: 92.97
[Train] Epoch: 2 [350976/387873]    Loss: 0.001784   Batch Acc: 90.62
[Train] Epoch: 2 [351104/387873]    Loss: 0.002448   Batch Acc: 85.16
[Train] Epoch: 2 [351232/387873]    Loss: 0.001697   Batch Acc: 94.53
[Train] Epoch: 2 [351360/387873]    Loss: 0.002140   Batch Acc: 88.28
[Train] Epoch: 2 [351488/387873]    Loss: 0.001415   Batch Acc: 94.53
[Train] Epoch: 2 [351616/387873]    Loss: 0.001856   Batch Acc: 89.06
[Train] Epoch: 2 [351744/387873]    Loss: 0.001613   Batch Acc: 94.53
[Train] Epoch: 2 [351872/387873]    Loss: 0.002189   Batch Acc: 86.72
[Train] Epoch: 2 [352000/387873]    Loss: 0.002399   Batch Acc: 90.62
[Train] Epoch: 2 [352128/387873]    Loss: 0.002650   Batch Acc: 84.38
[Train] Epoch: 2 [352256/387873]    Loss: 0.002047   Batch Acc: 89.06
[Train] Epoch: 2 [352384/387873]    Loss: 0.002443   Batch Acc: 87.50
[Train] Epoch: 2 [352512/387873]    Loss: 0.002457   Batch Acc: 83.59
[Train] Epoch: 2 [352640/387873]    Loss: 0.002240   Batch Acc: 88.28
[Train] Epoch: 2 [352768/387873]    Loss: 0.002206   Batch Acc: 88.28
[Train] Epoch: 2 [352896/387873]    Loss: 0.001992   Batch Acc: 87.50
[Train] Epoch: 2 [353024/387873]    Loss: 0.002212   Batch Acc: 86.72
[Train] Epoch: 2 [353152/387873]    Loss: 0.001458   Batch Acc: 92.97
[Train] Epoch: 2 [353280/387873]    Loss: 0.002038   Batch Acc: 85.16
[Train] Epoch: 2 [353408/387873]    Loss: 0.002131   Batch Acc: 86.72
[Train] Epoch: 2 [353536/387873]    Loss: 0.001670   Batch Acc: 91.41
[Train] Epoch: 2 [353664/387873]    Loss: 0.001606   Batch Acc: 94.53
[Train] Epoch: 2 [353792/387873]    Loss: 0.002551   Batch Acc: 82.03
[Train] Epoch: 2 [353920/387873]    Loss: 0.002591   Batch Acc: 87.50
[Train] Epoch: 2 [354048/387873]    Loss: 0.001788   Batch Acc: 90.62
[Train] Epoch: 2 [354176/387873]    Loss: 0.002763   Batch Acc: 85.94
[Train] Epoch: 2 [354304/387873]    Loss: 0.001837   Batch Acc: 91.41
[Train] Epoch: 2 [354432/387873]    Loss: 0.001990   Batch Acc: 89.84
[Train] Epoch: 2 [354560/387873]    Loss: 0.001895   Batch Acc: 91.41
[Train] Epoch: 2 [354688/387873]    Loss: 0.002034   Batch Acc: 85.94
[Train] Epoch: 2 [354816/387873]    Loss: 0.002083   Batch Acc: 88.28
[Train] Epoch: 2 [354944/387873]    Loss: 0.001757   Batch Acc: 89.84
[Train] Epoch: 2 [355072/387873]    Loss: 0.001787   Batch Acc: 91.41
[Train] Epoch: 2 [355200/387873]    Loss: 0.002372   Batch Acc: 86.72
[Train] Epoch: 2 [355328/387873]    Loss: 0.001995   Batch Acc: 88.28
[Train] Epoch: 2 [355456/387873]    Loss: 0.001659   Batch Acc: 92.19
[Train] Epoch: 2 [355584/387873]    Loss: 0.003127   Batch Acc: 79.69
[Train] Epoch: 2 [355712/387873]    Loss: 0.002565   Batch Acc: 81.25
[Train] Epoch: 2 [355840/387873]    Loss: 0.001572   Batch Acc: 92.19
[Train] Epoch: 2 [355968/387873]    Loss: 0.002187   Batch Acc: 86.72
[Train] Epoch: 2 [356096/387873]    Loss: 0.001699   Batch Acc: 92.97
[Train] Epoch: 2 [356224/387873]    Loss: 0.001710   Batch Acc: 91.41
[Train] Epoch: 2 [356352/387873]    Loss: 0.002425   Batch Acc: 82.81
[Train] Epoch: 2 [356480/387873]    Loss: 0.001964   Batch Acc: 89.06
[Train] Epoch: 2 [356608/387873]    Loss: 0.002069   Batch Acc: 88.28
[Train] Epoch: 2 [356736/387873]    Loss: 0.001558   Batch Acc: 93.75
[Train] Epoch: 2 [356864/387873]    Loss: 0.001624   Batch Acc: 89.84
[Train] Epoch: 2 [356992/387873]    Loss: 0.001830   Batch Acc: 90.62
[Train] Epoch: 2 [357120/387873]    Loss: 0.002267   Batch Acc: 89.06
[Train] Epoch: 2 [357248/387873]    Loss: 0.001575   Batch Acc: 94.53
[Train] Epoch: 2 [357376/387873]    Loss: 0.001495   Batch Acc: 96.09
[Train] Epoch: 2 [357504/387873]    Loss: 0.002007   Batch Acc: 87.50
[Train] Epoch: 2 [357632/387873]    Loss: 0.002118   Batch Acc: 89.06
[Train] Epoch: 2 [357760/387873]    Loss: 0.002313   Batch Acc: 86.72
[Train] Epoch: 2 [357888/387873]    Loss: 0.001840   Batch Acc: 90.62
[Train] Epoch: 2 [358016/387873]    Loss: 0.001649   Batch Acc: 93.75
[Train] Epoch: 2 [358144/387873]    Loss: 0.002129   Batch Acc: 87.50
[Train] Epoch: 2 [358272/387873]    Loss: 0.001717   Batch Acc: 90.62
[Train] Epoch: 2 [358400/387873]    Loss: 0.002155   Batch Acc: 90.62
[Train] Epoch: 2 [358528/387873]    Loss: 0.001844   Batch Acc: 90.62
[Train] Epoch: 2 [358656/387873]    Loss: 0.002497   Batch Acc: 84.38
[Train] Epoch: 2 [358784/387873]    Loss: 0.001602   Batch Acc: 93.75
[Train] Epoch: 2 [358912/387873]    Loss: 0.001471   Batch Acc: 94.53
[Train] Epoch: 2 [359040/387873]    Loss: 0.001820   Batch Acc: 90.62
[Train] Epoch: 2 [359168/387873]    Loss: 0.001735   Batch Acc: 91.41
[Train] Epoch: 2 [359296/387873]    Loss: 0.002681   Batch Acc: 80.47
[Train] Epoch: 2 [359424/387873]    Loss: 0.002230   Batch Acc: 86.72
[Train] Epoch: 2 [359552/387873]    Loss: 0.001823   Batch Acc: 92.97
[Train] Epoch: 2 [359680/387873]    Loss: 0.001532   Batch Acc: 92.19
[Train] Epoch: 2 [359808/387873]    Loss: 0.002340   Batch Acc: 89.06
[Train] Epoch: 2 [359936/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 2 [360064/387873]    Loss: 0.002443   Batch Acc: 85.94
[Train] Epoch: 2 [360192/387873]    Loss: 0.001186   Batch Acc: 92.19
[Train] Epoch: 2 [360320/387873]    Loss: 0.002084   Batch Acc: 89.84
[Train] Epoch: 2 [360448/387873]    Loss: 0.002182   Batch Acc: 88.28
[Train] Epoch: 2 [360576/387873]    Loss: 0.001826   Batch Acc: 89.84
[Train] Epoch: 2 [360704/387873]    Loss: 0.002546   Batch Acc: 85.16
[Train] Epoch: 2 [360832/387873]    Loss: 0.001765   Batch Acc: 89.06
[Train] Epoch: 2 [360960/387873]    Loss: 0.001735   Batch Acc: 91.41
[Train] Epoch: 2 [361088/387873]    Loss: 0.002134   Batch Acc: 90.62
[Train] Epoch: 2 [361216/387873]    Loss: 0.002243   Batch Acc: 87.50
[Train] Epoch: 2 [361344/387873]    Loss: 0.001602   Batch Acc: 92.19
[Train] Epoch: 2 [361472/387873]    Loss: 0.001598   Batch Acc: 95.31
[Train] Epoch: 2 [361600/387873]    Loss: 0.001493   Batch Acc: 92.97
[Train] Epoch: 2 [361728/387873]    Loss: 0.001969   Batch Acc: 88.28
[Train] Epoch: 2 [361856/387873]    Loss: 0.001767   Batch Acc: 92.19
[Train] Epoch: 2 [361984/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 2 [362112/387873]    Loss: 0.002267   Batch Acc: 88.28
[Train] Epoch: 2 [362240/387873]    Loss: 0.002267   Batch Acc: 84.38
[Train] Epoch: 2 [362368/387873]    Loss: 0.002176   Batch Acc: 86.72
[Train] Epoch: 2 [362496/387873]    Loss: 0.002159   Batch Acc: 87.50
[Train] Epoch: 2 [362624/387873]    Loss: 0.001862   Batch Acc: 89.06
[Train] Epoch: 2 [362752/387873]    Loss: 0.001865   Batch Acc: 89.84
[Train] Epoch: 2 [362880/387873]    Loss: 0.001983   Batch Acc: 89.06
[Train] Epoch: 2 [363008/387873]    Loss: 0.002104   Batch Acc: 89.84
[Train] Epoch: 2 [363136/387873]    Loss: 0.002015   Batch Acc: 88.28
[Train] Epoch: 2 [363264/387873]    Loss: 0.002508   Batch Acc: 86.72
[Train] Epoch: 2 [363392/387873]    Loss: 0.002212   Batch Acc: 90.62
[Train] Epoch: 2 [363520/387873]    Loss: 0.002253   Batch Acc: 87.50
[Train] Epoch: 2 [363648/387873]    Loss: 0.001956   Batch Acc: 89.06
[Train] Epoch: 2 [363776/387873]    Loss: 0.001935   Batch Acc: 89.06
[Train] Epoch: 2 [363904/387873]    Loss: 0.002243   Batch Acc: 89.84
[Train] Epoch: 2 [364032/387873]    Loss: 0.001978   Batch Acc: 92.19
[Train] Epoch: 2 [364160/387873]    Loss: 0.002194   Batch Acc: 88.28
[Train] Epoch: 2 [364288/387873]    Loss: 0.001830   Batch Acc: 90.62
[Train] Epoch: 2 [364416/387873]    Loss: 0.001925   Batch Acc: 89.84
[Train] Epoch: 2 [364544/387873]    Loss: 0.001651   Batch Acc: 90.62
[Train] Epoch: 2 [364672/387873]    Loss: 0.001835   Batch Acc: 91.41
[Train] Epoch: 2 [364800/387873]    Loss: 0.002573   Batch Acc: 85.94
[Train] Epoch: 2 [364928/387873]    Loss: 0.002432   Batch Acc: 85.94
[Train] Epoch: 2 [365056/387873]    Loss: 0.001603   Batch Acc: 91.41
[Train] Epoch: 2 [365184/387873]    Loss: 0.001796   Batch Acc: 88.28
[Train] Epoch: 2 [365312/387873]    Loss: 0.001940   Batch Acc: 89.84
[Train] Epoch: 2 [365440/387873]    Loss: 0.001858   Batch Acc: 92.19
[Train] Epoch: 2 [365568/387873]    Loss: 0.002106   Batch Acc: 89.84
[Train] Epoch: 2 [365696/387873]    Loss: 0.002418   Batch Acc: 89.06
[Train] Epoch: 2 [365824/387873]    Loss: 0.001600   Batch Acc: 93.75
[Train] Epoch: 2 [365952/387873]    Loss: 0.001771   Batch Acc: 91.41
[Train] Epoch: 2 [366080/387873]    Loss: 0.001936   Batch Acc: 90.62
[Train] Epoch: 2 [366208/387873]    Loss: 0.001682   Batch Acc: 89.84
[Train] Epoch: 2 [366336/387873]    Loss: 0.001602   Batch Acc: 91.41
[Train] Epoch: 2 [366464/387873]    Loss: 0.001470   Batch Acc: 92.97
[Train] Epoch: 2 [366592/387873]    Loss: 0.002083   Batch Acc: 86.72
[Train] Epoch: 2 [366720/387873]    Loss: 0.001666   Batch Acc: 92.19
[Train] Epoch: 2 [366848/387873]    Loss: 0.001760   Batch Acc: 91.41
[Train] Epoch: 2 [366976/387873]    Loss: 0.002559   Batch Acc: 86.72
[Train] Epoch: 2 [367104/387873]    Loss: 0.002016   Batch Acc: 87.50
[Train] Epoch: 2 [367232/387873]    Loss: 0.002262   Batch Acc: 85.16
[Train] Epoch: 2 [367360/387873]    Loss: 0.002566   Batch Acc: 88.28
[Train] Epoch: 2 [367488/387873]    Loss: 0.002166   Batch Acc: 87.50
[Train] Epoch: 2 [367616/387873]    Loss: 0.001553   Batch Acc: 92.19
[Train] Epoch: 2 [367744/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 2 [367872/387873]    Loss: 0.001822   Batch Acc: 89.84
[Train] Epoch: 2 [368000/387873]    Loss: 0.002288   Batch Acc: 86.72
[Train] Epoch: 2 [368128/387873]    Loss: 0.001791   Batch Acc: 92.19
[Train] Epoch: 2 [368256/387873]    Loss: 0.001708   Batch Acc: 91.41
[Train] Epoch: 2 [368384/387873]    Loss: 0.001581   Batch Acc: 92.97
[Train] Epoch: 2 [368512/387873]    Loss: 0.001553   Batch Acc: 96.09
[Train] Epoch: 2 [368640/387873]    Loss: 0.002035   Batch Acc: 89.06
[Train] Epoch: 2 [368768/387873]    Loss: 0.001595   Batch Acc: 90.62
[Train] Epoch: 2 [368896/387873]    Loss: 0.002026   Batch Acc: 86.72
[Train] Epoch: 2 [369024/387873]    Loss: 0.002532   Batch Acc: 83.59
[Train] Epoch: 2 [369152/387873]    Loss: 0.002344   Batch Acc: 85.16
[Train] Epoch: 2 [369280/387873]    Loss: 0.001788   Batch Acc: 91.41
[Train] Epoch: 2 [369408/387873]    Loss: 0.001940   Batch Acc: 89.84
[Train] Epoch: 2 [369536/387873]    Loss: 0.002182   Batch Acc: 89.06
[Train] Epoch: 2 [369664/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 2 [369792/387873]    Loss: 0.001723   Batch Acc: 90.62
[Train] Epoch: 2 [369920/387873]    Loss: 0.002115   Batch Acc: 88.28
[Train] Epoch: 2 [370048/387873]    Loss: 0.001678   Batch Acc: 89.06
[Train] Epoch: 2 [370176/387873]    Loss: 0.002451   Batch Acc: 86.72
[Train] Epoch: 2 [370304/387873]    Loss: 0.001567   Batch Acc: 92.19
[Train] Epoch: 2 [370432/387873]    Loss: 0.001805   Batch Acc: 89.06
[Train] Epoch: 2 [370560/387873]    Loss: 0.002003   Batch Acc: 89.84
[Train] Epoch: 2 [370688/387873]    Loss: 0.001831   Batch Acc: 89.06
[Train] Epoch: 2 [370816/387873]    Loss: 0.001621   Batch Acc: 92.97
[Train] Epoch: 2 [370944/387873]    Loss: 0.002380   Batch Acc: 86.72
[Train] Epoch: 2 [371072/387873]    Loss: 0.001558   Batch Acc: 94.53
[Train] Epoch: 2 [371200/387873]    Loss: 0.002137   Batch Acc: 85.94
[Train] Epoch: 2 [371328/387873]    Loss: 0.002047   Batch Acc: 91.41
[Train] Epoch: 2 [371456/387873]    Loss: 0.002733   Batch Acc: 82.81
[Train] Epoch: 2 [371584/387873]    Loss: 0.001613   Batch Acc: 92.19
[Train] Epoch: 2 [371712/387873]    Loss: 0.001758   Batch Acc: 91.41
[Train] Epoch: 2 [371840/387873]    Loss: 0.002087   Batch Acc: 89.06
[Train] Epoch: 2 [371968/387873]    Loss: 0.002039   Batch Acc: 89.06
[Train] Epoch: 2 [372096/387873]    Loss: 0.002588   Batch Acc: 87.50
[Train] Epoch: 2 [372224/387873]    Loss: 0.002407   Batch Acc: 89.06
[Train] Epoch: 2 [372352/387873]    Loss: 0.002186   Batch Acc: 87.50
[Train] Epoch: 2 [372480/387873]    Loss: 0.002015   Batch Acc: 86.72
[Train] Epoch: 2 [372608/387873]    Loss: 0.002293   Batch Acc: 86.72
[Train] Epoch: 2 [372736/387873]    Loss: 0.002296   Batch Acc: 88.28
[Train] Epoch: 2 [372864/387873]    Loss: 0.001762   Batch Acc: 89.84
[Train] Epoch: 2 [372992/387873]    Loss: 0.001742   Batch Acc: 92.19
[Train] Epoch: 2 [373120/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 2 [373248/387873]    Loss: 0.002588   Batch Acc: 85.94
[Train] Epoch: 2 [373376/387873]    Loss: 0.001934   Batch Acc: 89.84
[Train] Epoch: 2 [373504/387873]    Loss: 0.001861   Batch Acc: 89.84
[Train] Epoch: 2 [373632/387873]    Loss: 0.002521   Batch Acc: 85.16
[Train] Epoch: 2 [373760/387873]    Loss: 0.001932   Batch Acc: 88.28
[Train] Epoch: 2 [373888/387873]    Loss: 0.001859   Batch Acc: 91.41
[Train] Epoch: 2 [374016/387873]    Loss: 0.002052   Batch Acc: 87.50
[Train] Epoch: 2 [374144/387873]    Loss: 0.001878   Batch Acc: 90.62
[Train] Epoch: 2 [374272/387873]    Loss: 0.002105   Batch Acc: 91.41
[Train] Epoch: 2 [374400/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 2 [374528/387873]    Loss: 0.001797   Batch Acc: 89.84
[Train] Epoch: 2 [374656/387873]    Loss: 0.002316   Batch Acc: 86.72
[Train] Epoch: 2 [374784/387873]    Loss: 0.002388   Batch Acc: 87.50
[Train] Epoch: 2 [374912/387873]    Loss: 0.002663   Batch Acc: 85.16
[Train] Epoch: 2 [375040/387873]    Loss: 0.002222   Batch Acc: 86.72
[Train] Epoch: 2 [375168/387873]    Loss: 0.002750   Batch Acc: 82.81
[Train] Epoch: 2 [375296/387873]    Loss: 0.003001   Batch Acc: 82.03
[Train] Epoch: 2 [375424/387873]    Loss: 0.002335   Batch Acc: 85.16
[Train] Epoch: 2 [375552/387873]    Loss: 0.001892   Batch Acc: 88.28
[Train] Epoch: 2 [375680/387873]    Loss: 0.002287   Batch Acc: 85.16
[Train] Epoch: 2 [375808/387873]    Loss: 0.001803   Batch Acc: 91.41
[Train] Epoch: 2 [375936/387873]    Loss: 0.002427   Batch Acc: 89.06
[Train] Epoch: 2 [376064/387873]    Loss: 0.001790   Batch Acc: 92.19
[Train] Epoch: 2 [376192/387873]    Loss: 0.001562   Batch Acc: 94.53
[Train] Epoch: 2 [376320/387873]    Loss: 0.001623   Batch Acc: 92.97
[Train] Epoch: 2 [376448/387873]    Loss: 0.002076   Batch Acc: 89.84
[Train] Epoch: 2 [376576/387873]    Loss: 0.001885   Batch Acc: 90.62
[Train] Epoch: 2 [376704/387873]    Loss: 0.001899   Batch Acc: 87.50
[Train] Epoch: 2 [376832/387873]    Loss: 0.002542   Batch Acc: 86.72
[Train] Epoch: 2 [376960/387873]    Loss: 0.002295   Batch Acc: 89.06
[Train] Epoch: 2 [377088/387873]    Loss: 0.002117   Batch Acc: 90.62
[Train] Epoch: 2 [377216/387873]    Loss: 0.002239   Batch Acc: 84.38
[Train] Epoch: 2 [377344/387873]    Loss: 0.001992   Batch Acc: 89.06
[Train] Epoch: 2 [377472/387873]    Loss: 0.001782   Batch Acc: 89.06
[Train] Epoch: 2 [377600/387873]    Loss: 0.002124   Batch Acc: 88.28
[Train] Epoch: 2 [377728/387873]    Loss: 0.001611   Batch Acc: 92.19
[Train] Epoch: 2 [377856/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 2 [377984/387873]    Loss: 0.001625   Batch Acc: 93.75
[Train] Epoch: 2 [378112/387873]    Loss: 0.002333   Batch Acc: 87.50
[Train] Epoch: 2 [378240/387873]    Loss: 0.002271   Batch Acc: 88.28
[Train] Epoch: 2 [378368/387873]    Loss: 0.002362   Batch Acc: 88.28
[Train] Epoch: 2 [378496/387873]    Loss: 0.001679   Batch Acc: 93.75
[Train] Epoch: 2 [378624/387873]    Loss: 0.002548   Batch Acc: 82.81
[Train] Epoch: 2 [378752/387873]    Loss: 0.002568   Batch Acc: 84.38
[Train] Epoch: 2 [378880/387873]    Loss: 0.001793   Batch Acc: 92.19
[Train] Epoch: 2 [379008/387873]    Loss: 0.002205   Batch Acc: 86.72
[Train] Epoch: 2 [379136/387873]    Loss: 0.002198   Batch Acc: 87.50
[Train] Epoch: 2 [379264/387873]    Loss: 0.002028   Batch Acc: 89.06
[Train] Epoch: 2 [379392/387873]    Loss: 0.002243   Batch Acc: 85.94
[Train] Epoch: 2 [379520/387873]    Loss: 0.001870   Batch Acc: 90.62
[Train] Epoch: 2 [379648/387873]    Loss: 0.002616   Batch Acc: 82.81
[Train] Epoch: 2 [379776/387873]    Loss: 0.002107   Batch Acc: 87.50
[Train] Epoch: 2 [379904/387873]    Loss: 0.002334   Batch Acc: 87.50
[Train] Epoch: 2 [380032/387873]    Loss: 0.001677   Batch Acc: 91.41
[Train] Epoch: 2 [380160/387873]    Loss: 0.001465   Batch Acc: 90.62
[Train] Epoch: 2 [380288/387873]    Loss: 0.001685   Batch Acc: 90.62
[Train] Epoch: 2 [380416/387873]    Loss: 0.001768   Batch Acc: 90.62
[Train] Epoch: 2 [380544/387873]    Loss: 0.001817   Batch Acc: 88.28
[Train] Epoch: 2 [380672/387873]    Loss: 0.001697   Batch Acc: 94.53
[Train] Epoch: 2 [380800/387873]    Loss: 0.001822   Batch Acc: 89.84
[Train] Epoch: 2 [380928/387873]    Loss: 0.002042   Batch Acc: 89.06
[Train] Epoch: 2 [381056/387873]    Loss: 0.001880   Batch Acc: 91.41
[Train] Epoch: 2 [381184/387873]    Loss: 0.001810   Batch Acc: 90.62
[Train] Epoch: 2 [381312/387873]    Loss: 0.002122   Batch Acc: 88.28
[Train] Epoch: 2 [381440/387873]    Loss: 0.001569   Batch Acc: 94.53
[Train] Epoch: 2 [381568/387873]    Loss: 0.002331   Batch Acc: 87.50
[Train] Epoch: 2 [381696/387873]    Loss: 0.002991   Batch Acc: 82.03
[Train] Epoch: 2 [381824/387873]    Loss: 0.002147   Batch Acc: 85.94
[Train] Epoch: 2 [381952/387873]    Loss: 0.001404   Batch Acc: 92.97
[Train] Epoch: 2 [382080/387873]    Loss: 0.002103   Batch Acc: 88.28
[Train] Epoch: 2 [382208/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 2 [382336/387873]    Loss: 0.002350   Batch Acc: 87.50
[Train] Epoch: 2 [382464/387873]    Loss: 0.002721   Batch Acc: 82.81
[Train] Epoch: 2 [382592/387873]    Loss: 0.002212   Batch Acc: 88.28
[Train] Epoch: 2 [382720/387873]    Loss: 0.002009   Batch Acc: 88.28
[Train] Epoch: 2 [382848/387873]    Loss: 0.001742   Batch Acc: 92.19
[Train] Epoch: 2 [382976/387873]    Loss: 0.001600   Batch Acc: 90.62
[Train] Epoch: 2 [383104/387873]    Loss: 0.002407   Batch Acc: 89.06
[Train] Epoch: 2 [383232/387873]    Loss: 0.002076   Batch Acc: 89.06
[Train] Epoch: 2 [383360/387873]    Loss: 0.002634   Batch Acc: 82.81
[Train] Epoch: 2 [383488/387873]    Loss: 0.001549   Batch Acc: 92.19
[Train] Epoch: 2 [383616/387873]    Loss: 0.001751   Batch Acc: 90.62
[Train] Epoch: 2 [383744/387873]    Loss: 0.002046   Batch Acc: 88.28
[Train] Epoch: 2 [383872/387873]    Loss: 0.001832   Batch Acc: 90.62
[Train] Epoch: 2 [384000/387873]    Loss: 0.001620   Batch Acc: 91.41
[Train] Epoch: 2 [384128/387873]    Loss: 0.002237   Batch Acc: 88.28
[Train] Epoch: 2 [384256/387873]    Loss: 0.001578   Batch Acc: 90.62
[Train] Epoch: 2 [384384/387873]    Loss: 0.001576   Batch Acc: 93.75
[Train] Epoch: 2 [384512/387873]    Loss: 0.002136   Batch Acc: 87.50
[Train] Epoch: 2 [384640/387873]    Loss: 0.001868   Batch Acc: 91.41
[Train] Epoch: 2 [384768/387873]    Loss: 0.002298   Batch Acc: 85.94
[Train] Epoch: 2 [384896/387873]    Loss: 0.001648   Batch Acc: 92.19
[Train] Epoch: 2 [385024/387873]    Loss: 0.001734   Batch Acc: 92.97
[Train] Epoch: 2 [385152/387873]    Loss: 0.002155   Batch Acc: 89.06
[Train] Epoch: 2 [385280/387873]    Loss: 0.002679   Batch Acc: 85.94
[Train] Epoch: 2 [385408/387873]    Loss: 0.001875   Batch Acc: 90.62
[Train] Epoch: 2 [385536/387873]    Loss: 0.001808   Batch Acc: 90.62
[Train] Epoch: 2 [385664/387873]    Loss: 0.002018   Batch Acc: 87.50
[Train] Epoch: 2 [385792/387873]    Loss: 0.001815   Batch Acc: 91.41
[Train] Epoch: 2 [385920/387873]    Loss: 0.002068   Batch Acc: 89.06
[Train] Epoch: 2 [386048/387873]    Loss: 0.002180   Batch Acc: 89.84
[Train] Epoch: 2 [386176/387873]    Loss: 0.002312   Batch Acc: 83.59
[Train] Epoch: 2 [386304/387873]    Loss: 0.002355   Batch Acc: 84.38
[Train] Epoch: 2 [386432/387873]    Loss: 0.001569   Batch Acc: 92.19
[Train] Epoch: 2 [386560/387873]    Loss: 0.002430   Batch Acc: 85.16
[Train] Epoch: 2 [386688/387873]    Loss: 0.002225   Batch Acc: 89.84
[Train] Epoch: 2 [386816/387873]    Loss: 0.002203   Batch Acc: 86.72
[Train] Epoch: 2 [386944/387873]    Loss: 0.002054   Batch Acc: 88.28
[Train] Epoch: 2 [387072/387873]    Loss: 0.001857   Batch Acc: 89.06
[Train] Epoch: 2 [387200/387873]    Loss: 0.001914   Batch Acc: 90.62
[Train] Epoch: 2 [387328/387873]    Loss: 0.001743   Batch Acc: 93.75
[Train] Epoch: 2 [387456/387873]    Loss: 0.002567   Batch Acc: 83.59
[Train] Epoch: 2 [387584/387873]    Loss: 0.002286   Batch Acc: 85.94
[Train] Epoch: 2 [387712/387873]    Loss: 0.001610   Batch Acc: 89.84
[Train] Epoch: 2 [387840/387873]    Loss: 0.001625   Batch Acc: 92.19
[Train] Epoch: 2 [100023/387873]    Loss: 0.011769   Batch Acc: 81.82
Validation Done: [128/84203]
Validation Done: [256/84203]
Validation Done: [384/84203]
Validation Done: [512/84203]
Validation Done: [640/84203]
Validation Done: [768/84203]
Validation Done: [896/84203]
Validation Done: [1024/84203]
Validation Done: [1152/84203]
Validation Done: [1280/84203]
Validation Done: [1408/84203]
Validation Done: [1536/84203]
Validation Done: [1664/84203]
Validation Done: [1792/84203]
Validation Done: [1920/84203]
Validation Done: [2048/84203]
Validation Done: [2176/84203]
Validation Done: [2304/84203]
Validation Done: [2432/84203]
Validation Done: [2560/84203]
Validation Done: [2688/84203]
Validation Done: [2816/84203]
Validation Done: [2944/84203]
Validation Done: [3072/84203]
Validation Done: [3200/84203]
Validation Done: [3328/84203]
Validation Done: [3456/84203]
Validation Done: [3584/84203]
Validation Done: [3712/84203]
Validation Done: [3840/84203]
Validation Done: [3968/84203]
Validation Done: [4096/84203]
Validation Done: [4224/84203]
Validation Done: [4352/84203]
Validation Done: [4480/84203]
Validation Done: [4608/84203]
Validation Done: [4736/84203]
Validation Done: [4864/84203]
Validation Done: [4992/84203]
Validation Done: [5120/84203]
Validation Done: [5248/84203]
Validation Done: [5376/84203]
Validation Done: [5504/84203]
Validation Done: [5632/84203]
Validation Done: [5760/84203]
Validation Done: [5888/84203]
Validation Done: [6016/84203]
Validation Done: [6144/84203]
Validation Done: [6272/84203]
Validation Done: [6400/84203]
Validation Done: [6528/84203]
Validation Done: [6656/84203]
Validation Done: [6784/84203]
Validation Done: [6912/84203]
Validation Done: [7040/84203]
Validation Done: [7168/84203]
Validation Done: [7296/84203]
Validation Done: [7424/84203]
Validation Done: [7552/84203]
Validation Done: [7680/84203]
Validation Done: [7808/84203]
Validation Done: [7936/84203]
Validation Done: [8064/84203]
Validation Done: [8192/84203]
Validation Done: [8320/84203]
Validation Done: [8448/84203]
Validation Done: [8576/84203]
Validation Done: [8704/84203]
Validation Done: [8832/84203]
Validation Done: [8960/84203]
Validation Done: [9088/84203]
Validation Done: [9216/84203]
Validation Done: [9344/84203]
Validation Done: [9472/84203]
Validation Done: [9600/84203]
Validation Done: [9728/84203]
Validation Done: [9856/84203]
Validation Done: [9984/84203]
Validation Done: [10112/84203]
Validation Done: [10240/84203]
Validation Done: [10368/84203]
Validation Done: [10496/84203]
Validation Done: [10624/84203]
Validation Done: [10752/84203]
Validation Done: [10880/84203]
Validation Done: [11008/84203]
Validation Done: [11136/84203]
Validation Done: [11264/84203]
Validation Done: [11392/84203]
Validation Done: [11520/84203]
Validation Done: [11648/84203]
Validation Done: [11776/84203]
Validation Done: [11904/84203]
Validation Done: [12032/84203]
Validation Done: [12160/84203]
Validation Done: [12288/84203]
Validation Done: [12416/84203]
Validation Done: [12544/84203]
Validation Done: [12672/84203]
Validation Done: [12800/84203]
Validation Done: [12928/84203]
Validation Done: [13056/84203]
Validation Done: [13184/84203]
Validation Done: [13312/84203]
Validation Done: [13440/84203]
Validation Done: [13568/84203]
Validation Done: [13696/84203]
Validation Done: [13824/84203]
Validation Done: [13952/84203]
Validation Done: [14080/84203]
Validation Done: [14208/84203]
Validation Done: [14336/84203]
Validation Done: [14464/84203]
Validation Done: [14592/84203]
Validation Done: [14720/84203]
Validation Done: [14848/84203]
Validation Done: [14976/84203]
Validation Done: [15104/84203]
Validation Done: [15232/84203]
Validation Done: [15360/84203]
Validation Done: [15488/84203]
Validation Done: [15616/84203]
Validation Done: [15744/84203]
Validation Done: [15872/84203]
Validation Done: [16000/84203]
Validation Done: [16128/84203]
Validation Done: [16256/84203]
Validation Done: [16384/84203]
Validation Done: [16512/84203]
Validation Done: [16640/84203]
Validation Done: [16768/84203]
Validation Done: [16896/84203]
Validation Done: [17024/84203]
Validation Done: [17152/84203]
Validation Done: [17280/84203]
Validation Done: [17408/84203]
Validation Done: [17536/84203]
Validation Done: [17664/84203]
Validation Done: [17792/84203]
Validation Done: [17920/84203]
Validation Done: [18048/84203]
Validation Done: [18176/84203]
Validation Done: [18304/84203]
Validation Done: [18432/84203]
Validation Done: [18560/84203]
Validation Done: [18688/84203]
Validation Done: [18816/84203]
Validation Done: [18944/84203]
Validation Done: [19072/84203]
Validation Done: [19200/84203]
Validation Done: [19328/84203]
Validation Done: [19456/84203]
Validation Done: [19584/84203]
Validation Done: [19712/84203]
Validation Done: [19840/84203]
Validation Done: [19968/84203]
Validation Done: [20096/84203]
Validation Done: [20224/84203]
Validation Done: [20352/84203]
Validation Done: [20480/84203]
Validation Done: [20608/84203]
Validation Done: [20736/84203]
Validation Done: [20864/84203]
Validation Done: [20992/84203]
Validation Done: [21120/84203]
Validation Done: [21248/84203]
Validation Done: [21376/84203]
Validation Done: [21504/84203]
Validation Done: [21632/84203]
Validation Done: [21760/84203]
Validation Done: [21888/84203]
Validation Done: [22016/84203]
Validation Done: [22144/84203]
Validation Done: [22272/84203]
Validation Done: [22400/84203]
Validation Done: [22528/84203]
Validation Done: [22656/84203]
Validation Done: [22784/84203]
Validation Done: [22912/84203]
Validation Done: [23040/84203]
Validation Done: [23168/84203]
Validation Done: [23296/84203]
Validation Done: [23424/84203]
Validation Done: [23552/84203]
Validation Done: [23680/84203]
Validation Done: [23808/84203]
Validation Done: [23936/84203]
Validation Done: [24064/84203]
Validation Done: [24192/84203]
Validation Done: [24320/84203]
Validation Done: [24448/84203]
Validation Done: [24576/84203]
Validation Done: [24704/84203]
Validation Done: [24832/84203]
Validation Done: [24960/84203]
Validation Done: [25088/84203]
Validation Done: [25216/84203]
Validation Done: [25344/84203]
Validation Done: [25472/84203]
Validation Done: [25600/84203]
Validation Done: [25728/84203]
Validation Done: [25856/84203]
Validation Done: [25984/84203]
Validation Done: [26112/84203]
Validation Done: [26240/84203]
Validation Done: [26368/84203]
Validation Done: [26496/84203]
Validation Done: [26624/84203]
Validation Done: [26752/84203]
Validation Done: [26880/84203]
Validation Done: [27008/84203]
Validation Done: [27136/84203]
Validation Done: [27264/84203]
Validation Done: [27392/84203]
Validation Done: [27520/84203]
Validation Done: [27648/84203]
Validation Done: [27776/84203]
Validation Done: [27904/84203]
Validation Done: [28032/84203]
Validation Done: [28160/84203]
Validation Done: [28288/84203]
Validation Done: [28416/84203]
Validation Done: [28544/84203]
Validation Done: [28672/84203]
Validation Done: [28800/84203]
Validation Done: [28928/84203]
Validation Done: [29056/84203]
Validation Done: [29184/84203]
Validation Done: [29312/84203]
Validation Done: [29440/84203]
Validation Done: [29568/84203]
Validation Done: [29696/84203]
Validation Done: [29824/84203]
Validation Done: [29952/84203]
Validation Done: [30080/84203]
Validation Done: [30208/84203]
Validation Done: [30336/84203]
Validation Done: [30464/84203]
Validation Done: [30592/84203]
Validation Done: [30720/84203]
Validation Done: [30848/84203]
Validation Done: [30976/84203]
Validation Done: [31104/84203]
Validation Done: [31232/84203]
Validation Done: [31360/84203]
Validation Done: [31488/84203]
Validation Done: [31616/84203]
Validation Done: [31744/84203]
Validation Done: [31872/84203]
Validation Done: [32000/84203]
Validation Done: [32128/84203]
Validation Done: [32256/84203]
Validation Done: [32384/84203]
Validation Done: [32512/84203]
Validation Done: [32640/84203]
Validation Done: [32768/84203]
Validation Done: [32896/84203]
Validation Done: [33024/84203]
Validation Done: [33152/84203]
Validation Done: [33280/84203]
Validation Done: [33408/84203]
Validation Done: [33536/84203]
Validation Done: [33664/84203]
Validation Done: [33792/84203]
Validation Done: [33920/84203]
Validation Done: [34048/84203]
Validation Done: [34176/84203]
Validation Done: [34304/84203]
Validation Done: [34432/84203]
Validation Done: [34560/84203]
Validation Done: [34688/84203]
Validation Done: [34816/84203]
Validation Done: [34944/84203]
Validation Done: [35072/84203]
Validation Done: [35200/84203]
Validation Done: [35328/84203]
Validation Done: [35456/84203]
Validation Done: [35584/84203]
Validation Done: [35712/84203]
Validation Done: [35840/84203]
Validation Done: [35968/84203]
Validation Done: [36096/84203]
Validation Done: [36224/84203]
Validation Done: [36352/84203]
Validation Done: [36480/84203]
Validation Done: [36608/84203]
Validation Done: [36736/84203]
Validation Done: [36864/84203]
Validation Done: [36992/84203]
Validation Done: [37120/84203]
Validation Done: [37248/84203]
Validation Done: [37376/84203]
Validation Done: [37504/84203]
Validation Done: [37632/84203]
Validation Done: [37760/84203]
Validation Done: [37888/84203]
Validation Done: [38016/84203]
Validation Done: [38144/84203]
Validation Done: [38272/84203]
Validation Done: [38400/84203]
Validation Done: [38528/84203]
Validation Done: [38656/84203]
Validation Done: [38784/84203]
Validation Done: [38912/84203]
Validation Done: [39040/84203]
Validation Done: [39168/84203]
Validation Done: [39296/84203]
Validation Done: [39424/84203]
Validation Done: [39552/84203]
Validation Done: [39680/84203]
Validation Done: [39808/84203]
Validation Done: [39936/84203]
Validation Done: [40064/84203]
Validation Done: [40192/84203]
Validation Done: [40320/84203]
Validation Done: [40448/84203]
Validation Done: [40576/84203]
Validation Done: [40704/84203]
Validation Done: [40832/84203]
Validation Done: [40960/84203]
Validation Done: [41088/84203]
Validation Done: [41216/84203]
Validation Done: [41344/84203]
Validation Done: [41472/84203]
Validation Done: [41600/84203]
Validation Done: [41728/84203]
Validation Done: [41856/84203]
Validation Done: [41984/84203]
Validation Done: [42112/84203]
Validation Done: [42240/84203]
Validation Done: [42368/84203]
Validation Done: [42496/84203]
Validation Done: [42624/84203]
Validation Done: [42752/84203]
Validation Done: [42880/84203]
Validation Done: [43008/84203]
Validation Done: [43136/84203]
Validation Done: [43264/84203]
Validation Done: [43392/84203]
Validation Done: [43520/84203]
Validation Done: [43648/84203]
Validation Done: [43776/84203]
Validation Done: [43904/84203]
Validation Done: [44032/84203]
Validation Done: [44160/84203]
Validation Done: [44288/84203]
Validation Done: [44416/84203]
Validation Done: [44544/84203]
Validation Done: [44672/84203]
Validation Done: [44800/84203]
Validation Done: [44928/84203]
Validation Done: [45056/84203]
Validation Done: [45184/84203]
Validation Done: [45312/84203]
Validation Done: [45440/84203]
Validation Done: [45568/84203]
Validation Done: [45696/84203]
Validation Done: [45824/84203]
Validation Done: [45952/84203]
Validation Done: [46080/84203]
Validation Done: [46208/84203]
Validation Done: [46336/84203]
Validation Done: [46464/84203]
Validation Done: [46592/84203]
Validation Done: [46720/84203]
Validation Done: [46848/84203]
Validation Done: [46976/84203]
Validation Done: [47104/84203]
Validation Done: [47232/84203]
Validation Done: [47360/84203]
Validation Done: [47488/84203]
Validation Done: [47616/84203]
Validation Done: [47744/84203]
Validation Done: [47872/84203]
Validation Done: [48000/84203]
Validation Done: [48128/84203]
Validation Done: [48256/84203]
Validation Done: [48384/84203]
Validation Done: [48512/84203]
Validation Done: [48640/84203]
Validation Done: [48768/84203]
Validation Done: [48896/84203]
Validation Done: [49024/84203]
Validation Done: [49152/84203]
Validation Done: [49280/84203]
Validation Done: [49408/84203]
Validation Done: [49536/84203]
Validation Done: [49664/84203]
Validation Done: [49792/84203]
Validation Done: [49920/84203]
Validation Done: [50048/84203]
Validation Done: [50176/84203]
Validation Done: [50304/84203]
Validation Done: [50432/84203]
Validation Done: [50560/84203]
Validation Done: [50688/84203]
Validation Done: [50816/84203]
Validation Done: [50944/84203]
Validation Done: [51072/84203]
Validation Done: [51200/84203]
Validation Done: [51328/84203]
Validation Done: [51456/84203]
Validation Done: [51584/84203]
Validation Done: [51712/84203]
Validation Done: [51840/84203]
Validation Done: [51968/84203]
Validation Done: [52096/84203]
Validation Done: [52224/84203]
Validation Done: [52352/84203]
Validation Done: [52480/84203]
Validation Done: [52608/84203]
Validation Done: [52736/84203]
Validation Done: [52864/84203]
Validation Done: [52992/84203]
Validation Done: [53120/84203]
Validation Done: [53248/84203]
Validation Done: [53376/84203]
Validation Done: [53504/84203]
Validation Done: [53632/84203]
Validation Done: [53760/84203]
Validation Done: [53888/84203]
Validation Done: [54016/84203]
Validation Done: [54144/84203]
Validation Done: [54272/84203]
Validation Done: [54400/84203]
Validation Done: [54528/84203]
Validation Done: [54656/84203]
Validation Done: [54784/84203]
Validation Done: [54912/84203]
Validation Done: [55040/84203]
Validation Done: [55168/84203]
Validation Done: [55296/84203]
Validation Done: [55424/84203]
Validation Done: [55552/84203]
Validation Done: [55680/84203]
Validation Done: [55808/84203]
Validation Done: [55936/84203]
Validation Done: [56064/84203]
Validation Done: [56192/84203]
Validation Done: [56320/84203]
Validation Done: [56448/84203]
Validation Done: [56576/84203]
Validation Done: [56704/84203]
Validation Done: [56832/84203]
Validation Done: [56960/84203]
Validation Done: [57088/84203]
Validation Done: [57216/84203]
Validation Done: [57344/84203]
Validation Done: [57472/84203]
Validation Done: [57600/84203]
Validation Done: [57728/84203]
Validation Done: [57856/84203]
Validation Done: [57984/84203]
Validation Done: [58112/84203]
Validation Done: [58240/84203]
Validation Done: [58368/84203]
Validation Done: [58496/84203]
Validation Done: [58624/84203]
Validation Done: [58752/84203]
Validation Done: [58880/84203]
Validation Done: [59008/84203]
Validation Done: [59136/84203]
Validation Done: [59264/84203]
Validation Done: [59392/84203]
Validation Done: [59520/84203]
Validation Done: [59648/84203]
Validation Done: [59776/84203]
Validation Done: [59904/84203]
Validation Done: [60032/84203]
Validation Done: [60160/84203]
Validation Done: [60288/84203]
Validation Done: [60416/84203]
Validation Done: [60544/84203]
Validation Done: [60672/84203]
Validation Done: [60800/84203]
Validation Done: [60928/84203]
Validation Done: [61056/84203]
Validation Done: [61184/84203]
Validation Done: [61312/84203]
Validation Done: [61440/84203]
Validation Done: [61568/84203]
Validation Done: [61696/84203]
Validation Done: [61824/84203]
Validation Done: [61952/84203]
Validation Done: [62080/84203]
Validation Done: [62208/84203]
Validation Done: [62336/84203]
Validation Done: [62464/84203]
Validation Done: [62592/84203]
Validation Done: [62720/84203]
Validation Done: [62848/84203]
Validation Done: [62976/84203]
Validation Done: [63104/84203]
Validation Done: [63232/84203]
Validation Done: [63360/84203]
Validation Done: [63488/84203]
Validation Done: [63616/84203]
Validation Done: [63744/84203]
Validation Done: [63872/84203]
Validation Done: [64000/84203]
Validation Done: [64128/84203]
Validation Done: [64256/84203]
Validation Done: [64384/84203]
Validation Done: [64512/84203]
Validation Done: [64640/84203]
Validation Done: [64768/84203]
Validation Done: [64896/84203]
Validation Done: [65024/84203]
Validation Done: [65152/84203]
Validation Done: [65280/84203]
Validation Done: [65408/84203]
Validation Done: [65536/84203]
Validation Done: [65664/84203]
Validation Done: [65792/84203]
Validation Done: [65920/84203]
Validation Done: [66048/84203]
Validation Done: [66176/84203]
Validation Done: [66304/84203]
Validation Done: [66432/84203]
Validation Done: [66560/84203]
Validation Done: [66688/84203]
Validation Done: [66816/84203]
Validation Done: [66944/84203]
Validation Done: [67072/84203]
Validation Done: [67200/84203]
Validation Done: [67328/84203]
Validation Done: [67456/84203]
Validation Done: [67584/84203]
Validation Done: [67712/84203]
Validation Done: [67840/84203]
Validation Done: [67968/84203]
Validation Done: [68096/84203]
Validation Done: [68224/84203]
Validation Done: [68352/84203]
Validation Done: [68480/84203]
Validation Done: [68608/84203]
Validation Done: [68736/84203]
Validation Done: [68864/84203]
Validation Done: [68992/84203]
Validation Done: [69120/84203]
Validation Done: [69248/84203]
Validation Done: [69376/84203]
Validation Done: [69504/84203]
Validation Done: [69632/84203]
Validation Done: [69760/84203]
Validation Done: [69888/84203]
Validation Done: [70016/84203]
Validation Done: [70144/84203]
Validation Done: [70272/84203]
Validation Done: [70400/84203]
Validation Done: [70528/84203]
Validation Done: [70656/84203]
Validation Done: [70784/84203]
Validation Done: [70912/84203]
Validation Done: [71040/84203]
Validation Done: [71168/84203]
Validation Done: [71296/84203]
Validation Done: [71424/84203]
Validation Done: [71552/84203]
Validation Done: [71680/84203]
Validation Done: [71808/84203]
Validation Done: [71936/84203]
Validation Done: [72064/84203]
Validation Done: [72192/84203]
Validation Done: [72320/84203]
Validation Done: [72448/84203]
Validation Done: [72576/84203]
Validation Done: [72704/84203]
Validation Done: [72832/84203]
Validation Done: [72960/84203]
Validation Done: [73088/84203]
Validation Done: [73216/84203]
Validation Done: [73344/84203]
Validation Done: [73472/84203]
Validation Done: [73600/84203]
Validation Done: [73728/84203]
Validation Done: [73856/84203]
Validation Done: [73984/84203]
Validation Done: [74112/84203]
Validation Done: [74240/84203]
Validation Done: [74368/84203]
Validation Done: [74496/84203]
Validation Done: [74624/84203]
Validation Done: [74752/84203]
Validation Done: [74880/84203]
Validation Done: [75008/84203]
Validation Done: [75136/84203]
Validation Done: [75264/84203]
Validation Done: [75392/84203]
Validation Done: [75520/84203]
Validation Done: [75648/84203]
Validation Done: [75776/84203]
Validation Done: [75904/84203]
Validation Done: [76032/84203]
Validation Done: [76160/84203]
Validation Done: [76288/84203]
Validation Done: [76416/84203]
Validation Done: [76544/84203]
Validation Done: [76672/84203]
Validation Done: [76800/84203]
Validation Done: [76928/84203]
Validation Done: [77056/84203]
Validation Done: [77184/84203]
Validation Done: [77312/84203]
Validation Done: [77440/84203]
Validation Done: [77568/84203]
Validation Done: [77696/84203]
Validation Done: [77824/84203]
Validation Done: [77952/84203]
Validation Done: [78080/84203]
Validation Done: [78208/84203]
Validation Done: [78336/84203]
Validation Done: [78464/84203]
Validation Done: [78592/84203]
Validation Done: [78720/84203]
Validation Done: [78848/84203]
Validation Done: [78976/84203]
Validation Done: [79104/84203]
Validation Done: [79232/84203]
Validation Done: [79360/84203]
Validation Done: [79488/84203]
Validation Done: [79616/84203]
Validation Done: [79744/84203]
Validation Done: [79872/84203]
Validation Done: [80000/84203]
Validation Done: [80128/84203]
Validation Done: [80256/84203]
Validation Done: [80384/84203]
Validation Done: [80512/84203]
Validation Done: [80640/84203]
Validation Done: [80768/84203]
Validation Done: [80896/84203]
Validation Done: [81024/84203]
Validation Done: [81152/84203]
Validation Done: [81280/84203]
Validation Done: [81408/84203]
Validation Done: [81536/84203]
Validation Done: [81664/84203]
Validation Done: [81792/84203]
Validation Done: [81920/84203]
Validation Done: [82048/84203]
Validation Done: [82176/84203]
Validation Done: [82304/84203]
Validation Done: [82432/84203]
Validation Done: [82560/84203]
Validation Done: [82688/84203]
Validation Done: [82816/84203]
Validation Done: [82944/84203]
Validation Done: [83072/84203]
Validation Done: [83200/84203]
Validation Done: [83328/84203]
Validation Done: [83456/84203]
Validation Done: [83584/84203]
Validation Done: [83712/84203]
Validation Done: [83840/84203]
Validation Done: [83968/84203]
Validation Done: [84096/84203]
Validation Done: [70406/84203]
[Test] Epoch: 2 Test set: Average loss: 0.0021, Accuracy: 75309/84203 (89.44%)
{'accuracy': 0.8943743097039298, 'normal': {'precision': 0.8711284881938056, 'recall': 0.8042324297544058, 'support': 28258, 'f1-score': 0.83634490118868}, 'macro avg': {'precision': 0.887968958886544, 'recall': 0.8720688469265371, 'support': 84203, 'f1-score': 0.8791841987970404}, 'cancer': {'precision': 0.9048094295792825, 'recall': 0.9399052640986684, 'support': 55945, 'f1-score': 0.9220234964054007}, 'weighted avg': {'precision': 0.8935063163686985, 'recall': 0.8943743097039298, 'support': 84203, 'f1-score': 0.893270295882449}}
[Train] Epoch: 3 [128/387873]    Loss: 0.001907   Batch Acc: 91.41
[Train] Epoch: 3 [256/387873]    Loss: 0.001742   Batch Acc: 90.62
[Train] Epoch: 3 [384/387873]    Loss: 0.002070   Batch Acc: 89.06
[Train] Epoch: 3 [512/387873]    Loss: 0.002210   Batch Acc: 89.84
[Train] Epoch: 3 [640/387873]    Loss: 0.002377   Batch Acc: 87.50
[Train] Epoch: 3 [768/387873]    Loss: 0.002962   Batch Acc: 84.38
[Train] Epoch: 3 [896/387873]    Loss: 0.002142   Batch Acc: 89.06
[Train] Epoch: 3 [1024/387873]    Loss: 0.001956   Batch Acc: 88.28
[Train] Epoch: 3 [1152/387873]    Loss: 0.002076   Batch Acc: 87.50
[Train] Epoch: 3 [1280/387873]    Loss: 0.001457   Batch Acc: 96.88
[Train] Epoch: 3 [1408/387873]    Loss: 0.002052   Batch Acc: 91.41
[Train] Epoch: 3 [1536/387873]    Loss: 0.001636   Batch Acc: 92.19
[Train] Epoch: 3 [1664/387873]    Loss: 0.002224   Batch Acc: 89.06
[Train] Epoch: 3 [1792/387873]    Loss: 0.002009   Batch Acc: 88.28
[Train] Epoch: 3 [1920/387873]    Loss: 0.002187   Batch Acc: 87.50
[Train] Epoch: 3 [2048/387873]    Loss: 0.001985   Batch Acc: 89.06
[Train] Epoch: 3 [2176/387873]    Loss: 0.002111   Batch Acc: 90.62
[Train] Epoch: 3 [2304/387873]    Loss: 0.001758   Batch Acc: 92.97
[Train] Epoch: 3 [2432/387873]    Loss: 0.002364   Batch Acc: 89.84
[Train] Epoch: 3 [2560/387873]    Loss: 0.001798   Batch Acc: 90.62
[Train] Epoch: 3 [2688/387873]    Loss: 0.001800   Batch Acc: 93.75
[Train] Epoch: 3 [2816/387873]    Loss: 0.002216   Batch Acc: 89.84
[Train] Epoch: 3 [2944/387873]    Loss: 0.001621   Batch Acc: 89.84
[Train] Epoch: 3 [3072/387873]    Loss: 0.001796   Batch Acc: 91.41
[Train] Epoch: 3 [3200/387873]    Loss: 0.001809   Batch Acc: 91.41
[Train] Epoch: 3 [3328/387873]    Loss: 0.001886   Batch Acc: 91.41
[Train] Epoch: 3 [3456/387873]    Loss: 0.002442   Batch Acc: 87.50
[Train] Epoch: 3 [3584/387873]    Loss: 0.001781   Batch Acc: 90.62
[Train] Epoch: 3 [3712/387873]    Loss: 0.002714   Batch Acc: 84.38
[Train] Epoch: 3 [3840/387873]    Loss: 0.002162   Batch Acc: 86.72
[Train] Epoch: 3 [3968/387873]    Loss: 0.002072   Batch Acc: 88.28
[Train] Epoch: 3 [4096/387873]    Loss: 0.001965   Batch Acc: 86.72
[Train] Epoch: 3 [4224/387873]    Loss: 0.002003   Batch Acc: 89.84
[Train] Epoch: 3 [4352/387873]    Loss: 0.002141   Batch Acc: 86.72
[Train] Epoch: 3 [4480/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 3 [4608/387873]    Loss: 0.001714   Batch Acc: 91.41
[Train] Epoch: 3 [4736/387873]    Loss: 0.001664   Batch Acc: 92.19
[Train] Epoch: 3 [4864/387873]    Loss: 0.001343   Batch Acc: 95.31
[Train] Epoch: 3 [4992/387873]    Loss: 0.001803   Batch Acc: 90.62
[Train] Epoch: 3 [5120/387873]    Loss: 0.002423   Batch Acc: 87.50
[Train] Epoch: 3 [5248/387873]    Loss: 0.002200   Batch Acc: 90.62
[Train] Epoch: 3 [5376/387873]    Loss: 0.002163   Batch Acc: 89.84
[Train] Epoch: 3 [5504/387873]    Loss: 0.001277   Batch Acc: 92.97
[Train] Epoch: 3 [5632/387873]    Loss: 0.002314   Batch Acc: 85.16
[Train] Epoch: 3 [5760/387873]    Loss: 0.001848   Batch Acc: 91.41
[Train] Epoch: 3 [5888/387873]    Loss: 0.001801   Batch Acc: 89.06
[Train] Epoch: 3 [6016/387873]    Loss: 0.001705   Batch Acc: 89.84
[Train] Epoch: 3 [6144/387873]    Loss: 0.002421   Batch Acc: 85.16
[Train] Epoch: 3 [6272/387873]    Loss: 0.002418   Batch Acc: 86.72
[Train] Epoch: 3 [6400/387873]    Loss: 0.002047   Batch Acc: 91.41
[Train] Epoch: 3 [6528/387873]    Loss: 0.001895   Batch Acc: 89.06
[Train] Epoch: 3 [6656/387873]    Loss: 0.002275   Batch Acc: 85.16
[Train] Epoch: 3 [6784/387873]    Loss: 0.002456   Batch Acc: 85.94
[Train] Epoch: 3 [6912/387873]    Loss: 0.001578   Batch Acc: 93.75
[Train] Epoch: 3 [7040/387873]    Loss: 0.001907   Batch Acc: 91.41
[Train] Epoch: 3 [7168/387873]    Loss: 0.002296   Batch Acc: 89.84
[Train] Epoch: 3 [7296/387873]    Loss: 0.001804   Batch Acc: 90.62
[Train] Epoch: 3 [7424/387873]    Loss: 0.002398   Batch Acc: 87.50
[Train] Epoch: 3 [7552/387873]    Loss: 0.002644   Batch Acc: 83.59
[Train] Epoch: 3 [7680/387873]    Loss: 0.002197   Batch Acc: 85.16
[Train] Epoch: 3 [7808/387873]    Loss: 0.002044   Batch Acc: 91.41
[Train] Epoch: 3 [7936/387873]    Loss: 0.001335   Batch Acc: 93.75
[Train] Epoch: 3 [8064/387873]    Loss: 0.002141   Batch Acc: 87.50
[Train] Epoch: 3 [8192/387873]    Loss: 0.001670   Batch Acc: 91.41
[Train] Epoch: 3 [8320/387873]    Loss: 0.001941   Batch Acc: 90.62
[Train] Epoch: 3 [8448/387873]    Loss: 0.002219   Batch Acc: 86.72
[Train] Epoch: 3 [8576/387873]    Loss: 0.002615   Batch Acc: 84.38
[Train] Epoch: 3 [8704/387873]    Loss: 0.002326   Batch Acc: 85.94
[Train] Epoch: 3 [8832/387873]    Loss: 0.001339   Batch Acc: 95.31
[Train] Epoch: 3 [8960/387873]    Loss: 0.002584   Batch Acc: 84.38
[Train] Epoch: 3 [9088/387873]    Loss: 0.002121   Batch Acc: 89.06
[Train] Epoch: 3 [9216/387873]    Loss: 0.001918   Batch Acc: 87.50
[Train] Epoch: 3 [9344/387873]    Loss: 0.002193   Batch Acc: 87.50
[Train] Epoch: 3 [9472/387873]    Loss: 0.001874   Batch Acc: 90.62
[Train] Epoch: 3 [9600/387873]    Loss: 0.001907   Batch Acc: 92.19
[Train] Epoch: 3 [9728/387873]    Loss: 0.002101   Batch Acc: 88.28
[Train] Epoch: 3 [9856/387873]    Loss: 0.001809   Batch Acc: 91.41
[Train] Epoch: 3 [9984/387873]    Loss: 0.001659   Batch Acc: 92.97
[Train] Epoch: 3 [10112/387873]    Loss: 0.002227   Batch Acc: 91.41
[Train] Epoch: 3 [10240/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 3 [10368/387873]    Loss: 0.001823   Batch Acc: 89.84
[Train] Epoch: 3 [10496/387873]    Loss: 0.002016   Batch Acc: 90.62
[Train] Epoch: 3 [10624/387873]    Loss: 0.001922   Batch Acc: 89.06
[Train] Epoch: 3 [10752/387873]    Loss: 0.001740   Batch Acc: 93.75
[Train] Epoch: 3 [10880/387873]    Loss: 0.001584   Batch Acc: 94.53
[Train] Epoch: 3 [11008/387873]    Loss: 0.001923   Batch Acc: 86.72
[Train] Epoch: 3 [11136/387873]    Loss: 0.001775   Batch Acc: 89.84
[Train] Epoch: 3 [11264/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 3 [11392/387873]    Loss: 0.001868   Batch Acc: 90.62
[Train] Epoch: 3 [11520/387873]    Loss: 0.001796   Batch Acc: 92.19
[Train] Epoch: 3 [11648/387873]    Loss: 0.001880   Batch Acc: 91.41
[Train] Epoch: 3 [11776/387873]    Loss: 0.001529   Batch Acc: 94.53
[Train] Epoch: 3 [11904/387873]    Loss: 0.001798   Batch Acc: 89.84
[Train] Epoch: 3 [12032/387873]    Loss: 0.002400   Batch Acc: 85.94
[Train] Epoch: 3 [12160/387873]    Loss: 0.001671   Batch Acc: 92.97
[Train] Epoch: 3 [12288/387873]    Loss: 0.002633   Batch Acc: 82.81
[Train] Epoch: 3 [12416/387873]    Loss: 0.001892   Batch Acc: 88.28
[Train] Epoch: 3 [12544/387873]    Loss: 0.001804   Batch Acc: 92.19
[Train] Epoch: 3 [12672/387873]    Loss: 0.001658   Batch Acc: 92.19
[Train] Epoch: 3 [12800/387873]    Loss: 0.001537   Batch Acc: 92.19
[Train] Epoch: 3 [12928/387873]    Loss: 0.002105   Batch Acc: 86.72
[Train] Epoch: 3 [13056/387873]    Loss: 0.002557   Batch Acc: 87.50
[Train] Epoch: 3 [13184/387873]    Loss: 0.002183   Batch Acc: 89.84
[Train] Epoch: 3 [13312/387873]    Loss: 0.002470   Batch Acc: 85.94
[Train] Epoch: 3 [13440/387873]    Loss: 0.002463   Batch Acc: 85.16
[Train] Epoch: 3 [13568/387873]    Loss: 0.002242   Batch Acc: 86.72
[Train] Epoch: 3 [13696/387873]    Loss: 0.001884   Batch Acc: 89.06
[Train] Epoch: 3 [13824/387873]    Loss: 0.002479   Batch Acc: 86.72
[Train] Epoch: 3 [13952/387873]    Loss: 0.002550   Batch Acc: 85.94
[Train] Epoch: 3 [14080/387873]    Loss: 0.002174   Batch Acc: 87.50
[Train] Epoch: 3 [14208/387873]    Loss: 0.002030   Batch Acc: 86.72
[Train] Epoch: 3 [14336/387873]    Loss: 0.001738   Batch Acc: 88.28
[Train] Epoch: 3 [14464/387873]    Loss: 0.002455   Batch Acc: 84.38
[Train] Epoch: 3 [14592/387873]    Loss: 0.002061   Batch Acc: 90.62
[Train] Epoch: 3 [14720/387873]    Loss: 0.001883   Batch Acc: 92.97
[Train] Epoch: 3 [14848/387873]    Loss: 0.001850   Batch Acc: 91.41
[Train] Epoch: 3 [14976/387873]    Loss: 0.001684   Batch Acc: 92.97
[Train] Epoch: 3 [15104/387873]    Loss: 0.001649   Batch Acc: 94.53
[Train] Epoch: 3 [15232/387873]    Loss: 0.001706   Batch Acc: 89.84
[Train] Epoch: 3 [15360/387873]    Loss: 0.001725   Batch Acc: 92.97
[Train] Epoch: 3 [15488/387873]    Loss: 0.001930   Batch Acc: 89.84
[Train] Epoch: 3 [15616/387873]    Loss: 0.001952   Batch Acc: 91.41
[Train] Epoch: 3 [15744/387873]    Loss: 0.001982   Batch Acc: 89.84
[Train] Epoch: 3 [15872/387873]    Loss: 0.002296   Batch Acc: 88.28
[Train] Epoch: 3 [16000/387873]    Loss: 0.002491   Batch Acc: 85.16
[Train] Epoch: 3 [16128/387873]    Loss: 0.001756   Batch Acc: 92.97
[Train] Epoch: 3 [16256/387873]    Loss: 0.002262   Batch Acc: 89.84
[Train] Epoch: 3 [16384/387873]    Loss: 0.001765   Batch Acc: 90.62
[Train] Epoch: 3 [16512/387873]    Loss: 0.001930   Batch Acc: 89.84
[Train] Epoch: 3 [16640/387873]    Loss: 0.002277   Batch Acc: 86.72
[Train] Epoch: 3 [16768/387873]    Loss: 0.002113   Batch Acc: 89.06
[Train] Epoch: 3 [16896/387873]    Loss: 0.002304   Batch Acc: 88.28
[Train] Epoch: 3 [17024/387873]    Loss: 0.002346   Batch Acc: 86.72
[Train] Epoch: 3 [17152/387873]    Loss: 0.001984   Batch Acc: 90.62
[Train] Epoch: 3 [17280/387873]    Loss: 0.002245   Batch Acc: 85.16
[Train] Epoch: 3 [17408/387873]    Loss: 0.002377   Batch Acc: 85.94
[Train] Epoch: 3 [17536/387873]    Loss: 0.001630   Batch Acc: 92.19
[Train] Epoch: 3 [17664/387873]    Loss: 0.002563   Batch Acc: 85.94
[Train] Epoch: 3 [17792/387873]    Loss: 0.002099   Batch Acc: 89.84
[Train] Epoch: 3 [17920/387873]    Loss: 0.002205   Batch Acc: 90.62
[Train] Epoch: 3 [18048/387873]    Loss: 0.002011   Batch Acc: 88.28
[Train] Epoch: 3 [18176/387873]    Loss: 0.002272   Batch Acc: 85.94
[Train] Epoch: 3 [18304/387873]    Loss: 0.002239   Batch Acc: 88.28
[Train] Epoch: 3 [18432/387873]    Loss: 0.001879   Batch Acc: 89.06
[Train] Epoch: 3 [18560/387873]    Loss: 0.001872   Batch Acc: 92.97
[Train] Epoch: 3 [18688/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 3 [18816/387873]    Loss: 0.002102   Batch Acc: 89.84
[Train] Epoch: 3 [18944/387873]    Loss: 0.001873   Batch Acc: 89.06
[Train] Epoch: 3 [19072/387873]    Loss: 0.002050   Batch Acc: 88.28
[Train] Epoch: 3 [19200/387873]    Loss: 0.001911   Batch Acc: 91.41
[Train] Epoch: 3 [19328/387873]    Loss: 0.001635   Batch Acc: 92.19
[Train] Epoch: 3 [19456/387873]    Loss: 0.001842   Batch Acc: 88.28
[Train] Epoch: 3 [19584/387873]    Loss: 0.002042   Batch Acc: 89.84
[Train] Epoch: 3 [19712/387873]    Loss: 0.001496   Batch Acc: 93.75
[Train] Epoch: 3 [19840/387873]    Loss: 0.001834   Batch Acc: 92.19
[Train] Epoch: 3 [19968/387873]    Loss: 0.001627   Batch Acc: 89.06
[Train] Epoch: 3 [20096/387873]    Loss: 0.002762   Batch Acc: 85.94
[Train] Epoch: 3 [20224/387873]    Loss: 0.001942   Batch Acc: 91.41
[Train] Epoch: 3 [20352/387873]    Loss: 0.002351   Batch Acc: 89.06
[Train] Epoch: 3 [20480/387873]    Loss: 0.002486   Batch Acc: 85.94
[Train] Epoch: 3 [20608/387873]    Loss: 0.001963   Batch Acc: 90.62
[Train] Epoch: 3 [20736/387873]    Loss: 0.002068   Batch Acc: 88.28
[Train] Epoch: 3 [20864/387873]    Loss: 0.001812   Batch Acc: 92.97
[Train] Epoch: 3 [20992/387873]    Loss: 0.002168   Batch Acc: 87.50
[Train] Epoch: 3 [21120/387873]    Loss: 0.001869   Batch Acc: 89.84
[Train] Epoch: 3 [21248/387873]    Loss: 0.002290   Batch Acc: 85.94
[Train] Epoch: 3 [21376/387873]    Loss: 0.002148   Batch Acc: 92.19
[Train] Epoch: 3 [21504/387873]    Loss: 0.001567   Batch Acc: 92.19
[Train] Epoch: 3 [21632/387873]    Loss: 0.002494   Batch Acc: 85.94
[Train] Epoch: 3 [21760/387873]    Loss: 0.002107   Batch Acc: 89.06
[Train] Epoch: 3 [21888/387873]    Loss: 0.002140   Batch Acc: 85.16
[Train] Epoch: 3 [22016/387873]    Loss: 0.002060   Batch Acc: 88.28
[Train] Epoch: 3 [22144/387873]    Loss: 0.001614   Batch Acc: 92.97
[Train] Epoch: 3 [22272/387873]    Loss: 0.002203   Batch Acc: 89.06
[Train] Epoch: 3 [22400/387873]    Loss: 0.001454   Batch Acc: 96.09
[Train] Epoch: 3 [22528/387873]    Loss: 0.002012   Batch Acc: 91.41
[Train] Epoch: 3 [22656/387873]    Loss: 0.001733   Batch Acc: 91.41
[Train] Epoch: 3 [22784/387873]    Loss: 0.002077   Batch Acc: 89.84
[Train] Epoch: 3 [22912/387873]    Loss: 0.001808   Batch Acc: 88.28
[Train] Epoch: 3 [23040/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 3 [23168/387873]    Loss: 0.001640   Batch Acc: 92.19
[Train] Epoch: 3 [23296/387873]    Loss: 0.002098   Batch Acc: 88.28
[Train] Epoch: 3 [23424/387873]    Loss: 0.001670   Batch Acc: 92.19
[Train] Epoch: 3 [23552/387873]    Loss: 0.002223   Batch Acc: 85.94
[Train] Epoch: 3 [23680/387873]    Loss: 0.002023   Batch Acc: 90.62
[Train] Epoch: 3 [23808/387873]    Loss: 0.002554   Batch Acc: 84.38
[Train] Epoch: 3 [23936/387873]    Loss: 0.001964   Batch Acc: 91.41
[Train] Epoch: 3 [24064/387873]    Loss: 0.001931   Batch Acc: 88.28
[Train] Epoch: 3 [24192/387873]    Loss: 0.001380   Batch Acc: 94.53
[Train] Epoch: 3 [24320/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 3 [24448/387873]    Loss: 0.001756   Batch Acc: 90.62
[Train] Epoch: 3 [24576/387873]    Loss: 0.002010   Batch Acc: 89.84
[Train] Epoch: 3 [24704/387873]    Loss: 0.001744   Batch Acc: 93.75
[Train] Epoch: 3 [24832/387873]    Loss: 0.002333   Batch Acc: 85.16
[Train] Epoch: 3 [24960/387873]    Loss: 0.001428   Batch Acc: 93.75
[Train] Epoch: 3 [25088/387873]    Loss: 0.001621   Batch Acc: 91.41
[Train] Epoch: 3 [25216/387873]    Loss: 0.001532   Batch Acc: 92.97
[Train] Epoch: 3 [25344/387873]    Loss: 0.001609   Batch Acc: 92.19
[Train] Epoch: 3 [25472/387873]    Loss: 0.002044   Batch Acc: 87.50
[Train] Epoch: 3 [25600/387873]    Loss: 0.001696   Batch Acc: 89.84
[Train] Epoch: 3 [25728/387873]    Loss: 0.002768   Batch Acc: 87.50
[Train] Epoch: 3 [25856/387873]    Loss: 0.001733   Batch Acc: 92.19
[Train] Epoch: 3 [25984/387873]    Loss: 0.002323   Batch Acc: 86.72
[Train] Epoch: 3 [26112/387873]    Loss: 0.001946   Batch Acc: 92.97
[Train] Epoch: 3 [26240/387873]    Loss: 0.002278   Batch Acc: 87.50
[Train] Epoch: 3 [26368/387873]    Loss: 0.002137   Batch Acc: 89.06
[Train] Epoch: 3 [26496/387873]    Loss: 0.001979   Batch Acc: 88.28
[Train] Epoch: 3 [26624/387873]    Loss: 0.001788   Batch Acc: 90.62
[Train] Epoch: 3 [26752/387873]    Loss: 0.002084   Batch Acc: 89.84
[Train] Epoch: 3 [26880/387873]    Loss: 0.001795   Batch Acc: 89.06
[Train] Epoch: 3 [27008/387873]    Loss: 0.002176   Batch Acc: 89.84
[Train] Epoch: 3 [27136/387873]    Loss: 0.002339   Batch Acc: 87.50
[Train] Epoch: 3 [27264/387873]    Loss: 0.001518   Batch Acc: 93.75
[Train] Epoch: 3 [27392/387873]    Loss: 0.001552   Batch Acc: 92.97
[Train] Epoch: 3 [27520/387873]    Loss: 0.002606   Batch Acc: 88.28
[Train] Epoch: 3 [27648/387873]    Loss: 0.002547   Batch Acc: 85.94
[Train] Epoch: 3 [27776/387873]    Loss: 0.002538   Batch Acc: 87.50
[Train] Epoch: 3 [27904/387873]    Loss: 0.002243   Batch Acc: 89.84
[Train] Epoch: 3 [28032/387873]    Loss: 0.002198   Batch Acc: 86.72
[Train] Epoch: 3 [28160/387873]    Loss: 0.002257   Batch Acc: 89.84
[Train] Epoch: 3 [28288/387873]    Loss: 0.001904   Batch Acc: 91.41
[Train] Epoch: 3 [28416/387873]    Loss: 0.002527   Batch Acc: 85.94
[Train] Epoch: 3 [28544/387873]    Loss: 0.002312   Batch Acc: 88.28
[Train] Epoch: 3 [28672/387873]    Loss: 0.002082   Batch Acc: 90.62
[Train] Epoch: 3 [28800/387873]    Loss: 0.002392   Batch Acc: 87.50
[Train] Epoch: 3 [28928/387873]    Loss: 0.002667   Batch Acc: 83.59
[Train] Epoch: 3 [29056/387873]    Loss: 0.002109   Batch Acc: 85.94
[Train] Epoch: 3 [29184/387873]    Loss: 0.002229   Batch Acc: 86.72
[Train] Epoch: 3 [29312/387873]    Loss: 0.001474   Batch Acc: 92.97
[Train] Epoch: 3 [29440/387873]    Loss: 0.002836   Batch Acc: 82.03
[Train] Epoch: 3 [29568/387873]    Loss: 0.002061   Batch Acc: 86.72
[Train] Epoch: 3 [29696/387873]    Loss: 0.002032   Batch Acc: 90.62
[Train] Epoch: 3 [29824/387873]    Loss: 0.002018   Batch Acc: 85.94
[Train] Epoch: 3 [29952/387873]    Loss: 0.002059   Batch Acc: 86.72
[Train] Epoch: 3 [30080/387873]    Loss: 0.002226   Batch Acc: 86.72
[Train] Epoch: 3 [30208/387873]    Loss: 0.001992   Batch Acc: 89.06
[Train] Epoch: 3 [30336/387873]    Loss: 0.002066   Batch Acc: 89.84
[Train] Epoch: 3 [30464/387873]    Loss: 0.001799   Batch Acc: 90.62
[Train] Epoch: 3 [30592/387873]    Loss: 0.001775   Batch Acc: 92.19
[Train] Epoch: 3 [30720/387873]    Loss: 0.002443   Batch Acc: 85.16
[Train] Epoch: 3 [30848/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 3 [30976/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 3 [31104/387873]    Loss: 0.001992   Batch Acc: 89.84
[Train] Epoch: 3 [31232/387873]    Loss: 0.001792   Batch Acc: 93.75
[Train] Epoch: 3 [31360/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 3 [31488/387873]    Loss: 0.001903   Batch Acc: 89.06
[Train] Epoch: 3 [31616/387873]    Loss: 0.002033   Batch Acc: 92.19
[Train] Epoch: 3 [31744/387873]    Loss: 0.002407   Batch Acc: 86.72
[Train] Epoch: 3 [31872/387873]    Loss: 0.001707   Batch Acc: 89.06
[Train] Epoch: 3 [32000/387873]    Loss: 0.001894   Batch Acc: 91.41
[Train] Epoch: 3 [32128/387873]    Loss: 0.002176   Batch Acc: 86.72
[Train] Epoch: 3 [32256/387873]    Loss: 0.001862   Batch Acc: 89.06
[Train] Epoch: 3 [32384/387873]    Loss: 0.001991   Batch Acc: 88.28
[Train] Epoch: 3 [32512/387873]    Loss: 0.001562   Batch Acc: 91.41
[Train] Epoch: 3 [32640/387873]    Loss: 0.002177   Batch Acc: 86.72
[Train] Epoch: 3 [32768/387873]    Loss: 0.002298   Batch Acc: 88.28
[Train] Epoch: 3 [32896/387873]    Loss: 0.001710   Batch Acc: 88.28
[Train] Epoch: 3 [33024/387873]    Loss: 0.002285   Batch Acc: 89.06
[Train] Epoch: 3 [33152/387873]    Loss: 0.001988   Batch Acc: 89.06
[Train] Epoch: 3 [33280/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 3 [33408/387873]    Loss: 0.002018   Batch Acc: 88.28
[Train] Epoch: 3 [33536/387873]    Loss: 0.001972   Batch Acc: 90.62
[Train] Epoch: 3 [33664/387873]    Loss: 0.001534   Batch Acc: 92.97
[Train] Epoch: 3 [33792/387873]    Loss: 0.002219   Batch Acc: 85.16
[Train] Epoch: 3 [33920/387873]    Loss: 0.001863   Batch Acc: 89.84
[Train] Epoch: 3 [34048/387873]    Loss: 0.001836   Batch Acc: 89.06
[Train] Epoch: 3 [34176/387873]    Loss: 0.002359   Batch Acc: 89.06
[Train] Epoch: 3 [34304/387873]    Loss: 0.002117   Batch Acc: 87.50
[Train] Epoch: 3 [34432/387873]    Loss: 0.002213   Batch Acc: 89.06
[Train] Epoch: 3 [34560/387873]    Loss: 0.001454   Batch Acc: 95.31
[Train] Epoch: 3 [34688/387873]    Loss: 0.002355   Batch Acc: 88.28
[Train] Epoch: 3 [34816/387873]    Loss: 0.002181   Batch Acc: 89.84
[Train] Epoch: 3 [34944/387873]    Loss: 0.002545   Batch Acc: 82.81
[Train] Epoch: 3 [35072/387873]    Loss: 0.002504   Batch Acc: 87.50
[Train] Epoch: 3 [35200/387873]    Loss: 0.001511   Batch Acc: 92.97
[Train] Epoch: 3 [35328/387873]    Loss: 0.002276   Batch Acc: 88.28
[Train] Epoch: 3 [35456/387873]    Loss: 0.001637   Batch Acc: 89.84
[Train] Epoch: 3 [35584/387873]    Loss: 0.002334   Batch Acc: 87.50
[Train] Epoch: 3 [35712/387873]    Loss: 0.001982   Batch Acc: 89.84
[Train] Epoch: 3 [35840/387873]    Loss: 0.001548   Batch Acc: 92.19
[Train] Epoch: 3 [35968/387873]    Loss: 0.001614   Batch Acc: 92.19
[Train] Epoch: 3 [36096/387873]    Loss: 0.001781   Batch Acc: 91.41
[Train] Epoch: 3 [36224/387873]    Loss: 0.002166   Batch Acc: 89.84
[Train] Epoch: 3 [36352/387873]    Loss: 0.001894   Batch Acc: 90.62
[Train] Epoch: 3 [36480/387873]    Loss: 0.001927   Batch Acc: 91.41
[Train] Epoch: 3 [36608/387873]    Loss: 0.001572   Batch Acc: 92.97
[Train] Epoch: 3 [36736/387873]    Loss: 0.001607   Batch Acc: 90.62
[Train] Epoch: 3 [36864/387873]    Loss: 0.001750   Batch Acc: 90.62
[Train] Epoch: 3 [36992/387873]    Loss: 0.002264   Batch Acc: 87.50
[Train] Epoch: 3 [37120/387873]    Loss: 0.001823   Batch Acc: 94.53
[Train] Epoch: 3 [37248/387873]    Loss: 0.001664   Batch Acc: 91.41
[Train] Epoch: 3 [37376/387873]    Loss: 0.001868   Batch Acc: 92.19
[Train] Epoch: 3 [37504/387873]    Loss: 0.002351   Batch Acc: 87.50
[Train] Epoch: 3 [37632/387873]    Loss: 0.001618   Batch Acc: 93.75
[Train] Epoch: 3 [37760/387873]    Loss: 0.002142   Batch Acc: 90.62
[Train] Epoch: 3 [37888/387873]    Loss: 0.001841   Batch Acc: 90.62
[Train] Epoch: 3 [38016/387873]    Loss: 0.001986   Batch Acc: 89.84
[Train] Epoch: 3 [38144/387873]    Loss: 0.001815   Batch Acc: 89.06
[Train] Epoch: 3 [38272/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 3 [38400/387873]    Loss: 0.002276   Batch Acc: 87.50
[Train] Epoch: 3 [38528/387873]    Loss: 0.001901   Batch Acc: 89.84
[Train] Epoch: 3 [38656/387873]    Loss: 0.001429   Batch Acc: 95.31
[Train] Epoch: 3 [38784/387873]    Loss: 0.001940   Batch Acc: 90.62
[Train] Epoch: 3 [38912/387873]    Loss: 0.002025   Batch Acc: 90.62
[Train] Epoch: 3 [39040/387873]    Loss: 0.001843   Batch Acc: 91.41
[Train] Epoch: 3 [39168/387873]    Loss: 0.002405   Batch Acc: 82.81
[Train] Epoch: 3 [39296/387873]    Loss: 0.001957   Batch Acc: 91.41
[Train] Epoch: 3 [39424/387873]    Loss: 0.002079   Batch Acc: 86.72
[Train] Epoch: 3 [39552/387873]    Loss: 0.001683   Batch Acc: 92.19
[Train] Epoch: 3 [39680/387873]    Loss: 0.001940   Batch Acc: 90.62
[Train] Epoch: 3 [39808/387873]    Loss: 0.001738   Batch Acc: 90.62
[Train] Epoch: 3 [39936/387873]    Loss: 0.002373   Batch Acc: 87.50
[Train] Epoch: 3 [40064/387873]    Loss: 0.001611   Batch Acc: 92.19
[Train] Epoch: 3 [40192/387873]    Loss: 0.002164   Batch Acc: 89.06
[Train] Epoch: 3 [40320/387873]    Loss: 0.002076   Batch Acc: 88.28
[Train] Epoch: 3 [40448/387873]    Loss: 0.001564   Batch Acc: 92.19
[Train] Epoch: 3 [40576/387873]    Loss: 0.001843   Batch Acc: 91.41
[Train] Epoch: 3 [40704/387873]    Loss: 0.001918   Batch Acc: 90.62
[Train] Epoch: 3 [40832/387873]    Loss: 0.001865   Batch Acc: 90.62
[Train] Epoch: 3 [40960/387873]    Loss: 0.001824   Batch Acc: 90.62
[Train] Epoch: 3 [41088/387873]    Loss: 0.001992   Batch Acc: 90.62
[Train] Epoch: 3 [41216/387873]    Loss: 0.002145   Batch Acc: 87.50
[Train] Epoch: 3 [41344/387873]    Loss: 0.002526   Batch Acc: 84.38
[Train] Epoch: 3 [41472/387873]    Loss: 0.001720   Batch Acc: 91.41
[Train] Epoch: 3 [41600/387873]    Loss: 0.001632   Batch Acc: 89.84
[Train] Epoch: 3 [41728/387873]    Loss: 0.001491   Batch Acc: 93.75
[Train] Epoch: 3 [41856/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 3 [41984/387873]    Loss: 0.002249   Batch Acc: 85.94
[Train] Epoch: 3 [42112/387873]    Loss: 0.001663   Batch Acc: 92.19
[Train] Epoch: 3 [42240/387873]    Loss: 0.001645   Batch Acc: 90.62
[Train] Epoch: 3 [42368/387873]    Loss: 0.002145   Batch Acc: 89.06
[Train] Epoch: 3 [42496/387873]    Loss: 0.002154   Batch Acc: 85.94
[Train] Epoch: 3 [42624/387873]    Loss: 0.002073   Batch Acc: 91.41
[Train] Epoch: 3 [42752/387873]    Loss: 0.001386   Batch Acc: 92.97
[Train] Epoch: 3 [42880/387873]    Loss: 0.001883   Batch Acc: 90.62
[Train] Epoch: 3 [43008/387873]    Loss: 0.001880   Batch Acc: 86.72
[Train] Epoch: 3 [43136/387873]    Loss: 0.002204   Batch Acc: 89.06
[Train] Epoch: 3 [43264/387873]    Loss: 0.002210   Batch Acc: 89.06
[Train] Epoch: 3 [43392/387873]    Loss: 0.001738   Batch Acc: 92.97
[Train] Epoch: 3 [43520/387873]    Loss: 0.001670   Batch Acc: 91.41
[Train] Epoch: 3 [43648/387873]    Loss: 0.002355   Batch Acc: 84.38
[Train] Epoch: 3 [43776/387873]    Loss: 0.001459   Batch Acc: 92.97
[Train] Epoch: 3 [43904/387873]    Loss: 0.001701   Batch Acc: 92.97
[Train] Epoch: 3 [44032/387873]    Loss: 0.001729   Batch Acc: 91.41
[Train] Epoch: 3 [44160/387873]    Loss: 0.002340   Batch Acc: 85.94
[Train] Epoch: 3 [44288/387873]    Loss: 0.002381   Batch Acc: 88.28
[Train] Epoch: 3 [44416/387873]    Loss: 0.002120   Batch Acc: 87.50
[Train] Epoch: 3 [44544/387873]    Loss: 0.001950   Batch Acc: 90.62
[Train] Epoch: 3 [44672/387873]    Loss: 0.001456   Batch Acc: 95.31
[Train] Epoch: 3 [44800/387873]    Loss: 0.001615   Batch Acc: 92.19
[Train] Epoch: 3 [44928/387873]    Loss: 0.001911   Batch Acc: 92.19
[Train] Epoch: 3 [45056/387873]    Loss: 0.002390   Batch Acc: 89.06
[Train] Epoch: 3 [45184/387873]    Loss: 0.001499   Batch Acc: 91.41
[Train] Epoch: 3 [45312/387873]    Loss: 0.002188   Batch Acc: 86.72
[Train] Epoch: 3 [45440/387873]    Loss: 0.001756   Batch Acc: 90.62
[Train] Epoch: 3 [45568/387873]    Loss: 0.001798   Batch Acc: 92.19
[Train] Epoch: 3 [45696/387873]    Loss: 0.001607   Batch Acc: 90.62
[Train] Epoch: 3 [45824/387873]    Loss: 0.001912   Batch Acc: 89.06
[Train] Epoch: 3 [45952/387873]    Loss: 0.001727   Batch Acc: 92.19
[Train] Epoch: 3 [46080/387873]    Loss: 0.002225   Batch Acc: 89.06
[Train] Epoch: 3 [46208/387873]    Loss: 0.002348   Batch Acc: 88.28
[Train] Epoch: 3 [46336/387873]    Loss: 0.001938   Batch Acc: 88.28
[Train] Epoch: 3 [46464/387873]    Loss: 0.002328   Batch Acc: 88.28
[Train] Epoch: 3 [46592/387873]    Loss: 0.001792   Batch Acc: 92.97
[Train] Epoch: 3 [46720/387873]    Loss: 0.001777   Batch Acc: 92.19
[Train] Epoch: 3 [46848/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 3 [46976/387873]    Loss: 0.002066   Batch Acc: 90.62
[Train] Epoch: 3 [47104/387873]    Loss: 0.001701   Batch Acc: 92.19
[Train] Epoch: 3 [47232/387873]    Loss: 0.002443   Batch Acc: 85.94
[Train] Epoch: 3 [47360/387873]    Loss: 0.001807   Batch Acc: 90.62
[Train] Epoch: 3 [47488/387873]    Loss: 0.001878   Batch Acc: 89.84
[Train] Epoch: 3 [47616/387873]    Loss: 0.002650   Batch Acc: 84.38
[Train] Epoch: 3 [47744/387873]    Loss: 0.001808   Batch Acc: 90.62
[Train] Epoch: 3 [47872/387873]    Loss: 0.001636   Batch Acc: 92.97
[Train] Epoch: 3 [48000/387873]    Loss: 0.002076   Batch Acc: 88.28
[Train] Epoch: 3 [48128/387873]    Loss: 0.002354   Batch Acc: 85.94
[Train] Epoch: 3 [48256/387873]    Loss: 0.002073   Batch Acc: 89.06
[Train] Epoch: 3 [48384/387873]    Loss: 0.002073   Batch Acc: 90.62
[Train] Epoch: 3 [48512/387873]    Loss: 0.002271   Batch Acc: 85.94
[Train] Epoch: 3 [48640/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 3 [48768/387873]    Loss: 0.001843   Batch Acc: 90.62
[Train] Epoch: 3 [48896/387873]    Loss: 0.001829   Batch Acc: 89.06
[Train] Epoch: 3 [49024/387873]    Loss: 0.001879   Batch Acc: 90.62
[Train] Epoch: 3 [49152/387873]    Loss: 0.001885   Batch Acc: 91.41
[Train] Epoch: 3 [49280/387873]    Loss: 0.002511   Batch Acc: 89.06
[Train] Epoch: 3 [49408/387873]    Loss: 0.002432   Batch Acc: 83.59
[Train] Epoch: 3 [49536/387873]    Loss: 0.001910   Batch Acc: 89.84
[Train] Epoch: 3 [49664/387873]    Loss: 0.002227   Batch Acc: 89.06
[Train] Epoch: 3 [49792/387873]    Loss: 0.001559   Batch Acc: 93.75
[Train] Epoch: 3 [49920/387873]    Loss: 0.002258   Batch Acc: 87.50
[Train] Epoch: 3 [50048/387873]    Loss: 0.001863   Batch Acc: 89.06
[Train] Epoch: 3 [50176/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 3 [50304/387873]    Loss: 0.001729   Batch Acc: 90.62
[Train] Epoch: 3 [50432/387873]    Loss: 0.001918   Batch Acc: 91.41
[Train] Epoch: 3 [50560/387873]    Loss: 0.001624   Batch Acc: 92.97
[Train] Epoch: 3 [50688/387873]    Loss: 0.002266   Batch Acc: 86.72
[Train] Epoch: 3 [50816/387873]    Loss: 0.002199   Batch Acc: 89.06
[Train] Epoch: 3 [50944/387873]    Loss: 0.002306   Batch Acc: 86.72
[Train] Epoch: 3 [51072/387873]    Loss: 0.002213   Batch Acc: 89.84
[Train] Epoch: 3 [51200/387873]    Loss: 0.001733   Batch Acc: 89.84
[Train] Epoch: 3 [51328/387873]    Loss: 0.001796   Batch Acc: 89.06
[Train] Epoch: 3 [51456/387873]    Loss: 0.001728   Batch Acc: 89.84
[Train] Epoch: 3 [51584/387873]    Loss: 0.001703   Batch Acc: 92.19
[Train] Epoch: 3 [51712/387873]    Loss: 0.001800   Batch Acc: 93.75
[Train] Epoch: 3 [51840/387873]    Loss: 0.002035   Batch Acc: 88.28
[Train] Epoch: 3 [51968/387873]    Loss: 0.001992   Batch Acc: 91.41
[Train] Epoch: 3 [52096/387873]    Loss: 0.002466   Batch Acc: 83.59
[Train] Epoch: 3 [52224/387873]    Loss: 0.002040   Batch Acc: 89.84
[Train] Epoch: 3 [52352/387873]    Loss: 0.001779   Batch Acc: 92.19
[Train] Epoch: 3 [52480/387873]    Loss: 0.001904   Batch Acc: 90.62
[Train] Epoch: 3 [52608/387873]    Loss: 0.002467   Batch Acc: 86.72
[Train] Epoch: 3 [52736/387873]    Loss: 0.002171   Batch Acc: 89.06
[Train] Epoch: 3 [52864/387873]    Loss: 0.001866   Batch Acc: 90.62
[Train] Epoch: 3 [52992/387873]    Loss: 0.002152   Batch Acc: 86.72
[Train] Epoch: 3 [53120/387873]    Loss: 0.002269   Batch Acc: 87.50
[Train] Epoch: 3 [53248/387873]    Loss: 0.001989   Batch Acc: 88.28
[Train] Epoch: 3 [53376/387873]    Loss: 0.001867   Batch Acc: 89.06
[Train] Epoch: 3 [53504/387873]    Loss: 0.002358   Batch Acc: 83.59
[Train] Epoch: 3 [53632/387873]    Loss: 0.001793   Batch Acc: 89.06
[Train] Epoch: 3 [53760/387873]    Loss: 0.002250   Batch Acc: 87.50
[Train] Epoch: 3 [53888/387873]    Loss: 0.002166   Batch Acc: 90.62
[Train] Epoch: 3 [54016/387873]    Loss: 0.001976   Batch Acc: 87.50
[Train] Epoch: 3 [54144/387873]    Loss: 0.002098   Batch Acc: 86.72
[Train] Epoch: 3 [54272/387873]    Loss: 0.002000   Batch Acc: 89.06
[Train] Epoch: 3 [54400/387873]    Loss: 0.002255   Batch Acc: 88.28
[Train] Epoch: 3 [54528/387873]    Loss: 0.001652   Batch Acc: 91.41
[Train] Epoch: 3 [54656/387873]    Loss: 0.001954   Batch Acc: 89.06
[Train] Epoch: 3 [54784/387873]    Loss: 0.002353   Batch Acc: 85.16
[Train] Epoch: 3 [54912/387873]    Loss: 0.001542   Batch Acc: 93.75
[Train] Epoch: 3 [55040/387873]    Loss: 0.001951   Batch Acc: 88.28
[Train] Epoch: 3 [55168/387873]    Loss: 0.002286   Batch Acc: 89.06
[Train] Epoch: 3 [55296/387873]    Loss: 0.001685   Batch Acc: 90.62
[Train] Epoch: 3 [55424/387873]    Loss: 0.001824   Batch Acc: 89.06
[Train] Epoch: 3 [55552/387873]    Loss: 0.002365   Batch Acc: 85.16
[Train] Epoch: 3 [55680/387873]    Loss: 0.001722   Batch Acc: 92.97
[Train] Epoch: 3 [55808/387873]    Loss: 0.002314   Batch Acc: 85.94
[Train] Epoch: 3 [55936/387873]    Loss: 0.001839   Batch Acc: 91.41
[Train] Epoch: 3 [56064/387873]    Loss: 0.002250   Batch Acc: 88.28
[Train] Epoch: 3 [56192/387873]    Loss: 0.002352   Batch Acc: 87.50
[Train] Epoch: 3 [56320/387873]    Loss: 0.001684   Batch Acc: 89.84
[Train] Epoch: 3 [56448/387873]    Loss: 0.001608   Batch Acc: 89.84
[Train] Epoch: 3 [56576/387873]    Loss: 0.002513   Batch Acc: 86.72
[Train] Epoch: 3 [56704/387873]    Loss: 0.002043   Batch Acc: 89.84
[Train] Epoch: 3 [56832/387873]    Loss: 0.002436   Batch Acc: 84.38
[Train] Epoch: 3 [56960/387873]    Loss: 0.002466   Batch Acc: 85.94
[Train] Epoch: 3 [57088/387873]    Loss: 0.002148   Batch Acc: 88.28
[Train] Epoch: 3 [57216/387873]    Loss: 0.001730   Batch Acc: 91.41
[Train] Epoch: 3 [57344/387873]    Loss: 0.002352   Batch Acc: 91.41
[Train] Epoch: 3 [57472/387873]    Loss: 0.002086   Batch Acc: 85.94
[Train] Epoch: 3 [57600/387873]    Loss: 0.002288   Batch Acc: 87.50
[Train] Epoch: 3 [57728/387873]    Loss: 0.001834   Batch Acc: 92.19
[Train] Epoch: 3 [57856/387873]    Loss: 0.002499   Batch Acc: 86.72
[Train] Epoch: 3 [57984/387873]    Loss: 0.001617   Batch Acc: 89.84
[Train] Epoch: 3 [58112/387873]    Loss: 0.001906   Batch Acc: 88.28
[Train] Epoch: 3 [58240/387873]    Loss: 0.001545   Batch Acc: 92.97
[Train] Epoch: 3 [58368/387873]    Loss: 0.001764   Batch Acc: 91.41
[Train] Epoch: 3 [58496/387873]    Loss: 0.001894   Batch Acc: 89.84
[Train] Epoch: 3 [58624/387873]    Loss: 0.001193   Batch Acc: 96.09
[Train] Epoch: 3 [58752/387873]    Loss: 0.002411   Batch Acc: 87.50
[Train] Epoch: 3 [58880/387873]    Loss: 0.002108   Batch Acc: 89.06
[Train] Epoch: 3 [59008/387873]    Loss: 0.002026   Batch Acc: 88.28
[Train] Epoch: 3 [59136/387873]    Loss: 0.002554   Batch Acc: 85.94
[Train] Epoch: 3 [59264/387873]    Loss: 0.002289   Batch Acc: 89.84
[Train] Epoch: 3 [59392/387873]    Loss: 0.001731   Batch Acc: 90.62
[Train] Epoch: 3 [59520/387873]    Loss: 0.001795   Batch Acc: 89.84
[Train] Epoch: 3 [59648/387873]    Loss: 0.001974   Batch Acc: 89.06
[Train] Epoch: 3 [59776/387873]    Loss: 0.001988   Batch Acc: 89.84
[Train] Epoch: 3 [59904/387873]    Loss: 0.001492   Batch Acc: 94.53
[Train] Epoch: 3 [60032/387873]    Loss: 0.001957   Batch Acc: 90.62
[Train] Epoch: 3 [60160/387873]    Loss: 0.001856   Batch Acc: 89.84
[Train] Epoch: 3 [60288/387873]    Loss: 0.001619   Batch Acc: 92.19
[Train] Epoch: 3 [60416/387873]    Loss: 0.002383   Batch Acc: 89.84
[Train] Epoch: 3 [60544/387873]    Loss: 0.001723   Batch Acc: 92.19
[Train] Epoch: 3 [60672/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 3 [60800/387873]    Loss: 0.001474   Batch Acc: 93.75
[Train] Epoch: 3 [60928/387873]    Loss: 0.001771   Batch Acc: 91.41
[Train] Epoch: 3 [61056/387873]    Loss: 0.002067   Batch Acc: 88.28
[Train] Epoch: 3 [61184/387873]    Loss: 0.001825   Batch Acc: 90.62
[Train] Epoch: 3 [61312/387873]    Loss: 0.001733   Batch Acc: 94.53
[Train] Epoch: 3 [61440/387873]    Loss: 0.001891   Batch Acc: 92.19
[Train] Epoch: 3 [61568/387873]    Loss: 0.001984   Batch Acc: 89.06
[Train] Epoch: 3 [61696/387873]    Loss: 0.001716   Batch Acc: 93.75
[Train] Epoch: 3 [61824/387873]    Loss: 0.002511   Batch Acc: 87.50
[Train] Epoch: 3 [61952/387873]    Loss: 0.002161   Batch Acc: 86.72
[Train] Epoch: 3 [62080/387873]    Loss: 0.001916   Batch Acc: 92.19
[Train] Epoch: 3 [62208/387873]    Loss: 0.002259   Batch Acc: 87.50
[Train] Epoch: 3 [62336/387873]    Loss: 0.001985   Batch Acc: 89.06
[Train] Epoch: 3 [62464/387873]    Loss: 0.002335   Batch Acc: 86.72
[Train] Epoch: 3 [62592/387873]    Loss: 0.001728   Batch Acc: 91.41
[Train] Epoch: 3 [62720/387873]    Loss: 0.002274   Batch Acc: 88.28
[Train] Epoch: 3 [62848/387873]    Loss: 0.002378   Batch Acc: 88.28
[Train] Epoch: 3 [62976/387873]    Loss: 0.001520   Batch Acc: 94.53
[Train] Epoch: 3 [63104/387873]    Loss: 0.002325   Batch Acc: 86.72
[Train] Epoch: 3 [63232/387873]    Loss: 0.002092   Batch Acc: 87.50
[Train] Epoch: 3 [63360/387873]    Loss: 0.001978   Batch Acc: 88.28
[Train] Epoch: 3 [63488/387873]    Loss: 0.001877   Batch Acc: 91.41
[Train] Epoch: 3 [63616/387873]    Loss: 0.001232   Batch Acc: 96.09
[Train] Epoch: 3 [63744/387873]    Loss: 0.001360   Batch Acc: 95.31
[Train] Epoch: 3 [63872/387873]    Loss: 0.002172   Batch Acc: 89.84
[Train] Epoch: 3 [64000/387873]    Loss: 0.002148   Batch Acc: 89.84
[Train] Epoch: 3 [64128/387873]    Loss: 0.001758   Batch Acc: 92.97
[Train] Epoch: 3 [64256/387873]    Loss: 0.002065   Batch Acc: 89.84
[Train] Epoch: 3 [64384/387873]    Loss: 0.002001   Batch Acc: 89.06
[Train] Epoch: 3 [64512/387873]    Loss: 0.002489   Batch Acc: 85.94
[Train] Epoch: 3 [64640/387873]    Loss: 0.002591   Batch Acc: 86.72
[Train] Epoch: 3 [64768/387873]    Loss: 0.001474   Batch Acc: 95.31
[Train] Epoch: 3 [64896/387873]    Loss: 0.001581   Batch Acc: 92.19
[Train] Epoch: 3 [65024/387873]    Loss: 0.001730   Batch Acc: 92.19
[Train] Epoch: 3 [65152/387873]    Loss: 0.002025   Batch Acc: 88.28
[Train] Epoch: 3 [65280/387873]    Loss: 0.001892   Batch Acc: 87.50
[Train] Epoch: 3 [65408/387873]    Loss: 0.002640   Batch Acc: 86.72
[Train] Epoch: 3 [65536/387873]    Loss: 0.001688   Batch Acc: 93.75
[Train] Epoch: 3 [65664/387873]    Loss: 0.002810   Batch Acc: 83.59
[Train] Epoch: 3 [65792/387873]    Loss: 0.002174   Batch Acc: 87.50
[Train] Epoch: 3 [65920/387873]    Loss: 0.001956   Batch Acc: 88.28
[Train] Epoch: 3 [66048/387873]    Loss: 0.001610   Batch Acc: 93.75
[Train] Epoch: 3 [66176/387873]    Loss: 0.001784   Batch Acc: 90.62
[Train] Epoch: 3 [66304/387873]    Loss: 0.001628   Batch Acc: 90.62
[Train] Epoch: 3 [66432/387873]    Loss: 0.002131   Batch Acc: 88.28
[Train] Epoch: 3 [66560/387873]    Loss: 0.002739   Batch Acc: 83.59
[Train] Epoch: 3 [66688/387873]    Loss: 0.002317   Batch Acc: 87.50
[Train] Epoch: 3 [66816/387873]    Loss: 0.002763   Batch Acc: 85.16
[Train] Epoch: 3 [66944/387873]    Loss: 0.001723   Batch Acc: 92.97
[Train] Epoch: 3 [67072/387873]    Loss: 0.001994   Batch Acc: 89.06
[Train] Epoch: 3 [67200/387873]    Loss: 0.001870   Batch Acc: 92.19
[Train] Epoch: 3 [67328/387873]    Loss: 0.001912   Batch Acc: 89.84
[Train] Epoch: 3 [67456/387873]    Loss: 0.001910   Batch Acc: 87.50
[Train] Epoch: 3 [67584/387873]    Loss: 0.002236   Batch Acc: 91.41
[Train] Epoch: 3 [67712/387873]    Loss: 0.002002   Batch Acc: 90.62
[Train] Epoch: 3 [67840/387873]    Loss: 0.001884   Batch Acc: 89.84
[Train] Epoch: 3 [67968/387873]    Loss: 0.002340   Batch Acc: 87.50
[Train] Epoch: 3 [68096/387873]    Loss: 0.001922   Batch Acc: 92.19
[Train] Epoch: 3 [68224/387873]    Loss: 0.001662   Batch Acc: 91.41
[Train] Epoch: 3 [68352/387873]    Loss: 0.001878   Batch Acc: 89.06
[Train] Epoch: 3 [68480/387873]    Loss: 0.002678   Batch Acc: 83.59
[Train] Epoch: 3 [68608/387873]    Loss: 0.001721   Batch Acc: 92.19
[Train] Epoch: 3 [68736/387873]    Loss: 0.002153   Batch Acc: 85.16
[Train] Epoch: 3 [68864/387873]    Loss: 0.001672   Batch Acc: 91.41
[Train] Epoch: 3 [68992/387873]    Loss: 0.002442   Batch Acc: 85.94
[Train] Epoch: 3 [69120/387873]    Loss: 0.001665   Batch Acc: 92.97
[Train] Epoch: 3 [69248/387873]    Loss: 0.001726   Batch Acc: 92.19
[Train] Epoch: 3 [69376/387873]    Loss: 0.002197   Batch Acc: 85.94
[Train] Epoch: 3 [69504/387873]    Loss: 0.002022   Batch Acc: 89.84
[Train] Epoch: 3 [69632/387873]    Loss: 0.001899   Batch Acc: 92.19
[Train] Epoch: 3 [69760/387873]    Loss: 0.002015   Batch Acc: 89.06
[Train] Epoch: 3 [69888/387873]    Loss: 0.001671   Batch Acc: 94.53
[Train] Epoch: 3 [70016/387873]    Loss: 0.002266   Batch Acc: 89.06
[Train] Epoch: 3 [70144/387873]    Loss: 0.002027   Batch Acc: 89.84
[Train] Epoch: 3 [70272/387873]    Loss: 0.002689   Batch Acc: 83.59
[Train] Epoch: 3 [70400/387873]    Loss: 0.002237   Batch Acc: 86.72
[Train] Epoch: 3 [70528/387873]    Loss: 0.002151   Batch Acc: 88.28
[Train] Epoch: 3 [70656/387873]    Loss: 0.002083   Batch Acc: 89.84
[Train] Epoch: 3 [70784/387873]    Loss: 0.001624   Batch Acc: 90.62
[Train] Epoch: 3 [70912/387873]    Loss: 0.002571   Batch Acc: 83.59
[Train] Epoch: 3 [71040/387873]    Loss: 0.001511   Batch Acc: 92.97
[Train] Epoch: 3 [71168/387873]    Loss: 0.002199   Batch Acc: 85.16
[Train] Epoch: 3 [71296/387873]    Loss: 0.002203   Batch Acc: 85.94
[Train] Epoch: 3 [71424/387873]    Loss: 0.001734   Batch Acc: 89.84
[Train] Epoch: 3 [71552/387873]    Loss: 0.001690   Batch Acc: 92.19
[Train] Epoch: 3 [71680/387873]    Loss: 0.001729   Batch Acc: 89.84
[Train] Epoch: 3 [71808/387873]    Loss: 0.002985   Batch Acc: 83.59
[Train] Epoch: 3 [71936/387873]    Loss: 0.001832   Batch Acc: 90.62
[Train] Epoch: 3 [72064/387873]    Loss: 0.001721   Batch Acc: 92.19
[Train] Epoch: 3 [72192/387873]    Loss: 0.001972   Batch Acc: 92.19
[Train] Epoch: 3 [72320/387873]    Loss: 0.001714   Batch Acc: 88.28
[Train] Epoch: 3 [72448/387873]    Loss: 0.002549   Batch Acc: 85.94
[Train] Epoch: 3 [72576/387873]    Loss: 0.002134   Batch Acc: 89.84
[Train] Epoch: 3 [72704/387873]    Loss: 0.001690   Batch Acc: 92.97
[Train] Epoch: 3 [72832/387873]    Loss: 0.001888   Batch Acc: 90.62
[Train] Epoch: 3 [72960/387873]    Loss: 0.001582   Batch Acc: 93.75
[Train] Epoch: 3 [73088/387873]    Loss: 0.002424   Batch Acc: 87.50
[Train] Epoch: 3 [73216/387873]    Loss: 0.001804   Batch Acc: 91.41
[Train] Epoch: 3 [73344/387873]    Loss: 0.002503   Batch Acc: 87.50
[Train] Epoch: 3 [73472/387873]    Loss: 0.001952   Batch Acc: 90.62
[Train] Epoch: 3 [73600/387873]    Loss: 0.001726   Batch Acc: 91.41
[Train] Epoch: 3 [73728/387873]    Loss: 0.002794   Batch Acc: 83.59
[Train] Epoch: 3 [73856/387873]    Loss: 0.001711   Batch Acc: 92.19
[Train] Epoch: 3 [73984/387873]    Loss: 0.001911   Batch Acc: 88.28
[Train] Epoch: 3 [74112/387873]    Loss: 0.002358   Batch Acc: 85.16
[Train] Epoch: 3 [74240/387873]    Loss: 0.001910   Batch Acc: 90.62
[Train] Epoch: 3 [74368/387873]    Loss: 0.002270   Batch Acc: 87.50
[Train] Epoch: 3 [74496/387873]    Loss: 0.003116   Batch Acc: 83.59
[Train] Epoch: 3 [74624/387873]    Loss: 0.002257   Batch Acc: 89.06
[Train] Epoch: 3 [74752/387873]    Loss: 0.001779   Batch Acc: 91.41
[Train] Epoch: 3 [74880/387873]    Loss: 0.002402   Batch Acc: 84.38
[Train] Epoch: 3 [75008/387873]    Loss: 0.001807   Batch Acc: 90.62
[Train] Epoch: 3 [75136/387873]    Loss: 0.002060   Batch Acc: 90.62
[Train] Epoch: 3 [75264/387873]    Loss: 0.002303   Batch Acc: 85.94
[Train] Epoch: 3 [75392/387873]    Loss: 0.001828   Batch Acc: 91.41
[Train] Epoch: 3 [75520/387873]    Loss: 0.001948   Batch Acc: 89.84
[Train] Epoch: 3 [75648/387873]    Loss: 0.001936   Batch Acc: 91.41
[Train] Epoch: 3 [75776/387873]    Loss: 0.002153   Batch Acc: 86.72
[Train] Epoch: 3 [75904/387873]    Loss: 0.001807   Batch Acc: 91.41
[Train] Epoch: 3 [76032/387873]    Loss: 0.001719   Batch Acc: 90.62
[Train] Epoch: 3 [76160/387873]    Loss: 0.001840   Batch Acc: 90.62
[Train] Epoch: 3 [76288/387873]    Loss: 0.002149   Batch Acc: 87.50
[Train] Epoch: 3 [76416/387873]    Loss: 0.001559   Batch Acc: 92.97
[Train] Epoch: 3 [76544/387873]    Loss: 0.001860   Batch Acc: 89.84
[Train] Epoch: 3 [76672/387873]    Loss: 0.001789   Batch Acc: 93.75
[Train] Epoch: 3 [76800/387873]    Loss: 0.001638   Batch Acc: 89.84
[Train] Epoch: 3 [76928/387873]    Loss: 0.002207   Batch Acc: 89.06
[Train] Epoch: 3 [77056/387873]    Loss: 0.001989   Batch Acc: 89.84
[Train] Epoch: 3 [77184/387873]    Loss: 0.001400   Batch Acc: 94.53
[Train] Epoch: 3 [77312/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 3 [77440/387873]    Loss: 0.002431   Batch Acc: 85.94
[Train] Epoch: 3 [77568/387873]    Loss: 0.001443   Batch Acc: 93.75
[Train] Epoch: 3 [77696/387873]    Loss: 0.001815   Batch Acc: 90.62
[Train] Epoch: 3 [77824/387873]    Loss: 0.002473   Batch Acc: 86.72
[Train] Epoch: 3 [77952/387873]    Loss: 0.001721   Batch Acc: 89.06
[Train] Epoch: 3 [78080/387873]    Loss: 0.002267   Batch Acc: 85.94
[Train] Epoch: 3 [78208/387873]    Loss: 0.002523   Batch Acc: 88.28
[Train] Epoch: 3 [78336/387873]    Loss: 0.002227   Batch Acc: 84.38
[Train] Epoch: 3 [78464/387873]    Loss: 0.001793   Batch Acc: 89.06
[Train] Epoch: 3 [78592/387873]    Loss: 0.001850   Batch Acc: 89.06
[Train] Epoch: 3 [78720/387873]    Loss: 0.001895   Batch Acc: 88.28
[Train] Epoch: 3 [78848/387873]    Loss: 0.001864   Batch Acc: 90.62
[Train] Epoch: 3 [78976/387873]    Loss: 0.002416   Batch Acc: 87.50
[Train] Epoch: 3 [79104/387873]    Loss: 0.001742   Batch Acc: 91.41
[Train] Epoch: 3 [79232/387873]    Loss: 0.001763   Batch Acc: 91.41
[Train] Epoch: 3 [79360/387873]    Loss: 0.002412   Batch Acc: 85.16
[Train] Epoch: 3 [79488/387873]    Loss: 0.002044   Batch Acc: 89.84
[Train] Epoch: 3 [79616/387873]    Loss: 0.002238   Batch Acc: 86.72
[Train] Epoch: 3 [79744/387873]    Loss: 0.002327   Batch Acc: 86.72
[Train] Epoch: 3 [79872/387873]    Loss: 0.001522   Batch Acc: 97.66
[Train] Epoch: 3 [80000/387873]    Loss: 0.001861   Batch Acc: 91.41
[Train] Epoch: 3 [80128/387873]    Loss: 0.002015   Batch Acc: 89.06
[Train] Epoch: 3 [80256/387873]    Loss: 0.002088   Batch Acc: 87.50
[Train] Epoch: 3 [80384/387873]    Loss: 0.001685   Batch Acc: 93.75
[Train] Epoch: 3 [80512/387873]    Loss: 0.001853   Batch Acc: 93.75
[Train] Epoch: 3 [80640/387873]    Loss: 0.001726   Batch Acc: 91.41
[Train] Epoch: 3 [80768/387873]    Loss: 0.002591   Batch Acc: 86.72
[Train] Epoch: 3 [80896/387873]    Loss: 0.002105   Batch Acc: 88.28
[Train] Epoch: 3 [81024/387873]    Loss: 0.002026   Batch Acc: 89.84
[Train] Epoch: 3 [81152/387873]    Loss: 0.002009   Batch Acc: 88.28
[Train] Epoch: 3 [81280/387873]    Loss: 0.001917   Batch Acc: 91.41
[Train] Epoch: 3 [81408/387873]    Loss: 0.002290   Batch Acc: 85.94
[Train] Epoch: 3 [81536/387873]    Loss: 0.001548   Batch Acc: 92.19
[Train] Epoch: 3 [81664/387873]    Loss: 0.003217   Batch Acc: 82.03
[Train] Epoch: 3 [81792/387873]    Loss: 0.002455   Batch Acc: 86.72
[Train] Epoch: 3 [81920/387873]    Loss: 0.002359   Batch Acc: 85.94
[Train] Epoch: 3 [82048/387873]    Loss: 0.001908   Batch Acc: 88.28
[Train] Epoch: 3 [82176/387873]    Loss: 0.002468   Batch Acc: 87.50
[Train] Epoch: 3 [82304/387873]    Loss: 0.002090   Batch Acc: 87.50
[Train] Epoch: 3 [82432/387873]    Loss: 0.002603   Batch Acc: 79.69
[Train] Epoch: 3 [82560/387873]    Loss: 0.002078   Batch Acc: 89.06
[Train] Epoch: 3 [82688/387873]    Loss: 0.002466   Batch Acc: 89.06
[Train] Epoch: 3 [82816/387873]    Loss: 0.001780   Batch Acc: 89.06
[Train] Epoch: 3 [82944/387873]    Loss: 0.001771   Batch Acc: 89.84
[Train] Epoch: 3 [83072/387873]    Loss: 0.002155   Batch Acc: 86.72
[Train] Epoch: 3 [83200/387873]    Loss: 0.001890   Batch Acc: 91.41
[Train] Epoch: 3 [83328/387873]    Loss: 0.002015   Batch Acc: 92.19
[Train] Epoch: 3 [83456/387873]    Loss: 0.002057   Batch Acc: 86.72
[Train] Epoch: 3 [83584/387873]    Loss: 0.001970   Batch Acc: 91.41
[Train] Epoch: 3 [83712/387873]    Loss: 0.002037   Batch Acc: 89.84
[Train] Epoch: 3 [83840/387873]    Loss: 0.001759   Batch Acc: 93.75
[Train] Epoch: 3 [83968/387873]    Loss: 0.001892   Batch Acc: 89.06
[Train] Epoch: 3 [84096/387873]    Loss: 0.002396   Batch Acc: 83.59
[Train] Epoch: 3 [84224/387873]    Loss: 0.002298   Batch Acc: 85.94
[Train] Epoch: 3 [84352/387873]    Loss: 0.002451   Batch Acc: 87.50
[Train] Epoch: 3 [84480/387873]    Loss: 0.001712   Batch Acc: 92.19
[Train] Epoch: 3 [84608/387873]    Loss: 0.002107   Batch Acc: 86.72
[Train] Epoch: 3 [84736/387873]    Loss: 0.001749   Batch Acc: 93.75
[Train] Epoch: 3 [84864/387873]    Loss: 0.002059   Batch Acc: 90.62
[Train] Epoch: 3 [84992/387873]    Loss: 0.001605   Batch Acc: 91.41
[Train] Epoch: 3 [85120/387873]    Loss: 0.001641   Batch Acc: 89.84
[Train] Epoch: 3 [85248/387873]    Loss: 0.002300   Batch Acc: 85.94
[Train] Epoch: 3 [85376/387873]    Loss: 0.002181   Batch Acc: 87.50
[Train] Epoch: 3 [85504/387873]    Loss: 0.001772   Batch Acc: 91.41
[Train] Epoch: 3 [85632/387873]    Loss: 0.002130   Batch Acc: 92.19
[Train] Epoch: 3 [85760/387873]    Loss: 0.001680   Batch Acc: 89.84
[Train] Epoch: 3 [85888/387873]    Loss: 0.001968   Batch Acc: 90.62
[Train] Epoch: 3 [86016/387873]    Loss: 0.001783   Batch Acc: 92.19
[Train] Epoch: 3 [86144/387873]    Loss: 0.001956   Batch Acc: 89.06
[Train] Epoch: 3 [86272/387873]    Loss: 0.001972   Batch Acc: 88.28
[Train] Epoch: 3 [86400/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 3 [86528/387873]    Loss: 0.002732   Batch Acc: 83.59
[Train] Epoch: 3 [86656/387873]    Loss: 0.001864   Batch Acc: 92.19
[Train] Epoch: 3 [86784/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 3 [86912/387873]    Loss: 0.001946   Batch Acc: 92.97
[Train] Epoch: 3 [87040/387873]    Loss: 0.001864   Batch Acc: 89.84
[Train] Epoch: 3 [87168/387873]    Loss: 0.002096   Batch Acc: 89.06
[Train] Epoch: 3 [87296/387873]    Loss: 0.002282   Batch Acc: 89.06
[Train] Epoch: 3 [87424/387873]    Loss: 0.002416   Batch Acc: 90.62
[Train] Epoch: 3 [87552/387873]    Loss: 0.002122   Batch Acc: 85.16
[Train] Epoch: 3 [87680/387873]    Loss: 0.002680   Batch Acc: 85.94
[Train] Epoch: 3 [87808/387873]    Loss: 0.001401   Batch Acc: 95.31
[Train] Epoch: 3 [87936/387873]    Loss: 0.001779   Batch Acc: 94.53
[Train] Epoch: 3 [88064/387873]    Loss: 0.001848   Batch Acc: 91.41
[Train] Epoch: 3 [88192/387873]    Loss: 0.001427   Batch Acc: 93.75
[Train] Epoch: 3 [88320/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 3 [88448/387873]    Loss: 0.002375   Batch Acc: 85.94
[Train] Epoch: 3 [88576/387873]    Loss: 0.002393   Batch Acc: 87.50
[Train] Epoch: 3 [88704/387873]    Loss: 0.001619   Batch Acc: 92.97
[Train] Epoch: 3 [88832/387873]    Loss: 0.001487   Batch Acc: 92.97
[Train] Epoch: 3 [88960/387873]    Loss: 0.001799   Batch Acc: 90.62
[Train] Epoch: 3 [89088/387873]    Loss: 0.001645   Batch Acc: 90.62
[Train] Epoch: 3 [89216/387873]    Loss: 0.002757   Batch Acc: 87.50
[Train] Epoch: 3 [89344/387873]    Loss: 0.001875   Batch Acc: 89.06
[Train] Epoch: 3 [89472/387873]    Loss: 0.001656   Batch Acc: 89.84
[Train] Epoch: 3 [89600/387873]    Loss: 0.002537   Batch Acc: 85.94
[Train] Epoch: 3 [89728/387873]    Loss: 0.001696   Batch Acc: 89.84
[Train] Epoch: 3 [89856/387873]    Loss: 0.002419   Batch Acc: 86.72
[Train] Epoch: 3 [89984/387873]    Loss: 0.001725   Batch Acc: 92.19
[Train] Epoch: 3 [90112/387873]    Loss: 0.001672   Batch Acc: 90.62
[Train] Epoch: 3 [90240/387873]    Loss: 0.001789   Batch Acc: 91.41
[Train] Epoch: 3 [90368/387873]    Loss: 0.001778   Batch Acc: 89.06
[Train] Epoch: 3 [90496/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 3 [90624/387873]    Loss: 0.002731   Batch Acc: 82.81
[Train] Epoch: 3 [90752/387873]    Loss: 0.002132   Batch Acc: 89.84
[Train] Epoch: 3 [90880/387873]    Loss: 0.002302   Batch Acc: 85.16
[Train] Epoch: 3 [91008/387873]    Loss: 0.001428   Batch Acc: 97.66
[Train] Epoch: 3 [91136/387873]    Loss: 0.002151   Batch Acc: 89.84
[Train] Epoch: 3 [91264/387873]    Loss: 0.001457   Batch Acc: 92.97
[Train] Epoch: 3 [91392/387873]    Loss: 0.002377   Batch Acc: 85.94
[Train] Epoch: 3 [91520/387873]    Loss: 0.001544   Batch Acc: 92.97
[Train] Epoch: 3 [91648/387873]    Loss: 0.002591   Batch Acc: 85.94
[Train] Epoch: 3 [91776/387873]    Loss: 0.002231   Batch Acc: 85.94
[Train] Epoch: 3 [91904/387873]    Loss: 0.002590   Batch Acc: 88.28
[Train] Epoch: 3 [92032/387873]    Loss: 0.001318   Batch Acc: 96.09
[Train] Epoch: 3 [92160/387873]    Loss: 0.001794   Batch Acc: 89.06
[Train] Epoch: 3 [92288/387873]    Loss: 0.002300   Batch Acc: 85.94
[Train] Epoch: 3 [92416/387873]    Loss: 0.001694   Batch Acc: 92.97
[Train] Epoch: 3 [92544/387873]    Loss: 0.001755   Batch Acc: 89.06
[Train] Epoch: 3 [92672/387873]    Loss: 0.002194   Batch Acc: 87.50
[Train] Epoch: 3 [92800/387873]    Loss: 0.002081   Batch Acc: 89.06
[Train] Epoch: 3 [92928/387873]    Loss: 0.001673   Batch Acc: 91.41
[Train] Epoch: 3 [93056/387873]    Loss: 0.002026   Batch Acc: 87.50
[Train] Epoch: 3 [93184/387873]    Loss: 0.002299   Batch Acc: 86.72
[Train] Epoch: 3 [93312/387873]    Loss: 0.002548   Batch Acc: 85.16
[Train] Epoch: 3 [93440/387873]    Loss: 0.002917   Batch Acc: 85.94
[Train] Epoch: 3 [93568/387873]    Loss: 0.002686   Batch Acc: 83.59
[Train] Epoch: 3 [93696/387873]    Loss: 0.001811   Batch Acc: 90.62
[Train] Epoch: 3 [93824/387873]    Loss: 0.002321   Batch Acc: 86.72
[Train] Epoch: 3 [93952/387873]    Loss: 0.001941   Batch Acc: 92.97
[Train] Epoch: 3 [94080/387873]    Loss: 0.002480   Batch Acc: 86.72
[Train] Epoch: 3 [94208/387873]    Loss: 0.002168   Batch Acc: 90.62
[Train] Epoch: 3 [94336/387873]    Loss: 0.002418   Batch Acc: 87.50
[Train] Epoch: 3 [94464/387873]    Loss: 0.002057   Batch Acc: 88.28
[Train] Epoch: 3 [94592/387873]    Loss: 0.001669   Batch Acc: 93.75
[Train] Epoch: 3 [94720/387873]    Loss: 0.002432   Batch Acc: 86.72
[Train] Epoch: 3 [94848/387873]    Loss: 0.001621   Batch Acc: 92.19
[Train] Epoch: 3 [94976/387873]    Loss: 0.001909   Batch Acc: 86.72
[Train] Epoch: 3 [95104/387873]    Loss: 0.001576   Batch Acc: 92.19
[Train] Epoch: 3 [95232/387873]    Loss: 0.001598   Batch Acc: 90.62
[Train] Epoch: 3 [95360/387873]    Loss: 0.002185   Batch Acc: 86.72
[Train] Epoch: 3 [95488/387873]    Loss: 0.002594   Batch Acc: 85.16
[Train] Epoch: 3 [95616/387873]    Loss: 0.002267   Batch Acc: 85.94
[Train] Epoch: 3 [95744/387873]    Loss: 0.001940   Batch Acc: 89.06
[Train] Epoch: 3 [95872/387873]    Loss: 0.001933   Batch Acc: 91.41
[Train] Epoch: 3 [96000/387873]    Loss: 0.002266   Batch Acc: 86.72
[Train] Epoch: 3 [96128/387873]    Loss: 0.001897   Batch Acc: 91.41
[Train] Epoch: 3 [96256/387873]    Loss: 0.002136   Batch Acc: 86.72
[Train] Epoch: 3 [96384/387873]    Loss: 0.001903   Batch Acc: 90.62
[Train] Epoch: 3 [96512/387873]    Loss: 0.002476   Batch Acc: 86.72
[Train] Epoch: 3 [96640/387873]    Loss: 0.001663   Batch Acc: 91.41
[Train] Epoch: 3 [96768/387873]    Loss: 0.001738   Batch Acc: 91.41
[Train] Epoch: 3 [96896/387873]    Loss: 0.001803   Batch Acc: 91.41
[Train] Epoch: 3 [97024/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 3 [97152/387873]    Loss: 0.002289   Batch Acc: 86.72
[Train] Epoch: 3 [97280/387873]    Loss: 0.002253   Batch Acc: 88.28
[Train] Epoch: 3 [97408/387873]    Loss: 0.002114   Batch Acc: 90.62
[Train] Epoch: 3 [97536/387873]    Loss: 0.002341   Batch Acc: 85.16
[Train] Epoch: 3 [97664/387873]    Loss: 0.002061   Batch Acc: 90.62
[Train] Epoch: 3 [97792/387873]    Loss: 0.002039   Batch Acc: 88.28
[Train] Epoch: 3 [97920/387873]    Loss: 0.001910   Batch Acc: 89.06
[Train] Epoch: 3 [98048/387873]    Loss: 0.002588   Batch Acc: 85.94
[Train] Epoch: 3 [98176/387873]    Loss: 0.002207   Batch Acc: 86.72
[Train] Epoch: 3 [98304/387873]    Loss: 0.001763   Batch Acc: 91.41
[Train] Epoch: 3 [98432/387873]    Loss: 0.002032   Batch Acc: 89.06
[Train] Epoch: 3 [98560/387873]    Loss: 0.001549   Batch Acc: 92.19
[Train] Epoch: 3 [98688/387873]    Loss: 0.002215   Batch Acc: 90.62
[Train] Epoch: 3 [98816/387873]    Loss: 0.002171   Batch Acc: 89.06
[Train] Epoch: 3 [98944/387873]    Loss: 0.002114   Batch Acc: 87.50
[Train] Epoch: 3 [99072/387873]    Loss: 0.002278   Batch Acc: 85.94
[Train] Epoch: 3 [99200/387873]    Loss: 0.001687   Batch Acc: 92.97
[Train] Epoch: 3 [99328/387873]    Loss: 0.001515   Batch Acc: 92.97
[Train] Epoch: 3 [99456/387873]    Loss: 0.001469   Batch Acc: 94.53
[Train] Epoch: 3 [99584/387873]    Loss: 0.002351   Batch Acc: 84.38
[Train] Epoch: 3 [99712/387873]    Loss: 0.002159   Batch Acc: 90.62
[Train] Epoch: 3 [99840/387873]    Loss: 0.001854   Batch Acc: 88.28
[Train] Epoch: 3 [99968/387873]    Loss: 0.002257   Batch Acc: 85.16
[Train] Epoch: 3 [100096/387873]    Loss: 0.002342   Batch Acc: 85.16
[Train] Epoch: 3 [100224/387873]    Loss: 0.002767   Batch Acc: 84.38
[Train] Epoch: 3 [100352/387873]    Loss: 0.001831   Batch Acc: 92.19
[Train] Epoch: 3 [100480/387873]    Loss: 0.002258   Batch Acc: 89.06
[Train] Epoch: 3 [100608/387873]    Loss: 0.001818   Batch Acc: 92.19
[Train] Epoch: 3 [100736/387873]    Loss: 0.001865   Batch Acc: 89.84
[Train] Epoch: 3 [100864/387873]    Loss: 0.001742   Batch Acc: 92.19
[Train] Epoch: 3 [100992/387873]    Loss: 0.001813   Batch Acc: 92.19
[Train] Epoch: 3 [101120/387873]    Loss: 0.002329   Batch Acc: 85.94
[Train] Epoch: 3 [101248/387873]    Loss: 0.002077   Batch Acc: 87.50
[Train] Epoch: 3 [101376/387873]    Loss: 0.002070   Batch Acc: 87.50
[Train] Epoch: 3 [101504/387873]    Loss: 0.002359   Batch Acc: 88.28
[Train] Epoch: 3 [101632/387873]    Loss: 0.001671   Batch Acc: 93.75
[Train] Epoch: 3 [101760/387873]    Loss: 0.002417   Batch Acc: 85.94
[Train] Epoch: 3 [101888/387873]    Loss: 0.001871   Batch Acc: 91.41
[Train] Epoch: 3 [102016/387873]    Loss: 0.002369   Batch Acc: 82.81
[Train] Epoch: 3 [102144/387873]    Loss: 0.002236   Batch Acc: 89.84
[Train] Epoch: 3 [102272/387873]    Loss: 0.002469   Batch Acc: 85.94
[Train] Epoch: 3 [102400/387873]    Loss: 0.002260   Batch Acc: 88.28
[Train] Epoch: 3 [102528/387873]    Loss: 0.001728   Batch Acc: 92.19
[Train] Epoch: 3 [102656/387873]    Loss: 0.002324   Batch Acc: 85.94
[Train] Epoch: 3 [102784/387873]    Loss: 0.001811   Batch Acc: 90.62
[Train] Epoch: 3 [102912/387873]    Loss: 0.002007   Batch Acc: 89.06
[Train] Epoch: 3 [103040/387873]    Loss: 0.002143   Batch Acc: 89.84
[Train] Epoch: 3 [103168/387873]    Loss: 0.002477   Batch Acc: 89.06
[Train] Epoch: 3 [103296/387873]    Loss: 0.001668   Batch Acc: 89.84
[Train] Epoch: 3 [103424/387873]    Loss: 0.002098   Batch Acc: 89.06
[Train] Epoch: 3 [103552/387873]    Loss: 0.002299   Batch Acc: 84.38
[Train] Epoch: 3 [103680/387873]    Loss: 0.001842   Batch Acc: 89.06
[Train] Epoch: 3 [103808/387873]    Loss: 0.002172   Batch Acc: 85.16
[Train] Epoch: 3 [103936/387873]    Loss: 0.002209   Batch Acc: 89.06
[Train] Epoch: 3 [104064/387873]    Loss: 0.002311   Batch Acc: 83.59
[Train] Epoch: 3 [104192/387873]    Loss: 0.002112   Batch Acc: 89.06
[Train] Epoch: 3 [104320/387873]    Loss: 0.001309   Batch Acc: 94.53
[Train] Epoch: 3 [104448/387873]    Loss: 0.001305   Batch Acc: 93.75
[Train] Epoch: 3 [104576/387873]    Loss: 0.001571   Batch Acc: 92.19
[Train] Epoch: 3 [104704/387873]    Loss: 0.002192   Batch Acc: 86.72
[Train] Epoch: 3 [104832/387873]    Loss: 0.002386   Batch Acc: 88.28
[Train] Epoch: 3 [104960/387873]    Loss: 0.001782   Batch Acc: 91.41
[Train] Epoch: 3 [105088/387873]    Loss: 0.001878   Batch Acc: 92.19
[Train] Epoch: 3 [105216/387873]    Loss: 0.002533   Batch Acc: 86.72
[Train] Epoch: 3 [105344/387873]    Loss: 0.002305   Batch Acc: 88.28
[Train] Epoch: 3 [105472/387873]    Loss: 0.002188   Batch Acc: 85.94
[Train] Epoch: 3 [105600/387873]    Loss: 0.001685   Batch Acc: 94.53
[Train] Epoch: 3 [105728/387873]    Loss: 0.002178   Batch Acc: 85.94
[Train] Epoch: 3 [105856/387873]    Loss: 0.002121   Batch Acc: 85.94
[Train] Epoch: 3 [105984/387873]    Loss: 0.001748   Batch Acc: 88.28
[Train] Epoch: 3 [106112/387873]    Loss: 0.002314   Batch Acc: 86.72
[Train] Epoch: 3 [106240/387873]    Loss: 0.002286   Batch Acc: 86.72
[Train] Epoch: 3 [106368/387873]    Loss: 0.001854   Batch Acc: 87.50
[Train] Epoch: 3 [106496/387873]    Loss: 0.001799   Batch Acc: 89.84
[Train] Epoch: 3 [106624/387873]    Loss: 0.002471   Batch Acc: 85.94
[Train] Epoch: 3 [106752/387873]    Loss: 0.001697   Batch Acc: 92.97
[Train] Epoch: 3 [106880/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 3 [107008/387873]    Loss: 0.002156   Batch Acc: 86.72
[Train] Epoch: 3 [107136/387873]    Loss: 0.001943   Batch Acc: 89.06
[Train] Epoch: 3 [107264/387873]    Loss: 0.002028   Batch Acc: 86.72
[Train] Epoch: 3 [107392/387873]    Loss: 0.001832   Batch Acc: 89.84
[Train] Epoch: 3 [107520/387873]    Loss: 0.001949   Batch Acc: 89.84
[Train] Epoch: 3 [107648/387873]    Loss: 0.001608   Batch Acc: 93.75
[Train] Epoch: 3 [107776/387873]    Loss: 0.002078   Batch Acc: 88.28
[Train] Epoch: 3 [107904/387873]    Loss: 0.001744   Batch Acc: 91.41
[Train] Epoch: 3 [108032/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 3 [108160/387873]    Loss: 0.002274   Batch Acc: 89.06
[Train] Epoch: 3 [108288/387873]    Loss: 0.001841   Batch Acc: 89.84
[Train] Epoch: 3 [108416/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 3 [108544/387873]    Loss: 0.002075   Batch Acc: 88.28
[Train] Epoch: 3 [108672/387873]    Loss: 0.002392   Batch Acc: 85.16
[Train] Epoch: 3 [108800/387873]    Loss: 0.002089   Batch Acc: 88.28
[Train] Epoch: 3 [108928/387873]    Loss: 0.003012   Batch Acc: 80.47
[Train] Epoch: 3 [109056/387873]    Loss: 0.001700   Batch Acc: 90.62
[Train] Epoch: 3 [109184/387873]    Loss: 0.001288   Batch Acc: 95.31
[Train] Epoch: 3 [109312/387873]    Loss: 0.002039   Batch Acc: 91.41
[Train] Epoch: 3 [109440/387873]    Loss: 0.001775   Batch Acc: 90.62
[Train] Epoch: 3 [109568/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 3 [109696/387873]    Loss: 0.002552   Batch Acc: 85.16
[Train] Epoch: 3 [109824/387873]    Loss: 0.001825   Batch Acc: 92.97
[Train] Epoch: 3 [109952/387873]    Loss: 0.002021   Batch Acc: 92.19
[Train] Epoch: 3 [110080/387873]    Loss: 0.002281   Batch Acc: 88.28
[Train] Epoch: 3 [110208/387873]    Loss: 0.002080   Batch Acc: 87.50
[Train] Epoch: 3 [110336/387873]    Loss: 0.002038   Batch Acc: 89.84
[Train] Epoch: 3 [110464/387873]    Loss: 0.002051   Batch Acc: 92.19
[Train] Epoch: 3 [110592/387873]    Loss: 0.002335   Batch Acc: 83.59
[Train] Epoch: 3 [110720/387873]    Loss: 0.002165   Batch Acc: 86.72
[Train] Epoch: 3 [110848/387873]    Loss: 0.001687   Batch Acc: 92.19
[Train] Epoch: 3 [110976/387873]    Loss: 0.002641   Batch Acc: 85.16
[Train] Epoch: 3 [111104/387873]    Loss: 0.002339   Batch Acc: 88.28
[Train] Epoch: 3 [111232/387873]    Loss: 0.001965   Batch Acc: 88.28
[Train] Epoch: 3 [111360/387873]    Loss: 0.001688   Batch Acc: 91.41
[Train] Epoch: 3 [111488/387873]    Loss: 0.002301   Batch Acc: 88.28
[Train] Epoch: 3 [111616/387873]    Loss: 0.001848   Batch Acc: 88.28
[Train] Epoch: 3 [111744/387873]    Loss: 0.001695   Batch Acc: 92.19
[Train] Epoch: 3 [111872/387873]    Loss: 0.002255   Batch Acc: 87.50
[Train] Epoch: 3 [112000/387873]    Loss: 0.002154   Batch Acc: 86.72
[Train] Epoch: 3 [112128/387873]    Loss: 0.002235   Batch Acc: 86.72
[Train] Epoch: 3 [112256/387873]    Loss: 0.001798   Batch Acc: 92.19
[Train] Epoch: 3 [112384/387873]    Loss: 0.001852   Batch Acc: 90.62
[Train] Epoch: 3 [112512/387873]    Loss: 0.002029   Batch Acc: 89.06
[Train] Epoch: 3 [112640/387873]    Loss: 0.002045   Batch Acc: 87.50
[Train] Epoch: 3 [112768/387873]    Loss: 0.001965   Batch Acc: 90.62
[Train] Epoch: 3 [112896/387873]    Loss: 0.001833   Batch Acc: 89.84
[Train] Epoch: 3 [113024/387873]    Loss: 0.002047   Batch Acc: 86.72
[Train] Epoch: 3 [113152/387873]    Loss: 0.002048   Batch Acc: 86.72
[Train] Epoch: 3 [113280/387873]    Loss: 0.001873   Batch Acc: 90.62
[Train] Epoch: 3 [113408/387873]    Loss: 0.002060   Batch Acc: 91.41
[Train] Epoch: 3 [113536/387873]    Loss: 0.001716   Batch Acc: 90.62
[Train] Epoch: 3 [113664/387873]    Loss: 0.001522   Batch Acc: 92.19
[Train] Epoch: 3 [113792/387873]    Loss: 0.002433   Batch Acc: 85.16
[Train] Epoch: 3 [113920/387873]    Loss: 0.002367   Batch Acc: 85.94
[Train] Epoch: 3 [114048/387873]    Loss: 0.002227   Batch Acc: 89.84
[Train] Epoch: 3 [114176/387873]    Loss: 0.002454   Batch Acc: 85.94
[Train] Epoch: 3 [114304/387873]    Loss: 0.002291   Batch Acc: 89.84
[Train] Epoch: 3 [114432/387873]    Loss: 0.001791   Batch Acc: 90.62
[Train] Epoch: 3 [114560/387873]    Loss: 0.001616   Batch Acc: 92.19
[Train] Epoch: 3 [114688/387873]    Loss: 0.003058   Batch Acc: 84.38
[Train] Epoch: 3 [114816/387873]    Loss: 0.001766   Batch Acc: 87.50
[Train] Epoch: 3 [114944/387873]    Loss: 0.001465   Batch Acc: 93.75
[Train] Epoch: 3 [115072/387873]    Loss: 0.001653   Batch Acc: 96.09
[Train] Epoch: 3 [115200/387873]    Loss: 0.001369   Batch Acc: 94.53
[Train] Epoch: 3 [115328/387873]    Loss: 0.001834   Batch Acc: 91.41
[Train] Epoch: 3 [115456/387873]    Loss: 0.002193   Batch Acc: 85.94
[Train] Epoch: 3 [115584/387873]    Loss: 0.002198   Batch Acc: 85.94
[Train] Epoch: 3 [115712/387873]    Loss: 0.002457   Batch Acc: 85.94
[Train] Epoch: 3 [115840/387873]    Loss: 0.001889   Batch Acc: 94.53
[Train] Epoch: 3 [115968/387873]    Loss: 0.001841   Batch Acc: 90.62
[Train] Epoch: 3 [116096/387873]    Loss: 0.002531   Batch Acc: 85.94
[Train] Epoch: 3 [116224/387873]    Loss: 0.001868   Batch Acc: 87.50
[Train] Epoch: 3 [116352/387873]    Loss: 0.001634   Batch Acc: 92.19
[Train] Epoch: 3 [116480/387873]    Loss: 0.002115   Batch Acc: 83.59
[Train] Epoch: 3 [116608/387873]    Loss: 0.002646   Batch Acc: 87.50
[Train] Epoch: 3 [116736/387873]    Loss: 0.002022   Batch Acc: 86.72
[Train] Epoch: 3 [116864/387873]    Loss: 0.001857   Batch Acc: 89.06
[Train] Epoch: 3 [116992/387873]    Loss: 0.001992   Batch Acc: 85.94
[Train] Epoch: 3 [117120/387873]    Loss: 0.001768   Batch Acc: 89.84
[Train] Epoch: 3 [117248/387873]    Loss: 0.002004   Batch Acc: 90.62
[Train] Epoch: 3 [117376/387873]    Loss: 0.001638   Batch Acc: 92.19
[Train] Epoch: 3 [117504/387873]    Loss: 0.002209   Batch Acc: 89.06
[Train] Epoch: 3 [117632/387873]    Loss: 0.001723   Batch Acc: 91.41
[Train] Epoch: 3 [117760/387873]    Loss: 0.001580   Batch Acc: 94.53
[Train] Epoch: 3 [117888/387873]    Loss: 0.002256   Batch Acc: 89.84
[Train] Epoch: 3 [118016/387873]    Loss: 0.001922   Batch Acc: 91.41
[Train] Epoch: 3 [118144/387873]    Loss: 0.001874   Batch Acc: 87.50
[Train] Epoch: 3 [118272/387873]    Loss: 0.002091   Batch Acc: 89.84
[Train] Epoch: 3 [118400/387873]    Loss: 0.001120   Batch Acc: 96.09
[Train] Epoch: 3 [118528/387873]    Loss: 0.002734   Batch Acc: 85.94
[Train] Epoch: 3 [118656/387873]    Loss: 0.001882   Batch Acc: 89.06
[Train] Epoch: 3 [118784/387873]    Loss: 0.001942   Batch Acc: 88.28
[Train] Epoch: 3 [118912/387873]    Loss: 0.002065   Batch Acc: 89.06
[Train] Epoch: 3 [119040/387873]    Loss: 0.001610   Batch Acc: 90.62
[Train] Epoch: 3 [119168/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 3 [119296/387873]    Loss: 0.002117   Batch Acc: 87.50
[Train] Epoch: 3 [119424/387873]    Loss: 0.002089   Batch Acc: 89.84
[Train] Epoch: 3 [119552/387873]    Loss: 0.002223   Batch Acc: 89.84
[Train] Epoch: 3 [119680/387873]    Loss: 0.001860   Batch Acc: 89.06
[Train] Epoch: 3 [119808/387873]    Loss: 0.002082   Batch Acc: 91.41
[Train] Epoch: 3 [119936/387873]    Loss: 0.002102   Batch Acc: 88.28
[Train] Epoch: 3 [120064/387873]    Loss: 0.001794   Batch Acc: 92.19
[Train] Epoch: 3 [120192/387873]    Loss: 0.001855   Batch Acc: 90.62
[Train] Epoch: 3 [120320/387873]    Loss: 0.002280   Batch Acc: 89.06
[Train] Epoch: 3 [120448/387873]    Loss: 0.001901   Batch Acc: 88.28
[Train] Epoch: 3 [120576/387873]    Loss: 0.002025   Batch Acc: 89.84
[Train] Epoch: 3 [120704/387873]    Loss: 0.002041   Batch Acc: 91.41
[Train] Epoch: 3 [120832/387873]    Loss: 0.002174   Batch Acc: 87.50
[Train] Epoch: 3 [120960/387873]    Loss: 0.002364   Batch Acc: 86.72
[Train] Epoch: 3 [121088/387873]    Loss: 0.001891   Batch Acc: 89.84
[Train] Epoch: 3 [121216/387873]    Loss: 0.001683   Batch Acc: 92.19
[Train] Epoch: 3 [121344/387873]    Loss: 0.001867   Batch Acc: 89.06
[Train] Epoch: 3 [121472/387873]    Loss: 0.002206   Batch Acc: 87.50
[Train] Epoch: 3 [121600/387873]    Loss: 0.001868   Batch Acc: 92.19
[Train] Epoch: 3 [121728/387873]    Loss: 0.001605   Batch Acc: 93.75
[Train] Epoch: 3 [121856/387873]    Loss: 0.002278   Batch Acc: 87.50
[Train] Epoch: 3 [121984/387873]    Loss: 0.001848   Batch Acc: 92.19
[Train] Epoch: 3 [122112/387873]    Loss: 0.002198   Batch Acc: 89.06
[Train] Epoch: 3 [122240/387873]    Loss: 0.002284   Batch Acc: 92.19
[Train] Epoch: 3 [122368/387873]    Loss: 0.001505   Batch Acc: 94.53
[Train] Epoch: 3 [122496/387873]    Loss: 0.002561   Batch Acc: 83.59
[Train] Epoch: 3 [122624/387873]    Loss: 0.001604   Batch Acc: 93.75
[Train] Epoch: 3 [122752/387873]    Loss: 0.002475   Batch Acc: 89.06
[Train] Epoch: 3 [122880/387873]    Loss: 0.001731   Batch Acc: 91.41
[Train] Epoch: 3 [123008/387873]    Loss: 0.002020   Batch Acc: 89.84
[Train] Epoch: 3 [123136/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 3 [123264/387873]    Loss: 0.001908   Batch Acc: 88.28
[Train] Epoch: 3 [123392/387873]    Loss: 0.001827   Batch Acc: 88.28
[Train] Epoch: 3 [123520/387873]    Loss: 0.001733   Batch Acc: 93.75
[Train] Epoch: 3 [123648/387873]    Loss: 0.002474   Batch Acc: 86.72
[Train] Epoch: 3 [123776/387873]    Loss: 0.001659   Batch Acc: 92.97
[Train] Epoch: 3 [123904/387873]    Loss: 0.002097   Batch Acc: 89.06
[Train] Epoch: 3 [124032/387873]    Loss: 0.001992   Batch Acc: 89.84
[Train] Epoch: 3 [124160/387873]    Loss: 0.001974   Batch Acc: 88.28
[Train] Epoch: 3 [124288/387873]    Loss: 0.002221   Batch Acc: 86.72
[Train] Epoch: 3 [124416/387873]    Loss: 0.001762   Batch Acc: 92.19
[Train] Epoch: 3 [124544/387873]    Loss: 0.002099   Batch Acc: 87.50
[Train] Epoch: 3 [124672/387873]    Loss: 0.002322   Batch Acc: 82.03
[Train] Epoch: 3 [124800/387873]    Loss: 0.002060   Batch Acc: 88.28
[Train] Epoch: 3 [124928/387873]    Loss: 0.001567   Batch Acc: 92.97
[Train] Epoch: 3 [125056/387873]    Loss: 0.002697   Batch Acc: 86.72
[Train] Epoch: 3 [125184/387873]    Loss: 0.001900   Batch Acc: 90.62
[Train] Epoch: 3 [125312/387873]    Loss: 0.002059   Batch Acc: 89.84
[Train] Epoch: 3 [125440/387873]    Loss: 0.001677   Batch Acc: 93.75
[Train] Epoch: 3 [125568/387873]    Loss: 0.002545   Batch Acc: 84.38
[Train] Epoch: 3 [125696/387873]    Loss: 0.001860   Batch Acc: 89.84
[Train] Epoch: 3 [125824/387873]    Loss: 0.002098   Batch Acc: 89.84
[Train] Epoch: 3 [125952/387873]    Loss: 0.001620   Batch Acc: 92.19
[Train] Epoch: 3 [126080/387873]    Loss: 0.002355   Batch Acc: 86.72
[Train] Epoch: 3 [126208/387873]    Loss: 0.001931   Batch Acc: 90.62
[Train] Epoch: 3 [126336/387873]    Loss: 0.002335   Batch Acc: 87.50
[Train] Epoch: 3 [126464/387873]    Loss: 0.001827   Batch Acc: 92.97
[Train] Epoch: 3 [126592/387873]    Loss: 0.001933   Batch Acc: 88.28
[Train] Epoch: 3 [126720/387873]    Loss: 0.002288   Batch Acc: 87.50
[Train] Epoch: 3 [126848/387873]    Loss: 0.001751   Batch Acc: 89.84
[Train] Epoch: 3 [126976/387873]    Loss: 0.001541   Batch Acc: 92.19
[Train] Epoch: 3 [127104/387873]    Loss: 0.002788   Batch Acc: 85.16
[Train] Epoch: 3 [127232/387873]    Loss: 0.001179   Batch Acc: 94.53
[Train] Epoch: 3 [127360/387873]    Loss: 0.001914   Batch Acc: 91.41
[Train] Epoch: 3 [127488/387873]    Loss: 0.002366   Batch Acc: 89.84
[Train] Epoch: 3 [127616/387873]    Loss: 0.002126   Batch Acc: 85.94
[Train] Epoch: 3 [127744/387873]    Loss: 0.001687   Batch Acc: 92.97
[Train] Epoch: 3 [127872/387873]    Loss: 0.001962   Batch Acc: 89.84
[Train] Epoch: 3 [128000/387873]    Loss: 0.002193   Batch Acc: 89.06
[Train] Epoch: 3 [128128/387873]    Loss: 0.001836   Batch Acc: 89.84
[Train] Epoch: 3 [128256/387873]    Loss: 0.003410   Batch Acc: 81.25
[Train] Epoch: 3 [128384/387873]    Loss: 0.002583   Batch Acc: 83.59
[Train] Epoch: 3 [128512/387873]    Loss: 0.002137   Batch Acc: 91.41
[Train] Epoch: 3 [128640/387873]    Loss: 0.002242   Batch Acc: 88.28
[Train] Epoch: 3 [128768/387873]    Loss: 0.002281   Batch Acc: 87.50
[Train] Epoch: 3 [128896/387873]    Loss: 0.001932   Batch Acc: 89.84
[Train] Epoch: 3 [129024/387873]    Loss: 0.002358   Batch Acc: 89.06
[Train] Epoch: 3 [129152/387873]    Loss: 0.001376   Batch Acc: 94.53
[Train] Epoch: 3 [129280/387873]    Loss: 0.002296   Batch Acc: 87.50
[Train] Epoch: 3 [129408/387873]    Loss: 0.001632   Batch Acc: 92.19
[Train] Epoch: 3 [129536/387873]    Loss: 0.002229   Batch Acc: 89.06
[Train] Epoch: 3 [129664/387873]    Loss: 0.002297   Batch Acc: 85.16
[Train] Epoch: 3 [129792/387873]    Loss: 0.002311   Batch Acc: 88.28
[Train] Epoch: 3 [129920/387873]    Loss: 0.002351   Batch Acc: 89.06
[Train] Epoch: 3 [130048/387873]    Loss: 0.002454   Batch Acc: 87.50
[Train] Epoch: 3 [130176/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 3 [130304/387873]    Loss: 0.001793   Batch Acc: 90.62
[Train] Epoch: 3 [130432/387873]    Loss: 0.001706   Batch Acc: 92.97
[Train] Epoch: 3 [130560/387873]    Loss: 0.002100   Batch Acc: 88.28
[Train] Epoch: 3 [130688/387873]    Loss: 0.001979   Batch Acc: 92.19
[Train] Epoch: 3 [130816/387873]    Loss: 0.002001   Batch Acc: 86.72
[Train] Epoch: 3 [130944/387873]    Loss: 0.001403   Batch Acc: 92.97
[Train] Epoch: 3 [131072/387873]    Loss: 0.002198   Batch Acc: 92.19
[Train] Epoch: 3 [131200/387873]    Loss: 0.001727   Batch Acc: 94.53
[Train] Epoch: 3 [131328/387873]    Loss: 0.001998   Batch Acc: 89.06
[Train] Epoch: 3 [131456/387873]    Loss: 0.001511   Batch Acc: 92.19
[Train] Epoch: 3 [131584/387873]    Loss: 0.002368   Batch Acc: 85.16
[Train] Epoch: 3 [131712/387873]    Loss: 0.002289   Batch Acc: 86.72
[Train] Epoch: 3 [131840/387873]    Loss: 0.001453   Batch Acc: 92.19
[Train] Epoch: 3 [131968/387873]    Loss: 0.002201   Batch Acc: 89.06
[Train] Epoch: 3 [132096/387873]    Loss: 0.002421   Batch Acc: 85.94
[Train] Epoch: 3 [132224/387873]    Loss: 0.002839   Batch Acc: 85.16
[Train] Epoch: 3 [132352/387873]    Loss: 0.001696   Batch Acc: 92.97
[Train] Epoch: 3 [132480/387873]    Loss: 0.002641   Batch Acc: 82.81
[Train] Epoch: 3 [132608/387873]    Loss: 0.002676   Batch Acc: 81.25
[Train] Epoch: 3 [132736/387873]    Loss: 0.001910   Batch Acc: 89.06
[Train] Epoch: 3 [132864/387873]    Loss: 0.001674   Batch Acc: 92.19
[Train] Epoch: 3 [132992/387873]    Loss: 0.001800   Batch Acc: 90.62
[Train] Epoch: 3 [133120/387873]    Loss: 0.002268   Batch Acc: 85.16
[Train] Epoch: 3 [133248/387873]    Loss: 0.001964   Batch Acc: 90.62
[Train] Epoch: 3 [133376/387873]    Loss: 0.002434   Batch Acc: 86.72
[Train] Epoch: 3 [133504/387873]    Loss: 0.002082   Batch Acc: 89.06
[Train] Epoch: 3 [133632/387873]    Loss: 0.002035   Batch Acc: 85.16
[Train] Epoch: 3 [133760/387873]    Loss: 0.001589   Batch Acc: 93.75
[Train] Epoch: 3 [133888/387873]    Loss: 0.001562   Batch Acc: 94.53
[Train] Epoch: 3 [134016/387873]    Loss: 0.001799   Batch Acc: 91.41
[Train] Epoch: 3 [134144/387873]    Loss: 0.001698   Batch Acc: 92.19
[Train] Epoch: 3 [134272/387873]    Loss: 0.001890   Batch Acc: 89.06
[Train] Epoch: 3 [134400/387873]    Loss: 0.002160   Batch Acc: 87.50
[Train] Epoch: 3 [134528/387873]    Loss: 0.002113   Batch Acc: 91.41
[Train] Epoch: 3 [134656/387873]    Loss: 0.002653   Batch Acc: 89.06
[Train] Epoch: 3 [134784/387873]    Loss: 0.002294   Batch Acc: 83.59
[Train] Epoch: 3 [134912/387873]    Loss: 0.001512   Batch Acc: 93.75
[Train] Epoch: 3 [135040/387873]    Loss: 0.002454   Batch Acc: 87.50
[Train] Epoch: 3 [135168/387873]    Loss: 0.002243   Batch Acc: 87.50
[Train] Epoch: 3 [135296/387873]    Loss: 0.002299   Batch Acc: 85.16
[Train] Epoch: 3 [135424/387873]    Loss: 0.001993   Batch Acc: 90.62
[Train] Epoch: 3 [135552/387873]    Loss: 0.001759   Batch Acc: 92.19
[Train] Epoch: 3 [135680/387873]    Loss: 0.001968   Batch Acc: 90.62
[Train] Epoch: 3 [135808/387873]    Loss: 0.001910   Batch Acc: 88.28
[Train] Epoch: 3 [135936/387873]    Loss: 0.002210   Batch Acc: 89.06
[Train] Epoch: 3 [136064/387873]    Loss: 0.002420   Batch Acc: 85.16
[Train] Epoch: 3 [136192/387873]    Loss: 0.002430   Batch Acc: 85.16
[Train] Epoch: 3 [136320/387873]    Loss: 0.002537   Batch Acc: 85.94
[Train] Epoch: 3 [136448/387873]    Loss: 0.002358   Batch Acc: 88.28
[Train] Epoch: 3 [136576/387873]    Loss: 0.002040   Batch Acc: 89.84
[Train] Epoch: 3 [136704/387873]    Loss: 0.002402   Batch Acc: 86.72
[Train] Epoch: 3 [136832/387873]    Loss: 0.001441   Batch Acc: 92.97
[Train] Epoch: 3 [136960/387873]    Loss: 0.002065   Batch Acc: 89.06
[Train] Epoch: 3 [137088/387873]    Loss: 0.001726   Batch Acc: 91.41
[Train] Epoch: 3 [137216/387873]    Loss: 0.001830   Batch Acc: 91.41
[Train] Epoch: 3 [137344/387873]    Loss: 0.002446   Batch Acc: 88.28
[Train] Epoch: 3 [137472/387873]    Loss: 0.001993   Batch Acc: 87.50
[Train] Epoch: 3 [137600/387873]    Loss: 0.001999   Batch Acc: 88.28
[Train] Epoch: 3 [137728/387873]    Loss: 0.001931   Batch Acc: 91.41
[Train] Epoch: 3 [137856/387873]    Loss: 0.002115   Batch Acc: 87.50
[Train] Epoch: 3 [137984/387873]    Loss: 0.001936   Batch Acc: 89.84
[Train] Epoch: 3 [138112/387873]    Loss: 0.002187   Batch Acc: 89.84
[Train] Epoch: 3 [138240/387873]    Loss: 0.002053   Batch Acc: 89.84
[Train] Epoch: 3 [138368/387873]    Loss: 0.001918   Batch Acc: 90.62
[Train] Epoch: 3 [138496/387873]    Loss: 0.001528   Batch Acc: 95.31
[Train] Epoch: 3 [138624/387873]    Loss: 0.001753   Batch Acc: 91.41
[Train] Epoch: 3 [138752/387873]    Loss: 0.002218   Batch Acc: 89.06
[Train] Epoch: 3 [138880/387873]    Loss: 0.001627   Batch Acc: 92.19
[Train] Epoch: 3 [139008/387873]    Loss: 0.001925   Batch Acc: 87.50
[Train] Epoch: 3 [139136/387873]    Loss: 0.002165   Batch Acc: 89.06
[Train] Epoch: 3 [139264/387873]    Loss: 0.002648   Batch Acc: 85.94
[Train] Epoch: 3 [139392/387873]    Loss: 0.002046   Batch Acc: 90.62
[Train] Epoch: 3 [139520/387873]    Loss: 0.002159   Batch Acc: 89.84
[Train] Epoch: 3 [139648/387873]    Loss: 0.002271   Batch Acc: 85.94
[Train] Epoch: 3 [139776/387873]    Loss: 0.001870   Batch Acc: 89.06
[Train] Epoch: 3 [139904/387873]    Loss: 0.002605   Batch Acc: 85.94
[Train] Epoch: 3 [140032/387873]    Loss: 0.002527   Batch Acc: 86.72
[Train] Epoch: 3 [140160/387873]    Loss: 0.001767   Batch Acc: 92.97
[Train] Epoch: 3 [140288/387873]    Loss: 0.002305   Batch Acc: 86.72
[Train] Epoch: 3 [140416/387873]    Loss: 0.002105   Batch Acc: 89.06
[Train] Epoch: 3 [140544/387873]    Loss: 0.001644   Batch Acc: 93.75
[Train] Epoch: 3 [140672/387873]    Loss: 0.002067   Batch Acc: 85.94
[Train] Epoch: 3 [140800/387873]    Loss: 0.002168   Batch Acc: 90.62
[Train] Epoch: 3 [140928/387873]    Loss: 0.002478   Batch Acc: 89.06
[Train] Epoch: 3 [141056/387873]    Loss: 0.002325   Batch Acc: 88.28
[Train] Epoch: 3 [141184/387873]    Loss: 0.002196   Batch Acc: 85.94
[Train] Epoch: 3 [141312/387873]    Loss: 0.002003   Batch Acc: 90.62
[Train] Epoch: 3 [141440/387873]    Loss: 0.001888   Batch Acc: 88.28
[Train] Epoch: 3 [141568/387873]    Loss: 0.002149   Batch Acc: 92.19
[Train] Epoch: 3 [141696/387873]    Loss: 0.002293   Batch Acc: 88.28
[Train] Epoch: 3 [141824/387873]    Loss: 0.001735   Batch Acc: 92.19
[Train] Epoch: 3 [141952/387873]    Loss: 0.001400   Batch Acc: 96.09
[Train] Epoch: 3 [142080/387873]    Loss: 0.001835   Batch Acc: 91.41
[Train] Epoch: 3 [142208/387873]    Loss: 0.002034   Batch Acc: 86.72
[Train] Epoch: 3 [142336/387873]    Loss: 0.001428   Batch Acc: 95.31
[Train] Epoch: 3 [142464/387873]    Loss: 0.001838   Batch Acc: 91.41
[Train] Epoch: 3 [142592/387873]    Loss: 0.002168   Batch Acc: 89.84
[Train] Epoch: 3 [142720/387873]    Loss: 0.002364   Batch Acc: 87.50
[Train] Epoch: 3 [142848/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 3 [142976/387873]    Loss: 0.001809   Batch Acc: 90.62
[Train] Epoch: 3 [143104/387873]    Loss: 0.002123   Batch Acc: 85.94
[Train] Epoch: 3 [143232/387873]    Loss: 0.002398   Batch Acc: 89.06
[Train] Epoch: 3 [143360/387873]    Loss: 0.002203   Batch Acc: 85.94
[Train] Epoch: 3 [143488/387873]    Loss: 0.002385   Batch Acc: 85.94
[Train] Epoch: 3 [143616/387873]    Loss: 0.001715   Batch Acc: 91.41
[Train] Epoch: 3 [143744/387873]    Loss: 0.002510   Batch Acc: 84.38
[Train] Epoch: 3 [143872/387873]    Loss: 0.002437   Batch Acc: 84.38
[Train] Epoch: 3 [144000/387873]    Loss: 0.001950   Batch Acc: 89.84
[Train] Epoch: 3 [144128/387873]    Loss: 0.002093   Batch Acc: 88.28
[Train] Epoch: 3 [144256/387873]    Loss: 0.001485   Batch Acc: 93.75
[Train] Epoch: 3 [144384/387873]    Loss: 0.002113   Batch Acc: 87.50
[Train] Epoch: 3 [144512/387873]    Loss: 0.002579   Batch Acc: 87.50
[Train] Epoch: 3 [144640/387873]    Loss: 0.001794   Batch Acc: 91.41
[Train] Epoch: 3 [144768/387873]    Loss: 0.002035   Batch Acc: 87.50
[Train] Epoch: 3 [144896/387873]    Loss: 0.001651   Batch Acc: 91.41
[Train] Epoch: 3 [145024/387873]    Loss: 0.002482   Batch Acc: 85.94
[Train] Epoch: 3 [145152/387873]    Loss: 0.001587   Batch Acc: 94.53
[Train] Epoch: 3 [145280/387873]    Loss: 0.002131   Batch Acc: 88.28
[Train] Epoch: 3 [145408/387873]    Loss: 0.001511   Batch Acc: 92.19
[Train] Epoch: 3 [145536/387873]    Loss: 0.002132   Batch Acc: 90.62
[Train] Epoch: 3 [145664/387873]    Loss: 0.001777   Batch Acc: 91.41
[Train] Epoch: 3 [145792/387873]    Loss: 0.002159   Batch Acc: 87.50
[Train] Epoch: 3 [145920/387873]    Loss: 0.001762   Batch Acc: 89.06
[Train] Epoch: 3 [146048/387873]    Loss: 0.001908   Batch Acc: 91.41
[Train] Epoch: 3 [146176/387873]    Loss: 0.001625   Batch Acc: 92.97
[Train] Epoch: 3 [146304/387873]    Loss: 0.002538   Batch Acc: 89.84
[Train] Epoch: 3 [146432/387873]    Loss: 0.001968   Batch Acc: 87.50
[Train] Epoch: 3 [146560/387873]    Loss: 0.001991   Batch Acc: 91.41
[Train] Epoch: 3 [146688/387873]    Loss: 0.002741   Batch Acc: 85.94
[Train] Epoch: 3 [146816/387873]    Loss: 0.002239   Batch Acc: 88.28
[Train] Epoch: 3 [146944/387873]    Loss: 0.002306   Batch Acc: 85.94
[Train] Epoch: 3 [147072/387873]    Loss: 0.001967   Batch Acc: 89.06
[Train] Epoch: 3 [147200/387873]    Loss: 0.002532   Batch Acc: 89.06
[Train] Epoch: 3 [147328/387873]    Loss: 0.002494   Batch Acc: 84.38
[Train] Epoch: 3 [147456/387873]    Loss: 0.001640   Batch Acc: 92.19
[Train] Epoch: 3 [147584/387873]    Loss: 0.001889   Batch Acc: 90.62
[Train] Epoch: 3 [147712/387873]    Loss: 0.002023   Batch Acc: 88.28
[Train] Epoch: 3 [147840/387873]    Loss: 0.002286   Batch Acc: 87.50
[Train] Epoch: 3 [147968/387873]    Loss: 0.002348   Batch Acc: 85.16
[Train] Epoch: 3 [148096/387873]    Loss: 0.002180   Batch Acc: 86.72
[Train] Epoch: 3 [148224/387873]    Loss: 0.002079   Batch Acc: 89.84
[Train] Epoch: 3 [148352/387873]    Loss: 0.001733   Batch Acc: 92.19
[Train] Epoch: 3 [148480/387873]    Loss: 0.002453   Batch Acc: 88.28
[Train] Epoch: 3 [148608/387873]    Loss: 0.002506   Batch Acc: 84.38
[Train] Epoch: 3 [148736/387873]    Loss: 0.002506   Batch Acc: 89.06
[Train] Epoch: 3 [148864/387873]    Loss: 0.001621   Batch Acc: 91.41
[Train] Epoch: 3 [148992/387873]    Loss: 0.002170   Batch Acc: 86.72
[Train] Epoch: 3 [149120/387873]    Loss: 0.001815   Batch Acc: 92.19
[Train] Epoch: 3 [149248/387873]    Loss: 0.002334   Batch Acc: 86.72
[Train] Epoch: 3 [149376/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 3 [149504/387873]    Loss: 0.001693   Batch Acc: 91.41
[Train] Epoch: 3 [149632/387873]    Loss: 0.002170   Batch Acc: 89.06
[Train] Epoch: 3 [149760/387873]    Loss: 0.002116   Batch Acc: 89.84
[Train] Epoch: 3 [149888/387873]    Loss: 0.001979   Batch Acc: 87.50
[Train] Epoch: 3 [150016/387873]    Loss: 0.002369   Batch Acc: 85.94
[Train] Epoch: 3 [150144/387873]    Loss: 0.001949   Batch Acc: 92.97
[Train] Epoch: 3 [150272/387873]    Loss: 0.002205   Batch Acc: 89.06
[Train] Epoch: 3 [150400/387873]    Loss: 0.001476   Batch Acc: 92.97
[Train] Epoch: 3 [150528/387873]    Loss: 0.001571   Batch Acc: 90.62
[Train] Epoch: 3 [150656/387873]    Loss: 0.002022   Batch Acc: 89.84
[Train] Epoch: 3 [150784/387873]    Loss: 0.001826   Batch Acc: 89.84
[Train] Epoch: 3 [150912/387873]    Loss: 0.001758   Batch Acc: 92.97
[Train] Epoch: 3 [151040/387873]    Loss: 0.002665   Batch Acc: 82.03
[Train] Epoch: 3 [151168/387873]    Loss: 0.002705   Batch Acc: 83.59
[Train] Epoch: 3 [151296/387873]    Loss: 0.002524   Batch Acc: 85.94
[Train] Epoch: 3 [151424/387873]    Loss: 0.001994   Batch Acc: 91.41
[Train] Epoch: 3 [151552/387873]    Loss: 0.001870   Batch Acc: 90.62
[Train] Epoch: 3 [151680/387873]    Loss: 0.001790   Batch Acc: 92.97
[Train] Epoch: 3 [151808/387873]    Loss: 0.002392   Batch Acc: 88.28
[Train] Epoch: 3 [151936/387873]    Loss: 0.002072   Batch Acc: 91.41
[Train] Epoch: 3 [152064/387873]    Loss: 0.002100   Batch Acc: 89.06
[Train] Epoch: 3 [152192/387873]    Loss: 0.002129   Batch Acc: 91.41
[Train] Epoch: 3 [152320/387873]    Loss: 0.002507   Batch Acc: 82.03
[Train] Epoch: 3 [152448/387873]    Loss: 0.001912   Batch Acc: 86.72
[Train] Epoch: 3 [152576/387873]    Loss: 0.001944   Batch Acc: 91.41
[Train] Epoch: 3 [152704/387873]    Loss: 0.002077   Batch Acc: 88.28
[Train] Epoch: 3 [152832/387873]    Loss: 0.002881   Batch Acc: 82.81
[Train] Epoch: 3 [152960/387873]    Loss: 0.001591   Batch Acc: 91.41
[Train] Epoch: 3 [153088/387873]    Loss: 0.002049   Batch Acc: 88.28
[Train] Epoch: 3 [153216/387873]    Loss: 0.001801   Batch Acc: 90.62
[Train] Epoch: 3 [153344/387873]    Loss: 0.002305   Batch Acc: 84.38
[Train] Epoch: 3 [153472/387873]    Loss: 0.002701   Batch Acc: 87.50
[Train] Epoch: 3 [153600/387873]    Loss: 0.002194   Batch Acc: 88.28
[Train] Epoch: 3 [153728/387873]    Loss: 0.002134   Batch Acc: 85.16
[Train] Epoch: 3 [153856/387873]    Loss: 0.002010   Batch Acc: 89.84
[Train] Epoch: 3 [153984/387873]    Loss: 0.002129   Batch Acc: 87.50
[Train] Epoch: 3 [154112/387873]    Loss: 0.001619   Batch Acc: 93.75
[Train] Epoch: 3 [154240/387873]    Loss: 0.001814   Batch Acc: 91.41
[Train] Epoch: 3 [154368/387873]    Loss: 0.001733   Batch Acc: 92.19
[Train] Epoch: 3 [154496/387873]    Loss: 0.002706   Batch Acc: 83.59
[Train] Epoch: 3 [154624/387873]    Loss: 0.001710   Batch Acc: 93.75
[Train] Epoch: 3 [154752/387873]    Loss: 0.001781   Batch Acc: 89.84
[Train] Epoch: 3 [154880/387873]    Loss: 0.001736   Batch Acc: 92.97
[Train] Epoch: 3 [155008/387873]    Loss: 0.001988   Batch Acc: 91.41
[Train] Epoch: 3 [155136/387873]    Loss: 0.001966   Batch Acc: 88.28
[Train] Epoch: 3 [155264/387873]    Loss: 0.002453   Batch Acc: 83.59
[Train] Epoch: 3 [155392/387873]    Loss: 0.001765   Batch Acc: 92.19
[Train] Epoch: 3 [155520/387873]    Loss: 0.002300   Batch Acc: 85.94
[Train] Epoch: 3 [155648/387873]    Loss: 0.002324   Batch Acc: 88.28
[Train] Epoch: 3 [155776/387873]    Loss: 0.002953   Batch Acc: 86.72
[Train] Epoch: 3 [155904/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 3 [156032/387873]    Loss: 0.001890   Batch Acc: 89.06
[Train] Epoch: 3 [156160/387873]    Loss: 0.001974   Batch Acc: 92.19
[Train] Epoch: 3 [156288/387873]    Loss: 0.001639   Batch Acc: 92.97
[Train] Epoch: 3 [156416/387873]    Loss: 0.001772   Batch Acc: 92.19
[Train] Epoch: 3 [156544/387873]    Loss: 0.001863   Batch Acc: 89.06
[Train] Epoch: 3 [156672/387873]    Loss: 0.001710   Batch Acc: 92.97
[Train] Epoch: 3 [156800/387873]    Loss: 0.001603   Batch Acc: 92.97
[Train] Epoch: 3 [156928/387873]    Loss: 0.002146   Batch Acc: 90.62
[Train] Epoch: 3 [157056/387873]    Loss: 0.001972   Batch Acc: 88.28
[Train] Epoch: 3 [157184/387873]    Loss: 0.001438   Batch Acc: 92.19
[Train] Epoch: 3 [157312/387873]    Loss: 0.001778   Batch Acc: 89.84
[Train] Epoch: 3 [157440/387873]    Loss: 0.001804   Batch Acc: 89.06
[Train] Epoch: 3 [157568/387873]    Loss: 0.002342   Batch Acc: 87.50
[Train] Epoch: 3 [157696/387873]    Loss: 0.001927   Batch Acc: 90.62
[Train] Epoch: 3 [157824/387873]    Loss: 0.001758   Batch Acc: 91.41
[Train] Epoch: 3 [157952/387873]    Loss: 0.001629   Batch Acc: 91.41
[Train] Epoch: 3 [158080/387873]    Loss: 0.002029   Batch Acc: 89.06
[Train] Epoch: 3 [158208/387873]    Loss: 0.001987   Batch Acc: 90.62
[Train] Epoch: 3 [158336/387873]    Loss: 0.001654   Batch Acc: 86.72
[Train] Epoch: 3 [158464/387873]    Loss: 0.002094   Batch Acc: 88.28
[Train] Epoch: 3 [158592/387873]    Loss: 0.001752   Batch Acc: 91.41
[Train] Epoch: 3 [158720/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 3 [158848/387873]    Loss: 0.002425   Batch Acc: 85.94
[Train] Epoch: 3 [158976/387873]    Loss: 0.002000   Batch Acc: 89.06
[Train] Epoch: 3 [159104/387873]    Loss: 0.002176   Batch Acc: 92.97
[Train] Epoch: 3 [159232/387873]    Loss: 0.001618   Batch Acc: 92.19
[Train] Epoch: 3 [159360/387873]    Loss: 0.001742   Batch Acc: 89.84
[Train] Epoch: 3 [159488/387873]    Loss: 0.002465   Batch Acc: 84.38
[Train] Epoch: 3 [159616/387873]    Loss: 0.001785   Batch Acc: 92.97
[Train] Epoch: 3 [159744/387873]    Loss: 0.001732   Batch Acc: 92.97
[Train] Epoch: 3 [159872/387873]    Loss: 0.002072   Batch Acc: 87.50
[Train] Epoch: 3 [160000/387873]    Loss: 0.001362   Batch Acc: 92.97
[Train] Epoch: 3 [160128/387873]    Loss: 0.002132   Batch Acc: 89.06
[Train] Epoch: 3 [160256/387873]    Loss: 0.001621   Batch Acc: 93.75
[Train] Epoch: 3 [160384/387873]    Loss: 0.002591   Batch Acc: 82.81
[Train] Epoch: 3 [160512/387873]    Loss: 0.001791   Batch Acc: 89.84
[Train] Epoch: 3 [160640/387873]    Loss: 0.002302   Batch Acc: 84.38
[Train] Epoch: 3 [160768/387873]    Loss: 0.001936   Batch Acc: 89.84
[Train] Epoch: 3 [160896/387873]    Loss: 0.002130   Batch Acc: 87.50
[Train] Epoch: 3 [161024/387873]    Loss: 0.001953   Batch Acc: 86.72
[Train] Epoch: 3 [161152/387873]    Loss: 0.002513   Batch Acc: 85.94
[Train] Epoch: 3 [161280/387873]    Loss: 0.002074   Batch Acc: 92.19
[Train] Epoch: 3 [161408/387873]    Loss: 0.002651   Batch Acc: 81.25
[Train] Epoch: 3 [161536/387873]    Loss: 0.002668   Batch Acc: 83.59
[Train] Epoch: 3 [161664/387873]    Loss: 0.001515   Batch Acc: 95.31
[Train] Epoch: 3 [161792/387873]    Loss: 0.002253   Batch Acc: 85.94
[Train] Epoch: 3 [161920/387873]    Loss: 0.001957   Batch Acc: 88.28
[Train] Epoch: 3 [162048/387873]    Loss: 0.001736   Batch Acc: 92.97
[Train] Epoch: 3 [162176/387873]    Loss: 0.001824   Batch Acc: 90.62
[Train] Epoch: 3 [162304/387873]    Loss: 0.001680   Batch Acc: 92.97
[Train] Epoch: 3 [162432/387873]    Loss: 0.002026   Batch Acc: 90.62
[Train] Epoch: 3 [162560/387873]    Loss: 0.001896   Batch Acc: 86.72
[Train] Epoch: 3 [162688/387873]    Loss: 0.001648   Batch Acc: 91.41
[Train] Epoch: 3 [162816/387873]    Loss: 0.002057   Batch Acc: 85.16
[Train] Epoch: 3 [162944/387873]    Loss: 0.002119   Batch Acc: 85.16
[Train] Epoch: 3 [163072/387873]    Loss: 0.002242   Batch Acc: 87.50
[Train] Epoch: 3 [163200/387873]    Loss: 0.002066   Batch Acc: 90.62
[Train] Epoch: 3 [163328/387873]    Loss: 0.002138   Batch Acc: 88.28
[Train] Epoch: 3 [163456/387873]    Loss: 0.001791   Batch Acc: 89.84
[Train] Epoch: 3 [163584/387873]    Loss: 0.002126   Batch Acc: 89.84
[Train] Epoch: 3 [163712/387873]    Loss: 0.002062   Batch Acc: 86.72
[Train] Epoch: 3 [163840/387873]    Loss: 0.002118   Batch Acc: 89.06
[Train] Epoch: 3 [163968/387873]    Loss: 0.002505   Batch Acc: 85.94
[Train] Epoch: 3 [164096/387873]    Loss: 0.001913   Batch Acc: 92.97
[Train] Epoch: 3 [164224/387873]    Loss: 0.001583   Batch Acc: 91.41
[Train] Epoch: 3 [164352/387873]    Loss: 0.002685   Batch Acc: 85.16
[Train] Epoch: 3 [164480/387873]    Loss: 0.002012   Batch Acc: 89.84
[Train] Epoch: 3 [164608/387873]    Loss: 0.001815   Batch Acc: 90.62
[Train] Epoch: 3 [164736/387873]    Loss: 0.002094   Batch Acc: 86.72
[Train] Epoch: 3 [164864/387873]    Loss: 0.002040   Batch Acc: 87.50
[Train] Epoch: 3 [164992/387873]    Loss: 0.002491   Batch Acc: 87.50
[Train] Epoch: 3 [165120/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 3 [165248/387873]    Loss: 0.001863   Batch Acc: 92.19
[Train] Epoch: 3 [165376/387873]    Loss: 0.002132   Batch Acc: 88.28
[Train] Epoch: 3 [165504/387873]    Loss: 0.001743   Batch Acc: 89.84
[Train] Epoch: 3 [165632/387873]    Loss: 0.001850   Batch Acc: 90.62
[Train] Epoch: 3 [165760/387873]    Loss: 0.002649   Batch Acc: 83.59
[Train] Epoch: 3 [165888/387873]    Loss: 0.001528   Batch Acc: 91.41
[Train] Epoch: 3 [166016/387873]    Loss: 0.002495   Batch Acc: 88.28
[Train] Epoch: 3 [166144/387873]    Loss: 0.002069   Batch Acc: 89.06
[Train] Epoch: 3 [166272/387873]    Loss: 0.002314   Batch Acc: 86.72
[Train] Epoch: 3 [166400/387873]    Loss: 0.001781   Batch Acc: 91.41
[Train] Epoch: 3 [166528/387873]    Loss: 0.001818   Batch Acc: 89.06
[Train] Epoch: 3 [166656/387873]    Loss: 0.001821   Batch Acc: 90.62
[Train] Epoch: 3 [166784/387873]    Loss: 0.001905   Batch Acc: 89.84
[Train] Epoch: 3 [166912/387873]    Loss: 0.001920   Batch Acc: 89.84
[Train] Epoch: 3 [167040/387873]    Loss: 0.002120   Batch Acc: 87.50
[Train] Epoch: 3 [167168/387873]    Loss: 0.003355   Batch Acc: 79.69
[Train] Epoch: 3 [167296/387873]    Loss: 0.001562   Batch Acc: 92.97
[Train] Epoch: 3 [167424/387873]    Loss: 0.002305   Batch Acc: 87.50
[Train] Epoch: 3 [167552/387873]    Loss: 0.001817   Batch Acc: 90.62
[Train] Epoch: 3 [167680/387873]    Loss: 0.002633   Batch Acc: 84.38
[Train] Epoch: 3 [167808/387873]    Loss: 0.001788   Batch Acc: 91.41
[Train] Epoch: 3 [167936/387873]    Loss: 0.001916   Batch Acc: 88.28
[Train] Epoch: 3 [168064/387873]    Loss: 0.001499   Batch Acc: 94.53
[Train] Epoch: 3 [168192/387873]    Loss: 0.002187   Batch Acc: 86.72
[Train] Epoch: 3 [168320/387873]    Loss: 0.001661   Batch Acc: 91.41
[Train] Epoch: 3 [168448/387873]    Loss: 0.001946   Batch Acc: 91.41
[Train] Epoch: 3 [168576/387873]    Loss: 0.001788   Batch Acc: 89.84
[Train] Epoch: 3 [168704/387873]    Loss: 0.001750   Batch Acc: 92.19
[Train] Epoch: 3 [168832/387873]    Loss: 0.002015   Batch Acc: 88.28
[Train] Epoch: 3 [168960/387873]    Loss: 0.001410   Batch Acc: 93.75
[Train] Epoch: 3 [169088/387873]    Loss: 0.002189   Batch Acc: 85.94
[Train] Epoch: 3 [169216/387873]    Loss: 0.001525   Batch Acc: 92.97
[Train] Epoch: 3 [169344/387873]    Loss: 0.001814   Batch Acc: 92.19
[Train] Epoch: 3 [169472/387873]    Loss: 0.001237   Batch Acc: 96.09
[Train] Epoch: 3 [169600/387873]    Loss: 0.001499   Batch Acc: 92.19
[Train] Epoch: 3 [169728/387873]    Loss: 0.001820   Batch Acc: 92.97
[Train] Epoch: 3 [169856/387873]    Loss: 0.001876   Batch Acc: 88.28
[Train] Epoch: 3 [169984/387873]    Loss: 0.002192   Batch Acc: 87.50
[Train] Epoch: 3 [170112/387873]    Loss: 0.002273   Batch Acc: 87.50
[Train] Epoch: 3 [170240/387873]    Loss: 0.001705   Batch Acc: 90.62
[Train] Epoch: 3 [170368/387873]    Loss: 0.002092   Batch Acc: 87.50
[Train] Epoch: 3 [170496/387873]    Loss: 0.001861   Batch Acc: 89.06
[Train] Epoch: 3 [170624/387873]    Loss: 0.001967   Batch Acc: 89.84
[Train] Epoch: 3 [170752/387873]    Loss: 0.002598   Batch Acc: 83.59
[Train] Epoch: 3 [170880/387873]    Loss: 0.001904   Batch Acc: 90.62
[Train] Epoch: 3 [171008/387873]    Loss: 0.001849   Batch Acc: 91.41
[Train] Epoch: 3 [171136/387873]    Loss: 0.002085   Batch Acc: 91.41
[Train] Epoch: 3 [171264/387873]    Loss: 0.001696   Batch Acc: 88.28
[Train] Epoch: 3 [171392/387873]    Loss: 0.001600   Batch Acc: 94.53
[Train] Epoch: 3 [171520/387873]    Loss: 0.001903   Batch Acc: 90.62
[Train] Epoch: 3 [171648/387873]    Loss: 0.002223   Batch Acc: 89.84
[Train] Epoch: 3 [171776/387873]    Loss: 0.002133   Batch Acc: 87.50
[Train] Epoch: 3 [171904/387873]    Loss: 0.002369   Batch Acc: 88.28
[Train] Epoch: 3 [172032/387873]    Loss: 0.001731   Batch Acc: 89.84
[Train] Epoch: 3 [172160/387873]    Loss: 0.002236   Batch Acc: 89.06
[Train] Epoch: 3 [172288/387873]    Loss: 0.002018   Batch Acc: 91.41
[Train] Epoch: 3 [172416/387873]    Loss: 0.002534   Batch Acc: 84.38
[Train] Epoch: 3 [172544/387873]    Loss: 0.001968   Batch Acc: 87.50
[Train] Epoch: 3 [172672/387873]    Loss: 0.002155   Batch Acc: 89.06
[Train] Epoch: 3 [172800/387873]    Loss: 0.001811   Batch Acc: 89.84
[Train] Epoch: 3 [172928/387873]    Loss: 0.002284   Batch Acc: 89.84
[Train] Epoch: 3 [173056/387873]    Loss: 0.002205   Batch Acc: 89.06
[Train] Epoch: 3 [173184/387873]    Loss: 0.002255   Batch Acc: 89.84
[Train] Epoch: 3 [173312/387873]    Loss: 0.002306   Batch Acc: 89.06
[Train] Epoch: 3 [173440/387873]    Loss: 0.002474   Batch Acc: 85.16
[Train] Epoch: 3 [173568/387873]    Loss: 0.001710   Batch Acc: 92.97
[Train] Epoch: 3 [173696/387873]    Loss: 0.001933   Batch Acc: 89.84
[Train] Epoch: 3 [173824/387873]    Loss: 0.002138   Batch Acc: 89.06
[Train] Epoch: 3 [173952/387873]    Loss: 0.001718   Batch Acc: 88.28
[Train] Epoch: 3 [174080/387873]    Loss: 0.001858   Batch Acc: 88.28
[Train] Epoch: 3 [174208/387873]    Loss: 0.001470   Batch Acc: 93.75
[Train] Epoch: 3 [174336/387873]    Loss: 0.002094   Batch Acc: 89.06
[Train] Epoch: 3 [174464/387873]    Loss: 0.002131   Batch Acc: 87.50
[Train] Epoch: 3 [174592/387873]    Loss: 0.002252   Batch Acc: 88.28
[Train] Epoch: 3 [174720/387873]    Loss: 0.001512   Batch Acc: 92.97
[Train] Epoch: 3 [174848/387873]    Loss: 0.002161   Batch Acc: 89.06
[Train] Epoch: 3 [174976/387873]    Loss: 0.001752   Batch Acc: 92.19
[Train] Epoch: 3 [175104/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 3 [175232/387873]    Loss: 0.002183   Batch Acc: 86.72
[Train] Epoch: 3 [175360/387873]    Loss: 0.001849   Batch Acc: 89.06
[Train] Epoch: 3 [175488/387873]    Loss: 0.002205   Batch Acc: 88.28
[Train] Epoch: 3 [175616/387873]    Loss: 0.002800   Batch Acc: 85.16
[Train] Epoch: 3 [175744/387873]    Loss: 0.002051   Batch Acc: 87.50
[Train] Epoch: 3 [175872/387873]    Loss: 0.002511   Batch Acc: 86.72
[Train] Epoch: 3 [176000/387873]    Loss: 0.002791   Batch Acc: 85.16
[Train] Epoch: 3 [176128/387873]    Loss: 0.001953   Batch Acc: 89.06
[Train] Epoch: 3 [176256/387873]    Loss: 0.001941   Batch Acc: 88.28
[Train] Epoch: 3 [176384/387873]    Loss: 0.002779   Batch Acc: 82.03
[Train] Epoch: 3 [176512/387873]    Loss: 0.002711   Batch Acc: 84.38
[Train] Epoch: 3 [176640/387873]    Loss: 0.001758   Batch Acc: 91.41
[Train] Epoch: 3 [176768/387873]    Loss: 0.002301   Batch Acc: 89.06
[Train] Epoch: 3 [176896/387873]    Loss: 0.001666   Batch Acc: 91.41
[Train] Epoch: 3 [177024/387873]    Loss: 0.002387   Batch Acc: 85.16
[Train] Epoch: 3 [177152/387873]    Loss: 0.002220   Batch Acc: 87.50
[Train] Epoch: 3 [177280/387873]    Loss: 0.002067   Batch Acc: 86.72
[Train] Epoch: 3 [177408/387873]    Loss: 0.001998   Batch Acc: 89.84
[Train] Epoch: 3 [177536/387873]    Loss: 0.002186   Batch Acc: 87.50
[Train] Epoch: 3 [177664/387873]    Loss: 0.002069   Batch Acc: 89.06
[Train] Epoch: 3 [177792/387873]    Loss: 0.001797   Batch Acc: 89.06
[Train] Epoch: 3 [177920/387873]    Loss: 0.001548   Batch Acc: 92.19
[Train] Epoch: 3 [178048/387873]    Loss: 0.002405   Batch Acc: 86.72
[Train] Epoch: 3 [178176/387873]    Loss: 0.002216   Batch Acc: 85.16
[Train] Epoch: 3 [178304/387873]    Loss: 0.001673   Batch Acc: 92.19
[Train] Epoch: 3 [178432/387873]    Loss: 0.002295   Batch Acc: 85.94
[Train] Epoch: 3 [178560/387873]    Loss: 0.001708   Batch Acc: 93.75
[Train] Epoch: 3 [178688/387873]    Loss: 0.001836   Batch Acc: 89.84
[Train] Epoch: 3 [178816/387873]    Loss: 0.002834   Batch Acc: 87.50
[Train] Epoch: 3 [178944/387873]    Loss: 0.002152   Batch Acc: 87.50
[Train] Epoch: 3 [179072/387873]    Loss: 0.002311   Batch Acc: 87.50
[Train] Epoch: 3 [179200/387873]    Loss: 0.001862   Batch Acc: 91.41
[Train] Epoch: 3 [179328/387873]    Loss: 0.002325   Batch Acc: 89.84
[Train] Epoch: 3 [179456/387873]    Loss: 0.002158   Batch Acc: 87.50
[Train] Epoch: 3 [179584/387873]    Loss: 0.002343   Batch Acc: 86.72
[Train] Epoch: 3 [179712/387873]    Loss: 0.002060   Batch Acc: 89.84
[Train] Epoch: 3 [179840/387873]    Loss: 0.001734   Batch Acc: 90.62
[Train] Epoch: 3 [179968/387873]    Loss: 0.001724   Batch Acc: 92.19
[Train] Epoch: 3 [180096/387873]    Loss: 0.002388   Batch Acc: 88.28
[Train] Epoch: 3 [180224/387873]    Loss: 0.001923   Batch Acc: 90.62
[Train] Epoch: 3 [180352/387873]    Loss: 0.001664   Batch Acc: 89.84
[Train] Epoch: 3 [180480/387873]    Loss: 0.002351   Batch Acc: 85.94
[Train] Epoch: 3 [180608/387873]    Loss: 0.002464   Batch Acc: 88.28
[Train] Epoch: 3 [180736/387873]    Loss: 0.002319   Batch Acc: 86.72
[Train] Epoch: 3 [180864/387873]    Loss: 0.001465   Batch Acc: 94.53
[Train] Epoch: 3 [180992/387873]    Loss: 0.002508   Batch Acc: 83.59
[Train] Epoch: 3 [181120/387873]    Loss: 0.001666   Batch Acc: 92.19
[Train] Epoch: 3 [181248/387873]    Loss: 0.002078   Batch Acc: 88.28
[Train] Epoch: 3 [181376/387873]    Loss: 0.001869   Batch Acc: 92.97
[Train] Epoch: 3 [181504/387873]    Loss: 0.002043   Batch Acc: 91.41
[Train] Epoch: 3 [181632/387873]    Loss: 0.001810   Batch Acc: 91.41
[Train] Epoch: 3 [181760/387873]    Loss: 0.001940   Batch Acc: 91.41
[Train] Epoch: 3 [181888/387873]    Loss: 0.002317   Batch Acc: 86.72
[Train] Epoch: 3 [182016/387873]    Loss: 0.001883   Batch Acc: 89.84
[Train] Epoch: 3 [182144/387873]    Loss: 0.001955   Batch Acc: 90.62
[Train] Epoch: 3 [182272/387873]    Loss: 0.001812   Batch Acc: 89.06
[Train] Epoch: 3 [182400/387873]    Loss: 0.001655   Batch Acc: 93.75
[Train] Epoch: 3 [182528/387873]    Loss: 0.002077   Batch Acc: 90.62
[Train] Epoch: 3 [182656/387873]    Loss: 0.001990   Batch Acc: 87.50
[Train] Epoch: 3 [182784/387873]    Loss: 0.001720   Batch Acc: 92.97
[Train] Epoch: 3 [182912/387873]    Loss: 0.001477   Batch Acc: 93.75
[Train] Epoch: 3 [183040/387873]    Loss: 0.001845   Batch Acc: 89.84
[Train] Epoch: 3 [183168/387873]    Loss: 0.001625   Batch Acc: 92.19
[Train] Epoch: 3 [183296/387873]    Loss: 0.001891   Batch Acc: 91.41
[Train] Epoch: 3 [183424/387873]    Loss: 0.002065   Batch Acc: 89.06
[Train] Epoch: 3 [183552/387873]    Loss: 0.001645   Batch Acc: 91.41
[Train] Epoch: 3 [183680/387873]    Loss: 0.001780   Batch Acc: 89.06
[Train] Epoch: 3 [183808/387873]    Loss: 0.001229   Batch Acc: 96.88
[Train] Epoch: 3 [183936/387873]    Loss: 0.002286   Batch Acc: 89.06
[Train] Epoch: 3 [184064/387873]    Loss: 0.002073   Batch Acc: 86.72
[Train] Epoch: 3 [184192/387873]    Loss: 0.002294   Batch Acc: 85.94
[Train] Epoch: 3 [184320/387873]    Loss: 0.002106   Batch Acc: 89.06
[Train] Epoch: 3 [184448/387873]    Loss: 0.001607   Batch Acc: 92.97
[Train] Epoch: 3 [184576/387873]    Loss: 0.001626   Batch Acc: 92.19
[Train] Epoch: 3 [184704/387873]    Loss: 0.002568   Batch Acc: 85.16
[Train] Epoch: 3 [184832/387873]    Loss: 0.002111   Batch Acc: 89.06
[Train] Epoch: 3 [184960/387873]    Loss: 0.001904   Batch Acc: 92.19
[Train] Epoch: 3 [185088/387873]    Loss: 0.001945   Batch Acc: 91.41
[Train] Epoch: 3 [185216/387873]    Loss: 0.002224   Batch Acc: 88.28
[Train] Epoch: 3 [185344/387873]    Loss: 0.002605   Batch Acc: 84.38
[Train] Epoch: 3 [185472/387873]    Loss: 0.001675   Batch Acc: 90.62
[Train] Epoch: 3 [185600/387873]    Loss: 0.002078   Batch Acc: 89.06
[Train] Epoch: 3 [185728/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 3 [185856/387873]    Loss: 0.002258   Batch Acc: 86.72
[Train] Epoch: 3 [185984/387873]    Loss: 0.001858   Batch Acc: 90.62
[Train] Epoch: 3 [186112/387873]    Loss: 0.001865   Batch Acc: 92.97
[Train] Epoch: 3 [186240/387873]    Loss: 0.002199   Batch Acc: 87.50
[Train] Epoch: 3 [186368/387873]    Loss: 0.002125   Batch Acc: 89.84
[Train] Epoch: 3 [186496/387873]    Loss: 0.001877   Batch Acc: 89.06
[Train] Epoch: 3 [186624/387873]    Loss: 0.001571   Batch Acc: 92.97
[Train] Epoch: 3 [186752/387873]    Loss: 0.002146   Batch Acc: 89.84
[Train] Epoch: 3 [186880/387873]    Loss: 0.001728   Batch Acc: 90.62
[Train] Epoch: 3 [187008/387873]    Loss: 0.002007   Batch Acc: 87.50
[Train] Epoch: 3 [187136/387873]    Loss: 0.002223   Batch Acc: 87.50
[Train] Epoch: 3 [187264/387873]    Loss: 0.002009   Batch Acc: 90.62
[Train] Epoch: 3 [187392/387873]    Loss: 0.001998   Batch Acc: 92.19
[Train] Epoch: 3 [187520/387873]    Loss: 0.002177   Batch Acc: 85.94
[Train] Epoch: 3 [187648/387873]    Loss: 0.001854   Batch Acc: 91.41
[Train] Epoch: 3 [187776/387873]    Loss: 0.001782   Batch Acc: 89.06
[Train] Epoch: 3 [187904/387873]    Loss: 0.002029   Batch Acc: 92.19
[Train] Epoch: 3 [188032/387873]    Loss: 0.002150   Batch Acc: 90.62
[Train] Epoch: 3 [188160/387873]    Loss: 0.001680   Batch Acc: 89.84
[Train] Epoch: 3 [188288/387873]    Loss: 0.002005   Batch Acc: 89.84
[Train] Epoch: 3 [188416/387873]    Loss: 0.002003   Batch Acc: 92.19
[Train] Epoch: 3 [188544/387873]    Loss: 0.001466   Batch Acc: 92.97
[Train] Epoch: 3 [188672/387873]    Loss: 0.002358   Batch Acc: 89.06
[Train] Epoch: 3 [188800/387873]    Loss: 0.001377   Batch Acc: 93.75
[Train] Epoch: 3 [188928/387873]    Loss: 0.001990   Batch Acc: 92.19
[Train] Epoch: 3 [189056/387873]    Loss: 0.001378   Batch Acc: 96.09
[Train] Epoch: 3 [189184/387873]    Loss: 0.001705   Batch Acc: 91.41
[Train] Epoch: 3 [189312/387873]    Loss: 0.001697   Batch Acc: 92.97
[Train] Epoch: 3 [189440/387873]    Loss: 0.001975   Batch Acc: 88.28
[Train] Epoch: 3 [189568/387873]    Loss: 0.002063   Batch Acc: 89.06
[Train] Epoch: 3 [189696/387873]    Loss: 0.002114   Batch Acc: 89.06
[Train] Epoch: 3 [189824/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 3 [189952/387873]    Loss: 0.002007   Batch Acc: 91.41
[Train] Epoch: 3 [190080/387873]    Loss: 0.002093   Batch Acc: 88.28
[Train] Epoch: 3 [190208/387873]    Loss: 0.001920   Batch Acc: 92.19
[Train] Epoch: 3 [190336/387873]    Loss: 0.001992   Batch Acc: 89.84
[Train] Epoch: 3 [190464/387873]    Loss: 0.001655   Batch Acc: 91.41
[Train] Epoch: 3 [190592/387873]    Loss: 0.002067   Batch Acc: 87.50
[Train] Epoch: 3 [190720/387873]    Loss: 0.001834   Batch Acc: 89.84
[Train] Epoch: 3 [190848/387873]    Loss: 0.001948   Batch Acc: 89.84
[Train] Epoch: 3 [190976/387873]    Loss: 0.002123   Batch Acc: 87.50
[Train] Epoch: 3 [191104/387873]    Loss: 0.002436   Batch Acc: 87.50
[Train] Epoch: 3 [191232/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 3 [191360/387873]    Loss: 0.002128   Batch Acc: 88.28
[Train] Epoch: 3 [191488/387873]    Loss: 0.001872   Batch Acc: 87.50
[Train] Epoch: 3 [191616/387873]    Loss: 0.002424   Batch Acc: 86.72
[Train] Epoch: 3 [191744/387873]    Loss: 0.002274   Batch Acc: 89.06
[Train] Epoch: 3 [191872/387873]    Loss: 0.001971   Batch Acc: 88.28
[Train] Epoch: 3 [192000/387873]    Loss: 0.001833   Batch Acc: 89.06
[Train] Epoch: 3 [192128/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 3 [192256/387873]    Loss: 0.001861   Batch Acc: 91.41
[Train] Epoch: 3 [192384/387873]    Loss: 0.002190   Batch Acc: 85.94
[Train] Epoch: 3 [192512/387873]    Loss: 0.001692   Batch Acc: 91.41
[Train] Epoch: 3 [192640/387873]    Loss: 0.002590   Batch Acc: 82.81
[Train] Epoch: 3 [192768/387873]    Loss: 0.002411   Batch Acc: 86.72
[Train] Epoch: 3 [192896/387873]    Loss: 0.002049   Batch Acc: 89.84
[Train] Epoch: 3 [193024/387873]    Loss: 0.001845   Batch Acc: 90.62
[Train] Epoch: 3 [193152/387873]    Loss: 0.002474   Batch Acc: 88.28
[Train] Epoch: 3 [193280/387873]    Loss: 0.002066   Batch Acc: 88.28
[Train] Epoch: 3 [193408/387873]    Loss: 0.002172   Batch Acc: 90.62
[Train] Epoch: 3 [193536/387873]    Loss: 0.002326   Batch Acc: 90.62
[Train] Epoch: 3 [193664/387873]    Loss: 0.002161   Batch Acc: 89.84
[Train] Epoch: 3 [193792/387873]    Loss: 0.002245   Batch Acc: 86.72
[Train] Epoch: 3 [193920/387873]    Loss: 0.002321   Batch Acc: 89.06
[Train] Epoch: 3 [194048/387873]    Loss: 0.002252   Batch Acc: 86.72
[Train] Epoch: 3 [194176/387873]    Loss: 0.001709   Batch Acc: 89.84
[Train] Epoch: 3 [194304/387873]    Loss: 0.001537   Batch Acc: 92.19
[Train] Epoch: 3 [194432/387873]    Loss: 0.002002   Batch Acc: 89.84
[Train] Epoch: 3 [194560/387873]    Loss: 0.001734   Batch Acc: 91.41
[Train] Epoch: 3 [194688/387873]    Loss: 0.001817   Batch Acc: 91.41
[Train] Epoch: 3 [194816/387873]    Loss: 0.001868   Batch Acc: 87.50
[Train] Epoch: 3 [194944/387873]    Loss: 0.002222   Batch Acc: 88.28
[Train] Epoch: 3 [195072/387873]    Loss: 0.002345   Batch Acc: 85.94
[Train] Epoch: 3 [195200/387873]    Loss: 0.001835   Batch Acc: 92.97
[Train] Epoch: 3 [195328/387873]    Loss: 0.001585   Batch Acc: 92.97
[Train] Epoch: 3 [195456/387873]    Loss: 0.001952   Batch Acc: 88.28
[Train] Epoch: 3 [195584/387873]    Loss: 0.001984   Batch Acc: 91.41
[Train] Epoch: 3 [195712/387873]    Loss: 0.001962   Batch Acc: 89.84
[Train] Epoch: 3 [195840/387873]    Loss: 0.001738   Batch Acc: 89.06
[Train] Epoch: 3 [195968/387873]    Loss: 0.001976   Batch Acc: 87.50
[Train] Epoch: 3 [196096/387873]    Loss: 0.001865   Batch Acc: 91.41
[Train] Epoch: 3 [196224/387873]    Loss: 0.002247   Batch Acc: 90.62
[Train] Epoch: 3 [196352/387873]    Loss: 0.001576   Batch Acc: 94.53
[Train] Epoch: 3 [196480/387873]    Loss: 0.001920   Batch Acc: 89.84
[Train] Epoch: 3 [196608/387873]    Loss: 0.002021   Batch Acc: 89.84
[Train] Epoch: 3 [196736/387873]    Loss: 0.002023   Batch Acc: 91.41
[Train] Epoch: 3 [196864/387873]    Loss: 0.001906   Batch Acc: 91.41
[Train] Epoch: 3 [196992/387873]    Loss: 0.002424   Batch Acc: 89.84
[Train] Epoch: 3 [197120/387873]    Loss: 0.002459   Batch Acc: 85.16
[Train] Epoch: 3 [197248/387873]    Loss: 0.002060   Batch Acc: 87.50
[Train] Epoch: 3 [197376/387873]    Loss: 0.001802   Batch Acc: 92.19
[Train] Epoch: 3 [197504/387873]    Loss: 0.001304   Batch Acc: 92.97
[Train] Epoch: 3 [197632/387873]    Loss: 0.001510   Batch Acc: 91.41
[Train] Epoch: 3 [197760/387873]    Loss: 0.002105   Batch Acc: 89.84
[Train] Epoch: 3 [197888/387873]    Loss: 0.002384   Batch Acc: 85.94
[Train] Epoch: 3 [198016/387873]    Loss: 0.001665   Batch Acc: 92.97
[Train] Epoch: 3 [198144/387873]    Loss: 0.002177   Batch Acc: 89.84
[Train] Epoch: 3 [198272/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 3 [198400/387873]    Loss: 0.002257   Batch Acc: 86.72
[Train] Epoch: 3 [198528/387873]    Loss: 0.001845   Batch Acc: 89.06
[Train] Epoch: 3 [198656/387873]    Loss: 0.001657   Batch Acc: 89.84
[Train] Epoch: 3 [198784/387873]    Loss: 0.002109   Batch Acc: 89.06
[Train] Epoch: 3 [198912/387873]    Loss: 0.001464   Batch Acc: 93.75
[Train] Epoch: 3 [199040/387873]    Loss: 0.002611   Batch Acc: 84.38
[Train] Epoch: 3 [199168/387873]    Loss: 0.002256   Batch Acc: 89.06
[Train] Epoch: 3 [199296/387873]    Loss: 0.002309   Batch Acc: 85.94
[Train] Epoch: 3 [199424/387873]    Loss: 0.002516   Batch Acc: 84.38
[Train] Epoch: 3 [199552/387873]    Loss: 0.001801   Batch Acc: 91.41
[Train] Epoch: 3 [199680/387873]    Loss: 0.002567   Batch Acc: 83.59
[Train] Epoch: 3 [199808/387873]    Loss: 0.001852   Batch Acc: 89.06
[Train] Epoch: 3 [199936/387873]    Loss: 0.002171   Batch Acc: 89.84
[Train] Epoch: 3 [200064/387873]    Loss: 0.001942   Batch Acc: 90.62
[Train] Epoch: 3 [200192/387873]    Loss: 0.002430   Batch Acc: 87.50
[Train] Epoch: 3 [200320/387873]    Loss: 0.002187   Batch Acc: 89.06
[Train] Epoch: 3 [200448/387873]    Loss: 0.002913   Batch Acc: 84.38
[Train] Epoch: 3 [200576/387873]    Loss: 0.002418   Batch Acc: 88.28
[Train] Epoch: 3 [200704/387873]    Loss: 0.002625   Batch Acc: 84.38
[Train] Epoch: 3 [200832/387873]    Loss: 0.002476   Batch Acc: 89.06
[Train] Epoch: 3 [200960/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 3 [201088/387873]    Loss: 0.002158   Batch Acc: 87.50
[Train] Epoch: 3 [201216/387873]    Loss: 0.001416   Batch Acc: 92.19
[Train] Epoch: 3 [201344/387873]    Loss: 0.001978   Batch Acc: 89.84
[Train] Epoch: 3 [201472/387873]    Loss: 0.002053   Batch Acc: 89.84
[Train] Epoch: 3 [201600/387873]    Loss: 0.002406   Batch Acc: 88.28
[Train] Epoch: 3 [201728/387873]    Loss: 0.001985   Batch Acc: 88.28
[Train] Epoch: 3 [201856/387873]    Loss: 0.001516   Batch Acc: 89.84
[Train] Epoch: 3 [201984/387873]    Loss: 0.001459   Batch Acc: 93.75
[Train] Epoch: 3 [202112/387873]    Loss: 0.002221   Batch Acc: 89.84
[Train] Epoch: 3 [202240/387873]    Loss: 0.002179   Batch Acc: 87.50
[Train] Epoch: 3 [202368/387873]    Loss: 0.002269   Batch Acc: 89.84
[Train] Epoch: 3 [202496/387873]    Loss: 0.001923   Batch Acc: 90.62
[Train] Epoch: 3 [202624/387873]    Loss: 0.001600   Batch Acc: 93.75
[Train] Epoch: 3 [202752/387873]    Loss: 0.001673   Batch Acc: 91.41
[Train] Epoch: 3 [202880/387873]    Loss: 0.001769   Batch Acc: 92.19
[Train] Epoch: 3 [203008/387873]    Loss: 0.002427   Batch Acc: 85.94
[Train] Epoch: 3 [203136/387873]    Loss: 0.001734   Batch Acc: 91.41
[Train] Epoch: 3 [203264/387873]    Loss: 0.001561   Batch Acc: 91.41
[Train] Epoch: 3 [203392/387873]    Loss: 0.002291   Batch Acc: 86.72
[Train] Epoch: 3 [203520/387873]    Loss: 0.001601   Batch Acc: 91.41
[Train] Epoch: 3 [203648/387873]    Loss: 0.002123   Batch Acc: 86.72
[Train] Epoch: 3 [203776/387873]    Loss: 0.001439   Batch Acc: 92.19
[Train] Epoch: 3 [203904/387873]    Loss: 0.002001   Batch Acc: 89.84
[Train] Epoch: 3 [204032/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 3 [204160/387873]    Loss: 0.001862   Batch Acc: 87.50
[Train] Epoch: 3 [204288/387873]    Loss: 0.002174   Batch Acc: 88.28
[Train] Epoch: 3 [204416/387873]    Loss: 0.002052   Batch Acc: 88.28
[Train] Epoch: 3 [204544/387873]    Loss: 0.001858   Batch Acc: 89.84
[Train] Epoch: 3 [204672/387873]    Loss: 0.002152   Batch Acc: 86.72
[Train] Epoch: 3 [204800/387873]    Loss: 0.002313   Batch Acc: 86.72
[Train] Epoch: 3 [204928/387873]    Loss: 0.001562   Batch Acc: 94.53
[Train] Epoch: 3 [205056/387873]    Loss: 0.001703   Batch Acc: 92.19
[Train] Epoch: 3 [205184/387873]    Loss: 0.001645   Batch Acc: 91.41
[Train] Epoch: 3 [205312/387873]    Loss: 0.001963   Batch Acc: 89.06
[Train] Epoch: 3 [205440/387873]    Loss: 0.001904   Batch Acc: 88.28
[Train] Epoch: 3 [205568/387873]    Loss: 0.001866   Batch Acc: 90.62
[Train] Epoch: 3 [205696/387873]    Loss: 0.002180   Batch Acc: 86.72
[Train] Epoch: 3 [205824/387873]    Loss: 0.002446   Batch Acc: 88.28
[Train] Epoch: 3 [205952/387873]    Loss: 0.001771   Batch Acc: 89.84
[Train] Epoch: 3 [206080/387873]    Loss: 0.001700   Batch Acc: 91.41
[Train] Epoch: 3 [206208/387873]    Loss: 0.002273   Batch Acc: 89.06
[Train] Epoch: 3 [206336/387873]    Loss: 0.001520   Batch Acc: 93.75
[Train] Epoch: 3 [206464/387873]    Loss: 0.002327   Batch Acc: 88.28
[Train] Epoch: 3 [206592/387873]    Loss: 0.001732   Batch Acc: 92.97
[Train] Epoch: 3 [206720/387873]    Loss: 0.002196   Batch Acc: 87.50
[Train] Epoch: 3 [206848/387873]    Loss: 0.002421   Batch Acc: 85.94
[Train] Epoch: 3 [206976/387873]    Loss: 0.001924   Batch Acc: 91.41
[Train] Epoch: 3 [207104/387873]    Loss: 0.001890   Batch Acc: 90.62
[Train] Epoch: 3 [207232/387873]    Loss: 0.002216   Batch Acc: 85.16
[Train] Epoch: 3 [207360/387873]    Loss: 0.001772   Batch Acc: 90.62
[Train] Epoch: 3 [207488/387873]    Loss: 0.002674   Batch Acc: 85.94
[Train] Epoch: 3 [207616/387873]    Loss: 0.002544   Batch Acc: 85.16
[Train] Epoch: 3 [207744/387873]    Loss: 0.001853   Batch Acc: 91.41
[Train] Epoch: 3 [207872/387873]    Loss: 0.001817   Batch Acc: 90.62
[Train] Epoch: 3 [208000/387873]    Loss: 0.001855   Batch Acc: 87.50
[Train] Epoch: 3 [208128/387873]    Loss: 0.002048   Batch Acc: 89.84
[Train] Epoch: 3 [208256/387873]    Loss: 0.002474   Batch Acc: 87.50
[Train] Epoch: 3 [208384/387873]    Loss: 0.002121   Batch Acc: 91.41
[Train] Epoch: 3 [208512/387873]    Loss: 0.001767   Batch Acc: 92.19
[Train] Epoch: 3 [208640/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 3 [208768/387873]    Loss: 0.002215   Batch Acc: 87.50
[Train] Epoch: 3 [208896/387873]    Loss: 0.002320   Batch Acc: 85.16
[Train] Epoch: 3 [209024/387873]    Loss: 0.002045   Batch Acc: 88.28
[Train] Epoch: 3 [209152/387873]    Loss: 0.001875   Batch Acc: 92.97
[Train] Epoch: 3 [209280/387873]    Loss: 0.002044   Batch Acc: 88.28
[Train] Epoch: 3 [209408/387873]    Loss: 0.001956   Batch Acc: 89.84
[Train] Epoch: 3 [209536/387873]    Loss: 0.002160   Batch Acc: 91.41
[Train] Epoch: 3 [209664/387873]    Loss: 0.002110   Batch Acc: 86.72
[Train] Epoch: 3 [209792/387873]    Loss: 0.002613   Batch Acc: 85.16
[Train] Epoch: 3 [209920/387873]    Loss: 0.002147   Batch Acc: 89.84
[Train] Epoch: 3 [210048/387873]    Loss: 0.001773   Batch Acc: 89.84
[Train] Epoch: 3 [210176/387873]    Loss: 0.001887   Batch Acc: 89.84
[Train] Epoch: 3 [210304/387873]    Loss: 0.001503   Batch Acc: 94.53
[Train] Epoch: 3 [210432/387873]    Loss: 0.001655   Batch Acc: 90.62
[Train] Epoch: 3 [210560/387873]    Loss: 0.001547   Batch Acc: 92.97
[Train] Epoch: 3 [210688/387873]    Loss: 0.002000   Batch Acc: 92.97
[Train] Epoch: 3 [210816/387873]    Loss: 0.001553   Batch Acc: 92.19
[Train] Epoch: 3 [210944/387873]    Loss: 0.002642   Batch Acc: 88.28
[Train] Epoch: 3 [211072/387873]    Loss: 0.002027   Batch Acc: 89.84
[Train] Epoch: 3 [211200/387873]    Loss: 0.001853   Batch Acc: 91.41
[Train] Epoch: 3 [211328/387873]    Loss: 0.002503   Batch Acc: 85.16
[Train] Epoch: 3 [211456/387873]    Loss: 0.001853   Batch Acc: 90.62
[Train] Epoch: 3 [211584/387873]    Loss: 0.002027   Batch Acc: 89.84
[Train] Epoch: 3 [211712/387873]    Loss: 0.002228   Batch Acc: 89.84
[Train] Epoch: 3 [211840/387873]    Loss: 0.001789   Batch Acc: 92.19
[Train] Epoch: 3 [211968/387873]    Loss: 0.001756   Batch Acc: 92.97
[Train] Epoch: 3 [212096/387873]    Loss: 0.001753   Batch Acc: 92.97
[Train] Epoch: 3 [212224/387873]    Loss: 0.001871   Batch Acc: 91.41
[Train] Epoch: 3 [212352/387873]    Loss: 0.001690   Batch Acc: 91.41
[Train] Epoch: 3 [212480/387873]    Loss: 0.001968   Batch Acc: 88.28
[Train] Epoch: 3 [212608/387873]    Loss: 0.001724   Batch Acc: 93.75
[Train] Epoch: 3 [212736/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 3 [212864/387873]    Loss: 0.002000   Batch Acc: 87.50
[Train] Epoch: 3 [212992/387873]    Loss: 0.002013   Batch Acc: 87.50
[Train] Epoch: 3 [213120/387873]    Loss: 0.001941   Batch Acc: 92.19
[Train] Epoch: 3 [213248/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 3 [213376/387873]    Loss: 0.001831   Batch Acc: 89.84
[Train] Epoch: 3 [213504/387873]    Loss: 0.002152   Batch Acc: 87.50
[Train] Epoch: 3 [213632/387873]    Loss: 0.002248   Batch Acc: 89.84
[Train] Epoch: 3 [213760/387873]    Loss: 0.001764   Batch Acc: 92.97
[Train] Epoch: 3 [213888/387873]    Loss: 0.001335   Batch Acc: 92.97
[Train] Epoch: 3 [214016/387873]    Loss: 0.002117   Batch Acc: 87.50
[Train] Epoch: 3 [214144/387873]    Loss: 0.001542   Batch Acc: 93.75
[Train] Epoch: 3 [214272/387873]    Loss: 0.001352   Batch Acc: 93.75
[Train] Epoch: 3 [214400/387873]    Loss: 0.001947   Batch Acc: 89.84
[Train] Epoch: 3 [214528/387873]    Loss: 0.002100   Batch Acc: 89.84
[Train] Epoch: 3 [214656/387873]    Loss: 0.001839   Batch Acc: 88.28
[Train] Epoch: 3 [214784/387873]    Loss: 0.002089   Batch Acc: 87.50
[Train] Epoch: 3 [214912/387873]    Loss: 0.002163   Batch Acc: 89.06
[Train] Epoch: 3 [215040/387873]    Loss: 0.001514   Batch Acc: 92.97
[Train] Epoch: 3 [215168/387873]    Loss: 0.001679   Batch Acc: 92.19
[Train] Epoch: 3 [215296/387873]    Loss: 0.001833   Batch Acc: 89.84
[Train] Epoch: 3 [215424/387873]    Loss: 0.001915   Batch Acc: 92.19
[Train] Epoch: 3 [215552/387873]    Loss: 0.001973   Batch Acc: 90.62
[Train] Epoch: 3 [215680/387873]    Loss: 0.001912   Batch Acc: 89.84
[Train] Epoch: 3 [215808/387873]    Loss: 0.002343   Batch Acc: 90.62
[Train] Epoch: 3 [215936/387873]    Loss: 0.002311   Batch Acc: 86.72
[Train] Epoch: 3 [216064/387873]    Loss: 0.002697   Batch Acc: 89.84
[Train] Epoch: 3 [216192/387873]    Loss: 0.001870   Batch Acc: 89.84
[Train] Epoch: 3 [216320/387873]    Loss: 0.001770   Batch Acc: 91.41
[Train] Epoch: 3 [216448/387873]    Loss: 0.001762   Batch Acc: 91.41
[Train] Epoch: 3 [216576/387873]    Loss: 0.002258   Batch Acc: 85.94
[Train] Epoch: 3 [216704/387873]    Loss: 0.002496   Batch Acc: 85.16
[Train] Epoch: 3 [216832/387873]    Loss: 0.002124   Batch Acc: 86.72
[Train] Epoch: 3 [216960/387873]    Loss: 0.001628   Batch Acc: 92.97
[Train] Epoch: 3 [217088/387873]    Loss: 0.001446   Batch Acc: 93.75
[Train] Epoch: 3 [217216/387873]    Loss: 0.002171   Batch Acc: 87.50
[Train] Epoch: 3 [217344/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 3 [217472/387873]    Loss: 0.001994   Batch Acc: 88.28
[Train] Epoch: 3 [217600/387873]    Loss: 0.001474   Batch Acc: 92.97
[Train] Epoch: 3 [217728/387873]    Loss: 0.002229   Batch Acc: 85.94
[Train] Epoch: 3 [217856/387873]    Loss: 0.002437   Batch Acc: 85.94
[Train] Epoch: 3 [217984/387873]    Loss: 0.001915   Batch Acc: 92.97
[Train] Epoch: 3 [218112/387873]    Loss: 0.002456   Batch Acc: 87.50
[Train] Epoch: 3 [218240/387873]    Loss: 0.002340   Batch Acc: 86.72
[Train] Epoch: 3 [218368/387873]    Loss: 0.002051   Batch Acc: 87.50
[Train] Epoch: 3 [218496/387873]    Loss: 0.002029   Batch Acc: 89.06
[Train] Epoch: 3 [218624/387873]    Loss: 0.002407   Batch Acc: 87.50
[Train] Epoch: 3 [218752/387873]    Loss: 0.001683   Batch Acc: 91.41
[Train] Epoch: 3 [218880/387873]    Loss: 0.001930   Batch Acc: 89.84
[Train] Epoch: 3 [219008/387873]    Loss: 0.002012   Batch Acc: 87.50
[Train] Epoch: 3 [219136/387873]    Loss: 0.001578   Batch Acc: 92.97
[Train] Epoch: 3 [219264/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 3 [219392/387873]    Loss: 0.001924   Batch Acc: 88.28
[Train] Epoch: 3 [219520/387873]    Loss: 0.002393   Batch Acc: 83.59
[Train] Epoch: 3 [219648/387873]    Loss: 0.002546   Batch Acc: 86.72
[Train] Epoch: 3 [219776/387873]    Loss: 0.002660   Batch Acc: 83.59
[Train] Epoch: 3 [219904/387873]    Loss: 0.002218   Batch Acc: 87.50
[Train] Epoch: 3 [220032/387873]    Loss: 0.002296   Batch Acc: 88.28
[Train] Epoch: 3 [220160/387873]    Loss: 0.002434   Batch Acc: 83.59
[Train] Epoch: 3 [220288/387873]    Loss: 0.001506   Batch Acc: 92.19
[Train] Epoch: 3 [220416/387873]    Loss: 0.001939   Batch Acc: 89.84
[Train] Epoch: 3 [220544/387873]    Loss: 0.001889   Batch Acc: 91.41
[Train] Epoch: 3 [220672/387873]    Loss: 0.002342   Batch Acc: 85.16
[Train] Epoch: 3 [220800/387873]    Loss: 0.002273   Batch Acc: 86.72
[Train] Epoch: 3 [220928/387873]    Loss: 0.001623   Batch Acc: 91.41
[Train] Epoch: 3 [221056/387873]    Loss: 0.001786   Batch Acc: 88.28
[Train] Epoch: 3 [221184/387873]    Loss: 0.001771   Batch Acc: 92.19
[Train] Epoch: 3 [221312/387873]    Loss: 0.001629   Batch Acc: 91.41
[Train] Epoch: 3 [221440/387873]    Loss: 0.002781   Batch Acc: 84.38
[Train] Epoch: 3 [221568/387873]    Loss: 0.001447   Batch Acc: 92.97
[Train] Epoch: 3 [221696/387873]    Loss: 0.002025   Batch Acc: 89.84
[Train] Epoch: 3 [221824/387873]    Loss: 0.001836   Batch Acc: 92.19
[Train] Epoch: 3 [221952/387873]    Loss: 0.001878   Batch Acc: 90.62
[Train] Epoch: 3 [222080/387873]    Loss: 0.002099   Batch Acc: 90.62
[Train] Epoch: 3 [222208/387873]    Loss: 0.002555   Batch Acc: 85.16
[Train] Epoch: 3 [222336/387873]    Loss: 0.001752   Batch Acc: 92.19
[Train] Epoch: 3 [222464/387873]    Loss: 0.002432   Batch Acc: 83.59
[Train] Epoch: 3 [222592/387873]    Loss: 0.002119   Batch Acc: 88.28
[Train] Epoch: 3 [222720/387873]    Loss: 0.001886   Batch Acc: 91.41
[Train] Epoch: 3 [222848/387873]    Loss: 0.001974   Batch Acc: 89.84
[Train] Epoch: 3 [222976/387873]    Loss: 0.001691   Batch Acc: 92.97
[Train] Epoch: 3 [223104/387873]    Loss: 0.001925   Batch Acc: 92.19
[Train] Epoch: 3 [223232/387873]    Loss: 0.002486   Batch Acc: 86.72
[Train] Epoch: 3 [223360/387873]    Loss: 0.001796   Batch Acc: 91.41
[Train] Epoch: 3 [223488/387873]    Loss: 0.001963   Batch Acc: 92.19
[Train] Epoch: 3 [223616/387873]    Loss: 0.002003   Batch Acc: 89.06
[Train] Epoch: 3 [223744/387873]    Loss: 0.001890   Batch Acc: 89.84
[Train] Epoch: 3 [223872/387873]    Loss: 0.001799   Batch Acc: 91.41
[Train] Epoch: 3 [224000/387873]    Loss: 0.002138   Batch Acc: 85.94
[Train] Epoch: 3 [224128/387873]    Loss: 0.002060   Batch Acc: 88.28
[Train] Epoch: 3 [224256/387873]    Loss: 0.001672   Batch Acc: 90.62
[Train] Epoch: 3 [224384/387873]    Loss: 0.002441   Batch Acc: 85.94
[Train] Epoch: 3 [224512/387873]    Loss: 0.001938   Batch Acc: 89.84
[Train] Epoch: 3 [224640/387873]    Loss: 0.002626   Batch Acc: 85.94
[Train] Epoch: 3 [224768/387873]    Loss: 0.002029   Batch Acc: 86.72
[Train] Epoch: 3 [224896/387873]    Loss: 0.001716   Batch Acc: 90.62
[Train] Epoch: 3 [225024/387873]    Loss: 0.002056   Batch Acc: 92.19
[Train] Epoch: 3 [225152/387873]    Loss: 0.001497   Batch Acc: 94.53
[Train] Epoch: 3 [225280/387873]    Loss: 0.001990   Batch Acc: 87.50
[Train] Epoch: 3 [225408/387873]    Loss: 0.002591   Batch Acc: 86.72
[Train] Epoch: 3 [225536/387873]    Loss: 0.001556   Batch Acc: 95.31
[Train] Epoch: 3 [225664/387873]    Loss: 0.002071   Batch Acc: 87.50
[Train] Epoch: 3 [225792/387873]    Loss: 0.001836   Batch Acc: 91.41
[Train] Epoch: 3 [225920/387873]    Loss: 0.002227   Batch Acc: 87.50
[Train] Epoch: 3 [226048/387873]    Loss: 0.002448   Batch Acc: 88.28
[Train] Epoch: 3 [226176/387873]    Loss: 0.002285   Batch Acc: 85.16
[Train] Epoch: 3 [226304/387873]    Loss: 0.002500   Batch Acc: 84.38
[Train] Epoch: 3 [226432/387873]    Loss: 0.001910   Batch Acc: 92.19
[Train] Epoch: 3 [226560/387873]    Loss: 0.002105   Batch Acc: 91.41
[Train] Epoch: 3 [226688/387873]    Loss: 0.001636   Batch Acc: 92.97
[Train] Epoch: 3 [226816/387873]    Loss: 0.001604   Batch Acc: 90.62
[Train] Epoch: 3 [226944/387873]    Loss: 0.001650   Batch Acc: 89.84
[Train] Epoch: 3 [227072/387873]    Loss: 0.002048   Batch Acc: 89.84
[Train] Epoch: 3 [227200/387873]    Loss: 0.001654   Batch Acc: 92.19
[Train] Epoch: 3 [227328/387873]    Loss: 0.002147   Batch Acc: 89.84
[Train] Epoch: 3 [227456/387873]    Loss: 0.002439   Batch Acc: 88.28
[Train] Epoch: 3 [227584/387873]    Loss: 0.001490   Batch Acc: 92.97
[Train] Epoch: 3 [227712/387873]    Loss: 0.001998   Batch Acc: 89.06
[Train] Epoch: 3 [227840/387873]    Loss: 0.002012   Batch Acc: 89.06
[Train] Epoch: 3 [227968/387873]    Loss: 0.002345   Batch Acc: 89.06
[Train] Epoch: 3 [228096/387873]    Loss: 0.001703   Batch Acc: 91.41
[Train] Epoch: 3 [228224/387873]    Loss: 0.001746   Batch Acc: 88.28
[Train] Epoch: 3 [228352/387873]    Loss: 0.001675   Batch Acc: 93.75
[Train] Epoch: 3 [228480/387873]    Loss: 0.001796   Batch Acc: 92.19
[Train] Epoch: 3 [228608/387873]    Loss: 0.002367   Batch Acc: 86.72
[Train] Epoch: 3 [228736/387873]    Loss: 0.002107   Batch Acc: 89.84
[Train] Epoch: 3 [228864/387873]    Loss: 0.001306   Batch Acc: 94.53
[Train] Epoch: 3 [228992/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 3 [229120/387873]    Loss: 0.001383   Batch Acc: 92.97
[Train] Epoch: 3 [229248/387873]    Loss: 0.001982   Batch Acc: 85.94
[Train] Epoch: 3 [229376/387873]    Loss: 0.002391   Batch Acc: 83.59
[Train] Epoch: 3 [229504/387873]    Loss: 0.001825   Batch Acc: 90.62
[Train] Epoch: 3 [229632/387873]    Loss: 0.001672   Batch Acc: 90.62
[Train] Epoch: 3 [229760/387873]    Loss: 0.002561   Batch Acc: 85.94
[Train] Epoch: 3 [229888/387873]    Loss: 0.002413   Batch Acc: 84.38
[Train] Epoch: 3 [230016/387873]    Loss: 0.002066   Batch Acc: 91.41
[Train] Epoch: 3 [230144/387873]    Loss: 0.002217   Batch Acc: 89.06
[Train] Epoch: 3 [230272/387873]    Loss: 0.002170   Batch Acc: 86.72
[Train] Epoch: 3 [230400/387873]    Loss: 0.002000   Batch Acc: 89.84
[Train] Epoch: 3 [230528/387873]    Loss: 0.001897   Batch Acc: 89.06
[Train] Epoch: 3 [230656/387873]    Loss: 0.002074   Batch Acc: 88.28
[Train] Epoch: 3 [230784/387873]    Loss: 0.002155   Batch Acc: 84.38
[Train] Epoch: 3 [230912/387873]    Loss: 0.002627   Batch Acc: 82.03
[Train] Epoch: 3 [231040/387873]    Loss: 0.001892   Batch Acc: 90.62
[Train] Epoch: 3 [231168/387873]    Loss: 0.001664   Batch Acc: 92.19
[Train] Epoch: 3 [231296/387873]    Loss: 0.002104   Batch Acc: 88.28
[Train] Epoch: 3 [231424/387873]    Loss: 0.002523   Batch Acc: 85.16
[Train] Epoch: 3 [231552/387873]    Loss: 0.001924   Batch Acc: 87.50
[Train] Epoch: 3 [231680/387873]    Loss: 0.002287   Batch Acc: 88.28
[Train] Epoch: 3 [231808/387873]    Loss: 0.002357   Batch Acc: 87.50
[Train] Epoch: 3 [231936/387873]    Loss: 0.001420   Batch Acc: 93.75
[Train] Epoch: 3 [232064/387873]    Loss: 0.002205   Batch Acc: 86.72
[Train] Epoch: 3 [232192/387873]    Loss: 0.001737   Batch Acc: 90.62
[Train] Epoch: 3 [232320/387873]    Loss: 0.001841   Batch Acc: 92.19
[Train] Epoch: 3 [232448/387873]    Loss: 0.001655   Batch Acc: 89.84
[Train] Epoch: 3 [232576/387873]    Loss: 0.001696   Batch Acc: 91.41
[Train] Epoch: 3 [232704/387873]    Loss: 0.001973   Batch Acc: 87.50
[Train] Epoch: 3 [232832/387873]    Loss: 0.002688   Batch Acc: 80.47
[Train] Epoch: 3 [232960/387873]    Loss: 0.001450   Batch Acc: 96.09
[Train] Epoch: 3 [233088/387873]    Loss: 0.001683   Batch Acc: 92.19
[Train] Epoch: 3 [233216/387873]    Loss: 0.001993   Batch Acc: 89.84
[Train] Epoch: 3 [233344/387873]    Loss: 0.002287   Batch Acc: 87.50
[Train] Epoch: 3 [233472/387873]    Loss: 0.002102   Batch Acc: 85.16
[Train] Epoch: 3 [233600/387873]    Loss: 0.002354   Batch Acc: 86.72
[Train] Epoch: 3 [233728/387873]    Loss: 0.002411   Batch Acc: 84.38
[Train] Epoch: 3 [233856/387873]    Loss: 0.001818   Batch Acc: 92.19
[Train] Epoch: 3 [233984/387873]    Loss: 0.001878   Batch Acc: 90.62
[Train] Epoch: 3 [234112/387873]    Loss: 0.001350   Batch Acc: 93.75
[Train] Epoch: 3 [234240/387873]    Loss: 0.001566   Batch Acc: 93.75
[Train] Epoch: 3 [234368/387873]    Loss: 0.002284   Batch Acc: 87.50
[Train] Epoch: 3 [234496/387873]    Loss: 0.002071   Batch Acc: 88.28
[Train] Epoch: 3 [234624/387873]    Loss: 0.002017   Batch Acc: 87.50
[Train] Epoch: 3 [234752/387873]    Loss: 0.001791   Batch Acc: 91.41
[Train] Epoch: 3 [234880/387873]    Loss: 0.002206   Batch Acc: 85.16
[Train] Epoch: 3 [235008/387873]    Loss: 0.001955   Batch Acc: 91.41
[Train] Epoch: 3 [235136/387873]    Loss: 0.002310   Batch Acc: 89.06
[Train] Epoch: 3 [235264/387873]    Loss: 0.002393   Batch Acc: 84.38
[Train] Epoch: 3 [235392/387873]    Loss: 0.002064   Batch Acc: 89.84
[Train] Epoch: 3 [235520/387873]    Loss: 0.001576   Batch Acc: 92.19
[Train] Epoch: 3 [235648/387873]    Loss: 0.001829   Batch Acc: 91.41
[Train] Epoch: 3 [235776/387873]    Loss: 0.001992   Batch Acc: 89.84
[Train] Epoch: 3 [235904/387873]    Loss: 0.002358   Batch Acc: 87.50
[Train] Epoch: 3 [236032/387873]    Loss: 0.001513   Batch Acc: 94.53
[Train] Epoch: 3 [236160/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 3 [236288/387873]    Loss: 0.001813   Batch Acc: 92.19
[Train] Epoch: 3 [236416/387873]    Loss: 0.001881   Batch Acc: 89.84
[Train] Epoch: 3 [236544/387873]    Loss: 0.002090   Batch Acc: 88.28
[Train] Epoch: 3 [236672/387873]    Loss: 0.002196   Batch Acc: 90.62
[Train] Epoch: 3 [236800/387873]    Loss: 0.001952   Batch Acc: 87.50
[Train] Epoch: 3 [236928/387873]    Loss: 0.002767   Batch Acc: 83.59
[Train] Epoch: 3 [237056/387873]    Loss: 0.002270   Batch Acc: 86.72
[Train] Epoch: 3 [237184/387873]    Loss: 0.002011   Batch Acc: 91.41
[Train] Epoch: 3 [237312/387873]    Loss: 0.001732   Batch Acc: 88.28
[Train] Epoch: 3 [237440/387873]    Loss: 0.002091   Batch Acc: 88.28
[Train] Epoch: 3 [237568/387873]    Loss: 0.001830   Batch Acc: 92.97
[Train] Epoch: 3 [237696/387873]    Loss: 0.001994   Batch Acc: 89.84
[Train] Epoch: 3 [237824/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 3 [237952/387873]    Loss: 0.002132   Batch Acc: 85.94
[Train] Epoch: 3 [238080/387873]    Loss: 0.001892   Batch Acc: 87.50
[Train] Epoch: 3 [238208/387873]    Loss: 0.002332   Batch Acc: 87.50
[Train] Epoch: 3 [238336/387873]    Loss: 0.002092   Batch Acc: 89.06
[Train] Epoch: 3 [238464/387873]    Loss: 0.002397   Batch Acc: 85.94
[Train] Epoch: 3 [238592/387873]    Loss: 0.002443   Batch Acc: 85.94
[Train] Epoch: 3 [238720/387873]    Loss: 0.002896   Batch Acc: 81.25
[Train] Epoch: 3 [238848/387873]    Loss: 0.001524   Batch Acc: 93.75
[Train] Epoch: 3 [238976/387873]    Loss: 0.001944   Batch Acc: 91.41
[Train] Epoch: 3 [239104/387873]    Loss: 0.002239   Batch Acc: 87.50
[Train] Epoch: 3 [239232/387873]    Loss: 0.002482   Batch Acc: 85.94
[Train] Epoch: 3 [239360/387873]    Loss: 0.001913   Batch Acc: 89.84
[Train] Epoch: 3 [239488/387873]    Loss: 0.002511   Batch Acc: 85.16
[Train] Epoch: 3 [239616/387873]    Loss: 0.001743   Batch Acc: 89.84
[Train] Epoch: 3 [239744/387873]    Loss: 0.002114   Batch Acc: 89.06
[Train] Epoch: 3 [239872/387873]    Loss: 0.001537   Batch Acc: 93.75
[Train] Epoch: 3 [240000/387873]    Loss: 0.002095   Batch Acc: 89.84
[Train] Epoch: 3 [240128/387873]    Loss: 0.001992   Batch Acc: 86.72
[Train] Epoch: 3 [240256/387873]    Loss: 0.001699   Batch Acc: 89.06
[Train] Epoch: 3 [240384/387873]    Loss: 0.001546   Batch Acc: 94.53
[Train] Epoch: 3 [240512/387873]    Loss: 0.002095   Batch Acc: 85.94
[Train] Epoch: 3 [240640/387873]    Loss: 0.001570   Batch Acc: 92.19
[Train] Epoch: 3 [240768/387873]    Loss: 0.001680   Batch Acc: 90.62
[Train] Epoch: 3 [240896/387873]    Loss: 0.002099   Batch Acc: 89.06
[Train] Epoch: 3 [241024/387873]    Loss: 0.002094   Batch Acc: 90.62
[Train] Epoch: 3 [241152/387873]    Loss: 0.002509   Batch Acc: 84.38
[Train] Epoch: 3 [241280/387873]    Loss: 0.002101   Batch Acc: 89.06
[Train] Epoch: 3 [241408/387873]    Loss: 0.001673   Batch Acc: 89.84
[Train] Epoch: 3 [241536/387873]    Loss: 0.001657   Batch Acc: 92.97
[Train] Epoch: 3 [241664/387873]    Loss: 0.002113   Batch Acc: 85.94
[Train] Epoch: 3 [241792/387873]    Loss: 0.002118   Batch Acc: 89.84
[Train] Epoch: 3 [241920/387873]    Loss: 0.001821   Batch Acc: 91.41
[Train] Epoch: 3 [242048/387873]    Loss: 0.002215   Batch Acc: 88.28
[Train] Epoch: 3 [242176/387873]    Loss: 0.001916   Batch Acc: 92.19
[Train] Epoch: 3 [242304/387873]    Loss: 0.001711   Batch Acc: 92.19
[Train] Epoch: 3 [242432/387873]    Loss: 0.002544   Batch Acc: 85.94
[Train] Epoch: 3 [242560/387873]    Loss: 0.001674   Batch Acc: 89.84
[Train] Epoch: 3 [242688/387873]    Loss: 0.001622   Batch Acc: 92.97
[Train] Epoch: 3 [242816/387873]    Loss: 0.002369   Batch Acc: 89.84
[Train] Epoch: 3 [242944/387873]    Loss: 0.001903   Batch Acc: 91.41
[Train] Epoch: 3 [243072/387873]    Loss: 0.001980   Batch Acc: 88.28
[Train] Epoch: 3 [243200/387873]    Loss: 0.002580   Batch Acc: 87.50
[Train] Epoch: 3 [243328/387873]    Loss: 0.001922   Batch Acc: 92.97
[Train] Epoch: 3 [243456/387873]    Loss: 0.002207   Batch Acc: 88.28
[Train] Epoch: 3 [243584/387873]    Loss: 0.001844   Batch Acc: 89.06
[Train] Epoch: 3 [243712/387873]    Loss: 0.002368   Batch Acc: 89.06
[Train] Epoch: 3 [243840/387873]    Loss: 0.002410   Batch Acc: 85.16
[Train] Epoch: 3 [243968/387873]    Loss: 0.002276   Batch Acc: 85.94
[Train] Epoch: 3 [244096/387873]    Loss: 0.002252   Batch Acc: 85.94
[Train] Epoch: 3 [244224/387873]    Loss: 0.001560   Batch Acc: 93.75
[Train] Epoch: 3 [244352/387873]    Loss: 0.001856   Batch Acc: 91.41
[Train] Epoch: 3 [244480/387873]    Loss: 0.001946   Batch Acc: 89.84
[Train] Epoch: 3 [244608/387873]    Loss: 0.001783   Batch Acc: 91.41
[Train] Epoch: 3 [244736/387873]    Loss: 0.002084   Batch Acc: 89.84
[Train] Epoch: 3 [244864/387873]    Loss: 0.001960   Batch Acc: 90.62
[Train] Epoch: 3 [244992/387873]    Loss: 0.002093   Batch Acc: 89.06
[Train] Epoch: 3 [245120/387873]    Loss: 0.002463   Batch Acc: 85.16
[Train] Epoch: 3 [245248/387873]    Loss: 0.002244   Batch Acc: 87.50
[Train] Epoch: 3 [245376/387873]    Loss: 0.001540   Batch Acc: 91.41
[Train] Epoch: 3 [245504/387873]    Loss: 0.002206   Batch Acc: 84.38
[Train] Epoch: 3 [245632/387873]    Loss: 0.001743   Batch Acc: 89.06
[Train] Epoch: 3 [245760/387873]    Loss: 0.001665   Batch Acc: 92.19
[Train] Epoch: 3 [245888/387873]    Loss: 0.001719   Batch Acc: 90.62
[Train] Epoch: 3 [246016/387873]    Loss: 0.002181   Batch Acc: 88.28
[Train] Epoch: 3 [246144/387873]    Loss: 0.001988   Batch Acc: 86.72
[Train] Epoch: 3 [246272/387873]    Loss: 0.001905   Batch Acc: 89.84
[Train] Epoch: 3 [246400/387873]    Loss: 0.001774   Batch Acc: 90.62
[Train] Epoch: 3 [246528/387873]    Loss: 0.002498   Batch Acc: 85.94
[Train] Epoch: 3 [246656/387873]    Loss: 0.001406   Batch Acc: 92.97
[Train] Epoch: 3 [246784/387873]    Loss: 0.001651   Batch Acc: 93.75
[Train] Epoch: 3 [246912/387873]    Loss: 0.002234   Batch Acc: 89.06
[Train] Epoch: 3 [247040/387873]    Loss: 0.002578   Batch Acc: 85.16
[Train] Epoch: 3 [247168/387873]    Loss: 0.001588   Batch Acc: 92.19
[Train] Epoch: 3 [247296/387873]    Loss: 0.002016   Batch Acc: 92.19
[Train] Epoch: 3 [247424/387873]    Loss: 0.001797   Batch Acc: 89.84
[Train] Epoch: 3 [247552/387873]    Loss: 0.001492   Batch Acc: 92.19
[Train] Epoch: 3 [247680/387873]    Loss: 0.001882   Batch Acc: 90.62
[Train] Epoch: 3 [247808/387873]    Loss: 0.001754   Batch Acc: 91.41
[Train] Epoch: 3 [247936/387873]    Loss: 0.002107   Batch Acc: 89.84
[Train] Epoch: 3 [248064/387873]    Loss: 0.001252   Batch Acc: 96.09
[Train] Epoch: 3 [248192/387873]    Loss: 0.001508   Batch Acc: 91.41
[Train] Epoch: 3 [248320/387873]    Loss: 0.001805   Batch Acc: 89.84
[Train] Epoch: 3 [248448/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 3 [248576/387873]    Loss: 0.001835   Batch Acc: 92.19
[Train] Epoch: 3 [248704/387873]    Loss: 0.002526   Batch Acc: 88.28
[Train] Epoch: 3 [248832/387873]    Loss: 0.002677   Batch Acc: 81.25
[Train] Epoch: 3 [248960/387873]    Loss: 0.001674   Batch Acc: 93.75
[Train] Epoch: 3 [249088/387873]    Loss: 0.001937   Batch Acc: 88.28
[Train] Epoch: 3 [249216/387873]    Loss: 0.002135   Batch Acc: 88.28
[Train] Epoch: 3 [249344/387873]    Loss: 0.001781   Batch Acc: 93.75
[Train] Epoch: 3 [249472/387873]    Loss: 0.002152   Batch Acc: 89.84
[Train] Epoch: 3 [249600/387873]    Loss: 0.001949   Batch Acc: 91.41
[Train] Epoch: 3 [249728/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 3 [249856/387873]    Loss: 0.001784   Batch Acc: 92.97
[Train] Epoch: 3 [249984/387873]    Loss: 0.001431   Batch Acc: 92.97
[Train] Epoch: 3 [250112/387873]    Loss: 0.001566   Batch Acc: 92.19
[Train] Epoch: 3 [250240/387873]    Loss: 0.002018   Batch Acc: 91.41
[Train] Epoch: 3 [250368/387873]    Loss: 0.001529   Batch Acc: 94.53
[Train] Epoch: 3 [250496/387873]    Loss: 0.001758   Batch Acc: 92.19
[Train] Epoch: 3 [250624/387873]    Loss: 0.002584   Batch Acc: 85.94
[Train] Epoch: 3 [250752/387873]    Loss: 0.002413   Batch Acc: 89.06
[Train] Epoch: 3 [250880/387873]    Loss: 0.002060   Batch Acc: 91.41
[Train] Epoch: 3 [251008/387873]    Loss: 0.001947   Batch Acc: 90.62
[Train] Epoch: 3 [251136/387873]    Loss: 0.001858   Batch Acc: 92.19
[Train] Epoch: 3 [251264/387873]    Loss: 0.002022   Batch Acc: 86.72
[Train] Epoch: 3 [251392/387873]    Loss: 0.002108   Batch Acc: 89.06
[Train] Epoch: 3 [251520/387873]    Loss: 0.002039   Batch Acc: 91.41
[Train] Epoch: 3 [251648/387873]    Loss: 0.002196   Batch Acc: 86.72
[Train] Epoch: 3 [251776/387873]    Loss: 0.001567   Batch Acc: 92.19
[Train] Epoch: 3 [251904/387873]    Loss: 0.001701   Batch Acc: 89.84
[Train] Epoch: 3 [252032/387873]    Loss: 0.002182   Batch Acc: 89.06
[Train] Epoch: 3 [252160/387873]    Loss: 0.001503   Batch Acc: 92.97
[Train] Epoch: 3 [252288/387873]    Loss: 0.001827   Batch Acc: 90.62
[Train] Epoch: 3 [252416/387873]    Loss: 0.002473   Batch Acc: 87.50
[Train] Epoch: 3 [252544/387873]    Loss: 0.002625   Batch Acc: 83.59
[Train] Epoch: 3 [252672/387873]    Loss: 0.002021   Batch Acc: 87.50
[Train] Epoch: 3 [252800/387873]    Loss: 0.001583   Batch Acc: 91.41
[Train] Epoch: 3 [252928/387873]    Loss: 0.001276   Batch Acc: 94.53
[Train] Epoch: 3 [253056/387873]    Loss: 0.002006   Batch Acc: 92.97
[Train] Epoch: 3 [253184/387873]    Loss: 0.001668   Batch Acc: 90.62
[Train] Epoch: 3 [253312/387873]    Loss: 0.001998   Batch Acc: 88.28
[Train] Epoch: 3 [253440/387873]    Loss: 0.001584   Batch Acc: 90.62
[Train] Epoch: 3 [253568/387873]    Loss: 0.002023   Batch Acc: 91.41
[Train] Epoch: 3 [253696/387873]    Loss: 0.002158   Batch Acc: 86.72
[Train] Epoch: 3 [253824/387873]    Loss: 0.001470   Batch Acc: 93.75
[Train] Epoch: 3 [253952/387873]    Loss: 0.001986   Batch Acc: 89.84
[Train] Epoch: 3 [254080/387873]    Loss: 0.001693   Batch Acc: 89.84
[Train] Epoch: 3 [254208/387873]    Loss: 0.001709   Batch Acc: 90.62
[Train] Epoch: 3 [254336/387873]    Loss: 0.001199   Batch Acc: 96.09
[Train] Epoch: 3 [254464/387873]    Loss: 0.001462   Batch Acc: 92.97
[Train] Epoch: 3 [254592/387873]    Loss: 0.001876   Batch Acc: 89.06
[Train] Epoch: 3 [254720/387873]    Loss: 0.001831   Batch Acc: 89.84
[Train] Epoch: 3 [254848/387873]    Loss: 0.001873   Batch Acc: 90.62
[Train] Epoch: 3 [254976/387873]    Loss: 0.002229   Batch Acc: 90.62
[Train] Epoch: 3 [255104/387873]    Loss: 0.002020   Batch Acc: 92.19
[Train] Epoch: 3 [255232/387873]    Loss: 0.002100   Batch Acc: 88.28
[Train] Epoch: 3 [255360/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 3 [255488/387873]    Loss: 0.002145   Batch Acc: 88.28
[Train] Epoch: 3 [255616/387873]    Loss: 0.001964   Batch Acc: 90.62
[Train] Epoch: 3 [255744/387873]    Loss: 0.001960   Batch Acc: 90.62
[Train] Epoch: 3 [255872/387873]    Loss: 0.001790   Batch Acc: 89.06
[Train] Epoch: 3 [256000/387873]    Loss: 0.002318   Batch Acc: 91.41
[Train] Epoch: 3 [256128/387873]    Loss: 0.001808   Batch Acc: 87.50
[Train] Epoch: 3 [256256/387873]    Loss: 0.002315   Batch Acc: 85.94
[Train] Epoch: 3 [256384/387873]    Loss: 0.002214   Batch Acc: 86.72
[Train] Epoch: 3 [256512/387873]    Loss: 0.002133   Batch Acc: 87.50
[Train] Epoch: 3 [256640/387873]    Loss: 0.002496   Batch Acc: 85.94
[Train] Epoch: 3 [256768/387873]    Loss: 0.002194   Batch Acc: 89.84
[Train] Epoch: 3 [256896/387873]    Loss: 0.001563   Batch Acc: 94.53
[Train] Epoch: 3 [257024/387873]    Loss: 0.002383   Batch Acc: 86.72
[Train] Epoch: 3 [257152/387873]    Loss: 0.002541   Batch Acc: 85.16
[Train] Epoch: 3 [257280/387873]    Loss: 0.001478   Batch Acc: 92.19
[Train] Epoch: 3 [257408/387873]    Loss: 0.001824   Batch Acc: 89.06
[Train] Epoch: 3 [257536/387873]    Loss: 0.001869   Batch Acc: 89.06
[Train] Epoch: 3 [257664/387873]    Loss: 0.001852   Batch Acc: 92.19
[Train] Epoch: 3 [257792/387873]    Loss: 0.001770   Batch Acc: 90.62
[Train] Epoch: 3 [257920/387873]    Loss: 0.001294   Batch Acc: 96.09
[Train] Epoch: 3 [258048/387873]    Loss: 0.002240   Batch Acc: 88.28
[Train] Epoch: 3 [258176/387873]    Loss: 0.002098   Batch Acc: 87.50
[Train] Epoch: 3 [258304/387873]    Loss: 0.001784   Batch Acc: 92.19
[Train] Epoch: 3 [258432/387873]    Loss: 0.001923   Batch Acc: 92.19
[Train] Epoch: 3 [258560/387873]    Loss: 0.002027   Batch Acc: 91.41
[Train] Epoch: 3 [258688/387873]    Loss: 0.002161   Batch Acc: 88.28
[Train] Epoch: 3 [258816/387873]    Loss: 0.002011   Batch Acc: 90.62
[Train] Epoch: 3 [258944/387873]    Loss: 0.002044   Batch Acc: 85.16
[Train] Epoch: 3 [259072/387873]    Loss: 0.002026   Batch Acc: 89.06
[Train] Epoch: 3 [259200/387873]    Loss: 0.001984   Batch Acc: 90.62
[Train] Epoch: 3 [259328/387873]    Loss: 0.002050   Batch Acc: 89.84
[Train] Epoch: 3 [259456/387873]    Loss: 0.002020   Batch Acc: 88.28
[Train] Epoch: 3 [259584/387873]    Loss: 0.002443   Batch Acc: 86.72
[Train] Epoch: 3 [259712/387873]    Loss: 0.002236   Batch Acc: 84.38
[Train] Epoch: 3 [259840/387873]    Loss: 0.001369   Batch Acc: 94.53
[Train] Epoch: 3 [259968/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 3 [260096/387873]    Loss: 0.002675   Batch Acc: 84.38
[Train] Epoch: 3 [260224/387873]    Loss: 0.001771   Batch Acc: 89.84
[Train] Epoch: 3 [260352/387873]    Loss: 0.001977   Batch Acc: 91.41
[Train] Epoch: 3 [260480/387873]    Loss: 0.001561   Batch Acc: 94.53
[Train] Epoch: 3 [260608/387873]    Loss: 0.001887   Batch Acc: 90.62
[Train] Epoch: 3 [260736/387873]    Loss: 0.001537   Batch Acc: 93.75
[Train] Epoch: 3 [260864/387873]    Loss: 0.002109   Batch Acc: 89.84
[Train] Epoch: 3 [260992/387873]    Loss: 0.001512   Batch Acc: 92.19
[Train] Epoch: 3 [261120/387873]    Loss: 0.002013   Batch Acc: 89.06
[Train] Epoch: 3 [261248/387873]    Loss: 0.001462   Batch Acc: 93.75
[Train] Epoch: 3 [261376/387873]    Loss: 0.001381   Batch Acc: 93.75
[Train] Epoch: 3 [261504/387873]    Loss: 0.002072   Batch Acc: 87.50
[Train] Epoch: 3 [261632/387873]    Loss: 0.001802   Batch Acc: 92.19
[Train] Epoch: 3 [261760/387873]    Loss: 0.002508   Batch Acc: 85.16
[Train] Epoch: 3 [261888/387873]    Loss: 0.001614   Batch Acc: 91.41
[Train] Epoch: 3 [262016/387873]    Loss: 0.001671   Batch Acc: 91.41
[Train] Epoch: 3 [262144/387873]    Loss: 0.002183   Batch Acc: 85.94
[Train] Epoch: 3 [262272/387873]    Loss: 0.002227   Batch Acc: 89.84
[Train] Epoch: 3 [262400/387873]    Loss: 0.001845   Batch Acc: 87.50
[Train] Epoch: 3 [262528/387873]    Loss: 0.001631   Batch Acc: 89.84
[Train] Epoch: 3 [262656/387873]    Loss: 0.001857   Batch Acc: 91.41
[Train] Epoch: 3 [262784/387873]    Loss: 0.001836   Batch Acc: 92.97
[Train] Epoch: 3 [262912/387873]    Loss: 0.002227   Batch Acc: 87.50
[Train] Epoch: 3 [263040/387873]    Loss: 0.001871   Batch Acc: 90.62
[Train] Epoch: 3 [263168/387873]    Loss: 0.001689   Batch Acc: 94.53
[Train] Epoch: 3 [263296/387873]    Loss: 0.002070   Batch Acc: 89.06
[Train] Epoch: 3 [263424/387873]    Loss: 0.001748   Batch Acc: 91.41
[Train] Epoch: 3 [263552/387873]    Loss: 0.001466   Batch Acc: 91.41
[Train] Epoch: 3 [263680/387873]    Loss: 0.001785   Batch Acc: 89.84
[Train] Epoch: 3 [263808/387873]    Loss: 0.001951   Batch Acc: 91.41
[Train] Epoch: 3 [263936/387873]    Loss: 0.002634   Batch Acc: 82.03
[Train] Epoch: 3 [264064/387873]    Loss: 0.002102   Batch Acc: 88.28
[Train] Epoch: 3 [264192/387873]    Loss: 0.001830   Batch Acc: 91.41
[Train] Epoch: 3 [264320/387873]    Loss: 0.002282   Batch Acc: 91.41
[Train] Epoch: 3 [264448/387873]    Loss: 0.002287   Batch Acc: 88.28
[Train] Epoch: 3 [264576/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 3 [264704/387873]    Loss: 0.001963   Batch Acc: 91.41
[Train] Epoch: 3 [264832/387873]    Loss: 0.002122   Batch Acc: 90.62
[Train] Epoch: 3 [264960/387873]    Loss: 0.002203   Batch Acc: 86.72
[Train] Epoch: 3 [265088/387873]    Loss: 0.002105   Batch Acc: 89.84
[Train] Epoch: 3 [265216/387873]    Loss: 0.001891   Batch Acc: 89.06
[Train] Epoch: 3 [265344/387873]    Loss: 0.002013   Batch Acc: 90.62
[Train] Epoch: 3 [265472/387873]    Loss: 0.001866   Batch Acc: 91.41
[Train] Epoch: 3 [265600/387873]    Loss: 0.001788   Batch Acc: 89.84
[Train] Epoch: 3 [265728/387873]    Loss: 0.001577   Batch Acc: 92.19
[Train] Epoch: 3 [265856/387873]    Loss: 0.001786   Batch Acc: 92.19
[Train] Epoch: 3 [265984/387873]    Loss: 0.002215   Batch Acc: 90.62
[Train] Epoch: 3 [266112/387873]    Loss: 0.002075   Batch Acc: 87.50
[Train] Epoch: 3 [266240/387873]    Loss: 0.002117   Batch Acc: 91.41
[Train] Epoch: 3 [266368/387873]    Loss: 0.002324   Batch Acc: 85.16
[Train] Epoch: 3 [266496/387873]    Loss: 0.002114   Batch Acc: 86.72
[Train] Epoch: 3 [266624/387873]    Loss: 0.001940   Batch Acc: 89.06
[Train] Epoch: 3 [266752/387873]    Loss: 0.002635   Batch Acc: 85.16
[Train] Epoch: 3 [266880/387873]    Loss: 0.001958   Batch Acc: 89.84
[Train] Epoch: 3 [267008/387873]    Loss: 0.002383   Batch Acc: 85.16
[Train] Epoch: 3 [267136/387873]    Loss: 0.002151   Batch Acc: 89.06
[Train] Epoch: 3 [267264/387873]    Loss: 0.002222   Batch Acc: 85.16
[Train] Epoch: 3 [267392/387873]    Loss: 0.002292   Batch Acc: 89.84
[Train] Epoch: 3 [267520/387873]    Loss: 0.002674   Batch Acc: 84.38
[Train] Epoch: 3 [267648/387873]    Loss: 0.002058   Batch Acc: 89.06
[Train] Epoch: 3 [267776/387873]    Loss: 0.002138   Batch Acc: 92.19
[Train] Epoch: 3 [267904/387873]    Loss: 0.002338   Batch Acc: 85.16
[Train] Epoch: 3 [268032/387873]    Loss: 0.002642   Batch Acc: 85.94
[Train] Epoch: 3 [268160/387873]    Loss: 0.002357   Batch Acc: 89.84
[Train] Epoch: 3 [268288/387873]    Loss: 0.001731   Batch Acc: 90.62
[Train] Epoch: 3 [268416/387873]    Loss: 0.002009   Batch Acc: 90.62
[Train] Epoch: 3 [268544/387873]    Loss: 0.002247   Batch Acc: 86.72
[Train] Epoch: 3 [268672/387873]    Loss: 0.001995   Batch Acc: 90.62
[Train] Epoch: 3 [268800/387873]    Loss: 0.003033   Batch Acc: 80.47
[Train] Epoch: 3 [268928/387873]    Loss: 0.001634   Batch Acc: 92.19
[Train] Epoch: 3 [269056/387873]    Loss: 0.001750   Batch Acc: 92.19
[Train] Epoch: 3 [269184/387873]    Loss: 0.001915   Batch Acc: 91.41
[Train] Epoch: 3 [269312/387873]    Loss: 0.002143   Batch Acc: 87.50
[Train] Epoch: 3 [269440/387873]    Loss: 0.001824   Batch Acc: 89.84
[Train] Epoch: 3 [269568/387873]    Loss: 0.001764   Batch Acc: 90.62
[Train] Epoch: 3 [269696/387873]    Loss: 0.002703   Batch Acc: 83.59
[Train] Epoch: 3 [269824/387873]    Loss: 0.001949   Batch Acc: 89.06
[Train] Epoch: 3 [269952/387873]    Loss: 0.002047   Batch Acc: 87.50
[Train] Epoch: 3 [270080/387873]    Loss: 0.002460   Batch Acc: 87.50
[Train] Epoch: 3 [270208/387873]    Loss: 0.001596   Batch Acc: 89.84
[Train] Epoch: 3 [270336/387873]    Loss: 0.002230   Batch Acc: 85.94
[Train] Epoch: 3 [270464/387873]    Loss: 0.001998   Batch Acc: 91.41
[Train] Epoch: 3 [270592/387873]    Loss: 0.001919   Batch Acc: 91.41
[Train] Epoch: 3 [270720/387873]    Loss: 0.001334   Batch Acc: 93.75
[Train] Epoch: 3 [270848/387873]    Loss: 0.001896   Batch Acc: 89.84
[Train] Epoch: 3 [270976/387873]    Loss: 0.001619   Batch Acc: 94.53
[Train] Epoch: 3 [271104/387873]    Loss: 0.001806   Batch Acc: 90.62
[Train] Epoch: 3 [271232/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 3 [271360/387873]    Loss: 0.001798   Batch Acc: 89.06
[Train] Epoch: 3 [271488/387873]    Loss: 0.001729   Batch Acc: 92.19
[Train] Epoch: 3 [271616/387873]    Loss: 0.002082   Batch Acc: 86.72
[Train] Epoch: 3 [271744/387873]    Loss: 0.001932   Batch Acc: 92.19
[Train] Epoch: 3 [271872/387873]    Loss: 0.001849   Batch Acc: 89.84
[Train] Epoch: 3 [272000/387873]    Loss: 0.002404   Batch Acc: 86.72
[Train] Epoch: 3 [272128/387873]    Loss: 0.002032   Batch Acc: 90.62
[Train] Epoch: 3 [272256/387873]    Loss: 0.001818   Batch Acc: 89.06
[Train] Epoch: 3 [272384/387873]    Loss: 0.001398   Batch Acc: 93.75
[Train] Epoch: 3 [272512/387873]    Loss: 0.002480   Batch Acc: 85.94
[Train] Epoch: 3 [272640/387873]    Loss: 0.002224   Batch Acc: 88.28
[Train] Epoch: 3 [272768/387873]    Loss: 0.001626   Batch Acc: 92.19
[Train] Epoch: 3 [272896/387873]    Loss: 0.001438   Batch Acc: 94.53
[Train] Epoch: 3 [273024/387873]    Loss: 0.001782   Batch Acc: 92.19
[Train] Epoch: 3 [273152/387873]    Loss: 0.002085   Batch Acc: 84.38
[Train] Epoch: 3 [273280/387873]    Loss: 0.001914   Batch Acc: 88.28
[Train] Epoch: 3 [273408/387873]    Loss: 0.001963   Batch Acc: 91.41
[Train] Epoch: 3 [273536/387873]    Loss: 0.002006   Batch Acc: 89.84
[Train] Epoch: 3 [273664/387873]    Loss: 0.002046   Batch Acc: 89.84
[Train] Epoch: 3 [273792/387873]    Loss: 0.002244   Batch Acc: 85.94
[Train] Epoch: 3 [273920/387873]    Loss: 0.001865   Batch Acc: 90.62
[Train] Epoch: 3 [274048/387873]    Loss: 0.002141   Batch Acc: 88.28
[Train] Epoch: 3 [274176/387873]    Loss: 0.001530   Batch Acc: 93.75
[Train] Epoch: 3 [274304/387873]    Loss: 0.002066   Batch Acc: 89.06
[Train] Epoch: 3 [274432/387873]    Loss: 0.001633   Batch Acc: 92.97
[Train] Epoch: 3 [274560/387873]    Loss: 0.001379   Batch Acc: 92.97
[Train] Epoch: 3 [274688/387873]    Loss: 0.002360   Batch Acc: 85.94
[Train] Epoch: 3 [274816/387873]    Loss: 0.001853   Batch Acc: 90.62
[Train] Epoch: 3 [274944/387873]    Loss: 0.001801   Batch Acc: 89.84
[Train] Epoch: 3 [275072/387873]    Loss: 0.001529   Batch Acc: 92.19
[Train] Epoch: 3 [275200/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 3 [275328/387873]    Loss: 0.001794   Batch Acc: 90.62
[Train] Epoch: 3 [275456/387873]    Loss: 0.002136   Batch Acc: 88.28
[Train] Epoch: 3 [275584/387873]    Loss: 0.002370   Batch Acc: 86.72
[Train] Epoch: 3 [275712/387873]    Loss: 0.001968   Batch Acc: 92.19
[Train] Epoch: 3 [275840/387873]    Loss: 0.001704   Batch Acc: 92.19
[Train] Epoch: 3 [275968/387873]    Loss: 0.001532   Batch Acc: 94.53
[Train] Epoch: 3 [276096/387873]    Loss: 0.002230   Batch Acc: 86.72
[Train] Epoch: 3 [276224/387873]    Loss: 0.002049   Batch Acc: 88.28
[Train] Epoch: 3 [276352/387873]    Loss: 0.002516   Batch Acc: 87.50
[Train] Epoch: 3 [276480/387873]    Loss: 0.002014   Batch Acc: 87.50
[Train] Epoch: 3 [276608/387873]    Loss: 0.001385   Batch Acc: 96.09
[Train] Epoch: 3 [276736/387873]    Loss: 0.001547   Batch Acc: 91.41
[Train] Epoch: 3 [276864/387873]    Loss: 0.002324   Batch Acc: 85.94
[Train] Epoch: 3 [276992/387873]    Loss: 0.002753   Batch Acc: 83.59
[Train] Epoch: 3 [277120/387873]    Loss: 0.002187   Batch Acc: 89.84
[Train] Epoch: 3 [277248/387873]    Loss: 0.001645   Batch Acc: 92.97
[Train] Epoch: 3 [277376/387873]    Loss: 0.002165   Batch Acc: 83.59
[Train] Epoch: 3 [277504/387873]    Loss: 0.003120   Batch Acc: 82.81
[Train] Epoch: 3 [277632/387873]    Loss: 0.001815   Batch Acc: 88.28
[Train] Epoch: 3 [277760/387873]    Loss: 0.002492   Batch Acc: 85.16
[Train] Epoch: 3 [277888/387873]    Loss: 0.001935   Batch Acc: 90.62
[Train] Epoch: 3 [278016/387873]    Loss: 0.001587   Batch Acc: 90.62
[Train] Epoch: 3 [278144/387873]    Loss: 0.002158   Batch Acc: 87.50
[Train] Epoch: 3 [278272/387873]    Loss: 0.001547   Batch Acc: 92.97
[Train] Epoch: 3 [278400/387873]    Loss: 0.002155   Batch Acc: 89.84
[Train] Epoch: 3 [278528/387873]    Loss: 0.003050   Batch Acc: 85.16
[Train] Epoch: 3 [278656/387873]    Loss: 0.001826   Batch Acc: 89.84
[Train] Epoch: 3 [278784/387873]    Loss: 0.002304   Batch Acc: 86.72
[Train] Epoch: 3 [278912/387873]    Loss: 0.001608   Batch Acc: 94.53
[Train] Epoch: 3 [279040/387873]    Loss: 0.001857   Batch Acc: 92.19
[Train] Epoch: 3 [279168/387873]    Loss: 0.001926   Batch Acc: 89.06
[Train] Epoch: 3 [279296/387873]    Loss: 0.001654   Batch Acc: 91.41
[Train] Epoch: 3 [279424/387873]    Loss: 0.002217   Batch Acc: 85.16
[Train] Epoch: 3 [279552/387873]    Loss: 0.001743   Batch Acc: 91.41
[Train] Epoch: 3 [279680/387873]    Loss: 0.002844   Batch Acc: 85.16
[Train] Epoch: 3 [279808/387873]    Loss: 0.001753   Batch Acc: 90.62
[Train] Epoch: 3 [279936/387873]    Loss: 0.001702   Batch Acc: 91.41
[Train] Epoch: 3 [280064/387873]    Loss: 0.002481   Batch Acc: 87.50
[Train] Epoch: 3 [280192/387873]    Loss: 0.002285   Batch Acc: 89.84
[Train] Epoch: 3 [280320/387873]    Loss: 0.002507   Batch Acc: 87.50
[Train] Epoch: 3 [280448/387873]    Loss: 0.001800   Batch Acc: 89.84
[Train] Epoch: 3 [280576/387873]    Loss: 0.001901   Batch Acc: 90.62
[Train] Epoch: 3 [280704/387873]    Loss: 0.002334   Batch Acc: 86.72
[Train] Epoch: 3 [280832/387873]    Loss: 0.002536   Batch Acc: 87.50
[Train] Epoch: 3 [280960/387873]    Loss: 0.002226   Batch Acc: 89.84
[Train] Epoch: 3 [281088/387873]    Loss: 0.002287   Batch Acc: 87.50
[Train] Epoch: 3 [281216/387873]    Loss: 0.001986   Batch Acc: 89.84
[Train] Epoch: 3 [281344/387873]    Loss: 0.002031   Batch Acc: 87.50
[Train] Epoch: 3 [281472/387873]    Loss: 0.002047   Batch Acc: 88.28
[Train] Epoch: 3 [281600/387873]    Loss: 0.002048   Batch Acc: 91.41
[Train] Epoch: 3 [281728/387873]    Loss: 0.001961   Batch Acc: 87.50
[Train] Epoch: 3 [281856/387873]    Loss: 0.002200   Batch Acc: 89.06
[Train] Epoch: 3 [281984/387873]    Loss: 0.001676   Batch Acc: 92.19
[Train] Epoch: 3 [282112/387873]    Loss: 0.001729   Batch Acc: 91.41
[Train] Epoch: 3 [282240/387873]    Loss: 0.001962   Batch Acc: 90.62
[Train] Epoch: 3 [282368/387873]    Loss: 0.001931   Batch Acc: 90.62
[Train] Epoch: 3 [282496/387873]    Loss: 0.001694   Batch Acc: 93.75
[Train] Epoch: 3 [282624/387873]    Loss: 0.001810   Batch Acc: 89.84
[Train] Epoch: 3 [282752/387873]    Loss: 0.001807   Batch Acc: 90.62
[Train] Epoch: 3 [282880/387873]    Loss: 0.001767   Batch Acc: 91.41
[Train] Epoch: 3 [283008/387873]    Loss: 0.002509   Batch Acc: 85.94
[Train] Epoch: 3 [283136/387873]    Loss: 0.001343   Batch Acc: 94.53
[Train] Epoch: 3 [283264/387873]    Loss: 0.001788   Batch Acc: 90.62
[Train] Epoch: 3 [283392/387873]    Loss: 0.002490   Batch Acc: 85.16
[Train] Epoch: 3 [283520/387873]    Loss: 0.002197   Batch Acc: 88.28
[Train] Epoch: 3 [283648/387873]    Loss: 0.002068   Batch Acc: 87.50
[Train] Epoch: 3 [283776/387873]    Loss: 0.002186   Batch Acc: 85.16
[Train] Epoch: 3 [283904/387873]    Loss: 0.001691   Batch Acc: 92.19
[Train] Epoch: 3 [284032/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 3 [284160/387873]    Loss: 0.002141   Batch Acc: 85.16
[Train] Epoch: 3 [284288/387873]    Loss: 0.002186   Batch Acc: 89.84
[Train] Epoch: 3 [284416/387873]    Loss: 0.001716   Batch Acc: 93.75
[Train] Epoch: 3 [284544/387873]    Loss: 0.002206   Batch Acc: 88.28
[Train] Epoch: 3 [284672/387873]    Loss: 0.001756   Batch Acc: 92.19
[Train] Epoch: 3 [284800/387873]    Loss: 0.001703   Batch Acc: 92.19
[Train] Epoch: 3 [284928/387873]    Loss: 0.001864   Batch Acc: 90.62
[Train] Epoch: 3 [285056/387873]    Loss: 0.001720   Batch Acc: 91.41
[Train] Epoch: 3 [285184/387873]    Loss: 0.001737   Batch Acc: 90.62
[Train] Epoch: 3 [285312/387873]    Loss: 0.001672   Batch Acc: 89.06
[Train] Epoch: 3 [285440/387873]    Loss: 0.002724   Batch Acc: 84.38
[Train] Epoch: 3 [285568/387873]    Loss: 0.001655   Batch Acc: 92.19
[Train] Epoch: 3 [285696/387873]    Loss: 0.002283   Batch Acc: 83.59
[Train] Epoch: 3 [285824/387873]    Loss: 0.001761   Batch Acc: 92.97
[Train] Epoch: 3 [285952/387873]    Loss: 0.001868   Batch Acc: 92.97
[Train] Epoch: 3 [286080/387873]    Loss: 0.002222   Batch Acc: 85.94
[Train] Epoch: 3 [286208/387873]    Loss: 0.001756   Batch Acc: 89.84
[Train] Epoch: 3 [286336/387873]    Loss: 0.002235   Batch Acc: 87.50
[Train] Epoch: 3 [286464/387873]    Loss: 0.001985   Batch Acc: 90.62
[Train] Epoch: 3 [286592/387873]    Loss: 0.001931   Batch Acc: 90.62
[Train] Epoch: 3 [286720/387873]    Loss: 0.002122   Batch Acc: 89.06
[Train] Epoch: 3 [286848/387873]    Loss: 0.001447   Batch Acc: 93.75
[Train] Epoch: 3 [286976/387873]    Loss: 0.002440   Batch Acc: 89.06
[Train] Epoch: 3 [287104/387873]    Loss: 0.001565   Batch Acc: 91.41
[Train] Epoch: 3 [287232/387873]    Loss: 0.001843   Batch Acc: 89.84
[Train] Epoch: 3 [287360/387873]    Loss: 0.002301   Batch Acc: 88.28
[Train] Epoch: 3 [287488/387873]    Loss: 0.001481   Batch Acc: 92.97
[Train] Epoch: 3 [287616/387873]    Loss: 0.002230   Batch Acc: 86.72
[Train] Epoch: 3 [287744/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 3 [287872/387873]    Loss: 0.002050   Batch Acc: 92.19
[Train] Epoch: 3 [288000/387873]    Loss: 0.001549   Batch Acc: 91.41
[Train] Epoch: 3 [288128/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 3 [288256/387873]    Loss: 0.002464   Batch Acc: 90.62
[Train] Epoch: 3 [288384/387873]    Loss: 0.002808   Batch Acc: 84.38
[Train] Epoch: 3 [288512/387873]    Loss: 0.001855   Batch Acc: 89.84
[Train] Epoch: 3 [288640/387873]    Loss: 0.001702   Batch Acc: 89.84
[Train] Epoch: 3 [288768/387873]    Loss: 0.002598   Batch Acc: 84.38
[Train] Epoch: 3 [288896/387873]    Loss: 0.001565   Batch Acc: 92.97
[Train] Epoch: 3 [289024/387873]    Loss: 0.002389   Batch Acc: 83.59
[Train] Epoch: 3 [289152/387873]    Loss: 0.001444   Batch Acc: 93.75
[Train] Epoch: 3 [289280/387873]    Loss: 0.002545   Batch Acc: 85.94
[Train] Epoch: 3 [289408/387873]    Loss: 0.002109   Batch Acc: 90.62
[Train] Epoch: 3 [289536/387873]    Loss: 0.002170   Batch Acc: 89.06
[Train] Epoch: 3 [289664/387873]    Loss: 0.002069   Batch Acc: 86.72
[Train] Epoch: 3 [289792/387873]    Loss: 0.002190   Batch Acc: 88.28
[Train] Epoch: 3 [289920/387873]    Loss: 0.001562   Batch Acc: 91.41
[Train] Epoch: 3 [290048/387873]    Loss: 0.002365   Batch Acc: 85.94
[Train] Epoch: 3 [290176/387873]    Loss: 0.001619   Batch Acc: 91.41
[Train] Epoch: 3 [290304/387873]    Loss: 0.001361   Batch Acc: 92.97
[Train] Epoch: 3 [290432/387873]    Loss: 0.002052   Batch Acc: 88.28
[Train] Epoch: 3 [290560/387873]    Loss: 0.002252   Batch Acc: 87.50
[Train] Epoch: 3 [290688/387873]    Loss: 0.001913   Batch Acc: 89.06
[Train] Epoch: 3 [290816/387873]    Loss: 0.002577   Batch Acc: 82.81
[Train] Epoch: 3 [290944/387873]    Loss: 0.002014   Batch Acc: 91.41
[Train] Epoch: 3 [291072/387873]    Loss: 0.001944   Batch Acc: 89.84
[Train] Epoch: 3 [291200/387873]    Loss: 0.002210   Batch Acc: 88.28
[Train] Epoch: 3 [291328/387873]    Loss: 0.001647   Batch Acc: 92.19
[Train] Epoch: 3 [291456/387873]    Loss: 0.002186   Batch Acc: 91.41
[Train] Epoch: 3 [291584/387873]    Loss: 0.001691   Batch Acc: 92.97
[Train] Epoch: 3 [291712/387873]    Loss: 0.001917   Batch Acc: 91.41
[Train] Epoch: 3 [291840/387873]    Loss: 0.001730   Batch Acc: 91.41
[Train] Epoch: 3 [291968/387873]    Loss: 0.001470   Batch Acc: 92.97
[Train] Epoch: 3 [292096/387873]    Loss: 0.001620   Batch Acc: 92.19
[Train] Epoch: 3 [292224/387873]    Loss: 0.002597   Batch Acc: 85.16
[Train] Epoch: 3 [292352/387873]    Loss: 0.002043   Batch Acc: 89.06
[Train] Epoch: 3 [292480/387873]    Loss: 0.002177   Batch Acc: 89.84
[Train] Epoch: 3 [292608/387873]    Loss: 0.001986   Batch Acc: 89.06
[Train] Epoch: 3 [292736/387873]    Loss: 0.001701   Batch Acc: 92.19
[Train] Epoch: 3 [292864/387873]    Loss: 0.001878   Batch Acc: 86.72
[Train] Epoch: 3 [292992/387873]    Loss: 0.002340   Batch Acc: 85.94
[Train] Epoch: 3 [293120/387873]    Loss: 0.002016   Batch Acc: 88.28
[Train] Epoch: 3 [293248/387873]    Loss: 0.002007   Batch Acc: 89.84
[Train] Epoch: 3 [293376/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 3 [293504/387873]    Loss: 0.002262   Batch Acc: 87.50
[Train] Epoch: 3 [293632/387873]    Loss: 0.001835   Batch Acc: 89.06
[Train] Epoch: 3 [293760/387873]    Loss: 0.002123   Batch Acc: 88.28
[Train] Epoch: 3 [293888/387873]    Loss: 0.001725   Batch Acc: 89.06
[Train] Epoch: 3 [294016/387873]    Loss: 0.002256   Batch Acc: 86.72
[Train] Epoch: 3 [294144/387873]    Loss: 0.002673   Batch Acc: 88.28
[Train] Epoch: 3 [294272/387873]    Loss: 0.002287   Batch Acc: 83.59
[Train] Epoch: 3 [294400/387873]    Loss: 0.001873   Batch Acc: 88.28
[Train] Epoch: 3 [294528/387873]    Loss: 0.001453   Batch Acc: 91.41
[Train] Epoch: 3 [294656/387873]    Loss: 0.002632   Batch Acc: 82.81
[Train] Epoch: 3 [294784/387873]    Loss: 0.002098   Batch Acc: 89.06
[Train] Epoch: 3 [294912/387873]    Loss: 0.002028   Batch Acc: 91.41
[Train] Epoch: 3 [295040/387873]    Loss: 0.002070   Batch Acc: 88.28
[Train] Epoch: 3 [295168/387873]    Loss: 0.002186   Batch Acc: 90.62
[Train] Epoch: 3 [295296/387873]    Loss: 0.001684   Batch Acc: 89.84
[Train] Epoch: 3 [295424/387873]    Loss: 0.001910   Batch Acc: 88.28
[Train] Epoch: 3 [295552/387873]    Loss: 0.002671   Batch Acc: 82.81
[Train] Epoch: 3 [295680/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 3 [295808/387873]    Loss: 0.001731   Batch Acc: 92.19
[Train] Epoch: 3 [295936/387873]    Loss: 0.001863   Batch Acc: 90.62
[Train] Epoch: 3 [296064/387873]    Loss: 0.002047   Batch Acc: 91.41
[Train] Epoch: 3 [296192/387873]    Loss: 0.001417   Batch Acc: 96.09
[Train] Epoch: 3 [296320/387873]    Loss: 0.002172   Batch Acc: 87.50
[Train] Epoch: 3 [296448/387873]    Loss: 0.002083   Batch Acc: 89.06
[Train] Epoch: 3 [296576/387873]    Loss: 0.001690   Batch Acc: 91.41
[Train] Epoch: 3 [296704/387873]    Loss: 0.001666   Batch Acc: 90.62
[Train] Epoch: 3 [296832/387873]    Loss: 0.002002   Batch Acc: 89.84
[Train] Epoch: 3 [296960/387873]    Loss: 0.001674   Batch Acc: 89.84
[Train] Epoch: 3 [297088/387873]    Loss: 0.002432   Batch Acc: 89.06
[Train] Epoch: 3 [297216/387873]    Loss: 0.001878   Batch Acc: 90.62
[Train] Epoch: 3 [297344/387873]    Loss: 0.002287   Batch Acc: 88.28
[Train] Epoch: 3 [297472/387873]    Loss: 0.001653   Batch Acc: 91.41
[Train] Epoch: 3 [297600/387873]    Loss: 0.001763   Batch Acc: 92.97
[Train] Epoch: 3 [297728/387873]    Loss: 0.001813   Batch Acc: 92.97
[Train] Epoch: 3 [297856/387873]    Loss: 0.001904   Batch Acc: 92.97
[Train] Epoch: 3 [297984/387873]    Loss: 0.002312   Batch Acc: 88.28
[Train] Epoch: 3 [298112/387873]    Loss: 0.001401   Batch Acc: 93.75
[Train] Epoch: 3 [298240/387873]    Loss: 0.002309   Batch Acc: 86.72
[Train] Epoch: 3 [298368/387873]    Loss: 0.002172   Batch Acc: 87.50
[Train] Epoch: 3 [298496/387873]    Loss: 0.002523   Batch Acc: 84.38
[Train] Epoch: 3 [298624/387873]    Loss: 0.002311   Batch Acc: 87.50
[Train] Epoch: 3 [298752/387873]    Loss: 0.001905   Batch Acc: 88.28
[Train] Epoch: 3 [298880/387873]    Loss: 0.001597   Batch Acc: 92.19
[Train] Epoch: 3 [299008/387873]    Loss: 0.001580   Batch Acc: 89.06
[Train] Epoch: 3 [299136/387873]    Loss: 0.002149   Batch Acc: 88.28
[Train] Epoch: 3 [299264/387873]    Loss: 0.001807   Batch Acc: 92.19
[Train] Epoch: 3 [299392/387873]    Loss: 0.002290   Batch Acc: 89.06
[Train] Epoch: 3 [299520/387873]    Loss: 0.002225   Batch Acc: 87.50
[Train] Epoch: 3 [299648/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 3 [299776/387873]    Loss: 0.002228   Batch Acc: 88.28
[Train] Epoch: 3 [299904/387873]    Loss: 0.001351   Batch Acc: 94.53
[Train] Epoch: 3 [300032/387873]    Loss: 0.001388   Batch Acc: 92.97
[Train] Epoch: 3 [300160/387873]    Loss: 0.002179   Batch Acc: 88.28
[Train] Epoch: 3 [300288/387873]    Loss: 0.002341   Batch Acc: 84.38
[Train] Epoch: 3 [300416/387873]    Loss: 0.001850   Batch Acc: 90.62
[Train] Epoch: 3 [300544/387873]    Loss: 0.002552   Batch Acc: 85.94
[Train] Epoch: 3 [300672/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 3 [300800/387873]    Loss: 0.001754   Batch Acc: 92.19
[Train] Epoch: 3 [300928/387873]    Loss: 0.001667   Batch Acc: 90.62
[Train] Epoch: 3 [301056/387873]    Loss: 0.001797   Batch Acc: 89.06
[Train] Epoch: 3 [301184/387873]    Loss: 0.001789   Batch Acc: 91.41
[Train] Epoch: 3 [301312/387873]    Loss: 0.002067   Batch Acc: 90.62
[Train] Epoch: 3 [301440/387873]    Loss: 0.001972   Batch Acc: 89.84
[Train] Epoch: 3 [301568/387873]    Loss: 0.002293   Batch Acc: 86.72
[Train] Epoch: 3 [301696/387873]    Loss: 0.001811   Batch Acc: 91.41
[Train] Epoch: 3 [301824/387873]    Loss: 0.001876   Batch Acc: 88.28
[Train] Epoch: 3 [301952/387873]    Loss: 0.002152   Batch Acc: 88.28
[Train] Epoch: 3 [302080/387873]    Loss: 0.001835   Batch Acc: 89.84
[Train] Epoch: 3 [302208/387873]    Loss: 0.003750   Batch Acc: 81.25
[Train] Epoch: 3 [302336/387873]    Loss: 0.001958   Batch Acc: 86.72
[Train] Epoch: 3 [302464/387873]    Loss: 0.001966   Batch Acc: 88.28
[Train] Epoch: 3 [302592/387873]    Loss: 0.002020   Batch Acc: 89.06
[Train] Epoch: 3 [302720/387873]    Loss: 0.002526   Batch Acc: 85.16
[Train] Epoch: 3 [302848/387873]    Loss: 0.001692   Batch Acc: 89.06
[Train] Epoch: 3 [302976/387873]    Loss: 0.001657   Batch Acc: 91.41
[Train] Epoch: 3 [303104/387873]    Loss: 0.002059   Batch Acc: 88.28
[Train] Epoch: 3 [303232/387873]    Loss: 0.001985   Batch Acc: 92.19
[Train] Epoch: 3 [303360/387873]    Loss: 0.002504   Batch Acc: 85.94
[Train] Epoch: 3 [303488/387873]    Loss: 0.001612   Batch Acc: 89.84
[Train] Epoch: 3 [303616/387873]    Loss: 0.002153   Batch Acc: 86.72
[Train] Epoch: 3 [303744/387873]    Loss: 0.001824   Batch Acc: 92.19
[Train] Epoch: 3 [303872/387873]    Loss: 0.001931   Batch Acc: 91.41
[Train] Epoch: 3 [304000/387873]    Loss: 0.002382   Batch Acc: 85.16
[Train] Epoch: 3 [304128/387873]    Loss: 0.002098   Batch Acc: 91.41
[Train] Epoch: 3 [304256/387873]    Loss: 0.002732   Batch Acc: 82.81
[Train] Epoch: 3 [304384/387873]    Loss: 0.001842   Batch Acc: 89.84
[Train] Epoch: 3 [304512/387873]    Loss: 0.001910   Batch Acc: 89.06
[Train] Epoch: 3 [304640/387873]    Loss: 0.002247   Batch Acc: 86.72
[Train] Epoch: 3 [304768/387873]    Loss: 0.001788   Batch Acc: 92.97
[Train] Epoch: 3 [304896/387873]    Loss: 0.001622   Batch Acc: 92.97
[Train] Epoch: 3 [305024/387873]    Loss: 0.001759   Batch Acc: 91.41
[Train] Epoch: 3 [305152/387873]    Loss: 0.002330   Batch Acc: 89.06
[Train] Epoch: 3 [305280/387873]    Loss: 0.001920   Batch Acc: 89.84
[Train] Epoch: 3 [305408/387873]    Loss: 0.002045   Batch Acc: 89.06
[Train] Epoch: 3 [305536/387873]    Loss: 0.001970   Batch Acc: 91.41
[Train] Epoch: 3 [305664/387873]    Loss: 0.002143   Batch Acc: 89.06
[Train] Epoch: 3 [305792/387873]    Loss: 0.002064   Batch Acc: 90.62
[Train] Epoch: 3 [305920/387873]    Loss: 0.001726   Batch Acc: 89.06
[Train] Epoch: 3 [306048/387873]    Loss: 0.001426   Batch Acc: 93.75
[Train] Epoch: 3 [306176/387873]    Loss: 0.002750   Batch Acc: 82.03
[Train] Epoch: 3 [306304/387873]    Loss: 0.002194   Batch Acc: 88.28
[Train] Epoch: 3 [306432/387873]    Loss: 0.002073   Batch Acc: 89.84
[Train] Epoch: 3 [306560/387873]    Loss: 0.001602   Batch Acc: 92.97
[Train] Epoch: 3 [306688/387873]    Loss: 0.001925   Batch Acc: 89.84
[Train] Epoch: 3 [306816/387873]    Loss: 0.002142   Batch Acc: 87.50
[Train] Epoch: 3 [306944/387873]    Loss: 0.001698   Batch Acc: 90.62
[Train] Epoch: 3 [307072/387873]    Loss: 0.002122   Batch Acc: 88.28
[Train] Epoch: 3 [307200/387873]    Loss: 0.001624   Batch Acc: 92.19
[Train] Epoch: 3 [307328/387873]    Loss: 0.001836   Batch Acc: 89.06
[Train] Epoch: 3 [307456/387873]    Loss: 0.001767   Batch Acc: 91.41
[Train] Epoch: 3 [307584/387873]    Loss: 0.002216   Batch Acc: 89.84
[Train] Epoch: 3 [307712/387873]    Loss: 0.002694   Batch Acc: 82.81
[Train] Epoch: 3 [307840/387873]    Loss: 0.002220   Batch Acc: 88.28
[Train] Epoch: 3 [307968/387873]    Loss: 0.001378   Batch Acc: 96.09
[Train] Epoch: 3 [308096/387873]    Loss: 0.001506   Batch Acc: 91.41
[Train] Epoch: 3 [308224/387873]    Loss: 0.001543   Batch Acc: 93.75
[Train] Epoch: 3 [308352/387873]    Loss: 0.002029   Batch Acc: 86.72
[Train] Epoch: 3 [308480/387873]    Loss: 0.002111   Batch Acc: 91.41
[Train] Epoch: 3 [308608/387873]    Loss: 0.001747   Batch Acc: 92.19
[Train] Epoch: 3 [308736/387873]    Loss: 0.002252   Batch Acc: 89.84
[Train] Epoch: 3 [308864/387873]    Loss: 0.002102   Batch Acc: 87.50
[Train] Epoch: 3 [308992/387873]    Loss: 0.001789   Batch Acc: 89.84
[Train] Epoch: 3 [309120/387873]    Loss: 0.002047   Batch Acc: 89.06
[Train] Epoch: 3 [309248/387873]    Loss: 0.001640   Batch Acc: 92.97
[Train] Epoch: 3 [309376/387873]    Loss: 0.001673   Batch Acc: 90.62
[Train] Epoch: 3 [309504/387873]    Loss: 0.001648   Batch Acc: 93.75
[Train] Epoch: 3 [309632/387873]    Loss: 0.002416   Batch Acc: 86.72
[Train] Epoch: 3 [309760/387873]    Loss: 0.001614   Batch Acc: 92.97
[Train] Epoch: 3 [309888/387873]    Loss: 0.002274   Batch Acc: 89.06
[Train] Epoch: 3 [310016/387873]    Loss: 0.001225   Batch Acc: 95.31
[Train] Epoch: 3 [310144/387873]    Loss: 0.001810   Batch Acc: 89.84
[Train] Epoch: 3 [310272/387873]    Loss: 0.002027   Batch Acc: 89.06
[Train] Epoch: 3 [310400/387873]    Loss: 0.002022   Batch Acc: 89.06
[Train] Epoch: 3 [310528/387873]    Loss: 0.001987   Batch Acc: 87.50
[Train] Epoch: 3 [310656/387873]    Loss: 0.001808   Batch Acc: 89.06
[Train] Epoch: 3 [310784/387873]    Loss: 0.002363   Batch Acc: 84.38
[Train] Epoch: 3 [310912/387873]    Loss: 0.001385   Batch Acc: 94.53
[Train] Epoch: 3 [311040/387873]    Loss: 0.001705   Batch Acc: 91.41
[Train] Epoch: 3 [311168/387873]    Loss: 0.001904   Batch Acc: 87.50
[Train] Epoch: 3 [311296/387873]    Loss: 0.001930   Batch Acc: 88.28
[Train] Epoch: 3 [311424/387873]    Loss: 0.002147   Batch Acc: 87.50
[Train] Epoch: 3 [311552/387873]    Loss: 0.001547   Batch Acc: 92.19
[Train] Epoch: 3 [311680/387873]    Loss: 0.001905   Batch Acc: 89.84
[Train] Epoch: 3 [311808/387873]    Loss: 0.002198   Batch Acc: 86.72
[Train] Epoch: 3 [311936/387873]    Loss: 0.001821   Batch Acc: 91.41
[Train] Epoch: 3 [312064/387873]    Loss: 0.001753   Batch Acc: 89.06
[Train] Epoch: 3 [312192/387873]    Loss: 0.001793   Batch Acc: 90.62
[Train] Epoch: 3 [312320/387873]    Loss: 0.002156   Batch Acc: 85.94
[Train] Epoch: 3 [312448/387873]    Loss: 0.002121   Batch Acc: 87.50
[Train] Epoch: 3 [312576/387873]    Loss: 0.001497   Batch Acc: 94.53
[Train] Epoch: 3 [312704/387873]    Loss: 0.001695   Batch Acc: 92.19
[Train] Epoch: 3 [312832/387873]    Loss: 0.001623   Batch Acc: 92.19
[Train] Epoch: 3 [312960/387873]    Loss: 0.001967   Batch Acc: 90.62
[Train] Epoch: 3 [313088/387873]    Loss: 0.001964   Batch Acc: 86.72
[Train] Epoch: 3 [313216/387873]    Loss: 0.001873   Batch Acc: 87.50
[Train] Epoch: 3 [313344/387873]    Loss: 0.002314   Batch Acc: 84.38
[Train] Epoch: 3 [313472/387873]    Loss: 0.002107   Batch Acc: 88.28
[Train] Epoch: 3 [313600/387873]    Loss: 0.002227   Batch Acc: 90.62
[Train] Epoch: 3 [313728/387873]    Loss: 0.002055   Batch Acc: 87.50
[Train] Epoch: 3 [313856/387873]    Loss: 0.002577   Batch Acc: 84.38
[Train] Epoch: 3 [313984/387873]    Loss: 0.001834   Batch Acc: 91.41
[Train] Epoch: 3 [314112/387873]    Loss: 0.002533   Batch Acc: 85.16
[Train] Epoch: 3 [314240/387873]    Loss: 0.001603   Batch Acc: 92.19
[Train] Epoch: 3 [314368/387873]    Loss: 0.001874   Batch Acc: 89.06
[Train] Epoch: 3 [314496/387873]    Loss: 0.001844   Batch Acc: 89.06
[Train] Epoch: 3 [314624/387873]    Loss: 0.001809   Batch Acc: 89.06
[Train] Epoch: 3 [314752/387873]    Loss: 0.001936   Batch Acc: 89.06
[Train] Epoch: 3 [314880/387873]    Loss: 0.001442   Batch Acc: 95.31
[Train] Epoch: 3 [315008/387873]    Loss: 0.001719   Batch Acc: 92.97
[Train] Epoch: 3 [315136/387873]    Loss: 0.002271   Batch Acc: 88.28
[Train] Epoch: 3 [315264/387873]    Loss: 0.001783   Batch Acc: 89.84
[Train] Epoch: 3 [315392/387873]    Loss: 0.002311   Batch Acc: 88.28
[Train] Epoch: 3 [315520/387873]    Loss: 0.002076   Batch Acc: 87.50
[Train] Epoch: 3 [315648/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 3 [315776/387873]    Loss: 0.001893   Batch Acc: 88.28
[Train] Epoch: 3 [315904/387873]    Loss: 0.001623   Batch Acc: 90.62
[Train] Epoch: 3 [316032/387873]    Loss: 0.001718   Batch Acc: 92.19
[Train] Epoch: 3 [316160/387873]    Loss: 0.001848   Batch Acc: 90.62
[Train] Epoch: 3 [316288/387873]    Loss: 0.002384   Batch Acc: 85.16
[Train] Epoch: 3 [316416/387873]    Loss: 0.002039   Batch Acc: 89.84
[Train] Epoch: 3 [316544/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 3 [316672/387873]    Loss: 0.001786   Batch Acc: 92.97
[Train] Epoch: 3 [316800/387873]    Loss: 0.001737   Batch Acc: 92.97
[Train] Epoch: 3 [316928/387873]    Loss: 0.001737   Batch Acc: 89.06
[Train] Epoch: 3 [317056/387873]    Loss: 0.001822   Batch Acc: 92.19
[Train] Epoch: 3 [317184/387873]    Loss: 0.002266   Batch Acc: 88.28
[Train] Epoch: 3 [317312/387873]    Loss: 0.001878   Batch Acc: 92.97
[Train] Epoch: 3 [317440/387873]    Loss: 0.001870   Batch Acc: 92.19
[Train] Epoch: 3 [317568/387873]    Loss: 0.001566   Batch Acc: 92.19
[Train] Epoch: 3 [317696/387873]    Loss: 0.002213   Batch Acc: 85.94
[Train] Epoch: 3 [317824/387873]    Loss: 0.002148   Batch Acc: 88.28
[Train] Epoch: 3 [317952/387873]    Loss: 0.002273   Batch Acc: 87.50
[Train] Epoch: 3 [318080/387873]    Loss: 0.002331   Batch Acc: 89.84
[Train] Epoch: 3 [318208/387873]    Loss: 0.001605   Batch Acc: 92.97
[Train] Epoch: 3 [318336/387873]    Loss: 0.001961   Batch Acc: 85.94
[Train] Epoch: 3 [318464/387873]    Loss: 0.001638   Batch Acc: 93.75
[Train] Epoch: 3 [318592/387873]    Loss: 0.002494   Batch Acc: 87.50
[Train] Epoch: 3 [318720/387873]    Loss: 0.001978   Batch Acc: 89.06
[Train] Epoch: 3 [318848/387873]    Loss: 0.002178   Batch Acc: 84.38
[Train] Epoch: 3 [318976/387873]    Loss: 0.002467   Batch Acc: 87.50
[Train] Epoch: 3 [319104/387873]    Loss: 0.002153   Batch Acc: 89.84
[Train] Epoch: 3 [319232/387873]    Loss: 0.001686   Batch Acc: 91.41
[Train] Epoch: 3 [319360/387873]    Loss: 0.002029   Batch Acc: 89.84
[Train] Epoch: 3 [319488/387873]    Loss: 0.002146   Batch Acc: 86.72
[Train] Epoch: 3 [319616/387873]    Loss: 0.002042   Batch Acc: 89.84
[Train] Epoch: 3 [319744/387873]    Loss: 0.001578   Batch Acc: 92.19
[Train] Epoch: 3 [319872/387873]    Loss: 0.001540   Batch Acc: 92.19
[Train] Epoch: 3 [320000/387873]    Loss: 0.002575   Batch Acc: 85.94
[Train] Epoch: 3 [320128/387873]    Loss: 0.002151   Batch Acc: 86.72
[Train] Epoch: 3 [320256/387873]    Loss: 0.002204   Batch Acc: 90.62
[Train] Epoch: 3 [320384/387873]    Loss: 0.002310   Batch Acc: 85.94
[Train] Epoch: 3 [320512/387873]    Loss: 0.001966   Batch Acc: 88.28
[Train] Epoch: 3 [320640/387873]    Loss: 0.001597   Batch Acc: 92.97
[Train] Epoch: 3 [320768/387873]    Loss: 0.002763   Batch Acc: 85.16
[Train] Epoch: 3 [320896/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 3 [321024/387873]    Loss: 0.001663   Batch Acc: 90.62
[Train] Epoch: 3 [321152/387873]    Loss: 0.002394   Batch Acc: 89.06
[Train] Epoch: 3 [321280/387873]    Loss: 0.002132   Batch Acc: 86.72
[Train] Epoch: 3 [321408/387873]    Loss: 0.001856   Batch Acc: 90.62
[Train] Epoch: 3 [321536/387873]    Loss: 0.001755   Batch Acc: 92.19
[Train] Epoch: 3 [321664/387873]    Loss: 0.001992   Batch Acc: 89.06
[Train] Epoch: 3 [321792/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 3 [321920/387873]    Loss: 0.002143   Batch Acc: 86.72
[Train] Epoch: 3 [322048/387873]    Loss: 0.001952   Batch Acc: 90.62
[Train] Epoch: 3 [322176/387873]    Loss: 0.001954   Batch Acc: 89.84
[Train] Epoch: 3 [322304/387873]    Loss: 0.001840   Batch Acc: 91.41
[Train] Epoch: 3 [322432/387873]    Loss: 0.002090   Batch Acc: 89.84
[Train] Epoch: 3 [322560/387873]    Loss: 0.001734   Batch Acc: 92.97
[Train] Epoch: 3 [322688/387873]    Loss: 0.002214   Batch Acc: 87.50
[Train] Epoch: 3 [322816/387873]    Loss: 0.001679   Batch Acc: 90.62
[Train] Epoch: 3 [322944/387873]    Loss: 0.002284   Batch Acc: 88.28
[Train] Epoch: 3 [323072/387873]    Loss: 0.001881   Batch Acc: 89.06
[Train] Epoch: 3 [323200/387873]    Loss: 0.002104   Batch Acc: 87.50
[Train] Epoch: 3 [323328/387873]    Loss: 0.002189   Batch Acc: 88.28
[Train] Epoch: 3 [323456/387873]    Loss: 0.001874   Batch Acc: 87.50
[Train] Epoch: 3 [323584/387873]    Loss: 0.001883   Batch Acc: 90.62
[Train] Epoch: 3 [323712/387873]    Loss: 0.001541   Batch Acc: 92.97
[Train] Epoch: 3 [323840/387873]    Loss: 0.002180   Batch Acc: 88.28
[Train] Epoch: 3 [323968/387873]    Loss: 0.001805   Batch Acc: 90.62
[Train] Epoch: 3 [324096/387873]    Loss: 0.002262   Batch Acc: 85.94
[Train] Epoch: 3 [324224/387873]    Loss: 0.001719   Batch Acc: 90.62
[Train] Epoch: 3 [324352/387873]    Loss: 0.001290   Batch Acc: 95.31
[Train] Epoch: 3 [324480/387873]    Loss: 0.002329   Batch Acc: 86.72
[Train] Epoch: 3 [324608/387873]    Loss: 0.001978   Batch Acc: 88.28
[Train] Epoch: 3 [324736/387873]    Loss: 0.002431   Batch Acc: 86.72
[Train] Epoch: 3 [324864/387873]    Loss: 0.001592   Batch Acc: 92.97
[Train] Epoch: 3 [324992/387873]    Loss: 0.001790   Batch Acc: 90.62
[Train] Epoch: 3 [325120/387873]    Loss: 0.001740   Batch Acc: 89.84
[Train] Epoch: 3 [325248/387873]    Loss: 0.002195   Batch Acc: 88.28
[Train] Epoch: 3 [325376/387873]    Loss: 0.002023   Batch Acc: 88.28
[Train] Epoch: 3 [325504/387873]    Loss: 0.002344   Batch Acc: 87.50
[Train] Epoch: 3 [325632/387873]    Loss: 0.001999   Batch Acc: 88.28
[Train] Epoch: 3 [325760/387873]    Loss: 0.003376   Batch Acc: 81.25
[Train] Epoch: 3 [325888/387873]    Loss: 0.001803   Batch Acc: 92.19
[Train] Epoch: 3 [326016/387873]    Loss: 0.002148   Batch Acc: 86.72
[Train] Epoch: 3 [326144/387873]    Loss: 0.001981   Batch Acc: 87.50
[Train] Epoch: 3 [326272/387873]    Loss: 0.001892   Batch Acc: 87.50
[Train] Epoch: 3 [326400/387873]    Loss: 0.001836   Batch Acc: 92.97
[Train] Epoch: 3 [326528/387873]    Loss: 0.002388   Batch Acc: 86.72
[Train] Epoch: 3 [326656/387873]    Loss: 0.002227   Batch Acc: 86.72
[Train] Epoch: 3 [326784/387873]    Loss: 0.003017   Batch Acc: 82.03
[Train] Epoch: 3 [326912/387873]    Loss: 0.002434   Batch Acc: 85.16
[Train] Epoch: 3 [327040/387873]    Loss: 0.002267   Batch Acc: 91.41
[Train] Epoch: 3 [327168/387873]    Loss: 0.002145   Batch Acc: 87.50
[Train] Epoch: 3 [327296/387873]    Loss: 0.001938   Batch Acc: 85.94
[Train] Epoch: 3 [327424/387873]    Loss: 0.001928   Batch Acc: 89.06
[Train] Epoch: 3 [327552/387873]    Loss: 0.002502   Batch Acc: 87.50
[Train] Epoch: 3 [327680/387873]    Loss: 0.001880   Batch Acc: 91.41
[Train] Epoch: 3 [327808/387873]    Loss: 0.002039   Batch Acc: 88.28
[Train] Epoch: 3 [327936/387873]    Loss: 0.001878   Batch Acc: 89.84
[Train] Epoch: 3 [328064/387873]    Loss: 0.001810   Batch Acc: 89.06
[Train] Epoch: 3 [328192/387873]    Loss: 0.002170   Batch Acc: 85.16
[Train] Epoch: 3 [328320/387873]    Loss: 0.002615   Batch Acc: 83.59
[Train] Epoch: 3 [328448/387873]    Loss: 0.002242   Batch Acc: 89.84
[Train] Epoch: 3 [328576/387873]    Loss: 0.002471   Batch Acc: 88.28
[Train] Epoch: 3 [328704/387873]    Loss: 0.002668   Batch Acc: 85.16
[Train] Epoch: 3 [328832/387873]    Loss: 0.001981   Batch Acc: 88.28
[Train] Epoch: 3 [328960/387873]    Loss: 0.001610   Batch Acc: 93.75
[Train] Epoch: 3 [329088/387873]    Loss: 0.002179   Batch Acc: 87.50
[Train] Epoch: 3 [329216/387873]    Loss: 0.001944   Batch Acc: 89.84
[Train] Epoch: 3 [329344/387873]    Loss: 0.002047   Batch Acc: 90.62
[Train] Epoch: 3 [329472/387873]    Loss: 0.001718   Batch Acc: 89.84
[Train] Epoch: 3 [329600/387873]    Loss: 0.002323   Batch Acc: 87.50
[Train] Epoch: 3 [329728/387873]    Loss: 0.001633   Batch Acc: 90.62
[Train] Epoch: 3 [329856/387873]    Loss: 0.002077   Batch Acc: 87.50
[Train] Epoch: 3 [329984/387873]    Loss: 0.002333   Batch Acc: 88.28
[Train] Epoch: 3 [330112/387873]    Loss: 0.001552   Batch Acc: 90.62
[Train] Epoch: 3 [330240/387873]    Loss: 0.001816   Batch Acc: 90.62
[Train] Epoch: 3 [330368/387873]    Loss: 0.002279   Batch Acc: 87.50
[Train] Epoch: 3 [330496/387873]    Loss: 0.001696   Batch Acc: 89.84
[Train] Epoch: 3 [330624/387873]    Loss: 0.002121   Batch Acc: 89.84
[Train] Epoch: 3 [330752/387873]    Loss: 0.001580   Batch Acc: 90.62
[Train] Epoch: 3 [330880/387873]    Loss: 0.001898   Batch Acc: 89.84
[Train] Epoch: 3 [331008/387873]    Loss: 0.001967   Batch Acc: 89.06
[Train] Epoch: 3 [331136/387873]    Loss: 0.001538   Batch Acc: 93.75
[Train] Epoch: 3 [331264/387873]    Loss: 0.001808   Batch Acc: 89.06
[Train] Epoch: 3 [331392/387873]    Loss: 0.002423   Batch Acc: 90.62
[Train] Epoch: 3 [331520/387873]    Loss: 0.001881   Batch Acc: 89.06
[Train] Epoch: 3 [331648/387873]    Loss: 0.001403   Batch Acc: 92.19
[Train] Epoch: 3 [331776/387873]    Loss: 0.001442   Batch Acc: 93.75
[Train] Epoch: 3 [331904/387873]    Loss: 0.001884   Batch Acc: 89.06
[Train] Epoch: 3 [332032/387873]    Loss: 0.002249   Batch Acc: 85.94
[Train] Epoch: 3 [332160/387873]    Loss: 0.001565   Batch Acc: 91.41
[Train] Epoch: 3 [332288/387873]    Loss: 0.001633   Batch Acc: 91.41
[Train] Epoch: 3 [332416/387873]    Loss: 0.002171   Batch Acc: 90.62
[Train] Epoch: 3 [332544/387873]    Loss: 0.001662   Batch Acc: 92.19
[Train] Epoch: 3 [332672/387873]    Loss: 0.002221   Batch Acc: 89.06
[Train] Epoch: 3 [332800/387873]    Loss: 0.002614   Batch Acc: 82.03
[Train] Epoch: 3 [332928/387873]    Loss: 0.002349   Batch Acc: 87.50
[Train] Epoch: 3 [333056/387873]    Loss: 0.001785   Batch Acc: 91.41
[Train] Epoch: 3 [333184/387873]    Loss: 0.002255   Batch Acc: 86.72
[Train] Epoch: 3 [333312/387873]    Loss: 0.002339   Batch Acc: 91.41
[Train] Epoch: 3 [333440/387873]    Loss: 0.001707   Batch Acc: 92.19
[Train] Epoch: 3 [333568/387873]    Loss: 0.001895   Batch Acc: 91.41
[Train] Epoch: 3 [333696/387873]    Loss: 0.001247   Batch Acc: 96.09
[Train] Epoch: 3 [333824/387873]    Loss: 0.001618   Batch Acc: 92.97
[Train] Epoch: 3 [333952/387873]    Loss: 0.002071   Batch Acc: 90.62
[Train] Epoch: 3 [334080/387873]    Loss: 0.001690   Batch Acc: 90.62
[Train] Epoch: 3 [334208/387873]    Loss: 0.002107   Batch Acc: 90.62
[Train] Epoch: 3 [334336/387873]    Loss: 0.002609   Batch Acc: 87.50
[Train] Epoch: 3 [334464/387873]    Loss: 0.002301   Batch Acc: 86.72
[Train] Epoch: 3 [334592/387873]    Loss: 0.001632   Batch Acc: 91.41
[Train] Epoch: 3 [334720/387873]    Loss: 0.001623   Batch Acc: 92.19
[Train] Epoch: 3 [334848/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 3 [334976/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 3 [335104/387873]    Loss: 0.001537   Batch Acc: 92.19
[Train] Epoch: 3 [335232/387873]    Loss: 0.002162   Batch Acc: 87.50
[Train] Epoch: 3 [335360/387873]    Loss: 0.001436   Batch Acc: 95.31
[Train] Epoch: 3 [335488/387873]    Loss: 0.001965   Batch Acc: 91.41
[Train] Epoch: 3 [335616/387873]    Loss: 0.001499   Batch Acc: 92.19
[Train] Epoch: 3 [335744/387873]    Loss: 0.001468   Batch Acc: 93.75
[Train] Epoch: 3 [335872/387873]    Loss: 0.002309   Batch Acc: 88.28
[Train] Epoch: 3 [336000/387873]    Loss: 0.001854   Batch Acc: 89.84
[Train] Epoch: 3 [336128/387873]    Loss: 0.001857   Batch Acc: 90.62
[Train] Epoch: 3 [336256/387873]    Loss: 0.001888   Batch Acc: 89.06
[Train] Epoch: 3 [336384/387873]    Loss: 0.001838   Batch Acc: 90.62
[Train] Epoch: 3 [336512/387873]    Loss: 0.001820   Batch Acc: 90.62
[Train] Epoch: 3 [336640/387873]    Loss: 0.002963   Batch Acc: 82.03
[Train] Epoch: 3 [336768/387873]    Loss: 0.001987   Batch Acc: 89.84
[Train] Epoch: 3 [336896/387873]    Loss: 0.001473   Batch Acc: 94.53
[Train] Epoch: 3 [337024/387873]    Loss: 0.002626   Batch Acc: 87.50
[Train] Epoch: 3 [337152/387873]    Loss: 0.001588   Batch Acc: 93.75
[Train] Epoch: 3 [337280/387873]    Loss: 0.001741   Batch Acc: 92.19
[Train] Epoch: 3 [337408/387873]    Loss: 0.001853   Batch Acc: 89.06
[Train] Epoch: 3 [337536/387873]    Loss: 0.002141   Batch Acc: 88.28
[Train] Epoch: 3 [337664/387873]    Loss: 0.002103   Batch Acc: 89.06
[Train] Epoch: 3 [337792/387873]    Loss: 0.002580   Batch Acc: 84.38
[Train] Epoch: 3 [337920/387873]    Loss: 0.001718   Batch Acc: 89.06
[Train] Epoch: 3 [338048/387873]    Loss: 0.002005   Batch Acc: 91.41
[Train] Epoch: 3 [338176/387873]    Loss: 0.002296   Batch Acc: 88.28
[Train] Epoch: 3 [338304/387873]    Loss: 0.002102   Batch Acc: 86.72
[Train] Epoch: 3 [338432/387873]    Loss: 0.002171   Batch Acc: 87.50
[Train] Epoch: 3 [338560/387873]    Loss: 0.002026   Batch Acc: 85.94
[Train] Epoch: 3 [338688/387873]    Loss: 0.002382   Batch Acc: 87.50
[Train] Epoch: 3 [338816/387873]    Loss: 0.002252   Batch Acc: 85.94
[Train] Epoch: 3 [338944/387873]    Loss: 0.002018   Batch Acc: 87.50
[Train] Epoch: 3 [339072/387873]    Loss: 0.001515   Batch Acc: 92.19
[Train] Epoch: 3 [339200/387873]    Loss: 0.001967   Batch Acc: 88.28
[Train] Epoch: 3 [339328/387873]    Loss: 0.002127   Batch Acc: 89.84
[Train] Epoch: 3 [339456/387873]    Loss: 0.001965   Batch Acc: 87.50
[Train] Epoch: 3 [339584/387873]    Loss: 0.002114   Batch Acc: 89.06
[Train] Epoch: 3 [339712/387873]    Loss: 0.002087   Batch Acc: 88.28
[Train] Epoch: 3 [339840/387873]    Loss: 0.001935   Batch Acc: 88.28
[Train] Epoch: 3 [339968/387873]    Loss: 0.002068   Batch Acc: 89.06
[Train] Epoch: 3 [340096/387873]    Loss: 0.001954   Batch Acc: 89.06
[Train] Epoch: 3 [340224/387873]    Loss: 0.001808   Batch Acc: 92.19
[Train] Epoch: 3 [340352/387873]    Loss: 0.001949   Batch Acc: 91.41
[Train] Epoch: 3 [340480/387873]    Loss: 0.001869   Batch Acc: 89.06
[Train] Epoch: 3 [340608/387873]    Loss: 0.002001   Batch Acc: 92.19
[Train] Epoch: 3 [340736/387873]    Loss: 0.001507   Batch Acc: 92.97
[Train] Epoch: 3 [340864/387873]    Loss: 0.001832   Batch Acc: 90.62
[Train] Epoch: 3 [340992/387873]    Loss: 0.001817   Batch Acc: 92.19
[Train] Epoch: 3 [341120/387873]    Loss: 0.001825   Batch Acc: 88.28
[Train] Epoch: 3 [341248/387873]    Loss: 0.002400   Batch Acc: 85.94
[Train] Epoch: 3 [341376/387873]    Loss: 0.001925   Batch Acc: 90.62
[Train] Epoch: 3 [341504/387873]    Loss: 0.001469   Batch Acc: 93.75
[Train] Epoch: 3 [341632/387873]    Loss: 0.002367   Batch Acc: 85.94
[Train] Epoch: 3 [341760/387873]    Loss: 0.001391   Batch Acc: 93.75
[Train] Epoch: 3 [341888/387873]    Loss: 0.002142   Batch Acc: 87.50
[Train] Epoch: 3 [342016/387873]    Loss: 0.001239   Batch Acc: 96.88
[Train] Epoch: 3 [342144/387873]    Loss: 0.001347   Batch Acc: 95.31
[Train] Epoch: 3 [342272/387873]    Loss: 0.002471   Batch Acc: 89.06
[Train] Epoch: 3 [342400/387873]    Loss: 0.001627   Batch Acc: 92.19
[Train] Epoch: 3 [342528/387873]    Loss: 0.001423   Batch Acc: 94.53
[Train] Epoch: 3 [342656/387873]    Loss: 0.002634   Batch Acc: 84.38
[Train] Epoch: 3 [342784/387873]    Loss: 0.002375   Batch Acc: 85.94
[Train] Epoch: 3 [342912/387873]    Loss: 0.002037   Batch Acc: 90.62
[Train] Epoch: 3 [343040/387873]    Loss: 0.001644   Batch Acc: 92.19
[Train] Epoch: 3 [343168/387873]    Loss: 0.001635   Batch Acc: 93.75
[Train] Epoch: 3 [343296/387873]    Loss: 0.001785   Batch Acc: 90.62
[Train] Epoch: 3 [343424/387873]    Loss: 0.001876   Batch Acc: 90.62
[Train] Epoch: 3 [343552/387873]    Loss: 0.001493   Batch Acc: 94.53
[Train] Epoch: 3 [343680/387873]    Loss: 0.001705   Batch Acc: 89.84
[Train] Epoch: 3 [343808/387873]    Loss: 0.001393   Batch Acc: 93.75
[Train] Epoch: 3 [343936/387873]    Loss: 0.001988   Batch Acc: 89.06
[Train] Epoch: 3 [344064/387873]    Loss: 0.002050   Batch Acc: 85.94
[Train] Epoch: 3 [344192/387873]    Loss: 0.001970   Batch Acc: 89.84
[Train] Epoch: 3 [344320/387873]    Loss: 0.001968   Batch Acc: 88.28
[Train] Epoch: 3 [344448/387873]    Loss: 0.002040   Batch Acc: 92.19
[Train] Epoch: 3 [344576/387873]    Loss: 0.001617   Batch Acc: 92.19
[Train] Epoch: 3 [344704/387873]    Loss: 0.001789   Batch Acc: 89.84
[Train] Epoch: 3 [344832/387873]    Loss: 0.002185   Batch Acc: 85.16
[Train] Epoch: 3 [344960/387873]    Loss: 0.002275   Batch Acc: 86.72
[Train] Epoch: 3 [345088/387873]    Loss: 0.001906   Batch Acc: 92.97
[Train] Epoch: 3 [345216/387873]    Loss: 0.002106   Batch Acc: 88.28
[Train] Epoch: 3 [345344/387873]    Loss: 0.002201   Batch Acc: 90.62
[Train] Epoch: 3 [345472/387873]    Loss: 0.002558   Batch Acc: 84.38
[Train] Epoch: 3 [345600/387873]    Loss: 0.002447   Batch Acc: 85.94
[Train] Epoch: 3 [345728/387873]    Loss: 0.001835   Batch Acc: 91.41
[Train] Epoch: 3 [345856/387873]    Loss: 0.002243   Batch Acc: 86.72
[Train] Epoch: 3 [345984/387873]    Loss: 0.002498   Batch Acc: 82.81
[Train] Epoch: 3 [346112/387873]    Loss: 0.002149   Batch Acc: 89.06
[Train] Epoch: 3 [346240/387873]    Loss: 0.001960   Batch Acc: 90.62
[Train] Epoch: 3 [346368/387873]    Loss: 0.001481   Batch Acc: 96.09
[Train] Epoch: 3 [346496/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 3 [346624/387873]    Loss: 0.001595   Batch Acc: 92.19
[Train] Epoch: 3 [346752/387873]    Loss: 0.001760   Batch Acc: 92.19
[Train] Epoch: 3 [346880/387873]    Loss: 0.002142   Batch Acc: 90.62
[Train] Epoch: 3 [347008/387873]    Loss: 0.001286   Batch Acc: 96.09
[Train] Epoch: 3 [347136/387873]    Loss: 0.001809   Batch Acc: 92.19
[Train] Epoch: 3 [347264/387873]    Loss: 0.002529   Batch Acc: 85.94
[Train] Epoch: 3 [347392/387873]    Loss: 0.001921   Batch Acc: 90.62
[Train] Epoch: 3 [347520/387873]    Loss: 0.002375   Batch Acc: 87.50
[Train] Epoch: 3 [347648/387873]    Loss: 0.002146   Batch Acc: 89.06
[Train] Epoch: 3 [347776/387873]    Loss: 0.001983   Batch Acc: 88.28
[Train] Epoch: 3 [347904/387873]    Loss: 0.002036   Batch Acc: 89.84
[Train] Epoch: 3 [348032/387873]    Loss: 0.002597   Batch Acc: 82.81
[Train] Epoch: 3 [348160/387873]    Loss: 0.002822   Batch Acc: 83.59
[Train] Epoch: 3 [348288/387873]    Loss: 0.002036   Batch Acc: 87.50
[Train] Epoch: 3 [348416/387873]    Loss: 0.001815   Batch Acc: 91.41
[Train] Epoch: 3 [348544/387873]    Loss: 0.001780   Batch Acc: 92.19
[Train] Epoch: 3 [348672/387873]    Loss: 0.002054   Batch Acc: 87.50
[Train] Epoch: 3 [348800/387873]    Loss: 0.002592   Batch Acc: 85.16
[Train] Epoch: 3 [348928/387873]    Loss: 0.002403   Batch Acc: 85.16
[Train] Epoch: 3 [349056/387873]    Loss: 0.001857   Batch Acc: 88.28
[Train] Epoch: 3 [349184/387873]    Loss: 0.001897   Batch Acc: 90.62
[Train] Epoch: 3 [349312/387873]    Loss: 0.002739   Batch Acc: 82.81
[Train] Epoch: 3 [349440/387873]    Loss: 0.002460   Batch Acc: 84.38
[Train] Epoch: 3 [349568/387873]    Loss: 0.001854   Batch Acc: 92.19
[Train] Epoch: 3 [349696/387873]    Loss: 0.002538   Batch Acc: 85.94
[Train] Epoch: 3 [349824/387873]    Loss: 0.001455   Batch Acc: 91.41
[Train] Epoch: 3 [349952/387873]    Loss: 0.002035   Batch Acc: 85.94
[Train] Epoch: 3 [350080/387873]    Loss: 0.001646   Batch Acc: 89.84
[Train] Epoch: 3 [350208/387873]    Loss: 0.001973   Batch Acc: 88.28
[Train] Epoch: 3 [350336/387873]    Loss: 0.002088   Batch Acc: 89.84
[Train] Epoch: 3 [350464/387873]    Loss: 0.002021   Batch Acc: 87.50
[Train] Epoch: 3 [350592/387873]    Loss: 0.001786   Batch Acc: 90.62
[Train] Epoch: 3 [350720/387873]    Loss: 0.001902   Batch Acc: 88.28
[Train] Epoch: 3 [350848/387873]    Loss: 0.002317   Batch Acc: 85.16
[Train] Epoch: 3 [350976/387873]    Loss: 0.001911   Batch Acc: 89.84
[Train] Epoch: 3 [351104/387873]    Loss: 0.002039   Batch Acc: 90.62
[Train] Epoch: 3 [351232/387873]    Loss: 0.002364   Batch Acc: 85.16
[Train] Epoch: 3 [351360/387873]    Loss: 0.002079   Batch Acc: 85.94
[Train] Epoch: 3 [351488/387873]    Loss: 0.001626   Batch Acc: 91.41
[Train] Epoch: 3 [351616/387873]    Loss: 0.001859   Batch Acc: 89.84
[Train] Epoch: 3 [351744/387873]    Loss: 0.002073   Batch Acc: 87.50
[Train] Epoch: 3 [351872/387873]    Loss: 0.001309   Batch Acc: 93.75
[Train] Epoch: 3 [352000/387873]    Loss: 0.001626   Batch Acc: 93.75
[Train] Epoch: 3 [352128/387873]    Loss: 0.001735   Batch Acc: 89.84
[Train] Epoch: 3 [352256/387873]    Loss: 0.001851   Batch Acc: 89.84
[Train] Epoch: 3 [352384/387873]    Loss: 0.002846   Batch Acc: 85.16
[Train] Epoch: 3 [352512/387873]    Loss: 0.001669   Batch Acc: 92.97
[Train] Epoch: 3 [352640/387873]    Loss: 0.002678   Batch Acc: 89.06
[Train] Epoch: 3 [352768/387873]    Loss: 0.001951   Batch Acc: 90.62
[Train] Epoch: 3 [352896/387873]    Loss: 0.002247   Batch Acc: 89.06
[Train] Epoch: 3 [353024/387873]    Loss: 0.001888   Batch Acc: 91.41
[Train] Epoch: 3 [353152/387873]    Loss: 0.001832   Batch Acc: 88.28
[Train] Epoch: 3 [353280/387873]    Loss: 0.001949   Batch Acc: 92.97
[Train] Epoch: 3 [353408/387873]    Loss: 0.001689   Batch Acc: 92.19
[Train] Epoch: 3 [353536/387873]    Loss: 0.001992   Batch Acc: 92.97
[Train] Epoch: 3 [353664/387873]    Loss: 0.001784   Batch Acc: 92.97
[Train] Epoch: 3 [353792/387873]    Loss: 0.001829   Batch Acc: 92.19
[Train] Epoch: 3 [353920/387873]    Loss: 0.001787   Batch Acc: 92.19
[Train] Epoch: 3 [354048/387873]    Loss: 0.001757   Batch Acc: 91.41
[Train] Epoch: 3 [354176/387873]    Loss: 0.002016   Batch Acc: 92.19
[Train] Epoch: 3 [354304/387873]    Loss: 0.001416   Batch Acc: 94.53
[Train] Epoch: 3 [354432/387873]    Loss: 0.002931   Batch Acc: 80.47
[Train] Epoch: 3 [354560/387873]    Loss: 0.002087   Batch Acc: 86.72
[Train] Epoch: 3 [354688/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 3 [354816/387873]    Loss: 0.001975   Batch Acc: 88.28
[Train] Epoch: 3 [354944/387873]    Loss: 0.001866   Batch Acc: 88.28
[Train] Epoch: 3 [355072/387873]    Loss: 0.001777   Batch Acc: 91.41
[Train] Epoch: 3 [355200/387873]    Loss: 0.002474   Batch Acc: 85.16
[Train] Epoch: 3 [355328/387873]    Loss: 0.001771   Batch Acc: 92.19
[Train] Epoch: 3 [355456/387873]    Loss: 0.002114   Batch Acc: 88.28
[Train] Epoch: 3 [355584/387873]    Loss: 0.002102   Batch Acc: 89.84
[Train] Epoch: 3 [355712/387873]    Loss: 0.001874   Batch Acc: 89.06
[Train] Epoch: 3 [355840/387873]    Loss: 0.002542   Batch Acc: 85.16
[Train] Epoch: 3 [355968/387873]    Loss: 0.001891   Batch Acc: 91.41
[Train] Epoch: 3 [356096/387873]    Loss: 0.001959   Batch Acc: 89.84
[Train] Epoch: 3 [356224/387873]    Loss: 0.001820   Batch Acc: 90.62
[Train] Epoch: 3 [356352/387873]    Loss: 0.001975   Batch Acc: 89.06
[Train] Epoch: 3 [356480/387873]    Loss: 0.002045   Batch Acc: 90.62
[Train] Epoch: 3 [356608/387873]    Loss: 0.001746   Batch Acc: 93.75
[Train] Epoch: 3 [356736/387873]    Loss: 0.002021   Batch Acc: 88.28
[Train] Epoch: 3 [356864/387873]    Loss: 0.001733   Batch Acc: 89.84
[Train] Epoch: 3 [356992/387873]    Loss: 0.002612   Batch Acc: 83.59
[Train] Epoch: 3 [357120/387873]    Loss: 0.002193   Batch Acc: 87.50
[Train] Epoch: 3 [357248/387873]    Loss: 0.001832   Batch Acc: 88.28
[Train] Epoch: 3 [357376/387873]    Loss: 0.002042   Batch Acc: 87.50
[Train] Epoch: 3 [357504/387873]    Loss: 0.002022   Batch Acc: 87.50
[Train] Epoch: 3 [357632/387873]    Loss: 0.001755   Batch Acc: 90.62
[Train] Epoch: 3 [357760/387873]    Loss: 0.002871   Batch Acc: 82.81
[Train] Epoch: 3 [357888/387873]    Loss: 0.002838   Batch Acc: 87.50
[Train] Epoch: 3 [358016/387873]    Loss: 0.002173   Batch Acc: 87.50
[Train] Epoch: 3 [358144/387873]    Loss: 0.001887   Batch Acc: 91.41
[Train] Epoch: 3 [358272/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 3 [358400/387873]    Loss: 0.001853   Batch Acc: 89.84
[Train] Epoch: 3 [358528/387873]    Loss: 0.001942   Batch Acc: 91.41
[Train] Epoch: 3 [358656/387873]    Loss: 0.002464   Batch Acc: 90.62
[Train] Epoch: 3 [358784/387873]    Loss: 0.001902   Batch Acc: 91.41
[Train] Epoch: 3 [358912/387873]    Loss: 0.001838   Batch Acc: 91.41
[Train] Epoch: 3 [359040/387873]    Loss: 0.001399   Batch Acc: 94.53
[Train] Epoch: 3 [359168/387873]    Loss: 0.001722   Batch Acc: 92.97
[Train] Epoch: 3 [359296/387873]    Loss: 0.001349   Batch Acc: 95.31
[Train] Epoch: 3 [359424/387873]    Loss: 0.002279   Batch Acc: 85.16
[Train] Epoch: 3 [359552/387873]    Loss: 0.002017   Batch Acc: 90.62
[Train] Epoch: 3 [359680/387873]    Loss: 0.001641   Batch Acc: 89.84
[Train] Epoch: 3 [359808/387873]    Loss: 0.002052   Batch Acc: 90.62
[Train] Epoch: 3 [359936/387873]    Loss: 0.002252   Batch Acc: 87.50
[Train] Epoch: 3 [360064/387873]    Loss: 0.001870   Batch Acc: 90.62
[Train] Epoch: 3 [360192/387873]    Loss: 0.001951   Batch Acc: 90.62
[Train] Epoch: 3 [360320/387873]    Loss: 0.001588   Batch Acc: 92.97
[Train] Epoch: 3 [360448/387873]    Loss: 0.001807   Batch Acc: 92.97
[Train] Epoch: 3 [360576/387873]    Loss: 0.001984   Batch Acc: 92.19
[Train] Epoch: 3 [360704/387873]    Loss: 0.001484   Batch Acc: 92.97
[Train] Epoch: 3 [360832/387873]    Loss: 0.002110   Batch Acc: 89.06
[Train] Epoch: 3 [360960/387873]    Loss: 0.001889   Batch Acc: 89.06
[Train] Epoch: 3 [361088/387873]    Loss: 0.001925   Batch Acc: 90.62
[Train] Epoch: 3 [361216/387873]    Loss: 0.002017   Batch Acc: 89.06
[Train] Epoch: 3 [361344/387873]    Loss: 0.001800   Batch Acc: 89.84
[Train] Epoch: 3 [361472/387873]    Loss: 0.001742   Batch Acc: 92.19
[Train] Epoch: 3 [361600/387873]    Loss: 0.002559   Batch Acc: 83.59
[Train] Epoch: 3 [361728/387873]    Loss: 0.002074   Batch Acc: 90.62
[Train] Epoch: 3 [361856/387873]    Loss: 0.001889   Batch Acc: 89.84
[Train] Epoch: 3 [361984/387873]    Loss: 0.002331   Batch Acc: 87.50
[Train] Epoch: 3 [362112/387873]    Loss: 0.002432   Batch Acc: 83.59
[Train] Epoch: 3 [362240/387873]    Loss: 0.002693   Batch Acc: 84.38
[Train] Epoch: 3 [362368/387873]    Loss: 0.002653   Batch Acc: 84.38
[Train] Epoch: 3 [362496/387873]    Loss: 0.002210   Batch Acc: 85.94
[Train] Epoch: 3 [362624/387873]    Loss: 0.002131   Batch Acc: 85.16
[Train] Epoch: 3 [362752/387873]    Loss: 0.001766   Batch Acc: 91.41
[Train] Epoch: 3 [362880/387873]    Loss: 0.001965   Batch Acc: 89.84
[Train] Epoch: 3 [363008/387873]    Loss: 0.001790   Batch Acc: 93.75
[Train] Epoch: 3 [363136/387873]    Loss: 0.002810   Batch Acc: 84.38
[Train] Epoch: 3 [363264/387873]    Loss: 0.001367   Batch Acc: 92.97
[Train] Epoch: 3 [363392/387873]    Loss: 0.001952   Batch Acc: 91.41
[Train] Epoch: 3 [363520/387873]    Loss: 0.002227   Batch Acc: 86.72
[Train] Epoch: 3 [363648/387873]    Loss: 0.002290   Batch Acc: 86.72
[Train] Epoch: 3 [363776/387873]    Loss: 0.001708   Batch Acc: 89.06
[Train] Epoch: 3 [363904/387873]    Loss: 0.001991   Batch Acc: 88.28
[Train] Epoch: 3 [364032/387873]    Loss: 0.001856   Batch Acc: 89.84
[Train] Epoch: 3 [364160/387873]    Loss: 0.002667   Batch Acc: 87.50
[Train] Epoch: 3 [364288/387873]    Loss: 0.001944   Batch Acc: 89.06
[Train] Epoch: 3 [364416/387873]    Loss: 0.002411   Batch Acc: 87.50
[Train] Epoch: 3 [364544/387873]    Loss: 0.002380   Batch Acc: 88.28
[Train] Epoch: 3 [364672/387873]    Loss: 0.001484   Batch Acc: 92.97
[Train] Epoch: 3 [364800/387873]    Loss: 0.002754   Batch Acc: 84.38
[Train] Epoch: 3 [364928/387873]    Loss: 0.001765   Batch Acc: 90.62
[Train] Epoch: 3 [365056/387873]    Loss: 0.001805   Batch Acc: 92.19
[Train] Epoch: 3 [365184/387873]    Loss: 0.002469   Batch Acc: 83.59
[Train] Epoch: 3 [365312/387873]    Loss: 0.001499   Batch Acc: 91.41
[Train] Epoch: 3 [365440/387873]    Loss: 0.001844   Batch Acc: 92.19
[Train] Epoch: 3 [365568/387873]    Loss: 0.001763   Batch Acc: 90.62
[Train] Epoch: 3 [365696/387873]    Loss: 0.002239   Batch Acc: 87.50
[Train] Epoch: 3 [365824/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 3 [365952/387873]    Loss: 0.001784   Batch Acc: 92.97
[Train] Epoch: 3 [366080/387873]    Loss: 0.001532   Batch Acc: 91.41
[Train] Epoch: 3 [366208/387873]    Loss: 0.001717   Batch Acc: 90.62
[Train] Epoch: 3 [366336/387873]    Loss: 0.001699   Batch Acc: 91.41
[Train] Epoch: 3 [366464/387873]    Loss: 0.001889   Batch Acc: 91.41
[Train] Epoch: 3 [366592/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 3 [366720/387873]    Loss: 0.002210   Batch Acc: 85.94
[Train] Epoch: 3 [366848/387873]    Loss: 0.002147   Batch Acc: 85.94
[Train] Epoch: 3 [366976/387873]    Loss: 0.002086   Batch Acc: 92.19
[Train] Epoch: 3 [367104/387873]    Loss: 0.001997   Batch Acc: 91.41
[Train] Epoch: 3 [367232/387873]    Loss: 0.001897   Batch Acc: 89.06
[Train] Epoch: 3 [367360/387873]    Loss: 0.002640   Batch Acc: 85.94
[Train] Epoch: 3 [367488/387873]    Loss: 0.001980   Batch Acc: 90.62
[Train] Epoch: 3 [367616/387873]    Loss: 0.001618   Batch Acc: 93.75
[Train] Epoch: 3 [367744/387873]    Loss: 0.001468   Batch Acc: 93.75
[Train] Epoch: 3 [367872/387873]    Loss: 0.001860   Batch Acc: 90.62
[Train] Epoch: 3 [368000/387873]    Loss: 0.002748   Batch Acc: 84.38
[Train] Epoch: 3 [368128/387873]    Loss: 0.002164   Batch Acc: 88.28
[Train] Epoch: 3 [368256/387873]    Loss: 0.001702   Batch Acc: 92.19
[Train] Epoch: 3 [368384/387873]    Loss: 0.002096   Batch Acc: 88.28
[Train] Epoch: 3 [368512/387873]    Loss: 0.001924   Batch Acc: 85.16
[Train] Epoch: 3 [368640/387873]    Loss: 0.001360   Batch Acc: 92.97
[Train] Epoch: 3 [368768/387873]    Loss: 0.001776   Batch Acc: 92.97
[Train] Epoch: 3 [368896/387873]    Loss: 0.002113   Batch Acc: 86.72
[Train] Epoch: 3 [369024/387873]    Loss: 0.001979   Batch Acc: 89.06
[Train] Epoch: 3 [369152/387873]    Loss: 0.001605   Batch Acc: 94.53
[Train] Epoch: 3 [369280/387873]    Loss: 0.001782   Batch Acc: 90.62
[Train] Epoch: 3 [369408/387873]    Loss: 0.002470   Batch Acc: 83.59
[Train] Epoch: 3 [369536/387873]    Loss: 0.001381   Batch Acc: 94.53
[Train] Epoch: 3 [369664/387873]    Loss: 0.001567   Batch Acc: 92.97
[Train] Epoch: 3 [369792/387873]    Loss: 0.001824   Batch Acc: 88.28
[Train] Epoch: 3 [369920/387873]    Loss: 0.002393   Batch Acc: 88.28
[Train] Epoch: 3 [370048/387873]    Loss: 0.003089   Batch Acc: 80.47
[Train] Epoch: 3 [370176/387873]    Loss: 0.002550   Batch Acc: 85.94
[Train] Epoch: 3 [370304/387873]    Loss: 0.002026   Batch Acc: 89.84
[Train] Epoch: 3 [370432/387873]    Loss: 0.002378   Batch Acc: 85.16
[Train] Epoch: 3 [370560/387873]    Loss: 0.001539   Batch Acc: 92.19
[Train] Epoch: 3 [370688/387873]    Loss: 0.001616   Batch Acc: 89.84
[Train] Epoch: 3 [370816/387873]    Loss: 0.001719   Batch Acc: 91.41
[Train] Epoch: 3 [370944/387873]    Loss: 0.002172   Batch Acc: 90.62
[Train] Epoch: 3 [371072/387873]    Loss: 0.001642   Batch Acc: 90.62
[Train] Epoch: 3 [371200/387873]    Loss: 0.001432   Batch Acc: 93.75
[Train] Epoch: 3 [371328/387873]    Loss: 0.001927   Batch Acc: 92.19
[Train] Epoch: 3 [371456/387873]    Loss: 0.002094   Batch Acc: 90.62
[Train] Epoch: 3 [371584/387873]    Loss: 0.002223   Batch Acc: 88.28
[Train] Epoch: 3 [371712/387873]    Loss: 0.001732   Batch Acc: 91.41
[Train] Epoch: 3 [371840/387873]    Loss: 0.002057   Batch Acc: 86.72
[Train] Epoch: 3 [371968/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 3 [372096/387873]    Loss: 0.001815   Batch Acc: 90.62
[Train] Epoch: 3 [372224/387873]    Loss: 0.002112   Batch Acc: 90.62
[Train] Epoch: 3 [372352/387873]    Loss: 0.001736   Batch Acc: 92.19
[Train] Epoch: 3 [372480/387873]    Loss: 0.002273   Batch Acc: 86.72
[Train] Epoch: 3 [372608/387873]    Loss: 0.001596   Batch Acc: 90.62
[Train] Epoch: 3 [372736/387873]    Loss: 0.002387   Batch Acc: 83.59
[Train] Epoch: 3 [372864/387873]    Loss: 0.001622   Batch Acc: 89.84
[Train] Epoch: 3 [372992/387873]    Loss: 0.002374   Batch Acc: 85.94
[Train] Epoch: 3 [373120/387873]    Loss: 0.002422   Batch Acc: 87.50
[Train] Epoch: 3 [373248/387873]    Loss: 0.001678   Batch Acc: 91.41
[Train] Epoch: 3 [373376/387873]    Loss: 0.001808   Batch Acc: 90.62
[Train] Epoch: 3 [373504/387873]    Loss: 0.002217   Batch Acc: 85.16
[Train] Epoch: 3 [373632/387873]    Loss: 0.001424   Batch Acc: 92.19
[Train] Epoch: 3 [373760/387873]    Loss: 0.001925   Batch Acc: 89.84
[Train] Epoch: 3 [373888/387873]    Loss: 0.002167   Batch Acc: 88.28
[Train] Epoch: 3 [374016/387873]    Loss: 0.001692   Batch Acc: 90.62
[Train] Epoch: 3 [374144/387873]    Loss: 0.001774   Batch Acc: 91.41
[Train] Epoch: 3 [374272/387873]    Loss: 0.001723   Batch Acc: 91.41
[Train] Epoch: 3 [374400/387873]    Loss: 0.002409   Batch Acc: 89.06
[Train] Epoch: 3 [374528/387873]    Loss: 0.001554   Batch Acc: 94.53
[Train] Epoch: 3 [374656/387873]    Loss: 0.002384   Batch Acc: 87.50
[Train] Epoch: 3 [374784/387873]    Loss: 0.002141   Batch Acc: 89.84
[Train] Epoch: 3 [374912/387873]    Loss: 0.001607   Batch Acc: 91.41
[Train] Epoch: 3 [375040/387873]    Loss: 0.002609   Batch Acc: 89.06
[Train] Epoch: 3 [375168/387873]    Loss: 0.002172   Batch Acc: 87.50
[Train] Epoch: 3 [375296/387873]    Loss: 0.002387   Batch Acc: 85.16
[Train] Epoch: 3 [375424/387873]    Loss: 0.001761   Batch Acc: 91.41
[Train] Epoch: 3 [375552/387873]    Loss: 0.001913   Batch Acc: 89.84
[Train] Epoch: 3 [375680/387873]    Loss: 0.002333   Batch Acc: 89.06
[Train] Epoch: 3 [375808/387873]    Loss: 0.002207   Batch Acc: 88.28
[Train] Epoch: 3 [375936/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 3 [376064/387873]    Loss: 0.002091   Batch Acc: 89.06
[Train] Epoch: 3 [376192/387873]    Loss: 0.001881   Batch Acc: 89.06
[Train] Epoch: 3 [376320/387873]    Loss: 0.002358   Batch Acc: 85.94
[Train] Epoch: 3 [376448/387873]    Loss: 0.002089   Batch Acc: 90.62
[Train] Epoch: 3 [376576/387873]    Loss: 0.002205   Batch Acc: 86.72
[Train] Epoch: 3 [376704/387873]    Loss: 0.002428   Batch Acc: 86.72
[Train] Epoch: 3 [376832/387873]    Loss: 0.001544   Batch Acc: 93.75
[Train] Epoch: 3 [376960/387873]    Loss: 0.002006   Batch Acc: 89.84
[Train] Epoch: 3 [377088/387873]    Loss: 0.001916   Batch Acc: 87.50
[Train] Epoch: 3 [377216/387873]    Loss: 0.002622   Batch Acc: 80.47
[Train] Epoch: 3 [377344/387873]    Loss: 0.002513   Batch Acc: 85.94
[Train] Epoch: 3 [377472/387873]    Loss: 0.002154   Batch Acc: 87.50
[Train] Epoch: 3 [377600/387873]    Loss: 0.002507   Batch Acc: 89.06
[Train] Epoch: 3 [377728/387873]    Loss: 0.002154   Batch Acc: 88.28
[Train] Epoch: 3 [377856/387873]    Loss: 0.002138   Batch Acc: 88.28
[Train] Epoch: 3 [377984/387873]    Loss: 0.002035   Batch Acc: 89.06
[Train] Epoch: 3 [378112/387873]    Loss: 0.001863   Batch Acc: 89.84
[Train] Epoch: 3 [378240/387873]    Loss: 0.001417   Batch Acc: 93.75
[Train] Epoch: 3 [378368/387873]    Loss: 0.001608   Batch Acc: 94.53
[Train] Epoch: 3 [378496/387873]    Loss: 0.002468   Batch Acc: 88.28
[Train] Epoch: 3 [378624/387873]    Loss: 0.002024   Batch Acc: 89.84
[Train] Epoch: 3 [378752/387873]    Loss: 0.001410   Batch Acc: 92.97
[Train] Epoch: 3 [378880/387873]    Loss: 0.001808   Batch Acc: 89.84
[Train] Epoch: 3 [379008/387873]    Loss: 0.001899   Batch Acc: 92.19
[Train] Epoch: 3 [379136/387873]    Loss: 0.001880   Batch Acc: 89.06
[Train] Epoch: 3 [379264/387873]    Loss: 0.001633   Batch Acc: 92.97
[Train] Epoch: 3 [379392/387873]    Loss: 0.001903   Batch Acc: 89.06
[Train] Epoch: 3 [379520/387873]    Loss: 0.001640   Batch Acc: 90.62
[Train] Epoch: 3 [379648/387873]    Loss: 0.001567   Batch Acc: 92.19
[Train] Epoch: 3 [379776/387873]    Loss: 0.001818   Batch Acc: 89.06
[Train] Epoch: 3 [379904/387873]    Loss: 0.002536   Batch Acc: 86.72
[Train] Epoch: 3 [380032/387873]    Loss: 0.002095   Batch Acc: 89.84
[Train] Epoch: 3 [380160/387873]    Loss: 0.002523   Batch Acc: 84.38
[Train] Epoch: 3 [380288/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 3 [380416/387873]    Loss: 0.001957   Batch Acc: 90.62
[Train] Epoch: 3 [380544/387873]    Loss: 0.002382   Batch Acc: 86.72
[Train] Epoch: 3 [380672/387873]    Loss: 0.002052   Batch Acc: 89.84
[Train] Epoch: 3 [380800/387873]    Loss: 0.001550   Batch Acc: 92.97
[Train] Epoch: 3 [380928/387873]    Loss: 0.001899   Batch Acc: 91.41
[Train] Epoch: 3 [381056/387873]    Loss: 0.001691   Batch Acc: 90.62
[Train] Epoch: 3 [381184/387873]    Loss: 0.002724   Batch Acc: 82.81
[Train] Epoch: 3 [381312/387873]    Loss: 0.001929   Batch Acc: 92.19
[Train] Epoch: 3 [381440/387873]    Loss: 0.002099   Batch Acc: 87.50
[Train] Epoch: 3 [381568/387873]    Loss: 0.001937   Batch Acc: 89.06
[Train] Epoch: 3 [381696/387873]    Loss: 0.002340   Batch Acc: 89.06
[Train] Epoch: 3 [381824/387873]    Loss: 0.001850   Batch Acc: 91.41
[Train] Epoch: 3 [381952/387873]    Loss: 0.001992   Batch Acc: 90.62
[Train] Epoch: 3 [382080/387873]    Loss: 0.001628   Batch Acc: 93.75
[Train] Epoch: 3 [382208/387873]    Loss: 0.002043   Batch Acc: 89.06
[Train] Epoch: 3 [382336/387873]    Loss: 0.002672   Batch Acc: 85.16
[Train] Epoch: 3 [382464/387873]    Loss: 0.001485   Batch Acc: 94.53
[Train] Epoch: 3 [382592/387873]    Loss: 0.001676   Batch Acc: 92.19
[Train] Epoch: 3 [382720/387873]    Loss: 0.001846   Batch Acc: 87.50
[Train] Epoch: 3 [382848/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 3 [382976/387873]    Loss: 0.002223   Batch Acc: 88.28
[Train] Epoch: 3 [383104/387873]    Loss: 0.002587   Batch Acc: 81.25
[Train] Epoch: 3 [383232/387873]    Loss: 0.001945   Batch Acc: 90.62
[Train] Epoch: 3 [383360/387873]    Loss: 0.002106   Batch Acc: 90.62
[Train] Epoch: 3 [383488/387873]    Loss: 0.001512   Batch Acc: 90.62
[Train] Epoch: 3 [383616/387873]    Loss: 0.001740   Batch Acc: 92.19
[Train] Epoch: 3 [383744/387873]    Loss: 0.002815   Batch Acc: 86.72
[Train] Epoch: 3 [383872/387873]    Loss: 0.001933   Batch Acc: 89.06
[Train] Epoch: 3 [384000/387873]    Loss: 0.002341   Batch Acc: 89.06
[Train] Epoch: 3 [384128/387873]    Loss: 0.001910   Batch Acc: 89.06
[Train] Epoch: 3 [384256/387873]    Loss: 0.002186   Batch Acc: 89.06
[Train] Epoch: 3 [384384/387873]    Loss: 0.001493   Batch Acc: 96.88
[Train] Epoch: 3 [384512/387873]    Loss: 0.002360   Batch Acc: 85.94
[Train] Epoch: 3 [384640/387873]    Loss: 0.001953   Batch Acc: 87.50
[Train] Epoch: 3 [384768/387873]    Loss: 0.002050   Batch Acc: 87.50
[Train] Epoch: 3 [384896/387873]    Loss: 0.001748   Batch Acc: 89.84
[Train] Epoch: 3 [385024/387873]    Loss: 0.002062   Batch Acc: 85.94
[Train] Epoch: 3 [385152/387873]    Loss: 0.002197   Batch Acc: 84.38
[Train] Epoch: 3 [385280/387873]    Loss: 0.001790   Batch Acc: 90.62
[Train] Epoch: 3 [385408/387873]    Loss: 0.001968   Batch Acc: 89.84
[Train] Epoch: 3 [385536/387873]    Loss: 0.002602   Batch Acc: 85.16
[Train] Epoch: 3 [385664/387873]    Loss: 0.002002   Batch Acc: 86.72
[Train] Epoch: 3 [385792/387873]    Loss: 0.001939   Batch Acc: 87.50
[Train] Epoch: 3 [385920/387873]    Loss: 0.001468   Batch Acc: 93.75
[Train] Epoch: 3 [386048/387873]    Loss: 0.002132   Batch Acc: 86.72
[Train] Epoch: 3 [386176/387873]    Loss: 0.001381   Batch Acc: 92.97
[Train] Epoch: 3 [386304/387873]    Loss: 0.002027   Batch Acc: 89.06
[Train] Epoch: 3 [386432/387873]    Loss: 0.002254   Batch Acc: 88.28
[Train] Epoch: 3 [386560/387873]    Loss: 0.002357   Batch Acc: 88.28
[Train] Epoch: 3 [386688/387873]    Loss: 0.001658   Batch Acc: 90.62
[Train] Epoch: 3 [386816/387873]    Loss: 0.002135   Batch Acc: 87.50
[Train] Epoch: 3 [386944/387873]    Loss: 0.002263   Batch Acc: 89.06
[Train] Epoch: 3 [387072/387873]    Loss: 0.001655   Batch Acc: 92.19
[Train] Epoch: 3 [387200/387873]    Loss: 0.001959   Batch Acc: 90.62
[Train] Epoch: 3 [387328/387873]    Loss: 0.001798   Batch Acc: 92.19
[Train] Epoch: 3 [387456/387873]    Loss: 0.001843   Batch Acc: 91.41
[Train] Epoch: 3 [387584/387873]    Loss: 0.002134   Batch Acc: 87.50
[Train] Epoch: 3 [387712/387873]    Loss: 0.002041   Batch Acc: 91.41
[Train] Epoch: 3 [387840/387873]    Loss: 0.001938   Batch Acc: 89.84
[Train] Epoch: 3 [100023/387873]    Loss: 0.004754   Batch Acc: 96.97
Validation Done: [128/84203]
Validation Done: [256/84203]
Validation Done: [384/84203]
Validation Done: [512/84203]
Validation Done: [640/84203]
Validation Done: [768/84203]
Validation Done: [896/84203]
Validation Done: [1024/84203]
Validation Done: [1152/84203]
Validation Done: [1280/84203]
Validation Done: [1408/84203]
Validation Done: [1536/84203]
Validation Done: [1664/84203]
Validation Done: [1792/84203]
Validation Done: [1920/84203]
Validation Done: [2048/84203]
Validation Done: [2176/84203]
Validation Done: [2304/84203]
Validation Done: [2432/84203]
Validation Done: [2560/84203]
Validation Done: [2688/84203]
Validation Done: [2816/84203]
Validation Done: [2944/84203]
Validation Done: [3072/84203]
Validation Done: [3200/84203]
Validation Done: [3328/84203]
Validation Done: [3456/84203]
Validation Done: [3584/84203]
Validation Done: [3712/84203]
Validation Done: [3840/84203]
Validation Done: [3968/84203]
Validation Done: [4096/84203]
Validation Done: [4224/84203]
Validation Done: [4352/84203]
Validation Done: [4480/84203]
Validation Done: [4608/84203]
Validation Done: [4736/84203]
Validation Done: [4864/84203]
Validation Done: [4992/84203]
Validation Done: [5120/84203]
Validation Done: [5248/84203]
Validation Done: [5376/84203]
Validation Done: [5504/84203]
Validation Done: [5632/84203]
Validation Done: [5760/84203]
Validation Done: [5888/84203]
Validation Done: [6016/84203]
Validation Done: [6144/84203]
Validation Done: [6272/84203]
Validation Done: [6400/84203]
Validation Done: [6528/84203]
Validation Done: [6656/84203]
Validation Done: [6784/84203]
Validation Done: [6912/84203]
Validation Done: [7040/84203]
Validation Done: [7168/84203]
Validation Done: [7296/84203]
Validation Done: [7424/84203]
Validation Done: [7552/84203]
Validation Done: [7680/84203]
Validation Done: [7808/84203]
Validation Done: [7936/84203]
Validation Done: [8064/84203]
Validation Done: [8192/84203]
Validation Done: [8320/84203]
Validation Done: [8448/84203]
Validation Done: [8576/84203]
Validation Done: [8704/84203]
Validation Done: [8832/84203]
Validation Done: [8960/84203]
Validation Done: [9088/84203]
Validation Done: [9216/84203]
Validation Done: [9344/84203]
Validation Done: [9472/84203]
Validation Done: [9600/84203]
Validation Done: [9728/84203]
Validation Done: [9856/84203]
Validation Done: [9984/84203]
Validation Done: [10112/84203]
Validation Done: [10240/84203]
Validation Done: [10368/84203]
Validation Done: [10496/84203]
Validation Done: [10624/84203]
Validation Done: [10752/84203]
Validation Done: [10880/84203]
Validation Done: [11008/84203]
Validation Done: [11136/84203]
Validation Done: [11264/84203]
Validation Done: [11392/84203]
Validation Done: [11520/84203]
Validation Done: [11648/84203]
Validation Done: [11776/84203]
Validation Done: [11904/84203]
Validation Done: [12032/84203]
Validation Done: [12160/84203]
Validation Done: [12288/84203]
Validation Done: [12416/84203]
Validation Done: [12544/84203]
Validation Done: [12672/84203]
Validation Done: [12800/84203]
Validation Done: [12928/84203]
Validation Done: [13056/84203]
Validation Done: [13184/84203]
Validation Done: [13312/84203]
Validation Done: [13440/84203]
Validation Done: [13568/84203]
Validation Done: [13696/84203]
Validation Done: [13824/84203]
Validation Done: [13952/84203]
Validation Done: [14080/84203]
Validation Done: [14208/84203]
Validation Done: [14336/84203]
Validation Done: [14464/84203]
Validation Done: [14592/84203]
Validation Done: [14720/84203]
Validation Done: [14848/84203]
Validation Done: [14976/84203]
Validation Done: [15104/84203]
Validation Done: [15232/84203]
Validation Done: [15360/84203]
Validation Done: [15488/84203]
Validation Done: [15616/84203]
Validation Done: [15744/84203]
Validation Done: [15872/84203]
Validation Done: [16000/84203]
Validation Done: [16128/84203]
Validation Done: [16256/84203]
Validation Done: [16384/84203]
Validation Done: [16512/84203]
Validation Done: [16640/84203]
Validation Done: [16768/84203]
Validation Done: [16896/84203]
Validation Done: [17024/84203]
Validation Done: [17152/84203]
Validation Done: [17280/84203]
Validation Done: [17408/84203]
Validation Done: [17536/84203]
Validation Done: [17664/84203]
Validation Done: [17792/84203]
Validation Done: [17920/84203]
Validation Done: [18048/84203]
Validation Done: [18176/84203]
Validation Done: [18304/84203]
Validation Done: [18432/84203]
Validation Done: [18560/84203]
Validation Done: [18688/84203]
Validation Done: [18816/84203]
Validation Done: [18944/84203]
Validation Done: [19072/84203]
Validation Done: [19200/84203]
Validation Done: [19328/84203]
Validation Done: [19456/84203]
Validation Done: [19584/84203]
Validation Done: [19712/84203]
Validation Done: [19840/84203]
Validation Done: [19968/84203]
Validation Done: [20096/84203]
Validation Done: [20224/84203]
Validation Done: [20352/84203]
Validation Done: [20480/84203]
Validation Done: [20608/84203]
Validation Done: [20736/84203]
Validation Done: [20864/84203]
Validation Done: [20992/84203]
Validation Done: [21120/84203]
Validation Done: [21248/84203]
Validation Done: [21376/84203]
Validation Done: [21504/84203]
Validation Done: [21632/84203]
Validation Done: [21760/84203]
Validation Done: [21888/84203]
Validation Done: [22016/84203]
Validation Done: [22144/84203]
Validation Done: [22272/84203]
Validation Done: [22400/84203]
Validation Done: [22528/84203]
Validation Done: [22656/84203]
Validation Done: [22784/84203]
Validation Done: [22912/84203]
Validation Done: [23040/84203]
Validation Done: [23168/84203]
Validation Done: [23296/84203]
Validation Done: [23424/84203]
Validation Done: [23552/84203]
Validation Done: [23680/84203]
Validation Done: [23808/84203]
Validation Done: [23936/84203]
Validation Done: [24064/84203]
Validation Done: [24192/84203]
Validation Done: [24320/84203]
Validation Done: [24448/84203]
Validation Done: [24576/84203]
Validation Done: [24704/84203]
Validation Done: [24832/84203]
Validation Done: [24960/84203]
Validation Done: [25088/84203]
Validation Done: [25216/84203]
Validation Done: [25344/84203]
Validation Done: [25472/84203]
Validation Done: [25600/84203]
Validation Done: [25728/84203]
Validation Done: [25856/84203]
Validation Done: [25984/84203]
Validation Done: [26112/84203]
Validation Done: [26240/84203]
Validation Done: [26368/84203]
Validation Done: [26496/84203]
Validation Done: [26624/84203]
Validation Done: [26752/84203]
Validation Done: [26880/84203]
Validation Done: [27008/84203]
Validation Done: [27136/84203]
Validation Done: [27264/84203]
Validation Done: [27392/84203]
Validation Done: [27520/84203]
Validation Done: [27648/84203]
Validation Done: [27776/84203]
Validation Done: [27904/84203]
Validation Done: [28032/84203]
Validation Done: [28160/84203]
Validation Done: [28288/84203]
Validation Done: [28416/84203]
Validation Done: [28544/84203]
Validation Done: [28672/84203]
Validation Done: [28800/84203]
Validation Done: [28928/84203]
Validation Done: [29056/84203]
Validation Done: [29184/84203]
Validation Done: [29312/84203]
Validation Done: [29440/84203]
Validation Done: [29568/84203]
Validation Done: [29696/84203]
Validation Done: [29824/84203]
Validation Done: [29952/84203]
Validation Done: [30080/84203]
Validation Done: [30208/84203]
Validation Done: [30336/84203]
Validation Done: [30464/84203]
Validation Done: [30592/84203]
Validation Done: [30720/84203]
Validation Done: [30848/84203]
Validation Done: [30976/84203]
Validation Done: [31104/84203]
Validation Done: [31232/84203]
Validation Done: [31360/84203]
Validation Done: [31488/84203]
Validation Done: [31616/84203]
Validation Done: [31744/84203]
Validation Done: [31872/84203]
Validation Done: [32000/84203]
Validation Done: [32128/84203]
Validation Done: [32256/84203]
Validation Done: [32384/84203]
Validation Done: [32512/84203]
Validation Done: [32640/84203]
Validation Done: [32768/84203]
Validation Done: [32896/84203]
Validation Done: [33024/84203]
Validation Done: [33152/84203]
Validation Done: [33280/84203]
Validation Done: [33408/84203]
Validation Done: [33536/84203]
Validation Done: [33664/84203]
Validation Done: [33792/84203]
Validation Done: [33920/84203]
Validation Done: [34048/84203]
Validation Done: [34176/84203]
Validation Done: [34304/84203]
Validation Done: [34432/84203]
Validation Done: [34560/84203]
Validation Done: [34688/84203]
Validation Done: [34816/84203]
Validation Done: [34944/84203]
Validation Done: [35072/84203]
Validation Done: [35200/84203]
Validation Done: [35328/84203]
Validation Done: [35456/84203]
Validation Done: [35584/84203]
Validation Done: [35712/84203]
Validation Done: [35840/84203]
Validation Done: [35968/84203]
Validation Done: [36096/84203]
Validation Done: [36224/84203]
Validation Done: [36352/84203]
Validation Done: [36480/84203]
Validation Done: [36608/84203]
Validation Done: [36736/84203]
Validation Done: [36864/84203]
Validation Done: [36992/84203]
Validation Done: [37120/84203]
Validation Done: [37248/84203]
Validation Done: [37376/84203]
Validation Done: [37504/84203]
Validation Done: [37632/84203]
Validation Done: [37760/84203]
Validation Done: [37888/84203]
Validation Done: [38016/84203]
Validation Done: [38144/84203]
Validation Done: [38272/84203]
Validation Done: [38400/84203]
Validation Done: [38528/84203]
Validation Done: [38656/84203]
Validation Done: [38784/84203]
Validation Done: [38912/84203]
Validation Done: [39040/84203]
Validation Done: [39168/84203]
Validation Done: [39296/84203]
Validation Done: [39424/84203]
Validation Done: [39552/84203]
Validation Done: [39680/84203]
Validation Done: [39808/84203]
Validation Done: [39936/84203]
Validation Done: [40064/84203]
Validation Done: [40192/84203]
Validation Done: [40320/84203]
Validation Done: [40448/84203]
Validation Done: [40576/84203]
Validation Done: [40704/84203]
Validation Done: [40832/84203]
Validation Done: [40960/84203]
Validation Done: [41088/84203]
Validation Done: [41216/84203]
Validation Done: [41344/84203]
Validation Done: [41472/84203]
Validation Done: [41600/84203]
Validation Done: [41728/84203]
Validation Done: [41856/84203]
Validation Done: [41984/84203]
Validation Done: [42112/84203]
Validation Done: [42240/84203]
Validation Done: [42368/84203]
Validation Done: [42496/84203]
Validation Done: [42624/84203]
Validation Done: [42752/84203]
Validation Done: [42880/84203]
Validation Done: [43008/84203]
Validation Done: [43136/84203]
Validation Done: [43264/84203]
Validation Done: [43392/84203]
Validation Done: [43520/84203]
Validation Done: [43648/84203]
Validation Done: [43776/84203]
Validation Done: [43904/84203]
Validation Done: [44032/84203]
Validation Done: [44160/84203]
Validation Done: [44288/84203]
Validation Done: [44416/84203]
Validation Done: [44544/84203]
Validation Done: [44672/84203]
Validation Done: [44800/84203]
Validation Done: [44928/84203]
Validation Done: [45056/84203]
Validation Done: [45184/84203]
Validation Done: [45312/84203]
Validation Done: [45440/84203]
Validation Done: [45568/84203]
Validation Done: [45696/84203]
Validation Done: [45824/84203]
Validation Done: [45952/84203]
Validation Done: [46080/84203]
Validation Done: [46208/84203]
Validation Done: [46336/84203]
Validation Done: [46464/84203]
Validation Done: [46592/84203]
Validation Done: [46720/84203]
Validation Done: [46848/84203]
Validation Done: [46976/84203]
Validation Done: [47104/84203]
Validation Done: [47232/84203]
Validation Done: [47360/84203]
Validation Done: [47488/84203]
Validation Done: [47616/84203]
Validation Done: [47744/84203]
Validation Done: [47872/84203]
Validation Done: [48000/84203]
Validation Done: [48128/84203]
Validation Done: [48256/84203]
Validation Done: [48384/84203]
Validation Done: [48512/84203]
Validation Done: [48640/84203]
Validation Done: [48768/84203]
Validation Done: [48896/84203]
Validation Done: [49024/84203]
Validation Done: [49152/84203]
Validation Done: [49280/84203]
Validation Done: [49408/84203]
Validation Done: [49536/84203]
Validation Done: [49664/84203]
Validation Done: [49792/84203]
Validation Done: [49920/84203]
Validation Done: [50048/84203]
Validation Done: [50176/84203]
Validation Done: [50304/84203]
Validation Done: [50432/84203]
Validation Done: [50560/84203]
Validation Done: [50688/84203]
Validation Done: [50816/84203]
Validation Done: [50944/84203]
Validation Done: [51072/84203]
Validation Done: [51200/84203]
Validation Done: [51328/84203]
Validation Done: [51456/84203]
Validation Done: [51584/84203]
Validation Done: [51712/84203]
Validation Done: [51840/84203]
Validation Done: [51968/84203]
Validation Done: [52096/84203]
Validation Done: [52224/84203]
Validation Done: [52352/84203]
Validation Done: [52480/84203]
Validation Done: [52608/84203]
Validation Done: [52736/84203]
Validation Done: [52864/84203]
Validation Done: [52992/84203]
Validation Done: [53120/84203]
Validation Done: [53248/84203]
Validation Done: [53376/84203]
Validation Done: [53504/84203]
Validation Done: [53632/84203]
Validation Done: [53760/84203]
Validation Done: [53888/84203]
Validation Done: [54016/84203]
Validation Done: [54144/84203]
Validation Done: [54272/84203]
Validation Done: [54400/84203]
Validation Done: [54528/84203]
Validation Done: [54656/84203]
Validation Done: [54784/84203]
Validation Done: [54912/84203]
Validation Done: [55040/84203]
Validation Done: [55168/84203]
Validation Done: [55296/84203]
Validation Done: [55424/84203]
Validation Done: [55552/84203]
Validation Done: [55680/84203]
Validation Done: [55808/84203]
Validation Done: [55936/84203]
Validation Done: [56064/84203]
Validation Done: [56192/84203]
Validation Done: [56320/84203]
Validation Done: [56448/84203]
Validation Done: [56576/84203]
Validation Done: [56704/84203]
Validation Done: [56832/84203]
Validation Done: [56960/84203]
Validation Done: [57088/84203]
Validation Done: [57216/84203]
Validation Done: [57344/84203]
Validation Done: [57472/84203]
Validation Done: [57600/84203]
Validation Done: [57728/84203]
Validation Done: [57856/84203]
Validation Done: [57984/84203]
Validation Done: [58112/84203]
Validation Done: [58240/84203]
Validation Done: [58368/84203]
Validation Done: [58496/84203]
Validation Done: [58624/84203]
Validation Done: [58752/84203]
Validation Done: [58880/84203]
Validation Done: [59008/84203]
Validation Done: [59136/84203]
Validation Done: [59264/84203]
Validation Done: [59392/84203]
Validation Done: [59520/84203]
Validation Done: [59648/84203]
Validation Done: [59776/84203]
Validation Done: [59904/84203]
Validation Done: [60032/84203]
Validation Done: [60160/84203]
Validation Done: [60288/84203]
Validation Done: [60416/84203]
Validation Done: [60544/84203]
Validation Done: [60672/84203]
Validation Done: [60800/84203]
Validation Done: [60928/84203]
Validation Done: [61056/84203]
Validation Done: [61184/84203]
Validation Done: [61312/84203]
Validation Done: [61440/84203]
Validation Done: [61568/84203]
Validation Done: [61696/84203]
Validation Done: [61824/84203]
Validation Done: [61952/84203]
Validation Done: [62080/84203]
Validation Done: [62208/84203]
Validation Done: [62336/84203]
Validation Done: [62464/84203]
Validation Done: [62592/84203]
Validation Done: [62720/84203]
Validation Done: [62848/84203]
Validation Done: [62976/84203]
Validation Done: [63104/84203]
Validation Done: [63232/84203]
Validation Done: [63360/84203]
Validation Done: [63488/84203]
Validation Done: [63616/84203]
Validation Done: [63744/84203]
Validation Done: [63872/84203]
Validation Done: [64000/84203]
Validation Done: [64128/84203]
Validation Done: [64256/84203]
Validation Done: [64384/84203]
Validation Done: [64512/84203]
Validation Done: [64640/84203]
Validation Done: [64768/84203]
Validation Done: [64896/84203]
Validation Done: [65024/84203]
Validation Done: [65152/84203]
Validation Done: [65280/84203]
Validation Done: [65408/84203]
Validation Done: [65536/84203]
Validation Done: [65664/84203]
Validation Done: [65792/84203]
Validation Done: [65920/84203]
Validation Done: [66048/84203]
Validation Done: [66176/84203]
Validation Done: [66304/84203]
Validation Done: [66432/84203]
Validation Done: [66560/84203]
Validation Done: [66688/84203]
Validation Done: [66816/84203]
Validation Done: [66944/84203]
Validation Done: [67072/84203]
Validation Done: [67200/84203]
Validation Done: [67328/84203]
Validation Done: [67456/84203]
Validation Done: [67584/84203]
Validation Done: [67712/84203]
Validation Done: [67840/84203]
Validation Done: [67968/84203]
Validation Done: [68096/84203]
Validation Done: [68224/84203]
Validation Done: [68352/84203]
Validation Done: [68480/84203]
Validation Done: [68608/84203]
Validation Done: [68736/84203]
Validation Done: [68864/84203]
Validation Done: [68992/84203]
Validation Done: [69120/84203]
Validation Done: [69248/84203]
Validation Done: [69376/84203]
Validation Done: [69504/84203]
Validation Done: [69632/84203]
Validation Done: [69760/84203]
Validation Done: [69888/84203]
Validation Done: [70016/84203]
Validation Done: [70144/84203]
Validation Done: [70272/84203]
Validation Done: [70400/84203]
Validation Done: [70528/84203]
Validation Done: [70656/84203]
Validation Done: [70784/84203]
Validation Done: [70912/84203]
Validation Done: [71040/84203]
Validation Done: [71168/84203]
Validation Done: [71296/84203]
Validation Done: [71424/84203]
Validation Done: [71552/84203]
Validation Done: [71680/84203]
Validation Done: [71808/84203]
Validation Done: [71936/84203]
Validation Done: [72064/84203]
Validation Done: [72192/84203]
Validation Done: [72320/84203]
Validation Done: [72448/84203]
Validation Done: [72576/84203]
Validation Done: [72704/84203]
Validation Done: [72832/84203]
Validation Done: [72960/84203]
Validation Done: [73088/84203]
Validation Done: [73216/84203]
Validation Done: [73344/84203]
Validation Done: [73472/84203]
Validation Done: [73600/84203]
Validation Done: [73728/84203]
Validation Done: [73856/84203]
Validation Done: [73984/84203]
Validation Done: [74112/84203]
Validation Done: [74240/84203]
Validation Done: [74368/84203]
Validation Done: [74496/84203]
Validation Done: [74624/84203]
Validation Done: [74752/84203]
Validation Done: [74880/84203]
Validation Done: [75008/84203]
Validation Done: [75136/84203]
Validation Done: [75264/84203]
Validation Done: [75392/84203]
Validation Done: [75520/84203]
Validation Done: [75648/84203]
Validation Done: [75776/84203]
Validation Done: [75904/84203]
Validation Done: [76032/84203]
Validation Done: [76160/84203]
Validation Done: [76288/84203]
Validation Done: [76416/84203]
Validation Done: [76544/84203]
Validation Done: [76672/84203]
Validation Done: [76800/84203]
Validation Done: [76928/84203]
Validation Done: [77056/84203]
Validation Done: [77184/84203]
Validation Done: [77312/84203]
Validation Done: [77440/84203]
Validation Done: [77568/84203]
Validation Done: [77696/84203]
Validation Done: [77824/84203]
Validation Done: [77952/84203]
Validation Done: [78080/84203]
Validation Done: [78208/84203]
Validation Done: [78336/84203]
Validation Done: [78464/84203]
Validation Done: [78592/84203]
Validation Done: [78720/84203]
Validation Done: [78848/84203]
Validation Done: [78976/84203]
Validation Done: [79104/84203]
Validation Done: [79232/84203]
Validation Done: [79360/84203]
Validation Done: [79488/84203]
Validation Done: [79616/84203]
Validation Done: [79744/84203]
Validation Done: [79872/84203]
Validation Done: [80000/84203]
Validation Done: [80128/84203]
Validation Done: [80256/84203]
Validation Done: [80384/84203]
Validation Done: [80512/84203]
Validation Done: [80640/84203]
Validation Done: [80768/84203]
Validation Done: [80896/84203]
Validation Done: [81024/84203]
Validation Done: [81152/84203]
Validation Done: [81280/84203]
Validation Done: [81408/84203]
Validation Done: [81536/84203]
Validation Done: [81664/84203]
Validation Done: [81792/84203]
Validation Done: [81920/84203]
Validation Done: [82048/84203]
Validation Done: [82176/84203]
Validation Done: [82304/84203]
Validation Done: [82432/84203]
Validation Done: [82560/84203]
Validation Done: [82688/84203]
Validation Done: [82816/84203]
Validation Done: [82944/84203]
Validation Done: [83072/84203]
Validation Done: [83200/84203]
Validation Done: [83328/84203]
Validation Done: [83456/84203]
Validation Done: [83584/84203]
Validation Done: [83712/84203]
Validation Done: [83840/84203]
Validation Done: [83968/84203]
Validation Done: [84096/84203]
Validation Done: [70406/84203]
[Test] Epoch: 3 Test set: Average loss: 0.0020, Accuracy: 75465/84203 (89.62%)
{'accuracy': 0.8962269752859162, 'normal': {'precision': 0.8633926576811378, 'recall': 0.8206171703588364, 'support': 28258, 'f1-score': 0.8414616445315335}, 'macro avg': {'precision': 0.8874989271490527, 'recall': 0.8775174510298069, 'support': 84203, 'f1-score': 0.8821660769219588}, 'cancer': {'precision': 0.9116051966169675, 'recall': 0.9344177317007776, 'support': 55945, 'f1-score': 0.9228705093123842}, 'weighted avg': {'precision': 0.8954253701826519, 'recall': 0.8962269752859162, 'support': 84203, 'f1-score': 0.8955502036109569}}
[Train] Epoch: 4 [128/387873]    Loss: 0.002087   Batch Acc: 89.06
[Train] Epoch: 4 [256/387873]    Loss: 0.002147   Batch Acc: 89.06
[Train] Epoch: 4 [384/387873]    Loss: 0.001656   Batch Acc: 90.62
[Train] Epoch: 4 [512/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 4 [640/387873]    Loss: 0.001618   Batch Acc: 92.97
[Train] Epoch: 4 [768/387873]    Loss: 0.001874   Batch Acc: 92.19
[Train] Epoch: 4 [896/387873]    Loss: 0.002364   Batch Acc: 85.16
[Train] Epoch: 4 [1024/387873]    Loss: 0.001396   Batch Acc: 93.75
[Train] Epoch: 4 [1152/387873]    Loss: 0.002457   Batch Acc: 84.38
[Train] Epoch: 4 [1280/387873]    Loss: 0.001720   Batch Acc: 92.19
[Train] Epoch: 4 [1408/387873]    Loss: 0.001717   Batch Acc: 93.75
[Train] Epoch: 4 [1536/387873]    Loss: 0.002084   Batch Acc: 86.72
[Train] Epoch: 4 [1664/387873]    Loss: 0.002100   Batch Acc: 87.50
[Train] Epoch: 4 [1792/387873]    Loss: 0.002142   Batch Acc: 90.62
[Train] Epoch: 4 [1920/387873]    Loss: 0.001967   Batch Acc: 88.28
[Train] Epoch: 4 [2048/387873]    Loss: 0.002168   Batch Acc: 87.50
[Train] Epoch: 4 [2176/387873]    Loss: 0.002064   Batch Acc: 90.62
[Train] Epoch: 4 [2304/387873]    Loss: 0.002426   Batch Acc: 84.38
[Train] Epoch: 4 [2432/387873]    Loss: 0.001936   Batch Acc: 91.41
[Train] Epoch: 4 [2560/387873]    Loss: 0.001902   Batch Acc: 89.84
[Train] Epoch: 4 [2688/387873]    Loss: 0.001920   Batch Acc: 89.84
[Train] Epoch: 4 [2816/387873]    Loss: 0.001649   Batch Acc: 95.31
[Train] Epoch: 4 [2944/387873]    Loss: 0.001778   Batch Acc: 89.84
[Train] Epoch: 4 [3072/387873]    Loss: 0.002053   Batch Acc: 89.06
[Train] Epoch: 4 [3200/387873]    Loss: 0.002302   Batch Acc: 85.94
[Train] Epoch: 4 [3328/387873]    Loss: 0.002274   Batch Acc: 87.50
[Train] Epoch: 4 [3456/387873]    Loss: 0.002359   Batch Acc: 87.50
[Train] Epoch: 4 [3584/387873]    Loss: 0.002869   Batch Acc: 82.81
[Train] Epoch: 4 [3712/387873]    Loss: 0.002189   Batch Acc: 85.16
[Train] Epoch: 4 [3840/387873]    Loss: 0.002978   Batch Acc: 82.81
[Train] Epoch: 4 [3968/387873]    Loss: 0.001894   Batch Acc: 92.19
[Train] Epoch: 4 [4096/387873]    Loss: 0.002055   Batch Acc: 85.94
[Train] Epoch: 4 [4224/387873]    Loss: 0.001789   Batch Acc: 92.19
[Train] Epoch: 4 [4352/387873]    Loss: 0.001803   Batch Acc: 90.62
[Train] Epoch: 4 [4480/387873]    Loss: 0.001309   Batch Acc: 95.31
[Train] Epoch: 4 [4608/387873]    Loss: 0.001871   Batch Acc: 91.41
[Train] Epoch: 4 [4736/387873]    Loss: 0.002191   Batch Acc: 87.50
[Train] Epoch: 4 [4864/387873]    Loss: 0.001694   Batch Acc: 92.97
[Train] Epoch: 4 [4992/387873]    Loss: 0.001807   Batch Acc: 89.06
[Train] Epoch: 4 [5120/387873]    Loss: 0.002366   Batch Acc: 86.72
[Train] Epoch: 4 [5248/387873]    Loss: 0.001862   Batch Acc: 89.84
[Train] Epoch: 4 [5376/387873]    Loss: 0.002046   Batch Acc: 87.50
[Train] Epoch: 4 [5504/387873]    Loss: 0.001807   Batch Acc: 92.19
[Train] Epoch: 4 [5632/387873]    Loss: 0.001952   Batch Acc: 90.62
[Train] Epoch: 4 [5760/387873]    Loss: 0.001763   Batch Acc: 92.19
[Train] Epoch: 4 [5888/387873]    Loss: 0.002088   Batch Acc: 89.06
[Train] Epoch: 4 [6016/387873]    Loss: 0.001757   Batch Acc: 90.62
[Train] Epoch: 4 [6144/387873]    Loss: 0.002314   Batch Acc: 88.28
[Train] Epoch: 4 [6272/387873]    Loss: 0.002002   Batch Acc: 92.97
[Train] Epoch: 4 [6400/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 4 [6528/387873]    Loss: 0.002224   Batch Acc: 87.50
[Train] Epoch: 4 [6656/387873]    Loss: 0.001856   Batch Acc: 89.84
[Train] Epoch: 4 [6784/387873]    Loss: 0.002464   Batch Acc: 88.28
[Train] Epoch: 4 [6912/387873]    Loss: 0.002390   Batch Acc: 85.94
[Train] Epoch: 4 [7040/387873]    Loss: 0.001805   Batch Acc: 90.62
[Train] Epoch: 4 [7168/387873]    Loss: 0.001985   Batch Acc: 88.28
[Train] Epoch: 4 [7296/387873]    Loss: 0.001736   Batch Acc: 92.97
[Train] Epoch: 4 [7424/387873]    Loss: 0.001681   Batch Acc: 88.28
[Train] Epoch: 4 [7552/387873]    Loss: 0.002155   Batch Acc: 87.50
[Train] Epoch: 4 [7680/387873]    Loss: 0.001846   Batch Acc: 89.06
[Train] Epoch: 4 [7808/387873]    Loss: 0.001923   Batch Acc: 89.06
[Train] Epoch: 4 [7936/387873]    Loss: 0.001626   Batch Acc: 92.97
[Train] Epoch: 4 [8064/387873]    Loss: 0.002323   Batch Acc: 85.16
[Train] Epoch: 4 [8192/387873]    Loss: 0.001668   Batch Acc: 92.97
[Train] Epoch: 4 [8320/387873]    Loss: 0.002148   Batch Acc: 87.50
[Train] Epoch: 4 [8448/387873]    Loss: 0.002521   Batch Acc: 86.72
[Train] Epoch: 4 [8576/387873]    Loss: 0.003022   Batch Acc: 82.81
[Train] Epoch: 4 [8704/387873]    Loss: 0.001925   Batch Acc: 88.28
[Train] Epoch: 4 [8832/387873]    Loss: 0.002142   Batch Acc: 84.38
[Train] Epoch: 4 [8960/387873]    Loss: 0.001706   Batch Acc: 89.84
[Train] Epoch: 4 [9088/387873]    Loss: 0.001354   Batch Acc: 93.75
[Train] Epoch: 4 [9216/387873]    Loss: 0.001514   Batch Acc: 90.62
[Train] Epoch: 4 [9344/387873]    Loss: 0.002049   Batch Acc: 87.50
[Train] Epoch: 4 [9472/387873]    Loss: 0.001972   Batch Acc: 89.06
[Train] Epoch: 4 [9600/387873]    Loss: 0.001921   Batch Acc: 89.84
[Train] Epoch: 4 [9728/387873]    Loss: 0.002328   Batch Acc: 88.28
[Train] Epoch: 4 [9856/387873]    Loss: 0.002228   Batch Acc: 85.94
[Train] Epoch: 4 [9984/387873]    Loss: 0.001663   Batch Acc: 92.97
[Train] Epoch: 4 [10112/387873]    Loss: 0.002109   Batch Acc: 89.06
[Train] Epoch: 4 [10240/387873]    Loss: 0.002316   Batch Acc: 86.72
[Train] Epoch: 4 [10368/387873]    Loss: 0.002329   Batch Acc: 85.94
[Train] Epoch: 4 [10496/387873]    Loss: 0.002131   Batch Acc: 85.16
[Train] Epoch: 4 [10624/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 4 [10752/387873]    Loss: 0.001177   Batch Acc: 93.75
[Train] Epoch: 4 [10880/387873]    Loss: 0.002303   Batch Acc: 89.84
[Train] Epoch: 4 [11008/387873]    Loss: 0.002262   Batch Acc: 85.94
[Train] Epoch: 4 [11136/387873]    Loss: 0.002224   Batch Acc: 88.28
[Train] Epoch: 4 [11264/387873]    Loss: 0.001820   Batch Acc: 92.19
[Train] Epoch: 4 [11392/387873]    Loss: 0.001628   Batch Acc: 92.19
[Train] Epoch: 4 [11520/387873]    Loss: 0.002350   Batch Acc: 85.94
[Train] Epoch: 4 [11648/387873]    Loss: 0.002060   Batch Acc: 89.84
[Train] Epoch: 4 [11776/387873]    Loss: 0.002191   Batch Acc: 86.72
[Train] Epoch: 4 [11904/387873]    Loss: 0.001921   Batch Acc: 90.62
[Train] Epoch: 4 [12032/387873]    Loss: 0.002029   Batch Acc: 91.41
[Train] Epoch: 4 [12160/387873]    Loss: 0.002671   Batch Acc: 85.16
[Train] Epoch: 4 [12288/387873]    Loss: 0.002020   Batch Acc: 90.62
[Train] Epoch: 4 [12416/387873]    Loss: 0.002165   Batch Acc: 88.28
[Train] Epoch: 4 [12544/387873]    Loss: 0.001819   Batch Acc: 92.19
[Train] Epoch: 4 [12672/387873]    Loss: 0.001873   Batch Acc: 91.41
[Train] Epoch: 4 [12800/387873]    Loss: 0.001716   Batch Acc: 90.62
[Train] Epoch: 4 [12928/387873]    Loss: 0.002633   Batch Acc: 85.94
[Train] Epoch: 4 [13056/387873]    Loss: 0.002347   Batch Acc: 84.38
[Train] Epoch: 4 [13184/387873]    Loss: 0.001926   Batch Acc: 91.41
[Train] Epoch: 4 [13312/387873]    Loss: 0.002354   Batch Acc: 86.72
[Train] Epoch: 4 [13440/387873]    Loss: 0.001726   Batch Acc: 92.97
[Train] Epoch: 4 [13568/387873]    Loss: 0.001579   Batch Acc: 92.97
[Train] Epoch: 4 [13696/387873]    Loss: 0.002496   Batch Acc: 85.16
[Train] Epoch: 4 [13824/387873]    Loss: 0.001676   Batch Acc: 92.97
[Train] Epoch: 4 [13952/387873]    Loss: 0.002183   Batch Acc: 88.28
[Train] Epoch: 4 [14080/387873]    Loss: 0.002200   Batch Acc: 85.16
[Train] Epoch: 4 [14208/387873]    Loss: 0.002040   Batch Acc: 89.84
[Train] Epoch: 4 [14336/387873]    Loss: 0.001752   Batch Acc: 89.06
[Train] Epoch: 4 [14464/387873]    Loss: 0.001849   Batch Acc: 92.19
[Train] Epoch: 4 [14592/387873]    Loss: 0.002196   Batch Acc: 89.84
[Train] Epoch: 4 [14720/387873]    Loss: 0.002218   Batch Acc: 88.28
[Train] Epoch: 4 [14848/387873]    Loss: 0.001677   Batch Acc: 91.41
[Train] Epoch: 4 [14976/387873]    Loss: 0.001953   Batch Acc: 88.28
[Train] Epoch: 4 [15104/387873]    Loss: 0.002312   Batch Acc: 87.50
[Train] Epoch: 4 [15232/387873]    Loss: 0.002273   Batch Acc: 86.72
[Train] Epoch: 4 [15360/387873]    Loss: 0.001964   Batch Acc: 90.62
[Train] Epoch: 4 [15488/387873]    Loss: 0.001928   Batch Acc: 89.06
[Train] Epoch: 4 [15616/387873]    Loss: 0.001661   Batch Acc: 92.19
[Train] Epoch: 4 [15744/387873]    Loss: 0.002149   Batch Acc: 90.62
[Train] Epoch: 4 [15872/387873]    Loss: 0.001782   Batch Acc: 92.97
[Train] Epoch: 4 [16000/387873]    Loss: 0.002140   Batch Acc: 89.06
[Train] Epoch: 4 [16128/387873]    Loss: 0.001684   Batch Acc: 93.75
[Train] Epoch: 4 [16256/387873]    Loss: 0.002014   Batch Acc: 93.75
[Train] Epoch: 4 [16384/387873]    Loss: 0.002031   Batch Acc: 89.84
[Train] Epoch: 4 [16512/387873]    Loss: 0.001884   Batch Acc: 89.06
[Train] Epoch: 4 [16640/387873]    Loss: 0.002024   Batch Acc: 88.28
[Train] Epoch: 4 [16768/387873]    Loss: 0.001994   Batch Acc: 89.06
[Train] Epoch: 4 [16896/387873]    Loss: 0.001734   Batch Acc: 92.97
[Train] Epoch: 4 [17024/387873]    Loss: 0.002090   Batch Acc: 89.84
[Train] Epoch: 4 [17152/387873]    Loss: 0.002162   Batch Acc: 85.94
[Train] Epoch: 4 [17280/387873]    Loss: 0.001691   Batch Acc: 90.62
[Train] Epoch: 4 [17408/387873]    Loss: 0.002088   Batch Acc: 89.06
[Train] Epoch: 4 [17536/387873]    Loss: 0.002316   Batch Acc: 84.38
[Train] Epoch: 4 [17664/387873]    Loss: 0.002413   Batch Acc: 85.94
[Train] Epoch: 4 [17792/387873]    Loss: 0.001998   Batch Acc: 89.06
[Train] Epoch: 4 [17920/387873]    Loss: 0.002361   Batch Acc: 89.84
[Train] Epoch: 4 [18048/387873]    Loss: 0.002073   Batch Acc: 87.50
[Train] Epoch: 4 [18176/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 4 [18304/387873]    Loss: 0.001610   Batch Acc: 92.19
[Train] Epoch: 4 [18432/387873]    Loss: 0.001679   Batch Acc: 92.19
[Train] Epoch: 4 [18560/387873]    Loss: 0.001701   Batch Acc: 90.62
[Train] Epoch: 4 [18688/387873]    Loss: 0.001616   Batch Acc: 92.19
[Train] Epoch: 4 [18816/387873]    Loss: 0.002535   Batch Acc: 88.28
[Train] Epoch: 4 [18944/387873]    Loss: 0.001938   Batch Acc: 90.62
[Train] Epoch: 4 [19072/387873]    Loss: 0.001680   Batch Acc: 92.19
[Train] Epoch: 4 [19200/387873]    Loss: 0.001791   Batch Acc: 87.50
[Train] Epoch: 4 [19328/387873]    Loss: 0.001857   Batch Acc: 87.50
[Train] Epoch: 4 [19456/387873]    Loss: 0.002489   Batch Acc: 87.50
[Train] Epoch: 4 [19584/387873]    Loss: 0.002498   Batch Acc: 85.16
[Train] Epoch: 4 [19712/387873]    Loss: 0.002093   Batch Acc: 87.50
[Train] Epoch: 4 [19840/387873]    Loss: 0.002000   Batch Acc: 92.19
[Train] Epoch: 4 [19968/387873]    Loss: 0.002546   Batch Acc: 88.28
[Train] Epoch: 4 [20096/387873]    Loss: 0.002171   Batch Acc: 85.94
[Train] Epoch: 4 [20224/387873]    Loss: 0.001510   Batch Acc: 92.97
[Train] Epoch: 4 [20352/387873]    Loss: 0.001799   Batch Acc: 89.84
[Train] Epoch: 4 [20480/387873]    Loss: 0.001851   Batch Acc: 92.19
[Train] Epoch: 4 [20608/387873]    Loss: 0.001586   Batch Acc: 92.19
[Train] Epoch: 4 [20736/387873]    Loss: 0.002232   Batch Acc: 86.72
[Train] Epoch: 4 [20864/387873]    Loss: 0.001811   Batch Acc: 90.62
[Train] Epoch: 4 [20992/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 4 [21120/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 4 [21248/387873]    Loss: 0.002233   Batch Acc: 88.28
[Train] Epoch: 4 [21376/387873]    Loss: 0.002108   Batch Acc: 88.28
[Train] Epoch: 4 [21504/387873]    Loss: 0.002222   Batch Acc: 88.28
[Train] Epoch: 4 [21632/387873]    Loss: 0.002203   Batch Acc: 89.06
[Train] Epoch: 4 [21760/387873]    Loss: 0.001760   Batch Acc: 94.53
[Train] Epoch: 4 [21888/387873]    Loss: 0.002124   Batch Acc: 89.06
[Train] Epoch: 4 [22016/387873]    Loss: 0.001847   Batch Acc: 91.41
[Train] Epoch: 4 [22144/387873]    Loss: 0.002131   Batch Acc: 88.28
[Train] Epoch: 4 [22272/387873]    Loss: 0.002689   Batch Acc: 83.59
[Train] Epoch: 4 [22400/387873]    Loss: 0.001259   Batch Acc: 93.75
[Train] Epoch: 4 [22528/387873]    Loss: 0.003066   Batch Acc: 81.25
[Train] Epoch: 4 [22656/387873]    Loss: 0.002216   Batch Acc: 90.62
[Train] Epoch: 4 [22784/387873]    Loss: 0.001956   Batch Acc: 87.50
[Train] Epoch: 4 [22912/387873]    Loss: 0.001755   Batch Acc: 90.62
[Train] Epoch: 4 [23040/387873]    Loss: 0.002369   Batch Acc: 85.16
[Train] Epoch: 4 [23168/387873]    Loss: 0.002257   Batch Acc: 86.72
[Train] Epoch: 4 [23296/387873]    Loss: 0.001570   Batch Acc: 89.84
[Train] Epoch: 4 [23424/387873]    Loss: 0.002485   Batch Acc: 88.28
[Train] Epoch: 4 [23552/387873]    Loss: 0.002157   Batch Acc: 90.62
[Train] Epoch: 4 [23680/387873]    Loss: 0.002052   Batch Acc: 90.62
[Train] Epoch: 4 [23808/387873]    Loss: 0.001751   Batch Acc: 89.84
[Train] Epoch: 4 [23936/387873]    Loss: 0.001927   Batch Acc: 91.41
[Train] Epoch: 4 [24064/387873]    Loss: 0.002828   Batch Acc: 86.72
[Train] Epoch: 4 [24192/387873]    Loss: 0.001655   Batch Acc: 93.75
[Train] Epoch: 4 [24320/387873]    Loss: 0.002130   Batch Acc: 85.16
[Train] Epoch: 4 [24448/387873]    Loss: 0.001958   Batch Acc: 92.97
[Train] Epoch: 4 [24576/387873]    Loss: 0.001666   Batch Acc: 89.06
[Train] Epoch: 4 [24704/387873]    Loss: 0.001897   Batch Acc: 89.06
[Train] Epoch: 4 [24832/387873]    Loss: 0.002360   Batch Acc: 89.06
[Train] Epoch: 4 [24960/387873]    Loss: 0.001330   Batch Acc: 95.31
[Train] Epoch: 4 [25088/387873]    Loss: 0.002154   Batch Acc: 87.50
[Train] Epoch: 4 [25216/387873]    Loss: 0.002339   Batch Acc: 85.16
[Train] Epoch: 4 [25344/387873]    Loss: 0.001697   Batch Acc: 92.97
[Train] Epoch: 4 [25472/387873]    Loss: 0.001620   Batch Acc: 92.19
[Train] Epoch: 4 [25600/387873]    Loss: 0.001869   Batch Acc: 90.62
[Train] Epoch: 4 [25728/387873]    Loss: 0.001958   Batch Acc: 89.06
[Train] Epoch: 4 [25856/387873]    Loss: 0.002312   Batch Acc: 85.94
[Train] Epoch: 4 [25984/387873]    Loss: 0.001795   Batch Acc: 91.41
[Train] Epoch: 4 [26112/387873]    Loss: 0.002133   Batch Acc: 89.06
[Train] Epoch: 4 [26240/387873]    Loss: 0.002387   Batch Acc: 87.50
[Train] Epoch: 4 [26368/387873]    Loss: 0.001887   Batch Acc: 89.84
[Train] Epoch: 4 [26496/387873]    Loss: 0.001768   Batch Acc: 90.62
[Train] Epoch: 4 [26624/387873]    Loss: 0.002439   Batch Acc: 87.50
[Train] Epoch: 4 [26752/387873]    Loss: 0.002134   Batch Acc: 86.72
[Train] Epoch: 4 [26880/387873]    Loss: 0.002132   Batch Acc: 89.06
[Train] Epoch: 4 [27008/387873]    Loss: 0.001895   Batch Acc: 88.28
[Train] Epoch: 4 [27136/387873]    Loss: 0.002387   Batch Acc: 85.94
[Train] Epoch: 4 [27264/387873]    Loss: 0.002037   Batch Acc: 89.06
[Train] Epoch: 4 [27392/387873]    Loss: 0.002333   Batch Acc: 86.72
[Train] Epoch: 4 [27520/387873]    Loss: 0.001625   Batch Acc: 94.53
[Train] Epoch: 4 [27648/387873]    Loss: 0.002064   Batch Acc: 87.50
[Train] Epoch: 4 [27776/387873]    Loss: 0.001756   Batch Acc: 91.41
[Train] Epoch: 4 [27904/387873]    Loss: 0.002291   Batch Acc: 86.72
[Train] Epoch: 4 [28032/387873]    Loss: 0.001881   Batch Acc: 89.06
[Train] Epoch: 4 [28160/387873]    Loss: 0.001772   Batch Acc: 92.19
[Train] Epoch: 4 [28288/387873]    Loss: 0.002105   Batch Acc: 85.16
[Train] Epoch: 4 [28416/387873]    Loss: 0.001711   Batch Acc: 92.19
[Train] Epoch: 4 [28544/387873]    Loss: 0.002172   Batch Acc: 85.16
[Train] Epoch: 4 [28672/387873]    Loss: 0.001739   Batch Acc: 92.97
[Train] Epoch: 4 [28800/387873]    Loss: 0.002142   Batch Acc: 88.28
[Train] Epoch: 4 [28928/387873]    Loss: 0.001406   Batch Acc: 91.41
[Train] Epoch: 4 [29056/387873]    Loss: 0.002108   Batch Acc: 87.50
[Train] Epoch: 4 [29184/387873]    Loss: 0.002436   Batch Acc: 87.50
[Train] Epoch: 4 [29312/387873]    Loss: 0.001669   Batch Acc: 89.84
[Train] Epoch: 4 [29440/387873]    Loss: 0.002150   Batch Acc: 89.84
[Train] Epoch: 4 [29568/387873]    Loss: 0.001850   Batch Acc: 86.72
[Train] Epoch: 4 [29696/387873]    Loss: 0.001635   Batch Acc: 92.97
[Train] Epoch: 4 [29824/387873]    Loss: 0.001806   Batch Acc: 88.28
[Train] Epoch: 4 [29952/387873]    Loss: 0.002091   Batch Acc: 87.50
[Train] Epoch: 4 [30080/387873]    Loss: 0.002015   Batch Acc: 88.28
[Train] Epoch: 4 [30208/387873]    Loss: 0.001955   Batch Acc: 90.62
[Train] Epoch: 4 [30336/387873]    Loss: 0.002127   Batch Acc: 86.72
[Train] Epoch: 4 [30464/387873]    Loss: 0.001665   Batch Acc: 90.62
[Train] Epoch: 4 [30592/387873]    Loss: 0.001722   Batch Acc: 90.62
[Train] Epoch: 4 [30720/387873]    Loss: 0.002292   Batch Acc: 89.06
[Train] Epoch: 4 [30848/387873]    Loss: 0.001755   Batch Acc: 93.75
[Train] Epoch: 4 [30976/387873]    Loss: 0.001764   Batch Acc: 92.19
[Train] Epoch: 4 [31104/387873]    Loss: 0.001753   Batch Acc: 90.62
[Train] Epoch: 4 [31232/387873]    Loss: 0.001738   Batch Acc: 91.41
[Train] Epoch: 4 [31360/387873]    Loss: 0.001961   Batch Acc: 88.28
[Train] Epoch: 4 [31488/387873]    Loss: 0.001429   Batch Acc: 94.53
[Train] Epoch: 4 [31616/387873]    Loss: 0.002028   Batch Acc: 88.28
[Train] Epoch: 4 [31744/387873]    Loss: 0.002557   Batch Acc: 85.94
[Train] Epoch: 4 [31872/387873]    Loss: 0.001972   Batch Acc: 89.06
[Train] Epoch: 4 [32000/387873]    Loss: 0.001829   Batch Acc: 92.19
[Train] Epoch: 4 [32128/387873]    Loss: 0.001689   Batch Acc: 93.75
[Train] Epoch: 4 [32256/387873]    Loss: 0.002227   Batch Acc: 83.59
[Train] Epoch: 4 [32384/387873]    Loss: 0.001281   Batch Acc: 97.66
[Train] Epoch: 4 [32512/387873]    Loss: 0.002602   Batch Acc: 85.94
[Train] Epoch: 4 [32640/387873]    Loss: 0.001708   Batch Acc: 91.41
[Train] Epoch: 4 [32768/387873]    Loss: 0.001748   Batch Acc: 91.41
[Train] Epoch: 4 [32896/387873]    Loss: 0.001875   Batch Acc: 89.84
[Train] Epoch: 4 [33024/387873]    Loss: 0.001809   Batch Acc: 92.97
[Train] Epoch: 4 [33152/387873]    Loss: 0.001726   Batch Acc: 90.62
[Train] Epoch: 4 [33280/387873]    Loss: 0.001251   Batch Acc: 94.53
[Train] Epoch: 4 [33408/387873]    Loss: 0.002411   Batch Acc: 86.72
[Train] Epoch: 4 [33536/387873]    Loss: 0.001998   Batch Acc: 92.19
[Train] Epoch: 4 [33664/387873]    Loss: 0.002469   Batch Acc: 85.94
[Train] Epoch: 4 [33792/387873]    Loss: 0.001912   Batch Acc: 93.75
[Train] Epoch: 4 [33920/387873]    Loss: 0.002003   Batch Acc: 86.72
[Train] Epoch: 4 [34048/387873]    Loss: 0.001668   Batch Acc: 93.75
[Train] Epoch: 4 [34176/387873]    Loss: 0.002049   Batch Acc: 89.06
[Train] Epoch: 4 [34304/387873]    Loss: 0.001617   Batch Acc: 92.97
[Train] Epoch: 4 [34432/387873]    Loss: 0.001611   Batch Acc: 89.84
[Train] Epoch: 4 [34560/387873]    Loss: 0.002001   Batch Acc: 89.84
[Train] Epoch: 4 [34688/387873]    Loss: 0.001507   Batch Acc: 94.53
[Train] Epoch: 4 [34816/387873]    Loss: 0.001964   Batch Acc: 89.06
[Train] Epoch: 4 [34944/387873]    Loss: 0.001856   Batch Acc: 92.97
[Train] Epoch: 4 [35072/387873]    Loss: 0.002219   Batch Acc: 89.06
[Train] Epoch: 4 [35200/387873]    Loss: 0.002695   Batch Acc: 89.06
[Train] Epoch: 4 [35328/387873]    Loss: 0.001895   Batch Acc: 91.41
[Train] Epoch: 4 [35456/387873]    Loss: 0.001800   Batch Acc: 91.41
[Train] Epoch: 4 [35584/387873]    Loss: 0.001926   Batch Acc: 89.84
[Train] Epoch: 4 [35712/387873]    Loss: 0.002304   Batch Acc: 89.84
[Train] Epoch: 4 [35840/387873]    Loss: 0.001726   Batch Acc: 92.97
[Train] Epoch: 4 [35968/387873]    Loss: 0.002045   Batch Acc: 90.62
[Train] Epoch: 4 [36096/387873]    Loss: 0.002016   Batch Acc: 89.06
[Train] Epoch: 4 [36224/387873]    Loss: 0.001885   Batch Acc: 89.06
[Train] Epoch: 4 [36352/387873]    Loss: 0.001886   Batch Acc: 92.19
[Train] Epoch: 4 [36480/387873]    Loss: 0.002289   Batch Acc: 88.28
[Train] Epoch: 4 [36608/387873]    Loss: 0.001735   Batch Acc: 91.41
[Train] Epoch: 4 [36736/387873]    Loss: 0.002194   Batch Acc: 85.94
[Train] Epoch: 4 [36864/387873]    Loss: 0.001426   Batch Acc: 94.53
[Train] Epoch: 4 [36992/387873]    Loss: 0.001874   Batch Acc: 87.50
[Train] Epoch: 4 [37120/387873]    Loss: 0.001925   Batch Acc: 89.06
[Train] Epoch: 4 [37248/387873]    Loss: 0.001788   Batch Acc: 90.62
[Train] Epoch: 4 [37376/387873]    Loss: 0.001630   Batch Acc: 90.62
[Train] Epoch: 4 [37504/387873]    Loss: 0.002273   Batch Acc: 85.16
[Train] Epoch: 4 [37632/387873]    Loss: 0.001775   Batch Acc: 90.62
[Train] Epoch: 4 [37760/387873]    Loss: 0.002349   Batch Acc: 85.16
[Train] Epoch: 4 [37888/387873]    Loss: 0.001982   Batch Acc: 90.62
[Train] Epoch: 4 [38016/387873]    Loss: 0.002474   Batch Acc: 90.62
[Train] Epoch: 4 [38144/387873]    Loss: 0.001863   Batch Acc: 90.62
[Train] Epoch: 4 [38272/387873]    Loss: 0.002257   Batch Acc: 87.50
[Train] Epoch: 4 [38400/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 4 [38528/387873]    Loss: 0.001787   Batch Acc: 92.97
[Train] Epoch: 4 [38656/387873]    Loss: 0.001799   Batch Acc: 90.62
[Train] Epoch: 4 [38784/387873]    Loss: 0.001634   Batch Acc: 93.75
[Train] Epoch: 4 [38912/387873]    Loss: 0.002153   Batch Acc: 89.84
[Train] Epoch: 4 [39040/387873]    Loss: 0.002105   Batch Acc: 89.06
[Train] Epoch: 4 [39168/387873]    Loss: 0.002453   Batch Acc: 87.50
[Train] Epoch: 4 [39296/387873]    Loss: 0.002161   Batch Acc: 89.06
[Train] Epoch: 4 [39424/387873]    Loss: 0.001655   Batch Acc: 90.62
[Train] Epoch: 4 [39552/387873]    Loss: 0.002401   Batch Acc: 89.06
[Train] Epoch: 4 [39680/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 4 [39808/387873]    Loss: 0.002179   Batch Acc: 89.06
[Train] Epoch: 4 [39936/387873]    Loss: 0.002168   Batch Acc: 91.41
[Train] Epoch: 4 [40064/387873]    Loss: 0.001538   Batch Acc: 90.62
[Train] Epoch: 4 [40192/387873]    Loss: 0.001710   Batch Acc: 93.75
[Train] Epoch: 4 [40320/387873]    Loss: 0.001576   Batch Acc: 94.53
[Train] Epoch: 4 [40448/387873]    Loss: 0.002072   Batch Acc: 89.06
[Train] Epoch: 4 [40576/387873]    Loss: 0.002000   Batch Acc: 88.28
[Train] Epoch: 4 [40704/387873]    Loss: 0.001739   Batch Acc: 88.28
[Train] Epoch: 4 [40832/387873]    Loss: 0.001772   Batch Acc: 91.41
[Train] Epoch: 4 [40960/387873]    Loss: 0.001629   Batch Acc: 92.19
[Train] Epoch: 4 [41088/387873]    Loss: 0.001898   Batch Acc: 91.41
[Train] Epoch: 4 [41216/387873]    Loss: 0.001817   Batch Acc: 90.62
[Train] Epoch: 4 [41344/387873]    Loss: 0.001762   Batch Acc: 92.97
[Train] Epoch: 4 [41472/387873]    Loss: 0.001350   Batch Acc: 94.53
[Train] Epoch: 4 [41600/387873]    Loss: 0.002123   Batch Acc: 86.72
[Train] Epoch: 4 [41728/387873]    Loss: 0.002000   Batch Acc: 88.28
[Train] Epoch: 4 [41856/387873]    Loss: 0.002064   Batch Acc: 91.41
[Train] Epoch: 4 [41984/387873]    Loss: 0.001925   Batch Acc: 89.06
[Train] Epoch: 4 [42112/387873]    Loss: 0.001995   Batch Acc: 92.19
[Train] Epoch: 4 [42240/387873]    Loss: 0.001792   Batch Acc: 89.06
[Train] Epoch: 4 [42368/387873]    Loss: 0.001619   Batch Acc: 93.75
[Train] Epoch: 4 [42496/387873]    Loss: 0.001473   Batch Acc: 95.31
[Train] Epoch: 4 [42624/387873]    Loss: 0.001687   Batch Acc: 91.41
[Train] Epoch: 4 [42752/387873]    Loss: 0.002437   Batch Acc: 86.72
[Train] Epoch: 4 [42880/387873]    Loss: 0.001720   Batch Acc: 92.19
[Train] Epoch: 4 [43008/387873]    Loss: 0.002154   Batch Acc: 89.84
[Train] Epoch: 4 [43136/387873]    Loss: 0.001812   Batch Acc: 90.62
[Train] Epoch: 4 [43264/387873]    Loss: 0.001510   Batch Acc: 92.19
[Train] Epoch: 4 [43392/387873]    Loss: 0.002583   Batch Acc: 89.06
[Train] Epoch: 4 [43520/387873]    Loss: 0.001628   Batch Acc: 93.75
[Train] Epoch: 4 [43648/387873]    Loss: 0.002181   Batch Acc: 90.62
[Train] Epoch: 4 [43776/387873]    Loss: 0.001819   Batch Acc: 89.84
[Train] Epoch: 4 [43904/387873]    Loss: 0.002086   Batch Acc: 89.84
[Train] Epoch: 4 [44032/387873]    Loss: 0.001925   Batch Acc: 89.06
[Train] Epoch: 4 [44160/387873]    Loss: 0.002189   Batch Acc: 90.62
[Train] Epoch: 4 [44288/387873]    Loss: 0.001699   Batch Acc: 89.84
[Train] Epoch: 4 [44416/387873]    Loss: 0.001559   Batch Acc: 93.75
[Train] Epoch: 4 [44544/387873]    Loss: 0.001737   Batch Acc: 92.97
[Train] Epoch: 4 [44672/387873]    Loss: 0.001614   Batch Acc: 92.97
[Train] Epoch: 4 [44800/387873]    Loss: 0.002077   Batch Acc: 88.28
[Train] Epoch: 4 [44928/387873]    Loss: 0.002459   Batch Acc: 85.16
[Train] Epoch: 4 [45056/387873]    Loss: 0.001665   Batch Acc: 91.41
[Train] Epoch: 4 [45184/387873]    Loss: 0.002820   Batch Acc: 83.59
[Train] Epoch: 4 [45312/387873]    Loss: 0.002598   Batch Acc: 84.38
[Train] Epoch: 4 [45440/387873]    Loss: 0.002102   Batch Acc: 88.28
[Train] Epoch: 4 [45568/387873]    Loss: 0.002053   Batch Acc: 91.41
[Train] Epoch: 4 [45696/387873]    Loss: 0.002466   Batch Acc: 85.16
[Train] Epoch: 4 [45824/387873]    Loss: 0.001778   Batch Acc: 90.62
[Train] Epoch: 4 [45952/387873]    Loss: 0.001801   Batch Acc: 91.41
[Train] Epoch: 4 [46080/387873]    Loss: 0.002160   Batch Acc: 89.06
[Train] Epoch: 4 [46208/387873]    Loss: 0.002582   Batch Acc: 87.50
[Train] Epoch: 4 [46336/387873]    Loss: 0.001578   Batch Acc: 93.75
[Train] Epoch: 4 [46464/387873]    Loss: 0.002163   Batch Acc: 87.50
[Train] Epoch: 4 [46592/387873]    Loss: 0.001488   Batch Acc: 92.97
[Train] Epoch: 4 [46720/387873]    Loss: 0.001738   Batch Acc: 92.19
[Train] Epoch: 4 [46848/387873]    Loss: 0.001690   Batch Acc: 90.62
[Train] Epoch: 4 [46976/387873]    Loss: 0.002134   Batch Acc: 86.72
[Train] Epoch: 4 [47104/387873]    Loss: 0.002108   Batch Acc: 91.41
[Train] Epoch: 4 [47232/387873]    Loss: 0.001942   Batch Acc: 90.62
[Train] Epoch: 4 [47360/387873]    Loss: 0.001886   Batch Acc: 88.28
[Train] Epoch: 4 [47488/387873]    Loss: 0.002155   Batch Acc: 89.84
[Train] Epoch: 4 [47616/387873]    Loss: 0.002157   Batch Acc: 90.62
[Train] Epoch: 4 [47744/387873]    Loss: 0.001699   Batch Acc: 89.84
[Train] Epoch: 4 [47872/387873]    Loss: 0.001510   Batch Acc: 94.53
[Train] Epoch: 4 [48000/387873]    Loss: 0.001463   Batch Acc: 95.31
[Train] Epoch: 4 [48128/387873]    Loss: 0.001892   Batch Acc: 89.06
[Train] Epoch: 4 [48256/387873]    Loss: 0.001764   Batch Acc: 92.19
[Train] Epoch: 4 [48384/387873]    Loss: 0.002325   Batch Acc: 85.94
[Train] Epoch: 4 [48512/387873]    Loss: 0.002109   Batch Acc: 87.50
[Train] Epoch: 4 [48640/387873]    Loss: 0.002337   Batch Acc: 86.72
[Train] Epoch: 4 [48768/387873]    Loss: 0.001470   Batch Acc: 93.75
[Train] Epoch: 4 [48896/387873]    Loss: 0.002342   Batch Acc: 89.06
[Train] Epoch: 4 [49024/387873]    Loss: 0.001239   Batch Acc: 96.88
[Train] Epoch: 4 [49152/387873]    Loss: 0.002133   Batch Acc: 85.94
[Train] Epoch: 4 [49280/387873]    Loss: 0.002237   Batch Acc: 88.28
[Train] Epoch: 4 [49408/387873]    Loss: 0.002353   Batch Acc: 88.28
[Train] Epoch: 4 [49536/387873]    Loss: 0.001452   Batch Acc: 92.19
[Train] Epoch: 4 [49664/387873]    Loss: 0.002078   Batch Acc: 89.06
[Train] Epoch: 4 [49792/387873]    Loss: 0.002319   Batch Acc: 88.28
[Train] Epoch: 4 [49920/387873]    Loss: 0.002412   Batch Acc: 87.50
[Train] Epoch: 4 [50048/387873]    Loss: 0.001933   Batch Acc: 86.72
[Train] Epoch: 4 [50176/387873]    Loss: 0.001498   Batch Acc: 93.75
[Train] Epoch: 4 [50304/387873]    Loss: 0.002477   Batch Acc: 89.06
[Train] Epoch: 4 [50432/387873]    Loss: 0.001725   Batch Acc: 92.97
[Train] Epoch: 4 [50560/387873]    Loss: 0.001890   Batch Acc: 89.84
[Train] Epoch: 4 [50688/387873]    Loss: 0.001970   Batch Acc: 85.16
[Train] Epoch: 4 [50816/387873]    Loss: 0.001650   Batch Acc: 92.19
[Train] Epoch: 4 [50944/387873]    Loss: 0.002408   Batch Acc: 87.50
[Train] Epoch: 4 [51072/387873]    Loss: 0.002251   Batch Acc: 87.50
[Train] Epoch: 4 [51200/387873]    Loss: 0.001960   Batch Acc: 89.84
[Train] Epoch: 4 [51328/387873]    Loss: 0.001578   Batch Acc: 92.97
[Train] Epoch: 4 [51456/387873]    Loss: 0.001945   Batch Acc: 92.19
[Train] Epoch: 4 [51584/387873]    Loss: 0.002020   Batch Acc: 90.62
[Train] Epoch: 4 [51712/387873]    Loss: 0.001973   Batch Acc: 89.84
[Train] Epoch: 4 [51840/387873]    Loss: 0.002023   Batch Acc: 90.62
[Train] Epoch: 4 [51968/387873]    Loss: 0.002557   Batch Acc: 82.81
[Train] Epoch: 4 [52096/387873]    Loss: 0.002598   Batch Acc: 87.50
[Train] Epoch: 4 [52224/387873]    Loss: 0.002337   Batch Acc: 87.50
[Train] Epoch: 4 [52352/387873]    Loss: 0.001686   Batch Acc: 93.75
[Train] Epoch: 4 [52480/387873]    Loss: 0.002505   Batch Acc: 85.94
[Train] Epoch: 4 [52608/387873]    Loss: 0.001713   Batch Acc: 89.84
[Train] Epoch: 4 [52736/387873]    Loss: 0.002291   Batch Acc: 85.94
[Train] Epoch: 4 [52864/387873]    Loss: 0.001671   Batch Acc: 91.41
[Train] Epoch: 4 [52992/387873]    Loss: 0.001945   Batch Acc: 89.84
[Train] Epoch: 4 [53120/387873]    Loss: 0.002164   Batch Acc: 85.94
[Train] Epoch: 4 [53248/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 4 [53376/387873]    Loss: 0.001712   Batch Acc: 88.28
[Train] Epoch: 4 [53504/387873]    Loss: 0.001685   Batch Acc: 92.19
[Train] Epoch: 4 [53632/387873]    Loss: 0.002213   Batch Acc: 85.16
[Train] Epoch: 4 [53760/387873]    Loss: 0.001952   Batch Acc: 90.62
[Train] Epoch: 4 [53888/387873]    Loss: 0.001683   Batch Acc: 90.62
[Train] Epoch: 4 [54016/387873]    Loss: 0.001689   Batch Acc: 91.41
[Train] Epoch: 4 [54144/387873]    Loss: 0.001853   Batch Acc: 92.19
[Train] Epoch: 4 [54272/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 4 [54400/387873]    Loss: 0.001426   Batch Acc: 96.09
[Train] Epoch: 4 [54528/387873]    Loss: 0.002167   Batch Acc: 89.84
[Train] Epoch: 4 [54656/387873]    Loss: 0.001420   Batch Acc: 93.75
[Train] Epoch: 4 [54784/387873]    Loss: 0.002320   Batch Acc: 84.38
[Train] Epoch: 4 [54912/387873]    Loss: 0.001681   Batch Acc: 93.75
[Train] Epoch: 4 [55040/387873]    Loss: 0.002255   Batch Acc: 86.72
[Train] Epoch: 4 [55168/387873]    Loss: 0.002064   Batch Acc: 89.06
[Train] Epoch: 4 [55296/387873]    Loss: 0.002223   Batch Acc: 88.28
[Train] Epoch: 4 [55424/387873]    Loss: 0.001823   Batch Acc: 91.41
[Train] Epoch: 4 [55552/387873]    Loss: 0.001932   Batch Acc: 88.28
[Train] Epoch: 4 [55680/387873]    Loss: 0.002487   Batch Acc: 87.50
[Train] Epoch: 4 [55808/387873]    Loss: 0.002134   Batch Acc: 89.84
[Train] Epoch: 4 [55936/387873]    Loss: 0.001843   Batch Acc: 91.41
[Train] Epoch: 4 [56064/387873]    Loss: 0.002216   Batch Acc: 86.72
[Train] Epoch: 4 [56192/387873]    Loss: 0.001776   Batch Acc: 91.41
[Train] Epoch: 4 [56320/387873]    Loss: 0.002396   Batch Acc: 85.94
[Train] Epoch: 4 [56448/387873]    Loss: 0.002154   Batch Acc: 88.28
[Train] Epoch: 4 [56576/387873]    Loss: 0.002209   Batch Acc: 89.06
[Train] Epoch: 4 [56704/387873]    Loss: 0.001659   Batch Acc: 91.41
[Train] Epoch: 4 [56832/387873]    Loss: 0.001956   Batch Acc: 89.06
[Train] Epoch: 4 [56960/387873]    Loss: 0.002133   Batch Acc: 87.50
[Train] Epoch: 4 [57088/387873]    Loss: 0.001837   Batch Acc: 92.19
[Train] Epoch: 4 [57216/387873]    Loss: 0.002018   Batch Acc: 89.06
[Train] Epoch: 4 [57344/387873]    Loss: 0.001423   Batch Acc: 95.31
[Train] Epoch: 4 [57472/387873]    Loss: 0.002164   Batch Acc: 86.72
[Train] Epoch: 4 [57600/387873]    Loss: 0.002243   Batch Acc: 88.28
[Train] Epoch: 4 [57728/387873]    Loss: 0.002138   Batch Acc: 90.62
[Train] Epoch: 4 [57856/387873]    Loss: 0.002187   Batch Acc: 86.72
[Train] Epoch: 4 [57984/387873]    Loss: 0.002003   Batch Acc: 88.28
[Train] Epoch: 4 [58112/387873]    Loss: 0.001807   Batch Acc: 88.28
[Train] Epoch: 4 [58240/387873]    Loss: 0.002485   Batch Acc: 85.94
[Train] Epoch: 4 [58368/387873]    Loss: 0.002062   Batch Acc: 86.72
[Train] Epoch: 4 [58496/387873]    Loss: 0.001862   Batch Acc: 88.28
[Train] Epoch: 4 [58624/387873]    Loss: 0.002106   Batch Acc: 89.84
[Train] Epoch: 4 [58752/387873]    Loss: 0.002566   Batch Acc: 85.16
[Train] Epoch: 4 [58880/387873]    Loss: 0.001936   Batch Acc: 90.62
[Train] Epoch: 4 [59008/387873]    Loss: 0.001519   Batch Acc: 91.41
[Train] Epoch: 4 [59136/387873]    Loss: 0.001863   Batch Acc: 91.41
[Train] Epoch: 4 [59264/387873]    Loss: 0.001688   Batch Acc: 89.84
[Train] Epoch: 4 [59392/387873]    Loss: 0.001920   Batch Acc: 89.84
[Train] Epoch: 4 [59520/387873]    Loss: 0.001945   Batch Acc: 92.19
[Train] Epoch: 4 [59648/387873]    Loss: 0.002399   Batch Acc: 87.50
[Train] Epoch: 4 [59776/387873]    Loss: 0.002170   Batch Acc: 88.28
[Train] Epoch: 4 [59904/387873]    Loss: 0.001198   Batch Acc: 96.09
[Train] Epoch: 4 [60032/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 4 [60160/387873]    Loss: 0.001563   Batch Acc: 91.41
[Train] Epoch: 4 [60288/387873]    Loss: 0.002716   Batch Acc: 82.81
[Train] Epoch: 4 [60416/387873]    Loss: 0.002145   Batch Acc: 87.50
[Train] Epoch: 4 [60544/387873]    Loss: 0.002119   Batch Acc: 90.62
[Train] Epoch: 4 [60672/387873]    Loss: 0.002087   Batch Acc: 90.62
[Train] Epoch: 4 [60800/387873]    Loss: 0.002289   Batch Acc: 85.94
[Train] Epoch: 4 [60928/387873]    Loss: 0.001978   Batch Acc: 87.50
[Train] Epoch: 4 [61056/387873]    Loss: 0.002187   Batch Acc: 86.72
[Train] Epoch: 4 [61184/387873]    Loss: 0.001830   Batch Acc: 92.19
[Train] Epoch: 4 [61312/387873]    Loss: 0.002023   Batch Acc: 89.84
[Train] Epoch: 4 [61440/387873]    Loss: 0.001957   Batch Acc: 88.28
[Train] Epoch: 4 [61568/387873]    Loss: 0.001905   Batch Acc: 88.28
[Train] Epoch: 4 [61696/387873]    Loss: 0.001505   Batch Acc: 92.97
[Train] Epoch: 4 [61824/387873]    Loss: 0.001855   Batch Acc: 89.06
[Train] Epoch: 4 [61952/387873]    Loss: 0.001825   Batch Acc: 92.97
[Train] Epoch: 4 [62080/387873]    Loss: 0.002170   Batch Acc: 88.28
[Train] Epoch: 4 [62208/387873]    Loss: 0.001732   Batch Acc: 91.41
[Train] Epoch: 4 [62336/387873]    Loss: 0.001875   Batch Acc: 89.06
[Train] Epoch: 4 [62464/387873]    Loss: 0.002563   Batch Acc: 85.94
[Train] Epoch: 4 [62592/387873]    Loss: 0.001726   Batch Acc: 92.19
[Train] Epoch: 4 [62720/387873]    Loss: 0.001783   Batch Acc: 92.19
[Train] Epoch: 4 [62848/387873]    Loss: 0.002104   Batch Acc: 88.28
[Train] Epoch: 4 [62976/387873]    Loss: 0.001857   Batch Acc: 93.75
[Train] Epoch: 4 [63104/387873]    Loss: 0.001896   Batch Acc: 92.97
[Train] Epoch: 4 [63232/387873]    Loss: 0.001429   Batch Acc: 95.31
[Train] Epoch: 4 [63360/387873]    Loss: 0.001933   Batch Acc: 92.19
[Train] Epoch: 4 [63488/387873]    Loss: 0.002072   Batch Acc: 89.84
[Train] Epoch: 4 [63616/387873]    Loss: 0.001566   Batch Acc: 94.53
[Train] Epoch: 4 [63744/387873]    Loss: 0.002298   Batch Acc: 86.72
[Train] Epoch: 4 [63872/387873]    Loss: 0.001697   Batch Acc: 90.62
[Train] Epoch: 4 [64000/387873]    Loss: 0.001639   Batch Acc: 92.19
[Train] Epoch: 4 [64128/387873]    Loss: 0.001957   Batch Acc: 91.41
[Train] Epoch: 4 [64256/387873]    Loss: 0.002111   Batch Acc: 88.28
[Train] Epoch: 4 [64384/387873]    Loss: 0.001455   Batch Acc: 92.97
[Train] Epoch: 4 [64512/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 4 [64640/387873]    Loss: 0.001950   Batch Acc: 87.50
[Train] Epoch: 4 [64768/387873]    Loss: 0.002151   Batch Acc: 88.28
[Train] Epoch: 4 [64896/387873]    Loss: 0.001938   Batch Acc: 89.06
[Train] Epoch: 4 [65024/387873]    Loss: 0.001837   Batch Acc: 89.84
[Train] Epoch: 4 [65152/387873]    Loss: 0.001696   Batch Acc: 92.19
[Train] Epoch: 4 [65280/387873]    Loss: 0.002609   Batch Acc: 81.25
[Train] Epoch: 4 [65408/387873]    Loss: 0.001489   Batch Acc: 94.53
[Train] Epoch: 4 [65536/387873]    Loss: 0.001526   Batch Acc: 90.62
[Train] Epoch: 4 [65664/387873]    Loss: 0.002137   Batch Acc: 88.28
[Train] Epoch: 4 [65792/387873]    Loss: 0.002263   Batch Acc: 85.94
[Train] Epoch: 4 [65920/387873]    Loss: 0.002212   Batch Acc: 91.41
[Train] Epoch: 4 [66048/387873]    Loss: 0.001652   Batch Acc: 92.19
[Train] Epoch: 4 [66176/387873]    Loss: 0.001794   Batch Acc: 92.19
[Train] Epoch: 4 [66304/387873]    Loss: 0.002102   Batch Acc: 89.84
[Train] Epoch: 4 [66432/387873]    Loss: 0.001650   Batch Acc: 91.41
[Train] Epoch: 4 [66560/387873]    Loss: 0.002129   Batch Acc: 90.62
[Train] Epoch: 4 [66688/387873]    Loss: 0.002329   Batch Acc: 88.28
[Train] Epoch: 4 [66816/387873]    Loss: 0.001875   Batch Acc: 89.06
[Train] Epoch: 4 [66944/387873]    Loss: 0.002347   Batch Acc: 87.50
[Train] Epoch: 4 [67072/387873]    Loss: 0.002138   Batch Acc: 86.72
[Train] Epoch: 4 [67200/387873]    Loss: 0.002377   Batch Acc: 86.72
[Train] Epoch: 4 [67328/387873]    Loss: 0.001760   Batch Acc: 90.62
[Train] Epoch: 4 [67456/387873]    Loss: 0.001618   Batch Acc: 89.06
[Train] Epoch: 4 [67584/387873]    Loss: 0.001466   Batch Acc: 92.97
[Train] Epoch: 4 [67712/387873]    Loss: 0.002068   Batch Acc: 88.28
[Train] Epoch: 4 [67840/387873]    Loss: 0.002059   Batch Acc: 89.84
[Train] Epoch: 4 [67968/387873]    Loss: 0.001483   Batch Acc: 92.97
[Train] Epoch: 4 [68096/387873]    Loss: 0.002048   Batch Acc: 91.41
[Train] Epoch: 4 [68224/387873]    Loss: 0.001882   Batch Acc: 90.62
[Train] Epoch: 4 [68352/387873]    Loss: 0.002100   Batch Acc: 86.72
[Train] Epoch: 4 [68480/387873]    Loss: 0.002093   Batch Acc: 90.62
[Train] Epoch: 4 [68608/387873]    Loss: 0.002144   Batch Acc: 89.84
[Train] Epoch: 4 [68736/387873]    Loss: 0.001724   Batch Acc: 90.62
[Train] Epoch: 4 [68864/387873]    Loss: 0.001324   Batch Acc: 94.53
[Train] Epoch: 4 [68992/387873]    Loss: 0.001643   Batch Acc: 92.19
[Train] Epoch: 4 [69120/387873]    Loss: 0.001828   Batch Acc: 91.41
[Train] Epoch: 4 [69248/387873]    Loss: 0.002079   Batch Acc: 89.06
[Train] Epoch: 4 [69376/387873]    Loss: 0.001774   Batch Acc: 92.19
[Train] Epoch: 4 [69504/387873]    Loss: 0.002121   Batch Acc: 90.62
[Train] Epoch: 4 [69632/387873]    Loss: 0.001800   Batch Acc: 92.19
[Train] Epoch: 4 [69760/387873]    Loss: 0.002123   Batch Acc: 89.06
[Train] Epoch: 4 [69888/387873]    Loss: 0.002181   Batch Acc: 86.72
[Train] Epoch: 4 [70016/387873]    Loss: 0.002385   Batch Acc: 87.50
[Train] Epoch: 4 [70144/387873]    Loss: 0.001375   Batch Acc: 94.53
[Train] Epoch: 4 [70272/387873]    Loss: 0.002058   Batch Acc: 86.72
[Train] Epoch: 4 [70400/387873]    Loss: 0.001870   Batch Acc: 90.62
[Train] Epoch: 4 [70528/387873]    Loss: 0.002136   Batch Acc: 88.28
[Train] Epoch: 4 [70656/387873]    Loss: 0.001972   Batch Acc: 89.84
[Train] Epoch: 4 [70784/387873]    Loss: 0.001982   Batch Acc: 89.06
[Train] Epoch: 4 [70912/387873]    Loss: 0.002454   Batch Acc: 85.94
[Train] Epoch: 4 [71040/387873]    Loss: 0.002401   Batch Acc: 87.50
[Train] Epoch: 4 [71168/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 4 [71296/387873]    Loss: 0.001802   Batch Acc: 91.41
[Train] Epoch: 4 [71424/387873]    Loss: 0.002076   Batch Acc: 86.72
[Train] Epoch: 4 [71552/387873]    Loss: 0.001802   Batch Acc: 90.62
[Train] Epoch: 4 [71680/387873]    Loss: 0.001635   Batch Acc: 92.19
[Train] Epoch: 4 [71808/387873]    Loss: 0.001716   Batch Acc: 92.19
[Train] Epoch: 4 [71936/387873]    Loss: 0.002571   Batch Acc: 82.03
[Train] Epoch: 4 [72064/387873]    Loss: 0.002424   Batch Acc: 85.94
[Train] Epoch: 4 [72192/387873]    Loss: 0.001736   Batch Acc: 93.75
[Train] Epoch: 4 [72320/387873]    Loss: 0.001943   Batch Acc: 89.06
[Train] Epoch: 4 [72448/387873]    Loss: 0.002033   Batch Acc: 90.62
[Train] Epoch: 4 [72576/387873]    Loss: 0.002391   Batch Acc: 85.16
[Train] Epoch: 4 [72704/387873]    Loss: 0.002161   Batch Acc: 87.50
[Train] Epoch: 4 [72832/387873]    Loss: 0.002065   Batch Acc: 88.28
[Train] Epoch: 4 [72960/387873]    Loss: 0.001989   Batch Acc: 89.06
[Train] Epoch: 4 [73088/387873]    Loss: 0.002127   Batch Acc: 89.06
[Train] Epoch: 4 [73216/387873]    Loss: 0.001726   Batch Acc: 89.84
[Train] Epoch: 4 [73344/387873]    Loss: 0.002126   Batch Acc: 87.50
[Train] Epoch: 4 [73472/387873]    Loss: 0.001881   Batch Acc: 92.19
[Train] Epoch: 4 [73600/387873]    Loss: 0.001879   Batch Acc: 91.41
[Train] Epoch: 4 [73728/387873]    Loss: 0.002777   Batch Acc: 86.72
[Train] Epoch: 4 [73856/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 4 [73984/387873]    Loss: 0.001617   Batch Acc: 93.75
[Train] Epoch: 4 [74112/387873]    Loss: 0.001953   Batch Acc: 89.84
[Train] Epoch: 4 [74240/387873]    Loss: 0.002609   Batch Acc: 82.03
[Train] Epoch: 4 [74368/387873]    Loss: 0.002265   Batch Acc: 89.84
[Train] Epoch: 4 [74496/387873]    Loss: 0.001550   Batch Acc: 95.31
[Train] Epoch: 4 [74624/387873]    Loss: 0.002310   Batch Acc: 86.72
[Train] Epoch: 4 [74752/387873]    Loss: 0.002367   Batch Acc: 84.38
[Train] Epoch: 4 [74880/387873]    Loss: 0.001868   Batch Acc: 90.62
[Train] Epoch: 4 [75008/387873]    Loss: 0.001906   Batch Acc: 89.06
[Train] Epoch: 4 [75136/387873]    Loss: 0.001676   Batch Acc: 91.41
[Train] Epoch: 4 [75264/387873]    Loss: 0.001720   Batch Acc: 92.19
[Train] Epoch: 4 [75392/387873]    Loss: 0.001759   Batch Acc: 89.06
[Train] Epoch: 4 [75520/387873]    Loss: 0.002342   Batch Acc: 83.59
[Train] Epoch: 4 [75648/387873]    Loss: 0.001492   Batch Acc: 96.09
[Train] Epoch: 4 [75776/387873]    Loss: 0.002049   Batch Acc: 88.28
[Train] Epoch: 4 [75904/387873]    Loss: 0.002192   Batch Acc: 85.94
[Train] Epoch: 4 [76032/387873]    Loss: 0.002938   Batch Acc: 83.59
[Train] Epoch: 4 [76160/387873]    Loss: 0.001508   Batch Acc: 91.41
[Train] Epoch: 4 [76288/387873]    Loss: 0.001977   Batch Acc: 90.62
[Train] Epoch: 4 [76416/387873]    Loss: 0.002165   Batch Acc: 85.94
[Train] Epoch: 4 [76544/387873]    Loss: 0.002528   Batch Acc: 88.28
[Train] Epoch: 4 [76672/387873]    Loss: 0.001869   Batch Acc: 89.06
[Train] Epoch: 4 [76800/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 4 [76928/387873]    Loss: 0.001878   Batch Acc: 89.84
[Train] Epoch: 4 [77056/387873]    Loss: 0.001908   Batch Acc: 89.84
[Train] Epoch: 4 [77184/387873]    Loss: 0.001717   Batch Acc: 89.84
[Train] Epoch: 4 [77312/387873]    Loss: 0.002478   Batch Acc: 88.28
[Train] Epoch: 4 [77440/387873]    Loss: 0.002580   Batch Acc: 85.16
[Train] Epoch: 4 [77568/387873]    Loss: 0.001884   Batch Acc: 87.50
[Train] Epoch: 4 [77696/387873]    Loss: 0.002105   Batch Acc: 87.50
[Train] Epoch: 4 [77824/387873]    Loss: 0.001951   Batch Acc: 87.50
[Train] Epoch: 4 [77952/387873]    Loss: 0.001654   Batch Acc: 92.19
[Train] Epoch: 4 [78080/387873]    Loss: 0.001543   Batch Acc: 92.97
[Train] Epoch: 4 [78208/387873]    Loss: 0.002018   Batch Acc: 85.94
[Train] Epoch: 4 [78336/387873]    Loss: 0.002145   Batch Acc: 87.50
[Train] Epoch: 4 [78464/387873]    Loss: 0.001785   Batch Acc: 91.41
[Train] Epoch: 4 [78592/387873]    Loss: 0.002059   Batch Acc: 89.84
[Train] Epoch: 4 [78720/387873]    Loss: 0.001544   Batch Acc: 92.19
[Train] Epoch: 4 [78848/387873]    Loss: 0.001575   Batch Acc: 93.75
[Train] Epoch: 4 [78976/387873]    Loss: 0.002805   Batch Acc: 85.94
[Train] Epoch: 4 [79104/387873]    Loss: 0.001684   Batch Acc: 92.97
[Train] Epoch: 4 [79232/387873]    Loss: 0.001906   Batch Acc: 92.19
[Train] Epoch: 4 [79360/387873]    Loss: 0.002888   Batch Acc: 81.25
[Train] Epoch: 4 [79488/387873]    Loss: 0.002343   Batch Acc: 88.28
[Train] Epoch: 4 [79616/387873]    Loss: 0.002242   Batch Acc: 87.50
[Train] Epoch: 4 [79744/387873]    Loss: 0.001876   Batch Acc: 88.28
[Train] Epoch: 4 [79872/387873]    Loss: 0.001658   Batch Acc: 93.75
[Train] Epoch: 4 [80000/387873]    Loss: 0.001963   Batch Acc: 89.84
[Train] Epoch: 4 [80128/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 4 [80256/387873]    Loss: 0.002280   Batch Acc: 82.81
[Train] Epoch: 4 [80384/387873]    Loss: 0.002723   Batch Acc: 82.81
[Train] Epoch: 4 [80512/387873]    Loss: 0.002397   Batch Acc: 88.28
[Train] Epoch: 4 [80640/387873]    Loss: 0.001489   Batch Acc: 93.75
[Train] Epoch: 4 [80768/387873]    Loss: 0.002052   Batch Acc: 86.72
[Train] Epoch: 4 [80896/387873]    Loss: 0.001853   Batch Acc: 89.06
[Train] Epoch: 4 [81024/387873]    Loss: 0.001644   Batch Acc: 90.62
[Train] Epoch: 4 [81152/387873]    Loss: 0.001838   Batch Acc: 90.62
[Train] Epoch: 4 [81280/387873]    Loss: 0.002463   Batch Acc: 87.50
[Train] Epoch: 4 [81408/387873]    Loss: 0.002152   Batch Acc: 87.50
[Train] Epoch: 4 [81536/387873]    Loss: 0.003541   Batch Acc: 80.47
[Train] Epoch: 4 [81664/387873]    Loss: 0.001657   Batch Acc: 92.97
[Train] Epoch: 4 [81792/387873]    Loss: 0.002522   Batch Acc: 85.16
[Train] Epoch: 4 [81920/387873]    Loss: 0.002212   Batch Acc: 88.28
[Train] Epoch: 4 [82048/387873]    Loss: 0.002077   Batch Acc: 86.72
[Train] Epoch: 4 [82176/387873]    Loss: 0.001681   Batch Acc: 92.19
[Train] Epoch: 4 [82304/387873]    Loss: 0.001601   Batch Acc: 92.19
[Train] Epoch: 4 [82432/387873]    Loss: 0.001587   Batch Acc: 93.75
[Train] Epoch: 4 [82560/387873]    Loss: 0.002072   Batch Acc: 87.50
[Train] Epoch: 4 [82688/387873]    Loss: 0.001905   Batch Acc: 88.28
[Train] Epoch: 4 [82816/387873]    Loss: 0.002216   Batch Acc: 87.50
[Train] Epoch: 4 [82944/387873]    Loss: 0.002952   Batch Acc: 82.03
[Train] Epoch: 4 [83072/387873]    Loss: 0.001625   Batch Acc: 93.75
[Train] Epoch: 4 [83200/387873]    Loss: 0.001427   Batch Acc: 93.75
[Train] Epoch: 4 [83328/387873]    Loss: 0.001751   Batch Acc: 89.06
[Train] Epoch: 4 [83456/387873]    Loss: 0.002231   Batch Acc: 91.41
[Train] Epoch: 4 [83584/387873]    Loss: 0.001615   Batch Acc: 93.75
[Train] Epoch: 4 [83712/387873]    Loss: 0.001870   Batch Acc: 89.84
[Train] Epoch: 4 [83840/387873]    Loss: 0.002004   Batch Acc: 87.50
[Train] Epoch: 4 [83968/387873]    Loss: 0.002358   Batch Acc: 84.38
[Train] Epoch: 4 [84096/387873]    Loss: 0.001735   Batch Acc: 92.97
[Train] Epoch: 4 [84224/387873]    Loss: 0.002075   Batch Acc: 89.06
[Train] Epoch: 4 [84352/387873]    Loss: 0.001575   Batch Acc: 93.75
[Train] Epoch: 4 [84480/387873]    Loss: 0.001931   Batch Acc: 89.06
[Train] Epoch: 4 [84608/387873]    Loss: 0.001480   Batch Acc: 92.19
[Train] Epoch: 4 [84736/387873]    Loss: 0.002042   Batch Acc: 88.28
[Train] Epoch: 4 [84864/387873]    Loss: 0.001930   Batch Acc: 89.84
[Train] Epoch: 4 [84992/387873]    Loss: 0.002153   Batch Acc: 88.28
[Train] Epoch: 4 [85120/387873]    Loss: 0.001654   Batch Acc: 92.97
[Train] Epoch: 4 [85248/387873]    Loss: 0.001586   Batch Acc: 94.53
[Train] Epoch: 4 [85376/387873]    Loss: 0.002556   Batch Acc: 82.03
[Train] Epoch: 4 [85504/387873]    Loss: 0.002034   Batch Acc: 89.84
[Train] Epoch: 4 [85632/387873]    Loss: 0.002899   Batch Acc: 82.81
[Train] Epoch: 4 [85760/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 4 [85888/387873]    Loss: 0.001612   Batch Acc: 91.41
[Train] Epoch: 4 [86016/387873]    Loss: 0.002457   Batch Acc: 89.06
[Train] Epoch: 4 [86144/387873]    Loss: 0.002086   Batch Acc: 86.72
[Train] Epoch: 4 [86272/387873]    Loss: 0.002214   Batch Acc: 85.94
[Train] Epoch: 4 [86400/387873]    Loss: 0.002162   Batch Acc: 89.84
[Train] Epoch: 4 [86528/387873]    Loss: 0.002063   Batch Acc: 88.28
[Train] Epoch: 4 [86656/387873]    Loss: 0.002186   Batch Acc: 87.50
[Train] Epoch: 4 [86784/387873]    Loss: 0.002223   Batch Acc: 89.84
[Train] Epoch: 4 [86912/387873]    Loss: 0.002283   Batch Acc: 85.16
[Train] Epoch: 4 [87040/387873]    Loss: 0.001685   Batch Acc: 92.97
[Train] Epoch: 4 [87168/387873]    Loss: 0.001968   Batch Acc: 89.06
[Train] Epoch: 4 [87296/387873]    Loss: 0.001773   Batch Acc: 92.19
[Train] Epoch: 4 [87424/387873]    Loss: 0.001668   Batch Acc: 92.97
[Train] Epoch: 4 [87552/387873]    Loss: 0.001992   Batch Acc: 89.06
[Train] Epoch: 4 [87680/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 4 [87808/387873]    Loss: 0.002026   Batch Acc: 89.84
[Train] Epoch: 4 [87936/387873]    Loss: 0.001627   Batch Acc: 92.97
[Train] Epoch: 4 [88064/387873]    Loss: 0.002447   Batch Acc: 87.50
[Train] Epoch: 4 [88192/387873]    Loss: 0.001816   Batch Acc: 92.19
[Train] Epoch: 4 [88320/387873]    Loss: 0.002277   Batch Acc: 85.16
[Train] Epoch: 4 [88448/387873]    Loss: 0.001612   Batch Acc: 94.53
[Train] Epoch: 4 [88576/387873]    Loss: 0.001785   Batch Acc: 90.62
[Train] Epoch: 4 [88704/387873]    Loss: 0.001809   Batch Acc: 90.62
[Train] Epoch: 4 [88832/387873]    Loss: 0.002500   Batch Acc: 83.59
[Train] Epoch: 4 [88960/387873]    Loss: 0.002665   Batch Acc: 83.59
[Train] Epoch: 4 [89088/387873]    Loss: 0.001961   Batch Acc: 89.84
[Train] Epoch: 4 [89216/387873]    Loss: 0.002638   Batch Acc: 84.38
[Train] Epoch: 4 [89344/387873]    Loss: 0.001749   Batch Acc: 90.62
[Train] Epoch: 4 [89472/387873]    Loss: 0.001775   Batch Acc: 89.06
[Train] Epoch: 4 [89600/387873]    Loss: 0.001909   Batch Acc: 90.62
[Train] Epoch: 4 [89728/387873]    Loss: 0.001572   Batch Acc: 94.53
[Train] Epoch: 4 [89856/387873]    Loss: 0.001676   Batch Acc: 93.75
[Train] Epoch: 4 [89984/387873]    Loss: 0.001928   Batch Acc: 92.19
[Train] Epoch: 4 [90112/387873]    Loss: 0.002060   Batch Acc: 89.84
[Train] Epoch: 4 [90240/387873]    Loss: 0.002137   Batch Acc: 87.50
[Train] Epoch: 4 [90368/387873]    Loss: 0.001870   Batch Acc: 89.84
[Train] Epoch: 4 [90496/387873]    Loss: 0.002090   Batch Acc: 85.94
[Train] Epoch: 4 [90624/387873]    Loss: 0.001640   Batch Acc: 91.41
[Train] Epoch: 4 [90752/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 4 [90880/387873]    Loss: 0.001910   Batch Acc: 90.62
[Train] Epoch: 4 [91008/387873]    Loss: 0.002054   Batch Acc: 87.50
[Train] Epoch: 4 [91136/387873]    Loss: 0.002254   Batch Acc: 87.50
[Train] Epoch: 4 [91264/387873]    Loss: 0.001988   Batch Acc: 86.72
[Train] Epoch: 4 [91392/387873]    Loss: 0.002543   Batch Acc: 85.16
[Train] Epoch: 4 [91520/387873]    Loss: 0.001782   Batch Acc: 90.62
[Train] Epoch: 4 [91648/387873]    Loss: 0.002429   Batch Acc: 85.94
[Train] Epoch: 4 [91776/387873]    Loss: 0.001656   Batch Acc: 92.19
[Train] Epoch: 4 [91904/387873]    Loss: 0.002062   Batch Acc: 89.06
[Train] Epoch: 4 [92032/387873]    Loss: 0.001485   Batch Acc: 91.41
[Train] Epoch: 4 [92160/387873]    Loss: 0.002376   Batch Acc: 87.50
[Train] Epoch: 4 [92288/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 4 [92416/387873]    Loss: 0.001872   Batch Acc: 89.06
[Train] Epoch: 4 [92544/387873]    Loss: 0.001611   Batch Acc: 92.97
[Train] Epoch: 4 [92672/387873]    Loss: 0.001981   Batch Acc: 91.41
[Train] Epoch: 4 [92800/387873]    Loss: 0.002331   Batch Acc: 85.94
[Train] Epoch: 4 [92928/387873]    Loss: 0.001671   Batch Acc: 92.97
[Train] Epoch: 4 [93056/387873]    Loss: 0.001712   Batch Acc: 91.41
[Train] Epoch: 4 [93184/387873]    Loss: 0.001570   Batch Acc: 93.75
[Train] Epoch: 4 [93312/387873]    Loss: 0.002579   Batch Acc: 85.16
[Train] Epoch: 4 [93440/387873]    Loss: 0.001875   Batch Acc: 90.62
[Train] Epoch: 4 [93568/387873]    Loss: 0.001530   Batch Acc: 92.97
[Train] Epoch: 4 [93696/387873]    Loss: 0.001679   Batch Acc: 92.97
[Train] Epoch: 4 [93824/387873]    Loss: 0.001688   Batch Acc: 89.84
[Train] Epoch: 4 [93952/387873]    Loss: 0.001558   Batch Acc: 92.19
[Train] Epoch: 4 [94080/387873]    Loss: 0.001724   Batch Acc: 91.41
[Train] Epoch: 4 [94208/387873]    Loss: 0.001501   Batch Acc: 92.19
[Train] Epoch: 4 [94336/387873]    Loss: 0.002048   Batch Acc: 88.28
[Train] Epoch: 4 [94464/387873]    Loss: 0.002272   Batch Acc: 88.28
[Train] Epoch: 4 [94592/387873]    Loss: 0.002168   Batch Acc: 89.06
[Train] Epoch: 4 [94720/387873]    Loss: 0.002479   Batch Acc: 85.16
[Train] Epoch: 4 [94848/387873]    Loss: 0.002001   Batch Acc: 89.84
[Train] Epoch: 4 [94976/387873]    Loss: 0.001847   Batch Acc: 91.41
[Train] Epoch: 4 [95104/387873]    Loss: 0.001462   Batch Acc: 92.97
[Train] Epoch: 4 [95232/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 4 [95360/387873]    Loss: 0.002156   Batch Acc: 89.84
[Train] Epoch: 4 [95488/387873]    Loss: 0.001704   Batch Acc: 93.75
[Train] Epoch: 4 [95616/387873]    Loss: 0.001912   Batch Acc: 88.28
[Train] Epoch: 4 [95744/387873]    Loss: 0.002476   Batch Acc: 86.72
[Train] Epoch: 4 [95872/387873]    Loss: 0.001690   Batch Acc: 92.97
[Train] Epoch: 4 [96000/387873]    Loss: 0.002305   Batch Acc: 87.50
[Train] Epoch: 4 [96128/387873]    Loss: 0.001638   Batch Acc: 92.97
[Train] Epoch: 4 [96256/387873]    Loss: 0.001532   Batch Acc: 93.75
[Train] Epoch: 4 [96384/387873]    Loss: 0.002439   Batch Acc: 85.94
[Train] Epoch: 4 [96512/387873]    Loss: 0.001853   Batch Acc: 90.62
[Train] Epoch: 4 [96640/387873]    Loss: 0.001721   Batch Acc: 91.41
[Train] Epoch: 4 [96768/387873]    Loss: 0.001924   Batch Acc: 91.41
[Train] Epoch: 4 [96896/387873]    Loss: 0.002265   Batch Acc: 88.28
[Train] Epoch: 4 [97024/387873]    Loss: 0.002051   Batch Acc: 88.28
[Train] Epoch: 4 [97152/387873]    Loss: 0.002082   Batch Acc: 90.62
[Train] Epoch: 4 [97280/387873]    Loss: 0.002183   Batch Acc: 88.28
[Train] Epoch: 4 [97408/387873]    Loss: 0.002643   Batch Acc: 79.69
[Train] Epoch: 4 [97536/387873]    Loss: 0.001978   Batch Acc: 86.72
[Train] Epoch: 4 [97664/387873]    Loss: 0.002277   Batch Acc: 85.16
[Train] Epoch: 4 [97792/387873]    Loss: 0.001814   Batch Acc: 90.62
[Train] Epoch: 4 [97920/387873]    Loss: 0.002012   Batch Acc: 89.84
[Train] Epoch: 4 [98048/387873]    Loss: 0.001951   Batch Acc: 89.06
[Train] Epoch: 4 [98176/387873]    Loss: 0.002032   Batch Acc: 89.06
[Train] Epoch: 4 [98304/387873]    Loss: 0.002390   Batch Acc: 89.06
[Train] Epoch: 4 [98432/387873]    Loss: 0.001973   Batch Acc: 86.72
[Train] Epoch: 4 [98560/387873]    Loss: 0.002318   Batch Acc: 87.50
[Train] Epoch: 4 [98688/387873]    Loss: 0.000968   Batch Acc: 96.88
[Train] Epoch: 4 [98816/387873]    Loss: 0.002131   Batch Acc: 85.16
[Train] Epoch: 4 [98944/387873]    Loss: 0.001290   Batch Acc: 94.53
[Train] Epoch: 4 [99072/387873]    Loss: 0.001841   Batch Acc: 92.19
[Train] Epoch: 4 [99200/387873]    Loss: 0.001458   Batch Acc: 96.09
[Train] Epoch: 4 [99328/387873]    Loss: 0.001866   Batch Acc: 89.84
[Train] Epoch: 4 [99456/387873]    Loss: 0.001865   Batch Acc: 89.06
[Train] Epoch: 4 [99584/387873]    Loss: 0.003212   Batch Acc: 79.69
[Train] Epoch: 4 [99712/387873]    Loss: 0.001668   Batch Acc: 92.97
[Train] Epoch: 4 [99840/387873]    Loss: 0.001510   Batch Acc: 92.19
[Train] Epoch: 4 [99968/387873]    Loss: 0.001728   Batch Acc: 92.19
[Train] Epoch: 4 [100096/387873]    Loss: 0.002002   Batch Acc: 88.28
[Train] Epoch: 4 [100224/387873]    Loss: 0.001590   Batch Acc: 92.19
[Train] Epoch: 4 [100352/387873]    Loss: 0.002866   Batch Acc: 87.50
[Train] Epoch: 4 [100480/387873]    Loss: 0.001941   Batch Acc: 92.19
[Train] Epoch: 4 [100608/387873]    Loss: 0.002184   Batch Acc: 85.94
[Train] Epoch: 4 [100736/387873]    Loss: 0.001996   Batch Acc: 89.06
[Train] Epoch: 4 [100864/387873]    Loss: 0.001857   Batch Acc: 90.62
[Train] Epoch: 4 [100992/387873]    Loss: 0.002000   Batch Acc: 89.84
[Train] Epoch: 4 [101120/387873]    Loss: 0.001818   Batch Acc: 91.41
[Train] Epoch: 4 [101248/387873]    Loss: 0.001537   Batch Acc: 92.97
[Train] Epoch: 4 [101376/387873]    Loss: 0.001633   Batch Acc: 92.19
[Train] Epoch: 4 [101504/387873]    Loss: 0.001790   Batch Acc: 90.62
[Train] Epoch: 4 [101632/387873]    Loss: 0.002002   Batch Acc: 89.06
[Train] Epoch: 4 [101760/387873]    Loss: 0.002052   Batch Acc: 89.06
[Train] Epoch: 4 [101888/387873]    Loss: 0.001646   Batch Acc: 91.41
[Train] Epoch: 4 [102016/387873]    Loss: 0.001659   Batch Acc: 90.62
[Train] Epoch: 4 [102144/387873]    Loss: 0.001709   Batch Acc: 92.19
[Train] Epoch: 4 [102272/387873]    Loss: 0.001458   Batch Acc: 96.09
[Train] Epoch: 4 [102400/387873]    Loss: 0.002269   Batch Acc: 87.50
[Train] Epoch: 4 [102528/387873]    Loss: 0.001593   Batch Acc: 91.41
[Train] Epoch: 4 [102656/387873]    Loss: 0.001833   Batch Acc: 89.84
[Train] Epoch: 4 [102784/387873]    Loss: 0.002111   Batch Acc: 89.06
[Train] Epoch: 4 [102912/387873]    Loss: 0.002248   Batch Acc: 86.72
[Train] Epoch: 4 [103040/387873]    Loss: 0.002233   Batch Acc: 87.50
[Train] Epoch: 4 [103168/387873]    Loss: 0.001848   Batch Acc: 90.62
[Train] Epoch: 4 [103296/387873]    Loss: 0.002123   Batch Acc: 89.06
[Train] Epoch: 4 [103424/387873]    Loss: 0.002113   Batch Acc: 89.84
[Train] Epoch: 4 [103552/387873]    Loss: 0.002249   Batch Acc: 85.94
[Train] Epoch: 4 [103680/387873]    Loss: 0.002073   Batch Acc: 89.84
[Train] Epoch: 4 [103808/387873]    Loss: 0.001673   Batch Acc: 92.19
[Train] Epoch: 4 [103936/387873]    Loss: 0.001672   Batch Acc: 89.84
[Train] Epoch: 4 [104064/387873]    Loss: 0.002280   Batch Acc: 88.28
[Train] Epoch: 4 [104192/387873]    Loss: 0.002736   Batch Acc: 84.38
[Train] Epoch: 4 [104320/387873]    Loss: 0.001531   Batch Acc: 92.97
[Train] Epoch: 4 [104448/387873]    Loss: 0.002507   Batch Acc: 82.03
[Train] Epoch: 4 [104576/387873]    Loss: 0.002920   Batch Acc: 82.03
[Train] Epoch: 4 [104704/387873]    Loss: 0.002273   Batch Acc: 89.06
[Train] Epoch: 4 [104832/387873]    Loss: 0.002209   Batch Acc: 89.84
[Train] Epoch: 4 [104960/387873]    Loss: 0.001772   Batch Acc: 91.41
[Train] Epoch: 4 [105088/387873]    Loss: 0.002885   Batch Acc: 83.59
[Train] Epoch: 4 [105216/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 4 [105344/387873]    Loss: 0.001934   Batch Acc: 91.41
[Train] Epoch: 4 [105472/387873]    Loss: 0.001728   Batch Acc: 92.97
[Train] Epoch: 4 [105600/387873]    Loss: 0.002439   Batch Acc: 87.50
[Train] Epoch: 4 [105728/387873]    Loss: 0.002073   Batch Acc: 88.28
[Train] Epoch: 4 [105856/387873]    Loss: 0.002220   Batch Acc: 88.28
[Train] Epoch: 4 [105984/387873]    Loss: 0.001932   Batch Acc: 90.62
[Train] Epoch: 4 [106112/387873]    Loss: 0.001988   Batch Acc: 85.94
[Train] Epoch: 4 [106240/387873]    Loss: 0.001825   Batch Acc: 89.84
[Train] Epoch: 4 [106368/387873]    Loss: 0.002915   Batch Acc: 83.59
[Train] Epoch: 4 [106496/387873]    Loss: 0.002360   Batch Acc: 88.28
[Train] Epoch: 4 [106624/387873]    Loss: 0.001795   Batch Acc: 89.84
[Train] Epoch: 4 [106752/387873]    Loss: 0.002170   Batch Acc: 89.06
[Train] Epoch: 4 [106880/387873]    Loss: 0.001849   Batch Acc: 90.62
[Train] Epoch: 4 [107008/387873]    Loss: 0.002049   Batch Acc: 88.28
[Train] Epoch: 4 [107136/387873]    Loss: 0.002138   Batch Acc: 89.84
[Train] Epoch: 4 [107264/387873]    Loss: 0.002314   Batch Acc: 87.50
[Train] Epoch: 4 [107392/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 4 [107520/387873]    Loss: 0.002009   Batch Acc: 89.06
[Train] Epoch: 4 [107648/387873]    Loss: 0.001585   Batch Acc: 92.19
[Train] Epoch: 4 [107776/387873]    Loss: 0.002048   Batch Acc: 91.41
[Train] Epoch: 4 [107904/387873]    Loss: 0.001607   Batch Acc: 91.41
[Train] Epoch: 4 [108032/387873]    Loss: 0.002074   Batch Acc: 89.84
[Train] Epoch: 4 [108160/387873]    Loss: 0.001742   Batch Acc: 90.62
[Train] Epoch: 4 [108288/387873]    Loss: 0.001904   Batch Acc: 90.62
[Train] Epoch: 4 [108416/387873]    Loss: 0.002179   Batch Acc: 91.41
[Train] Epoch: 4 [108544/387873]    Loss: 0.001742   Batch Acc: 89.06
[Train] Epoch: 4 [108672/387873]    Loss: 0.001591   Batch Acc: 90.62
[Train] Epoch: 4 [108800/387873]    Loss: 0.001738   Batch Acc: 92.97
[Train] Epoch: 4 [108928/387873]    Loss: 0.001816   Batch Acc: 89.84
[Train] Epoch: 4 [109056/387873]    Loss: 0.001623   Batch Acc: 89.84
[Train] Epoch: 4 [109184/387873]    Loss: 0.002489   Batch Acc: 86.72
[Train] Epoch: 4 [109312/387873]    Loss: 0.001825   Batch Acc: 86.72
[Train] Epoch: 4 [109440/387873]    Loss: 0.002247   Batch Acc: 87.50
[Train] Epoch: 4 [109568/387873]    Loss: 0.002426   Batch Acc: 89.06
[Train] Epoch: 4 [109696/387873]    Loss: 0.001951   Batch Acc: 91.41
[Train] Epoch: 4 [109824/387873]    Loss: 0.001750   Batch Acc: 89.84
[Train] Epoch: 4 [109952/387873]    Loss: 0.001499   Batch Acc: 92.97
[Train] Epoch: 4 [110080/387873]    Loss: 0.002854   Batch Acc: 81.25
[Train] Epoch: 4 [110208/387873]    Loss: 0.001949   Batch Acc: 89.06
[Train] Epoch: 4 [110336/387873]    Loss: 0.001828   Batch Acc: 92.19
[Train] Epoch: 4 [110464/387873]    Loss: 0.001575   Batch Acc: 92.97
[Train] Epoch: 4 [110592/387873]    Loss: 0.002195   Batch Acc: 88.28
[Train] Epoch: 4 [110720/387873]    Loss: 0.001867   Batch Acc: 88.28
[Train] Epoch: 4 [110848/387873]    Loss: 0.002190   Batch Acc: 86.72
[Train] Epoch: 4 [110976/387873]    Loss: 0.002019   Batch Acc: 91.41
[Train] Epoch: 4 [111104/387873]    Loss: 0.002396   Batch Acc: 89.06
[Train] Epoch: 4 [111232/387873]    Loss: 0.002262   Batch Acc: 89.06
[Train] Epoch: 4 [111360/387873]    Loss: 0.002168   Batch Acc: 88.28
[Train] Epoch: 4 [111488/387873]    Loss: 0.001665   Batch Acc: 90.62
[Train] Epoch: 4 [111616/387873]    Loss: 0.002295   Batch Acc: 88.28
[Train] Epoch: 4 [111744/387873]    Loss: 0.002208   Batch Acc: 87.50
[Train] Epoch: 4 [111872/387873]    Loss: 0.001908   Batch Acc: 90.62
[Train] Epoch: 4 [112000/387873]    Loss: 0.001841   Batch Acc: 89.84
[Train] Epoch: 4 [112128/387873]    Loss: 0.002183   Batch Acc: 89.06
[Train] Epoch: 4 [112256/387873]    Loss: 0.001888   Batch Acc: 89.06
[Train] Epoch: 4 [112384/387873]    Loss: 0.001318   Batch Acc: 95.31
[Train] Epoch: 4 [112512/387873]    Loss: 0.001706   Batch Acc: 89.84
[Train] Epoch: 4 [112640/387873]    Loss: 0.001935   Batch Acc: 89.06
[Train] Epoch: 4 [112768/387873]    Loss: 0.003096   Batch Acc: 83.59
[Train] Epoch: 4 [112896/387873]    Loss: 0.002054   Batch Acc: 91.41
[Train] Epoch: 4 [113024/387873]    Loss: 0.002531   Batch Acc: 82.03
[Train] Epoch: 4 [113152/387873]    Loss: 0.001855   Batch Acc: 88.28
[Train] Epoch: 4 [113280/387873]    Loss: 0.002128   Batch Acc: 89.06
[Train] Epoch: 4 [113408/387873]    Loss: 0.001507   Batch Acc: 94.53
[Train] Epoch: 4 [113536/387873]    Loss: 0.002883   Batch Acc: 83.59
[Train] Epoch: 4 [113664/387873]    Loss: 0.001892   Batch Acc: 89.84
[Train] Epoch: 4 [113792/387873]    Loss: 0.002102   Batch Acc: 89.06
[Train] Epoch: 4 [113920/387873]    Loss: 0.001489   Batch Acc: 94.53
[Train] Epoch: 4 [114048/387873]    Loss: 0.001680   Batch Acc: 89.84
[Train] Epoch: 4 [114176/387873]    Loss: 0.001668   Batch Acc: 92.19
[Train] Epoch: 4 [114304/387873]    Loss: 0.001783   Batch Acc: 92.19
[Train] Epoch: 4 [114432/387873]    Loss: 0.001806   Batch Acc: 90.62
[Train] Epoch: 4 [114560/387873]    Loss: 0.001816   Batch Acc: 88.28
[Train] Epoch: 4 [114688/387873]    Loss: 0.001694   Batch Acc: 90.62
[Train] Epoch: 4 [114816/387873]    Loss: 0.002135   Batch Acc: 86.72
[Train] Epoch: 4 [114944/387873]    Loss: 0.002104   Batch Acc: 87.50
[Train] Epoch: 4 [115072/387873]    Loss: 0.001389   Batch Acc: 93.75
[Train] Epoch: 4 [115200/387873]    Loss: 0.002074   Batch Acc: 89.84
[Train] Epoch: 4 [115328/387873]    Loss: 0.002018   Batch Acc: 87.50
[Train] Epoch: 4 [115456/387873]    Loss: 0.002118   Batch Acc: 87.50
[Train] Epoch: 4 [115584/387873]    Loss: 0.001847   Batch Acc: 92.97
[Train] Epoch: 4 [115712/387873]    Loss: 0.001903   Batch Acc: 89.84
[Train] Epoch: 4 [115840/387873]    Loss: 0.002685   Batch Acc: 85.16
[Train] Epoch: 4 [115968/387873]    Loss: 0.002167   Batch Acc: 87.50
[Train] Epoch: 4 [116096/387873]    Loss: 0.002006   Batch Acc: 86.72
[Train] Epoch: 4 [116224/387873]    Loss: 0.001559   Batch Acc: 92.19
[Train] Epoch: 4 [116352/387873]    Loss: 0.001975   Batch Acc: 88.28
[Train] Epoch: 4 [116480/387873]    Loss: 0.001694   Batch Acc: 91.41
[Train] Epoch: 4 [116608/387873]    Loss: 0.001582   Batch Acc: 89.84
[Train] Epoch: 4 [116736/387873]    Loss: 0.001724   Batch Acc: 91.41
[Train] Epoch: 4 [116864/387873]    Loss: 0.002068   Batch Acc: 88.28
[Train] Epoch: 4 [116992/387873]    Loss: 0.001580   Batch Acc: 92.97
[Train] Epoch: 4 [117120/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 4 [117248/387873]    Loss: 0.001573   Batch Acc: 92.97
[Train] Epoch: 4 [117376/387873]    Loss: 0.002175   Batch Acc: 89.06
[Train] Epoch: 4 [117504/387873]    Loss: 0.002400   Batch Acc: 86.72
[Train] Epoch: 4 [117632/387873]    Loss: 0.002054   Batch Acc: 91.41
[Train] Epoch: 4 [117760/387873]    Loss: 0.002174   Batch Acc: 89.06
[Train] Epoch: 4 [117888/387873]    Loss: 0.002095   Batch Acc: 87.50
[Train] Epoch: 4 [118016/387873]    Loss: 0.001946   Batch Acc: 91.41
[Train] Epoch: 4 [118144/387873]    Loss: 0.001721   Batch Acc: 89.84
[Train] Epoch: 4 [118272/387873]    Loss: 0.001993   Batch Acc: 86.72
[Train] Epoch: 4 [118400/387873]    Loss: 0.002401   Batch Acc: 87.50
[Train] Epoch: 4 [118528/387873]    Loss: 0.001968   Batch Acc: 89.06
[Train] Epoch: 4 [118656/387873]    Loss: 0.001899   Batch Acc: 89.06
[Train] Epoch: 4 [118784/387873]    Loss: 0.002077   Batch Acc: 89.84
[Train] Epoch: 4 [118912/387873]    Loss: 0.001774   Batch Acc: 90.62
[Train] Epoch: 4 [119040/387873]    Loss: 0.001801   Batch Acc: 92.19
[Train] Epoch: 4 [119168/387873]    Loss: 0.002663   Batch Acc: 86.72
[Train] Epoch: 4 [119296/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 4 [119424/387873]    Loss: 0.002031   Batch Acc: 89.84
[Train] Epoch: 4 [119552/387873]    Loss: 0.001814   Batch Acc: 91.41
[Train] Epoch: 4 [119680/387873]    Loss: 0.002002   Batch Acc: 88.28
[Train] Epoch: 4 [119808/387873]    Loss: 0.002399   Batch Acc: 85.16
[Train] Epoch: 4 [119936/387873]    Loss: 0.001894   Batch Acc: 90.62
[Train] Epoch: 4 [120064/387873]    Loss: 0.002520   Batch Acc: 87.50
[Train] Epoch: 4 [120192/387873]    Loss: 0.002384   Batch Acc: 83.59
[Train] Epoch: 4 [120320/387873]    Loss: 0.002037   Batch Acc: 88.28
[Train] Epoch: 4 [120448/387873]    Loss: 0.002159   Batch Acc: 86.72
[Train] Epoch: 4 [120576/387873]    Loss: 0.002152   Batch Acc: 89.06
[Train] Epoch: 4 [120704/387873]    Loss: 0.002012   Batch Acc: 88.28
[Train] Epoch: 4 [120832/387873]    Loss: 0.002328   Batch Acc: 88.28
[Train] Epoch: 4 [120960/387873]    Loss: 0.002287   Batch Acc: 87.50
[Train] Epoch: 4 [121088/387873]    Loss: 0.002261   Batch Acc: 88.28
[Train] Epoch: 4 [121216/387873]    Loss: 0.001902   Batch Acc: 90.62
[Train] Epoch: 4 [121344/387873]    Loss: 0.002083   Batch Acc: 89.84
[Train] Epoch: 4 [121472/387873]    Loss: 0.001932   Batch Acc: 88.28
[Train] Epoch: 4 [121600/387873]    Loss: 0.002011   Batch Acc: 86.72
[Train] Epoch: 4 [121728/387873]    Loss: 0.002111   Batch Acc: 89.84
[Train] Epoch: 4 [121856/387873]    Loss: 0.002274   Batch Acc: 87.50
[Train] Epoch: 4 [121984/387873]    Loss: 0.001805   Batch Acc: 89.06
[Train] Epoch: 4 [122112/387873]    Loss: 0.002117   Batch Acc: 91.41
[Train] Epoch: 4 [122240/387873]    Loss: 0.002360   Batch Acc: 87.50
[Train] Epoch: 4 [122368/387873]    Loss: 0.002047   Batch Acc: 88.28
[Train] Epoch: 4 [122496/387873]    Loss: 0.002088   Batch Acc: 87.50
[Train] Epoch: 4 [122624/387873]    Loss: 0.001839   Batch Acc: 90.62
[Train] Epoch: 4 [122752/387873]    Loss: 0.001623   Batch Acc: 91.41
[Train] Epoch: 4 [122880/387873]    Loss: 0.001889   Batch Acc: 90.62
[Train] Epoch: 4 [123008/387873]    Loss: 0.001608   Batch Acc: 92.19
[Train] Epoch: 4 [123136/387873]    Loss: 0.002365   Batch Acc: 87.50
[Train] Epoch: 4 [123264/387873]    Loss: 0.002146   Batch Acc: 88.28
[Train] Epoch: 4 [123392/387873]    Loss: 0.001949   Batch Acc: 89.84
[Train] Epoch: 4 [123520/387873]    Loss: 0.002074   Batch Acc: 90.62
[Train] Epoch: 4 [123648/387873]    Loss: 0.001853   Batch Acc: 91.41
[Train] Epoch: 4 [123776/387873]    Loss: 0.002031   Batch Acc: 91.41
[Train] Epoch: 4 [123904/387873]    Loss: 0.002125   Batch Acc: 89.06
[Train] Epoch: 4 [124032/387873]    Loss: 0.002133   Batch Acc: 85.94
[Train] Epoch: 4 [124160/387873]    Loss: 0.001617   Batch Acc: 91.41
[Train] Epoch: 4 [124288/387873]    Loss: 0.002068   Batch Acc: 89.84
[Train] Epoch: 4 [124416/387873]    Loss: 0.001943   Batch Acc: 89.84
[Train] Epoch: 4 [124544/387873]    Loss: 0.001975   Batch Acc: 91.41
[Train] Epoch: 4 [124672/387873]    Loss: 0.002051   Batch Acc: 89.84
[Train] Epoch: 4 [124800/387873]    Loss: 0.001741   Batch Acc: 95.31
[Train] Epoch: 4 [124928/387873]    Loss: 0.002309   Batch Acc: 82.81
[Train] Epoch: 4 [125056/387873]    Loss: 0.001310   Batch Acc: 94.53
[Train] Epoch: 4 [125184/387873]    Loss: 0.002333   Batch Acc: 84.38
[Train] Epoch: 4 [125312/387873]    Loss: 0.001854   Batch Acc: 90.62
[Train] Epoch: 4 [125440/387873]    Loss: 0.002189   Batch Acc: 87.50
[Train] Epoch: 4 [125568/387873]    Loss: 0.002277   Batch Acc: 89.06
[Train] Epoch: 4 [125696/387873]    Loss: 0.001721   Batch Acc: 91.41
[Train] Epoch: 4 [125824/387873]    Loss: 0.002023   Batch Acc: 88.28
[Train] Epoch: 4 [125952/387873]    Loss: 0.002062   Batch Acc: 87.50
[Train] Epoch: 4 [126080/387873]    Loss: 0.001760   Batch Acc: 89.06
[Train] Epoch: 4 [126208/387873]    Loss: 0.001922   Batch Acc: 92.19
[Train] Epoch: 4 [126336/387873]    Loss: 0.002823   Batch Acc: 83.59
[Train] Epoch: 4 [126464/387873]    Loss: 0.001626   Batch Acc: 89.84
[Train] Epoch: 4 [126592/387873]    Loss: 0.002372   Batch Acc: 87.50
[Train] Epoch: 4 [126720/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 4 [126848/387873]    Loss: 0.001754   Batch Acc: 91.41
[Train] Epoch: 4 [126976/387873]    Loss: 0.002462   Batch Acc: 86.72
[Train] Epoch: 4 [127104/387873]    Loss: 0.001398   Batch Acc: 95.31
[Train] Epoch: 4 [127232/387873]    Loss: 0.001519   Batch Acc: 93.75
[Train] Epoch: 4 [127360/387873]    Loss: 0.002114   Batch Acc: 89.84
[Train] Epoch: 4 [127488/387873]    Loss: 0.001780   Batch Acc: 92.97
[Train] Epoch: 4 [127616/387873]    Loss: 0.002017   Batch Acc: 91.41
[Train] Epoch: 4 [127744/387873]    Loss: 0.001769   Batch Acc: 89.84
[Train] Epoch: 4 [127872/387873]    Loss: 0.002198   Batch Acc: 89.84
[Train] Epoch: 4 [128000/387873]    Loss: 0.002311   Batch Acc: 89.84
[Train] Epoch: 4 [128128/387873]    Loss: 0.002271   Batch Acc: 86.72
[Train] Epoch: 4 [128256/387873]    Loss: 0.001589   Batch Acc: 92.19
[Train] Epoch: 4 [128384/387873]    Loss: 0.001999   Batch Acc: 88.28
[Train] Epoch: 4 [128512/387873]    Loss: 0.002234   Batch Acc: 85.94
[Train] Epoch: 4 [128640/387873]    Loss: 0.001886   Batch Acc: 91.41
[Train] Epoch: 4 [128768/387873]    Loss: 0.002030   Batch Acc: 92.19
[Train] Epoch: 4 [128896/387873]    Loss: 0.001579   Batch Acc: 92.97
[Train] Epoch: 4 [129024/387873]    Loss: 0.001569   Batch Acc: 89.84
[Train] Epoch: 4 [129152/387873]    Loss: 0.001994   Batch Acc: 89.84
[Train] Epoch: 4 [129280/387873]    Loss: 0.001719   Batch Acc: 92.97
[Train] Epoch: 4 [129408/387873]    Loss: 0.002115   Batch Acc: 87.50
[Train] Epoch: 4 [129536/387873]    Loss: 0.002165   Batch Acc: 85.16
[Train] Epoch: 4 [129664/387873]    Loss: 0.002081   Batch Acc: 89.06
[Train] Epoch: 4 [129792/387873]    Loss: 0.002147   Batch Acc: 89.84
[Train] Epoch: 4 [129920/387873]    Loss: 0.002395   Batch Acc: 85.94
[Train] Epoch: 4 [130048/387873]    Loss: 0.001774   Batch Acc: 95.31
[Train] Epoch: 4 [130176/387873]    Loss: 0.001740   Batch Acc: 91.41
[Train] Epoch: 4 [130304/387873]    Loss: 0.001898   Batch Acc: 90.62
[Train] Epoch: 4 [130432/387873]    Loss: 0.001985   Batch Acc: 90.62
[Train] Epoch: 4 [130560/387873]    Loss: 0.001742   Batch Acc: 92.19
[Train] Epoch: 4 [130688/387873]    Loss: 0.002023   Batch Acc: 90.62
[Train] Epoch: 4 [130816/387873]    Loss: 0.002120   Batch Acc: 86.72
[Train] Epoch: 4 [130944/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 4 [131072/387873]    Loss: 0.002161   Batch Acc: 86.72
[Train] Epoch: 4 [131200/387873]    Loss: 0.001808   Batch Acc: 90.62
[Train] Epoch: 4 [131328/387873]    Loss: 0.002697   Batch Acc: 83.59
[Train] Epoch: 4 [131456/387873]    Loss: 0.001889   Batch Acc: 87.50
[Train] Epoch: 4 [131584/387873]    Loss: 0.001836   Batch Acc: 88.28
[Train] Epoch: 4 [131712/387873]    Loss: 0.001829   Batch Acc: 92.97
[Train] Epoch: 4 [131840/387873]    Loss: 0.002528   Batch Acc: 89.06
[Train] Epoch: 4 [131968/387873]    Loss: 0.001507   Batch Acc: 93.75
[Train] Epoch: 4 [132096/387873]    Loss: 0.001971   Batch Acc: 90.62
[Train] Epoch: 4 [132224/387873]    Loss: 0.001927   Batch Acc: 89.84
[Train] Epoch: 4 [132352/387873]    Loss: 0.002316   Batch Acc: 90.62
[Train] Epoch: 4 [132480/387873]    Loss: 0.002229   Batch Acc: 85.16
[Train] Epoch: 4 [132608/387873]    Loss: 0.002721   Batch Acc: 85.94
[Train] Epoch: 4 [132736/387873]    Loss: 0.002529   Batch Acc: 85.16
[Train] Epoch: 4 [132864/387873]    Loss: 0.001745   Batch Acc: 90.62
[Train] Epoch: 4 [132992/387873]    Loss: 0.001698   Batch Acc: 89.84
[Train] Epoch: 4 [133120/387873]    Loss: 0.001740   Batch Acc: 92.19
[Train] Epoch: 4 [133248/387873]    Loss: 0.002038   Batch Acc: 89.84
[Train] Epoch: 4 [133376/387873]    Loss: 0.001946   Batch Acc: 92.19
[Train] Epoch: 4 [133504/387873]    Loss: 0.001562   Batch Acc: 90.62
[Train] Epoch: 4 [133632/387873]    Loss: 0.002476   Batch Acc: 85.94
[Train] Epoch: 4 [133760/387873]    Loss: 0.001729   Batch Acc: 91.41
[Train] Epoch: 4 [133888/387873]    Loss: 0.001873   Batch Acc: 91.41
[Train] Epoch: 4 [134016/387873]    Loss: 0.001747   Batch Acc: 91.41
[Train] Epoch: 4 [134144/387873]    Loss: 0.002413   Batch Acc: 85.16
[Train] Epoch: 4 [134272/387873]    Loss: 0.002647   Batch Acc: 85.94
[Train] Epoch: 4 [134400/387873]    Loss: 0.002432   Batch Acc: 85.16
[Train] Epoch: 4 [134528/387873]    Loss: 0.002592   Batch Acc: 86.72
[Train] Epoch: 4 [134656/387873]    Loss: 0.001604   Batch Acc: 93.75
[Train] Epoch: 4 [134784/387873]    Loss: 0.001761   Batch Acc: 92.97
[Train] Epoch: 4 [134912/387873]    Loss: 0.002122   Batch Acc: 88.28
[Train] Epoch: 4 [135040/387873]    Loss: 0.001937   Batch Acc: 89.84
[Train] Epoch: 4 [135168/387873]    Loss: 0.002083   Batch Acc: 91.41
[Train] Epoch: 4 [135296/387873]    Loss: 0.002217   Batch Acc: 87.50
[Train] Epoch: 4 [135424/387873]    Loss: 0.002048   Batch Acc: 86.72
[Train] Epoch: 4 [135552/387873]    Loss: 0.002290   Batch Acc: 89.84
[Train] Epoch: 4 [135680/387873]    Loss: 0.002245   Batch Acc: 87.50
[Train] Epoch: 4 [135808/387873]    Loss: 0.001551   Batch Acc: 92.97
[Train] Epoch: 4 [135936/387873]    Loss: 0.001457   Batch Acc: 92.97
[Train] Epoch: 4 [136064/387873]    Loss: 0.002280   Batch Acc: 87.50
[Train] Epoch: 4 [136192/387873]    Loss: 0.002682   Batch Acc: 83.59
[Train] Epoch: 4 [136320/387873]    Loss: 0.002047   Batch Acc: 89.84
[Train] Epoch: 4 [136448/387873]    Loss: 0.001805   Batch Acc: 92.97
[Train] Epoch: 4 [136576/387873]    Loss: 0.001439   Batch Acc: 94.53
[Train] Epoch: 4 [136704/387873]    Loss: 0.002321   Batch Acc: 84.38
[Train] Epoch: 4 [136832/387873]    Loss: 0.002603   Batch Acc: 87.50
[Train] Epoch: 4 [136960/387873]    Loss: 0.001690   Batch Acc: 90.62
[Train] Epoch: 4 [137088/387873]    Loss: 0.001898   Batch Acc: 91.41
[Train] Epoch: 4 [137216/387873]    Loss: 0.001669   Batch Acc: 91.41
[Train] Epoch: 4 [137344/387873]    Loss: 0.001593   Batch Acc: 95.31
[Train] Epoch: 4 [137472/387873]    Loss: 0.001596   Batch Acc: 95.31
[Train] Epoch: 4 [137600/387873]    Loss: 0.002938   Batch Acc: 81.25
[Train] Epoch: 4 [137728/387873]    Loss: 0.002218   Batch Acc: 85.16
[Train] Epoch: 4 [137856/387873]    Loss: 0.001551   Batch Acc: 93.75
[Train] Epoch: 4 [137984/387873]    Loss: 0.001967   Batch Acc: 90.62
[Train] Epoch: 4 [138112/387873]    Loss: 0.001819   Batch Acc: 89.06
[Train] Epoch: 4 [138240/387873]    Loss: 0.001941   Batch Acc: 86.72
[Train] Epoch: 4 [138368/387873]    Loss: 0.001676   Batch Acc: 92.97
[Train] Epoch: 4 [138496/387873]    Loss: 0.002361   Batch Acc: 86.72
[Train] Epoch: 4 [138624/387873]    Loss: 0.002125   Batch Acc: 88.28
[Train] Epoch: 4 [138752/387873]    Loss: 0.002179   Batch Acc: 89.06
[Train] Epoch: 4 [138880/387873]    Loss: 0.001759   Batch Acc: 89.84
[Train] Epoch: 4 [139008/387873]    Loss: 0.001883   Batch Acc: 90.62
[Train] Epoch: 4 [139136/387873]    Loss: 0.002115   Batch Acc: 88.28
[Train] Epoch: 4 [139264/387873]    Loss: 0.002168   Batch Acc: 88.28
[Train] Epoch: 4 [139392/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 4 [139520/387873]    Loss: 0.001953   Batch Acc: 90.62
[Train] Epoch: 4 [139648/387873]    Loss: 0.002568   Batch Acc: 85.16
[Train] Epoch: 4 [139776/387873]    Loss: 0.001760   Batch Acc: 90.62
[Train] Epoch: 4 [139904/387873]    Loss: 0.001924   Batch Acc: 89.84
[Train] Epoch: 4 [140032/387873]    Loss: 0.002097   Batch Acc: 87.50
[Train] Epoch: 4 [140160/387873]    Loss: 0.001656   Batch Acc: 90.62
[Train] Epoch: 4 [140288/387873]    Loss: 0.001779   Batch Acc: 90.62
[Train] Epoch: 4 [140416/387873]    Loss: 0.002148   Batch Acc: 84.38
[Train] Epoch: 4 [140544/387873]    Loss: 0.002714   Batch Acc: 84.38
[Train] Epoch: 4 [140672/387873]    Loss: 0.002377   Batch Acc: 87.50
[Train] Epoch: 4 [140800/387873]    Loss: 0.002333   Batch Acc: 86.72
[Train] Epoch: 4 [140928/387873]    Loss: 0.001510   Batch Acc: 92.97
[Train] Epoch: 4 [141056/387873]    Loss: 0.001982   Batch Acc: 89.84
[Train] Epoch: 4 [141184/387873]    Loss: 0.002135   Batch Acc: 86.72
[Train] Epoch: 4 [141312/387873]    Loss: 0.001994   Batch Acc: 89.06
[Train] Epoch: 4 [141440/387873]    Loss: 0.001841   Batch Acc: 85.94
[Train] Epoch: 4 [141568/387873]    Loss: 0.001715   Batch Acc: 92.19
[Train] Epoch: 4 [141696/387873]    Loss: 0.002112   Batch Acc: 86.72
[Train] Epoch: 4 [141824/387873]    Loss: 0.002123   Batch Acc: 86.72
[Train] Epoch: 4 [141952/387873]    Loss: 0.001522   Batch Acc: 92.97
[Train] Epoch: 4 [142080/387873]    Loss: 0.001676   Batch Acc: 89.84
[Train] Epoch: 4 [142208/387873]    Loss: 0.001791   Batch Acc: 90.62
[Train] Epoch: 4 [142336/387873]    Loss: 0.001900   Batch Acc: 90.62
[Train] Epoch: 4 [142464/387873]    Loss: 0.002322   Batch Acc: 86.72
[Train] Epoch: 4 [142592/387873]    Loss: 0.001512   Batch Acc: 93.75
[Train] Epoch: 4 [142720/387873]    Loss: 0.001751   Batch Acc: 92.19
[Train] Epoch: 4 [142848/387873]    Loss: 0.002415   Batch Acc: 88.28
[Train] Epoch: 4 [142976/387873]    Loss: 0.001735   Batch Acc: 92.19
[Train] Epoch: 4 [143104/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 4 [143232/387873]    Loss: 0.002511   Batch Acc: 89.84
[Train] Epoch: 4 [143360/387873]    Loss: 0.001964   Batch Acc: 91.41
[Train] Epoch: 4 [143488/387873]    Loss: 0.001825   Batch Acc: 92.97
[Train] Epoch: 4 [143616/387873]    Loss: 0.002116   Batch Acc: 84.38
[Train] Epoch: 4 [143744/387873]    Loss: 0.001535   Batch Acc: 93.75
[Train] Epoch: 4 [143872/387873]    Loss: 0.002668   Batch Acc: 87.50
[Train] Epoch: 4 [144000/387873]    Loss: 0.001888   Batch Acc: 90.62
[Train] Epoch: 4 [144128/387873]    Loss: 0.001855   Batch Acc: 90.62
[Train] Epoch: 4 [144256/387873]    Loss: 0.002047   Batch Acc: 85.16
[Train] Epoch: 4 [144384/387873]    Loss: 0.002218   Batch Acc: 85.94
[Train] Epoch: 4 [144512/387873]    Loss: 0.002246   Batch Acc: 87.50
[Train] Epoch: 4 [144640/387873]    Loss: 0.002167   Batch Acc: 86.72
[Train] Epoch: 4 [144768/387873]    Loss: 0.002088   Batch Acc: 91.41
[Train] Epoch: 4 [144896/387873]    Loss: 0.002599   Batch Acc: 86.72
[Train] Epoch: 4 [145024/387873]    Loss: 0.001563   Batch Acc: 92.97
[Train] Epoch: 4 [145152/387873]    Loss: 0.002290   Batch Acc: 85.94
[Train] Epoch: 4 [145280/387873]    Loss: 0.002037   Batch Acc: 89.84
[Train] Epoch: 4 [145408/387873]    Loss: 0.002085   Batch Acc: 89.06
[Train] Epoch: 4 [145536/387873]    Loss: 0.002066   Batch Acc: 89.06
[Train] Epoch: 4 [145664/387873]    Loss: 0.001866   Batch Acc: 91.41
[Train] Epoch: 4 [145792/387873]    Loss: 0.001953   Batch Acc: 89.06
[Train] Epoch: 4 [145920/387873]    Loss: 0.001846   Batch Acc: 91.41
[Train] Epoch: 4 [146048/387873]    Loss: 0.002308   Batch Acc: 85.16
[Train] Epoch: 4 [146176/387873]    Loss: 0.001834   Batch Acc: 91.41
[Train] Epoch: 4 [146304/387873]    Loss: 0.002384   Batch Acc: 89.06
[Train] Epoch: 4 [146432/387873]    Loss: 0.002291   Batch Acc: 87.50
[Train] Epoch: 4 [146560/387873]    Loss: 0.001915   Batch Acc: 88.28
[Train] Epoch: 4 [146688/387873]    Loss: 0.001915   Batch Acc: 89.06
[Train] Epoch: 4 [146816/387873]    Loss: 0.001131   Batch Acc: 92.97
[Train] Epoch: 4 [146944/387873]    Loss: 0.002037   Batch Acc: 89.06
[Train] Epoch: 4 [147072/387873]    Loss: 0.001529   Batch Acc: 92.97
[Train] Epoch: 4 [147200/387873]    Loss: 0.002242   Batch Acc: 88.28
[Train] Epoch: 4 [147328/387873]    Loss: 0.002035   Batch Acc: 89.06
[Train] Epoch: 4 [147456/387873]    Loss: 0.001765   Batch Acc: 92.97
[Train] Epoch: 4 [147584/387873]    Loss: 0.001967   Batch Acc: 89.84
[Train] Epoch: 4 [147712/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 4 [147840/387873]    Loss: 0.002066   Batch Acc: 87.50
[Train] Epoch: 4 [147968/387873]    Loss: 0.001879   Batch Acc: 89.84
[Train] Epoch: 4 [148096/387873]    Loss: 0.002262   Batch Acc: 88.28
[Train] Epoch: 4 [148224/387873]    Loss: 0.002670   Batch Acc: 84.38
[Train] Epoch: 4 [148352/387873]    Loss: 0.002010   Batch Acc: 90.62
[Train] Epoch: 4 [148480/387873]    Loss: 0.002400   Batch Acc: 85.94
[Train] Epoch: 4 [148608/387873]    Loss: 0.002115   Batch Acc: 90.62
[Train] Epoch: 4 [148736/387873]    Loss: 0.002206   Batch Acc: 92.19
[Train] Epoch: 4 [148864/387873]    Loss: 0.002216   Batch Acc: 87.50
[Train] Epoch: 4 [148992/387873]    Loss: 0.001755   Batch Acc: 89.84
[Train] Epoch: 4 [149120/387873]    Loss: 0.001751   Batch Acc: 91.41
[Train] Epoch: 4 [149248/387873]    Loss: 0.002144   Batch Acc: 89.84
[Train] Epoch: 4 [149376/387873]    Loss: 0.001665   Batch Acc: 90.62
[Train] Epoch: 4 [149504/387873]    Loss: 0.001602   Batch Acc: 91.41
[Train] Epoch: 4 [149632/387873]    Loss: 0.002153   Batch Acc: 89.06
[Train] Epoch: 4 [149760/387873]    Loss: 0.001647   Batch Acc: 92.19
[Train] Epoch: 4 [149888/387873]    Loss: 0.002084   Batch Acc: 89.06
[Train] Epoch: 4 [150016/387873]    Loss: 0.001907   Batch Acc: 91.41
[Train] Epoch: 4 [150144/387873]    Loss: 0.001904   Batch Acc: 89.06
[Train] Epoch: 4 [150272/387873]    Loss: 0.002088   Batch Acc: 90.62
[Train] Epoch: 4 [150400/387873]    Loss: 0.002222   Batch Acc: 86.72
[Train] Epoch: 4 [150528/387873]    Loss: 0.001906   Batch Acc: 90.62
[Train] Epoch: 4 [150656/387873]    Loss: 0.001871   Batch Acc: 92.19
[Train] Epoch: 4 [150784/387873]    Loss: 0.001864   Batch Acc: 88.28
[Train] Epoch: 4 [150912/387873]    Loss: 0.002404   Batch Acc: 84.38
[Train] Epoch: 4 [151040/387873]    Loss: 0.002251   Batch Acc: 90.62
[Train] Epoch: 4 [151168/387873]    Loss: 0.001640   Batch Acc: 89.84
[Train] Epoch: 4 [151296/387873]    Loss: 0.002026   Batch Acc: 85.94
[Train] Epoch: 4 [151424/387873]    Loss: 0.001368   Batch Acc: 95.31
[Train] Epoch: 4 [151552/387873]    Loss: 0.001698   Batch Acc: 89.84
[Train] Epoch: 4 [151680/387873]    Loss: 0.001868   Batch Acc: 92.19
[Train] Epoch: 4 [151808/387873]    Loss: 0.001740   Batch Acc: 90.62
[Train] Epoch: 4 [151936/387873]    Loss: 0.001618   Batch Acc: 93.75
[Train] Epoch: 4 [152064/387873]    Loss: 0.002839   Batch Acc: 88.28
[Train] Epoch: 4 [152192/387873]    Loss: 0.002688   Batch Acc: 84.38
[Train] Epoch: 4 [152320/387873]    Loss: 0.001976   Batch Acc: 83.59
[Train] Epoch: 4 [152448/387873]    Loss: 0.002493   Batch Acc: 86.72
[Train] Epoch: 4 [152576/387873]    Loss: 0.001676   Batch Acc: 94.53
[Train] Epoch: 4 [152704/387873]    Loss: 0.001936   Batch Acc: 88.28
[Train] Epoch: 4 [152832/387873]    Loss: 0.001982   Batch Acc: 87.50
[Train] Epoch: 4 [152960/387873]    Loss: 0.001926   Batch Acc: 92.19
[Train] Epoch: 4 [153088/387873]    Loss: 0.001345   Batch Acc: 95.31
[Train] Epoch: 4 [153216/387873]    Loss: 0.002544   Batch Acc: 91.41
[Train] Epoch: 4 [153344/387873]    Loss: 0.002021   Batch Acc: 89.84
[Train] Epoch: 4 [153472/387873]    Loss: 0.002059   Batch Acc: 89.06
[Train] Epoch: 4 [153600/387873]    Loss: 0.002404   Batch Acc: 87.50
[Train] Epoch: 4 [153728/387873]    Loss: 0.001949   Batch Acc: 89.06
[Train] Epoch: 4 [153856/387873]    Loss: 0.001275   Batch Acc: 95.31
[Train] Epoch: 4 [153984/387873]    Loss: 0.002353   Batch Acc: 84.38
[Train] Epoch: 4 [154112/387873]    Loss: 0.001731   Batch Acc: 88.28
[Train] Epoch: 4 [154240/387873]    Loss: 0.001908   Batch Acc: 87.50
[Train] Epoch: 4 [154368/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 4 [154496/387873]    Loss: 0.001964   Batch Acc: 88.28
[Train] Epoch: 4 [154624/387873]    Loss: 0.002145   Batch Acc: 86.72
[Train] Epoch: 4 [154752/387873]    Loss: 0.001855   Batch Acc: 90.62
[Train] Epoch: 4 [154880/387873]    Loss: 0.001568   Batch Acc: 93.75
[Train] Epoch: 4 [155008/387873]    Loss: 0.001546   Batch Acc: 93.75
[Train] Epoch: 4 [155136/387873]    Loss: 0.002449   Batch Acc: 85.16
[Train] Epoch: 4 [155264/387873]    Loss: 0.001707   Batch Acc: 89.84
[Train] Epoch: 4 [155392/387873]    Loss: 0.001804   Batch Acc: 90.62
[Train] Epoch: 4 [155520/387873]    Loss: 0.001866   Batch Acc: 92.19
[Train] Epoch: 4 [155648/387873]    Loss: 0.002066   Batch Acc: 84.38
[Train] Epoch: 4 [155776/387873]    Loss: 0.001763   Batch Acc: 89.84
[Train] Epoch: 4 [155904/387873]    Loss: 0.001575   Batch Acc: 91.41
[Train] Epoch: 4 [156032/387873]    Loss: 0.001886   Batch Acc: 90.62
[Train] Epoch: 4 [156160/387873]    Loss: 0.002458   Batch Acc: 85.94
[Train] Epoch: 4 [156288/387873]    Loss: 0.002012   Batch Acc: 90.62
[Train] Epoch: 4 [156416/387873]    Loss: 0.001690   Batch Acc: 90.62
[Train] Epoch: 4 [156544/387873]    Loss: 0.002464   Batch Acc: 89.84
[Train] Epoch: 4 [156672/387873]    Loss: 0.001989   Batch Acc: 89.84
[Train] Epoch: 4 [156800/387873]    Loss: 0.002053   Batch Acc: 89.84
[Train] Epoch: 4 [156928/387873]    Loss: 0.001835   Batch Acc: 89.84
[Train] Epoch: 4 [157056/387873]    Loss: 0.001471   Batch Acc: 92.97
[Train] Epoch: 4 [157184/387873]    Loss: 0.001952   Batch Acc: 90.62
[Train] Epoch: 4 [157312/387873]    Loss: 0.001788   Batch Acc: 91.41
[Train] Epoch: 4 [157440/387873]    Loss: 0.001879   Batch Acc: 89.06
[Train] Epoch: 4 [157568/387873]    Loss: 0.001834   Batch Acc: 92.19
[Train] Epoch: 4 [157696/387873]    Loss: 0.002119   Batch Acc: 89.84
[Train] Epoch: 4 [157824/387873]    Loss: 0.001586   Batch Acc: 90.62
[Train] Epoch: 4 [157952/387873]    Loss: 0.002009   Batch Acc: 88.28
[Train] Epoch: 4 [158080/387873]    Loss: 0.001480   Batch Acc: 93.75
[Train] Epoch: 4 [158208/387873]    Loss: 0.001713   Batch Acc: 89.84
[Train] Epoch: 4 [158336/387873]    Loss: 0.002032   Batch Acc: 88.28
[Train] Epoch: 4 [158464/387873]    Loss: 0.001425   Batch Acc: 93.75
[Train] Epoch: 4 [158592/387873]    Loss: 0.002311   Batch Acc: 85.16
[Train] Epoch: 4 [158720/387873]    Loss: 0.001825   Batch Acc: 92.19
[Train] Epoch: 4 [158848/387873]    Loss: 0.001729   Batch Acc: 93.75
[Train] Epoch: 4 [158976/387873]    Loss: 0.001646   Batch Acc: 92.19
[Train] Epoch: 4 [159104/387873]    Loss: 0.002254   Batch Acc: 89.84
[Train] Epoch: 4 [159232/387873]    Loss: 0.001848   Batch Acc: 89.06
[Train] Epoch: 4 [159360/387873]    Loss: 0.002053   Batch Acc: 87.50
[Train] Epoch: 4 [159488/387873]    Loss: 0.002399   Batch Acc: 85.94
[Train] Epoch: 4 [159616/387873]    Loss: 0.002051   Batch Acc: 90.62
[Train] Epoch: 4 [159744/387873]    Loss: 0.001997   Batch Acc: 89.06
[Train] Epoch: 4 [159872/387873]    Loss: 0.002083   Batch Acc: 89.84
[Train] Epoch: 4 [160000/387873]    Loss: 0.002182   Batch Acc: 85.16
[Train] Epoch: 4 [160128/387873]    Loss: 0.001647   Batch Acc: 90.62
[Train] Epoch: 4 [160256/387873]    Loss: 0.002693   Batch Acc: 85.94
[Train] Epoch: 4 [160384/387873]    Loss: 0.001329   Batch Acc: 94.53
[Train] Epoch: 4 [160512/387873]    Loss: 0.001899   Batch Acc: 90.62
[Train] Epoch: 4 [160640/387873]    Loss: 0.001662   Batch Acc: 89.84
[Train] Epoch: 4 [160768/387873]    Loss: 0.001820   Batch Acc: 88.28
[Train] Epoch: 4 [160896/387873]    Loss: 0.002188   Batch Acc: 91.41
[Train] Epoch: 4 [161024/387873]    Loss: 0.002357   Batch Acc: 85.16
[Train] Epoch: 4 [161152/387873]    Loss: 0.002003   Batch Acc: 87.50
[Train] Epoch: 4 [161280/387873]    Loss: 0.001816   Batch Acc: 90.62
[Train] Epoch: 4 [161408/387873]    Loss: 0.001473   Batch Acc: 92.97
[Train] Epoch: 4 [161536/387873]    Loss: 0.001564   Batch Acc: 92.19
[Train] Epoch: 4 [161664/387873]    Loss: 0.001818   Batch Acc: 91.41
[Train] Epoch: 4 [161792/387873]    Loss: 0.001915   Batch Acc: 89.06
[Train] Epoch: 4 [161920/387873]    Loss: 0.001797   Batch Acc: 90.62
[Train] Epoch: 4 [162048/387873]    Loss: 0.001706   Batch Acc: 92.97
[Train] Epoch: 4 [162176/387873]    Loss: 0.001852   Batch Acc: 91.41
[Train] Epoch: 4 [162304/387873]    Loss: 0.002026   Batch Acc: 89.06
[Train] Epoch: 4 [162432/387873]    Loss: 0.001913   Batch Acc: 90.62
[Train] Epoch: 4 [162560/387873]    Loss: 0.001990   Batch Acc: 87.50
[Train] Epoch: 4 [162688/387873]    Loss: 0.002432   Batch Acc: 85.16
[Train] Epoch: 4 [162816/387873]    Loss: 0.002510   Batch Acc: 87.50
[Train] Epoch: 4 [162944/387873]    Loss: 0.002108   Batch Acc: 90.62
[Train] Epoch: 4 [163072/387873]    Loss: 0.001936   Batch Acc: 89.84
[Train] Epoch: 4 [163200/387873]    Loss: 0.001973   Batch Acc: 89.84
[Train] Epoch: 4 [163328/387873]    Loss: 0.001767   Batch Acc: 92.97
[Train] Epoch: 4 [163456/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 4 [163584/387873]    Loss: 0.001892   Batch Acc: 91.41
[Train] Epoch: 4 [163712/387873]    Loss: 0.001541   Batch Acc: 89.84
[Train] Epoch: 4 [163840/387873]    Loss: 0.002173   Batch Acc: 89.06
[Train] Epoch: 4 [163968/387873]    Loss: 0.001463   Batch Acc: 93.75
[Train] Epoch: 4 [164096/387873]    Loss: 0.001451   Batch Acc: 94.53
[Train] Epoch: 4 [164224/387873]    Loss: 0.001969   Batch Acc: 89.06
[Train] Epoch: 4 [164352/387873]    Loss: 0.001530   Batch Acc: 91.41
[Train] Epoch: 4 [164480/387873]    Loss: 0.002229   Batch Acc: 85.94
[Train] Epoch: 4 [164608/387873]    Loss: 0.001825   Batch Acc: 88.28
[Train] Epoch: 4 [164736/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 4 [164864/387873]    Loss: 0.002315   Batch Acc: 85.16
[Train] Epoch: 4 [164992/387873]    Loss: 0.001685   Batch Acc: 90.62
[Train] Epoch: 4 [165120/387873]    Loss: 0.002039   Batch Acc: 90.62
[Train] Epoch: 4 [165248/387873]    Loss: 0.002626   Batch Acc: 85.94
[Train] Epoch: 4 [165376/387873]    Loss: 0.001933   Batch Acc: 89.84
[Train] Epoch: 4 [165504/387873]    Loss: 0.002228   Batch Acc: 85.94
[Train] Epoch: 4 [165632/387873]    Loss: 0.001927   Batch Acc: 89.06
[Train] Epoch: 4 [165760/387873]    Loss: 0.001551   Batch Acc: 92.19
[Train] Epoch: 4 [165888/387873]    Loss: 0.001872   Batch Acc: 92.97
[Train] Epoch: 4 [166016/387873]    Loss: 0.001950   Batch Acc: 90.62
[Train] Epoch: 4 [166144/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 4 [166272/387873]    Loss: 0.001884   Batch Acc: 89.84
[Train] Epoch: 4 [166400/387873]    Loss: 0.001866   Batch Acc: 91.41
[Train] Epoch: 4 [166528/387873]    Loss: 0.001724   Batch Acc: 91.41
[Train] Epoch: 4 [166656/387873]    Loss: 0.002093   Batch Acc: 88.28
[Train] Epoch: 4 [166784/387873]    Loss: 0.002026   Batch Acc: 90.62
[Train] Epoch: 4 [166912/387873]    Loss: 0.002270   Batch Acc: 89.06
[Train] Epoch: 4 [167040/387873]    Loss: 0.002131   Batch Acc: 89.84
[Train] Epoch: 4 [167168/387873]    Loss: 0.002191   Batch Acc: 87.50
[Train] Epoch: 4 [167296/387873]    Loss: 0.001794   Batch Acc: 89.06
[Train] Epoch: 4 [167424/387873]    Loss: 0.001700   Batch Acc: 90.62
[Train] Epoch: 4 [167552/387873]    Loss: 0.002756   Batch Acc: 82.81
[Train] Epoch: 4 [167680/387873]    Loss: 0.002319   Batch Acc: 82.81
[Train] Epoch: 4 [167808/387873]    Loss: 0.002692   Batch Acc: 82.81
[Train] Epoch: 4 [167936/387873]    Loss: 0.001334   Batch Acc: 96.09
[Train] Epoch: 4 [168064/387873]    Loss: 0.002132   Batch Acc: 88.28
[Train] Epoch: 4 [168192/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 4 [168320/387873]    Loss: 0.001702   Batch Acc: 90.62
[Train] Epoch: 4 [168448/387873]    Loss: 0.002102   Batch Acc: 88.28
[Train] Epoch: 4 [168576/387873]    Loss: 0.001728   Batch Acc: 90.62
[Train] Epoch: 4 [168704/387873]    Loss: 0.002484   Batch Acc: 87.50
[Train] Epoch: 4 [168832/387873]    Loss: 0.002152   Batch Acc: 87.50
[Train] Epoch: 4 [168960/387873]    Loss: 0.001990   Batch Acc: 89.84
[Train] Epoch: 4 [169088/387873]    Loss: 0.001952   Batch Acc: 89.84
[Train] Epoch: 4 [169216/387873]    Loss: 0.002184   Batch Acc: 88.28
[Train] Epoch: 4 [169344/387873]    Loss: 0.002029   Batch Acc: 90.62
[Train] Epoch: 4 [169472/387873]    Loss: 0.001970   Batch Acc: 89.06
[Train] Epoch: 4 [169600/387873]    Loss: 0.001438   Batch Acc: 95.31
[Train] Epoch: 4 [169728/387873]    Loss: 0.001871   Batch Acc: 92.19
[Train] Epoch: 4 [169856/387873]    Loss: 0.002310   Batch Acc: 88.28
[Train] Epoch: 4 [169984/387873]    Loss: 0.001762   Batch Acc: 92.19
[Train] Epoch: 4 [170112/387873]    Loss: 0.001422   Batch Acc: 93.75
[Train] Epoch: 4 [170240/387873]    Loss: 0.001603   Batch Acc: 96.09
[Train] Epoch: 4 [170368/387873]    Loss: 0.001793   Batch Acc: 91.41
[Train] Epoch: 4 [170496/387873]    Loss: 0.002429   Batch Acc: 86.72
[Train] Epoch: 4 [170624/387873]    Loss: 0.002391   Batch Acc: 88.28
[Train] Epoch: 4 [170752/387873]    Loss: 0.002056   Batch Acc: 87.50
[Train] Epoch: 4 [170880/387873]    Loss: 0.002365   Batch Acc: 85.94
[Train] Epoch: 4 [171008/387873]    Loss: 0.002531   Batch Acc: 89.06
[Train] Epoch: 4 [171136/387873]    Loss: 0.002076   Batch Acc: 87.50
[Train] Epoch: 4 [171264/387873]    Loss: 0.001871   Batch Acc: 89.84
[Train] Epoch: 4 [171392/387873]    Loss: 0.001808   Batch Acc: 89.84
[Train] Epoch: 4 [171520/387873]    Loss: 0.002389   Batch Acc: 84.38
[Train] Epoch: 4 [171648/387873]    Loss: 0.001726   Batch Acc: 91.41
[Train] Epoch: 4 [171776/387873]    Loss: 0.001966   Batch Acc: 88.28
[Train] Epoch: 4 [171904/387873]    Loss: 0.001551   Batch Acc: 92.19
[Train] Epoch: 4 [172032/387873]    Loss: 0.002119   Batch Acc: 90.62
[Train] Epoch: 4 [172160/387873]    Loss: 0.001809   Batch Acc: 90.62
[Train] Epoch: 4 [172288/387873]    Loss: 0.001906   Batch Acc: 88.28
[Train] Epoch: 4 [172416/387873]    Loss: 0.001691   Batch Acc: 91.41
[Train] Epoch: 4 [172544/387873]    Loss: 0.001775   Batch Acc: 90.62
[Train] Epoch: 4 [172672/387873]    Loss: 0.001497   Batch Acc: 92.97
[Train] Epoch: 4 [172800/387873]    Loss: 0.001940   Batch Acc: 91.41
[Train] Epoch: 4 [172928/387873]    Loss: 0.001900   Batch Acc: 91.41
[Train] Epoch: 4 [173056/387873]    Loss: 0.002423   Batch Acc: 82.81
[Train] Epoch: 4 [173184/387873]    Loss: 0.002300   Batch Acc: 89.06
[Train] Epoch: 4 [173312/387873]    Loss: 0.001445   Batch Acc: 92.19
[Train] Epoch: 4 [173440/387873]    Loss: 0.002823   Batch Acc: 84.38
[Train] Epoch: 4 [173568/387873]    Loss: 0.001901   Batch Acc: 89.84
[Train] Epoch: 4 [173696/387873]    Loss: 0.002076   Batch Acc: 89.06
[Train] Epoch: 4 [173824/387873]    Loss: 0.001674   Batch Acc: 92.97
[Train] Epoch: 4 [173952/387873]    Loss: 0.002093   Batch Acc: 88.28
[Train] Epoch: 4 [174080/387873]    Loss: 0.001751   Batch Acc: 89.84
[Train] Epoch: 4 [174208/387873]    Loss: 0.002269   Batch Acc: 87.50
[Train] Epoch: 4 [174336/387873]    Loss: 0.001598   Batch Acc: 93.75
[Train] Epoch: 4 [174464/387873]    Loss: 0.002182   Batch Acc: 86.72
[Train] Epoch: 4 [174592/387873]    Loss: 0.002050   Batch Acc: 87.50
[Train] Epoch: 4 [174720/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 4 [174848/387873]    Loss: 0.002009   Batch Acc: 88.28
[Train] Epoch: 4 [174976/387873]    Loss: 0.001493   Batch Acc: 92.19
[Train] Epoch: 4 [175104/387873]    Loss: 0.002027   Batch Acc: 86.72
[Train] Epoch: 4 [175232/387873]    Loss: 0.002281   Batch Acc: 86.72
[Train] Epoch: 4 [175360/387873]    Loss: 0.002190   Batch Acc: 87.50
[Train] Epoch: 4 [175488/387873]    Loss: 0.002321   Batch Acc: 82.81
[Train] Epoch: 4 [175616/387873]    Loss: 0.001412   Batch Acc: 93.75
[Train] Epoch: 4 [175744/387873]    Loss: 0.001715   Batch Acc: 92.19
[Train] Epoch: 4 [175872/387873]    Loss: 0.002299   Batch Acc: 86.72
[Train] Epoch: 4 [176000/387873]    Loss: 0.002271   Batch Acc: 87.50
[Train] Epoch: 4 [176128/387873]    Loss: 0.002056   Batch Acc: 89.84
[Train] Epoch: 4 [176256/387873]    Loss: 0.001645   Batch Acc: 90.62
[Train] Epoch: 4 [176384/387873]    Loss: 0.002236   Batch Acc: 89.06
[Train] Epoch: 4 [176512/387873]    Loss: 0.001741   Batch Acc: 90.62
[Train] Epoch: 4 [176640/387873]    Loss: 0.001797   Batch Acc: 88.28
[Train] Epoch: 4 [176768/387873]    Loss: 0.002977   Batch Acc: 81.25
[Train] Epoch: 4 [176896/387873]    Loss: 0.001886   Batch Acc: 89.06
[Train] Epoch: 4 [177024/387873]    Loss: 0.001524   Batch Acc: 93.75
[Train] Epoch: 4 [177152/387873]    Loss: 0.001950   Batch Acc: 85.16
[Train] Epoch: 4 [177280/387873]    Loss: 0.001682   Batch Acc: 90.62
[Train] Epoch: 4 [177408/387873]    Loss: 0.002094   Batch Acc: 89.06
[Train] Epoch: 4 [177536/387873]    Loss: 0.001952   Batch Acc: 88.28
[Train] Epoch: 4 [177664/387873]    Loss: 0.001709   Batch Acc: 88.28
[Train] Epoch: 4 [177792/387873]    Loss: 0.001632   Batch Acc: 92.97
[Train] Epoch: 4 [177920/387873]    Loss: 0.001572   Batch Acc: 92.19
[Train] Epoch: 4 [178048/387873]    Loss: 0.001888   Batch Acc: 89.06
[Train] Epoch: 4 [178176/387873]    Loss: 0.001773   Batch Acc: 92.97
[Train] Epoch: 4 [178304/387873]    Loss: 0.002043   Batch Acc: 88.28
[Train] Epoch: 4 [178432/387873]    Loss: 0.001668   Batch Acc: 91.41
[Train] Epoch: 4 [178560/387873]    Loss: 0.001652   Batch Acc: 90.62
[Train] Epoch: 4 [178688/387873]    Loss: 0.002123   Batch Acc: 88.28
[Train] Epoch: 4 [178816/387873]    Loss: 0.002036   Batch Acc: 89.84
[Train] Epoch: 4 [178944/387873]    Loss: 0.001855   Batch Acc: 89.06
[Train] Epoch: 4 [179072/387873]    Loss: 0.001729   Batch Acc: 90.62
[Train] Epoch: 4 [179200/387873]    Loss: 0.001904   Batch Acc: 91.41
[Train] Epoch: 4 [179328/387873]    Loss: 0.002036   Batch Acc: 91.41
[Train] Epoch: 4 [179456/387873]    Loss: 0.001722   Batch Acc: 91.41
[Train] Epoch: 4 [179584/387873]    Loss: 0.002125   Batch Acc: 89.06
[Train] Epoch: 4 [179712/387873]    Loss: 0.002465   Batch Acc: 82.81
[Train] Epoch: 4 [179840/387873]    Loss: 0.001557   Batch Acc: 96.88
[Train] Epoch: 4 [179968/387873]    Loss: 0.002815   Batch Acc: 88.28
[Train] Epoch: 4 [180096/387873]    Loss: 0.002081   Batch Acc: 87.50
[Train] Epoch: 4 [180224/387873]    Loss: 0.001691   Batch Acc: 91.41
[Train] Epoch: 4 [180352/387873]    Loss: 0.002217   Batch Acc: 84.38
[Train] Epoch: 4 [180480/387873]    Loss: 0.002432   Batch Acc: 84.38
[Train] Epoch: 4 [180608/387873]    Loss: 0.002362   Batch Acc: 85.16
[Train] Epoch: 4 [180736/387873]    Loss: 0.001736   Batch Acc: 93.75
[Train] Epoch: 4 [180864/387873]    Loss: 0.002232   Batch Acc: 86.72
[Train] Epoch: 4 [180992/387873]    Loss: 0.001579   Batch Acc: 90.62
[Train] Epoch: 4 [181120/387873]    Loss: 0.001836   Batch Acc: 91.41
[Train] Epoch: 4 [181248/387873]    Loss: 0.002053   Batch Acc: 88.28
[Train] Epoch: 4 [181376/387873]    Loss: 0.002038   Batch Acc: 89.06
[Train] Epoch: 4 [181504/387873]    Loss: 0.001847   Batch Acc: 89.06
[Train] Epoch: 4 [181632/387873]    Loss: 0.001731   Batch Acc: 90.62
[Train] Epoch: 4 [181760/387873]    Loss: 0.001363   Batch Acc: 95.31
[Train] Epoch: 4 [181888/387873]    Loss: 0.002066   Batch Acc: 89.06
[Train] Epoch: 4 [182016/387873]    Loss: 0.001874   Batch Acc: 89.84
[Train] Epoch: 4 [182144/387873]    Loss: 0.002070   Batch Acc: 87.50
[Train] Epoch: 4 [182272/387873]    Loss: 0.002225   Batch Acc: 89.06
[Train] Epoch: 4 [182400/387873]    Loss: 0.002194   Batch Acc: 87.50
[Train] Epoch: 4 [182528/387873]    Loss: 0.001641   Batch Acc: 89.84
[Train] Epoch: 4 [182656/387873]    Loss: 0.002379   Batch Acc: 86.72
[Train] Epoch: 4 [182784/387873]    Loss: 0.001521   Batch Acc: 91.41
[Train] Epoch: 4 [182912/387873]    Loss: 0.002555   Batch Acc: 87.50
[Train] Epoch: 4 [183040/387873]    Loss: 0.002325   Batch Acc: 89.84
[Train] Epoch: 4 [183168/387873]    Loss: 0.002500   Batch Acc: 85.94
[Train] Epoch: 4 [183296/387873]    Loss: 0.002038   Batch Acc: 90.62
[Train] Epoch: 4 [183424/387873]    Loss: 0.001911   Batch Acc: 89.06
[Train] Epoch: 4 [183552/387873]    Loss: 0.001693   Batch Acc: 90.62
[Train] Epoch: 4 [183680/387873]    Loss: 0.001886   Batch Acc: 89.84
[Train] Epoch: 4 [183808/387873]    Loss: 0.001842   Batch Acc: 92.19
[Train] Epoch: 4 [183936/387873]    Loss: 0.001742   Batch Acc: 90.62
[Train] Epoch: 4 [184064/387873]    Loss: 0.002624   Batch Acc: 85.16
[Train] Epoch: 4 [184192/387873]    Loss: 0.001797   Batch Acc: 88.28
[Train] Epoch: 4 [184320/387873]    Loss: 0.001872   Batch Acc: 88.28
[Train] Epoch: 4 [184448/387873]    Loss: 0.001453   Batch Acc: 92.97
[Train] Epoch: 4 [184576/387873]    Loss: 0.001962   Batch Acc: 90.62
[Train] Epoch: 4 [184704/387873]    Loss: 0.002351   Batch Acc: 88.28
[Train] Epoch: 4 [184832/387873]    Loss: 0.002087   Batch Acc: 89.06
[Train] Epoch: 4 [184960/387873]    Loss: 0.001749   Batch Acc: 91.41
[Train] Epoch: 4 [185088/387873]    Loss: 0.001907   Batch Acc: 89.84
[Train] Epoch: 4 [185216/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 4 [185344/387873]    Loss: 0.001725   Batch Acc: 91.41
[Train] Epoch: 4 [185472/387873]    Loss: 0.002356   Batch Acc: 87.50
[Train] Epoch: 4 [185600/387873]    Loss: 0.001494   Batch Acc: 94.53
[Train] Epoch: 4 [185728/387873]    Loss: 0.002092   Batch Acc: 89.84
[Train] Epoch: 4 [185856/387873]    Loss: 0.001419   Batch Acc: 93.75
[Train] Epoch: 4 [185984/387873]    Loss: 0.001570   Batch Acc: 92.97
[Train] Epoch: 4 [186112/387873]    Loss: 0.002093   Batch Acc: 85.94
[Train] Epoch: 4 [186240/387873]    Loss: 0.002207   Batch Acc: 89.84
[Train] Epoch: 4 [186368/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 4 [186496/387873]    Loss: 0.001975   Batch Acc: 92.19
[Train] Epoch: 4 [186624/387873]    Loss: 0.001883   Batch Acc: 89.84
[Train] Epoch: 4 [186752/387873]    Loss: 0.001988   Batch Acc: 88.28
[Train] Epoch: 4 [186880/387873]    Loss: 0.001963   Batch Acc: 90.62
[Train] Epoch: 4 [187008/387873]    Loss: 0.002546   Batch Acc: 85.94
[Train] Epoch: 4 [187136/387873]    Loss: 0.002067   Batch Acc: 88.28
[Train] Epoch: 4 [187264/387873]    Loss: 0.002110   Batch Acc: 89.06
[Train] Epoch: 4 [187392/387873]    Loss: 0.001898   Batch Acc: 88.28
[Train] Epoch: 4 [187520/387873]    Loss: 0.001877   Batch Acc: 89.06
[Train] Epoch: 4 [187648/387873]    Loss: 0.002161   Batch Acc: 86.72
[Train] Epoch: 4 [187776/387873]    Loss: 0.002306   Batch Acc: 85.16
[Train] Epoch: 4 [187904/387873]    Loss: 0.001680   Batch Acc: 92.19
[Train] Epoch: 4 [188032/387873]    Loss: 0.001902   Batch Acc: 90.62
[Train] Epoch: 4 [188160/387873]    Loss: 0.002050   Batch Acc: 88.28
[Train] Epoch: 4 [188288/387873]    Loss: 0.001713   Batch Acc: 90.62
[Train] Epoch: 4 [188416/387873]    Loss: 0.002080   Batch Acc: 87.50
[Train] Epoch: 4 [188544/387873]    Loss: 0.001661   Batch Acc: 91.41
[Train] Epoch: 4 [188672/387873]    Loss: 0.002464   Batch Acc: 85.94
[Train] Epoch: 4 [188800/387873]    Loss: 0.002523   Batch Acc: 85.94
[Train] Epoch: 4 [188928/387873]    Loss: 0.001622   Batch Acc: 93.75
[Train] Epoch: 4 [189056/387873]    Loss: 0.002363   Batch Acc: 85.16
[Train] Epoch: 4 [189184/387873]    Loss: 0.001700   Batch Acc: 92.97
[Train] Epoch: 4 [189312/387873]    Loss: 0.002187   Batch Acc: 89.84
[Train] Epoch: 4 [189440/387873]    Loss: 0.002024   Batch Acc: 86.72
[Train] Epoch: 4 [189568/387873]    Loss: 0.002367   Batch Acc: 88.28
[Train] Epoch: 4 [189696/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 4 [189824/387873]    Loss: 0.002199   Batch Acc: 85.16
[Train] Epoch: 4 [189952/387873]    Loss: 0.001539   Batch Acc: 92.19
[Train] Epoch: 4 [190080/387873]    Loss: 0.001604   Batch Acc: 93.75
[Train] Epoch: 4 [190208/387873]    Loss: 0.001717   Batch Acc: 92.97
[Train] Epoch: 4 [190336/387873]    Loss: 0.001763   Batch Acc: 93.75
[Train] Epoch: 4 [190464/387873]    Loss: 0.001923   Batch Acc: 89.06
[Train] Epoch: 4 [190592/387873]    Loss: 0.002443   Batch Acc: 85.16
[Train] Epoch: 4 [190720/387873]    Loss: 0.001676   Batch Acc: 91.41
[Train] Epoch: 4 [190848/387873]    Loss: 0.001566   Batch Acc: 92.97
[Train] Epoch: 4 [190976/387873]    Loss: 0.001836   Batch Acc: 90.62
[Train] Epoch: 4 [191104/387873]    Loss: 0.001881   Batch Acc: 89.84
[Train] Epoch: 4 [191232/387873]    Loss: 0.001491   Batch Acc: 94.53
[Train] Epoch: 4 [191360/387873]    Loss: 0.001922   Batch Acc: 90.62
[Train] Epoch: 4 [191488/387873]    Loss: 0.002118   Batch Acc: 88.28
[Train] Epoch: 4 [191616/387873]    Loss: 0.002299   Batch Acc: 86.72
[Train] Epoch: 4 [191744/387873]    Loss: 0.002104   Batch Acc: 87.50
[Train] Epoch: 4 [191872/387873]    Loss: 0.002077   Batch Acc: 89.84
[Train] Epoch: 4 [192000/387873]    Loss: 0.001584   Batch Acc: 94.53
[Train] Epoch: 4 [192128/387873]    Loss: 0.002246   Batch Acc: 86.72
[Train] Epoch: 4 [192256/387873]    Loss: 0.002226   Batch Acc: 89.06
[Train] Epoch: 4 [192384/387873]    Loss: 0.001794   Batch Acc: 92.97
[Train] Epoch: 4 [192512/387873]    Loss: 0.002004   Batch Acc: 89.84
[Train] Epoch: 4 [192640/387873]    Loss: 0.002018   Batch Acc: 89.06
[Train] Epoch: 4 [192768/387873]    Loss: 0.002255   Batch Acc: 89.06
[Train] Epoch: 4 [192896/387873]    Loss: 0.001551   Batch Acc: 91.41
[Train] Epoch: 4 [193024/387873]    Loss: 0.001837   Batch Acc: 90.62
[Train] Epoch: 4 [193152/387873]    Loss: 0.002169   Batch Acc: 86.72
[Train] Epoch: 4 [193280/387873]    Loss: 0.002037   Batch Acc: 91.41
[Train] Epoch: 4 [193408/387873]    Loss: 0.001383   Batch Acc: 94.53
[Train] Epoch: 4 [193536/387873]    Loss: 0.001384   Batch Acc: 94.53
[Train] Epoch: 4 [193664/387873]    Loss: 0.002170   Batch Acc: 89.84
[Train] Epoch: 4 [193792/387873]    Loss: 0.002103   Batch Acc: 88.28
[Train] Epoch: 4 [193920/387873]    Loss: 0.001384   Batch Acc: 94.53
[Train] Epoch: 4 [194048/387873]    Loss: 0.002995   Batch Acc: 83.59
[Train] Epoch: 4 [194176/387873]    Loss: 0.002196   Batch Acc: 87.50
[Train] Epoch: 4 [194304/387873]    Loss: 0.003120   Batch Acc: 82.03
[Train] Epoch: 4 [194432/387873]    Loss: 0.002299   Batch Acc: 88.28
[Train] Epoch: 4 [194560/387873]    Loss: 0.002601   Batch Acc: 87.50
[Train] Epoch: 4 [194688/387873]    Loss: 0.002009   Batch Acc: 88.28
[Train] Epoch: 4 [194816/387873]    Loss: 0.002570   Batch Acc: 85.94
[Train] Epoch: 4 [194944/387873]    Loss: 0.001458   Batch Acc: 95.31
[Train] Epoch: 4 [195072/387873]    Loss: 0.002324   Batch Acc: 89.06
[Train] Epoch: 4 [195200/387873]    Loss: 0.001819   Batch Acc: 90.62
[Train] Epoch: 4 [195328/387873]    Loss: 0.001689   Batch Acc: 94.53
[Train] Epoch: 4 [195456/387873]    Loss: 0.002415   Batch Acc: 87.50
[Train] Epoch: 4 [195584/387873]    Loss: 0.002540   Batch Acc: 87.50
[Train] Epoch: 4 [195712/387873]    Loss: 0.001919   Batch Acc: 90.62
[Train] Epoch: 4 [195840/387873]    Loss: 0.001657   Batch Acc: 92.97
[Train] Epoch: 4 [195968/387873]    Loss: 0.002174   Batch Acc: 88.28
[Train] Epoch: 4 [196096/387873]    Loss: 0.002419   Batch Acc: 85.94
[Train] Epoch: 4 [196224/387873]    Loss: 0.001813   Batch Acc: 90.62
[Train] Epoch: 4 [196352/387873]    Loss: 0.001762   Batch Acc: 91.41
[Train] Epoch: 4 [196480/387873]    Loss: 0.002005   Batch Acc: 89.06
[Train] Epoch: 4 [196608/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 4 [196736/387873]    Loss: 0.001784   Batch Acc: 90.62
[Train] Epoch: 4 [196864/387873]    Loss: 0.002557   Batch Acc: 89.06
[Train] Epoch: 4 [196992/387873]    Loss: 0.001891   Batch Acc: 89.06
[Train] Epoch: 4 [197120/387873]    Loss: 0.001984   Batch Acc: 90.62
[Train] Epoch: 4 [197248/387873]    Loss: 0.001574   Batch Acc: 92.97
[Train] Epoch: 4 [197376/387873]    Loss: 0.002300   Batch Acc: 87.50
[Train] Epoch: 4 [197504/387873]    Loss: 0.002273   Batch Acc: 87.50
[Train] Epoch: 4 [197632/387873]    Loss: 0.001990   Batch Acc: 88.28
[Train] Epoch: 4 [197760/387873]    Loss: 0.001642   Batch Acc: 94.53
[Train] Epoch: 4 [197888/387873]    Loss: 0.002144   Batch Acc: 88.28
[Train] Epoch: 4 [198016/387873]    Loss: 0.001884   Batch Acc: 88.28
[Train] Epoch: 4 [198144/387873]    Loss: 0.001578   Batch Acc: 90.62
[Train] Epoch: 4 [198272/387873]    Loss: 0.002184   Batch Acc: 87.50
[Train] Epoch: 4 [198400/387873]    Loss: 0.001281   Batch Acc: 95.31
[Train] Epoch: 4 [198528/387873]    Loss: 0.002107   Batch Acc: 88.28
[Train] Epoch: 4 [198656/387873]    Loss: 0.001702   Batch Acc: 91.41
[Train] Epoch: 4 [198784/387873]    Loss: 0.001925   Batch Acc: 85.16
[Train] Epoch: 4 [198912/387873]    Loss: 0.002631   Batch Acc: 84.38
[Train] Epoch: 4 [199040/387873]    Loss: 0.001537   Batch Acc: 92.97
[Train] Epoch: 4 [199168/387873]    Loss: 0.001838   Batch Acc: 90.62
[Train] Epoch: 4 [199296/387873]    Loss: 0.002289   Batch Acc: 85.94
[Train] Epoch: 4 [199424/387873]    Loss: 0.001912   Batch Acc: 90.62
[Train] Epoch: 4 [199552/387873]    Loss: 0.002429   Batch Acc: 86.72
[Train] Epoch: 4 [199680/387873]    Loss: 0.001647   Batch Acc: 92.19
[Train] Epoch: 4 [199808/387873]    Loss: 0.002310   Batch Acc: 87.50
[Train] Epoch: 4 [199936/387873]    Loss: 0.001903   Batch Acc: 89.06
[Train] Epoch: 4 [200064/387873]    Loss: 0.001447   Batch Acc: 92.97
[Train] Epoch: 4 [200192/387873]    Loss: 0.002104   Batch Acc: 89.06
[Train] Epoch: 4 [200320/387873]    Loss: 0.002019   Batch Acc: 90.62
[Train] Epoch: 4 [200448/387873]    Loss: 0.002061   Batch Acc: 86.72
[Train] Epoch: 4 [200576/387873]    Loss: 0.001682   Batch Acc: 92.97
[Train] Epoch: 4 [200704/387873]    Loss: 0.002114   Batch Acc: 84.38
[Train] Epoch: 4 [200832/387873]    Loss: 0.002356   Batch Acc: 87.50
[Train] Epoch: 4 [200960/387873]    Loss: 0.002076   Batch Acc: 88.28
[Train] Epoch: 4 [201088/387873]    Loss: 0.002062   Batch Acc: 86.72
[Train] Epoch: 4 [201216/387873]    Loss: 0.001545   Batch Acc: 93.75
[Train] Epoch: 4 [201344/387873]    Loss: 0.001726   Batch Acc: 88.28
[Train] Epoch: 4 [201472/387873]    Loss: 0.002083   Batch Acc: 89.06
[Train] Epoch: 4 [201600/387873]    Loss: 0.002191   Batch Acc: 89.84
[Train] Epoch: 4 [201728/387873]    Loss: 0.001474   Batch Acc: 91.41
[Train] Epoch: 4 [201856/387873]    Loss: 0.001946   Batch Acc: 90.62
[Train] Epoch: 4 [201984/387873]    Loss: 0.002335   Batch Acc: 89.06
[Train] Epoch: 4 [202112/387873]    Loss: 0.002879   Batch Acc: 85.94
[Train] Epoch: 4 [202240/387873]    Loss: 0.002255   Batch Acc: 85.94
[Train] Epoch: 4 [202368/387873]    Loss: 0.002101   Batch Acc: 90.62
[Train] Epoch: 4 [202496/387873]    Loss: 0.001782   Batch Acc: 91.41
[Train] Epoch: 4 [202624/387873]    Loss: 0.001534   Batch Acc: 91.41
[Train] Epoch: 4 [202752/387873]    Loss: 0.001837   Batch Acc: 89.06
[Train] Epoch: 4 [202880/387873]    Loss: 0.001896   Batch Acc: 89.84
[Train] Epoch: 4 [203008/387873]    Loss: 0.001731   Batch Acc: 90.62
[Train] Epoch: 4 [203136/387873]    Loss: 0.001956   Batch Acc: 91.41
[Train] Epoch: 4 [203264/387873]    Loss: 0.002126   Batch Acc: 90.62
[Train] Epoch: 4 [203392/387873]    Loss: 0.001576   Batch Acc: 93.75
[Train] Epoch: 4 [203520/387873]    Loss: 0.002467   Batch Acc: 85.94
[Train] Epoch: 4 [203648/387873]    Loss: 0.002322   Batch Acc: 87.50
[Train] Epoch: 4 [203776/387873]    Loss: 0.001545   Batch Acc: 93.75
[Train] Epoch: 4 [203904/387873]    Loss: 0.001915   Batch Acc: 87.50
[Train] Epoch: 4 [204032/387873]    Loss: 0.002352   Batch Acc: 85.16
[Train] Epoch: 4 [204160/387873]    Loss: 0.002107   Batch Acc: 90.62
[Train] Epoch: 4 [204288/387873]    Loss: 0.001849   Batch Acc: 89.06
[Train] Epoch: 4 [204416/387873]    Loss: 0.001758   Batch Acc: 91.41
[Train] Epoch: 4 [204544/387873]    Loss: 0.002767   Batch Acc: 84.38
[Train] Epoch: 4 [204672/387873]    Loss: 0.002155   Batch Acc: 85.94
[Train] Epoch: 4 [204800/387873]    Loss: 0.002117   Batch Acc: 88.28
[Train] Epoch: 4 [204928/387873]    Loss: 0.001493   Batch Acc: 91.41
[Train] Epoch: 4 [205056/387873]    Loss: 0.001926   Batch Acc: 90.62
[Train] Epoch: 4 [205184/387873]    Loss: 0.002100   Batch Acc: 89.06
[Train] Epoch: 4 [205312/387873]    Loss: 0.001757   Batch Acc: 92.97
[Train] Epoch: 4 [205440/387873]    Loss: 0.002032   Batch Acc: 90.62
[Train] Epoch: 4 [205568/387873]    Loss: 0.002042   Batch Acc: 87.50
[Train] Epoch: 4 [205696/387873]    Loss: 0.001704   Batch Acc: 93.75
[Train] Epoch: 4 [205824/387873]    Loss: 0.002465   Batch Acc: 86.72
[Train] Epoch: 4 [205952/387873]    Loss: 0.001588   Batch Acc: 92.97
[Train] Epoch: 4 [206080/387873]    Loss: 0.001904   Batch Acc: 90.62
[Train] Epoch: 4 [206208/387873]    Loss: 0.002402   Batch Acc: 86.72
[Train] Epoch: 4 [206336/387873]    Loss: 0.001964   Batch Acc: 89.84
[Train] Epoch: 4 [206464/387873]    Loss: 0.002364   Batch Acc: 85.16
[Train] Epoch: 4 [206592/387873]    Loss: 0.001669   Batch Acc: 91.41
[Train] Epoch: 4 [206720/387873]    Loss: 0.002030   Batch Acc: 89.84
[Train] Epoch: 4 [206848/387873]    Loss: 0.002112   Batch Acc: 89.06
[Train] Epoch: 4 [206976/387873]    Loss: 0.001691   Batch Acc: 89.84
[Train] Epoch: 4 [207104/387873]    Loss: 0.002641   Batch Acc: 88.28
[Train] Epoch: 4 [207232/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 4 [207360/387873]    Loss: 0.002370   Batch Acc: 85.94
[Train] Epoch: 4 [207488/387873]    Loss: 0.001919   Batch Acc: 89.84
[Train] Epoch: 4 [207616/387873]    Loss: 0.002649   Batch Acc: 86.72
[Train] Epoch: 4 [207744/387873]    Loss: 0.001960   Batch Acc: 89.06
[Train] Epoch: 4 [207872/387873]    Loss: 0.003245   Batch Acc: 83.59
[Train] Epoch: 4 [208000/387873]    Loss: 0.002621   Batch Acc: 85.94
[Train] Epoch: 4 [208128/387873]    Loss: 0.001890   Batch Acc: 89.84
[Train] Epoch: 4 [208256/387873]    Loss: 0.002141   Batch Acc: 91.41
[Train] Epoch: 4 [208384/387873]    Loss: 0.002117   Batch Acc: 87.50
[Train] Epoch: 4 [208512/387873]    Loss: 0.002427   Batch Acc: 88.28
[Train] Epoch: 4 [208640/387873]    Loss: 0.001507   Batch Acc: 93.75
[Train] Epoch: 4 [208768/387873]    Loss: 0.002051   Batch Acc: 89.06
[Train] Epoch: 4 [208896/387873]    Loss: 0.001710   Batch Acc: 92.19
[Train] Epoch: 4 [209024/387873]    Loss: 0.002353   Batch Acc: 85.94
[Train] Epoch: 4 [209152/387873]    Loss: 0.002450   Batch Acc: 88.28
[Train] Epoch: 4 [209280/387873]    Loss: 0.001707   Batch Acc: 92.97
[Train] Epoch: 4 [209408/387873]    Loss: 0.002021   Batch Acc: 90.62
[Train] Epoch: 4 [209536/387873]    Loss: 0.002242   Batch Acc: 88.28
[Train] Epoch: 4 [209664/387873]    Loss: 0.002205   Batch Acc: 92.19
[Train] Epoch: 4 [209792/387873]    Loss: 0.001964   Batch Acc: 91.41
[Train] Epoch: 4 [209920/387873]    Loss: 0.002278   Batch Acc: 89.06
[Train] Epoch: 4 [210048/387873]    Loss: 0.002716   Batch Acc: 82.81
[Train] Epoch: 4 [210176/387873]    Loss: 0.002320   Batch Acc: 84.38
[Train] Epoch: 4 [210304/387873]    Loss: 0.001775   Batch Acc: 92.19
[Train] Epoch: 4 [210432/387873]    Loss: 0.002033   Batch Acc: 88.28
[Train] Epoch: 4 [210560/387873]    Loss: 0.001767   Batch Acc: 91.41
[Train] Epoch: 4 [210688/387873]    Loss: 0.001251   Batch Acc: 96.88
[Train] Epoch: 4 [210816/387873]    Loss: 0.002258   Batch Acc: 89.84
[Train] Epoch: 4 [210944/387873]    Loss: 0.002616   Batch Acc: 83.59
[Train] Epoch: 4 [211072/387873]    Loss: 0.002252   Batch Acc: 87.50
[Train] Epoch: 4 [211200/387873]    Loss: 0.001489   Batch Acc: 90.62
[Train] Epoch: 4 [211328/387873]    Loss: 0.002165   Batch Acc: 87.50
[Train] Epoch: 4 [211456/387873]    Loss: 0.001972   Batch Acc: 92.19
[Train] Epoch: 4 [211584/387873]    Loss: 0.001706   Batch Acc: 93.75
[Train] Epoch: 4 [211712/387873]    Loss: 0.001914   Batch Acc: 90.62
[Train] Epoch: 4 [211840/387873]    Loss: 0.001837   Batch Acc: 88.28
[Train] Epoch: 4 [211968/387873]    Loss: 0.002219   Batch Acc: 83.59
[Train] Epoch: 4 [212096/387873]    Loss: 0.002553   Batch Acc: 83.59
[Train] Epoch: 4 [212224/387873]    Loss: 0.001890   Batch Acc: 90.62
[Train] Epoch: 4 [212352/387873]    Loss: 0.001860   Batch Acc: 87.50
[Train] Epoch: 4 [212480/387873]    Loss: 0.002588   Batch Acc: 89.06
[Train] Epoch: 4 [212608/387873]    Loss: 0.002027   Batch Acc: 89.84
[Train] Epoch: 4 [212736/387873]    Loss: 0.001748   Batch Acc: 90.62
[Train] Epoch: 4 [212864/387873]    Loss: 0.002352   Batch Acc: 89.06
[Train] Epoch: 4 [212992/387873]    Loss: 0.002215   Batch Acc: 88.28
[Train] Epoch: 4 [213120/387873]    Loss: 0.001983   Batch Acc: 87.50
[Train] Epoch: 4 [213248/387873]    Loss: 0.002370   Batch Acc: 82.81
[Train] Epoch: 4 [213376/387873]    Loss: 0.002154   Batch Acc: 87.50
[Train] Epoch: 4 [213504/387873]    Loss: 0.001840   Batch Acc: 92.19
[Train] Epoch: 4 [213632/387873]    Loss: 0.001849   Batch Acc: 91.41
[Train] Epoch: 4 [213760/387873]    Loss: 0.001727   Batch Acc: 91.41
[Train] Epoch: 4 [213888/387873]    Loss: 0.001615   Batch Acc: 90.62
[Train] Epoch: 4 [214016/387873]    Loss: 0.002855   Batch Acc: 84.38
[Train] Epoch: 4 [214144/387873]    Loss: 0.001759   Batch Acc: 89.84
[Train] Epoch: 4 [214272/387873]    Loss: 0.001649   Batch Acc: 91.41
[Train] Epoch: 4 [214400/387873]    Loss: 0.002721   Batch Acc: 81.25
[Train] Epoch: 4 [214528/387873]    Loss: 0.001955   Batch Acc: 85.94
[Train] Epoch: 4 [214656/387873]    Loss: 0.001869   Batch Acc: 88.28
[Train] Epoch: 4 [214784/387873]    Loss: 0.003177   Batch Acc: 82.81
[Train] Epoch: 4 [214912/387873]    Loss: 0.002314   Batch Acc: 88.28
[Train] Epoch: 4 [215040/387873]    Loss: 0.001530   Batch Acc: 92.19
[Train] Epoch: 4 [215168/387873]    Loss: 0.001801   Batch Acc: 91.41
[Train] Epoch: 4 [215296/387873]    Loss: 0.001843   Batch Acc: 89.06
[Train] Epoch: 4 [215424/387873]    Loss: 0.001855   Batch Acc: 90.62
[Train] Epoch: 4 [215552/387873]    Loss: 0.003081   Batch Acc: 83.59
[Train] Epoch: 4 [215680/387873]    Loss: 0.001975   Batch Acc: 87.50
[Train] Epoch: 4 [215808/387873]    Loss: 0.001910   Batch Acc: 90.62
[Train] Epoch: 4 [215936/387873]    Loss: 0.002157   Batch Acc: 85.94
[Train] Epoch: 4 [216064/387873]    Loss: 0.002329   Batch Acc: 89.06
[Train] Epoch: 4 [216192/387873]    Loss: 0.001238   Batch Acc: 96.09
[Train] Epoch: 4 [216320/387873]    Loss: 0.001866   Batch Acc: 90.62
[Train] Epoch: 4 [216448/387873]    Loss: 0.002672   Batch Acc: 85.94
[Train] Epoch: 4 [216576/387873]    Loss: 0.002145   Batch Acc: 89.06
[Train] Epoch: 4 [216704/387873]    Loss: 0.001557   Batch Acc: 91.41
[Train] Epoch: 4 [216832/387873]    Loss: 0.002010   Batch Acc: 89.84
[Train] Epoch: 4 [216960/387873]    Loss: 0.002253   Batch Acc: 89.06
[Train] Epoch: 4 [217088/387873]    Loss: 0.001963   Batch Acc: 86.72
[Train] Epoch: 4 [217216/387873]    Loss: 0.002287   Batch Acc: 87.50
[Train] Epoch: 4 [217344/387873]    Loss: 0.001906   Batch Acc: 89.06
[Train] Epoch: 4 [217472/387873]    Loss: 0.001805   Batch Acc: 90.62
[Train] Epoch: 4 [217600/387873]    Loss: 0.002486   Batch Acc: 85.16
[Train] Epoch: 4 [217728/387873]    Loss: 0.001615   Batch Acc: 93.75
[Train] Epoch: 4 [217856/387873]    Loss: 0.001863   Batch Acc: 87.50
[Train] Epoch: 4 [217984/387873]    Loss: 0.002196   Batch Acc: 92.19
[Train] Epoch: 4 [218112/387873]    Loss: 0.002076   Batch Acc: 87.50
[Train] Epoch: 4 [218240/387873]    Loss: 0.001940   Batch Acc: 89.84
[Train] Epoch: 4 [218368/387873]    Loss: 0.001405   Batch Acc: 92.97
[Train] Epoch: 4 [218496/387873]    Loss: 0.001865   Batch Acc: 89.84
[Train] Epoch: 4 [218624/387873]    Loss: 0.001649   Batch Acc: 92.19
[Train] Epoch: 4 [218752/387873]    Loss: 0.002127   Batch Acc: 87.50
[Train] Epoch: 4 [218880/387873]    Loss: 0.002103   Batch Acc: 90.62
[Train] Epoch: 4 [219008/387873]    Loss: 0.002152   Batch Acc: 88.28
[Train] Epoch: 4 [219136/387873]    Loss: 0.001853   Batch Acc: 89.84
[Train] Epoch: 4 [219264/387873]    Loss: 0.001677   Batch Acc: 89.84
[Train] Epoch: 4 [219392/387873]    Loss: 0.001633   Batch Acc: 90.62
[Train] Epoch: 4 [219520/387873]    Loss: 0.001331   Batch Acc: 95.31
[Train] Epoch: 4 [219648/387873]    Loss: 0.002471   Batch Acc: 85.16
[Train] Epoch: 4 [219776/387873]    Loss: 0.002106   Batch Acc: 88.28
[Train] Epoch: 4 [219904/387873]    Loss: 0.001756   Batch Acc: 89.84
[Train] Epoch: 4 [220032/387873]    Loss: 0.001797   Batch Acc: 92.97
[Train] Epoch: 4 [220160/387873]    Loss: 0.002236   Batch Acc: 86.72
[Train] Epoch: 4 [220288/387873]    Loss: 0.001734   Batch Acc: 93.75
[Train] Epoch: 4 [220416/387873]    Loss: 0.002171   Batch Acc: 88.28
[Train] Epoch: 4 [220544/387873]    Loss: 0.001701   Batch Acc: 95.31
[Train] Epoch: 4 [220672/387873]    Loss: 0.001943   Batch Acc: 89.06
[Train] Epoch: 4 [220800/387873]    Loss: 0.002302   Batch Acc: 86.72
[Train] Epoch: 4 [220928/387873]    Loss: 0.001930   Batch Acc: 88.28
[Train] Epoch: 4 [221056/387873]    Loss: 0.002681   Batch Acc: 82.03
[Train] Epoch: 4 [221184/387873]    Loss: 0.002268   Batch Acc: 87.50
[Train] Epoch: 4 [221312/387873]    Loss: 0.002452   Batch Acc: 86.72
[Train] Epoch: 4 [221440/387873]    Loss: 0.002195   Batch Acc: 85.94
[Train] Epoch: 4 [221568/387873]    Loss: 0.002195   Batch Acc: 87.50
[Train] Epoch: 4 [221696/387873]    Loss: 0.001889   Batch Acc: 90.62
[Train] Epoch: 4 [221824/387873]    Loss: 0.002352   Batch Acc: 88.28
[Train] Epoch: 4 [221952/387873]    Loss: 0.001529   Batch Acc: 94.53
[Train] Epoch: 4 [222080/387873]    Loss: 0.001411   Batch Acc: 92.97
[Train] Epoch: 4 [222208/387873]    Loss: 0.001515   Batch Acc: 92.97
[Train] Epoch: 4 [222336/387873]    Loss: 0.001717   Batch Acc: 90.62
[Train] Epoch: 4 [222464/387873]    Loss: 0.001715   Batch Acc: 95.31
[Train] Epoch: 4 [222592/387873]    Loss: 0.002001   Batch Acc: 90.62
[Train] Epoch: 4 [222720/387873]    Loss: 0.001636   Batch Acc: 93.75
[Train] Epoch: 4 [222848/387873]    Loss: 0.002463   Batch Acc: 82.81
[Train] Epoch: 4 [222976/387873]    Loss: 0.001502   Batch Acc: 93.75
[Train] Epoch: 4 [223104/387873]    Loss: 0.001687   Batch Acc: 92.97
[Train] Epoch: 4 [223232/387873]    Loss: 0.001665   Batch Acc: 90.62
[Train] Epoch: 4 [223360/387873]    Loss: 0.001778   Batch Acc: 92.97
[Train] Epoch: 4 [223488/387873]    Loss: 0.001682   Batch Acc: 91.41
[Train] Epoch: 4 [223616/387873]    Loss: 0.002134   Batch Acc: 89.06
[Train] Epoch: 4 [223744/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 4 [223872/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 4 [224000/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 4 [224128/387873]    Loss: 0.002198   Batch Acc: 87.50
[Train] Epoch: 4 [224256/387873]    Loss: 0.001868   Batch Acc: 91.41
[Train] Epoch: 4 [224384/387873]    Loss: 0.001939   Batch Acc: 89.84
[Train] Epoch: 4 [224512/387873]    Loss: 0.002282   Batch Acc: 89.06
[Train] Epoch: 4 [224640/387873]    Loss: 0.002075   Batch Acc: 89.06
[Train] Epoch: 4 [224768/387873]    Loss: 0.002072   Batch Acc: 87.50
[Train] Epoch: 4 [224896/387873]    Loss: 0.002490   Batch Acc: 85.94
[Train] Epoch: 4 [225024/387873]    Loss: 0.001573   Batch Acc: 92.19
[Train] Epoch: 4 [225152/387873]    Loss: 0.001854   Batch Acc: 87.50
[Train] Epoch: 4 [225280/387873]    Loss: 0.002195   Batch Acc: 89.06
[Train] Epoch: 4 [225408/387873]    Loss: 0.002156   Batch Acc: 89.84
[Train] Epoch: 4 [225536/387873]    Loss: 0.001915   Batch Acc: 88.28
[Train] Epoch: 4 [225664/387873]    Loss: 0.002062   Batch Acc: 89.06
[Train] Epoch: 4 [225792/387873]    Loss: 0.001810   Batch Acc: 92.97
[Train] Epoch: 4 [225920/387873]    Loss: 0.001853   Batch Acc: 91.41
[Train] Epoch: 4 [226048/387873]    Loss: 0.002029   Batch Acc: 89.06
[Train] Epoch: 4 [226176/387873]    Loss: 0.001646   Batch Acc: 91.41
[Train] Epoch: 4 [226304/387873]    Loss: 0.001372   Batch Acc: 92.97
[Train] Epoch: 4 [226432/387873]    Loss: 0.001879   Batch Acc: 90.62
[Train] Epoch: 4 [226560/387873]    Loss: 0.001752   Batch Acc: 90.62
[Train] Epoch: 4 [226688/387873]    Loss: 0.002641   Batch Acc: 86.72
[Train] Epoch: 4 [226816/387873]    Loss: 0.001798   Batch Acc: 90.62
[Train] Epoch: 4 [226944/387873]    Loss: 0.002554   Batch Acc: 87.50
[Train] Epoch: 4 [227072/387873]    Loss: 0.002263   Batch Acc: 85.16
[Train] Epoch: 4 [227200/387873]    Loss: 0.001760   Batch Acc: 91.41
[Train] Epoch: 4 [227328/387873]    Loss: 0.002106   Batch Acc: 87.50
[Train] Epoch: 4 [227456/387873]    Loss: 0.001861   Batch Acc: 89.06
[Train] Epoch: 4 [227584/387873]    Loss: 0.001517   Batch Acc: 93.75
[Train] Epoch: 4 [227712/387873]    Loss: 0.002814   Batch Acc: 85.94
[Train] Epoch: 4 [227840/387873]    Loss: 0.001932   Batch Acc: 91.41
[Train] Epoch: 4 [227968/387873]    Loss: 0.002464   Batch Acc: 88.28
[Train] Epoch: 4 [228096/387873]    Loss: 0.002028   Batch Acc: 89.84
[Train] Epoch: 4 [228224/387873]    Loss: 0.001733   Batch Acc: 92.19
[Train] Epoch: 4 [228352/387873]    Loss: 0.001783   Batch Acc: 89.84
[Train] Epoch: 4 [228480/387873]    Loss: 0.001735   Batch Acc: 89.06
[Train] Epoch: 4 [228608/387873]    Loss: 0.002337   Batch Acc: 86.72
[Train] Epoch: 4 [228736/387873]    Loss: 0.002278   Batch Acc: 85.94
[Train] Epoch: 4 [228864/387873]    Loss: 0.002017   Batch Acc: 89.06
[Train] Epoch: 4 [228992/387873]    Loss: 0.001574   Batch Acc: 92.97
[Train] Epoch: 4 [229120/387873]    Loss: 0.002160   Batch Acc: 87.50
[Train] Epoch: 4 [229248/387873]    Loss: 0.001691   Batch Acc: 89.06
[Train] Epoch: 4 [229376/387873]    Loss: 0.002319   Batch Acc: 85.94
[Train] Epoch: 4 [229504/387873]    Loss: 0.001751   Batch Acc: 91.41
[Train] Epoch: 4 [229632/387873]    Loss: 0.002304   Batch Acc: 88.28
[Train] Epoch: 4 [229760/387873]    Loss: 0.001693   Batch Acc: 91.41
[Train] Epoch: 4 [229888/387873]    Loss: 0.002309   Batch Acc: 88.28
[Train] Epoch: 4 [230016/387873]    Loss: 0.002814   Batch Acc: 83.59
[Train] Epoch: 4 [230144/387873]    Loss: 0.001930   Batch Acc: 91.41
[Train] Epoch: 4 [230272/387873]    Loss: 0.001989   Batch Acc: 88.28
[Train] Epoch: 4 [230400/387873]    Loss: 0.001495   Batch Acc: 89.84
[Train] Epoch: 4 [230528/387873]    Loss: 0.001761   Batch Acc: 92.19
[Train] Epoch: 4 [230656/387873]    Loss: 0.002262   Batch Acc: 84.38
[Train] Epoch: 4 [230784/387873]    Loss: 0.001240   Batch Acc: 93.75
[Train] Epoch: 4 [230912/387873]    Loss: 0.001736   Batch Acc: 92.19
[Train] Epoch: 4 [231040/387873]    Loss: 0.002635   Batch Acc: 86.72
[Train] Epoch: 4 [231168/387873]    Loss: 0.002455   Batch Acc: 86.72
[Train] Epoch: 4 [231296/387873]    Loss: 0.002160   Batch Acc: 88.28
[Train] Epoch: 4 [231424/387873]    Loss: 0.001682   Batch Acc: 92.19
[Train] Epoch: 4 [231552/387873]    Loss: 0.002079   Batch Acc: 88.28
[Train] Epoch: 4 [231680/387873]    Loss: 0.001910   Batch Acc: 88.28
[Train] Epoch: 4 [231808/387873]    Loss: 0.002444   Batch Acc: 82.03
[Train] Epoch: 4 [231936/387873]    Loss: 0.002142   Batch Acc: 89.84
[Train] Epoch: 4 [232064/387873]    Loss: 0.001904   Batch Acc: 87.50
[Train] Epoch: 4 [232192/387873]    Loss: 0.001826   Batch Acc: 91.41
[Train] Epoch: 4 [232320/387873]    Loss: 0.001952   Batch Acc: 89.06
[Train] Epoch: 4 [232448/387873]    Loss: 0.002330   Batch Acc: 82.81
[Train] Epoch: 4 [232576/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 4 [232704/387873]    Loss: 0.001459   Batch Acc: 92.97
[Train] Epoch: 4 [232832/387873]    Loss: 0.001999   Batch Acc: 86.72
[Train] Epoch: 4 [232960/387873]    Loss: 0.001698   Batch Acc: 92.97
[Train] Epoch: 4 [233088/387873]    Loss: 0.002306   Batch Acc: 90.62
[Train] Epoch: 4 [233216/387873]    Loss: 0.002222   Batch Acc: 88.28
[Train] Epoch: 4 [233344/387873]    Loss: 0.001841   Batch Acc: 89.06
[Train] Epoch: 4 [233472/387873]    Loss: 0.001533   Batch Acc: 92.97
[Train] Epoch: 4 [233600/387873]    Loss: 0.002090   Batch Acc: 87.50
[Train] Epoch: 4 [233728/387873]    Loss: 0.001934   Batch Acc: 88.28
[Train] Epoch: 4 [233856/387873]    Loss: 0.002319   Batch Acc: 89.84
[Train] Epoch: 4 [233984/387873]    Loss: 0.002366   Batch Acc: 88.28
[Train] Epoch: 4 [234112/387873]    Loss: 0.001778   Batch Acc: 91.41
[Train] Epoch: 4 [234240/387873]    Loss: 0.001830   Batch Acc: 92.97
[Train] Epoch: 4 [234368/387873]    Loss: 0.001785   Batch Acc: 91.41
[Train] Epoch: 4 [234496/387873]    Loss: 0.002034   Batch Acc: 87.50
[Train] Epoch: 4 [234624/387873]    Loss: 0.002065   Batch Acc: 90.62
[Train] Epoch: 4 [234752/387873]    Loss: 0.001685   Batch Acc: 93.75
[Train] Epoch: 4 [234880/387873]    Loss: 0.002359   Batch Acc: 82.03
[Train] Epoch: 4 [235008/387873]    Loss: 0.001657   Batch Acc: 89.84
[Train] Epoch: 4 [235136/387873]    Loss: 0.001789   Batch Acc: 88.28
[Train] Epoch: 4 [235264/387873]    Loss: 0.001904   Batch Acc: 89.06
[Train] Epoch: 4 [235392/387873]    Loss: 0.002304   Batch Acc: 87.50
[Train] Epoch: 4 [235520/387873]    Loss: 0.002309   Batch Acc: 88.28
[Train] Epoch: 4 [235648/387873]    Loss: 0.001888   Batch Acc: 91.41
[Train] Epoch: 4 [235776/387873]    Loss: 0.002051   Batch Acc: 89.84
[Train] Epoch: 4 [235904/387873]    Loss: 0.001732   Batch Acc: 91.41
[Train] Epoch: 4 [236032/387873]    Loss: 0.001961   Batch Acc: 88.28
[Train] Epoch: 4 [236160/387873]    Loss: 0.002077   Batch Acc: 89.84
[Train] Epoch: 4 [236288/387873]    Loss: 0.001830   Batch Acc: 91.41
[Train] Epoch: 4 [236416/387873]    Loss: 0.001748   Batch Acc: 91.41
[Train] Epoch: 4 [236544/387873]    Loss: 0.001934   Batch Acc: 89.84
[Train] Epoch: 4 [236672/387873]    Loss: 0.002300   Batch Acc: 89.84
[Train] Epoch: 4 [236800/387873]    Loss: 0.001852   Batch Acc: 88.28
[Train] Epoch: 4 [236928/387873]    Loss: 0.002069   Batch Acc: 87.50
[Train] Epoch: 4 [237056/387873]    Loss: 0.001980   Batch Acc: 89.84
[Train] Epoch: 4 [237184/387873]    Loss: 0.002432   Batch Acc: 87.50
[Train] Epoch: 4 [237312/387873]    Loss: 0.002416   Batch Acc: 89.06
[Train] Epoch: 4 [237440/387873]    Loss: 0.001684   Batch Acc: 91.41
[Train] Epoch: 4 [237568/387873]    Loss: 0.001794   Batch Acc: 92.19
[Train] Epoch: 4 [237696/387873]    Loss: 0.001845   Batch Acc: 91.41
[Train] Epoch: 4 [237824/387873]    Loss: 0.001681   Batch Acc: 89.84
[Train] Epoch: 4 [237952/387873]    Loss: 0.002083   Batch Acc: 89.84
[Train] Epoch: 4 [238080/387873]    Loss: 0.001783   Batch Acc: 91.41
[Train] Epoch: 4 [238208/387873]    Loss: 0.002240   Batch Acc: 89.06
[Train] Epoch: 4 [238336/387873]    Loss: 0.001921   Batch Acc: 85.94
[Train] Epoch: 4 [238464/387873]    Loss: 0.002385   Batch Acc: 88.28
[Train] Epoch: 4 [238592/387873]    Loss: 0.002154   Batch Acc: 89.84
[Train] Epoch: 4 [238720/387873]    Loss: 0.002092   Batch Acc: 87.50
[Train] Epoch: 4 [238848/387873]    Loss: 0.001603   Batch Acc: 92.19
[Train] Epoch: 4 [238976/387873]    Loss: 0.002093   Batch Acc: 90.62
[Train] Epoch: 4 [239104/387873]    Loss: 0.002579   Batch Acc: 87.50
[Train] Epoch: 4 [239232/387873]    Loss: 0.001578   Batch Acc: 92.97
[Train] Epoch: 4 [239360/387873]    Loss: 0.001904   Batch Acc: 91.41
[Train] Epoch: 4 [239488/387873]    Loss: 0.002144   Batch Acc: 91.41
[Train] Epoch: 4 [239616/387873]    Loss: 0.002228   Batch Acc: 87.50
[Train] Epoch: 4 [239744/387873]    Loss: 0.001906   Batch Acc: 90.62
[Train] Epoch: 4 [239872/387873]    Loss: 0.001696   Batch Acc: 92.19
[Train] Epoch: 4 [240000/387873]    Loss: 0.002128   Batch Acc: 88.28
[Train] Epoch: 4 [240128/387873]    Loss: 0.001803   Batch Acc: 90.62
[Train] Epoch: 4 [240256/387873]    Loss: 0.002625   Batch Acc: 85.94
[Train] Epoch: 4 [240384/387873]    Loss: 0.001853   Batch Acc: 90.62
[Train] Epoch: 4 [240512/387873]    Loss: 0.001969   Batch Acc: 92.19
[Train] Epoch: 4 [240640/387873]    Loss: 0.001441   Batch Acc: 94.53
[Train] Epoch: 4 [240768/387873]    Loss: 0.001893   Batch Acc: 91.41
[Train] Epoch: 4 [240896/387873]    Loss: 0.002096   Batch Acc: 90.62
[Train] Epoch: 4 [241024/387873]    Loss: 0.001859   Batch Acc: 88.28
[Train] Epoch: 4 [241152/387873]    Loss: 0.002606   Batch Acc: 88.28
[Train] Epoch: 4 [241280/387873]    Loss: 0.002495   Batch Acc: 84.38
[Train] Epoch: 4 [241408/387873]    Loss: 0.001769   Batch Acc: 92.19
[Train] Epoch: 4 [241536/387873]    Loss: 0.002229   Batch Acc: 89.06
[Train] Epoch: 4 [241664/387873]    Loss: 0.002040   Batch Acc: 87.50
[Train] Epoch: 4 [241792/387873]    Loss: 0.001868   Batch Acc: 92.19
[Train] Epoch: 4 [241920/387873]    Loss: 0.002348   Batch Acc: 86.72
[Train] Epoch: 4 [242048/387873]    Loss: 0.001861   Batch Acc: 90.62
[Train] Epoch: 4 [242176/387873]    Loss: 0.001944   Batch Acc: 89.84
[Train] Epoch: 4 [242304/387873]    Loss: 0.002024   Batch Acc: 86.72
[Train] Epoch: 4 [242432/387873]    Loss: 0.001791   Batch Acc: 87.50
[Train] Epoch: 4 [242560/387873]    Loss: 0.001367   Batch Acc: 93.75
[Train] Epoch: 4 [242688/387873]    Loss: 0.001661   Batch Acc: 90.62
[Train] Epoch: 4 [242816/387873]    Loss: 0.001615   Batch Acc: 92.97
[Train] Epoch: 4 [242944/387873]    Loss: 0.001702   Batch Acc: 92.97
[Train] Epoch: 4 [243072/387873]    Loss: 0.001663   Batch Acc: 93.75
[Train] Epoch: 4 [243200/387873]    Loss: 0.001741   Batch Acc: 91.41
[Train] Epoch: 4 [243328/387873]    Loss: 0.002368   Batch Acc: 85.94
[Train] Epoch: 4 [243456/387873]    Loss: 0.002517   Batch Acc: 85.16
[Train] Epoch: 4 [243584/387873]    Loss: 0.001761   Batch Acc: 90.62
[Train] Epoch: 4 [243712/387873]    Loss: 0.001612   Batch Acc: 91.41
[Train] Epoch: 4 [243840/387873]    Loss: 0.001831   Batch Acc: 89.06
[Train] Epoch: 4 [243968/387873]    Loss: 0.002005   Batch Acc: 89.06
[Train] Epoch: 4 [244096/387873]    Loss: 0.002401   Batch Acc: 87.50
[Train] Epoch: 4 [244224/387873]    Loss: 0.002317   Batch Acc: 85.16
[Train] Epoch: 4 [244352/387873]    Loss: 0.001841   Batch Acc: 89.84
[Train] Epoch: 4 [244480/387873]    Loss: 0.002717   Batch Acc: 85.16
[Train] Epoch: 4 [244608/387873]    Loss: 0.002181   Batch Acc: 87.50
[Train] Epoch: 4 [244736/387873]    Loss: 0.001787   Batch Acc: 92.97
[Train] Epoch: 4 [244864/387873]    Loss: 0.001980   Batch Acc: 91.41
[Train] Epoch: 4 [244992/387873]    Loss: 0.001766   Batch Acc: 92.19
[Train] Epoch: 4 [245120/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 4 [245248/387873]    Loss: 0.001568   Batch Acc: 92.97
[Train] Epoch: 4 [245376/387873]    Loss: 0.002099   Batch Acc: 87.50
[Train] Epoch: 4 [245504/387873]    Loss: 0.002248   Batch Acc: 89.84
[Train] Epoch: 4 [245632/387873]    Loss: 0.002383   Batch Acc: 88.28
[Train] Epoch: 4 [245760/387873]    Loss: 0.002114   Batch Acc: 88.28
[Train] Epoch: 4 [245888/387873]    Loss: 0.001878   Batch Acc: 89.06
[Train] Epoch: 4 [246016/387873]    Loss: 0.003182   Batch Acc: 84.38
[Train] Epoch: 4 [246144/387873]    Loss: 0.002258   Batch Acc: 89.84
[Train] Epoch: 4 [246272/387873]    Loss: 0.002770   Batch Acc: 83.59
[Train] Epoch: 4 [246400/387873]    Loss: 0.001810   Batch Acc: 89.84
[Train] Epoch: 4 [246528/387873]    Loss: 0.001757   Batch Acc: 91.41
[Train] Epoch: 4 [246656/387873]    Loss: 0.002133   Batch Acc: 87.50
[Train] Epoch: 4 [246784/387873]    Loss: 0.002123   Batch Acc: 90.62
[Train] Epoch: 4 [246912/387873]    Loss: 0.002027   Batch Acc: 91.41
[Train] Epoch: 4 [247040/387873]    Loss: 0.002559   Batch Acc: 87.50
[Train] Epoch: 4 [247168/387873]    Loss: 0.001898   Batch Acc: 89.84
[Train] Epoch: 4 [247296/387873]    Loss: 0.002234   Batch Acc: 85.94
[Train] Epoch: 4 [247424/387873]    Loss: 0.001696   Batch Acc: 92.19
[Train] Epoch: 4 [247552/387873]    Loss: 0.001605   Batch Acc: 92.97
[Train] Epoch: 4 [247680/387873]    Loss: 0.001856   Batch Acc: 89.84
[Train] Epoch: 4 [247808/387873]    Loss: 0.001383   Batch Acc: 92.97
[Train] Epoch: 4 [247936/387873]    Loss: 0.002097   Batch Acc: 89.84
[Train] Epoch: 4 [248064/387873]    Loss: 0.001474   Batch Acc: 92.97
[Train] Epoch: 4 [248192/387873]    Loss: 0.002080   Batch Acc: 91.41
[Train] Epoch: 4 [248320/387873]    Loss: 0.001978   Batch Acc: 89.06
[Train] Epoch: 4 [248448/387873]    Loss: 0.001980   Batch Acc: 89.84
[Train] Epoch: 4 [248576/387873]    Loss: 0.001486   Batch Acc: 92.19
[Train] Epoch: 4 [248704/387873]    Loss: 0.001950   Batch Acc: 89.06
[Train] Epoch: 4 [248832/387873]    Loss: 0.001698   Batch Acc: 92.19
[Train] Epoch: 4 [248960/387873]    Loss: 0.001656   Batch Acc: 90.62
[Train] Epoch: 4 [249088/387873]    Loss: 0.001971   Batch Acc: 84.38
[Train] Epoch: 4 [249216/387873]    Loss: 0.002072   Batch Acc: 88.28
[Train] Epoch: 4 [249344/387873]    Loss: 0.001761   Batch Acc: 89.06
[Train] Epoch: 4 [249472/387873]    Loss: 0.001411   Batch Acc: 95.31
[Train] Epoch: 4 [249600/387873]    Loss: 0.002085   Batch Acc: 90.62
[Train] Epoch: 4 [249728/387873]    Loss: 0.001749   Batch Acc: 89.84
[Train] Epoch: 4 [249856/387873]    Loss: 0.002371   Batch Acc: 86.72
[Train] Epoch: 4 [249984/387873]    Loss: 0.002245   Batch Acc: 87.50
[Train] Epoch: 4 [250112/387873]    Loss: 0.002033   Batch Acc: 87.50
[Train] Epoch: 4 [250240/387873]    Loss: 0.001227   Batch Acc: 96.09
[Train] Epoch: 4 [250368/387873]    Loss: 0.002185   Batch Acc: 89.06
[Train] Epoch: 4 [250496/387873]    Loss: 0.001733   Batch Acc: 91.41
[Train] Epoch: 4 [250624/387873]    Loss: 0.002080   Batch Acc: 89.84
[Train] Epoch: 4 [250752/387873]    Loss: 0.002013   Batch Acc: 90.62
[Train] Epoch: 4 [250880/387873]    Loss: 0.002237   Batch Acc: 88.28
[Train] Epoch: 4 [251008/387873]    Loss: 0.001968   Batch Acc: 91.41
[Train] Epoch: 4 [251136/387873]    Loss: 0.001690   Batch Acc: 90.62
[Train] Epoch: 4 [251264/387873]    Loss: 0.002269   Batch Acc: 86.72
[Train] Epoch: 4 [251392/387873]    Loss: 0.002144   Batch Acc: 90.62
[Train] Epoch: 4 [251520/387873]    Loss: 0.002460   Batch Acc: 85.94
[Train] Epoch: 4 [251648/387873]    Loss: 0.001976   Batch Acc: 88.28
[Train] Epoch: 4 [251776/387873]    Loss: 0.001876   Batch Acc: 91.41
[Train] Epoch: 4 [251904/387873]    Loss: 0.002473   Batch Acc: 85.16
[Train] Epoch: 4 [252032/387873]    Loss: 0.001669   Batch Acc: 94.53
[Train] Epoch: 4 [252160/387873]    Loss: 0.002042   Batch Acc: 88.28
[Train] Epoch: 4 [252288/387873]    Loss: 0.002268   Batch Acc: 86.72
[Train] Epoch: 4 [252416/387873]    Loss: 0.002696   Batch Acc: 87.50
[Train] Epoch: 4 [252544/387873]    Loss: 0.001929   Batch Acc: 93.75
[Train] Epoch: 4 [252672/387873]    Loss: 0.001229   Batch Acc: 97.66
[Train] Epoch: 4 [252800/387873]    Loss: 0.001308   Batch Acc: 96.09
[Train] Epoch: 4 [252928/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 4 [253056/387873]    Loss: 0.002163   Batch Acc: 88.28
[Train] Epoch: 4 [253184/387873]    Loss: 0.002399   Batch Acc: 85.94
[Train] Epoch: 4 [253312/387873]    Loss: 0.001735   Batch Acc: 92.19
[Train] Epoch: 4 [253440/387873]    Loss: 0.002711   Batch Acc: 86.72
[Train] Epoch: 4 [253568/387873]    Loss: 0.001785   Batch Acc: 90.62
[Train] Epoch: 4 [253696/387873]    Loss: 0.001768   Batch Acc: 92.97
[Train] Epoch: 4 [253824/387873]    Loss: 0.001555   Batch Acc: 89.84
[Train] Epoch: 4 [253952/387873]    Loss: 0.001987   Batch Acc: 89.06
[Train] Epoch: 4 [254080/387873]    Loss: 0.002119   Batch Acc: 89.06
[Train] Epoch: 4 [254208/387873]    Loss: 0.002127   Batch Acc: 87.50
[Train] Epoch: 4 [254336/387873]    Loss: 0.002052   Batch Acc: 92.97
[Train] Epoch: 4 [254464/387873]    Loss: 0.001951   Batch Acc: 90.62
[Train] Epoch: 4 [254592/387873]    Loss: 0.001984   Batch Acc: 89.06
[Train] Epoch: 4 [254720/387873]    Loss: 0.003077   Batch Acc: 84.38
[Train] Epoch: 4 [254848/387873]    Loss: 0.002829   Batch Acc: 85.16
[Train] Epoch: 4 [254976/387873]    Loss: 0.002723   Batch Acc: 85.94
[Train] Epoch: 4 [255104/387873]    Loss: 0.001763   Batch Acc: 91.41
[Train] Epoch: 4 [255232/387873]    Loss: 0.002167   Batch Acc: 88.28
[Train] Epoch: 4 [255360/387873]    Loss: 0.001671   Batch Acc: 92.97
[Train] Epoch: 4 [255488/387873]    Loss: 0.002258   Batch Acc: 89.06
[Train] Epoch: 4 [255616/387873]    Loss: 0.002161   Batch Acc: 86.72
[Train] Epoch: 4 [255744/387873]    Loss: 0.001936   Batch Acc: 89.06
[Train] Epoch: 4 [255872/387873]    Loss: 0.002312   Batch Acc: 87.50
[Train] Epoch: 4 [256000/387873]    Loss: 0.001870   Batch Acc: 91.41
[Train] Epoch: 4 [256128/387873]    Loss: 0.001760   Batch Acc: 89.06
[Train] Epoch: 4 [256256/387873]    Loss: 0.001674   Batch Acc: 92.19
[Train] Epoch: 4 [256384/387873]    Loss: 0.001948   Batch Acc: 89.84
[Train] Epoch: 4 [256512/387873]    Loss: 0.002888   Batch Acc: 82.03
[Train] Epoch: 4 [256640/387873]    Loss: 0.001919   Batch Acc: 89.06
[Train] Epoch: 4 [256768/387873]    Loss: 0.001919   Batch Acc: 89.84
[Train] Epoch: 4 [256896/387873]    Loss: 0.001718   Batch Acc: 92.19
[Train] Epoch: 4 [257024/387873]    Loss: 0.002113   Batch Acc: 86.72
[Train] Epoch: 4 [257152/387873]    Loss: 0.001677   Batch Acc: 92.19
[Train] Epoch: 4 [257280/387873]    Loss: 0.002133   Batch Acc: 89.06
[Train] Epoch: 4 [257408/387873]    Loss: 0.002479   Batch Acc: 85.16
[Train] Epoch: 4 [257536/387873]    Loss: 0.001490   Batch Acc: 92.19
[Train] Epoch: 4 [257664/387873]    Loss: 0.002040   Batch Acc: 84.38
[Train] Epoch: 4 [257792/387873]    Loss: 0.001777   Batch Acc: 89.06
[Train] Epoch: 4 [257920/387873]    Loss: 0.002029   Batch Acc: 87.50
[Train] Epoch: 4 [258048/387873]    Loss: 0.001636   Batch Acc: 92.97
[Train] Epoch: 4 [258176/387873]    Loss: 0.001878   Batch Acc: 91.41
[Train] Epoch: 4 [258304/387873]    Loss: 0.001972   Batch Acc: 90.62
[Train] Epoch: 4 [258432/387873]    Loss: 0.001849   Batch Acc: 89.84
[Train] Epoch: 4 [258560/387873]    Loss: 0.002159   Batch Acc: 88.28
[Train] Epoch: 4 [258688/387873]    Loss: 0.002046   Batch Acc: 89.84
[Train] Epoch: 4 [258816/387873]    Loss: 0.002348   Batch Acc: 87.50
[Train] Epoch: 4 [258944/387873]    Loss: 0.002053   Batch Acc: 89.06
[Train] Epoch: 4 [259072/387873]    Loss: 0.001974   Batch Acc: 93.75
[Train] Epoch: 4 [259200/387873]    Loss: 0.002182   Batch Acc: 88.28
[Train] Epoch: 4 [259328/387873]    Loss: 0.001639   Batch Acc: 92.19
[Train] Epoch: 4 [259456/387873]    Loss: 0.002063   Batch Acc: 91.41
[Train] Epoch: 4 [259584/387873]    Loss: 0.002122   Batch Acc: 88.28
[Train] Epoch: 4 [259712/387873]    Loss: 0.001961   Batch Acc: 88.28
[Train] Epoch: 4 [259840/387873]    Loss: 0.002246   Batch Acc: 88.28
[Train] Epoch: 4 [259968/387873]    Loss: 0.002056   Batch Acc: 90.62
[Train] Epoch: 4 [260096/387873]    Loss: 0.001924   Batch Acc: 91.41
[Train] Epoch: 4 [260224/387873]    Loss: 0.001735   Batch Acc: 93.75
[Train] Epoch: 4 [260352/387873]    Loss: 0.001859   Batch Acc: 91.41
[Train] Epoch: 4 [260480/387873]    Loss: 0.001563   Batch Acc: 92.19
[Train] Epoch: 4 [260608/387873]    Loss: 0.001760   Batch Acc: 91.41
[Train] Epoch: 4 [260736/387873]    Loss: 0.002165   Batch Acc: 88.28
[Train] Epoch: 4 [260864/387873]    Loss: 0.002112   Batch Acc: 89.06
[Train] Epoch: 4 [260992/387873]    Loss: 0.002074   Batch Acc: 89.84
[Train] Epoch: 4 [261120/387873]    Loss: 0.001897   Batch Acc: 89.84
[Train] Epoch: 4 [261248/387873]    Loss: 0.001571   Batch Acc: 90.62
[Train] Epoch: 4 [261376/387873]    Loss: 0.002367   Batch Acc: 85.16
[Train] Epoch: 4 [261504/387873]    Loss: 0.001807   Batch Acc: 89.84
[Train] Epoch: 4 [261632/387873]    Loss: 0.002030   Batch Acc: 89.06
[Train] Epoch: 4 [261760/387873]    Loss: 0.002288   Batch Acc: 84.38
[Train] Epoch: 4 [261888/387873]    Loss: 0.002006   Batch Acc: 90.62
[Train] Epoch: 4 [262016/387873]    Loss: 0.002272   Batch Acc: 85.16
[Train] Epoch: 4 [262144/387873]    Loss: 0.001704   Batch Acc: 91.41
[Train] Epoch: 4 [262272/387873]    Loss: 0.001986   Batch Acc: 86.72
[Train] Epoch: 4 [262400/387873]    Loss: 0.001696   Batch Acc: 92.19
[Train] Epoch: 4 [262528/387873]    Loss: 0.002217   Batch Acc: 89.06
[Train] Epoch: 4 [262656/387873]    Loss: 0.001821   Batch Acc: 90.62
[Train] Epoch: 4 [262784/387873]    Loss: 0.001735   Batch Acc: 88.28
[Train] Epoch: 4 [262912/387873]    Loss: 0.002641   Batch Acc: 85.16
[Train] Epoch: 4 [263040/387873]    Loss: 0.001828   Batch Acc: 92.19
[Train] Epoch: 4 [263168/387873]    Loss: 0.001757   Batch Acc: 89.84
[Train] Epoch: 4 [263296/387873]    Loss: 0.002390   Batch Acc: 83.59
[Train] Epoch: 4 [263424/387873]    Loss: 0.002783   Batch Acc: 85.16
[Train] Epoch: 4 [263552/387873]    Loss: 0.002217   Batch Acc: 88.28
[Train] Epoch: 4 [263680/387873]    Loss: 0.002053   Batch Acc: 91.41
[Train] Epoch: 4 [263808/387873]    Loss: 0.001612   Batch Acc: 93.75
[Train] Epoch: 4 [263936/387873]    Loss: 0.001837   Batch Acc: 89.84
[Train] Epoch: 4 [264064/387873]    Loss: 0.002041   Batch Acc: 89.06
[Train] Epoch: 4 [264192/387873]    Loss: 0.002271   Batch Acc: 87.50
[Train] Epoch: 4 [264320/387873]    Loss: 0.002317   Batch Acc: 89.84
[Train] Epoch: 4 [264448/387873]    Loss: 0.002094   Batch Acc: 86.72
[Train] Epoch: 4 [264576/387873]    Loss: 0.002150   Batch Acc: 89.06
[Train] Epoch: 4 [264704/387873]    Loss: 0.001196   Batch Acc: 93.75
[Train] Epoch: 4 [264832/387873]    Loss: 0.002104   Batch Acc: 89.06
[Train] Epoch: 4 [264960/387873]    Loss: 0.001719   Batch Acc: 91.41
[Train] Epoch: 4 [265088/387873]    Loss: 0.002018   Batch Acc: 88.28
[Train] Epoch: 4 [265216/387873]    Loss: 0.002630   Batch Acc: 82.81
[Train] Epoch: 4 [265344/387873]    Loss: 0.001481   Batch Acc: 92.97
[Train] Epoch: 4 [265472/387873]    Loss: 0.001602   Batch Acc: 92.19
[Train] Epoch: 4 [265600/387873]    Loss: 0.002265   Batch Acc: 89.06
[Train] Epoch: 4 [265728/387873]    Loss: 0.001944   Batch Acc: 89.06
[Train] Epoch: 4 [265856/387873]    Loss: 0.002577   Batch Acc: 83.59
[Train] Epoch: 4 [265984/387873]    Loss: 0.001959   Batch Acc: 90.62
[Train] Epoch: 4 [266112/387873]    Loss: 0.001862   Batch Acc: 89.06
[Train] Epoch: 4 [266240/387873]    Loss: 0.002314   Batch Acc: 88.28
[Train] Epoch: 4 [266368/387873]    Loss: 0.001749   Batch Acc: 91.41
[Train] Epoch: 4 [266496/387873]    Loss: 0.002517   Batch Acc: 85.16
[Train] Epoch: 4 [266624/387873]    Loss: 0.001948   Batch Acc: 92.97
[Train] Epoch: 4 [266752/387873]    Loss: 0.002076   Batch Acc: 87.50
[Train] Epoch: 4 [266880/387873]    Loss: 0.002161   Batch Acc: 87.50
[Train] Epoch: 4 [267008/387873]    Loss: 0.002137   Batch Acc: 90.62
[Train] Epoch: 4 [267136/387873]    Loss: 0.001566   Batch Acc: 92.97
[Train] Epoch: 4 [267264/387873]    Loss: 0.002152   Batch Acc: 88.28
[Train] Epoch: 4 [267392/387873]    Loss: 0.001951   Batch Acc: 87.50
[Train] Epoch: 4 [267520/387873]    Loss: 0.001793   Batch Acc: 91.41
[Train] Epoch: 4 [267648/387873]    Loss: 0.001869   Batch Acc: 89.06
[Train] Epoch: 4 [267776/387873]    Loss: 0.001758   Batch Acc: 89.84
[Train] Epoch: 4 [267904/387873]    Loss: 0.002190   Batch Acc: 92.19
[Train] Epoch: 4 [268032/387873]    Loss: 0.002325   Batch Acc: 85.94
[Train] Epoch: 4 [268160/387873]    Loss: 0.001741   Batch Acc: 92.97
[Train] Epoch: 4 [268288/387873]    Loss: 0.001670   Batch Acc: 92.97
[Train] Epoch: 4 [268416/387873]    Loss: 0.001858   Batch Acc: 92.19
[Train] Epoch: 4 [268544/387873]    Loss: 0.002348   Batch Acc: 87.50
[Train] Epoch: 4 [268672/387873]    Loss: 0.001578   Batch Acc: 94.53
[Train] Epoch: 4 [268800/387873]    Loss: 0.002405   Batch Acc: 86.72
[Train] Epoch: 4 [268928/387873]    Loss: 0.002218   Batch Acc: 89.06
[Train] Epoch: 4 [269056/387873]    Loss: 0.001574   Batch Acc: 92.97
[Train] Epoch: 4 [269184/387873]    Loss: 0.002094   Batch Acc: 89.06
[Train] Epoch: 4 [269312/387873]    Loss: 0.002475   Batch Acc: 82.03
[Train] Epoch: 4 [269440/387873]    Loss: 0.001602   Batch Acc: 91.41
[Train] Epoch: 4 [269568/387873]    Loss: 0.002271   Batch Acc: 84.38
[Train] Epoch: 4 [269696/387873]    Loss: 0.001672   Batch Acc: 92.19
[Train] Epoch: 4 [269824/387873]    Loss: 0.001435   Batch Acc: 95.31
[Train] Epoch: 4 [269952/387873]    Loss: 0.001820   Batch Acc: 90.62
[Train] Epoch: 4 [270080/387873]    Loss: 0.002322   Batch Acc: 86.72
[Train] Epoch: 4 [270208/387873]    Loss: 0.002143   Batch Acc: 87.50
[Train] Epoch: 4 [270336/387873]    Loss: 0.001870   Batch Acc: 91.41
[Train] Epoch: 4 [270464/387873]    Loss: 0.002416   Batch Acc: 86.72
[Train] Epoch: 4 [270592/387873]    Loss: 0.001870   Batch Acc: 90.62
[Train] Epoch: 4 [270720/387873]    Loss: 0.001588   Batch Acc: 93.75
[Train] Epoch: 4 [270848/387873]    Loss: 0.001297   Batch Acc: 95.31
[Train] Epoch: 4 [270976/387873]    Loss: 0.001784   Batch Acc: 92.19
[Train] Epoch: 4 [271104/387873]    Loss: 0.001704   Batch Acc: 91.41
[Train] Epoch: 4 [271232/387873]    Loss: 0.001570   Batch Acc: 92.97
[Train] Epoch: 4 [271360/387873]    Loss: 0.001476   Batch Acc: 91.41
[Train] Epoch: 4 [271488/387873]    Loss: 0.002535   Batch Acc: 84.38
[Train] Epoch: 4 [271616/387873]    Loss: 0.002025   Batch Acc: 87.50
[Train] Epoch: 4 [271744/387873]    Loss: 0.002169   Batch Acc: 86.72
[Train] Epoch: 4 [271872/387873]    Loss: 0.001783   Batch Acc: 89.06
[Train] Epoch: 4 [272000/387873]    Loss: 0.001779   Batch Acc: 92.19
[Train] Epoch: 4 [272128/387873]    Loss: 0.002199   Batch Acc: 87.50
[Train] Epoch: 4 [272256/387873]    Loss: 0.001636   Batch Acc: 92.97
[Train] Epoch: 4 [272384/387873]    Loss: 0.002128   Batch Acc: 88.28
[Train] Epoch: 4 [272512/387873]    Loss: 0.002083   Batch Acc: 87.50
[Train] Epoch: 4 [272640/387873]    Loss: 0.002192   Batch Acc: 88.28
[Train] Epoch: 4 [272768/387873]    Loss: 0.002214   Batch Acc: 85.16
[Train] Epoch: 4 [272896/387873]    Loss: 0.001527   Batch Acc: 94.53
[Train] Epoch: 4 [273024/387873]    Loss: 0.001739   Batch Acc: 91.41
[Train] Epoch: 4 [273152/387873]    Loss: 0.001939   Batch Acc: 90.62
[Train] Epoch: 4 [273280/387873]    Loss: 0.002012   Batch Acc: 90.62
[Train] Epoch: 4 [273408/387873]    Loss: 0.001958   Batch Acc: 85.94
[Train] Epoch: 4 [273536/387873]    Loss: 0.001878   Batch Acc: 88.28
[Train] Epoch: 4 [273664/387873]    Loss: 0.001381   Batch Acc: 94.53
[Train] Epoch: 4 [273792/387873]    Loss: 0.002770   Batch Acc: 84.38
[Train] Epoch: 4 [273920/387873]    Loss: 0.001963   Batch Acc: 91.41
[Train] Epoch: 4 [274048/387873]    Loss: 0.002058   Batch Acc: 89.06
[Train] Epoch: 4 [274176/387873]    Loss: 0.001757   Batch Acc: 90.62
[Train] Epoch: 4 [274304/387873]    Loss: 0.002136   Batch Acc: 88.28
[Train] Epoch: 4 [274432/387873]    Loss: 0.001933   Batch Acc: 91.41
[Train] Epoch: 4 [274560/387873]    Loss: 0.001891   Batch Acc: 90.62
[Train] Epoch: 4 [274688/387873]    Loss: 0.002179   Batch Acc: 88.28
[Train] Epoch: 4 [274816/387873]    Loss: 0.002108   Batch Acc: 87.50
[Train] Epoch: 4 [274944/387873]    Loss: 0.002334   Batch Acc: 83.59
[Train] Epoch: 4 [275072/387873]    Loss: 0.002065   Batch Acc: 89.06
[Train] Epoch: 4 [275200/387873]    Loss: 0.002159   Batch Acc: 88.28
[Train] Epoch: 4 [275328/387873]    Loss: 0.002303   Batch Acc: 86.72
[Train] Epoch: 4 [275456/387873]    Loss: 0.002446   Batch Acc: 86.72
[Train] Epoch: 4 [275584/387873]    Loss: 0.001414   Batch Acc: 92.97
[Train] Epoch: 4 [275712/387873]    Loss: 0.002003   Batch Acc: 88.28
[Train] Epoch: 4 [275840/387873]    Loss: 0.001877   Batch Acc: 90.62
[Train] Epoch: 4 [275968/387873]    Loss: 0.002409   Batch Acc: 88.28
[Train] Epoch: 4 [276096/387873]    Loss: 0.001705   Batch Acc: 92.19
[Train] Epoch: 4 [276224/387873]    Loss: 0.002333   Batch Acc: 85.94
[Train] Epoch: 4 [276352/387873]    Loss: 0.001958   Batch Acc: 87.50
[Train] Epoch: 4 [276480/387873]    Loss: 0.001725   Batch Acc: 92.97
[Train] Epoch: 4 [276608/387873]    Loss: 0.001701   Batch Acc: 92.19
[Train] Epoch: 4 [276736/387873]    Loss: 0.001729   Batch Acc: 93.75
[Train] Epoch: 4 [276864/387873]    Loss: 0.001534   Batch Acc: 92.97
[Train] Epoch: 4 [276992/387873]    Loss: 0.002022   Batch Acc: 89.06
[Train] Epoch: 4 [277120/387873]    Loss: 0.001705   Batch Acc: 92.19
[Train] Epoch: 4 [277248/387873]    Loss: 0.001684   Batch Acc: 92.19
[Train] Epoch: 4 [277376/387873]    Loss: 0.002553   Batch Acc: 85.16
[Train] Epoch: 4 [277504/387873]    Loss: 0.002250   Batch Acc: 87.50
[Train] Epoch: 4 [277632/387873]    Loss: 0.001753   Batch Acc: 89.06
[Train] Epoch: 4 [277760/387873]    Loss: 0.002139   Batch Acc: 85.94
[Train] Epoch: 4 [277888/387873]    Loss: 0.001815   Batch Acc: 90.62
[Train] Epoch: 4 [278016/387873]    Loss: 0.002007   Batch Acc: 92.19
[Train] Epoch: 4 [278144/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 4 [278272/387873]    Loss: 0.002027   Batch Acc: 91.41
[Train] Epoch: 4 [278400/387873]    Loss: 0.002651   Batch Acc: 86.72
[Train] Epoch: 4 [278528/387873]    Loss: 0.001759   Batch Acc: 92.97
[Train] Epoch: 4 [278656/387873]    Loss: 0.002260   Batch Acc: 86.72
[Train] Epoch: 4 [278784/387873]    Loss: 0.001578   Batch Acc: 92.19
[Train] Epoch: 4 [278912/387873]    Loss: 0.001970   Batch Acc: 89.84
[Train] Epoch: 4 [279040/387873]    Loss: 0.002114   Batch Acc: 89.06
[Train] Epoch: 4 [279168/387873]    Loss: 0.001713   Batch Acc: 91.41
[Train] Epoch: 4 [279296/387873]    Loss: 0.001596   Batch Acc: 94.53
[Train] Epoch: 4 [279424/387873]    Loss: 0.001712   Batch Acc: 89.84
[Train] Epoch: 4 [279552/387873]    Loss: 0.001461   Batch Acc: 93.75
[Train] Epoch: 4 [279680/387873]    Loss: 0.002292   Batch Acc: 84.38
[Train] Epoch: 4 [279808/387873]    Loss: 0.002069   Batch Acc: 88.28
[Train] Epoch: 4 [279936/387873]    Loss: 0.002084   Batch Acc: 91.41
[Train] Epoch: 4 [280064/387873]    Loss: 0.001626   Batch Acc: 92.97
[Train] Epoch: 4 [280192/387873]    Loss: 0.001957   Batch Acc: 89.84
[Train] Epoch: 4 [280320/387873]    Loss: 0.001499   Batch Acc: 94.53
[Train] Epoch: 4 [280448/387873]    Loss: 0.001861   Batch Acc: 89.84
[Train] Epoch: 4 [280576/387873]    Loss: 0.002855   Batch Acc: 85.94
[Train] Epoch: 4 [280704/387873]    Loss: 0.001746   Batch Acc: 89.84
[Train] Epoch: 4 [280832/387873]    Loss: 0.002481   Batch Acc: 85.94
[Train] Epoch: 4 [280960/387873]    Loss: 0.001678   Batch Acc: 92.97
[Train] Epoch: 4 [281088/387873]    Loss: 0.001632   Batch Acc: 92.97
[Train] Epoch: 4 [281216/387873]    Loss: 0.002686   Batch Acc: 85.94
[Train] Epoch: 4 [281344/387873]    Loss: 0.001830   Batch Acc: 89.84
[Train] Epoch: 4 [281472/387873]    Loss: 0.002021   Batch Acc: 87.50
[Train] Epoch: 4 [281600/387873]    Loss: 0.001894   Batch Acc: 90.62
[Train] Epoch: 4 [281728/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 4 [281856/387873]    Loss: 0.001817   Batch Acc: 89.84
[Train] Epoch: 4 [281984/387873]    Loss: 0.001728   Batch Acc: 91.41
[Train] Epoch: 4 [282112/387873]    Loss: 0.002219   Batch Acc: 90.62
[Train] Epoch: 4 [282240/387873]    Loss: 0.001966   Batch Acc: 89.06
[Train] Epoch: 4 [282368/387873]    Loss: 0.002241   Batch Acc: 89.06
[Train] Epoch: 4 [282496/387873]    Loss: 0.002733   Batch Acc: 85.16
[Train] Epoch: 4 [282624/387873]    Loss: 0.002120   Batch Acc: 89.84
[Train] Epoch: 4 [282752/387873]    Loss: 0.001383   Batch Acc: 92.97
[Train] Epoch: 4 [282880/387873]    Loss: 0.002002   Batch Acc: 89.06
[Train] Epoch: 4 [283008/387873]    Loss: 0.002135   Batch Acc: 89.06
[Train] Epoch: 4 [283136/387873]    Loss: 0.001590   Batch Acc: 91.41
[Train] Epoch: 4 [283264/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 4 [283392/387873]    Loss: 0.001941   Batch Acc: 89.06
[Train] Epoch: 4 [283520/387873]    Loss: 0.001630   Batch Acc: 94.53
[Train] Epoch: 4 [283648/387873]    Loss: 0.002256   Batch Acc: 87.50
[Train] Epoch: 4 [283776/387873]    Loss: 0.001711   Batch Acc: 90.62
[Train] Epoch: 4 [283904/387873]    Loss: 0.001777   Batch Acc: 90.62
[Train] Epoch: 4 [284032/387873]    Loss: 0.002469   Batch Acc: 88.28
[Train] Epoch: 4 [284160/387873]    Loss: 0.001639   Batch Acc: 93.75
[Train] Epoch: 4 [284288/387873]    Loss: 0.002023   Batch Acc: 91.41
[Train] Epoch: 4 [284416/387873]    Loss: 0.002351   Batch Acc: 88.28
[Train] Epoch: 4 [284544/387873]    Loss: 0.002001   Batch Acc: 91.41
[Train] Epoch: 4 [284672/387873]    Loss: 0.002634   Batch Acc: 84.38
[Train] Epoch: 4 [284800/387873]    Loss: 0.001761   Batch Acc: 90.62
[Train] Epoch: 4 [284928/387873]    Loss: 0.001646   Batch Acc: 92.19
[Train] Epoch: 4 [285056/387873]    Loss: 0.002281   Batch Acc: 86.72
[Train] Epoch: 4 [285184/387873]    Loss: 0.002004   Batch Acc: 89.06
[Train] Epoch: 4 [285312/387873]    Loss: 0.002068   Batch Acc: 91.41
[Train] Epoch: 4 [285440/387873]    Loss: 0.002324   Batch Acc: 86.72
[Train] Epoch: 4 [285568/387873]    Loss: 0.001637   Batch Acc: 91.41
[Train] Epoch: 4 [285696/387873]    Loss: 0.002320   Batch Acc: 86.72
[Train] Epoch: 4 [285824/387873]    Loss: 0.002214   Batch Acc: 86.72
[Train] Epoch: 4 [285952/387873]    Loss: 0.001870   Batch Acc: 91.41
[Train] Epoch: 4 [286080/387873]    Loss: 0.002907   Batch Acc: 82.81
[Train] Epoch: 4 [286208/387873]    Loss: 0.001544   Batch Acc: 92.97
[Train] Epoch: 4 [286336/387873]    Loss: 0.002161   Batch Acc: 88.28
[Train] Epoch: 4 [286464/387873]    Loss: 0.002047   Batch Acc: 89.84
[Train] Epoch: 4 [286592/387873]    Loss: 0.001761   Batch Acc: 92.19
[Train] Epoch: 4 [286720/387873]    Loss: 0.002622   Batch Acc: 85.94
[Train] Epoch: 4 [286848/387873]    Loss: 0.001967   Batch Acc: 87.50
[Train] Epoch: 4 [286976/387873]    Loss: 0.001378   Batch Acc: 93.75
[Train] Epoch: 4 [287104/387873]    Loss: 0.002249   Batch Acc: 86.72
[Train] Epoch: 4 [287232/387873]    Loss: 0.002504   Batch Acc: 87.50
[Train] Epoch: 4 [287360/387873]    Loss: 0.001970   Batch Acc: 91.41
[Train] Epoch: 4 [287488/387873]    Loss: 0.002086   Batch Acc: 87.50
[Train] Epoch: 4 [287616/387873]    Loss: 0.001700   Batch Acc: 92.19
[Train] Epoch: 4 [287744/387873]    Loss: 0.002208   Batch Acc: 89.84
[Train] Epoch: 4 [287872/387873]    Loss: 0.002466   Batch Acc: 88.28
[Train] Epoch: 4 [288000/387873]    Loss: 0.001831   Batch Acc: 89.84
[Train] Epoch: 4 [288128/387873]    Loss: 0.002486   Batch Acc: 86.72
[Train] Epoch: 4 [288256/387873]    Loss: 0.002086   Batch Acc: 89.84
[Train] Epoch: 4 [288384/387873]    Loss: 0.001978   Batch Acc: 88.28
[Train] Epoch: 4 [288512/387873]    Loss: 0.001329   Batch Acc: 95.31
[Train] Epoch: 4 [288640/387873]    Loss: 0.002395   Batch Acc: 88.28
[Train] Epoch: 4 [288768/387873]    Loss: 0.001752   Batch Acc: 92.19
[Train] Epoch: 4 [288896/387873]    Loss: 0.001857   Batch Acc: 91.41
[Train] Epoch: 4 [289024/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 4 [289152/387873]    Loss: 0.001291   Batch Acc: 93.75
[Train] Epoch: 4 [289280/387873]    Loss: 0.002039   Batch Acc: 89.06
[Train] Epoch: 4 [289408/387873]    Loss: 0.001980   Batch Acc: 91.41
[Train] Epoch: 4 [289536/387873]    Loss: 0.001453   Batch Acc: 92.19
[Train] Epoch: 4 [289664/387873]    Loss: 0.001875   Batch Acc: 90.62
[Train] Epoch: 4 [289792/387873]    Loss: 0.001701   Batch Acc: 94.53
[Train] Epoch: 4 [289920/387873]    Loss: 0.001757   Batch Acc: 90.62
[Train] Epoch: 4 [290048/387873]    Loss: 0.002047   Batch Acc: 87.50
[Train] Epoch: 4 [290176/387873]    Loss: 0.001941   Batch Acc: 89.06
[Train] Epoch: 4 [290304/387873]    Loss: 0.002313   Batch Acc: 85.94
[Train] Epoch: 4 [290432/387873]    Loss: 0.001442   Batch Acc: 94.53
[Train] Epoch: 4 [290560/387873]    Loss: 0.001905   Batch Acc: 88.28
[Train] Epoch: 4 [290688/387873]    Loss: 0.001850   Batch Acc: 90.62
[Train] Epoch: 4 [290816/387873]    Loss: 0.001632   Batch Acc: 91.41
[Train] Epoch: 4 [290944/387873]    Loss: 0.002201   Batch Acc: 89.06
[Train] Epoch: 4 [291072/387873]    Loss: 0.001837   Batch Acc: 88.28
[Train] Epoch: 4 [291200/387873]    Loss: 0.002347   Batch Acc: 85.94
[Train] Epoch: 4 [291328/387873]    Loss: 0.001854   Batch Acc: 91.41
[Train] Epoch: 4 [291456/387873]    Loss: 0.002380   Batch Acc: 86.72
[Train] Epoch: 4 [291584/387873]    Loss: 0.002665   Batch Acc: 87.50
[Train] Epoch: 4 [291712/387873]    Loss: 0.001458   Batch Acc: 93.75
[Train] Epoch: 4 [291840/387873]    Loss: 0.002563   Batch Acc: 84.38
[Train] Epoch: 4 [291968/387873]    Loss: 0.002668   Batch Acc: 87.50
[Train] Epoch: 4 [292096/387873]    Loss: 0.002262   Batch Acc: 88.28
[Train] Epoch: 4 [292224/387873]    Loss: 0.001580   Batch Acc: 92.97
[Train] Epoch: 4 [292352/387873]    Loss: 0.001748   Batch Acc: 93.75
[Train] Epoch: 4 [292480/387873]    Loss: 0.001479   Batch Acc: 93.75
[Train] Epoch: 4 [292608/387873]    Loss: 0.001939   Batch Acc: 89.06
[Train] Epoch: 4 [292736/387873]    Loss: 0.002625   Batch Acc: 84.38
[Train] Epoch: 4 [292864/387873]    Loss: 0.002586   Batch Acc: 85.16
[Train] Epoch: 4 [292992/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 4 [293120/387873]    Loss: 0.001975   Batch Acc: 88.28
[Train] Epoch: 4 [293248/387873]    Loss: 0.001872   Batch Acc: 91.41
[Train] Epoch: 4 [293376/387873]    Loss: 0.002894   Batch Acc: 83.59
[Train] Epoch: 4 [293504/387873]    Loss: 0.002394   Batch Acc: 86.72
[Train] Epoch: 4 [293632/387873]    Loss: 0.002221   Batch Acc: 88.28
[Train] Epoch: 4 [293760/387873]    Loss: 0.001942   Batch Acc: 91.41
[Train] Epoch: 4 [293888/387873]    Loss: 0.001635   Batch Acc: 91.41
[Train] Epoch: 4 [294016/387873]    Loss: 0.001612   Batch Acc: 91.41
[Train] Epoch: 4 [294144/387873]    Loss: 0.001752   Batch Acc: 90.62
[Train] Epoch: 4 [294272/387873]    Loss: 0.002508   Batch Acc: 82.81
[Train] Epoch: 4 [294400/387873]    Loss: 0.001871   Batch Acc: 90.62
[Train] Epoch: 4 [294528/387873]    Loss: 0.002473   Batch Acc: 88.28
[Train] Epoch: 4 [294656/387873]    Loss: 0.001970   Batch Acc: 90.62
[Train] Epoch: 4 [294784/387873]    Loss: 0.001708   Batch Acc: 92.97
[Train] Epoch: 4 [294912/387873]    Loss: 0.002162   Batch Acc: 88.28
[Train] Epoch: 4 [295040/387873]    Loss: 0.002391   Batch Acc: 85.94
[Train] Epoch: 4 [295168/387873]    Loss: 0.001851   Batch Acc: 89.06
[Train] Epoch: 4 [295296/387873]    Loss: 0.002213   Batch Acc: 86.72
[Train] Epoch: 4 [295424/387873]    Loss: 0.001839   Batch Acc: 86.72
[Train] Epoch: 4 [295552/387873]    Loss: 0.001896   Batch Acc: 92.19
[Train] Epoch: 4 [295680/387873]    Loss: 0.002217   Batch Acc: 89.84
[Train] Epoch: 4 [295808/387873]    Loss: 0.001680   Batch Acc: 92.97
[Train] Epoch: 4 [295936/387873]    Loss: 0.001726   Batch Acc: 89.84
[Train] Epoch: 4 [296064/387873]    Loss: 0.001722   Batch Acc: 89.84
[Train] Epoch: 4 [296192/387873]    Loss: 0.002052   Batch Acc: 91.41
[Train] Epoch: 4 [296320/387873]    Loss: 0.001786   Batch Acc: 92.19
[Train] Epoch: 4 [296448/387873]    Loss: 0.002273   Batch Acc: 85.94
[Train] Epoch: 4 [296576/387873]    Loss: 0.001450   Batch Acc: 93.75
[Train] Epoch: 4 [296704/387873]    Loss: 0.001641   Batch Acc: 92.19
[Train] Epoch: 4 [296832/387873]    Loss: 0.002040   Batch Acc: 89.84
[Train] Epoch: 4 [296960/387873]    Loss: 0.001816   Batch Acc: 88.28
[Train] Epoch: 4 [297088/387873]    Loss: 0.002010   Batch Acc: 92.19
[Train] Epoch: 4 [297216/387873]    Loss: 0.002188   Batch Acc: 89.84
[Train] Epoch: 4 [297344/387873]    Loss: 0.001661   Batch Acc: 89.84
[Train] Epoch: 4 [297472/387873]    Loss: 0.001638   Batch Acc: 92.19
[Train] Epoch: 4 [297600/387873]    Loss: 0.001661   Batch Acc: 93.75
[Train] Epoch: 4 [297728/387873]    Loss: 0.002129   Batch Acc: 91.41
[Train] Epoch: 4 [297856/387873]    Loss: 0.002248   Batch Acc: 86.72
[Train] Epoch: 4 [297984/387873]    Loss: 0.001907   Batch Acc: 92.97
[Train] Epoch: 4 [298112/387873]    Loss: 0.002199   Batch Acc: 88.28
[Train] Epoch: 4 [298240/387873]    Loss: 0.002227   Batch Acc: 86.72
[Train] Epoch: 4 [298368/387873]    Loss: 0.001613   Batch Acc: 92.97
[Train] Epoch: 4 [298496/387873]    Loss: 0.002133   Batch Acc: 89.06
[Train] Epoch: 4 [298624/387873]    Loss: 0.001759   Batch Acc: 89.84
[Train] Epoch: 4 [298752/387873]    Loss: 0.001780   Batch Acc: 93.75
[Train] Epoch: 4 [298880/387873]    Loss: 0.002665   Batch Acc: 85.94
[Train] Epoch: 4 [299008/387873]    Loss: 0.002030   Batch Acc: 89.06
[Train] Epoch: 4 [299136/387873]    Loss: 0.001329   Batch Acc: 93.75
[Train] Epoch: 4 [299264/387873]    Loss: 0.001786   Batch Acc: 91.41
[Train] Epoch: 4 [299392/387873]    Loss: 0.002208   Batch Acc: 88.28
[Train] Epoch: 4 [299520/387873]    Loss: 0.002107   Batch Acc: 88.28
[Train] Epoch: 4 [299648/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 4 [299776/387873]    Loss: 0.002305   Batch Acc: 86.72
[Train] Epoch: 4 [299904/387873]    Loss: 0.001976   Batch Acc: 90.62
[Train] Epoch: 4 [300032/387873]    Loss: 0.002216   Batch Acc: 89.84
[Train] Epoch: 4 [300160/387873]    Loss: 0.002417   Batch Acc: 88.28
[Train] Epoch: 4 [300288/387873]    Loss: 0.001922   Batch Acc: 89.06
[Train] Epoch: 4 [300416/387873]    Loss: 0.002338   Batch Acc: 85.94
[Train] Epoch: 4 [300544/387873]    Loss: 0.002021   Batch Acc: 88.28
[Train] Epoch: 4 [300672/387873]    Loss: 0.001897   Batch Acc: 88.28
[Train] Epoch: 4 [300800/387873]    Loss: 0.001999   Batch Acc: 89.06
[Train] Epoch: 4 [300928/387873]    Loss: 0.001909   Batch Acc: 90.62
[Train] Epoch: 4 [301056/387873]    Loss: 0.001736   Batch Acc: 89.84
[Train] Epoch: 4 [301184/387873]    Loss: 0.002454   Batch Acc: 82.81
[Train] Epoch: 4 [301312/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 4 [301440/387873]    Loss: 0.001649   Batch Acc: 92.19
[Train] Epoch: 4 [301568/387873]    Loss: 0.001990   Batch Acc: 89.06
[Train] Epoch: 4 [301696/387873]    Loss: 0.001710   Batch Acc: 92.97
[Train] Epoch: 4 [301824/387873]    Loss: 0.001936   Batch Acc: 86.72
[Train] Epoch: 4 [301952/387873]    Loss: 0.001492   Batch Acc: 89.84
[Train] Epoch: 4 [302080/387873]    Loss: 0.002052   Batch Acc: 85.94
[Train] Epoch: 4 [302208/387873]    Loss: 0.002138   Batch Acc: 82.81
[Train] Epoch: 4 [302336/387873]    Loss: 0.002079   Batch Acc: 92.19
[Train] Epoch: 4 [302464/387873]    Loss: 0.002350   Batch Acc: 85.94
[Train] Epoch: 4 [302592/387873]    Loss: 0.002335   Batch Acc: 85.16
[Train] Epoch: 4 [302720/387873]    Loss: 0.001921   Batch Acc: 89.84
[Train] Epoch: 4 [302848/387873]    Loss: 0.002417   Batch Acc: 86.72
[Train] Epoch: 4 [302976/387873]    Loss: 0.001757   Batch Acc: 89.06
[Train] Epoch: 4 [303104/387873]    Loss: 0.001741   Batch Acc: 91.41
[Train] Epoch: 4 [303232/387873]    Loss: 0.001526   Batch Acc: 94.53
[Train] Epoch: 4 [303360/387873]    Loss: 0.001997   Batch Acc: 89.06
[Train] Epoch: 4 [303488/387873]    Loss: 0.002276   Batch Acc: 89.06
[Train] Epoch: 4 [303616/387873]    Loss: 0.002398   Batch Acc: 86.72
[Train] Epoch: 4 [303744/387873]    Loss: 0.002339   Batch Acc: 85.94
[Train] Epoch: 4 [303872/387873]    Loss: 0.001669   Batch Acc: 92.97
[Train] Epoch: 4 [304000/387873]    Loss: 0.002279   Batch Acc: 88.28
[Train] Epoch: 4 [304128/387873]    Loss: 0.001436   Batch Acc: 93.75
[Train] Epoch: 4 [304256/387873]    Loss: 0.001797   Batch Acc: 89.84
[Train] Epoch: 4 [304384/387873]    Loss: 0.001951   Batch Acc: 90.62
[Train] Epoch: 4 [304512/387873]    Loss: 0.001741   Batch Acc: 92.19
[Train] Epoch: 4 [304640/387873]    Loss: 0.002360   Batch Acc: 84.38
[Train] Epoch: 4 [304768/387873]    Loss: 0.002296   Batch Acc: 85.16
[Train] Epoch: 4 [304896/387873]    Loss: 0.001516   Batch Acc: 93.75
[Train] Epoch: 4 [305024/387873]    Loss: 0.001624   Batch Acc: 93.75
[Train] Epoch: 4 [305152/387873]    Loss: 0.001783   Batch Acc: 90.62
[Train] Epoch: 4 [305280/387873]    Loss: 0.001741   Batch Acc: 89.84
[Train] Epoch: 4 [305408/387873]    Loss: 0.002262   Batch Acc: 85.94
[Train] Epoch: 4 [305536/387873]    Loss: 0.001753   Batch Acc: 92.97
[Train] Epoch: 4 [305664/387873]    Loss: 0.001772   Batch Acc: 90.62
[Train] Epoch: 4 [305792/387873]    Loss: 0.002177   Batch Acc: 86.72
[Train] Epoch: 4 [305920/387873]    Loss: 0.002462   Batch Acc: 83.59
[Train] Epoch: 4 [306048/387873]    Loss: 0.002057   Batch Acc: 87.50
[Train] Epoch: 4 [306176/387873]    Loss: 0.002059   Batch Acc: 91.41
[Train] Epoch: 4 [306304/387873]    Loss: 0.001817   Batch Acc: 90.62
[Train] Epoch: 4 [306432/387873]    Loss: 0.001905   Batch Acc: 87.50
[Train] Epoch: 4 [306560/387873]    Loss: 0.002022   Batch Acc: 90.62
[Train] Epoch: 4 [306688/387873]    Loss: 0.002203   Batch Acc: 90.62
[Train] Epoch: 4 [306816/387873]    Loss: 0.002039   Batch Acc: 90.62
[Train] Epoch: 4 [306944/387873]    Loss: 0.002293   Batch Acc: 85.94
[Train] Epoch: 4 [307072/387873]    Loss: 0.002155   Batch Acc: 89.06
[Train] Epoch: 4 [307200/387873]    Loss: 0.002212   Batch Acc: 87.50
[Train] Epoch: 4 [307328/387873]    Loss: 0.002156   Batch Acc: 85.94
[Train] Epoch: 4 [307456/387873]    Loss: 0.002089   Batch Acc: 88.28
[Train] Epoch: 4 [307584/387873]    Loss: 0.002248   Batch Acc: 88.28
[Train] Epoch: 4 [307712/387873]    Loss: 0.002160   Batch Acc: 87.50
[Train] Epoch: 4 [307840/387873]    Loss: 0.002666   Batch Acc: 86.72
[Train] Epoch: 4 [307968/387873]    Loss: 0.001877   Batch Acc: 88.28
[Train] Epoch: 4 [308096/387873]    Loss: 0.002612   Batch Acc: 85.94
[Train] Epoch: 4 [308224/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 4 [308352/387873]    Loss: 0.001697   Batch Acc: 89.84
[Train] Epoch: 4 [308480/387873]    Loss: 0.002187   Batch Acc: 88.28
[Train] Epoch: 4 [308608/387873]    Loss: 0.001693   Batch Acc: 92.19
[Train] Epoch: 4 [308736/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 4 [308864/387873]    Loss: 0.001658   Batch Acc: 89.84
[Train] Epoch: 4 [308992/387873]    Loss: 0.001858   Batch Acc: 90.62
[Train] Epoch: 4 [309120/387873]    Loss: 0.002419   Batch Acc: 85.16
[Train] Epoch: 4 [309248/387873]    Loss: 0.001888   Batch Acc: 92.19
[Train] Epoch: 4 [309376/387873]    Loss: 0.001641   Batch Acc: 92.19
[Train] Epoch: 4 [309504/387873]    Loss: 0.002389   Batch Acc: 89.06
[Train] Epoch: 4 [309632/387873]    Loss: 0.001532   Batch Acc: 92.97
[Train] Epoch: 4 [309760/387873]    Loss: 0.002047   Batch Acc: 85.94
[Train] Epoch: 4 [309888/387873]    Loss: 0.002535   Batch Acc: 85.16
[Train] Epoch: 4 [310016/387873]    Loss: 0.002102   Batch Acc: 89.84
[Train] Epoch: 4 [310144/387873]    Loss: 0.001815   Batch Acc: 90.62
[Train] Epoch: 4 [310272/387873]    Loss: 0.001557   Batch Acc: 92.97
[Train] Epoch: 4 [310400/387873]    Loss: 0.002029   Batch Acc: 89.06
[Train] Epoch: 4 [310528/387873]    Loss: 0.002393   Batch Acc: 84.38
[Train] Epoch: 4 [310656/387873]    Loss: 0.001668   Batch Acc: 92.97
[Train] Epoch: 4 [310784/387873]    Loss: 0.001923   Batch Acc: 92.19
[Train] Epoch: 4 [310912/387873]    Loss: 0.001642   Batch Acc: 92.97
[Train] Epoch: 4 [311040/387873]    Loss: 0.002167   Batch Acc: 86.72
[Train] Epoch: 4 [311168/387873]    Loss: 0.001983   Batch Acc: 89.06
[Train] Epoch: 4 [311296/387873]    Loss: 0.001890   Batch Acc: 90.62
[Train] Epoch: 4 [311424/387873]    Loss: 0.001777   Batch Acc: 92.97
[Train] Epoch: 4 [311552/387873]    Loss: 0.001940   Batch Acc: 89.06
[Train] Epoch: 4 [311680/387873]    Loss: 0.001848   Batch Acc: 88.28
[Train] Epoch: 4 [311808/387873]    Loss: 0.002317   Batch Acc: 88.28
[Train] Epoch: 4 [311936/387873]    Loss: 0.001711   Batch Acc: 90.62
[Train] Epoch: 4 [312064/387873]    Loss: 0.002527   Batch Acc: 86.72
[Train] Epoch: 4 [312192/387873]    Loss: 0.002595   Batch Acc: 83.59
[Train] Epoch: 4 [312320/387873]    Loss: 0.002284   Batch Acc: 86.72
[Train] Epoch: 4 [312448/387873]    Loss: 0.002399   Batch Acc: 84.38
[Train] Epoch: 4 [312576/387873]    Loss: 0.001903   Batch Acc: 91.41
[Train] Epoch: 4 [312704/387873]    Loss: 0.001809   Batch Acc: 86.72
[Train] Epoch: 4 [312832/387873]    Loss: 0.001815   Batch Acc: 89.84
[Train] Epoch: 4 [312960/387873]    Loss: 0.002108   Batch Acc: 88.28
[Train] Epoch: 4 [313088/387873]    Loss: 0.001477   Batch Acc: 92.97
[Train] Epoch: 4 [313216/387873]    Loss: 0.001761   Batch Acc: 91.41
[Train] Epoch: 4 [313344/387873]    Loss: 0.002112   Batch Acc: 91.41
[Train] Epoch: 4 [313472/387873]    Loss: 0.001911   Batch Acc: 87.50
[Train] Epoch: 4 [313600/387873]    Loss: 0.001829   Batch Acc: 88.28
[Train] Epoch: 4 [313728/387873]    Loss: 0.001961   Batch Acc: 89.06
[Train] Epoch: 4 [313856/387873]    Loss: 0.002166   Batch Acc: 85.94
[Train] Epoch: 4 [313984/387873]    Loss: 0.001933   Batch Acc: 92.19
[Train] Epoch: 4 [314112/387873]    Loss: 0.001633   Batch Acc: 93.75
[Train] Epoch: 4 [314240/387873]    Loss: 0.001766   Batch Acc: 89.06
[Train] Epoch: 4 [314368/387873]    Loss: 0.002165   Batch Acc: 85.94
[Train] Epoch: 4 [314496/387873]    Loss: 0.002150   Batch Acc: 89.06
[Train] Epoch: 4 [314624/387873]    Loss: 0.002314   Batch Acc: 86.72
[Train] Epoch: 4 [314752/387873]    Loss: 0.001983   Batch Acc: 88.28
[Train] Epoch: 4 [314880/387873]    Loss: 0.001627   Batch Acc: 92.19
[Train] Epoch: 4 [315008/387873]    Loss: 0.001798   Batch Acc: 91.41
[Train] Epoch: 4 [315136/387873]    Loss: 0.002224   Batch Acc: 86.72
[Train] Epoch: 4 [315264/387873]    Loss: 0.001541   Batch Acc: 93.75
[Train] Epoch: 4 [315392/387873]    Loss: 0.002205   Batch Acc: 89.84
[Train] Epoch: 4 [315520/387873]    Loss: 0.001866   Batch Acc: 89.06
[Train] Epoch: 4 [315648/387873]    Loss: 0.002208   Batch Acc: 88.28
[Train] Epoch: 4 [315776/387873]    Loss: 0.001467   Batch Acc: 94.53
[Train] Epoch: 4 [315904/387873]    Loss: 0.002268   Batch Acc: 88.28
[Train] Epoch: 4 [316032/387873]    Loss: 0.002100   Batch Acc: 88.28
[Train] Epoch: 4 [316160/387873]    Loss: 0.001929   Batch Acc: 90.62
[Train] Epoch: 4 [316288/387873]    Loss: 0.001786   Batch Acc: 90.62
[Train] Epoch: 4 [316416/387873]    Loss: 0.002197   Batch Acc: 87.50
[Train] Epoch: 4 [316544/387873]    Loss: 0.001550   Batch Acc: 92.19
[Train] Epoch: 4 [316672/387873]    Loss: 0.001535   Batch Acc: 91.41
[Train] Epoch: 4 [316800/387873]    Loss: 0.001526   Batch Acc: 92.19
[Train] Epoch: 4 [316928/387873]    Loss: 0.001705   Batch Acc: 91.41
[Train] Epoch: 4 [317056/387873]    Loss: 0.001644   Batch Acc: 92.19
[Train] Epoch: 4 [317184/387873]    Loss: 0.002066   Batch Acc: 90.62
[Train] Epoch: 4 [317312/387873]    Loss: 0.001568   Batch Acc: 94.53
[Train] Epoch: 4 [317440/387873]    Loss: 0.002212   Batch Acc: 85.94
[Train] Epoch: 4 [317568/387873]    Loss: 0.001919   Batch Acc: 90.62
[Train] Epoch: 4 [317696/387873]    Loss: 0.001624   Batch Acc: 91.41
[Train] Epoch: 4 [317824/387873]    Loss: 0.001858   Batch Acc: 87.50
[Train] Epoch: 4 [317952/387873]    Loss: 0.002205   Batch Acc: 89.84
[Train] Epoch: 4 [318080/387873]    Loss: 0.001384   Batch Acc: 93.75
[Train] Epoch: 4 [318208/387873]    Loss: 0.002291   Batch Acc: 85.94
[Train] Epoch: 4 [318336/387873]    Loss: 0.001947   Batch Acc: 91.41
[Train] Epoch: 4 [318464/387873]    Loss: 0.002130   Batch Acc: 88.28
[Train] Epoch: 4 [318592/387873]    Loss: 0.002058   Batch Acc: 89.06
[Train] Epoch: 4 [318720/387873]    Loss: 0.002037   Batch Acc: 86.72
[Train] Epoch: 4 [318848/387873]    Loss: 0.002041   Batch Acc: 89.84
[Train] Epoch: 4 [318976/387873]    Loss: 0.001788   Batch Acc: 89.06
[Train] Epoch: 4 [319104/387873]    Loss: 0.001551   Batch Acc: 93.75
[Train] Epoch: 4 [319232/387873]    Loss: 0.002009   Batch Acc: 86.72
[Train] Epoch: 4 [319360/387873]    Loss: 0.001749   Batch Acc: 93.75
[Train] Epoch: 4 [319488/387873]    Loss: 0.002033   Batch Acc: 90.62
[Train] Epoch: 4 [319616/387873]    Loss: 0.002792   Batch Acc: 84.38
[Train] Epoch: 4 [319744/387873]    Loss: 0.001789   Batch Acc: 91.41
[Train] Epoch: 4 [319872/387873]    Loss: 0.002183   Batch Acc: 88.28
[Train] Epoch: 4 [320000/387873]    Loss: 0.002712   Batch Acc: 85.94
[Train] Epoch: 4 [320128/387873]    Loss: 0.001830   Batch Acc: 85.94
[Train] Epoch: 4 [320256/387873]    Loss: 0.001996   Batch Acc: 87.50
[Train] Epoch: 4 [320384/387873]    Loss: 0.002012   Batch Acc: 89.06
[Train] Epoch: 4 [320512/387873]    Loss: 0.002186   Batch Acc: 87.50
[Train] Epoch: 4 [320640/387873]    Loss: 0.002430   Batch Acc: 85.94
[Train] Epoch: 4 [320768/387873]    Loss: 0.001543   Batch Acc: 92.97
[Train] Epoch: 4 [320896/387873]    Loss: 0.002287   Batch Acc: 89.06
[Train] Epoch: 4 [321024/387873]    Loss: 0.002073   Batch Acc: 87.50
[Train] Epoch: 4 [321152/387873]    Loss: 0.002471   Batch Acc: 85.16
[Train] Epoch: 4 [321280/387873]    Loss: 0.001758   Batch Acc: 90.62
[Train] Epoch: 4 [321408/387873]    Loss: 0.001902   Batch Acc: 90.62
[Train] Epoch: 4 [321536/387873]    Loss: 0.002179   Batch Acc: 88.28
[Train] Epoch: 4 [321664/387873]    Loss: 0.002096   Batch Acc: 89.84
[Train] Epoch: 4 [321792/387873]    Loss: 0.001941   Batch Acc: 89.84
[Train] Epoch: 4 [321920/387873]    Loss: 0.002409   Batch Acc: 84.38
[Train] Epoch: 4 [322048/387873]    Loss: 0.001477   Batch Acc: 94.53
[Train] Epoch: 4 [322176/387873]    Loss: 0.001866   Batch Acc: 92.19
[Train] Epoch: 4 [322304/387873]    Loss: 0.002257   Batch Acc: 84.38
[Train] Epoch: 4 [322432/387873]    Loss: 0.001879   Batch Acc: 91.41
[Train] Epoch: 4 [322560/387873]    Loss: 0.001791   Batch Acc: 92.19
[Train] Epoch: 4 [322688/387873]    Loss: 0.002299   Batch Acc: 87.50
[Train] Epoch: 4 [322816/387873]    Loss: 0.001925   Batch Acc: 89.06
[Train] Epoch: 4 [322944/387873]    Loss: 0.002338   Batch Acc: 86.72
[Train] Epoch: 4 [323072/387873]    Loss: 0.001493   Batch Acc: 94.53
[Train] Epoch: 4 [323200/387873]    Loss: 0.001814   Batch Acc: 89.06
[Train] Epoch: 4 [323328/387873]    Loss: 0.002458   Batch Acc: 88.28
[Train] Epoch: 4 [323456/387873]    Loss: 0.002267   Batch Acc: 85.94
[Train] Epoch: 4 [323584/387873]    Loss: 0.002169   Batch Acc: 89.06
[Train] Epoch: 4 [323712/387873]    Loss: 0.002208   Batch Acc: 88.28
[Train] Epoch: 4 [323840/387873]    Loss: 0.002670   Batch Acc: 82.03
[Train] Epoch: 4 [323968/387873]    Loss: 0.002551   Batch Acc: 83.59
[Train] Epoch: 4 [324096/387873]    Loss: 0.001886   Batch Acc: 88.28
[Train] Epoch: 4 [324224/387873]    Loss: 0.001827   Batch Acc: 88.28
[Train] Epoch: 4 [324352/387873]    Loss: 0.002697   Batch Acc: 85.16
[Train] Epoch: 4 [324480/387873]    Loss: 0.001963   Batch Acc: 88.28
[Train] Epoch: 4 [324608/387873]    Loss: 0.001282   Batch Acc: 93.75
[Train] Epoch: 4 [324736/387873]    Loss: 0.002296   Batch Acc: 89.06
[Train] Epoch: 4 [324864/387873]    Loss: 0.001741   Batch Acc: 89.06
[Train] Epoch: 4 [324992/387873]    Loss: 0.002070   Batch Acc: 90.62
[Train] Epoch: 4 [325120/387873]    Loss: 0.001871   Batch Acc: 92.97
[Train] Epoch: 4 [325248/387873]    Loss: 0.002115   Batch Acc: 89.84
[Train] Epoch: 4 [325376/387873]    Loss: 0.002283   Batch Acc: 89.84
[Train] Epoch: 4 [325504/387873]    Loss: 0.001879   Batch Acc: 90.62
[Train] Epoch: 4 [325632/387873]    Loss: 0.001822   Batch Acc: 90.62
[Train] Epoch: 4 [325760/387873]    Loss: 0.002110   Batch Acc: 90.62
[Train] Epoch: 4 [325888/387873]    Loss: 0.001851   Batch Acc: 92.19
[Train] Epoch: 4 [326016/387873]    Loss: 0.002206   Batch Acc: 88.28
[Train] Epoch: 4 [326144/387873]    Loss: 0.002435   Batch Acc: 86.72
[Train] Epoch: 4 [326272/387873]    Loss: 0.001870   Batch Acc: 90.62
[Train] Epoch: 4 [326400/387873]    Loss: 0.002146   Batch Acc: 88.28
[Train] Epoch: 4 [326528/387873]    Loss: 0.002050   Batch Acc: 88.28
[Train] Epoch: 4 [326656/387873]    Loss: 0.001881   Batch Acc: 92.19
[Train] Epoch: 4 [326784/387873]    Loss: 0.001827   Batch Acc: 89.84
[Train] Epoch: 4 [326912/387873]    Loss: 0.001739   Batch Acc: 89.06
[Train] Epoch: 4 [327040/387873]    Loss: 0.002155   Batch Acc: 87.50
[Train] Epoch: 4 [327168/387873]    Loss: 0.002031   Batch Acc: 89.06
[Train] Epoch: 4 [327296/387873]    Loss: 0.002350   Batch Acc: 86.72
[Train] Epoch: 4 [327424/387873]    Loss: 0.002264   Batch Acc: 85.94
[Train] Epoch: 4 [327552/387873]    Loss: 0.001759   Batch Acc: 90.62
[Train] Epoch: 4 [327680/387873]    Loss: 0.001924   Batch Acc: 92.19
[Train] Epoch: 4 [327808/387873]    Loss: 0.002047   Batch Acc: 89.84
[Train] Epoch: 4 [327936/387873]    Loss: 0.002012   Batch Acc: 90.62
[Train] Epoch: 4 [328064/387873]    Loss: 0.002167   Batch Acc: 85.94
[Train] Epoch: 4 [328192/387873]    Loss: 0.001824   Batch Acc: 91.41
[Train] Epoch: 4 [328320/387873]    Loss: 0.002162   Batch Acc: 90.62
[Train] Epoch: 4 [328448/387873]    Loss: 0.001418   Batch Acc: 91.41
[Train] Epoch: 4 [328576/387873]    Loss: 0.002192   Batch Acc: 85.94
[Train] Epoch: 4 [328704/387873]    Loss: 0.001563   Batch Acc: 91.41
[Train] Epoch: 4 [328832/387873]    Loss: 0.002532   Batch Acc: 87.50
[Train] Epoch: 4 [328960/387873]    Loss: 0.001775   Batch Acc: 90.62
[Train] Epoch: 4 [329088/387873]    Loss: 0.001786   Batch Acc: 90.62
[Train] Epoch: 4 [329216/387873]    Loss: 0.002466   Batch Acc: 84.38
[Train] Epoch: 4 [329344/387873]    Loss: 0.001613   Batch Acc: 93.75
[Train] Epoch: 4 [329472/387873]    Loss: 0.001913   Batch Acc: 91.41
[Train] Epoch: 4 [329600/387873]    Loss: 0.002371   Batch Acc: 88.28
[Train] Epoch: 4 [329728/387873]    Loss: 0.001972   Batch Acc: 90.62
[Train] Epoch: 4 [329856/387873]    Loss: 0.002246   Batch Acc: 87.50
[Train] Epoch: 4 [329984/387873]    Loss: 0.001408   Batch Acc: 93.75
[Train] Epoch: 4 [330112/387873]    Loss: 0.001865   Batch Acc: 89.84
[Train] Epoch: 4 [330240/387873]    Loss: 0.001632   Batch Acc: 92.19
[Train] Epoch: 4 [330368/387873]    Loss: 0.001671   Batch Acc: 89.06
[Train] Epoch: 4 [330496/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 4 [330624/387873]    Loss: 0.002175   Batch Acc: 89.06
[Train] Epoch: 4 [330752/387873]    Loss: 0.001760   Batch Acc: 92.19
[Train] Epoch: 4 [330880/387873]    Loss: 0.001620   Batch Acc: 91.41
[Train] Epoch: 4 [331008/387873]    Loss: 0.002495   Batch Acc: 89.06
[Train] Epoch: 4 [331136/387873]    Loss: 0.002029   Batch Acc: 88.28
[Train] Epoch: 4 [331264/387873]    Loss: 0.001551   Batch Acc: 91.41
[Train] Epoch: 4 [331392/387873]    Loss: 0.001680   Batch Acc: 92.19
[Train] Epoch: 4 [331520/387873]    Loss: 0.002372   Batch Acc: 85.94
[Train] Epoch: 4 [331648/387873]    Loss: 0.001823   Batch Acc: 91.41
[Train] Epoch: 4 [331776/387873]    Loss: 0.001976   Batch Acc: 92.19
[Train] Epoch: 4 [331904/387873]    Loss: 0.002595   Batch Acc: 84.38
[Train] Epoch: 4 [332032/387873]    Loss: 0.001781   Batch Acc: 89.06
[Train] Epoch: 4 [332160/387873]    Loss: 0.002119   Batch Acc: 90.62
[Train] Epoch: 4 [332288/387873]    Loss: 0.001778   Batch Acc: 92.19
[Train] Epoch: 4 [332416/387873]    Loss: 0.001276   Batch Acc: 95.31
[Train] Epoch: 4 [332544/387873]    Loss: 0.001643   Batch Acc: 90.62
[Train] Epoch: 4 [332672/387873]    Loss: 0.001925   Batch Acc: 90.62
[Train] Epoch: 4 [332800/387873]    Loss: 0.001618   Batch Acc: 90.62
[Train] Epoch: 4 [332928/387873]    Loss: 0.002270   Batch Acc: 87.50
[Train] Epoch: 4 [333056/387873]    Loss: 0.001887   Batch Acc: 89.84
[Train] Epoch: 4 [333184/387873]    Loss: 0.002047   Batch Acc: 88.28
[Train] Epoch: 4 [333312/387873]    Loss: 0.002005   Batch Acc: 86.72
[Train] Epoch: 4 [333440/387873]    Loss: 0.001960   Batch Acc: 90.62
[Train] Epoch: 4 [333568/387873]    Loss: 0.001950   Batch Acc: 91.41
[Train] Epoch: 4 [333696/387873]    Loss: 0.002087   Batch Acc: 89.06
[Train] Epoch: 4 [333824/387873]    Loss: 0.002421   Batch Acc: 87.50
[Train] Epoch: 4 [333952/387873]    Loss: 0.002012   Batch Acc: 89.84
[Train] Epoch: 4 [334080/387873]    Loss: 0.001834   Batch Acc: 88.28
[Train] Epoch: 4 [334208/387873]    Loss: 0.001454   Batch Acc: 92.19
[Train] Epoch: 4 [334336/387873]    Loss: 0.002160   Batch Acc: 88.28
[Train] Epoch: 4 [334464/387873]    Loss: 0.001599   Batch Acc: 92.19
[Train] Epoch: 4 [334592/387873]    Loss: 0.001581   Batch Acc: 90.62
[Train] Epoch: 4 [334720/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 4 [334848/387873]    Loss: 0.001990   Batch Acc: 86.72
[Train] Epoch: 4 [334976/387873]    Loss: 0.001670   Batch Acc: 88.28
[Train] Epoch: 4 [335104/387873]    Loss: 0.002156   Batch Acc: 86.72
[Train] Epoch: 4 [335232/387873]    Loss: 0.002087   Batch Acc: 89.06
[Train] Epoch: 4 [335360/387873]    Loss: 0.002435   Batch Acc: 86.72
[Train] Epoch: 4 [335488/387873]    Loss: 0.001548   Batch Acc: 92.19
[Train] Epoch: 4 [335616/387873]    Loss: 0.001634   Batch Acc: 92.19
[Train] Epoch: 4 [335744/387873]    Loss: 0.001747   Batch Acc: 92.19
[Train] Epoch: 4 [335872/387873]    Loss: 0.002108   Batch Acc: 89.06
[Train] Epoch: 4 [336000/387873]    Loss: 0.002151   Batch Acc: 86.72
[Train] Epoch: 4 [336128/387873]    Loss: 0.002424   Batch Acc: 83.59
[Train] Epoch: 4 [336256/387873]    Loss: 0.001885   Batch Acc: 91.41
[Train] Epoch: 4 [336384/387873]    Loss: 0.001551   Batch Acc: 93.75
[Train] Epoch: 4 [336512/387873]    Loss: 0.001636   Batch Acc: 91.41
[Train] Epoch: 4 [336640/387873]    Loss: 0.001670   Batch Acc: 93.75
[Train] Epoch: 4 [336768/387873]    Loss: 0.002067   Batch Acc: 91.41
[Train] Epoch: 4 [336896/387873]    Loss: 0.002074   Batch Acc: 89.06
[Train] Epoch: 4 [337024/387873]    Loss: 0.001680   Batch Acc: 91.41
[Train] Epoch: 4 [337152/387873]    Loss: 0.002030   Batch Acc: 89.84
[Train] Epoch: 4 [337280/387873]    Loss: 0.001871   Batch Acc: 91.41
[Train] Epoch: 4 [337408/387873]    Loss: 0.001676   Batch Acc: 90.62
[Train] Epoch: 4 [337536/387873]    Loss: 0.001272   Batch Acc: 96.88
[Train] Epoch: 4 [337664/387873]    Loss: 0.002049   Batch Acc: 89.84
[Train] Epoch: 4 [337792/387873]    Loss: 0.002366   Batch Acc: 86.72
[Train] Epoch: 4 [337920/387873]    Loss: 0.002073   Batch Acc: 89.84
[Train] Epoch: 4 [338048/387873]    Loss: 0.001751   Batch Acc: 90.62
[Train] Epoch: 4 [338176/387873]    Loss: 0.002111   Batch Acc: 85.16
[Train] Epoch: 4 [338304/387873]    Loss: 0.001822   Batch Acc: 90.62
[Train] Epoch: 4 [338432/387873]    Loss: 0.002676   Batch Acc: 79.69
[Train] Epoch: 4 [338560/387873]    Loss: 0.001572   Batch Acc: 91.41
[Train] Epoch: 4 [338688/387873]    Loss: 0.002449   Batch Acc: 85.94
[Train] Epoch: 4 [338816/387873]    Loss: 0.002059   Batch Acc: 86.72
[Train] Epoch: 4 [338944/387873]    Loss: 0.002972   Batch Acc: 83.59
[Train] Epoch: 4 [339072/387873]    Loss: 0.001803   Batch Acc: 90.62
[Train] Epoch: 4 [339200/387873]    Loss: 0.002244   Batch Acc: 89.06
[Train] Epoch: 4 [339328/387873]    Loss: 0.002165   Batch Acc: 89.06
[Train] Epoch: 4 [339456/387873]    Loss: 0.001898   Batch Acc: 90.62
[Train] Epoch: 4 [339584/387873]    Loss: 0.002313   Batch Acc: 89.06
[Train] Epoch: 4 [339712/387873]    Loss: 0.002019   Batch Acc: 88.28
[Train] Epoch: 4 [339840/387873]    Loss: 0.002082   Batch Acc: 88.28
[Train] Epoch: 4 [339968/387873]    Loss: 0.001567   Batch Acc: 91.41
[Train] Epoch: 4 [340096/387873]    Loss: 0.002455   Batch Acc: 85.94
[Train] Epoch: 4 [340224/387873]    Loss: 0.001668   Batch Acc: 92.19
[Train] Epoch: 4 [340352/387873]    Loss: 0.001924   Batch Acc: 89.84
[Train] Epoch: 4 [340480/387873]    Loss: 0.001922   Batch Acc: 89.84
[Train] Epoch: 4 [340608/387873]    Loss: 0.001853   Batch Acc: 91.41
[Train] Epoch: 4 [340736/387873]    Loss: 0.001859   Batch Acc: 89.06
[Train] Epoch: 4 [340864/387873]    Loss: 0.002031   Batch Acc: 88.28
[Train] Epoch: 4 [340992/387873]    Loss: 0.001417   Batch Acc: 94.53
[Train] Epoch: 4 [341120/387873]    Loss: 0.002284   Batch Acc: 87.50
[Train] Epoch: 4 [341248/387873]    Loss: 0.001945   Batch Acc: 92.19
[Train] Epoch: 4 [341376/387873]    Loss: 0.001916   Batch Acc: 89.06
[Train] Epoch: 4 [341504/387873]    Loss: 0.002116   Batch Acc: 88.28
[Train] Epoch: 4 [341632/387873]    Loss: 0.001807   Batch Acc: 91.41
[Train] Epoch: 4 [341760/387873]    Loss: 0.002251   Batch Acc: 85.16
[Train] Epoch: 4 [341888/387873]    Loss: 0.002416   Batch Acc: 87.50
[Train] Epoch: 4 [342016/387873]    Loss: 0.002106   Batch Acc: 89.84
[Train] Epoch: 4 [342144/387873]    Loss: 0.002111   Batch Acc: 86.72
[Train] Epoch: 4 [342272/387873]    Loss: 0.001999   Batch Acc: 88.28
[Train] Epoch: 4 [342400/387873]    Loss: 0.001894   Batch Acc: 90.62
[Train] Epoch: 4 [342528/387873]    Loss: 0.002098   Batch Acc: 88.28
[Train] Epoch: 4 [342656/387873]    Loss: 0.002106   Batch Acc: 89.06
[Train] Epoch: 4 [342784/387873]    Loss: 0.001914   Batch Acc: 91.41
[Train] Epoch: 4 [342912/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 4 [343040/387873]    Loss: 0.002368   Batch Acc: 88.28
[Train] Epoch: 4 [343168/387873]    Loss: 0.002761   Batch Acc: 84.38
[Train] Epoch: 4 [343296/387873]    Loss: 0.001998   Batch Acc: 86.72
[Train] Epoch: 4 [343424/387873]    Loss: 0.001888   Batch Acc: 89.84
[Train] Epoch: 4 [343552/387873]    Loss: 0.002243   Batch Acc: 89.06
[Train] Epoch: 4 [343680/387873]    Loss: 0.001650   Batch Acc: 90.62
[Train] Epoch: 4 [343808/387873]    Loss: 0.001878   Batch Acc: 89.06
[Train] Epoch: 4 [343936/387873]    Loss: 0.002387   Batch Acc: 82.81
[Train] Epoch: 4 [344064/387873]    Loss: 0.002118   Batch Acc: 90.62
[Train] Epoch: 4 [344192/387873]    Loss: 0.001444   Batch Acc: 93.75
[Train] Epoch: 4 [344320/387873]    Loss: 0.001395   Batch Acc: 92.97
[Train] Epoch: 4 [344448/387873]    Loss: 0.001084   Batch Acc: 95.31
[Train] Epoch: 4 [344576/387873]    Loss: 0.001918   Batch Acc: 89.06
[Train] Epoch: 4 [344704/387873]    Loss: 0.002210   Batch Acc: 88.28
[Train] Epoch: 4 [344832/387873]    Loss: 0.002709   Batch Acc: 82.81
[Train] Epoch: 4 [344960/387873]    Loss: 0.001896   Batch Acc: 90.62
[Train] Epoch: 4 [345088/387873]    Loss: 0.001982   Batch Acc: 89.84
[Train] Epoch: 4 [345216/387873]    Loss: 0.002281   Batch Acc: 86.72
[Train] Epoch: 4 [345344/387873]    Loss: 0.001765   Batch Acc: 92.19
[Train] Epoch: 4 [345472/387873]    Loss: 0.002419   Batch Acc: 85.16
[Train] Epoch: 4 [345600/387873]    Loss: 0.002116   Batch Acc: 89.84
[Train] Epoch: 4 [345728/387873]    Loss: 0.001501   Batch Acc: 90.62
[Train] Epoch: 4 [345856/387873]    Loss: 0.002241   Batch Acc: 85.94
[Train] Epoch: 4 [345984/387873]    Loss: 0.001445   Batch Acc: 94.53
[Train] Epoch: 4 [346112/387873]    Loss: 0.002253   Batch Acc: 87.50
[Train] Epoch: 4 [346240/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 4 [346368/387873]    Loss: 0.001865   Batch Acc: 90.62
[Train] Epoch: 4 [346496/387873]    Loss: 0.002121   Batch Acc: 86.72
[Train] Epoch: 4 [346624/387873]    Loss: 0.001903   Batch Acc: 89.06
[Train] Epoch: 4 [346752/387873]    Loss: 0.002289   Batch Acc: 86.72
[Train] Epoch: 4 [346880/387873]    Loss: 0.001745   Batch Acc: 88.28
[Train] Epoch: 4 [347008/387873]    Loss: 0.002035   Batch Acc: 89.84
[Train] Epoch: 4 [347136/387873]    Loss: 0.002220   Batch Acc: 89.06
[Train] Epoch: 4 [347264/387873]    Loss: 0.001629   Batch Acc: 92.19
[Train] Epoch: 4 [347392/387873]    Loss: 0.002142   Batch Acc: 86.72
[Train] Epoch: 4 [347520/387873]    Loss: 0.001955   Batch Acc: 89.84
[Train] Epoch: 4 [347648/387873]    Loss: 0.002331   Batch Acc: 86.72
[Train] Epoch: 4 [347776/387873]    Loss: 0.001861   Batch Acc: 89.84
[Train] Epoch: 4 [347904/387873]    Loss: 0.002116   Batch Acc: 91.41
[Train] Epoch: 4 [348032/387873]    Loss: 0.002303   Batch Acc: 88.28
[Train] Epoch: 4 [348160/387873]    Loss: 0.002090   Batch Acc: 87.50
[Train] Epoch: 4 [348288/387873]    Loss: 0.002362   Batch Acc: 86.72
[Train] Epoch: 4 [348416/387873]    Loss: 0.002072   Batch Acc: 87.50
[Train] Epoch: 4 [348544/387873]    Loss: 0.002146   Batch Acc: 88.28
[Train] Epoch: 4 [348672/387873]    Loss: 0.002081   Batch Acc: 87.50
[Train] Epoch: 4 [348800/387873]    Loss: 0.001757   Batch Acc: 89.06
[Train] Epoch: 4 [348928/387873]    Loss: 0.001879   Batch Acc: 91.41
[Train] Epoch: 4 [349056/387873]    Loss: 0.002052   Batch Acc: 89.84
[Train] Epoch: 4 [349184/387873]    Loss: 0.001971   Batch Acc: 88.28
[Train] Epoch: 4 [349312/387873]    Loss: 0.002495   Batch Acc: 84.38
[Train] Epoch: 4 [349440/387873]    Loss: 0.001915   Batch Acc: 89.06
[Train] Epoch: 4 [349568/387873]    Loss: 0.002064   Batch Acc: 89.06
[Train] Epoch: 4 [349696/387873]    Loss: 0.002134   Batch Acc: 84.38
[Train] Epoch: 4 [349824/387873]    Loss: 0.002042   Batch Acc: 89.84
[Train] Epoch: 4 [349952/387873]    Loss: 0.001448   Batch Acc: 94.53
[Train] Epoch: 4 [350080/387873]    Loss: 0.001495   Batch Acc: 91.41
[Train] Epoch: 4 [350208/387873]    Loss: 0.001514   Batch Acc: 92.19
[Train] Epoch: 4 [350336/387873]    Loss: 0.001914   Batch Acc: 90.62
[Train] Epoch: 4 [350464/387873]    Loss: 0.002347   Batch Acc: 85.16
[Train] Epoch: 4 [350592/387873]    Loss: 0.001999   Batch Acc: 88.28
[Train] Epoch: 4 [350720/387873]    Loss: 0.002335   Batch Acc: 89.06
[Train] Epoch: 4 [350848/387873]    Loss: 0.002106   Batch Acc: 89.06
[Train] Epoch: 4 [350976/387873]    Loss: 0.001985   Batch Acc: 89.06
[Train] Epoch: 4 [351104/387873]    Loss: 0.001739   Batch Acc: 92.19
[Train] Epoch: 4 [351232/387873]    Loss: 0.002136   Batch Acc: 89.06
[Train] Epoch: 4 [351360/387873]    Loss: 0.001631   Batch Acc: 89.84
[Train] Epoch: 4 [351488/387873]    Loss: 0.001773   Batch Acc: 90.62
[Train] Epoch: 4 [351616/387873]    Loss: 0.002512   Batch Acc: 82.81
[Train] Epoch: 4 [351744/387873]    Loss: 0.001937   Batch Acc: 89.06
[Train] Epoch: 4 [351872/387873]    Loss: 0.002141   Batch Acc: 89.84
[Train] Epoch: 4 [352000/387873]    Loss: 0.001564   Batch Acc: 90.62
[Train] Epoch: 4 [352128/387873]    Loss: 0.002571   Batch Acc: 85.16
[Train] Epoch: 4 [352256/387873]    Loss: 0.002190   Batch Acc: 85.94
[Train] Epoch: 4 [352384/387873]    Loss: 0.001869   Batch Acc: 90.62
[Train] Epoch: 4 [352512/387873]    Loss: 0.001951   Batch Acc: 92.97
[Train] Epoch: 4 [352640/387873]    Loss: 0.001707   Batch Acc: 92.19
[Train] Epoch: 4 [352768/387873]    Loss: 0.001810   Batch Acc: 90.62
[Train] Epoch: 4 [352896/387873]    Loss: 0.002211   Batch Acc: 82.81
[Train] Epoch: 4 [353024/387873]    Loss: 0.002003   Batch Acc: 89.06
[Train] Epoch: 4 [353152/387873]    Loss: 0.002144   Batch Acc: 86.72
[Train] Epoch: 4 [353280/387873]    Loss: 0.001782   Batch Acc: 92.19
[Train] Epoch: 4 [353408/387873]    Loss: 0.001551   Batch Acc: 93.75
[Train] Epoch: 4 [353536/387873]    Loss: 0.002269   Batch Acc: 90.62
[Train] Epoch: 4 [353664/387873]    Loss: 0.001528   Batch Acc: 90.62
[Train] Epoch: 4 [353792/387873]    Loss: 0.001677   Batch Acc: 92.97
[Train] Epoch: 4 [353920/387873]    Loss: 0.001710   Batch Acc: 91.41
[Train] Epoch: 4 [354048/387873]    Loss: 0.001921   Batch Acc: 91.41
[Train] Epoch: 4 [354176/387873]    Loss: 0.001839   Batch Acc: 90.62
[Train] Epoch: 4 [354304/387873]    Loss: 0.002049   Batch Acc: 86.72
[Train] Epoch: 4 [354432/387873]    Loss: 0.001740   Batch Acc: 93.75
[Train] Epoch: 4 [354560/387873]    Loss: 0.002304   Batch Acc: 86.72
[Train] Epoch: 4 [354688/387873]    Loss: 0.002181   Batch Acc: 89.06
[Train] Epoch: 4 [354816/387873]    Loss: 0.001865   Batch Acc: 90.62
[Train] Epoch: 4 [354944/387873]    Loss: 0.001981   Batch Acc: 92.19
[Train] Epoch: 4 [355072/387873]    Loss: 0.001819   Batch Acc: 91.41
[Train] Epoch: 4 [355200/387873]    Loss: 0.001645   Batch Acc: 91.41
[Train] Epoch: 4 [355328/387873]    Loss: 0.002342   Batch Acc: 89.06
[Train] Epoch: 4 [355456/387873]    Loss: 0.001814   Batch Acc: 90.62
[Train] Epoch: 4 [355584/387873]    Loss: 0.002188   Batch Acc: 88.28
[Train] Epoch: 4 [355712/387873]    Loss: 0.002372   Batch Acc: 84.38
[Train] Epoch: 4 [355840/387873]    Loss: 0.001673   Batch Acc: 90.62
[Train] Epoch: 4 [355968/387873]    Loss: 0.001556   Batch Acc: 93.75
[Train] Epoch: 4 [356096/387873]    Loss: 0.002649   Batch Acc: 85.16
[Train] Epoch: 4 [356224/387873]    Loss: 0.001722   Batch Acc: 89.84
[Train] Epoch: 4 [356352/387873]    Loss: 0.002301   Batch Acc: 89.06
[Train] Epoch: 4 [356480/387873]    Loss: 0.001829   Batch Acc: 92.19
[Train] Epoch: 4 [356608/387873]    Loss: 0.001903   Batch Acc: 89.84
[Train] Epoch: 4 [356736/387873]    Loss: 0.001783   Batch Acc: 93.75
[Train] Epoch: 4 [356864/387873]    Loss: 0.002112   Batch Acc: 89.84
[Train] Epoch: 4 [356992/387873]    Loss: 0.001785   Batch Acc: 92.97
[Train] Epoch: 4 [357120/387873]    Loss: 0.001646   Batch Acc: 93.75
[Train] Epoch: 4 [357248/387873]    Loss: 0.001526   Batch Acc: 91.41
[Train] Epoch: 4 [357376/387873]    Loss: 0.002130   Batch Acc: 89.06
[Train] Epoch: 4 [357504/387873]    Loss: 0.001938   Batch Acc: 89.06
[Train] Epoch: 4 [357632/387873]    Loss: 0.001472   Batch Acc: 93.75
[Train] Epoch: 4 [357760/387873]    Loss: 0.001623   Batch Acc: 90.62
[Train] Epoch: 4 [357888/387873]    Loss: 0.002256   Batch Acc: 89.06
[Train] Epoch: 4 [358016/387873]    Loss: 0.001921   Batch Acc: 91.41
[Train] Epoch: 4 [358144/387873]    Loss: 0.002138   Batch Acc: 89.06
[Train] Epoch: 4 [358272/387873]    Loss: 0.001895   Batch Acc: 90.62
[Train] Epoch: 4 [358400/387873]    Loss: 0.001911   Batch Acc: 89.84
[Train] Epoch: 4 [358528/387873]    Loss: 0.001408   Batch Acc: 94.53
[Train] Epoch: 4 [358656/387873]    Loss: 0.002213   Batch Acc: 89.84
[Train] Epoch: 4 [358784/387873]    Loss: 0.001812   Batch Acc: 89.84
[Train] Epoch: 4 [358912/387873]    Loss: 0.001850   Batch Acc: 89.84
[Train] Epoch: 4 [359040/387873]    Loss: 0.002060   Batch Acc: 89.84
[Train] Epoch: 4 [359168/387873]    Loss: 0.001653   Batch Acc: 91.41
[Train] Epoch: 4 [359296/387873]    Loss: 0.001882   Batch Acc: 89.84
[Train] Epoch: 4 [359424/387873]    Loss: 0.001593   Batch Acc: 92.97
[Train] Epoch: 4 [359552/387873]    Loss: 0.001707   Batch Acc: 90.62
[Train] Epoch: 4 [359680/387873]    Loss: 0.001385   Batch Acc: 93.75
[Train] Epoch: 4 [359808/387873]    Loss: 0.001859   Batch Acc: 91.41
[Train] Epoch: 4 [359936/387873]    Loss: 0.001657   Batch Acc: 92.97
[Train] Epoch: 4 [360064/387873]    Loss: 0.001711   Batch Acc: 91.41
[Train] Epoch: 4 [360192/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 4 [360320/387873]    Loss: 0.001724   Batch Acc: 91.41
[Train] Epoch: 4 [360448/387873]    Loss: 0.001694   Batch Acc: 91.41
[Train] Epoch: 4 [360576/387873]    Loss: 0.001548   Batch Acc: 92.97
[Train] Epoch: 4 [360704/387873]    Loss: 0.002526   Batch Acc: 86.72
[Train] Epoch: 4 [360832/387873]    Loss: 0.001890   Batch Acc: 92.19
[Train] Epoch: 4 [360960/387873]    Loss: 0.002059   Batch Acc: 87.50
[Train] Epoch: 4 [361088/387873]    Loss: 0.002020   Batch Acc: 91.41
[Train] Epoch: 4 [361216/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 4 [361344/387873]    Loss: 0.002285   Batch Acc: 89.84
[Train] Epoch: 4 [361472/387873]    Loss: 0.001701   Batch Acc: 91.41
[Train] Epoch: 4 [361600/387873]    Loss: 0.001825   Batch Acc: 92.19
[Train] Epoch: 4 [361728/387873]    Loss: 0.001887   Batch Acc: 92.97
[Train] Epoch: 4 [361856/387873]    Loss: 0.002053   Batch Acc: 85.16
[Train] Epoch: 4 [361984/387873]    Loss: 0.002639   Batch Acc: 86.72
[Train] Epoch: 4 [362112/387873]    Loss: 0.001659   Batch Acc: 90.62
[Train] Epoch: 4 [362240/387873]    Loss: 0.001685   Batch Acc: 89.84
[Train] Epoch: 4 [362368/387873]    Loss: 0.001673   Batch Acc: 92.19
[Train] Epoch: 4 [362496/387873]    Loss: 0.002418   Batch Acc: 83.59
[Train] Epoch: 4 [362624/387873]    Loss: 0.002050   Batch Acc: 89.84
[Train] Epoch: 4 [362752/387873]    Loss: 0.001610   Batch Acc: 89.06
[Train] Epoch: 4 [362880/387873]    Loss: 0.001739   Batch Acc: 89.06
[Train] Epoch: 4 [363008/387873]    Loss: 0.002876   Batch Acc: 86.72
[Train] Epoch: 4 [363136/387873]    Loss: 0.002439   Batch Acc: 86.72
[Train] Epoch: 4 [363264/387873]    Loss: 0.002172   Batch Acc: 89.06
[Train] Epoch: 4 [363392/387873]    Loss: 0.002285   Batch Acc: 84.38
[Train] Epoch: 4 [363520/387873]    Loss: 0.002503   Batch Acc: 83.59
[Train] Epoch: 4 [363648/387873]    Loss: 0.001715   Batch Acc: 91.41
[Train] Epoch: 4 [363776/387873]    Loss: 0.001682   Batch Acc: 91.41
[Train] Epoch: 4 [363904/387873]    Loss: 0.002608   Batch Acc: 88.28
[Train] Epoch: 4 [364032/387873]    Loss: 0.001528   Batch Acc: 95.31
[Train] Epoch: 4 [364160/387873]    Loss: 0.002109   Batch Acc: 86.72
[Train] Epoch: 4 [364288/387873]    Loss: 0.002229   Batch Acc: 88.28
[Train] Epoch: 4 [364416/387873]    Loss: 0.001824   Batch Acc: 91.41
[Train] Epoch: 4 [364544/387873]    Loss: 0.001933   Batch Acc: 89.06
[Train] Epoch: 4 [364672/387873]    Loss: 0.002204   Batch Acc: 84.38
[Train] Epoch: 4 [364800/387873]    Loss: 0.001992   Batch Acc: 89.84
[Train] Epoch: 4 [364928/387873]    Loss: 0.002019   Batch Acc: 89.84
[Train] Epoch: 4 [365056/387873]    Loss: 0.001954   Batch Acc: 89.84
[Train] Epoch: 4 [365184/387873]    Loss: 0.002137   Batch Acc: 88.28
[Train] Epoch: 4 [365312/387873]    Loss: 0.002124   Batch Acc: 89.06
[Train] Epoch: 4 [365440/387873]    Loss: 0.002387   Batch Acc: 88.28
[Train] Epoch: 4 [365568/387873]    Loss: 0.002079   Batch Acc: 86.72
[Train] Epoch: 4 [365696/387873]    Loss: 0.001764   Batch Acc: 91.41
[Train] Epoch: 4 [365824/387873]    Loss: 0.002076   Batch Acc: 86.72
[Train] Epoch: 4 [365952/387873]    Loss: 0.002373   Batch Acc: 91.41
[Train] Epoch: 4 [366080/387873]    Loss: 0.002059   Batch Acc: 88.28
[Train] Epoch: 4 [366208/387873]    Loss: 0.001673   Batch Acc: 92.97
[Train] Epoch: 4 [366336/387873]    Loss: 0.002013   Batch Acc: 89.84
[Train] Epoch: 4 [366464/387873]    Loss: 0.002201   Batch Acc: 88.28
[Train] Epoch: 4 [366592/387873]    Loss: 0.002425   Batch Acc: 90.62
[Train] Epoch: 4 [366720/387873]    Loss: 0.001757   Batch Acc: 91.41
[Train] Epoch: 4 [366848/387873]    Loss: 0.002148   Batch Acc: 85.16
[Train] Epoch: 4 [366976/387873]    Loss: 0.001786   Batch Acc: 89.84
[Train] Epoch: 4 [367104/387873]    Loss: 0.001986   Batch Acc: 89.84
[Train] Epoch: 4 [367232/387873]    Loss: 0.001669   Batch Acc: 93.75
[Train] Epoch: 4 [367360/387873]    Loss: 0.001732   Batch Acc: 92.19
[Train] Epoch: 4 [367488/387873]    Loss: 0.001800   Batch Acc: 92.19
[Train] Epoch: 4 [367616/387873]    Loss: 0.001723   Batch Acc: 89.84
[Train] Epoch: 4 [367744/387873]    Loss: 0.001829   Batch Acc: 91.41
[Train] Epoch: 4 [367872/387873]    Loss: 0.001733   Batch Acc: 92.97
[Train] Epoch: 4 [368000/387873]    Loss: 0.002212   Batch Acc: 85.16
[Train] Epoch: 4 [368128/387873]    Loss: 0.001878   Batch Acc: 89.06
[Train] Epoch: 4 [368256/387873]    Loss: 0.002052   Batch Acc: 88.28
[Train] Epoch: 4 [368384/387873]    Loss: 0.002224   Batch Acc: 90.62
[Train] Epoch: 4 [368512/387873]    Loss: 0.001679   Batch Acc: 91.41
[Train] Epoch: 4 [368640/387873]    Loss: 0.001892   Batch Acc: 89.84
[Train] Epoch: 4 [368768/387873]    Loss: 0.002077   Batch Acc: 86.72
[Train] Epoch: 4 [368896/387873]    Loss: 0.001728   Batch Acc: 91.41
[Train] Epoch: 4 [369024/387873]    Loss: 0.002429   Batch Acc: 86.72
[Train] Epoch: 4 [369152/387873]    Loss: 0.002095   Batch Acc: 87.50
[Train] Epoch: 4 [369280/387873]    Loss: 0.001929   Batch Acc: 89.06
[Train] Epoch: 4 [369408/387873]    Loss: 0.001966   Batch Acc: 90.62
[Train] Epoch: 4 [369536/387873]    Loss: 0.001986   Batch Acc: 89.84
[Train] Epoch: 4 [369664/387873]    Loss: 0.003002   Batch Acc: 84.38
[Train] Epoch: 4 [369792/387873]    Loss: 0.001731   Batch Acc: 91.41
[Train] Epoch: 4 [369920/387873]    Loss: 0.002138   Batch Acc: 86.72
[Train] Epoch: 4 [370048/387873]    Loss: 0.002769   Batch Acc: 83.59
[Train] Epoch: 4 [370176/387873]    Loss: 0.002565   Batch Acc: 84.38
[Train] Epoch: 4 [370304/387873]    Loss: 0.001884   Batch Acc: 88.28
[Train] Epoch: 4 [370432/387873]    Loss: 0.001744   Batch Acc: 90.62
[Train] Epoch: 4 [370560/387873]    Loss: 0.001738   Batch Acc: 91.41
[Train] Epoch: 4 [370688/387873]    Loss: 0.002705   Batch Acc: 85.94
[Train] Epoch: 4 [370816/387873]    Loss: 0.001683   Batch Acc: 91.41
[Train] Epoch: 4 [370944/387873]    Loss: 0.002068   Batch Acc: 89.06
[Train] Epoch: 4 [371072/387873]    Loss: 0.001634   Batch Acc: 92.97
[Train] Epoch: 4 [371200/387873]    Loss: 0.002714   Batch Acc: 84.38
[Train] Epoch: 4 [371328/387873]    Loss: 0.001893   Batch Acc: 92.97
[Train] Epoch: 4 [371456/387873]    Loss: 0.002113   Batch Acc: 87.50
[Train] Epoch: 4 [371584/387873]    Loss: 0.002202   Batch Acc: 86.72
[Train] Epoch: 4 [371712/387873]    Loss: 0.001588   Batch Acc: 90.62
[Train] Epoch: 4 [371840/387873]    Loss: 0.002243   Batch Acc: 86.72
[Train] Epoch: 4 [371968/387873]    Loss: 0.002005   Batch Acc: 91.41
[Train] Epoch: 4 [372096/387873]    Loss: 0.002029   Batch Acc: 88.28
[Train] Epoch: 4 [372224/387873]    Loss: 0.001757   Batch Acc: 92.19
[Train] Epoch: 4 [372352/387873]    Loss: 0.001965   Batch Acc: 91.41
[Train] Epoch: 4 [372480/387873]    Loss: 0.002214   Batch Acc: 89.06
[Train] Epoch: 4 [372608/387873]    Loss: 0.002220   Batch Acc: 90.62
[Train] Epoch: 4 [372736/387873]    Loss: 0.001730   Batch Acc: 91.41
[Train] Epoch: 4 [372864/387873]    Loss: 0.001982   Batch Acc: 89.84
[Train] Epoch: 4 [372992/387873]    Loss: 0.002076   Batch Acc: 89.84
[Train] Epoch: 4 [373120/387873]    Loss: 0.002029   Batch Acc: 89.06
[Train] Epoch: 4 [373248/387873]    Loss: 0.002435   Batch Acc: 87.50
[Train] Epoch: 4 [373376/387873]    Loss: 0.002237   Batch Acc: 88.28
[Train] Epoch: 4 [373504/387873]    Loss: 0.001854   Batch Acc: 92.97
[Train] Epoch: 4 [373632/387873]    Loss: 0.001893   Batch Acc: 90.62
[Train] Epoch: 4 [373760/387873]    Loss: 0.002066   Batch Acc: 89.84
[Train] Epoch: 4 [373888/387873]    Loss: 0.002366   Batch Acc: 85.16
[Train] Epoch: 4 [374016/387873]    Loss: 0.001660   Batch Acc: 92.19
[Train] Epoch: 4 [374144/387873]    Loss: 0.002044   Batch Acc: 90.62
[Train] Epoch: 4 [374272/387873]    Loss: 0.001829   Batch Acc: 90.62
[Train] Epoch: 4 [374400/387873]    Loss: 0.002115   Batch Acc: 89.06
[Train] Epoch: 4 [374528/387873]    Loss: 0.002189   Batch Acc: 86.72
[Train] Epoch: 4 [374656/387873]    Loss: 0.001514   Batch Acc: 95.31
[Train] Epoch: 4 [374784/387873]    Loss: 0.002138   Batch Acc: 85.16
[Train] Epoch: 4 [374912/387873]    Loss: 0.001616   Batch Acc: 91.41
[Train] Epoch: 4 [375040/387873]    Loss: 0.001833   Batch Acc: 90.62
[Train] Epoch: 4 [375168/387873]    Loss: 0.001647   Batch Acc: 93.75
[Train] Epoch: 4 [375296/387873]    Loss: 0.002467   Batch Acc: 83.59
[Train] Epoch: 4 [375424/387873]    Loss: 0.001846   Batch Acc: 89.06
[Train] Epoch: 4 [375552/387873]    Loss: 0.001980   Batch Acc: 88.28
[Train] Epoch: 4 [375680/387873]    Loss: 0.002018   Batch Acc: 89.84
[Train] Epoch: 4 [375808/387873]    Loss: 0.002048   Batch Acc: 89.06
[Train] Epoch: 4 [375936/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 4 [376064/387873]    Loss: 0.002190   Batch Acc: 89.84
[Train] Epoch: 4 [376192/387873]    Loss: 0.001345   Batch Acc: 95.31
[Train] Epoch: 4 [376320/387873]    Loss: 0.001728   Batch Acc: 92.97
[Train] Epoch: 4 [376448/387873]    Loss: 0.002494   Batch Acc: 89.06
[Train] Epoch: 4 [376576/387873]    Loss: 0.001737   Batch Acc: 91.41
[Train] Epoch: 4 [376704/387873]    Loss: 0.001220   Batch Acc: 96.09
[Train] Epoch: 4 [376832/387873]    Loss: 0.002300   Batch Acc: 87.50
[Train] Epoch: 4 [376960/387873]    Loss: 0.002054   Batch Acc: 89.06
[Train] Epoch: 4 [377088/387873]    Loss: 0.001873   Batch Acc: 89.84
[Train] Epoch: 4 [377216/387873]    Loss: 0.002444   Batch Acc: 83.59
[Train] Epoch: 4 [377344/387873]    Loss: 0.002301   Batch Acc: 87.50
[Train] Epoch: 4 [377472/387873]    Loss: 0.002360   Batch Acc: 86.72
[Train] Epoch: 4 [377600/387873]    Loss: 0.002408   Batch Acc: 85.16
[Train] Epoch: 4 [377728/387873]    Loss: 0.002075   Batch Acc: 88.28
[Train] Epoch: 4 [377856/387873]    Loss: 0.001881   Batch Acc: 89.06
[Train] Epoch: 4 [377984/387873]    Loss: 0.001830   Batch Acc: 89.84
[Train] Epoch: 4 [378112/387873]    Loss: 0.001860   Batch Acc: 91.41
[Train] Epoch: 4 [378240/387873]    Loss: 0.001831   Batch Acc: 88.28
[Train] Epoch: 4 [378368/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 4 [378496/387873]    Loss: 0.002250   Batch Acc: 89.06
[Train] Epoch: 4 [378624/387873]    Loss: 0.001532   Batch Acc: 92.19
[Train] Epoch: 4 [378752/387873]    Loss: 0.001812   Batch Acc: 92.19
[Train] Epoch: 4 [378880/387873]    Loss: 0.001818   Batch Acc: 89.84
[Train] Epoch: 4 [379008/387873]    Loss: 0.001945   Batch Acc: 89.84
[Train] Epoch: 4 [379136/387873]    Loss: 0.001756   Batch Acc: 89.84
[Train] Epoch: 4 [379264/387873]    Loss: 0.002233   Batch Acc: 89.06
[Train] Epoch: 4 [379392/387873]    Loss: 0.001586   Batch Acc: 91.41
[Train] Epoch: 4 [379520/387873]    Loss: 0.002242   Batch Acc: 90.62
[Train] Epoch: 4 [379648/387873]    Loss: 0.002399   Batch Acc: 89.06
[Train] Epoch: 4 [379776/387873]    Loss: 0.001646   Batch Acc: 91.41
[Train] Epoch: 4 [379904/387873]    Loss: 0.002330   Batch Acc: 87.50
[Train] Epoch: 4 [380032/387873]    Loss: 0.001615   Batch Acc: 90.62
[Train] Epoch: 4 [380160/387873]    Loss: 0.001858   Batch Acc: 91.41
[Train] Epoch: 4 [380288/387873]    Loss: 0.001756   Batch Acc: 89.84
[Train] Epoch: 4 [380416/387873]    Loss: 0.001843   Batch Acc: 92.19
[Train] Epoch: 4 [380544/387873]    Loss: 0.001815   Batch Acc: 89.06
[Train] Epoch: 4 [380672/387873]    Loss: 0.001678   Batch Acc: 89.84
[Train] Epoch: 4 [380800/387873]    Loss: 0.001596   Batch Acc: 92.19
[Train] Epoch: 4 [380928/387873]    Loss: 0.001700   Batch Acc: 90.62
[Train] Epoch: 4 [381056/387873]    Loss: 0.001698   Batch Acc: 91.41
[Train] Epoch: 4 [381184/387873]    Loss: 0.001805   Batch Acc: 90.62
[Train] Epoch: 4 [381312/387873]    Loss: 0.001361   Batch Acc: 94.53
[Train] Epoch: 4 [381440/387873]    Loss: 0.002376   Batch Acc: 86.72
[Train] Epoch: 4 [381568/387873]    Loss: 0.002070   Batch Acc: 88.28
[Train] Epoch: 4 [381696/387873]    Loss: 0.001949   Batch Acc: 91.41
[Train] Epoch: 4 [381824/387873]    Loss: 0.002586   Batch Acc: 84.38
[Train] Epoch: 4 [381952/387873]    Loss: 0.001842   Batch Acc: 91.41
[Train] Epoch: 4 [382080/387873]    Loss: 0.001759   Batch Acc: 90.62
[Train] Epoch: 4 [382208/387873]    Loss: 0.002308   Batch Acc: 85.94
[Train] Epoch: 4 [382336/387873]    Loss: 0.001836   Batch Acc: 89.84
[Train] Epoch: 4 [382464/387873]    Loss: 0.002150   Batch Acc: 88.28
[Train] Epoch: 4 [382592/387873]    Loss: 0.001898   Batch Acc: 89.06
[Train] Epoch: 4 [382720/387873]    Loss: 0.001856   Batch Acc: 89.06
[Train] Epoch: 4 [382848/387873]    Loss: 0.001999   Batch Acc: 85.94
[Train] Epoch: 4 [382976/387873]    Loss: 0.001672   Batch Acc: 92.19
[Train] Epoch: 4 [383104/387873]    Loss: 0.001801   Batch Acc: 90.62
[Train] Epoch: 4 [383232/387873]    Loss: 0.002204   Batch Acc: 86.72
[Train] Epoch: 4 [383360/387873]    Loss: 0.001687   Batch Acc: 92.97
[Train] Epoch: 4 [383488/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 4 [383616/387873]    Loss: 0.002238   Batch Acc: 87.50
[Train] Epoch: 4 [383744/387873]    Loss: 0.001786   Batch Acc: 89.06
[Train] Epoch: 4 [383872/387873]    Loss: 0.002088   Batch Acc: 86.72
[Train] Epoch: 4 [384000/387873]    Loss: 0.001846   Batch Acc: 87.50
[Train] Epoch: 4 [384128/387873]    Loss: 0.002144   Batch Acc: 89.84
[Train] Epoch: 4 [384256/387873]    Loss: 0.001757   Batch Acc: 89.84
[Train] Epoch: 4 [384384/387873]    Loss: 0.001880   Batch Acc: 89.06
[Train] Epoch: 4 [384512/387873]    Loss: 0.001825   Batch Acc: 91.41
[Train] Epoch: 4 [384640/387873]    Loss: 0.002178   Batch Acc: 89.84
[Train] Epoch: 4 [384768/387873]    Loss: 0.001314   Batch Acc: 95.31
[Train] Epoch: 4 [384896/387873]    Loss: 0.002296   Batch Acc: 86.72
[Train] Epoch: 4 [385024/387873]    Loss: 0.001783   Batch Acc: 91.41
[Train] Epoch: 4 [385152/387873]    Loss: 0.001656   Batch Acc: 90.62
[Train] Epoch: 4 [385280/387873]    Loss: 0.001997   Batch Acc: 88.28
[Train] Epoch: 4 [385408/387873]    Loss: 0.001808   Batch Acc: 92.19
[Train] Epoch: 4 [385536/387873]    Loss: 0.001892   Batch Acc: 89.84
[Train] Epoch: 4 [385664/387873]    Loss: 0.002281   Batch Acc: 85.94
[Train] Epoch: 4 [385792/387873]    Loss: 0.001642   Batch Acc: 91.41
[Train] Epoch: 4 [385920/387873]    Loss: 0.001636   Batch Acc: 93.75
[Train] Epoch: 4 [386048/387873]    Loss: 0.002198   Batch Acc: 88.28
[Train] Epoch: 4 [386176/387873]    Loss: 0.001901   Batch Acc: 92.19
[Train] Epoch: 4 [386304/387873]    Loss: 0.002539   Batch Acc: 86.72
[Train] Epoch: 4 [386432/387873]    Loss: 0.001997   Batch Acc: 91.41
[Train] Epoch: 4 [386560/387873]    Loss: 0.001775   Batch Acc: 91.41
[Train] Epoch: 4 [386688/387873]    Loss: 0.001765   Batch Acc: 94.53
[Train] Epoch: 4 [386816/387873]    Loss: 0.001797   Batch Acc: 92.19
[Train] Epoch: 4 [386944/387873]    Loss: 0.001623   Batch Acc: 92.19
[Train] Epoch: 4 [387072/387873]    Loss: 0.001622   Batch Acc: 91.41
[Train] Epoch: 4 [387200/387873]    Loss: 0.002079   Batch Acc: 88.28
[Train] Epoch: 4 [387328/387873]    Loss: 0.002104   Batch Acc: 89.06
[Train] Epoch: 4 [387456/387873]    Loss: 0.002195   Batch Acc: 85.94
[Train] Epoch: 4 [387584/387873]    Loss: 0.002269   Batch Acc: 85.94
[Train] Epoch: 4 [387712/387873]    Loss: 0.002507   Batch Acc: 88.28
[Train] Epoch: 4 [387840/387873]    Loss: 0.001854   Batch Acc: 93.75
[Train] Epoch: 4 [100023/387873]    Loss: 0.009293   Batch Acc: 84.85
Validation Done: [128/84203]
Validation Done: [256/84203]
Validation Done: [384/84203]
Validation Done: [512/84203]
Validation Done: [640/84203]
Validation Done: [768/84203]
Validation Done: [896/84203]
Validation Done: [1024/84203]
Validation Done: [1152/84203]
Validation Done: [1280/84203]
Validation Done: [1408/84203]
Validation Done: [1536/84203]
Validation Done: [1664/84203]
Validation Done: [1792/84203]
Validation Done: [1920/84203]
Validation Done: [2048/84203]
Validation Done: [2176/84203]
Validation Done: [2304/84203]
Validation Done: [2432/84203]
Validation Done: [2560/84203]
Validation Done: [2688/84203]
Validation Done: [2816/84203]
Validation Done: [2944/84203]
Validation Done: [3072/84203]
Validation Done: [3200/84203]
Validation Done: [3328/84203]
Validation Done: [3456/84203]
Validation Done: [3584/84203]
Validation Done: [3712/84203]
Validation Done: [3840/84203]
Validation Done: [3968/84203]
Validation Done: [4096/84203]
Validation Done: [4224/84203]
Validation Done: [4352/84203]
Validation Done: [4480/84203]
Validation Done: [4608/84203]
Validation Done: [4736/84203]
Validation Done: [4864/84203]
Validation Done: [4992/84203]
Validation Done: [5120/84203]
Validation Done: [5248/84203]
Validation Done: [5376/84203]
Validation Done: [5504/84203]
Validation Done: [5632/84203]
Validation Done: [5760/84203]
Validation Done: [5888/84203]
Validation Done: [6016/84203]
Validation Done: [6144/84203]
Validation Done: [6272/84203]
Validation Done: [6400/84203]
Validation Done: [6528/84203]
Validation Done: [6656/84203]
Validation Done: [6784/84203]
Validation Done: [6912/84203]
Validation Done: [7040/84203]
Validation Done: [7168/84203]
Validation Done: [7296/84203]
Validation Done: [7424/84203]
Validation Done: [7552/84203]
Validation Done: [7680/84203]
Validation Done: [7808/84203]
Validation Done: [7936/84203]
Validation Done: [8064/84203]
Validation Done: [8192/84203]
Validation Done: [8320/84203]
Validation Done: [8448/84203]
Validation Done: [8576/84203]
Validation Done: [8704/84203]
Validation Done: [8832/84203]
Validation Done: [8960/84203]
Validation Done: [9088/84203]
Validation Done: [9216/84203]
Validation Done: [9344/84203]
Validation Done: [9472/84203]
Validation Done: [9600/84203]
Validation Done: [9728/84203]
Validation Done: [9856/84203]
Validation Done: [9984/84203]
Validation Done: [10112/84203]
Validation Done: [10240/84203]
Validation Done: [10368/84203]
Validation Done: [10496/84203]
Validation Done: [10624/84203]
Validation Done: [10752/84203]
Validation Done: [10880/84203]
Validation Done: [11008/84203]
Validation Done: [11136/84203]
Validation Done: [11264/84203]
Validation Done: [11392/84203]
Validation Done: [11520/84203]
Validation Done: [11648/84203]
Validation Done: [11776/84203]
Validation Done: [11904/84203]
Validation Done: [12032/84203]
Validation Done: [12160/84203]
Validation Done: [12288/84203]
Validation Done: [12416/84203]
Validation Done: [12544/84203]
Validation Done: [12672/84203]
Validation Done: [12800/84203]
Validation Done: [12928/84203]
Validation Done: [13056/84203]
Validation Done: [13184/84203]
Validation Done: [13312/84203]
Validation Done: [13440/84203]
Validation Done: [13568/84203]
Validation Done: [13696/84203]
Validation Done: [13824/84203]
Validation Done: [13952/84203]
Validation Done: [14080/84203]
Validation Done: [14208/84203]
Validation Done: [14336/84203]
Validation Done: [14464/84203]
Validation Done: [14592/84203]
Validation Done: [14720/84203]
Validation Done: [14848/84203]
Validation Done: [14976/84203]
Validation Done: [15104/84203]
Validation Done: [15232/84203]
Validation Done: [15360/84203]
Validation Done: [15488/84203]
Validation Done: [15616/84203]
Validation Done: [15744/84203]
Validation Done: [15872/84203]
Validation Done: [16000/84203]
Validation Done: [16128/84203]
Validation Done: [16256/84203]
Validation Done: [16384/84203]
Validation Done: [16512/84203]
Validation Done: [16640/84203]
Validation Done: [16768/84203]
Validation Done: [16896/84203]
Validation Done: [17024/84203]
Validation Done: [17152/84203]
Validation Done: [17280/84203]
Validation Done: [17408/84203]
Validation Done: [17536/84203]
Validation Done: [17664/84203]
Validation Done: [17792/84203]
Validation Done: [17920/84203]
Validation Done: [18048/84203]
Validation Done: [18176/84203]
Validation Done: [18304/84203]
Validation Done: [18432/84203]
Validation Done: [18560/84203]
Validation Done: [18688/84203]
Validation Done: [18816/84203]
Validation Done: [18944/84203]
Validation Done: [19072/84203]
Validation Done: [19200/84203]
Validation Done: [19328/84203]
Validation Done: [19456/84203]
Validation Done: [19584/84203]
Validation Done: [19712/84203]
Validation Done: [19840/84203]
Validation Done: [19968/84203]
Validation Done: [20096/84203]
Validation Done: [20224/84203]
Validation Done: [20352/84203]
Validation Done: [20480/84203]
Validation Done: [20608/84203]
Validation Done: [20736/84203]
Validation Done: [20864/84203]
Validation Done: [20992/84203]
Validation Done: [21120/84203]
Validation Done: [21248/84203]
Validation Done: [21376/84203]
Validation Done: [21504/84203]
Validation Done: [21632/84203]
Validation Done: [21760/84203]
Validation Done: [21888/84203]
Validation Done: [22016/84203]
Validation Done: [22144/84203]
Validation Done: [22272/84203]
Validation Done: [22400/84203]
Validation Done: [22528/84203]
Validation Done: [22656/84203]
Validation Done: [22784/84203]
Validation Done: [22912/84203]
Validation Done: [23040/84203]
Validation Done: [23168/84203]
Validation Done: [23296/84203]
Validation Done: [23424/84203]
Validation Done: [23552/84203]
Validation Done: [23680/84203]
Validation Done: [23808/84203]
Validation Done: [23936/84203]
Validation Done: [24064/84203]
Validation Done: [24192/84203]
Validation Done: [24320/84203]
Validation Done: [24448/84203]
Validation Done: [24576/84203]
Validation Done: [24704/84203]
Validation Done: [24832/84203]
Validation Done: [24960/84203]
Validation Done: [25088/84203]
Validation Done: [25216/84203]
Validation Done: [25344/84203]
Validation Done: [25472/84203]
Validation Done: [25600/84203]
Validation Done: [25728/84203]
Validation Done: [25856/84203]
Validation Done: [25984/84203]
Validation Done: [26112/84203]
Validation Done: [26240/84203]
Validation Done: [26368/84203]
Validation Done: [26496/84203]
Validation Done: [26624/84203]
Validation Done: [26752/84203]
Validation Done: [26880/84203]
Validation Done: [27008/84203]
Validation Done: [27136/84203]
Validation Done: [27264/84203]
Validation Done: [27392/84203]
Validation Done: [27520/84203]
Validation Done: [27648/84203]
Validation Done: [27776/84203]
Validation Done: [27904/84203]
Validation Done: [28032/84203]
Validation Done: [28160/84203]
Validation Done: [28288/84203]
Validation Done: [28416/84203]
Validation Done: [28544/84203]
Validation Done: [28672/84203]
Validation Done: [28800/84203]
Validation Done: [28928/84203]
Validation Done: [29056/84203]
Validation Done: [29184/84203]
Validation Done: [29312/84203]
Validation Done: [29440/84203]
Validation Done: [29568/84203]
Validation Done: [29696/84203]
Validation Done: [29824/84203]
Validation Done: [29952/84203]
Validation Done: [30080/84203]
Validation Done: [30208/84203]
Validation Done: [30336/84203]
Validation Done: [30464/84203]
Validation Done: [30592/84203]
Validation Done: [30720/84203]
Validation Done: [30848/84203]
Validation Done: [30976/84203]
Validation Done: [31104/84203]
Validation Done: [31232/84203]
Validation Done: [31360/84203]
Validation Done: [31488/84203]
Validation Done: [31616/84203]
Validation Done: [31744/84203]
Validation Done: [31872/84203]
Validation Done: [32000/84203]
Validation Done: [32128/84203]
Validation Done: [32256/84203]
Validation Done: [32384/84203]
Validation Done: [32512/84203]
Validation Done: [32640/84203]
Validation Done: [32768/84203]
Validation Done: [32896/84203]
Validation Done: [33024/84203]
Validation Done: [33152/84203]
Validation Done: [33280/84203]
Validation Done: [33408/84203]
Validation Done: [33536/84203]
Validation Done: [33664/84203]
Validation Done: [33792/84203]
Validation Done: [33920/84203]
Validation Done: [34048/84203]
Validation Done: [34176/84203]
Validation Done: [34304/84203]
Validation Done: [34432/84203]
Validation Done: [34560/84203]
Validation Done: [34688/84203]
Validation Done: [34816/84203]
Validation Done: [34944/84203]
Validation Done: [35072/84203]
Validation Done: [35200/84203]
Validation Done: [35328/84203]
Validation Done: [35456/84203]
Validation Done: [35584/84203]
Validation Done: [35712/84203]
Validation Done: [35840/84203]
Validation Done: [35968/84203]
Validation Done: [36096/84203]
Validation Done: [36224/84203]
Validation Done: [36352/84203]
Validation Done: [36480/84203]
Validation Done: [36608/84203]
Validation Done: [36736/84203]
Validation Done: [36864/84203]
Validation Done: [36992/84203]
Validation Done: [37120/84203]
Validation Done: [37248/84203]
Validation Done: [37376/84203]
Validation Done: [37504/84203]
Validation Done: [37632/84203]
Validation Done: [37760/84203]
Validation Done: [37888/84203]
Validation Done: [38016/84203]
Validation Done: [38144/84203]
Validation Done: [38272/84203]
Validation Done: [38400/84203]
Validation Done: [38528/84203]
Validation Done: [38656/84203]
Validation Done: [38784/84203]
Validation Done: [38912/84203]
Validation Done: [39040/84203]
Validation Done: [39168/84203]
Validation Done: [39296/84203]
Validation Done: [39424/84203]
Validation Done: [39552/84203]
Validation Done: [39680/84203]
Validation Done: [39808/84203]
Validation Done: [39936/84203]
Validation Done: [40064/84203]
Validation Done: [40192/84203]
Validation Done: [40320/84203]
Validation Done: [40448/84203]
Validation Done: [40576/84203]
Validation Done: [40704/84203]
Validation Done: [40832/84203]
Validation Done: [40960/84203]
Validation Done: [41088/84203]
Validation Done: [41216/84203]
Validation Done: [41344/84203]
Validation Done: [41472/84203]
Validation Done: [41600/84203]
Validation Done: [41728/84203]
Validation Done: [41856/84203]
Validation Done: [41984/84203]
Validation Done: [42112/84203]
Validation Done: [42240/84203]
Validation Done: [42368/84203]
Validation Done: [42496/84203]
Validation Done: [42624/84203]
Validation Done: [42752/84203]
Validation Done: [42880/84203]
Validation Done: [43008/84203]
Validation Done: [43136/84203]
Validation Done: [43264/84203]
Validation Done: [43392/84203]
Validation Done: [43520/84203]
Validation Done: [43648/84203]
Validation Done: [43776/84203]
Validation Done: [43904/84203]
Validation Done: [44032/84203]
Validation Done: [44160/84203]
Validation Done: [44288/84203]
Validation Done: [44416/84203]
Validation Done: [44544/84203]
Validation Done: [44672/84203]
Validation Done: [44800/84203]
Validation Done: [44928/84203]
Validation Done: [45056/84203]
Validation Done: [45184/84203]
Validation Done: [45312/84203]
Validation Done: [45440/84203]
Validation Done: [45568/84203]
Validation Done: [45696/84203]
Validation Done: [45824/84203]
Validation Done: [45952/84203]
Validation Done: [46080/84203]
Validation Done: [46208/84203]
Validation Done: [46336/84203]
Validation Done: [46464/84203]
Validation Done: [46592/84203]
Validation Done: [46720/84203]
Validation Done: [46848/84203]
Validation Done: [46976/84203]
Validation Done: [47104/84203]
Validation Done: [47232/84203]
Validation Done: [47360/84203]
Validation Done: [47488/84203]
Validation Done: [47616/84203]
Validation Done: [47744/84203]
Validation Done: [47872/84203]
Validation Done: [48000/84203]
Validation Done: [48128/84203]
Validation Done: [48256/84203]
Validation Done: [48384/84203]
Validation Done: [48512/84203]
Validation Done: [48640/84203]
Validation Done: [48768/84203]
Validation Done: [48896/84203]
Validation Done: [49024/84203]
Validation Done: [49152/84203]
Validation Done: [49280/84203]
Validation Done: [49408/84203]
Validation Done: [49536/84203]
Validation Done: [49664/84203]
Validation Done: [49792/84203]
Validation Done: [49920/84203]
Validation Done: [50048/84203]
Validation Done: [50176/84203]
Validation Done: [50304/84203]
Validation Done: [50432/84203]
Validation Done: [50560/84203]
Validation Done: [50688/84203]
Validation Done: [50816/84203]
Validation Done: [50944/84203]
Validation Done: [51072/84203]
Validation Done: [51200/84203]
Validation Done: [51328/84203]
Validation Done: [51456/84203]
Validation Done: [51584/84203]
Validation Done: [51712/84203]
Validation Done: [51840/84203]
Validation Done: [51968/84203]
Validation Done: [52096/84203]
Validation Done: [52224/84203]
Validation Done: [52352/84203]
Validation Done: [52480/84203]
Validation Done: [52608/84203]
Validation Done: [52736/84203]
Validation Done: [52864/84203]
Validation Done: [52992/84203]
Validation Done: [53120/84203]
Validation Done: [53248/84203]
Validation Done: [53376/84203]
Validation Done: [53504/84203]
Validation Done: [53632/84203]
Validation Done: [53760/84203]
Validation Done: [53888/84203]
Validation Done: [54016/84203]
Validation Done: [54144/84203]
Validation Done: [54272/84203]
Validation Done: [54400/84203]
Validation Done: [54528/84203]
Validation Done: [54656/84203]
Validation Done: [54784/84203]
Validation Done: [54912/84203]
Validation Done: [55040/84203]
Validation Done: [55168/84203]
Validation Done: [55296/84203]
Validation Done: [55424/84203]
Validation Done: [55552/84203]
Validation Done: [55680/84203]
Validation Done: [55808/84203]
Validation Done: [55936/84203]
Validation Done: [56064/84203]
Validation Done: [56192/84203]
Validation Done: [56320/84203]
Validation Done: [56448/84203]
Validation Done: [56576/84203]
Validation Done: [56704/84203]
Validation Done: [56832/84203]
Validation Done: [56960/84203]
Validation Done: [57088/84203]
Validation Done: [57216/84203]
Validation Done: [57344/84203]
Validation Done: [57472/84203]
Validation Done: [57600/84203]
Validation Done: [57728/84203]
Validation Done: [57856/84203]
Validation Done: [57984/84203]
Validation Done: [58112/84203]
Validation Done: [58240/84203]
Validation Done: [58368/84203]
Validation Done: [58496/84203]
Validation Done: [58624/84203]
Validation Done: [58752/84203]
Validation Done: [58880/84203]
Validation Done: [59008/84203]
Validation Done: [59136/84203]
Validation Done: [59264/84203]
Validation Done: [59392/84203]
Validation Done: [59520/84203]
Validation Done: [59648/84203]
Validation Done: [59776/84203]
Validation Done: [59904/84203]
Validation Done: [60032/84203]
Validation Done: [60160/84203]
Validation Done: [60288/84203]
Validation Done: [60416/84203]
Validation Done: [60544/84203]
Validation Done: [60672/84203]
Validation Done: [60800/84203]
Validation Done: [60928/84203]
Validation Done: [61056/84203]
Validation Done: [61184/84203]
Validation Done: [61312/84203]
Validation Done: [61440/84203]
Validation Done: [61568/84203]
Validation Done: [61696/84203]
Validation Done: [61824/84203]
Validation Done: [61952/84203]
Validation Done: [62080/84203]
Validation Done: [62208/84203]
Validation Done: [62336/84203]
Validation Done: [62464/84203]
Validation Done: [62592/84203]
Validation Done: [62720/84203]
Validation Done: [62848/84203]
Validation Done: [62976/84203]
Validation Done: [63104/84203]
Validation Done: [63232/84203]
Validation Done: [63360/84203]
Validation Done: [63488/84203]
Validation Done: [63616/84203]
Validation Done: [63744/84203]
Validation Done: [63872/84203]
Validation Done: [64000/84203]
Validation Done: [64128/84203]
Validation Done: [64256/84203]
Validation Done: [64384/84203]
Validation Done: [64512/84203]
Validation Done: [64640/84203]
Validation Done: [64768/84203]
Validation Done: [64896/84203]
Validation Done: [65024/84203]
Validation Done: [65152/84203]
Validation Done: [65280/84203]
Validation Done: [65408/84203]
Validation Done: [65536/84203]
Validation Done: [65664/84203]
Validation Done: [65792/84203]
Validation Done: [65920/84203]
Validation Done: [66048/84203]
Validation Done: [66176/84203]
Validation Done: [66304/84203]
Validation Done: [66432/84203]
Validation Done: [66560/84203]
Validation Done: [66688/84203]
Validation Done: [66816/84203]
Validation Done: [66944/84203]
Validation Done: [67072/84203]
Validation Done: [67200/84203]
Validation Done: [67328/84203]
Validation Done: [67456/84203]
Validation Done: [67584/84203]
Validation Done: [67712/84203]
Validation Done: [67840/84203]
Validation Done: [67968/84203]
Validation Done: [68096/84203]
Validation Done: [68224/84203]
Validation Done: [68352/84203]
Validation Done: [68480/84203]
Validation Done: [68608/84203]
Validation Done: [68736/84203]
Validation Done: [68864/84203]
Validation Done: [68992/84203]
Validation Done: [69120/84203]
Validation Done: [69248/84203]
Validation Done: [69376/84203]
Validation Done: [69504/84203]
Validation Done: [69632/84203]
Validation Done: [69760/84203]
Validation Done: [69888/84203]
Validation Done: [70016/84203]
Validation Done: [70144/84203]
Validation Done: [70272/84203]
Validation Done: [70400/84203]
Validation Done: [70528/84203]
Validation Done: [70656/84203]
Validation Done: [70784/84203]
Validation Done: [70912/84203]
Validation Done: [71040/84203]
Validation Done: [71168/84203]
Validation Done: [71296/84203]
Validation Done: [71424/84203]
Validation Done: [71552/84203]
Validation Done: [71680/84203]
Validation Done: [71808/84203]
Validation Done: [71936/84203]
Validation Done: [72064/84203]
Validation Done: [72192/84203]
Validation Done: [72320/84203]
Validation Done: [72448/84203]
Validation Done: [72576/84203]
Validation Done: [72704/84203]
Validation Done: [72832/84203]
Validation Done: [72960/84203]
Validation Done: [73088/84203]
Validation Done: [73216/84203]
Validation Done: [73344/84203]
Validation Done: [73472/84203]
Validation Done: [73600/84203]
Validation Done: [73728/84203]
Validation Done: [73856/84203]
Validation Done: [73984/84203]
Validation Done: [74112/84203]
Validation Done: [74240/84203]
Validation Done: [74368/84203]
Validation Done: [74496/84203]
Validation Done: [74624/84203]
Validation Done: [74752/84203]
Validation Done: [74880/84203]
Validation Done: [75008/84203]
Validation Done: [75136/84203]
Validation Done: [75264/84203]
Validation Done: [75392/84203]
Validation Done: [75520/84203]
Validation Done: [75648/84203]
Validation Done: [75776/84203]
Validation Done: [75904/84203]
Validation Done: [76032/84203]
Validation Done: [76160/84203]
Validation Done: [76288/84203]
Validation Done: [76416/84203]
Validation Done: [76544/84203]
Validation Done: [76672/84203]
Validation Done: [76800/84203]
Validation Done: [76928/84203]
Validation Done: [77056/84203]
Validation Done: [77184/84203]
Validation Done: [77312/84203]
Validation Done: [77440/84203]
Validation Done: [77568/84203]
Validation Done: [77696/84203]
Validation Done: [77824/84203]
Validation Done: [77952/84203]
Validation Done: [78080/84203]
Validation Done: [78208/84203]
Validation Done: [78336/84203]
Validation Done: [78464/84203]
Validation Done: [78592/84203]
Validation Done: [78720/84203]
Validation Done: [78848/84203]
Validation Done: [78976/84203]
Validation Done: [79104/84203]
Validation Done: [79232/84203]
Validation Done: [79360/84203]
Validation Done: [79488/84203]
Validation Done: [79616/84203]
Validation Done: [79744/84203]
Validation Done: [79872/84203]
Validation Done: [80000/84203]
Validation Done: [80128/84203]
Validation Done: [80256/84203]
Validation Done: [80384/84203]
Validation Done: [80512/84203]
Validation Done: [80640/84203]
Validation Done: [80768/84203]
Validation Done: [80896/84203]
Validation Done: [81024/84203]
Validation Done: [81152/84203]
Validation Done: [81280/84203]
Validation Done: [81408/84203]
Validation Done: [81536/84203]
Validation Done: [81664/84203]
Validation Done: [81792/84203]
Validation Done: [81920/84203]
Validation Done: [82048/84203]
Validation Done: [82176/84203]
Validation Done: [82304/84203]
Validation Done: [82432/84203]
Validation Done: [82560/84203]
Validation Done: [82688/84203]
Validation Done: [82816/84203]
Validation Done: [82944/84203]
Validation Done: [83072/84203]
Validation Done: [83200/84203]
Validation Done: [83328/84203]
Validation Done: [83456/84203]
Validation Done: [83584/84203]
Validation Done: [83712/84203]
Validation Done: [83840/84203]
Validation Done: [83968/84203]
Validation Done: [84096/84203]
Validation Done: [70406/84203]
[Test] Epoch: 4 Test set: Average loss: 0.0020, Accuracy: 75352/84203 (89.49%)
{'accuracy': 0.8948849803451183, 'normal': {'precision': 0.8850442442760208, 'recall': 0.7892986057045792, 'support': 28258, 'f1-score': 0.8344338652051105}, 'macro avg': {'precision': 0.8920662053894256, 'recall': 0.8687578022713619, 'support': 84203, 'f1-score': 0.8787165802662611}, 'cancer': {'precision': 0.8990881665028304, 'recall': 0.9482169988381446, 'support': 55945, 'f1-score': 0.9229992953274118}, 'weighted avg': {'precision': 0.8943751140666323, 'recall': 0.8948849803451183, 'support': 84203, 'f1-score': 0.8932772910710791}}
[Train] Epoch: 5 [128/387873]    Loss: 0.001414   Batch Acc: 94.53
[Train] Epoch: 5 [256/387873]    Loss: 0.001976   Batch Acc: 89.84
[Train] Epoch: 5 [384/387873]    Loss: 0.001550   Batch Acc: 93.75
[Train] Epoch: 5 [512/387873]    Loss: 0.001691   Batch Acc: 92.19
[Train] Epoch: 5 [640/387873]    Loss: 0.001302   Batch Acc: 96.88
[Train] Epoch: 5 [768/387873]    Loss: 0.001655   Batch Acc: 93.75
[Train] Epoch: 5 [896/387873]    Loss: 0.002169   Batch Acc: 85.94
[Train] Epoch: 5 [1024/387873]    Loss: 0.001904   Batch Acc: 92.19
[Train] Epoch: 5 [1152/387873]    Loss: 0.001572   Batch Acc: 92.97
[Train] Epoch: 5 [1280/387873]    Loss: 0.001703   Batch Acc: 92.19
[Train] Epoch: 5 [1408/387873]    Loss: 0.001930   Batch Acc: 90.62
[Train] Epoch: 5 [1536/387873]    Loss: 0.001805   Batch Acc: 92.97
[Train] Epoch: 5 [1664/387873]    Loss: 0.001917   Batch Acc: 86.72
[Train] Epoch: 5 [1792/387873]    Loss: 0.001957   Batch Acc: 91.41
[Train] Epoch: 5 [1920/387873]    Loss: 0.002024   Batch Acc: 85.94
[Train] Epoch: 5 [2048/387873]    Loss: 0.001869   Batch Acc: 89.06
[Train] Epoch: 5 [2176/387873]    Loss: 0.001960   Batch Acc: 89.06
[Train] Epoch: 5 [2304/387873]    Loss: 0.002001   Batch Acc: 90.62
[Train] Epoch: 5 [2432/387873]    Loss: 0.002963   Batch Acc: 84.38
[Train] Epoch: 5 [2560/387873]    Loss: 0.002296   Batch Acc: 87.50
[Train] Epoch: 5 [2688/387873]    Loss: 0.001996   Batch Acc: 87.50
[Train] Epoch: 5 [2816/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 5 [2944/387873]    Loss: 0.002357   Batch Acc: 85.16
[Train] Epoch: 5 [3072/387873]    Loss: 0.001723   Batch Acc: 89.84
[Train] Epoch: 5 [3200/387873]    Loss: 0.001767   Batch Acc: 88.28
[Train] Epoch: 5 [3328/387873]    Loss: 0.001652   Batch Acc: 92.97
[Train] Epoch: 5 [3456/387873]    Loss: 0.001861   Batch Acc: 91.41
[Train] Epoch: 5 [3584/387873]    Loss: 0.002704   Batch Acc: 80.47
[Train] Epoch: 5 [3712/387873]    Loss: 0.002119   Batch Acc: 87.50
[Train] Epoch: 5 [3840/387873]    Loss: 0.002346   Batch Acc: 90.62
[Train] Epoch: 5 [3968/387873]    Loss: 0.002479   Batch Acc: 82.81
[Train] Epoch: 5 [4096/387873]    Loss: 0.001867   Batch Acc: 87.50
[Train] Epoch: 5 [4224/387873]    Loss: 0.001774   Batch Acc: 90.62
[Train] Epoch: 5 [4352/387873]    Loss: 0.002429   Batch Acc: 85.94
[Train] Epoch: 5 [4480/387873]    Loss: 0.002012   Batch Acc: 90.62
[Train] Epoch: 5 [4608/387873]    Loss: 0.002151   Batch Acc: 86.72
[Train] Epoch: 5 [4736/387873]    Loss: 0.001735   Batch Acc: 90.62
[Train] Epoch: 5 [4864/387873]    Loss: 0.001814   Batch Acc: 92.97
[Train] Epoch: 5 [4992/387873]    Loss: 0.002058   Batch Acc: 88.28
[Train] Epoch: 5 [5120/387873]    Loss: 0.002698   Batch Acc: 83.59
[Train] Epoch: 5 [5248/387873]    Loss: 0.001771   Batch Acc: 92.97
[Train] Epoch: 5 [5376/387873]    Loss: 0.002047   Batch Acc: 89.06
[Train] Epoch: 5 [5504/387873]    Loss: 0.002134   Batch Acc: 86.72
[Train] Epoch: 5 [5632/387873]    Loss: 0.001742   Batch Acc: 92.97
[Train] Epoch: 5 [5760/387873]    Loss: 0.002472   Batch Acc: 85.16
[Train] Epoch: 5 [5888/387873]    Loss: 0.002186   Batch Acc: 90.62
[Train] Epoch: 5 [6016/387873]    Loss: 0.001950   Batch Acc: 89.06
[Train] Epoch: 5 [6144/387873]    Loss: 0.002294   Batch Acc: 85.16
[Train] Epoch: 5 [6272/387873]    Loss: 0.001801   Batch Acc: 91.41
[Train] Epoch: 5 [6400/387873]    Loss: 0.002172   Batch Acc: 89.06
[Train] Epoch: 5 [6528/387873]    Loss: 0.001947   Batch Acc: 90.62
[Train] Epoch: 5 [6656/387873]    Loss: 0.002158   Batch Acc: 85.94
[Train] Epoch: 5 [6784/387873]    Loss: 0.001402   Batch Acc: 93.75
[Train] Epoch: 5 [6912/387873]    Loss: 0.001962   Batch Acc: 88.28
[Train] Epoch: 5 [7040/387873]    Loss: 0.002261   Batch Acc: 88.28
[Train] Epoch: 5 [7168/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 5 [7296/387873]    Loss: 0.002461   Batch Acc: 89.06
[Train] Epoch: 5 [7424/387873]    Loss: 0.002058   Batch Acc: 89.84
[Train] Epoch: 5 [7552/387873]    Loss: 0.002147   Batch Acc: 88.28
[Train] Epoch: 5 [7680/387873]    Loss: 0.001824   Batch Acc: 89.84
[Train] Epoch: 5 [7808/387873]    Loss: 0.002560   Batch Acc: 80.47
[Train] Epoch: 5 [7936/387873]    Loss: 0.002149   Batch Acc: 87.50
[Train] Epoch: 5 [8064/387873]    Loss: 0.001505   Batch Acc: 93.75
[Train] Epoch: 5 [8192/387873]    Loss: 0.001670   Batch Acc: 92.97
[Train] Epoch: 5 [8320/387873]    Loss: 0.001853   Batch Acc: 91.41
[Train] Epoch: 5 [8448/387873]    Loss: 0.002340   Batch Acc: 82.03
[Train] Epoch: 5 [8576/387873]    Loss: 0.001779   Batch Acc: 90.62
[Train] Epoch: 5 [8704/387873]    Loss: 0.001843   Batch Acc: 90.62
[Train] Epoch: 5 [8832/387873]    Loss: 0.002237   Batch Acc: 86.72
[Train] Epoch: 5 [8960/387873]    Loss: 0.001788   Batch Acc: 89.84
[Train] Epoch: 5 [9088/387873]    Loss: 0.002405   Batch Acc: 85.94
[Train] Epoch: 5 [9216/387873]    Loss: 0.002543   Batch Acc: 84.38
[Train] Epoch: 5 [9344/387873]    Loss: 0.001809   Batch Acc: 90.62
[Train] Epoch: 5 [9472/387873]    Loss: 0.002085   Batch Acc: 90.62
[Train] Epoch: 5 [9600/387873]    Loss: 0.002146   Batch Acc: 88.28
[Train] Epoch: 5 [9728/387873]    Loss: 0.001552   Batch Acc: 91.41
[Train] Epoch: 5 [9856/387873]    Loss: 0.001825   Batch Acc: 90.62
[Train] Epoch: 5 [9984/387873]    Loss: 0.001561   Batch Acc: 93.75
[Train] Epoch: 5 [10112/387873]    Loss: 0.001383   Batch Acc: 92.97
[Train] Epoch: 5 [10240/387873]    Loss: 0.001761   Batch Acc: 89.84
[Train] Epoch: 5 [10368/387873]    Loss: 0.001790   Batch Acc: 93.75
[Train] Epoch: 5 [10496/387873]    Loss: 0.001749   Batch Acc: 89.06
[Train] Epoch: 5 [10624/387873]    Loss: 0.001590   Batch Acc: 91.41
[Train] Epoch: 5 [10752/387873]    Loss: 0.002081   Batch Acc: 89.06
[Train] Epoch: 5 [10880/387873]    Loss: 0.002044   Batch Acc: 89.84
[Train] Epoch: 5 [11008/387873]    Loss: 0.001886   Batch Acc: 86.72
[Train] Epoch: 5 [11136/387873]    Loss: 0.001582   Batch Acc: 96.09
[Train] Epoch: 5 [11264/387873]    Loss: 0.001842   Batch Acc: 90.62
[Train] Epoch: 5 [11392/387873]    Loss: 0.002009   Batch Acc: 90.62
[Train] Epoch: 5 [11520/387873]    Loss: 0.001657   Batch Acc: 92.19
[Train] Epoch: 5 [11648/387873]    Loss: 0.001467   Batch Acc: 92.97
[Train] Epoch: 5 [11776/387873]    Loss: 0.001968   Batch Acc: 88.28
[Train] Epoch: 5 [11904/387873]    Loss: 0.002113   Batch Acc: 86.72
[Train] Epoch: 5 [12032/387873]    Loss: 0.001871   Batch Acc: 89.06
[Train] Epoch: 5 [12160/387873]    Loss: 0.002328   Batch Acc: 86.72
[Train] Epoch: 5 [12288/387873]    Loss: 0.001544   Batch Acc: 91.41
[Train] Epoch: 5 [12416/387873]    Loss: 0.001805   Batch Acc: 93.75
[Train] Epoch: 5 [12544/387873]    Loss: 0.001937   Batch Acc: 92.19
[Train] Epoch: 5 [12672/387873]    Loss: 0.002109   Batch Acc: 87.50
[Train] Epoch: 5 [12800/387873]    Loss: 0.002006   Batch Acc: 86.72
[Train] Epoch: 5 [12928/387873]    Loss: 0.002184   Batch Acc: 88.28
[Train] Epoch: 5 [13056/387873]    Loss: 0.001527   Batch Acc: 91.41
[Train] Epoch: 5 [13184/387873]    Loss: 0.002487   Batch Acc: 86.72
[Train] Epoch: 5 [13312/387873]    Loss: 0.002345   Batch Acc: 84.38
[Train] Epoch: 5 [13440/387873]    Loss: 0.002066   Batch Acc: 85.94
[Train] Epoch: 5 [13568/387873]    Loss: 0.002361   Batch Acc: 85.16
[Train] Epoch: 5 [13696/387873]    Loss: 0.002088   Batch Acc: 88.28
[Train] Epoch: 5 [13824/387873]    Loss: 0.001997   Batch Acc: 87.50
[Train] Epoch: 5 [13952/387873]    Loss: 0.001341   Batch Acc: 94.53
[Train] Epoch: 5 [14080/387873]    Loss: 0.002230   Batch Acc: 87.50
[Train] Epoch: 5 [14208/387873]    Loss: 0.001781   Batch Acc: 90.62
[Train] Epoch: 5 [14336/387873]    Loss: 0.002519   Batch Acc: 83.59
[Train] Epoch: 5 [14464/387873]    Loss: 0.001917   Batch Acc: 91.41
[Train] Epoch: 5 [14592/387873]    Loss: 0.001578   Batch Acc: 92.97
[Train] Epoch: 5 [14720/387873]    Loss: 0.001797   Batch Acc: 92.97
[Train] Epoch: 5 [14848/387873]    Loss: 0.002467   Batch Acc: 84.38
[Train] Epoch: 5 [14976/387873]    Loss: 0.002606   Batch Acc: 85.94
[Train] Epoch: 5 [15104/387873]    Loss: 0.001543   Batch Acc: 91.41
[Train] Epoch: 5 [15232/387873]    Loss: 0.001676   Batch Acc: 90.62
[Train] Epoch: 5 [15360/387873]    Loss: 0.001448   Batch Acc: 93.75
[Train] Epoch: 5 [15488/387873]    Loss: 0.002557   Batch Acc: 86.72
[Train] Epoch: 5 [15616/387873]    Loss: 0.002175   Batch Acc: 87.50
[Train] Epoch: 5 [15744/387873]    Loss: 0.001867   Batch Acc: 89.84
[Train] Epoch: 5 [15872/387873]    Loss: 0.002068   Batch Acc: 89.84
[Train] Epoch: 5 [16000/387873]    Loss: 0.002130   Batch Acc: 87.50
[Train] Epoch: 5 [16128/387873]    Loss: 0.001301   Batch Acc: 94.53
[Train] Epoch: 5 [16256/387873]    Loss: 0.002307   Batch Acc: 87.50
[Train] Epoch: 5 [16384/387873]    Loss: 0.001807   Batch Acc: 90.62
[Train] Epoch: 5 [16512/387873]    Loss: 0.002156   Batch Acc: 90.62
[Train] Epoch: 5 [16640/387873]    Loss: 0.002135   Batch Acc: 88.28
[Train] Epoch: 5 [16768/387873]    Loss: 0.001468   Batch Acc: 94.53
[Train] Epoch: 5 [16896/387873]    Loss: 0.001901   Batch Acc: 89.84
[Train] Epoch: 5 [17024/387873]    Loss: 0.002603   Batch Acc: 87.50
[Train] Epoch: 5 [17152/387873]    Loss: 0.002290   Batch Acc: 84.38
[Train] Epoch: 5 [17280/387873]    Loss: 0.002215   Batch Acc: 89.06
[Train] Epoch: 5 [17408/387873]    Loss: 0.002294   Batch Acc: 87.50
[Train] Epoch: 5 [17536/387873]    Loss: 0.002019   Batch Acc: 89.06
[Train] Epoch: 5 [17664/387873]    Loss: 0.002158   Batch Acc: 87.50
[Train] Epoch: 5 [17792/387873]    Loss: 0.002050   Batch Acc: 86.72
[Train] Epoch: 5 [17920/387873]    Loss: 0.002042   Batch Acc: 87.50
[Train] Epoch: 5 [18048/387873]    Loss: 0.002360   Batch Acc: 83.59
[Train] Epoch: 5 [18176/387873]    Loss: 0.001967   Batch Acc: 88.28
[Train] Epoch: 5 [18304/387873]    Loss: 0.001734   Batch Acc: 90.62
[Train] Epoch: 5 [18432/387873]    Loss: 0.001634   Batch Acc: 92.19
[Train] Epoch: 5 [18560/387873]    Loss: 0.001829   Batch Acc: 89.84
[Train] Epoch: 5 [18688/387873]    Loss: 0.001719   Batch Acc: 91.41
[Train] Epoch: 5 [18816/387873]    Loss: 0.002155   Batch Acc: 88.28
[Train] Epoch: 5 [18944/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 5 [19072/387873]    Loss: 0.001699   Batch Acc: 90.62
[Train] Epoch: 5 [19200/387873]    Loss: 0.001927   Batch Acc: 89.06
[Train] Epoch: 5 [19328/387873]    Loss: 0.001978   Batch Acc: 89.06
[Train] Epoch: 5 [19456/387873]    Loss: 0.002117   Batch Acc: 85.94
[Train] Epoch: 5 [19584/387873]    Loss: 0.002145   Batch Acc: 87.50
[Train] Epoch: 5 [19712/387873]    Loss: 0.001993   Batch Acc: 92.19
[Train] Epoch: 5 [19840/387873]    Loss: 0.001498   Batch Acc: 92.97
[Train] Epoch: 5 [19968/387873]    Loss: 0.002987   Batch Acc: 82.81
[Train] Epoch: 5 [20096/387873]    Loss: 0.001633   Batch Acc: 90.62
[Train] Epoch: 5 [20224/387873]    Loss: 0.001907   Batch Acc: 91.41
[Train] Epoch: 5 [20352/387873]    Loss: 0.002427   Batch Acc: 87.50
[Train] Epoch: 5 [20480/387873]    Loss: 0.002294   Batch Acc: 89.06
[Train] Epoch: 5 [20608/387873]    Loss: 0.001450   Batch Acc: 94.53
[Train] Epoch: 5 [20736/387873]    Loss: 0.001489   Batch Acc: 93.75
[Train] Epoch: 5 [20864/387873]    Loss: 0.001599   Batch Acc: 95.31
[Train] Epoch: 5 [20992/387873]    Loss: 0.001998   Batch Acc: 88.28
[Train] Epoch: 5 [21120/387873]    Loss: 0.001939   Batch Acc: 90.62
[Train] Epoch: 5 [21248/387873]    Loss: 0.002048   Batch Acc: 89.84
[Train] Epoch: 5 [21376/387873]    Loss: 0.002193   Batch Acc: 85.94
[Train] Epoch: 5 [21504/387873]    Loss: 0.002712   Batch Acc: 84.38
[Train] Epoch: 5 [21632/387873]    Loss: 0.001796   Batch Acc: 91.41
[Train] Epoch: 5 [21760/387873]    Loss: 0.002417   Batch Acc: 84.38
[Train] Epoch: 5 [21888/387873]    Loss: 0.002051   Batch Acc: 89.84
[Train] Epoch: 5 [22016/387873]    Loss: 0.001461   Batch Acc: 90.62
[Train] Epoch: 5 [22144/387873]    Loss: 0.001853   Batch Acc: 91.41
[Train] Epoch: 5 [22272/387873]    Loss: 0.001751   Batch Acc: 89.84
[Train] Epoch: 5 [22400/387873]    Loss: 0.001746   Batch Acc: 90.62
[Train] Epoch: 5 [22528/387873]    Loss: 0.001710   Batch Acc: 91.41
[Train] Epoch: 5 [22656/387873]    Loss: 0.002363   Batch Acc: 89.06
[Train] Epoch: 5 [22784/387873]    Loss: 0.002085   Batch Acc: 87.50
[Train] Epoch: 5 [22912/387873]    Loss: 0.001719   Batch Acc: 90.62
[Train] Epoch: 5 [23040/387873]    Loss: 0.001757   Batch Acc: 89.84
[Train] Epoch: 5 [23168/387873]    Loss: 0.001996   Batch Acc: 89.06
[Train] Epoch: 5 [23296/387873]    Loss: 0.002250   Batch Acc: 86.72
[Train] Epoch: 5 [23424/387873]    Loss: 0.001814   Batch Acc: 93.75
[Train] Epoch: 5 [23552/387873]    Loss: 0.002262   Batch Acc: 88.28
[Train] Epoch: 5 [23680/387873]    Loss: 0.001519   Batch Acc: 92.19
[Train] Epoch: 5 [23808/387873]    Loss: 0.001963   Batch Acc: 92.97
[Train] Epoch: 5 [23936/387873]    Loss: 0.002114   Batch Acc: 87.50
[Train] Epoch: 5 [24064/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 5 [24192/387873]    Loss: 0.002150   Batch Acc: 86.72
[Train] Epoch: 5 [24320/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 5 [24448/387873]    Loss: 0.001759   Batch Acc: 91.41
[Train] Epoch: 5 [24576/387873]    Loss: 0.001654   Batch Acc: 91.41
[Train] Epoch: 5 [24704/387873]    Loss: 0.001925   Batch Acc: 91.41
[Train] Epoch: 5 [24832/387873]    Loss: 0.001912   Batch Acc: 89.84
[Train] Epoch: 5 [24960/387873]    Loss: 0.002208   Batch Acc: 88.28
[Train] Epoch: 5 [25088/387873]    Loss: 0.002048   Batch Acc: 89.84
[Train] Epoch: 5 [25216/387873]    Loss: 0.001949   Batch Acc: 88.28
[Train] Epoch: 5 [25344/387873]    Loss: 0.002295   Batch Acc: 84.38
[Train] Epoch: 5 [25472/387873]    Loss: 0.001744   Batch Acc: 92.19
[Train] Epoch: 5 [25600/387873]    Loss: 0.001680   Batch Acc: 92.97
[Train] Epoch: 5 [25728/387873]    Loss: 0.002344   Batch Acc: 85.16
[Train] Epoch: 5 [25856/387873]    Loss: 0.001946   Batch Acc: 91.41
[Train] Epoch: 5 [25984/387873]    Loss: 0.002482   Batch Acc: 85.94
[Train] Epoch: 5 [26112/387873]    Loss: 0.001784   Batch Acc: 89.06
[Train] Epoch: 5 [26240/387873]    Loss: 0.001538   Batch Acc: 94.53
[Train] Epoch: 5 [26368/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 5 [26496/387873]    Loss: 0.002207   Batch Acc: 83.59
[Train] Epoch: 5 [26624/387873]    Loss: 0.002563   Batch Acc: 83.59
[Train] Epoch: 5 [26752/387873]    Loss: 0.001958   Batch Acc: 89.84
[Train] Epoch: 5 [26880/387873]    Loss: 0.002059   Batch Acc: 86.72
[Train] Epoch: 5 [27008/387873]    Loss: 0.001597   Batch Acc: 92.97
[Train] Epoch: 5 [27136/387873]    Loss: 0.002182   Batch Acc: 90.62
[Train] Epoch: 5 [27264/387873]    Loss: 0.001793   Batch Acc: 90.62
[Train] Epoch: 5 [27392/387873]    Loss: 0.002293   Batch Acc: 89.84
[Train] Epoch: 5 [27520/387873]    Loss: 0.001541   Batch Acc: 92.97
[Train] Epoch: 5 [27648/387873]    Loss: 0.001840   Batch Acc: 89.84
[Train] Epoch: 5 [27776/387873]    Loss: 0.002032   Batch Acc: 91.41
[Train] Epoch: 5 [27904/387873]    Loss: 0.001540   Batch Acc: 94.53
[Train] Epoch: 5 [28032/387873]    Loss: 0.001690   Batch Acc: 91.41
[Train] Epoch: 5 [28160/387873]    Loss: 0.002854   Batch Acc: 85.16
[Train] Epoch: 5 [28288/387873]    Loss: 0.002021   Batch Acc: 88.28
[Train] Epoch: 5 [28416/387873]    Loss: 0.002368   Batch Acc: 88.28
[Train] Epoch: 5 [28544/387873]    Loss: 0.001911   Batch Acc: 91.41
[Train] Epoch: 5 [28672/387873]    Loss: 0.001877   Batch Acc: 86.72
[Train] Epoch: 5 [28800/387873]    Loss: 0.001972   Batch Acc: 90.62
[Train] Epoch: 5 [28928/387873]    Loss: 0.001770   Batch Acc: 90.62
[Train] Epoch: 5 [29056/387873]    Loss: 0.001711   Batch Acc: 89.84
[Train] Epoch: 5 [29184/387873]    Loss: 0.001751   Batch Acc: 89.84
[Train] Epoch: 5 [29312/387873]    Loss: 0.002250   Batch Acc: 86.72
[Train] Epoch: 5 [29440/387873]    Loss: 0.002040   Batch Acc: 91.41
[Train] Epoch: 5 [29568/387873]    Loss: 0.002393   Batch Acc: 89.84
[Train] Epoch: 5 [29696/387873]    Loss: 0.002321   Batch Acc: 86.72
[Train] Epoch: 5 [29824/387873]    Loss: 0.001899   Batch Acc: 88.28
[Train] Epoch: 5 [29952/387873]    Loss: 0.001721   Batch Acc: 92.19
[Train] Epoch: 5 [30080/387873]    Loss: 0.002169   Batch Acc: 90.62
[Train] Epoch: 5 [30208/387873]    Loss: 0.001739   Batch Acc: 88.28
[Train] Epoch: 5 [30336/387873]    Loss: 0.002131   Batch Acc: 87.50
[Train] Epoch: 5 [30464/387873]    Loss: 0.001831   Batch Acc: 89.06
[Train] Epoch: 5 [30592/387873]    Loss: 0.002396   Batch Acc: 86.72
[Train] Epoch: 5 [30720/387873]    Loss: 0.002031   Batch Acc: 91.41
[Train] Epoch: 5 [30848/387873]    Loss: 0.001846   Batch Acc: 91.41
[Train] Epoch: 5 [30976/387873]    Loss: 0.002026   Batch Acc: 91.41
[Train] Epoch: 5 [31104/387873]    Loss: 0.001979   Batch Acc: 90.62
[Train] Epoch: 5 [31232/387873]    Loss: 0.002348   Batch Acc: 86.72
[Train] Epoch: 5 [31360/387873]    Loss: 0.001831   Batch Acc: 89.06
[Train] Epoch: 5 [31488/387873]    Loss: 0.002076   Batch Acc: 91.41
[Train] Epoch: 5 [31616/387873]    Loss: 0.001956   Batch Acc: 89.06
[Train] Epoch: 5 [31744/387873]    Loss: 0.001733   Batch Acc: 92.19
[Train] Epoch: 5 [31872/387873]    Loss: 0.001982   Batch Acc: 91.41
[Train] Epoch: 5 [32000/387873]    Loss: 0.001746   Batch Acc: 92.19
[Train] Epoch: 5 [32128/387873]    Loss: 0.002089   Batch Acc: 88.28
[Train] Epoch: 5 [32256/387873]    Loss: 0.001932   Batch Acc: 89.06
[Train] Epoch: 5 [32384/387873]    Loss: 0.002193   Batch Acc: 85.94
[Train] Epoch: 5 [32512/387873]    Loss: 0.001540   Batch Acc: 94.53
[Train] Epoch: 5 [32640/387873]    Loss: 0.002261   Batch Acc: 86.72
[Train] Epoch: 5 [32768/387873]    Loss: 0.002524   Batch Acc: 85.94
[Train] Epoch: 5 [32896/387873]    Loss: 0.001446   Batch Acc: 92.19
[Train] Epoch: 5 [33024/387873]    Loss: 0.001908   Batch Acc: 89.06
[Train] Epoch: 5 [33152/387873]    Loss: 0.001433   Batch Acc: 93.75
[Train] Epoch: 5 [33280/387873]    Loss: 0.002439   Batch Acc: 83.59
[Train] Epoch: 5 [33408/387873]    Loss: 0.001900   Batch Acc: 89.06
[Train] Epoch: 5 [33536/387873]    Loss: 0.002174   Batch Acc: 86.72
[Train] Epoch: 5 [33664/387873]    Loss: 0.002062   Batch Acc: 89.06
[Train] Epoch: 5 [33792/387873]    Loss: 0.001615   Batch Acc: 91.41
[Train] Epoch: 5 [33920/387873]    Loss: 0.002493   Batch Acc: 87.50
[Train] Epoch: 5 [34048/387873]    Loss: 0.001802   Batch Acc: 89.06
[Train] Epoch: 5 [34176/387873]    Loss: 0.002517   Batch Acc: 86.72
[Train] Epoch: 5 [34304/387873]    Loss: 0.001671   Batch Acc: 89.84
[Train] Epoch: 5 [34432/387873]    Loss: 0.001689   Batch Acc: 91.41
[Train] Epoch: 5 [34560/387873]    Loss: 0.002138   Batch Acc: 86.72
[Train] Epoch: 5 [34688/387873]    Loss: 0.001604   Batch Acc: 90.62
[Train] Epoch: 5 [34816/387873]    Loss: 0.002071   Batch Acc: 89.84
[Train] Epoch: 5 [34944/387873]    Loss: 0.002129   Batch Acc: 85.94
[Train] Epoch: 5 [35072/387873]    Loss: 0.002698   Batch Acc: 82.03
[Train] Epoch: 5 [35200/387873]    Loss: 0.001989   Batch Acc: 88.28
[Train] Epoch: 5 [35328/387873]    Loss: 0.002603   Batch Acc: 83.59
[Train] Epoch: 5 [35456/387873]    Loss: 0.002295   Batch Acc: 85.94
[Train] Epoch: 5 [35584/387873]    Loss: 0.002154   Batch Acc: 85.16
[Train] Epoch: 5 [35712/387873]    Loss: 0.002155   Batch Acc: 87.50
[Train] Epoch: 5 [35840/387873]    Loss: 0.002401   Batch Acc: 89.06
[Train] Epoch: 5 [35968/387873]    Loss: 0.001802   Batch Acc: 91.41
[Train] Epoch: 5 [36096/387873]    Loss: 0.001852   Batch Acc: 92.97
[Train] Epoch: 5 [36224/387873]    Loss: 0.001884   Batch Acc: 91.41
[Train] Epoch: 5 [36352/387873]    Loss: 0.001845   Batch Acc: 89.84
[Train] Epoch: 5 [36480/387873]    Loss: 0.002061   Batch Acc: 90.62
[Train] Epoch: 5 [36608/387873]    Loss: 0.001781   Batch Acc: 90.62
[Train] Epoch: 5 [36736/387873]    Loss: 0.001734   Batch Acc: 92.19
[Train] Epoch: 5 [36864/387873]    Loss: 0.002199   Batch Acc: 86.72
[Train] Epoch: 5 [36992/387873]    Loss: 0.001917   Batch Acc: 89.06
[Train] Epoch: 5 [37120/387873]    Loss: 0.002317   Batch Acc: 85.94
[Train] Epoch: 5 [37248/387873]    Loss: 0.001718   Batch Acc: 92.97
[Train] Epoch: 5 [37376/387873]    Loss: 0.002155   Batch Acc: 88.28
[Train] Epoch: 5 [37504/387873]    Loss: 0.002150   Batch Acc: 88.28
[Train] Epoch: 5 [37632/387873]    Loss: 0.001817   Batch Acc: 91.41
[Train] Epoch: 5 [37760/387873]    Loss: 0.001587   Batch Acc: 93.75
[Train] Epoch: 5 [37888/387873]    Loss: 0.001859   Batch Acc: 89.06
[Train] Epoch: 5 [38016/387873]    Loss: 0.002140   Batch Acc: 89.06
[Train] Epoch: 5 [38144/387873]    Loss: 0.001393   Batch Acc: 93.75
[Train] Epoch: 5 [38272/387873]    Loss: 0.001841   Batch Acc: 92.19
[Train] Epoch: 5 [38400/387873]    Loss: 0.001825   Batch Acc: 92.19
[Train] Epoch: 5 [38528/387873]    Loss: 0.001783   Batch Acc: 91.41
[Train] Epoch: 5 [38656/387873]    Loss: 0.002386   Batch Acc: 85.16
[Train] Epoch: 5 [38784/387873]    Loss: 0.002668   Batch Acc: 85.94
[Train] Epoch: 5 [38912/387873]    Loss: 0.002118   Batch Acc: 88.28
[Train] Epoch: 5 [39040/387873]    Loss: 0.002343   Batch Acc: 89.06
[Train] Epoch: 5 [39168/387873]    Loss: 0.002206   Batch Acc: 89.84
[Train] Epoch: 5 [39296/387873]    Loss: 0.001571   Batch Acc: 92.97
[Train] Epoch: 5 [39424/387873]    Loss: 0.002075   Batch Acc: 88.28
[Train] Epoch: 5 [39552/387873]    Loss: 0.002224   Batch Acc: 87.50
[Train] Epoch: 5 [39680/387873]    Loss: 0.002686   Batch Acc: 84.38
[Train] Epoch: 5 [39808/387873]    Loss: 0.001955   Batch Acc: 89.06
[Train] Epoch: 5 [39936/387873]    Loss: 0.001640   Batch Acc: 89.84
[Train] Epoch: 5 [40064/387873]    Loss: 0.001507   Batch Acc: 92.19
[Train] Epoch: 5 [40192/387873]    Loss: 0.002278   Batch Acc: 86.72
[Train] Epoch: 5 [40320/387873]    Loss: 0.001465   Batch Acc: 91.41
[Train] Epoch: 5 [40448/387873]    Loss: 0.001985   Batch Acc: 89.06
[Train] Epoch: 5 [40576/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 5 [40704/387873]    Loss: 0.002350   Batch Acc: 87.50
[Train] Epoch: 5 [40832/387873]    Loss: 0.002463   Batch Acc: 89.06
[Train] Epoch: 5 [40960/387873]    Loss: 0.001879   Batch Acc: 90.62
[Train] Epoch: 5 [41088/387873]    Loss: 0.002355   Batch Acc: 85.94
[Train] Epoch: 5 [41216/387873]    Loss: 0.001362   Batch Acc: 93.75
[Train] Epoch: 5 [41344/387873]    Loss: 0.001915   Batch Acc: 90.62
[Train] Epoch: 5 [41472/387873]    Loss: 0.002000   Batch Acc: 88.28
[Train] Epoch: 5 [41600/387873]    Loss: 0.002246   Batch Acc: 86.72
[Train] Epoch: 5 [41728/387873]    Loss: 0.002044   Batch Acc: 88.28
[Train] Epoch: 5 [41856/387873]    Loss: 0.001579   Batch Acc: 92.97
[Train] Epoch: 5 [41984/387873]    Loss: 0.002484   Batch Acc: 85.16
[Train] Epoch: 5 [42112/387873]    Loss: 0.001632   Batch Acc: 92.19
[Train] Epoch: 5 [42240/387873]    Loss: 0.001912   Batch Acc: 89.06
[Train] Epoch: 5 [42368/387873]    Loss: 0.001518   Batch Acc: 93.75
[Train] Epoch: 5 [42496/387873]    Loss: 0.001716   Batch Acc: 89.84
[Train] Epoch: 5 [42624/387873]    Loss: 0.002706   Batch Acc: 84.38
[Train] Epoch: 5 [42752/387873]    Loss: 0.001854   Batch Acc: 92.19
[Train] Epoch: 5 [42880/387873]    Loss: 0.001605   Batch Acc: 91.41
[Train] Epoch: 5 [43008/387873]    Loss: 0.002043   Batch Acc: 92.19
[Train] Epoch: 5 [43136/387873]    Loss: 0.001691   Batch Acc: 92.19
[Train] Epoch: 5 [43264/387873]    Loss: 0.002168   Batch Acc: 89.06
[Train] Epoch: 5 [43392/387873]    Loss: 0.002016   Batch Acc: 89.84
[Train] Epoch: 5 [43520/387873]    Loss: 0.001734   Batch Acc: 89.06
[Train] Epoch: 5 [43648/387873]    Loss: 0.001999   Batch Acc: 88.28
[Train] Epoch: 5 [43776/387873]    Loss: 0.002148   Batch Acc: 89.06
[Train] Epoch: 5 [43904/387873]    Loss: 0.002098   Batch Acc: 90.62
[Train] Epoch: 5 [44032/387873]    Loss: 0.002153   Batch Acc: 89.84
[Train] Epoch: 5 [44160/387873]    Loss: 0.002186   Batch Acc: 89.84
[Train] Epoch: 5 [44288/387873]    Loss: 0.001659   Batch Acc: 92.97
[Train] Epoch: 5 [44416/387873]    Loss: 0.002214   Batch Acc: 89.06
[Train] Epoch: 5 [44544/387873]    Loss: 0.001576   Batch Acc: 91.41
[Train] Epoch: 5 [44672/387873]    Loss: 0.001774   Batch Acc: 92.97
[Train] Epoch: 5 [44800/387873]    Loss: 0.001637   Batch Acc: 93.75
[Train] Epoch: 5 [44928/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 5 [45056/387873]    Loss: 0.002022   Batch Acc: 89.06
[Train] Epoch: 5 [45184/387873]    Loss: 0.002378   Batch Acc: 86.72
[Train] Epoch: 5 [45312/387873]    Loss: 0.002264   Batch Acc: 89.06
[Train] Epoch: 5 [45440/387873]    Loss: 0.001927   Batch Acc: 91.41
[Train] Epoch: 5 [45568/387873]    Loss: 0.002712   Batch Acc: 83.59
[Train] Epoch: 5 [45696/387873]    Loss: 0.002299   Batch Acc: 84.38
[Train] Epoch: 5 [45824/387873]    Loss: 0.002592   Batch Acc: 81.25
[Train] Epoch: 5 [45952/387873]    Loss: 0.001938   Batch Acc: 89.06
[Train] Epoch: 5 [46080/387873]    Loss: 0.001936   Batch Acc: 90.62
[Train] Epoch: 5 [46208/387873]    Loss: 0.002518   Batch Acc: 88.28
[Train] Epoch: 5 [46336/387873]    Loss: 0.001669   Batch Acc: 92.97
[Train] Epoch: 5 [46464/387873]    Loss: 0.001797   Batch Acc: 92.19
[Train] Epoch: 5 [46592/387873]    Loss: 0.001635   Batch Acc: 94.53
[Train] Epoch: 5 [46720/387873]    Loss: 0.002288   Batch Acc: 87.50
[Train] Epoch: 5 [46848/387873]    Loss: 0.002689   Batch Acc: 85.16
[Train] Epoch: 5 [46976/387873]    Loss: 0.001666   Batch Acc: 91.41
[Train] Epoch: 5 [47104/387873]    Loss: 0.002135   Batch Acc: 89.84
[Train] Epoch: 5 [47232/387873]    Loss: 0.002239   Batch Acc: 90.62
[Train] Epoch: 5 [47360/387873]    Loss: 0.001301   Batch Acc: 93.75
[Train] Epoch: 5 [47488/387873]    Loss: 0.001645   Batch Acc: 90.62
[Train] Epoch: 5 [47616/387873]    Loss: 0.002160   Batch Acc: 88.28
[Train] Epoch: 5 [47744/387873]    Loss: 0.001599   Batch Acc: 92.19
[Train] Epoch: 5 [47872/387873]    Loss: 0.001528   Batch Acc: 93.75
[Train] Epoch: 5 [48000/387873]    Loss: 0.002260   Batch Acc: 88.28
[Train] Epoch: 5 [48128/387873]    Loss: 0.001833   Batch Acc: 89.84
[Train] Epoch: 5 [48256/387873]    Loss: 0.002457   Batch Acc: 85.94
[Train] Epoch: 5 [48384/387873]    Loss: 0.001953   Batch Acc: 89.84
[Train] Epoch: 5 [48512/387873]    Loss: 0.002305   Batch Acc: 84.38
[Train] Epoch: 5 [48640/387873]    Loss: 0.001808   Batch Acc: 90.62
[Train] Epoch: 5 [48768/387873]    Loss: 0.002353   Batch Acc: 85.16
[Train] Epoch: 5 [48896/387873]    Loss: 0.001700   Batch Acc: 91.41
[Train] Epoch: 5 [49024/387873]    Loss: 0.001434   Batch Acc: 93.75
[Train] Epoch: 5 [49152/387873]    Loss: 0.001955   Batch Acc: 91.41
[Train] Epoch: 5 [49280/387873]    Loss: 0.001610   Batch Acc: 92.19
[Train] Epoch: 5 [49408/387873]    Loss: 0.001468   Batch Acc: 92.19
[Train] Epoch: 5 [49536/387873]    Loss: 0.001526   Batch Acc: 92.97
[Train] Epoch: 5 [49664/387873]    Loss: 0.001613   Batch Acc: 90.62
[Train] Epoch: 5 [49792/387873]    Loss: 0.001381   Batch Acc: 92.97
[Train] Epoch: 5 [49920/387873]    Loss: 0.002677   Batch Acc: 85.16
[Train] Epoch: 5 [50048/387873]    Loss: 0.002188   Batch Acc: 88.28
[Train] Epoch: 5 [50176/387873]    Loss: 0.001988   Batch Acc: 90.62
[Train] Epoch: 5 [50304/387873]    Loss: 0.001901   Batch Acc: 90.62
[Train] Epoch: 5 [50432/387873]    Loss: 0.002145   Batch Acc: 87.50
[Train] Epoch: 5 [50560/387873]    Loss: 0.002361   Batch Acc: 87.50
[Train] Epoch: 5 [50688/387873]    Loss: 0.001921   Batch Acc: 89.84
[Train] Epoch: 5 [50816/387873]    Loss: 0.001656   Batch Acc: 94.53
[Train] Epoch: 5 [50944/387873]    Loss: 0.002035   Batch Acc: 88.28
[Train] Epoch: 5 [51072/387873]    Loss: 0.001623   Batch Acc: 92.19
[Train] Epoch: 5 [51200/387873]    Loss: 0.001646   Batch Acc: 92.19
[Train] Epoch: 5 [51328/387873]    Loss: 0.001988   Batch Acc: 91.41
[Train] Epoch: 5 [51456/387873]    Loss: 0.002274   Batch Acc: 88.28
[Train] Epoch: 5 [51584/387873]    Loss: 0.001804   Batch Acc: 92.19
[Train] Epoch: 5 [51712/387873]    Loss: 0.001955   Batch Acc: 87.50
[Train] Epoch: 5 [51840/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 5 [51968/387873]    Loss: 0.001872   Batch Acc: 92.19
[Train] Epoch: 5 [52096/387873]    Loss: 0.001573   Batch Acc: 93.75
[Train] Epoch: 5 [52224/387873]    Loss: 0.002304   Batch Acc: 85.94
[Train] Epoch: 5 [52352/387873]    Loss: 0.001818   Batch Acc: 92.19
[Train] Epoch: 5 [52480/387873]    Loss: 0.002159   Batch Acc: 87.50
[Train] Epoch: 5 [52608/387873]    Loss: 0.001686   Batch Acc: 92.97
[Train] Epoch: 5 [52736/387873]    Loss: 0.001957   Batch Acc: 88.28
[Train] Epoch: 5 [52864/387873]    Loss: 0.002255   Batch Acc: 89.06
[Train] Epoch: 5 [52992/387873]    Loss: 0.002006   Batch Acc: 87.50
[Train] Epoch: 5 [53120/387873]    Loss: 0.002278   Batch Acc: 85.16
[Train] Epoch: 5 [53248/387873]    Loss: 0.001511   Batch Acc: 94.53
[Train] Epoch: 5 [53376/387873]    Loss: 0.001818   Batch Acc: 90.62
[Train] Epoch: 5 [53504/387873]    Loss: 0.001702   Batch Acc: 90.62
[Train] Epoch: 5 [53632/387873]    Loss: 0.001680   Batch Acc: 89.84
[Train] Epoch: 5 [53760/387873]    Loss: 0.002325   Batch Acc: 85.16
[Train] Epoch: 5 [53888/387873]    Loss: 0.001679   Batch Acc: 91.41
[Train] Epoch: 5 [54016/387873]    Loss: 0.002070   Batch Acc: 85.94
[Train] Epoch: 5 [54144/387873]    Loss: 0.002346   Batch Acc: 87.50
[Train] Epoch: 5 [54272/387873]    Loss: 0.002293   Batch Acc: 83.59
[Train] Epoch: 5 [54400/387873]    Loss: 0.002211   Batch Acc: 87.50
[Train] Epoch: 5 [54528/387873]    Loss: 0.001646   Batch Acc: 91.41
[Train] Epoch: 5 [54656/387873]    Loss: 0.001941   Batch Acc: 89.84
[Train] Epoch: 5 [54784/387873]    Loss: 0.002099   Batch Acc: 86.72
[Train] Epoch: 5 [54912/387873]    Loss: 0.002061   Batch Acc: 87.50
[Train] Epoch: 5 [55040/387873]    Loss: 0.002237   Batch Acc: 85.94
[Train] Epoch: 5 [55168/387873]    Loss: 0.001724   Batch Acc: 90.62
[Train] Epoch: 5 [55296/387873]    Loss: 0.001866   Batch Acc: 89.84
[Train] Epoch: 5 [55424/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 5 [55552/387873]    Loss: 0.002914   Batch Acc: 85.94
[Train] Epoch: 5 [55680/387873]    Loss: 0.001405   Batch Acc: 95.31
[Train] Epoch: 5 [55808/387873]    Loss: 0.002195   Batch Acc: 85.94
[Train] Epoch: 5 [55936/387873]    Loss: 0.002372   Batch Acc: 85.94
[Train] Epoch: 5 [56064/387873]    Loss: 0.002225   Batch Acc: 86.72
[Train] Epoch: 5 [56192/387873]    Loss: 0.001444   Batch Acc: 93.75
[Train] Epoch: 5 [56320/387873]    Loss: 0.001726   Batch Acc: 89.84
[Train] Epoch: 5 [56448/387873]    Loss: 0.002592   Batch Acc: 84.38
[Train] Epoch: 5 [56576/387873]    Loss: 0.002575   Batch Acc: 83.59
[Train] Epoch: 5 [56704/387873]    Loss: 0.001874   Batch Acc: 89.84
[Train] Epoch: 5 [56832/387873]    Loss: 0.001643   Batch Acc: 91.41
[Train] Epoch: 5 [56960/387873]    Loss: 0.002317   Batch Acc: 87.50
[Train] Epoch: 5 [57088/387873]    Loss: 0.001993   Batch Acc: 89.84
[Train] Epoch: 5 [57216/387873]    Loss: 0.001606   Batch Acc: 92.19
[Train] Epoch: 5 [57344/387873]    Loss: 0.002067   Batch Acc: 88.28
[Train] Epoch: 5 [57472/387873]    Loss: 0.001735   Batch Acc: 92.97
[Train] Epoch: 5 [57600/387873]    Loss: 0.001496   Batch Acc: 92.19
[Train] Epoch: 5 [57728/387873]    Loss: 0.001842   Batch Acc: 92.97
[Train] Epoch: 5 [57856/387873]    Loss: 0.001618   Batch Acc: 92.97
[Train] Epoch: 5 [57984/387873]    Loss: 0.001456   Batch Acc: 92.97
[Train] Epoch: 5 [58112/387873]    Loss: 0.001811   Batch Acc: 89.84
[Train] Epoch: 5 [58240/387873]    Loss: 0.001729   Batch Acc: 92.19
[Train] Epoch: 5 [58368/387873]    Loss: 0.001463   Batch Acc: 92.97
[Train] Epoch: 5 [58496/387873]    Loss: 0.001934   Batch Acc: 89.06
[Train] Epoch: 5 [58624/387873]    Loss: 0.001756   Batch Acc: 93.75
[Train] Epoch: 5 [58752/387873]    Loss: 0.002122   Batch Acc: 89.84
[Train] Epoch: 5 [58880/387873]    Loss: 0.001890   Batch Acc: 88.28
[Train] Epoch: 5 [59008/387873]    Loss: 0.001924   Batch Acc: 89.06
[Train] Epoch: 5 [59136/387873]    Loss: 0.002525   Batch Acc: 85.94
[Train] Epoch: 5 [59264/387873]    Loss: 0.001862   Batch Acc: 88.28
[Train] Epoch: 5 [59392/387873]    Loss: 0.002318   Batch Acc: 89.06
[Train] Epoch: 5 [59520/387873]    Loss: 0.001658   Batch Acc: 92.19
[Train] Epoch: 5 [59648/387873]    Loss: 0.002226   Batch Acc: 86.72
[Train] Epoch: 5 [59776/387873]    Loss: 0.002168   Batch Acc: 89.06
[Train] Epoch: 5 [59904/387873]    Loss: 0.002135   Batch Acc: 88.28
[Train] Epoch: 5 [60032/387873]    Loss: 0.001794   Batch Acc: 91.41
[Train] Epoch: 5 [60160/387873]    Loss: 0.002612   Batch Acc: 83.59
[Train] Epoch: 5 [60288/387873]    Loss: 0.001958   Batch Acc: 88.28
[Train] Epoch: 5 [60416/387873]    Loss: 0.002188   Batch Acc: 87.50
[Train] Epoch: 5 [60544/387873]    Loss: 0.001563   Batch Acc: 92.97
[Train] Epoch: 5 [60672/387873]    Loss: 0.002322   Batch Acc: 85.16
[Train] Epoch: 5 [60800/387873]    Loss: 0.002008   Batch Acc: 87.50
[Train] Epoch: 5 [60928/387873]    Loss: 0.001566   Batch Acc: 91.41
[Train] Epoch: 5 [61056/387873]    Loss: 0.001717   Batch Acc: 92.19
[Train] Epoch: 5 [61184/387873]    Loss: 0.002254   Batch Acc: 86.72
[Train] Epoch: 5 [61312/387873]    Loss: 0.002590   Batch Acc: 85.94
[Train] Epoch: 5 [61440/387873]    Loss: 0.002359   Batch Acc: 87.50
[Train] Epoch: 5 [61568/387873]    Loss: 0.002595   Batch Acc: 85.16
[Train] Epoch: 5 [61696/387873]    Loss: 0.002161   Batch Acc: 87.50
[Train] Epoch: 5 [61824/387873]    Loss: 0.001578   Batch Acc: 92.19
[Train] Epoch: 5 [61952/387873]    Loss: 0.002154   Batch Acc: 86.72
[Train] Epoch: 5 [62080/387873]    Loss: 0.001516   Batch Acc: 92.19
[Train] Epoch: 5 [62208/387873]    Loss: 0.001778   Batch Acc: 89.84
[Train] Epoch: 5 [62336/387873]    Loss: 0.001899   Batch Acc: 90.62
[Train] Epoch: 5 [62464/387873]    Loss: 0.001566   Batch Acc: 92.97
[Train] Epoch: 5 [62592/387873]    Loss: 0.001749   Batch Acc: 92.19
[Train] Epoch: 5 [62720/387873]    Loss: 0.001588   Batch Acc: 92.19
[Train] Epoch: 5 [62848/387873]    Loss: 0.001850   Batch Acc: 91.41
[Train] Epoch: 5 [62976/387873]    Loss: 0.002280   Batch Acc: 88.28
[Train] Epoch: 5 [63104/387873]    Loss: 0.002378   Batch Acc: 86.72
[Train] Epoch: 5 [63232/387873]    Loss: 0.002021   Batch Acc: 92.97
[Train] Epoch: 5 [63360/387873]    Loss: 0.002085   Batch Acc: 91.41
[Train] Epoch: 5 [63488/387873]    Loss: 0.002227   Batch Acc: 88.28
[Train] Epoch: 5 [63616/387873]    Loss: 0.001611   Batch Acc: 92.97
[Train] Epoch: 5 [63744/387873]    Loss: 0.002255   Batch Acc: 88.28
[Train] Epoch: 5 [63872/387873]    Loss: 0.002030   Batch Acc: 89.06
[Train] Epoch: 5 [64000/387873]    Loss: 0.002419   Batch Acc: 91.41
[Train] Epoch: 5 [64128/387873]    Loss: 0.001856   Batch Acc: 89.84
[Train] Epoch: 5 [64256/387873]    Loss: 0.001808   Batch Acc: 92.97
[Train] Epoch: 5 [64384/387873]    Loss: 0.001810   Batch Acc: 91.41
[Train] Epoch: 5 [64512/387873]    Loss: 0.002271   Batch Acc: 87.50
[Train] Epoch: 5 [64640/387873]    Loss: 0.002500   Batch Acc: 85.94
[Train] Epoch: 5 [64768/387873]    Loss: 0.002194   Batch Acc: 90.62
[Train] Epoch: 5 [64896/387873]    Loss: 0.002230   Batch Acc: 85.94
[Train] Epoch: 5 [65024/387873]    Loss: 0.001261   Batch Acc: 95.31
[Train] Epoch: 5 [65152/387873]    Loss: 0.001788   Batch Acc: 87.50
[Train] Epoch: 5 [65280/387873]    Loss: 0.001684   Batch Acc: 90.62
[Train] Epoch: 5 [65408/387873]    Loss: 0.002013   Batch Acc: 90.62
[Train] Epoch: 5 [65536/387873]    Loss: 0.001861   Batch Acc: 89.06
[Train] Epoch: 5 [65664/387873]    Loss: 0.001416   Batch Acc: 92.19
[Train] Epoch: 5 [65792/387873]    Loss: 0.002217   Batch Acc: 87.50
[Train] Epoch: 5 [65920/387873]    Loss: 0.002243   Batch Acc: 85.94
[Train] Epoch: 5 [66048/387873]    Loss: 0.001711   Batch Acc: 96.09
[Train] Epoch: 5 [66176/387873]    Loss: 0.002314   Batch Acc: 86.72
[Train] Epoch: 5 [66304/387873]    Loss: 0.002160   Batch Acc: 87.50
[Train] Epoch: 5 [66432/387873]    Loss: 0.002864   Batch Acc: 84.38
[Train] Epoch: 5 [66560/387873]    Loss: 0.001358   Batch Acc: 95.31
[Train] Epoch: 5 [66688/387873]    Loss: 0.002149   Batch Acc: 89.06
[Train] Epoch: 5 [66816/387873]    Loss: 0.001719   Batch Acc: 92.97
[Train] Epoch: 5 [66944/387873]    Loss: 0.001479   Batch Acc: 93.75
[Train] Epoch: 5 [67072/387873]    Loss: 0.001917   Batch Acc: 88.28
[Train] Epoch: 5 [67200/387873]    Loss: 0.001503   Batch Acc: 94.53
[Train] Epoch: 5 [67328/387873]    Loss: 0.002368   Batch Acc: 91.41
[Train] Epoch: 5 [67456/387873]    Loss: 0.002130   Batch Acc: 87.50
[Train] Epoch: 5 [67584/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 5 [67712/387873]    Loss: 0.001564   Batch Acc: 93.75
[Train] Epoch: 5 [67840/387873]    Loss: 0.001842   Batch Acc: 92.97
[Train] Epoch: 5 [67968/387873]    Loss: 0.002909   Batch Acc: 85.94
[Train] Epoch: 5 [68096/387873]    Loss: 0.001448   Batch Acc: 92.19
[Train] Epoch: 5 [68224/387873]    Loss: 0.002188   Batch Acc: 85.94
[Train] Epoch: 5 [68352/387873]    Loss: 0.001766   Batch Acc: 90.62
[Train] Epoch: 5 [68480/387873]    Loss: 0.001843   Batch Acc: 91.41
[Train] Epoch: 5 [68608/387873]    Loss: 0.001711   Batch Acc: 91.41
[Train] Epoch: 5 [68736/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 5 [68864/387873]    Loss: 0.001834   Batch Acc: 91.41
[Train] Epoch: 5 [68992/387873]    Loss: 0.001452   Batch Acc: 93.75
[Train] Epoch: 5 [69120/387873]    Loss: 0.001885   Batch Acc: 89.84
[Train] Epoch: 5 [69248/387873]    Loss: 0.001739   Batch Acc: 89.06
[Train] Epoch: 5 [69376/387873]    Loss: 0.002042   Batch Acc: 92.19
[Train] Epoch: 5 [69504/387873]    Loss: 0.002306   Batch Acc: 86.72
[Train] Epoch: 5 [69632/387873]    Loss: 0.001455   Batch Acc: 94.53
[Train] Epoch: 5 [69760/387873]    Loss: 0.002181   Batch Acc: 87.50
[Train] Epoch: 5 [69888/387873]    Loss: 0.002663   Batch Acc: 81.25
[Train] Epoch: 5 [70016/387873]    Loss: 0.002067   Batch Acc: 89.06
[Train] Epoch: 5 [70144/387873]    Loss: 0.002182   Batch Acc: 89.06
[Train] Epoch: 5 [70272/387873]    Loss: 0.002298   Batch Acc: 86.72
[Train] Epoch: 5 [70400/387873]    Loss: 0.002440   Batch Acc: 89.06
[Train] Epoch: 5 [70528/387873]    Loss: 0.001481   Batch Acc: 93.75
[Train] Epoch: 5 [70656/387873]    Loss: 0.002086   Batch Acc: 88.28
[Train] Epoch: 5 [70784/387873]    Loss: 0.002478   Batch Acc: 88.28
[Train] Epoch: 5 [70912/387873]    Loss: 0.002113   Batch Acc: 88.28
[Train] Epoch: 5 [71040/387873]    Loss: 0.001618   Batch Acc: 93.75
[Train] Epoch: 5 [71168/387873]    Loss: 0.001852   Batch Acc: 89.06
[Train] Epoch: 5 [71296/387873]    Loss: 0.002631   Batch Acc: 85.16
[Train] Epoch: 5 [71424/387873]    Loss: 0.001878   Batch Acc: 89.84
[Train] Epoch: 5 [71552/387873]    Loss: 0.002061   Batch Acc: 89.84
[Train] Epoch: 5 [71680/387873]    Loss: 0.001990   Batch Acc: 89.84
[Train] Epoch: 5 [71808/387873]    Loss: 0.001812   Batch Acc: 88.28
[Train] Epoch: 5 [71936/387873]    Loss: 0.001694   Batch Acc: 92.97
[Train] Epoch: 5 [72064/387873]    Loss: 0.001859   Batch Acc: 89.06
[Train] Epoch: 5 [72192/387873]    Loss: 0.002421   Batch Acc: 85.16
[Train] Epoch: 5 [72320/387873]    Loss: 0.002381   Batch Acc: 89.06
[Train] Epoch: 5 [72448/387873]    Loss: 0.001751   Batch Acc: 89.84
[Train] Epoch: 5 [72576/387873]    Loss: 0.001497   Batch Acc: 94.53
[Train] Epoch: 5 [72704/387873]    Loss: 0.001962   Batch Acc: 90.62
[Train] Epoch: 5 [72832/387873]    Loss: 0.002099   Batch Acc: 85.94
[Train] Epoch: 5 [72960/387873]    Loss: 0.001712   Batch Acc: 91.41
[Train] Epoch: 5 [73088/387873]    Loss: 0.001839   Batch Acc: 89.06
[Train] Epoch: 5 [73216/387873]    Loss: 0.001668   Batch Acc: 91.41
[Train] Epoch: 5 [73344/387873]    Loss: 0.002077   Batch Acc: 89.84
[Train] Epoch: 5 [73472/387873]    Loss: 0.002444   Batch Acc: 86.72
[Train] Epoch: 5 [73600/387873]    Loss: 0.001821   Batch Acc: 90.62
[Train] Epoch: 5 [73728/387873]    Loss: 0.001378   Batch Acc: 94.53
[Train] Epoch: 5 [73856/387873]    Loss: 0.002478   Batch Acc: 85.16
[Train] Epoch: 5 [73984/387873]    Loss: 0.002418   Batch Acc: 85.16
[Train] Epoch: 5 [74112/387873]    Loss: 0.001771   Batch Acc: 88.28
[Train] Epoch: 5 [74240/387873]    Loss: 0.001646   Batch Acc: 92.97
[Train] Epoch: 5 [74368/387873]    Loss: 0.001502   Batch Acc: 92.97
[Train] Epoch: 5 [74496/387873]    Loss: 0.001973   Batch Acc: 89.06
[Train] Epoch: 5 [74624/387873]    Loss: 0.001823   Batch Acc: 88.28
[Train] Epoch: 5 [74752/387873]    Loss: 0.002405   Batch Acc: 85.16
[Train] Epoch: 5 [74880/387873]    Loss: 0.002314   Batch Acc: 84.38
[Train] Epoch: 5 [75008/387873]    Loss: 0.001720   Batch Acc: 93.75
[Train] Epoch: 5 [75136/387873]    Loss: 0.002676   Batch Acc: 88.28
[Train] Epoch: 5 [75264/387873]    Loss: 0.001397   Batch Acc: 94.53
[Train] Epoch: 5 [75392/387873]    Loss: 0.001670   Batch Acc: 91.41
[Train] Epoch: 5 [75520/387873]    Loss: 0.002001   Batch Acc: 90.62
[Train] Epoch: 5 [75648/387873]    Loss: 0.002070   Batch Acc: 87.50
[Train] Epoch: 5 [75776/387873]    Loss: 0.001919   Batch Acc: 92.97
[Train] Epoch: 5 [75904/387873]    Loss: 0.002009   Batch Acc: 89.06
[Train] Epoch: 5 [76032/387873]    Loss: 0.001968   Batch Acc: 91.41
[Train] Epoch: 5 [76160/387873]    Loss: 0.001585   Batch Acc: 92.19
[Train] Epoch: 5 [76288/387873]    Loss: 0.001998   Batch Acc: 91.41
[Train] Epoch: 5 [76416/387873]    Loss: 0.001679   Batch Acc: 93.75
[Train] Epoch: 5 [76544/387873]    Loss: 0.001905   Batch Acc: 91.41
[Train] Epoch: 5 [76672/387873]    Loss: 0.002236   Batch Acc: 87.50
[Train] Epoch: 5 [76800/387873]    Loss: 0.001542   Batch Acc: 92.97
[Train] Epoch: 5 [76928/387873]    Loss: 0.002384   Batch Acc: 88.28
[Train] Epoch: 5 [77056/387873]    Loss: 0.001896   Batch Acc: 89.06
[Train] Epoch: 5 [77184/387873]    Loss: 0.002008   Batch Acc: 89.84
[Train] Epoch: 5 [77312/387873]    Loss: 0.001940   Batch Acc: 90.62
[Train] Epoch: 5 [77440/387873]    Loss: 0.002309   Batch Acc: 86.72
[Train] Epoch: 5 [77568/387873]    Loss: 0.001720   Batch Acc: 91.41
[Train] Epoch: 5 [77696/387873]    Loss: 0.001359   Batch Acc: 92.97
[Train] Epoch: 5 [77824/387873]    Loss: 0.001975   Batch Acc: 89.06
[Train] Epoch: 5 [77952/387873]    Loss: 0.001973   Batch Acc: 89.84
[Train] Epoch: 5 [78080/387873]    Loss: 0.001942   Batch Acc: 89.84
[Train] Epoch: 5 [78208/387873]    Loss: 0.001753   Batch Acc: 87.50
[Train] Epoch: 5 [78336/387873]    Loss: 0.002578   Batch Acc: 86.72
[Train] Epoch: 5 [78464/387873]    Loss: 0.002971   Batch Acc: 81.25
[Train] Epoch: 5 [78592/387873]    Loss: 0.001774   Batch Acc: 90.62
[Train] Epoch: 5 [78720/387873]    Loss: 0.002172   Batch Acc: 89.06
[Train] Epoch: 5 [78848/387873]    Loss: 0.001952   Batch Acc: 91.41
[Train] Epoch: 5 [78976/387873]    Loss: 0.002198   Batch Acc: 87.50
[Train] Epoch: 5 [79104/387873]    Loss: 0.001802   Batch Acc: 90.62
[Train] Epoch: 5 [79232/387873]    Loss: 0.001532   Batch Acc: 93.75
[Train] Epoch: 5 [79360/387873]    Loss: 0.001918   Batch Acc: 91.41
[Train] Epoch: 5 [79488/387873]    Loss: 0.001929   Batch Acc: 89.84
[Train] Epoch: 5 [79616/387873]    Loss: 0.002021   Batch Acc: 88.28
[Train] Epoch: 5 [79744/387873]    Loss: 0.002021   Batch Acc: 87.50
[Train] Epoch: 5 [79872/387873]    Loss: 0.002141   Batch Acc: 90.62
[Train] Epoch: 5 [80000/387873]    Loss: 0.001679   Batch Acc: 92.19
[Train] Epoch: 5 [80128/387873]    Loss: 0.001756   Batch Acc: 88.28
[Train] Epoch: 5 [80256/387873]    Loss: 0.001554   Batch Acc: 92.97
[Train] Epoch: 5 [80384/387873]    Loss: 0.001671   Batch Acc: 86.72
[Train] Epoch: 5 [80512/387873]    Loss: 0.002055   Batch Acc: 91.41
[Train] Epoch: 5 [80640/387873]    Loss: 0.001842   Batch Acc: 89.06
[Train] Epoch: 5 [80768/387873]    Loss: 0.001858   Batch Acc: 90.62
[Train] Epoch: 5 [80896/387873]    Loss: 0.002097   Batch Acc: 88.28
[Train] Epoch: 5 [81024/387873]    Loss: 0.002036   Batch Acc: 87.50
[Train] Epoch: 5 [81152/387873]    Loss: 0.002240   Batch Acc: 86.72
[Train] Epoch: 5 [81280/387873]    Loss: 0.002199   Batch Acc: 85.94
[Train] Epoch: 5 [81408/387873]    Loss: 0.001920   Batch Acc: 93.75
[Train] Epoch: 5 [81536/387873]    Loss: 0.002131   Batch Acc: 87.50
[Train] Epoch: 5 [81664/387873]    Loss: 0.002259   Batch Acc: 87.50
[Train] Epoch: 5 [81792/387873]    Loss: 0.002180   Batch Acc: 90.62
[Train] Epoch: 5 [81920/387873]    Loss: 0.002131   Batch Acc: 88.28
[Train] Epoch: 5 [82048/387873]    Loss: 0.002121   Batch Acc: 86.72
[Train] Epoch: 5 [82176/387873]    Loss: 0.001796   Batch Acc: 92.19
[Train] Epoch: 5 [82304/387873]    Loss: 0.002344   Batch Acc: 88.28
[Train] Epoch: 5 [82432/387873]    Loss: 0.001787   Batch Acc: 92.19
[Train] Epoch: 5 [82560/387873]    Loss: 0.001811   Batch Acc: 89.84
[Train] Epoch: 5 [82688/387873]    Loss: 0.002338   Batch Acc: 89.84
[Train] Epoch: 5 [82816/387873]    Loss: 0.001565   Batch Acc: 92.97
[Train] Epoch: 5 [82944/387873]    Loss: 0.001702   Batch Acc: 92.97
[Train] Epoch: 5 [83072/387873]    Loss: 0.001513   Batch Acc: 92.97
[Train] Epoch: 5 [83200/387873]    Loss: 0.002298   Batch Acc: 86.72
[Train] Epoch: 5 [83328/387873]    Loss: 0.001818   Batch Acc: 88.28
[Train] Epoch: 5 [83456/387873]    Loss: 0.002267   Batch Acc: 86.72
[Train] Epoch: 5 [83584/387873]    Loss: 0.002011   Batch Acc: 89.84
[Train] Epoch: 5 [83712/387873]    Loss: 0.002237   Batch Acc: 84.38
[Train] Epoch: 5 [83840/387873]    Loss: 0.001501   Batch Acc: 96.09
[Train] Epoch: 5 [83968/387873]    Loss: 0.002121   Batch Acc: 89.06
[Train] Epoch: 5 [84096/387873]    Loss: 0.001996   Batch Acc: 89.06
[Train] Epoch: 5 [84224/387873]    Loss: 0.002103   Batch Acc: 87.50
[Train] Epoch: 5 [84352/387873]    Loss: 0.002037   Batch Acc: 89.06
[Train] Epoch: 5 [84480/387873]    Loss: 0.001393   Batch Acc: 92.19
[Train] Epoch: 5 [84608/387873]    Loss: 0.002186   Batch Acc: 88.28
[Train] Epoch: 5 [84736/387873]    Loss: 0.001947   Batch Acc: 89.06
[Train] Epoch: 5 [84864/387873]    Loss: 0.001554   Batch Acc: 92.19
[Train] Epoch: 5 [84992/387873]    Loss: 0.002461   Batch Acc: 85.94
[Train] Epoch: 5 [85120/387873]    Loss: 0.001995   Batch Acc: 89.84
[Train] Epoch: 5 [85248/387873]    Loss: 0.001690   Batch Acc: 91.41
[Train] Epoch: 5 [85376/387873]    Loss: 0.002195   Batch Acc: 85.16
[Train] Epoch: 5 [85504/387873]    Loss: 0.001543   Batch Acc: 92.19
[Train] Epoch: 5 [85632/387873]    Loss: 0.001749   Batch Acc: 89.06
[Train] Epoch: 5 [85760/387873]    Loss: 0.001684   Batch Acc: 89.06
[Train] Epoch: 5 [85888/387873]    Loss: 0.001536   Batch Acc: 94.53
[Train] Epoch: 5 [86016/387873]    Loss: 0.001686   Batch Acc: 92.19
[Train] Epoch: 5 [86144/387873]    Loss: 0.002337   Batch Acc: 82.81
[Train] Epoch: 5 [86272/387873]    Loss: 0.002332   Batch Acc: 88.28
[Train] Epoch: 5 [86400/387873]    Loss: 0.001481   Batch Acc: 93.75
[Train] Epoch: 5 [86528/387873]    Loss: 0.002461   Batch Acc: 86.72
[Train] Epoch: 5 [86656/387873]    Loss: 0.002025   Batch Acc: 89.84
[Train] Epoch: 5 [86784/387873]    Loss: 0.002269   Batch Acc: 89.84
[Train] Epoch: 5 [86912/387873]    Loss: 0.002218   Batch Acc: 87.50
[Train] Epoch: 5 [87040/387873]    Loss: 0.002034   Batch Acc: 88.28
[Train] Epoch: 5 [87168/387873]    Loss: 0.001902   Batch Acc: 91.41
[Train] Epoch: 5 [87296/387873]    Loss: 0.002797   Batch Acc: 83.59
[Train] Epoch: 5 [87424/387873]    Loss: 0.002186   Batch Acc: 88.28
[Train] Epoch: 5 [87552/387873]    Loss: 0.001562   Batch Acc: 93.75
[Train] Epoch: 5 [87680/387873]    Loss: 0.002341   Batch Acc: 84.38
[Train] Epoch: 5 [87808/387873]    Loss: 0.001710   Batch Acc: 94.53
[Train] Epoch: 5 [87936/387873]    Loss: 0.001992   Batch Acc: 89.06
[Train] Epoch: 5 [88064/387873]    Loss: 0.001894   Batch Acc: 90.62
[Train] Epoch: 5 [88192/387873]    Loss: 0.001640   Batch Acc: 91.41
[Train] Epoch: 5 [88320/387873]    Loss: 0.001983   Batch Acc: 88.28
[Train] Epoch: 5 [88448/387873]    Loss: 0.001936   Batch Acc: 90.62
[Train] Epoch: 5 [88576/387873]    Loss: 0.001981   Batch Acc: 89.84
[Train] Epoch: 5 [88704/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 5 [88832/387873]    Loss: 0.002142   Batch Acc: 87.50
[Train] Epoch: 5 [88960/387873]    Loss: 0.002191   Batch Acc: 86.72
[Train] Epoch: 5 [89088/387873]    Loss: 0.002162   Batch Acc: 84.38
[Train] Epoch: 5 [89216/387873]    Loss: 0.001940   Batch Acc: 89.84
[Train] Epoch: 5 [89344/387873]    Loss: 0.002317   Batch Acc: 90.62
[Train] Epoch: 5 [89472/387873]    Loss: 0.001638   Batch Acc: 92.19
[Train] Epoch: 5 [89600/387873]    Loss: 0.002219   Batch Acc: 89.84
[Train] Epoch: 5 [89728/387873]    Loss: 0.001851   Batch Acc: 90.62
[Train] Epoch: 5 [89856/387873]    Loss: 0.001742   Batch Acc: 90.62
[Train] Epoch: 5 [89984/387873]    Loss: 0.001856   Batch Acc: 92.19
[Train] Epoch: 5 [90112/387873]    Loss: 0.002683   Batch Acc: 84.38
[Train] Epoch: 5 [90240/387873]    Loss: 0.001516   Batch Acc: 91.41
[Train] Epoch: 5 [90368/387873]    Loss: 0.002376   Batch Acc: 87.50
[Train] Epoch: 5 [90496/387873]    Loss: 0.002251   Batch Acc: 87.50
[Train] Epoch: 5 [90624/387873]    Loss: 0.002133   Batch Acc: 87.50
[Train] Epoch: 5 [90752/387873]    Loss: 0.002243   Batch Acc: 89.84
[Train] Epoch: 5 [90880/387873]    Loss: 0.002274   Batch Acc: 89.06
[Train] Epoch: 5 [91008/387873]    Loss: 0.002087   Batch Acc: 86.72
[Train] Epoch: 5 [91136/387873]    Loss: 0.002859   Batch Acc: 85.16
[Train] Epoch: 5 [91264/387873]    Loss: 0.001791   Batch Acc: 92.19
[Train] Epoch: 5 [91392/387873]    Loss: 0.001338   Batch Acc: 92.97
[Train] Epoch: 5 [91520/387873]    Loss: 0.002197   Batch Acc: 87.50
[Train] Epoch: 5 [91648/387873]    Loss: 0.002771   Batch Acc: 84.38
[Train] Epoch: 5 [91776/387873]    Loss: 0.001539   Batch Acc: 92.19
[Train] Epoch: 5 [91904/387873]    Loss: 0.001684   Batch Acc: 90.62
[Train] Epoch: 5 [92032/387873]    Loss: 0.001453   Batch Acc: 93.75
[Train] Epoch: 5 [92160/387873]    Loss: 0.001636   Batch Acc: 91.41
[Train] Epoch: 5 [92288/387873]    Loss: 0.001981   Batch Acc: 91.41
[Train] Epoch: 5 [92416/387873]    Loss: 0.001827   Batch Acc: 88.28
[Train] Epoch: 5 [92544/387873]    Loss: 0.001653   Batch Acc: 92.19
[Train] Epoch: 5 [92672/387873]    Loss: 0.002419   Batch Acc: 86.72
[Train] Epoch: 5 [92800/387873]    Loss: 0.001863   Batch Acc: 92.19
[Train] Epoch: 5 [92928/387873]    Loss: 0.001477   Batch Acc: 93.75
[Train] Epoch: 5 [93056/387873]    Loss: 0.001651   Batch Acc: 89.84
[Train] Epoch: 5 [93184/387873]    Loss: 0.001604   Batch Acc: 92.19
[Train] Epoch: 5 [93312/387873]    Loss: 0.002230   Batch Acc: 86.72
[Train] Epoch: 5 [93440/387873]    Loss: 0.002249   Batch Acc: 86.72
[Train] Epoch: 5 [93568/387873]    Loss: 0.001722   Batch Acc: 93.75
[Train] Epoch: 5 [93696/387873]    Loss: 0.002144   Batch Acc: 87.50
[Train] Epoch: 5 [93824/387873]    Loss: 0.002038   Batch Acc: 92.97
[Train] Epoch: 5 [93952/387873]    Loss: 0.002468   Batch Acc: 86.72
[Train] Epoch: 5 [94080/387873]    Loss: 0.002150   Batch Acc: 84.38
[Train] Epoch: 5 [94208/387873]    Loss: 0.001667   Batch Acc: 89.84
[Train] Epoch: 5 [94336/387873]    Loss: 0.001868   Batch Acc: 90.62
[Train] Epoch: 5 [94464/387873]    Loss: 0.002086   Batch Acc: 89.84
[Train] Epoch: 5 [94592/387873]    Loss: 0.001500   Batch Acc: 91.41
[Train] Epoch: 5 [94720/387873]    Loss: 0.002493   Batch Acc: 85.16
[Train] Epoch: 5 [94848/387873]    Loss: 0.002307   Batch Acc: 85.94
[Train] Epoch: 5 [94976/387873]    Loss: 0.002252   Batch Acc: 86.72
[Train] Epoch: 5 [95104/387873]    Loss: 0.001808   Batch Acc: 92.97
[Train] Epoch: 5 [95232/387873]    Loss: 0.002184   Batch Acc: 88.28
[Train] Epoch: 5 [95360/387873]    Loss: 0.001774   Batch Acc: 89.06
[Train] Epoch: 5 [95488/387873]    Loss: 0.001312   Batch Acc: 95.31
[Train] Epoch: 5 [95616/387873]    Loss: 0.001724   Batch Acc: 92.97
[Train] Epoch: 5 [95744/387873]    Loss: 0.002361   Batch Acc: 85.94
[Train] Epoch: 5 [95872/387873]    Loss: 0.001897   Batch Acc: 87.50
[Train] Epoch: 5 [96000/387873]    Loss: 0.001974   Batch Acc: 90.62
[Train] Epoch: 5 [96128/387873]    Loss: 0.001933   Batch Acc: 88.28
[Train] Epoch: 5 [96256/387873]    Loss: 0.001992   Batch Acc: 90.62
[Train] Epoch: 5 [96384/387873]    Loss: 0.001557   Batch Acc: 91.41
[Train] Epoch: 5 [96512/387873]    Loss: 0.001743   Batch Acc: 91.41
[Train] Epoch: 5 [96640/387873]    Loss: 0.002064   Batch Acc: 89.06
[Train] Epoch: 5 [96768/387873]    Loss: 0.001924   Batch Acc: 90.62
[Train] Epoch: 5 [96896/387873]    Loss: 0.002529   Batch Acc: 88.28
[Train] Epoch: 5 [97024/387873]    Loss: 0.001752   Batch Acc: 90.62
[Train] Epoch: 5 [97152/387873]    Loss: 0.002189   Batch Acc: 86.72
[Train] Epoch: 5 [97280/387873]    Loss: 0.001650   Batch Acc: 94.53
[Train] Epoch: 5 [97408/387873]    Loss: 0.001740   Batch Acc: 90.62
[Train] Epoch: 5 [97536/387873]    Loss: 0.002174   Batch Acc: 89.06
[Train] Epoch: 5 [97664/387873]    Loss: 0.001784   Batch Acc: 91.41
[Train] Epoch: 5 [97792/387873]    Loss: 0.001989   Batch Acc: 89.06
[Train] Epoch: 5 [97920/387873]    Loss: 0.001724   Batch Acc: 89.06
[Train] Epoch: 5 [98048/387873]    Loss: 0.001574   Batch Acc: 95.31
[Train] Epoch: 5 [98176/387873]    Loss: 0.001662   Batch Acc: 92.19
[Train] Epoch: 5 [98304/387873]    Loss: 0.002313   Batch Acc: 86.72
[Train] Epoch: 5 [98432/387873]    Loss: 0.002162   Batch Acc: 89.06
[Train] Epoch: 5 [98560/387873]    Loss: 0.001759   Batch Acc: 91.41
[Train] Epoch: 5 [98688/387873]    Loss: 0.001603   Batch Acc: 95.31
[Train] Epoch: 5 [98816/387873]    Loss: 0.001670   Batch Acc: 92.19
[Train] Epoch: 5 [98944/387873]    Loss: 0.001876   Batch Acc: 90.62
[Train] Epoch: 5 [99072/387873]    Loss: 0.001540   Batch Acc: 92.19
[Train] Epoch: 5 [99200/387873]    Loss: 0.002091   Batch Acc: 88.28
[Train] Epoch: 5 [99328/387873]    Loss: 0.002368   Batch Acc: 85.16
[Train] Epoch: 5 [99456/387873]    Loss: 0.002090   Batch Acc: 88.28
[Train] Epoch: 5 [99584/387873]    Loss: 0.001832   Batch Acc: 88.28
[Train] Epoch: 5 [99712/387873]    Loss: 0.001928   Batch Acc: 90.62
[Train] Epoch: 5 [99840/387873]    Loss: 0.002209   Batch Acc: 87.50
[Train] Epoch: 5 [99968/387873]    Loss: 0.001467   Batch Acc: 92.97
[Train] Epoch: 5 [100096/387873]    Loss: 0.001354   Batch Acc: 93.75
[Train] Epoch: 5 [100224/387873]    Loss: 0.002112   Batch Acc: 86.72
[Train] Epoch: 5 [100352/387873]    Loss: 0.002381   Batch Acc: 86.72
[Train] Epoch: 5 [100480/387873]    Loss: 0.002259   Batch Acc: 89.06
[Train] Epoch: 5 [100608/387873]    Loss: 0.001887   Batch Acc: 89.84
[Train] Epoch: 5 [100736/387873]    Loss: 0.001393   Batch Acc: 92.97
[Train] Epoch: 5 [100864/387873]    Loss: 0.001930   Batch Acc: 92.19
[Train] Epoch: 5 [100992/387873]    Loss: 0.002143   Batch Acc: 89.06
[Train] Epoch: 5 [101120/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 5 [101248/387873]    Loss: 0.001932   Batch Acc: 88.28
[Train] Epoch: 5 [101376/387873]    Loss: 0.002199   Batch Acc: 89.84
[Train] Epoch: 5 [101504/387873]    Loss: 0.001883   Batch Acc: 90.62
[Train] Epoch: 5 [101632/387873]    Loss: 0.002438   Batch Acc: 86.72
[Train] Epoch: 5 [101760/387873]    Loss: 0.001687   Batch Acc: 91.41
[Train] Epoch: 5 [101888/387873]    Loss: 0.001917   Batch Acc: 89.06
[Train] Epoch: 5 [102016/387873]    Loss: 0.002462   Batch Acc: 85.94
[Train] Epoch: 5 [102144/387873]    Loss: 0.001558   Batch Acc: 94.53
[Train] Epoch: 5 [102272/387873]    Loss: 0.001899   Batch Acc: 90.62
[Train] Epoch: 5 [102400/387873]    Loss: 0.001362   Batch Acc: 91.41
[Train] Epoch: 5 [102528/387873]    Loss: 0.001776   Batch Acc: 91.41
[Train] Epoch: 5 [102656/387873]    Loss: 0.002253   Batch Acc: 87.50
[Train] Epoch: 5 [102784/387873]    Loss: 0.001792   Batch Acc: 91.41
[Train] Epoch: 5 [102912/387873]    Loss: 0.002162   Batch Acc: 89.06
[Train] Epoch: 5 [103040/387873]    Loss: 0.001758   Batch Acc: 90.62
[Train] Epoch: 5 [103168/387873]    Loss: 0.001788   Batch Acc: 92.19
[Train] Epoch: 5 [103296/387873]    Loss: 0.002385   Batch Acc: 88.28
[Train] Epoch: 5 [103424/387873]    Loss: 0.001365   Batch Acc: 95.31
[Train] Epoch: 5 [103552/387873]    Loss: 0.001508   Batch Acc: 92.97
[Train] Epoch: 5 [103680/387873]    Loss: 0.002386   Batch Acc: 85.94
[Train] Epoch: 5 [103808/387873]    Loss: 0.001841   Batch Acc: 92.19
[Train] Epoch: 5 [103936/387873]    Loss: 0.001545   Batch Acc: 95.31
[Train] Epoch: 5 [104064/387873]    Loss: 0.001506   Batch Acc: 91.41
[Train] Epoch: 5 [104192/387873]    Loss: 0.002448   Batch Acc: 85.16
[Train] Epoch: 5 [104320/387873]    Loss: 0.002030   Batch Acc: 89.06
[Train] Epoch: 5 [104448/387873]    Loss: 0.002025   Batch Acc: 88.28
[Train] Epoch: 5 [104576/387873]    Loss: 0.002027   Batch Acc: 87.50
[Train] Epoch: 5 [104704/387873]    Loss: 0.002594   Batch Acc: 86.72
[Train] Epoch: 5 [104832/387873]    Loss: 0.002220   Batch Acc: 86.72
[Train] Epoch: 5 [104960/387873]    Loss: 0.002022   Batch Acc: 89.84
[Train] Epoch: 5 [105088/387873]    Loss: 0.002013   Batch Acc: 89.84
[Train] Epoch: 5 [105216/387873]    Loss: 0.001851   Batch Acc: 89.06
[Train] Epoch: 5 [105344/387873]    Loss: 0.001651   Batch Acc: 89.84
[Train] Epoch: 5 [105472/387873]    Loss: 0.002633   Batch Acc: 83.59
[Train] Epoch: 5 [105600/387873]    Loss: 0.001786   Batch Acc: 92.97
[Train] Epoch: 5 [105728/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 5 [105856/387873]    Loss: 0.002036   Batch Acc: 89.06
[Train] Epoch: 5 [105984/387873]    Loss: 0.001761   Batch Acc: 91.41
[Train] Epoch: 5 [106112/387873]    Loss: 0.001830   Batch Acc: 91.41
[Train] Epoch: 5 [106240/387873]    Loss: 0.002454   Batch Acc: 85.16
[Train] Epoch: 5 [106368/387873]    Loss: 0.002185   Batch Acc: 86.72
[Train] Epoch: 5 [106496/387873]    Loss: 0.001876   Batch Acc: 90.62
[Train] Epoch: 5 [106624/387873]    Loss: 0.001082   Batch Acc: 97.66
[Train] Epoch: 5 [106752/387873]    Loss: 0.002228   Batch Acc: 84.38
[Train] Epoch: 5 [106880/387873]    Loss: 0.002126   Batch Acc: 88.28
[Train] Epoch: 5 [107008/387873]    Loss: 0.002352   Batch Acc: 84.38
[Train] Epoch: 5 [107136/387873]    Loss: 0.002071   Batch Acc: 88.28
[Train] Epoch: 5 [107264/387873]    Loss: 0.001481   Batch Acc: 94.53
[Train] Epoch: 5 [107392/387873]    Loss: 0.001758   Batch Acc: 92.97
[Train] Epoch: 5 [107520/387873]    Loss: 0.001829   Batch Acc: 91.41
[Train] Epoch: 5 [107648/387873]    Loss: 0.002063   Batch Acc: 89.84
[Train] Epoch: 5 [107776/387873]    Loss: 0.002387   Batch Acc: 85.94
[Train] Epoch: 5 [107904/387873]    Loss: 0.002041   Batch Acc: 90.62
[Train] Epoch: 5 [108032/387873]    Loss: 0.001519   Batch Acc: 91.41
[Train] Epoch: 5 [108160/387873]    Loss: 0.001853   Batch Acc: 90.62
[Train] Epoch: 5 [108288/387873]    Loss: 0.002019   Batch Acc: 85.94
[Train] Epoch: 5 [108416/387873]    Loss: 0.002032   Batch Acc: 89.06
[Train] Epoch: 5 [108544/387873]    Loss: 0.001560   Batch Acc: 92.19
[Train] Epoch: 5 [108672/387873]    Loss: 0.002142   Batch Acc: 88.28
[Train] Epoch: 5 [108800/387873]    Loss: 0.001981   Batch Acc: 86.72
[Train] Epoch: 5 [108928/387873]    Loss: 0.001912   Batch Acc: 91.41
[Train] Epoch: 5 [109056/387873]    Loss: 0.002187   Batch Acc: 89.06
[Train] Epoch: 5 [109184/387873]    Loss: 0.001814   Batch Acc: 91.41
[Train] Epoch: 5 [109312/387873]    Loss: 0.002001   Batch Acc: 91.41
[Train] Epoch: 5 [109440/387873]    Loss: 0.001563   Batch Acc: 93.75
[Train] Epoch: 5 [109568/387873]    Loss: 0.001888   Batch Acc: 90.62
[Train] Epoch: 5 [109696/387873]    Loss: 0.002699   Batch Acc: 83.59
[Train] Epoch: 5 [109824/387873]    Loss: 0.001812   Batch Acc: 89.84
[Train] Epoch: 5 [109952/387873]    Loss: 0.001792   Batch Acc: 93.75
[Train] Epoch: 5 [110080/387873]    Loss: 0.001944   Batch Acc: 86.72
[Train] Epoch: 5 [110208/387873]    Loss: 0.001938   Batch Acc: 88.28
[Train] Epoch: 5 [110336/387873]    Loss: 0.002108   Batch Acc: 86.72
[Train] Epoch: 5 [110464/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 5 [110592/387873]    Loss: 0.001622   Batch Acc: 92.19
[Train] Epoch: 5 [110720/387873]    Loss: 0.002278   Batch Acc: 89.84
[Train] Epoch: 5 [110848/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 5 [110976/387873]    Loss: 0.002416   Batch Acc: 86.72
[Train] Epoch: 5 [111104/387873]    Loss: 0.001802   Batch Acc: 91.41
[Train] Epoch: 5 [111232/387873]    Loss: 0.001950   Batch Acc: 88.28
[Train] Epoch: 5 [111360/387873]    Loss: 0.001622   Batch Acc: 96.09
[Train] Epoch: 5 [111488/387873]    Loss: 0.001942   Batch Acc: 89.06
[Train] Epoch: 5 [111616/387873]    Loss: 0.002059   Batch Acc: 89.06
[Train] Epoch: 5 [111744/387873]    Loss: 0.002087   Batch Acc: 89.84
[Train] Epoch: 5 [111872/387873]    Loss: 0.002145   Batch Acc: 90.62
[Train] Epoch: 5 [112000/387873]    Loss: 0.001776   Batch Acc: 92.19
[Train] Epoch: 5 [112128/387873]    Loss: 0.001935   Batch Acc: 92.19
[Train] Epoch: 5 [112256/387873]    Loss: 0.002145   Batch Acc: 89.84
[Train] Epoch: 5 [112384/387873]    Loss: 0.001910   Batch Acc: 93.75
[Train] Epoch: 5 [112512/387873]    Loss: 0.002270   Batch Acc: 84.38
[Train] Epoch: 5 [112640/387873]    Loss: 0.002303   Batch Acc: 88.28
[Train] Epoch: 5 [112768/387873]    Loss: 0.001462   Batch Acc: 93.75
[Train] Epoch: 5 [112896/387873]    Loss: 0.001858   Batch Acc: 90.62
[Train] Epoch: 5 [113024/387873]    Loss: 0.002456   Batch Acc: 85.94
[Train] Epoch: 5 [113152/387873]    Loss: 0.001874   Batch Acc: 89.84
[Train] Epoch: 5 [113280/387873]    Loss: 0.001761   Batch Acc: 91.41
[Train] Epoch: 5 [113408/387873]    Loss: 0.001681   Batch Acc: 92.19
[Train] Epoch: 5 [113536/387873]    Loss: 0.002022   Batch Acc: 88.28
[Train] Epoch: 5 [113664/387873]    Loss: 0.002299   Batch Acc: 89.06
[Train] Epoch: 5 [113792/387873]    Loss: 0.001842   Batch Acc: 89.84
[Train] Epoch: 5 [113920/387873]    Loss: 0.001795   Batch Acc: 89.84
[Train] Epoch: 5 [114048/387873]    Loss: 0.001918   Batch Acc: 89.06
[Train] Epoch: 5 [114176/387873]    Loss: 0.002283   Batch Acc: 89.06
[Train] Epoch: 5 [114304/387873]    Loss: 0.001466   Batch Acc: 93.75
[Train] Epoch: 5 [114432/387873]    Loss: 0.002303   Batch Acc: 85.16
[Train] Epoch: 5 [114560/387873]    Loss: 0.002875   Batch Acc: 86.72
[Train] Epoch: 5 [114688/387873]    Loss: 0.002081   Batch Acc: 89.84
[Train] Epoch: 5 [114816/387873]    Loss: 0.001788   Batch Acc: 92.19
[Train] Epoch: 5 [114944/387873]    Loss: 0.002395   Batch Acc: 85.16
[Train] Epoch: 5 [115072/387873]    Loss: 0.002198   Batch Acc: 87.50
[Train] Epoch: 5 [115200/387873]    Loss: 0.002002   Batch Acc: 89.06
[Train] Epoch: 5 [115328/387873]    Loss: 0.002366   Batch Acc: 86.72
[Train] Epoch: 5 [115456/387873]    Loss: 0.002185   Batch Acc: 85.94
[Train] Epoch: 5 [115584/387873]    Loss: 0.001985   Batch Acc: 89.84
[Train] Epoch: 5 [115712/387873]    Loss: 0.001429   Batch Acc: 94.53
[Train] Epoch: 5 [115840/387873]    Loss: 0.002711   Batch Acc: 81.25
[Train] Epoch: 5 [115968/387873]    Loss: 0.001782   Batch Acc: 89.84
[Train] Epoch: 5 [116096/387873]    Loss: 0.001905   Batch Acc: 86.72
[Train] Epoch: 5 [116224/387873]    Loss: 0.002464   Batch Acc: 89.84
[Train] Epoch: 5 [116352/387873]    Loss: 0.001531   Batch Acc: 92.97
[Train] Epoch: 5 [116480/387873]    Loss: 0.002195   Batch Acc: 86.72
[Train] Epoch: 5 [116608/387873]    Loss: 0.002225   Batch Acc: 86.72
[Train] Epoch: 5 [116736/387873]    Loss: 0.002217   Batch Acc: 89.84
[Train] Epoch: 5 [116864/387873]    Loss: 0.001416   Batch Acc: 93.75
[Train] Epoch: 5 [116992/387873]    Loss: 0.001351   Batch Acc: 93.75
[Train] Epoch: 5 [117120/387873]    Loss: 0.001775   Batch Acc: 88.28
[Train] Epoch: 5 [117248/387873]    Loss: 0.001874   Batch Acc: 89.06
[Train] Epoch: 5 [117376/387873]    Loss: 0.002160   Batch Acc: 87.50
[Train] Epoch: 5 [117504/387873]    Loss: 0.001616   Batch Acc: 92.19
[Train] Epoch: 5 [117632/387873]    Loss: 0.002181   Batch Acc: 87.50
[Train] Epoch: 5 [117760/387873]    Loss: 0.002524   Batch Acc: 85.16
[Train] Epoch: 5 [117888/387873]    Loss: 0.001581   Batch Acc: 92.97
[Train] Epoch: 5 [118016/387873]    Loss: 0.001619   Batch Acc: 92.19
[Train] Epoch: 5 [118144/387873]    Loss: 0.001695   Batch Acc: 89.06
[Train] Epoch: 5 [118272/387873]    Loss: 0.002452   Batch Acc: 84.38
[Train] Epoch: 5 [118400/387873]    Loss: 0.002249   Batch Acc: 86.72
[Train] Epoch: 5 [118528/387873]    Loss: 0.001704   Batch Acc: 92.19
[Train] Epoch: 5 [118656/387873]    Loss: 0.002175   Batch Acc: 89.06
[Train] Epoch: 5 [118784/387873]    Loss: 0.002471   Batch Acc: 82.81
[Train] Epoch: 5 [118912/387873]    Loss: 0.001746   Batch Acc: 89.84
[Train] Epoch: 5 [119040/387873]    Loss: 0.001778   Batch Acc: 91.41
[Train] Epoch: 5 [119168/387873]    Loss: 0.002076   Batch Acc: 89.84
[Train] Epoch: 5 [119296/387873]    Loss: 0.001467   Batch Acc: 92.97
[Train] Epoch: 5 [119424/387873]    Loss: 0.001944   Batch Acc: 89.06
[Train] Epoch: 5 [119552/387873]    Loss: 0.002441   Batch Acc: 82.81
[Train] Epoch: 5 [119680/387873]    Loss: 0.002184   Batch Acc: 88.28
[Train] Epoch: 5 [119808/387873]    Loss: 0.001864   Batch Acc: 90.62
[Train] Epoch: 5 [119936/387873]    Loss: 0.002489   Batch Acc: 85.16
[Train] Epoch: 5 [120064/387873]    Loss: 0.002453   Batch Acc: 87.50
[Train] Epoch: 5 [120192/387873]    Loss: 0.002027   Batch Acc: 89.84
[Train] Epoch: 5 [120320/387873]    Loss: 0.001893   Batch Acc: 88.28
[Train] Epoch: 5 [120448/387873]    Loss: 0.001590   Batch Acc: 92.97
[Train] Epoch: 5 [120576/387873]    Loss: 0.001582   Batch Acc: 92.19
[Train] Epoch: 5 [120704/387873]    Loss: 0.002914   Batch Acc: 82.03
[Train] Epoch: 5 [120832/387873]    Loss: 0.002642   Batch Acc: 88.28
[Train] Epoch: 5 [120960/387873]    Loss: 0.002009   Batch Acc: 92.97
[Train] Epoch: 5 [121088/387873]    Loss: 0.001627   Batch Acc: 92.97
[Train] Epoch: 5 [121216/387873]    Loss: 0.001825   Batch Acc: 94.53
[Train] Epoch: 5 [121344/387873]    Loss: 0.001722   Batch Acc: 91.41
[Train] Epoch: 5 [121472/387873]    Loss: 0.001842   Batch Acc: 89.84
[Train] Epoch: 5 [121600/387873]    Loss: 0.002076   Batch Acc: 89.06
[Train] Epoch: 5 [121728/387873]    Loss: 0.002001   Batch Acc: 91.41
[Train] Epoch: 5 [121856/387873]    Loss: 0.002096   Batch Acc: 88.28
[Train] Epoch: 5 [121984/387873]    Loss: 0.001458   Batch Acc: 92.97
[Train] Epoch: 5 [122112/387873]    Loss: 0.002216   Batch Acc: 83.59
[Train] Epoch: 5 [122240/387873]    Loss: 0.002024   Batch Acc: 85.16
[Train] Epoch: 5 [122368/387873]    Loss: 0.002249   Batch Acc: 88.28
[Train] Epoch: 5 [122496/387873]    Loss: 0.002000   Batch Acc: 89.06
[Train] Epoch: 5 [122624/387873]    Loss: 0.001686   Batch Acc: 91.41
[Train] Epoch: 5 [122752/387873]    Loss: 0.002137   Batch Acc: 89.06
[Train] Epoch: 5 [122880/387873]    Loss: 0.001646   Batch Acc: 92.19
[Train] Epoch: 5 [123008/387873]    Loss: 0.002150   Batch Acc: 91.41
[Train] Epoch: 5 [123136/387873]    Loss: 0.001631   Batch Acc: 91.41
[Train] Epoch: 5 [123264/387873]    Loss: 0.002396   Batch Acc: 84.38
[Train] Epoch: 5 [123392/387873]    Loss: 0.002492   Batch Acc: 85.94
[Train] Epoch: 5 [123520/387873]    Loss: 0.001651   Batch Acc: 90.62
[Train] Epoch: 5 [123648/387873]    Loss: 0.001852   Batch Acc: 92.19
[Train] Epoch: 5 [123776/387873]    Loss: 0.001848   Batch Acc: 89.84
[Train] Epoch: 5 [123904/387873]    Loss: 0.001904   Batch Acc: 85.94
[Train] Epoch: 5 [124032/387873]    Loss: 0.001783   Batch Acc: 90.62
[Train] Epoch: 5 [124160/387873]    Loss: 0.001847   Batch Acc: 91.41
[Train] Epoch: 5 [124288/387873]    Loss: 0.002673   Batch Acc: 83.59
[Train] Epoch: 5 [124416/387873]    Loss: 0.001657   Batch Acc: 89.06
[Train] Epoch: 5 [124544/387873]    Loss: 0.002603   Batch Acc: 84.38
[Train] Epoch: 5 [124672/387873]    Loss: 0.001908   Batch Acc: 89.06
[Train] Epoch: 5 [124800/387873]    Loss: 0.001746   Batch Acc: 89.84
[Train] Epoch: 5 [124928/387873]    Loss: 0.002462   Batch Acc: 85.94
[Train] Epoch: 5 [125056/387873]    Loss: 0.001624   Batch Acc: 89.84
[Train] Epoch: 5 [125184/387873]    Loss: 0.001412   Batch Acc: 93.75
[Train] Epoch: 5 [125312/387873]    Loss: 0.001784   Batch Acc: 91.41
[Train] Epoch: 5 [125440/387873]    Loss: 0.001695   Batch Acc: 92.97
[Train] Epoch: 5 [125568/387873]    Loss: 0.001880   Batch Acc: 89.84
[Train] Epoch: 5 [125696/387873]    Loss: 0.002102   Batch Acc: 89.06
[Train] Epoch: 5 [125824/387873]    Loss: 0.002069   Batch Acc: 88.28
[Train] Epoch: 5 [125952/387873]    Loss: 0.002075   Batch Acc: 89.06
[Train] Epoch: 5 [126080/387873]    Loss: 0.002498   Batch Acc: 88.28
[Train] Epoch: 5 [126208/387873]    Loss: 0.001975   Batch Acc: 93.75
[Train] Epoch: 5 [126336/387873]    Loss: 0.002178   Batch Acc: 88.28
[Train] Epoch: 5 [126464/387873]    Loss: 0.002155   Batch Acc: 87.50
[Train] Epoch: 5 [126592/387873]    Loss: 0.002241   Batch Acc: 89.06
[Train] Epoch: 5 [126720/387873]    Loss: 0.002554   Batch Acc: 85.16
[Train] Epoch: 5 [126848/387873]    Loss: 0.001926   Batch Acc: 88.28
[Train] Epoch: 5 [126976/387873]    Loss: 0.001761   Batch Acc: 91.41
[Train] Epoch: 5 [127104/387873]    Loss: 0.002226   Batch Acc: 85.94
[Train] Epoch: 5 [127232/387873]    Loss: 0.002222   Batch Acc: 89.06
[Train] Epoch: 5 [127360/387873]    Loss: 0.002268   Batch Acc: 88.28
[Train] Epoch: 5 [127488/387873]    Loss: 0.001439   Batch Acc: 93.75
[Train] Epoch: 5 [127616/387873]    Loss: 0.001874   Batch Acc: 88.28
[Train] Epoch: 5 [127744/387873]    Loss: 0.001959   Batch Acc: 89.84
[Train] Epoch: 5 [127872/387873]    Loss: 0.002275   Batch Acc: 89.84
[Train] Epoch: 5 [128000/387873]    Loss: 0.001294   Batch Acc: 95.31
[Train] Epoch: 5 [128128/387873]    Loss: 0.001937   Batch Acc: 92.97
[Train] Epoch: 5 [128256/387873]    Loss: 0.002164   Batch Acc: 89.06
[Train] Epoch: 5 [128384/387873]    Loss: 0.002534   Batch Acc: 85.94
[Train] Epoch: 5 [128512/387873]    Loss: 0.001688   Batch Acc: 89.84
[Train] Epoch: 5 [128640/387873]    Loss: 0.001915   Batch Acc: 87.50
[Train] Epoch: 5 [128768/387873]    Loss: 0.001527   Batch Acc: 94.53
[Train] Epoch: 5 [128896/387873]    Loss: 0.001924   Batch Acc: 89.06
[Train] Epoch: 5 [129024/387873]    Loss: 0.001818   Batch Acc: 93.75
[Train] Epoch: 5 [129152/387873]    Loss: 0.001558   Batch Acc: 93.75
[Train] Epoch: 5 [129280/387873]    Loss: 0.001818   Batch Acc: 89.06
[Train] Epoch: 5 [129408/387873]    Loss: 0.002254   Batch Acc: 87.50
[Train] Epoch: 5 [129536/387873]    Loss: 0.001990   Batch Acc: 85.16
[Train] Epoch: 5 [129664/387873]    Loss: 0.001763   Batch Acc: 90.62
[Train] Epoch: 5 [129792/387873]    Loss: 0.001736   Batch Acc: 93.75
[Train] Epoch: 5 [129920/387873]    Loss: 0.002452   Batch Acc: 89.84
[Train] Epoch: 5 [130048/387873]    Loss: 0.002554   Batch Acc: 85.16
[Train] Epoch: 5 [130176/387873]    Loss: 0.001594   Batch Acc: 93.75
[Train] Epoch: 5 [130304/387873]    Loss: 0.001670   Batch Acc: 93.75
[Train] Epoch: 5 [130432/387873]    Loss: 0.002222   Batch Acc: 89.06
[Train] Epoch: 5 [130560/387873]    Loss: 0.001466   Batch Acc: 92.19
[Train] Epoch: 5 [130688/387873]    Loss: 0.001817   Batch Acc: 89.84
[Train] Epoch: 5 [130816/387873]    Loss: 0.001996   Batch Acc: 90.62
[Train] Epoch: 5 [130944/387873]    Loss: 0.001992   Batch Acc: 91.41
[Train] Epoch: 5 [131072/387873]    Loss: 0.001690   Batch Acc: 92.19
[Train] Epoch: 5 [131200/387873]    Loss: 0.001867   Batch Acc: 89.06
[Train] Epoch: 5 [131328/387873]    Loss: 0.002232   Batch Acc: 86.72
[Train] Epoch: 5 [131456/387873]    Loss: 0.002308   Batch Acc: 86.72
[Train] Epoch: 5 [131584/387873]    Loss: 0.002123   Batch Acc: 87.50
[Train] Epoch: 5 [131712/387873]    Loss: 0.001651   Batch Acc: 90.62
[Train] Epoch: 5 [131840/387873]    Loss: 0.001932   Batch Acc: 87.50
[Train] Epoch: 5 [131968/387873]    Loss: 0.001882   Batch Acc: 89.06
[Train] Epoch: 5 [132096/387873]    Loss: 0.001968   Batch Acc: 88.28
[Train] Epoch: 5 [132224/387873]    Loss: 0.001910   Batch Acc: 89.84
[Train] Epoch: 5 [132352/387873]    Loss: 0.001510   Batch Acc: 91.41
[Train] Epoch: 5 [132480/387873]    Loss: 0.001908   Batch Acc: 87.50
[Train] Epoch: 5 [132608/387873]    Loss: 0.002027   Batch Acc: 87.50
[Train] Epoch: 5 [132736/387873]    Loss: 0.001598   Batch Acc: 91.41
[Train] Epoch: 5 [132864/387873]    Loss: 0.002374   Batch Acc: 86.72
[Train] Epoch: 5 [132992/387873]    Loss: 0.001670   Batch Acc: 90.62
[Train] Epoch: 5 [133120/387873]    Loss: 0.001890   Batch Acc: 89.06
[Train] Epoch: 5 [133248/387873]    Loss: 0.002137   Batch Acc: 87.50
[Train] Epoch: 5 [133376/387873]    Loss: 0.001704   Batch Acc: 92.19
[Train] Epoch: 5 [133504/387873]    Loss: 0.002432   Batch Acc: 85.16
[Train] Epoch: 5 [133632/387873]    Loss: 0.001585   Batch Acc: 94.53
[Train] Epoch: 5 [133760/387873]    Loss: 0.001736   Batch Acc: 93.75
[Train] Epoch: 5 [133888/387873]    Loss: 0.001849   Batch Acc: 92.19
[Train] Epoch: 5 [134016/387873]    Loss: 0.002304   Batch Acc: 85.16
[Train] Epoch: 5 [134144/387873]    Loss: 0.002350   Batch Acc: 83.59
[Train] Epoch: 5 [134272/387873]    Loss: 0.002402   Batch Acc: 85.16
[Train] Epoch: 5 [134400/387873]    Loss: 0.002073   Batch Acc: 89.84
[Train] Epoch: 5 [134528/387873]    Loss: 0.002031   Batch Acc: 88.28
[Train] Epoch: 5 [134656/387873]    Loss: 0.001643   Batch Acc: 92.19
[Train] Epoch: 5 [134784/387873]    Loss: 0.002380   Batch Acc: 85.16
[Train] Epoch: 5 [134912/387873]    Loss: 0.001808   Batch Acc: 92.19
[Train] Epoch: 5 [135040/387873]    Loss: 0.002131   Batch Acc: 89.84
[Train] Epoch: 5 [135168/387873]    Loss: 0.002343   Batch Acc: 88.28
[Train] Epoch: 5 [135296/387873]    Loss: 0.002614   Batch Acc: 83.59
[Train] Epoch: 5 [135424/387873]    Loss: 0.002150   Batch Acc: 89.06
[Train] Epoch: 5 [135552/387873]    Loss: 0.001851   Batch Acc: 92.19
[Train] Epoch: 5 [135680/387873]    Loss: 0.002498   Batch Acc: 85.94
[Train] Epoch: 5 [135808/387873]    Loss: 0.002372   Batch Acc: 85.16
[Train] Epoch: 5 [135936/387873]    Loss: 0.001337   Batch Acc: 92.19
[Train] Epoch: 5 [136064/387873]    Loss: 0.002262   Batch Acc: 88.28
[Train] Epoch: 5 [136192/387873]    Loss: 0.001842   Batch Acc: 89.84
[Train] Epoch: 5 [136320/387873]    Loss: 0.002134   Batch Acc: 88.28
[Train] Epoch: 5 [136448/387873]    Loss: 0.001449   Batch Acc: 93.75
[Train] Epoch: 5 [136576/387873]    Loss: 0.002336   Batch Acc: 87.50
[Train] Epoch: 5 [136704/387873]    Loss: 0.002029   Batch Acc: 92.19
[Train] Epoch: 5 [136832/387873]    Loss: 0.002070   Batch Acc: 89.84
[Train] Epoch: 5 [136960/387873]    Loss: 0.002252   Batch Acc: 89.06
[Train] Epoch: 5 [137088/387873]    Loss: 0.002248   Batch Acc: 86.72
[Train] Epoch: 5 [137216/387873]    Loss: 0.002179   Batch Acc: 87.50
[Train] Epoch: 5 [137344/387873]    Loss: 0.001835   Batch Acc: 89.06
[Train] Epoch: 5 [137472/387873]    Loss: 0.001940   Batch Acc: 89.84
[Train] Epoch: 5 [137600/387873]    Loss: 0.002293   Batch Acc: 93.75
[Train] Epoch: 5 [137728/387873]    Loss: 0.001682   Batch Acc: 94.53
[Train] Epoch: 5 [137856/387873]    Loss: 0.002446   Batch Acc: 86.72
[Train] Epoch: 5 [137984/387873]    Loss: 0.001877   Batch Acc: 90.62
[Train] Epoch: 5 [138112/387873]    Loss: 0.001678   Batch Acc: 92.97
[Train] Epoch: 5 [138240/387873]    Loss: 0.001806   Batch Acc: 91.41
[Train] Epoch: 5 [138368/387873]    Loss: 0.002020   Batch Acc: 90.62
[Train] Epoch: 5 [138496/387873]    Loss: 0.001684   Batch Acc: 92.97
[Train] Epoch: 5 [138624/387873]    Loss: 0.001509   Batch Acc: 92.19
[Train] Epoch: 5 [138752/387873]    Loss: 0.002061   Batch Acc: 89.06
[Train] Epoch: 5 [138880/387873]    Loss: 0.002114   Batch Acc: 86.72
[Train] Epoch: 5 [139008/387873]    Loss: 0.001967   Batch Acc: 90.62
[Train] Epoch: 5 [139136/387873]    Loss: 0.002144   Batch Acc: 89.06
[Train] Epoch: 5 [139264/387873]    Loss: 0.002236   Batch Acc: 89.06
[Train] Epoch: 5 [139392/387873]    Loss: 0.002314   Batch Acc: 86.72
[Train] Epoch: 5 [139520/387873]    Loss: 0.002275   Batch Acc: 88.28
[Train] Epoch: 5 [139648/387873]    Loss: 0.002031   Batch Acc: 90.62
[Train] Epoch: 5 [139776/387873]    Loss: 0.002152   Batch Acc: 87.50
[Train] Epoch: 5 [139904/387873]    Loss: 0.002113   Batch Acc: 88.28
[Train] Epoch: 5 [140032/387873]    Loss: 0.002398   Batch Acc: 84.38
[Train] Epoch: 5 [140160/387873]    Loss: 0.001971   Batch Acc: 90.62
[Train] Epoch: 5 [140288/387873]    Loss: 0.001816   Batch Acc: 89.84
[Train] Epoch: 5 [140416/387873]    Loss: 0.001844   Batch Acc: 90.62
[Train] Epoch: 5 [140544/387873]    Loss: 0.002897   Batch Acc: 79.69
[Train] Epoch: 5 [140672/387873]    Loss: 0.002216   Batch Acc: 88.28
[Train] Epoch: 5 [140800/387873]    Loss: 0.002086   Batch Acc: 87.50
[Train] Epoch: 5 [140928/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 5 [141056/387873]    Loss: 0.001901   Batch Acc: 89.84
[Train] Epoch: 5 [141184/387873]    Loss: 0.002320   Batch Acc: 85.16
[Train] Epoch: 5 [141312/387873]    Loss: 0.001803   Batch Acc: 93.75
[Train] Epoch: 5 [141440/387873]    Loss: 0.002497   Batch Acc: 85.16
[Train] Epoch: 5 [141568/387873]    Loss: 0.002304   Batch Acc: 87.50
[Train] Epoch: 5 [141696/387873]    Loss: 0.002104   Batch Acc: 89.06
[Train] Epoch: 5 [141824/387873]    Loss: 0.002215   Batch Acc: 89.06
[Train] Epoch: 5 [141952/387873]    Loss: 0.001600   Batch Acc: 92.97
[Train] Epoch: 5 [142080/387873]    Loss: 0.001937   Batch Acc: 85.94
[Train] Epoch: 5 [142208/387873]    Loss: 0.001964   Batch Acc: 89.84
[Train] Epoch: 5 [142336/387873]    Loss: 0.002203   Batch Acc: 87.50
[Train] Epoch: 5 [142464/387873]    Loss: 0.002023   Batch Acc: 89.84
[Train] Epoch: 5 [142592/387873]    Loss: 0.002400   Batch Acc: 89.06
[Train] Epoch: 5 [142720/387873]    Loss: 0.002048   Batch Acc: 85.94
[Train] Epoch: 5 [142848/387873]    Loss: 0.002105   Batch Acc: 86.72
[Train] Epoch: 5 [142976/387873]    Loss: 0.001621   Batch Acc: 92.97
[Train] Epoch: 5 [143104/387873]    Loss: 0.001512   Batch Acc: 93.75
[Train] Epoch: 5 [143232/387873]    Loss: 0.001554   Batch Acc: 92.97
[Train] Epoch: 5 [143360/387873]    Loss: 0.001373   Batch Acc: 95.31
[Train] Epoch: 5 [143488/387873]    Loss: 0.002113   Batch Acc: 86.72
[Train] Epoch: 5 [143616/387873]    Loss: 0.001880   Batch Acc: 90.62
[Train] Epoch: 5 [143744/387873]    Loss: 0.002677   Batch Acc: 83.59
[Train] Epoch: 5 [143872/387873]    Loss: 0.001888   Batch Acc: 89.84
[Train] Epoch: 5 [144000/387873]    Loss: 0.002157   Batch Acc: 86.72
[Train] Epoch: 5 [144128/387873]    Loss: 0.002419   Batch Acc: 90.62
[Train] Epoch: 5 [144256/387873]    Loss: 0.001935   Batch Acc: 87.50
[Train] Epoch: 5 [144384/387873]    Loss: 0.001470   Batch Acc: 94.53
[Train] Epoch: 5 [144512/387873]    Loss: 0.001667   Batch Acc: 94.53
[Train] Epoch: 5 [144640/387873]    Loss: 0.001915   Batch Acc: 89.06
[Train] Epoch: 5 [144768/387873]    Loss: 0.001816   Batch Acc: 89.06
[Train] Epoch: 5 [144896/387873]    Loss: 0.001664   Batch Acc: 92.97
[Train] Epoch: 5 [145024/387873]    Loss: 0.002215   Batch Acc: 82.81
[Train] Epoch: 5 [145152/387873]    Loss: 0.002141   Batch Acc: 87.50
[Train] Epoch: 5 [145280/387873]    Loss: 0.002098   Batch Acc: 89.84
[Train] Epoch: 5 [145408/387873]    Loss: 0.001923   Batch Acc: 90.62
[Train] Epoch: 5 [145536/387873]    Loss: 0.001812   Batch Acc: 93.75
[Train] Epoch: 5 [145664/387873]    Loss: 0.001762   Batch Acc: 90.62
[Train] Epoch: 5 [145792/387873]    Loss: 0.001868   Batch Acc: 89.84
[Train] Epoch: 5 [145920/387873]    Loss: 0.002170   Batch Acc: 87.50
[Train] Epoch: 5 [146048/387873]    Loss: 0.001743   Batch Acc: 92.97
[Train] Epoch: 5 [146176/387873]    Loss: 0.001431   Batch Acc: 94.53
[Train] Epoch: 5 [146304/387873]    Loss: 0.001949   Batch Acc: 89.84
[Train] Epoch: 5 [146432/387873]    Loss: 0.001545   Batch Acc: 92.97
[Train] Epoch: 5 [146560/387873]    Loss: 0.002018   Batch Acc: 89.06
[Train] Epoch: 5 [146688/387873]    Loss: 0.002157   Batch Acc: 89.06
[Train] Epoch: 5 [146816/387873]    Loss: 0.001693   Batch Acc: 89.84
[Train] Epoch: 5 [146944/387873]    Loss: 0.002144   Batch Acc: 91.41
[Train] Epoch: 5 [147072/387873]    Loss: 0.001627   Batch Acc: 92.97
[Train] Epoch: 5 [147200/387873]    Loss: 0.002480   Batch Acc: 85.94
[Train] Epoch: 5 [147328/387873]    Loss: 0.001923   Batch Acc: 90.62
[Train] Epoch: 5 [147456/387873]    Loss: 0.002291   Batch Acc: 87.50
[Train] Epoch: 5 [147584/387873]    Loss: 0.001602   Batch Acc: 90.62
[Train] Epoch: 5 [147712/387873]    Loss: 0.001853   Batch Acc: 92.19
[Train] Epoch: 5 [147840/387873]    Loss: 0.002055   Batch Acc: 90.62
[Train] Epoch: 5 [147968/387873]    Loss: 0.002019   Batch Acc: 87.50
[Train] Epoch: 5 [148096/387873]    Loss: 0.002008   Batch Acc: 87.50
[Train] Epoch: 5 [148224/387873]    Loss: 0.001860   Batch Acc: 90.62
[Train] Epoch: 5 [148352/387873]    Loss: 0.001531   Batch Acc: 92.97
[Train] Epoch: 5 [148480/387873]    Loss: 0.001772   Batch Acc: 88.28
[Train] Epoch: 5 [148608/387873]    Loss: 0.002182   Batch Acc: 88.28
[Train] Epoch: 5 [148736/387873]    Loss: 0.002388   Batch Acc: 86.72
[Train] Epoch: 5 [148864/387873]    Loss: 0.001718   Batch Acc: 92.19
[Train] Epoch: 5 [148992/387873]    Loss: 0.002078   Batch Acc: 87.50
[Train] Epoch: 5 [149120/387873]    Loss: 0.002039   Batch Acc: 90.62
[Train] Epoch: 5 [149248/387873]    Loss: 0.002364   Batch Acc: 89.06
[Train] Epoch: 5 [149376/387873]    Loss: 0.001804   Batch Acc: 89.06
[Train] Epoch: 5 [149504/387873]    Loss: 0.001363   Batch Acc: 92.19
[Train] Epoch: 5 [149632/387873]    Loss: 0.001533   Batch Acc: 92.19
[Train] Epoch: 5 [149760/387873]    Loss: 0.001759   Batch Acc: 88.28
[Train] Epoch: 5 [149888/387873]    Loss: 0.001620   Batch Acc: 92.19
[Train] Epoch: 5 [150016/387873]    Loss: 0.001410   Batch Acc: 94.53
[Train] Epoch: 5 [150144/387873]    Loss: 0.002573   Batch Acc: 87.50
[Train] Epoch: 5 [150272/387873]    Loss: 0.001468   Batch Acc: 90.62
[Train] Epoch: 5 [150400/387873]    Loss: 0.001615   Batch Acc: 89.84
[Train] Epoch: 5 [150528/387873]    Loss: 0.001911   Batch Acc: 88.28
[Train] Epoch: 5 [150656/387873]    Loss: 0.002237   Batch Acc: 88.28
[Train] Epoch: 5 [150784/387873]    Loss: 0.002187   Batch Acc: 86.72
[Train] Epoch: 5 [150912/387873]    Loss: 0.001601   Batch Acc: 93.75
[Train] Epoch: 5 [151040/387873]    Loss: 0.002133   Batch Acc: 86.72
[Train] Epoch: 5 [151168/387873]    Loss: 0.002032   Batch Acc: 85.16
[Train] Epoch: 5 [151296/387873]    Loss: 0.001772   Batch Acc: 90.62
[Train] Epoch: 5 [151424/387873]    Loss: 0.001859   Batch Acc: 88.28
[Train] Epoch: 5 [151552/387873]    Loss: 0.001646   Batch Acc: 89.84
[Train] Epoch: 5 [151680/387873]    Loss: 0.001704   Batch Acc: 92.19
[Train] Epoch: 5 [151808/387873]    Loss: 0.001581   Batch Acc: 93.75
[Train] Epoch: 5 [151936/387873]    Loss: 0.001841   Batch Acc: 91.41
[Train] Epoch: 5 [152064/387873]    Loss: 0.002315   Batch Acc: 85.94
[Train] Epoch: 5 [152192/387873]    Loss: 0.002004   Batch Acc: 89.06
[Train] Epoch: 5 [152320/387873]    Loss: 0.001911   Batch Acc: 89.84
[Train] Epoch: 5 [152448/387873]    Loss: 0.001522   Batch Acc: 92.97
[Train] Epoch: 5 [152576/387873]    Loss: 0.002001   Batch Acc: 92.19
[Train] Epoch: 5 [152704/387873]    Loss: 0.001997   Batch Acc: 90.62
[Train] Epoch: 5 [152832/387873]    Loss: 0.002668   Batch Acc: 82.03
[Train] Epoch: 5 [152960/387873]    Loss: 0.001591   Batch Acc: 92.19
[Train] Epoch: 5 [153088/387873]    Loss: 0.001896   Batch Acc: 91.41
[Train] Epoch: 5 [153216/387873]    Loss: 0.001275   Batch Acc: 95.31
[Train] Epoch: 5 [153344/387873]    Loss: 0.001891   Batch Acc: 89.84
[Train] Epoch: 5 [153472/387873]    Loss: 0.001796   Batch Acc: 90.62
[Train] Epoch: 5 [153600/387873]    Loss: 0.002477   Batch Acc: 85.94
[Train] Epoch: 5 [153728/387873]    Loss: 0.002278   Batch Acc: 87.50
[Train] Epoch: 5 [153856/387873]    Loss: 0.001627   Batch Acc: 92.97
[Train] Epoch: 5 [153984/387873]    Loss: 0.001963   Batch Acc: 90.62
[Train] Epoch: 5 [154112/387873]    Loss: 0.002332   Batch Acc: 89.84
[Train] Epoch: 5 [154240/387873]    Loss: 0.001896   Batch Acc: 89.84
[Train] Epoch: 5 [154368/387873]    Loss: 0.002386   Batch Acc: 85.94
[Train] Epoch: 5 [154496/387873]    Loss: 0.002357   Batch Acc: 86.72
[Train] Epoch: 5 [154624/387873]    Loss: 0.002215   Batch Acc: 86.72
[Train] Epoch: 5 [154752/387873]    Loss: 0.001717   Batch Acc: 91.41
[Train] Epoch: 5 [154880/387873]    Loss: 0.001793   Batch Acc: 90.62
[Train] Epoch: 5 [155008/387873]    Loss: 0.001297   Batch Acc: 95.31
[Train] Epoch: 5 [155136/387873]    Loss: 0.000958   Batch Acc: 97.66
[Train] Epoch: 5 [155264/387873]    Loss: 0.002527   Batch Acc: 85.94
[Train] Epoch: 5 [155392/387873]    Loss: 0.001635   Batch Acc: 92.97
[Train] Epoch: 5 [155520/387873]    Loss: 0.001612   Batch Acc: 92.97
[Train] Epoch: 5 [155648/387873]    Loss: 0.002485   Batch Acc: 84.38
[Train] Epoch: 5 [155776/387873]    Loss: 0.001762   Batch Acc: 92.97
[Train] Epoch: 5 [155904/387873]    Loss: 0.002377   Batch Acc: 87.50
[Train] Epoch: 5 [156032/387873]    Loss: 0.002368   Batch Acc: 85.16
[Train] Epoch: 5 [156160/387873]    Loss: 0.002160   Batch Acc: 87.50
[Train] Epoch: 5 [156288/387873]    Loss: 0.001885   Batch Acc: 89.06
[Train] Epoch: 5 [156416/387873]    Loss: 0.001843   Batch Acc: 87.50
[Train] Epoch: 5 [156544/387873]    Loss: 0.002007   Batch Acc: 88.28
[Train] Epoch: 5 [156672/387873]    Loss: 0.002653   Batch Acc: 86.72
[Train] Epoch: 5 [156800/387873]    Loss: 0.002069   Batch Acc: 86.72
[Train] Epoch: 5 [156928/387873]    Loss: 0.002096   Batch Acc: 87.50
[Train] Epoch: 5 [157056/387873]    Loss: 0.002001   Batch Acc: 89.84
[Train] Epoch: 5 [157184/387873]    Loss: 0.001902   Batch Acc: 92.19
[Train] Epoch: 5 [157312/387873]    Loss: 0.001733   Batch Acc: 88.28
[Train] Epoch: 5 [157440/387873]    Loss: 0.002129   Batch Acc: 86.72
[Train] Epoch: 5 [157568/387873]    Loss: 0.001602   Batch Acc: 90.62
[Train] Epoch: 5 [157696/387873]    Loss: 0.001652   Batch Acc: 94.53
[Train] Epoch: 5 [157824/387873]    Loss: 0.001800   Batch Acc: 90.62
[Train] Epoch: 5 [157952/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 5 [158080/387873]    Loss: 0.001635   Batch Acc: 92.97
[Train] Epoch: 5 [158208/387873]    Loss: 0.001747   Batch Acc: 90.62
[Train] Epoch: 5 [158336/387873]    Loss: 0.001804   Batch Acc: 92.19
[Train] Epoch: 5 [158464/387873]    Loss: 0.002711   Batch Acc: 85.94
[Train] Epoch: 5 [158592/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 5 [158720/387873]    Loss: 0.001675   Batch Acc: 92.19
[Train] Epoch: 5 [158848/387873]    Loss: 0.001862   Batch Acc: 89.84
[Train] Epoch: 5 [158976/387873]    Loss: 0.001723   Batch Acc: 92.97
[Train] Epoch: 5 [159104/387873]    Loss: 0.002015   Batch Acc: 89.84
[Train] Epoch: 5 [159232/387873]    Loss: 0.002030   Batch Acc: 86.72
[Train] Epoch: 5 [159360/387873]    Loss: 0.002089   Batch Acc: 89.06
[Train] Epoch: 5 [159488/387873]    Loss: 0.001724   Batch Acc: 92.19
[Train] Epoch: 5 [159616/387873]    Loss: 0.002751   Batch Acc: 85.16
[Train] Epoch: 5 [159744/387873]    Loss: 0.001828   Batch Acc: 92.19
[Train] Epoch: 5 [159872/387873]    Loss: 0.002253   Batch Acc: 88.28
[Train] Epoch: 5 [160000/387873]    Loss: 0.001756   Batch Acc: 91.41
[Train] Epoch: 5 [160128/387873]    Loss: 0.002191   Batch Acc: 85.16
[Train] Epoch: 5 [160256/387873]    Loss: 0.001913   Batch Acc: 89.84
[Train] Epoch: 5 [160384/387873]    Loss: 0.001941   Batch Acc: 88.28
[Train] Epoch: 5 [160512/387873]    Loss: 0.001798   Batch Acc: 90.62
[Train] Epoch: 5 [160640/387873]    Loss: 0.001709   Batch Acc: 91.41
[Train] Epoch: 5 [160768/387873]    Loss: 0.001775   Batch Acc: 89.06
[Train] Epoch: 5 [160896/387873]    Loss: 0.002862   Batch Acc: 82.81
[Train] Epoch: 5 [161024/387873]    Loss: 0.002468   Batch Acc: 84.38
[Train] Epoch: 5 [161152/387873]    Loss: 0.001816   Batch Acc: 91.41
[Train] Epoch: 5 [161280/387873]    Loss: 0.001726   Batch Acc: 91.41
[Train] Epoch: 5 [161408/387873]    Loss: 0.001937   Batch Acc: 92.19
[Train] Epoch: 5 [161536/387873]    Loss: 0.002030   Batch Acc: 89.84
[Train] Epoch: 5 [161664/387873]    Loss: 0.002315   Batch Acc: 85.94
[Train] Epoch: 5 [161792/387873]    Loss: 0.002610   Batch Acc: 83.59
[Train] Epoch: 5 [161920/387873]    Loss: 0.001939   Batch Acc: 87.50
[Train] Epoch: 5 [162048/387873]    Loss: 0.002217   Batch Acc: 88.28
[Train] Epoch: 5 [162176/387873]    Loss: 0.001685   Batch Acc: 94.53
[Train] Epoch: 5 [162304/387873]    Loss: 0.001828   Batch Acc: 92.19
[Train] Epoch: 5 [162432/387873]    Loss: 0.001962   Batch Acc: 91.41
[Train] Epoch: 5 [162560/387873]    Loss: 0.002555   Batch Acc: 82.03
[Train] Epoch: 5 [162688/387873]    Loss: 0.001630   Batch Acc: 92.97
[Train] Epoch: 5 [162816/387873]    Loss: 0.002275   Batch Acc: 89.06
[Train] Epoch: 5 [162944/387873]    Loss: 0.002191   Batch Acc: 88.28
[Train] Epoch: 5 [163072/387873]    Loss: 0.002225   Batch Acc: 88.28
[Train] Epoch: 5 [163200/387873]    Loss: 0.001810   Batch Acc: 92.19
[Train] Epoch: 5 [163328/387873]    Loss: 0.001918   Batch Acc: 89.84
[Train] Epoch: 5 [163456/387873]    Loss: 0.001880   Batch Acc: 90.62
[Train] Epoch: 5 [163584/387873]    Loss: 0.001530   Batch Acc: 93.75
[Train] Epoch: 5 [163712/387873]    Loss: 0.001841   Batch Acc: 92.19
[Train] Epoch: 5 [163840/387873]    Loss: 0.001495   Batch Acc: 92.19
[Train] Epoch: 5 [163968/387873]    Loss: 0.002077   Batch Acc: 89.84
[Train] Epoch: 5 [164096/387873]    Loss: 0.002558   Batch Acc: 85.94
[Train] Epoch: 5 [164224/387873]    Loss: 0.001898   Batch Acc: 91.41
[Train] Epoch: 5 [164352/387873]    Loss: 0.002435   Batch Acc: 87.50
[Train] Epoch: 5 [164480/387873]    Loss: 0.002336   Batch Acc: 88.28
[Train] Epoch: 5 [164608/387873]    Loss: 0.002568   Batch Acc: 86.72
[Train] Epoch: 5 [164736/387873]    Loss: 0.002592   Batch Acc: 85.94
[Train] Epoch: 5 [164864/387873]    Loss: 0.002158   Batch Acc: 86.72
[Train] Epoch: 5 [164992/387873]    Loss: 0.001933   Batch Acc: 88.28
[Train] Epoch: 5 [165120/387873]    Loss: 0.002155   Batch Acc: 87.50
[Train] Epoch: 5 [165248/387873]    Loss: 0.001819   Batch Acc: 92.19
[Train] Epoch: 5 [165376/387873]    Loss: 0.001710   Batch Acc: 91.41
[Train] Epoch: 5 [165504/387873]    Loss: 0.001611   Batch Acc: 88.28
[Train] Epoch: 5 [165632/387873]    Loss: 0.001547   Batch Acc: 90.62
[Train] Epoch: 5 [165760/387873]    Loss: 0.001833   Batch Acc: 90.62
[Train] Epoch: 5 [165888/387873]    Loss: 0.002110   Batch Acc: 89.84
[Train] Epoch: 5 [166016/387873]    Loss: 0.002095   Batch Acc: 87.50
[Train] Epoch: 5 [166144/387873]    Loss: 0.002423   Batch Acc: 85.94
[Train] Epoch: 5 [166272/387873]    Loss: 0.002414   Batch Acc: 89.06
[Train] Epoch: 5 [166400/387873]    Loss: 0.001792   Batch Acc: 92.19
[Train] Epoch: 5 [166528/387873]    Loss: 0.001533   Batch Acc: 91.41
[Train] Epoch: 5 [166656/387873]    Loss: 0.002132   Batch Acc: 88.28
[Train] Epoch: 5 [166784/387873]    Loss: 0.002227   Batch Acc: 90.62
[Train] Epoch: 5 [166912/387873]    Loss: 0.001643   Batch Acc: 90.62
[Train] Epoch: 5 [167040/387873]    Loss: 0.002118   Batch Acc: 89.06
[Train] Epoch: 5 [167168/387873]    Loss: 0.001492   Batch Acc: 94.53
[Train] Epoch: 5 [167296/387873]    Loss: 0.001702   Batch Acc: 92.97
[Train] Epoch: 5 [167424/387873]    Loss: 0.002298   Batch Acc: 87.50
[Train] Epoch: 5 [167552/387873]    Loss: 0.001992   Batch Acc: 89.06
[Train] Epoch: 5 [167680/387873]    Loss: 0.001791   Batch Acc: 91.41
[Train] Epoch: 5 [167808/387873]    Loss: 0.002295   Batch Acc: 85.94
[Train] Epoch: 5 [167936/387873]    Loss: 0.002111   Batch Acc: 88.28
[Train] Epoch: 5 [168064/387873]    Loss: 0.002908   Batch Acc: 85.94
[Train] Epoch: 5 [168192/387873]    Loss: 0.002600   Batch Acc: 85.94
[Train] Epoch: 5 [168320/387873]    Loss: 0.002013   Batch Acc: 89.06
[Train] Epoch: 5 [168448/387873]    Loss: 0.002059   Batch Acc: 87.50
[Train] Epoch: 5 [168576/387873]    Loss: 0.002038   Batch Acc: 86.72
[Train] Epoch: 5 [168704/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 5 [168832/387873]    Loss: 0.002136   Batch Acc: 85.94
[Train] Epoch: 5 [168960/387873]    Loss: 0.002103   Batch Acc: 89.84
[Train] Epoch: 5 [169088/387873]    Loss: 0.002255   Batch Acc: 85.16
[Train] Epoch: 5 [169216/387873]    Loss: 0.001661   Batch Acc: 92.97
[Train] Epoch: 5 [169344/387873]    Loss: 0.002023   Batch Acc: 89.84
[Train] Epoch: 5 [169472/387873]    Loss: 0.002025   Batch Acc: 87.50
[Train] Epoch: 5 [169600/387873]    Loss: 0.002117   Batch Acc: 89.84
[Train] Epoch: 5 [169728/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 5 [169856/387873]    Loss: 0.002377   Batch Acc: 88.28
[Train] Epoch: 5 [169984/387873]    Loss: 0.002133   Batch Acc: 88.28
[Train] Epoch: 5 [170112/387873]    Loss: 0.001788   Batch Acc: 89.84
[Train] Epoch: 5 [170240/387873]    Loss: 0.002341   Batch Acc: 87.50
[Train] Epoch: 5 [170368/387873]    Loss: 0.001561   Batch Acc: 92.19
[Train] Epoch: 5 [170496/387873]    Loss: 0.001771   Batch Acc: 89.84
[Train] Epoch: 5 [170624/387873]    Loss: 0.002029   Batch Acc: 89.84
[Train] Epoch: 5 [170752/387873]    Loss: 0.002110   Batch Acc: 86.72
[Train] Epoch: 5 [170880/387873]    Loss: 0.002103   Batch Acc: 89.06
[Train] Epoch: 5 [171008/387873]    Loss: 0.002271   Batch Acc: 88.28
[Train] Epoch: 5 [171136/387873]    Loss: 0.002004   Batch Acc: 89.84
[Train] Epoch: 5 [171264/387873]    Loss: 0.002140   Batch Acc: 87.50
[Train] Epoch: 5 [171392/387873]    Loss: 0.002068   Batch Acc: 89.06
[Train] Epoch: 5 [171520/387873]    Loss: 0.001695   Batch Acc: 94.53
[Train] Epoch: 5 [171648/387873]    Loss: 0.002216   Batch Acc: 89.06
[Train] Epoch: 5 [171776/387873]    Loss: 0.002206   Batch Acc: 89.06
[Train] Epoch: 5 [171904/387873]    Loss: 0.001669   Batch Acc: 92.19
[Train] Epoch: 5 [172032/387873]    Loss: 0.001374   Batch Acc: 93.75
[Train] Epoch: 5 [172160/387873]    Loss: 0.002163   Batch Acc: 84.38
[Train] Epoch: 5 [172288/387873]    Loss: 0.001888   Batch Acc: 89.84
[Train] Epoch: 5 [172416/387873]    Loss: 0.002257   Batch Acc: 90.62
[Train] Epoch: 5 [172544/387873]    Loss: 0.001950   Batch Acc: 86.72
[Train] Epoch: 5 [172672/387873]    Loss: 0.001747   Batch Acc: 92.19
[Train] Epoch: 5 [172800/387873]    Loss: 0.002212   Batch Acc: 88.28
[Train] Epoch: 5 [172928/387873]    Loss: 0.001739   Batch Acc: 92.19
[Train] Epoch: 5 [173056/387873]    Loss: 0.001626   Batch Acc: 93.75
[Train] Epoch: 5 [173184/387873]    Loss: 0.002175   Batch Acc: 88.28
[Train] Epoch: 5 [173312/387873]    Loss: 0.002213   Batch Acc: 87.50
[Train] Epoch: 5 [173440/387873]    Loss: 0.002219   Batch Acc: 87.50
[Train] Epoch: 5 [173568/387873]    Loss: 0.001597   Batch Acc: 93.75
[Train] Epoch: 5 [173696/387873]    Loss: 0.002594   Batch Acc: 89.06
[Train] Epoch: 5 [173824/387873]    Loss: 0.001879   Batch Acc: 89.06
[Train] Epoch: 5 [173952/387873]    Loss: 0.001865   Batch Acc: 89.06
[Train] Epoch: 5 [174080/387873]    Loss: 0.001964   Batch Acc: 92.19
[Train] Epoch: 5 [174208/387873]    Loss: 0.001948   Batch Acc: 89.84
[Train] Epoch: 5 [174336/387873]    Loss: 0.002334   Batch Acc: 85.94
[Train] Epoch: 5 [174464/387873]    Loss: 0.001691   Batch Acc: 90.62
[Train] Epoch: 5 [174592/387873]    Loss: 0.002007   Batch Acc: 89.06
[Train] Epoch: 5 [174720/387873]    Loss: 0.002439   Batch Acc: 88.28
[Train] Epoch: 5 [174848/387873]    Loss: 0.001905   Batch Acc: 91.41
[Train] Epoch: 5 [174976/387873]    Loss: 0.001720   Batch Acc: 91.41
[Train] Epoch: 5 [175104/387873]    Loss: 0.001976   Batch Acc: 92.19
[Train] Epoch: 5 [175232/387873]    Loss: 0.001944   Batch Acc: 88.28
[Train] Epoch: 5 [175360/387873]    Loss: 0.002351   Batch Acc: 85.16
[Train] Epoch: 5 [175488/387873]    Loss: 0.001972   Batch Acc: 91.41
[Train] Epoch: 5 [175616/387873]    Loss: 0.001915   Batch Acc: 91.41
[Train] Epoch: 5 [175744/387873]    Loss: 0.001982   Batch Acc: 92.97
[Train] Epoch: 5 [175872/387873]    Loss: 0.001472   Batch Acc: 93.75
[Train] Epoch: 5 [176000/387873]    Loss: 0.002595   Batch Acc: 86.72
[Train] Epoch: 5 [176128/387873]    Loss: 0.001812   Batch Acc: 91.41
[Train] Epoch: 5 [176256/387873]    Loss: 0.001917   Batch Acc: 88.28
[Train] Epoch: 5 [176384/387873]    Loss: 0.001695   Batch Acc: 89.84
[Train] Epoch: 5 [176512/387873]    Loss: 0.002135   Batch Acc: 89.84
[Train] Epoch: 5 [176640/387873]    Loss: 0.002884   Batch Acc: 83.59
[Train] Epoch: 5 [176768/387873]    Loss: 0.002663   Batch Acc: 82.81
[Train] Epoch: 5 [176896/387873]    Loss: 0.002062   Batch Acc: 90.62
[Train] Epoch: 5 [177024/387873]    Loss: 0.002656   Batch Acc: 86.72
[Train] Epoch: 5 [177152/387873]    Loss: 0.001897   Batch Acc: 90.62
[Train] Epoch: 5 [177280/387873]    Loss: 0.001946   Batch Acc: 88.28
[Train] Epoch: 5 [177408/387873]    Loss: 0.001850   Batch Acc: 91.41
[Train] Epoch: 5 [177536/387873]    Loss: 0.001938   Batch Acc: 92.19
[Train] Epoch: 5 [177664/387873]    Loss: 0.002005   Batch Acc: 88.28
[Train] Epoch: 5 [177792/387873]    Loss: 0.002003   Batch Acc: 89.06
[Train] Epoch: 5 [177920/387873]    Loss: 0.001571   Batch Acc: 91.41
[Train] Epoch: 5 [178048/387873]    Loss: 0.001761   Batch Acc: 89.84
[Train] Epoch: 5 [178176/387873]    Loss: 0.002169   Batch Acc: 89.06
[Train] Epoch: 5 [178304/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 5 [178432/387873]    Loss: 0.001796   Batch Acc: 91.41
[Train] Epoch: 5 [178560/387873]    Loss: 0.001848   Batch Acc: 89.84
[Train] Epoch: 5 [178688/387873]    Loss: 0.001955   Batch Acc: 90.62
[Train] Epoch: 5 [178816/387873]    Loss: 0.002175   Batch Acc: 92.19
[Train] Epoch: 5 [178944/387873]    Loss: 0.002452   Batch Acc: 85.16
[Train] Epoch: 5 [179072/387873]    Loss: 0.002072   Batch Acc: 90.62
[Train] Epoch: 5 [179200/387873]    Loss: 0.001347   Batch Acc: 94.53
[Train] Epoch: 5 [179328/387873]    Loss: 0.001771   Batch Acc: 91.41
[Train] Epoch: 5 [179456/387873]    Loss: 0.002748   Batch Acc: 85.16
[Train] Epoch: 5 [179584/387873]    Loss: 0.001892   Batch Acc: 89.06
[Train] Epoch: 5 [179712/387873]    Loss: 0.001429   Batch Acc: 93.75
[Train] Epoch: 5 [179840/387873]    Loss: 0.001874   Batch Acc: 90.62
[Train] Epoch: 5 [179968/387873]    Loss: 0.001883   Batch Acc: 90.62
[Train] Epoch: 5 [180096/387873]    Loss: 0.002274   Batch Acc: 88.28
[Train] Epoch: 5 [180224/387873]    Loss: 0.002028   Batch Acc: 85.94
[Train] Epoch: 5 [180352/387873]    Loss: 0.002210   Batch Acc: 88.28
[Train] Epoch: 5 [180480/387873]    Loss: 0.001946   Batch Acc: 88.28
[Train] Epoch: 5 [180608/387873]    Loss: 0.002338   Batch Acc: 87.50
[Train] Epoch: 5 [180736/387873]    Loss: 0.002023   Batch Acc: 88.28
[Train] Epoch: 5 [180864/387873]    Loss: 0.002107   Batch Acc: 90.62
[Train] Epoch: 5 [180992/387873]    Loss: 0.001862   Batch Acc: 91.41
[Train] Epoch: 5 [181120/387873]    Loss: 0.001895   Batch Acc: 89.84
[Train] Epoch: 5 [181248/387873]    Loss: 0.001859   Batch Acc: 91.41
[Train] Epoch: 5 [181376/387873]    Loss: 0.001889   Batch Acc: 88.28
[Train] Epoch: 5 [181504/387873]    Loss: 0.002083   Batch Acc: 89.06
[Train] Epoch: 5 [181632/387873]    Loss: 0.002015   Batch Acc: 86.72
[Train] Epoch: 5 [181760/387873]    Loss: 0.001804   Batch Acc: 89.84
[Train] Epoch: 5 [181888/387873]    Loss: 0.002334   Batch Acc: 87.50
[Train] Epoch: 5 [182016/387873]    Loss: 0.001733   Batch Acc: 91.41
[Train] Epoch: 5 [182144/387873]    Loss: 0.002072   Batch Acc: 89.84
[Train] Epoch: 5 [182272/387873]    Loss: 0.001789   Batch Acc: 92.19
[Train] Epoch: 5 [182400/387873]    Loss: 0.001838   Batch Acc: 88.28
[Train] Epoch: 5 [182528/387873]    Loss: 0.001733   Batch Acc: 88.28
[Train] Epoch: 5 [182656/387873]    Loss: 0.001736   Batch Acc: 90.62
[Train] Epoch: 5 [182784/387873]    Loss: 0.002033   Batch Acc: 86.72
[Train] Epoch: 5 [182912/387873]    Loss: 0.001742   Batch Acc: 88.28
[Train] Epoch: 5 [183040/387873]    Loss: 0.002308   Batch Acc: 88.28
[Train] Epoch: 5 [183168/387873]    Loss: 0.002750   Batch Acc: 83.59
[Train] Epoch: 5 [183296/387873]    Loss: 0.001804   Batch Acc: 93.75
[Train] Epoch: 5 [183424/387873]    Loss: 0.001928   Batch Acc: 89.84
[Train] Epoch: 5 [183552/387873]    Loss: 0.002018   Batch Acc: 86.72
[Train] Epoch: 5 [183680/387873]    Loss: 0.002536   Batch Acc: 86.72
[Train] Epoch: 5 [183808/387873]    Loss: 0.001927   Batch Acc: 89.84
[Train] Epoch: 5 [183936/387873]    Loss: 0.001785   Batch Acc: 92.97
[Train] Epoch: 5 [184064/387873]    Loss: 0.002333   Batch Acc: 86.72
[Train] Epoch: 5 [184192/387873]    Loss: 0.002272   Batch Acc: 87.50
[Train] Epoch: 5 [184320/387873]    Loss: 0.001727   Batch Acc: 89.06
[Train] Epoch: 5 [184448/387873]    Loss: 0.002208   Batch Acc: 87.50
[Train] Epoch: 5 [184576/387873]    Loss: 0.001990   Batch Acc: 88.28
[Train] Epoch: 5 [184704/387873]    Loss: 0.001836   Batch Acc: 93.75
[Train] Epoch: 5 [184832/387873]    Loss: 0.002324   Batch Acc: 84.38
[Train] Epoch: 5 [184960/387873]    Loss: 0.001938   Batch Acc: 89.06
[Train] Epoch: 5 [185088/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 5 [185216/387873]    Loss: 0.002009   Batch Acc: 86.72
[Train] Epoch: 5 [185344/387873]    Loss: 0.002324   Batch Acc: 86.72
[Train] Epoch: 5 [185472/387873]    Loss: 0.002333   Batch Acc: 86.72
[Train] Epoch: 5 [185600/387873]    Loss: 0.002025   Batch Acc: 89.06
[Train] Epoch: 5 [185728/387873]    Loss: 0.001980   Batch Acc: 88.28
[Train] Epoch: 5 [185856/387873]    Loss: 0.001632   Batch Acc: 92.19
[Train] Epoch: 5 [185984/387873]    Loss: 0.001779   Batch Acc: 92.19
[Train] Epoch: 5 [186112/387873]    Loss: 0.001990   Batch Acc: 91.41
[Train] Epoch: 5 [186240/387873]    Loss: 0.002338   Batch Acc: 85.94
[Train] Epoch: 5 [186368/387873]    Loss: 0.002059   Batch Acc: 89.06
[Train] Epoch: 5 [186496/387873]    Loss: 0.001608   Batch Acc: 92.19
[Train] Epoch: 5 [186624/387873]    Loss: 0.001926   Batch Acc: 89.84
[Train] Epoch: 5 [186752/387873]    Loss: 0.002229   Batch Acc: 85.16
[Train] Epoch: 5 [186880/387873]    Loss: 0.001883   Batch Acc: 89.84
[Train] Epoch: 5 [187008/387873]    Loss: 0.002469   Batch Acc: 83.59
[Train] Epoch: 5 [187136/387873]    Loss: 0.001635   Batch Acc: 94.53
[Train] Epoch: 5 [187264/387873]    Loss: 0.002372   Batch Acc: 88.28
[Train] Epoch: 5 [187392/387873]    Loss: 0.001890   Batch Acc: 88.28
[Train] Epoch: 5 [187520/387873]    Loss: 0.002185   Batch Acc: 87.50
[Train] Epoch: 5 [187648/387873]    Loss: 0.001811   Batch Acc: 92.19
[Train] Epoch: 5 [187776/387873]    Loss: 0.001774   Batch Acc: 93.75
[Train] Epoch: 5 [187904/387873]    Loss: 0.001958   Batch Acc: 89.06
[Train] Epoch: 5 [188032/387873]    Loss: 0.001847   Batch Acc: 89.84
[Train] Epoch: 5 [188160/387873]    Loss: 0.002019   Batch Acc: 94.53
[Train] Epoch: 5 [188288/387873]    Loss: 0.001905   Batch Acc: 88.28
[Train] Epoch: 5 [188416/387873]    Loss: 0.002035   Batch Acc: 89.06
[Train] Epoch: 5 [188544/387873]    Loss: 0.001445   Batch Acc: 95.31
[Train] Epoch: 5 [188672/387873]    Loss: 0.002144   Batch Acc: 87.50
[Train] Epoch: 5 [188800/387873]    Loss: 0.001649   Batch Acc: 93.75
[Train] Epoch: 5 [188928/387873]    Loss: 0.002200   Batch Acc: 89.06
[Train] Epoch: 5 [189056/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 5 [189184/387873]    Loss: 0.001953   Batch Acc: 89.06
[Train] Epoch: 5 [189312/387873]    Loss: 0.001870   Batch Acc: 94.53
[Train] Epoch: 5 [189440/387873]    Loss: 0.002301   Batch Acc: 87.50
[Train] Epoch: 5 [189568/387873]    Loss: 0.001690   Batch Acc: 92.97
[Train] Epoch: 5 [189696/387873]    Loss: 0.001593   Batch Acc: 92.19
[Train] Epoch: 5 [189824/387873]    Loss: 0.002343   Batch Acc: 89.06
[Train] Epoch: 5 [189952/387873]    Loss: 0.001625   Batch Acc: 92.19
[Train] Epoch: 5 [190080/387873]    Loss: 0.002252   Batch Acc: 86.72
[Train] Epoch: 5 [190208/387873]    Loss: 0.001660   Batch Acc: 91.41
[Train] Epoch: 5 [190336/387873]    Loss: 0.001900   Batch Acc: 92.19
[Train] Epoch: 5 [190464/387873]    Loss: 0.001497   Batch Acc: 92.19
[Train] Epoch: 5 [190592/387873]    Loss: 0.001804   Batch Acc: 91.41
[Train] Epoch: 5 [190720/387873]    Loss: 0.002112   Batch Acc: 86.72
[Train] Epoch: 5 [190848/387873]    Loss: 0.002127   Batch Acc: 89.06
[Train] Epoch: 5 [190976/387873]    Loss: 0.001907   Batch Acc: 87.50
[Train] Epoch: 5 [191104/387873]    Loss: 0.001582   Batch Acc: 93.75
[Train] Epoch: 5 [191232/387873]    Loss: 0.001980   Batch Acc: 88.28
[Train] Epoch: 5 [191360/387873]    Loss: 0.001781   Batch Acc: 87.50
[Train] Epoch: 5 [191488/387873]    Loss: 0.002093   Batch Acc: 85.16
[Train] Epoch: 5 [191616/387873]    Loss: 0.001868   Batch Acc: 93.75
[Train] Epoch: 5 [191744/387873]    Loss: 0.001819   Batch Acc: 92.19
[Train] Epoch: 5 [191872/387873]    Loss: 0.001701   Batch Acc: 91.41
[Train] Epoch: 5 [192000/387873]    Loss: 0.002079   Batch Acc: 87.50
[Train] Epoch: 5 [192128/387873]    Loss: 0.001505   Batch Acc: 94.53
[Train] Epoch: 5 [192256/387873]    Loss: 0.002008   Batch Acc: 89.06
[Train] Epoch: 5 [192384/387873]    Loss: 0.002357   Batch Acc: 88.28
[Train] Epoch: 5 [192512/387873]    Loss: 0.002150   Batch Acc: 87.50
[Train] Epoch: 5 [192640/387873]    Loss: 0.001704   Batch Acc: 90.62
[Train] Epoch: 5 [192768/387873]    Loss: 0.002370   Batch Acc: 86.72
[Train] Epoch: 5 [192896/387873]    Loss: 0.002137   Batch Acc: 89.06
[Train] Epoch: 5 [193024/387873]    Loss: 0.002351   Batch Acc: 89.06
[Train] Epoch: 5 [193152/387873]    Loss: 0.002160   Batch Acc: 89.06
[Train] Epoch: 5 [193280/387873]    Loss: 0.001935   Batch Acc: 90.62
[Train] Epoch: 5 [193408/387873]    Loss: 0.002264   Batch Acc: 87.50
[Train] Epoch: 5 [193536/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 5 [193664/387873]    Loss: 0.001823   Batch Acc: 90.62
[Train] Epoch: 5 [193792/387873]    Loss: 0.002274   Batch Acc: 85.16
[Train] Epoch: 5 [193920/387873]    Loss: 0.001794   Batch Acc: 89.84
[Train] Epoch: 5 [194048/387873]    Loss: 0.002217   Batch Acc: 85.94
[Train] Epoch: 5 [194176/387873]    Loss: 0.001829   Batch Acc: 89.84
[Train] Epoch: 5 [194304/387873]    Loss: 0.001463   Batch Acc: 94.53
[Train] Epoch: 5 [194432/387873]    Loss: 0.001671   Batch Acc: 92.19
[Train] Epoch: 5 [194560/387873]    Loss: 0.001942   Batch Acc: 90.62
[Train] Epoch: 5 [194688/387873]    Loss: 0.001883   Batch Acc: 93.75
[Train] Epoch: 5 [194816/387873]    Loss: 0.002254   Batch Acc: 86.72
[Train] Epoch: 5 [194944/387873]    Loss: 0.001658   Batch Acc: 92.97
[Train] Epoch: 5 [195072/387873]    Loss: 0.001983   Batch Acc: 89.84
[Train] Epoch: 5 [195200/387873]    Loss: 0.002033   Batch Acc: 92.19
[Train] Epoch: 5 [195328/387873]    Loss: 0.001874   Batch Acc: 91.41
[Train] Epoch: 5 [195456/387873]    Loss: 0.001962   Batch Acc: 89.84
[Train] Epoch: 5 [195584/387873]    Loss: 0.001918   Batch Acc: 90.62
[Train] Epoch: 5 [195712/387873]    Loss: 0.002353   Batch Acc: 86.72
[Train] Epoch: 5 [195840/387873]    Loss: 0.001669   Batch Acc: 92.97
[Train] Epoch: 5 [195968/387873]    Loss: 0.001866   Batch Acc: 89.84
[Train] Epoch: 5 [196096/387873]    Loss: 0.001617   Batch Acc: 93.75
[Train] Epoch: 5 [196224/387873]    Loss: 0.001781   Batch Acc: 92.97
[Train] Epoch: 5 [196352/387873]    Loss: 0.001964   Batch Acc: 88.28
[Train] Epoch: 5 [196480/387873]    Loss: 0.001775   Batch Acc: 92.19
[Train] Epoch: 5 [196608/387873]    Loss: 0.002055   Batch Acc: 86.72
[Train] Epoch: 5 [196736/387873]    Loss: 0.002132   Batch Acc: 89.06
[Train] Epoch: 5 [196864/387873]    Loss: 0.002357   Batch Acc: 87.50
[Train] Epoch: 5 [196992/387873]    Loss: 0.001841   Batch Acc: 91.41
[Train] Epoch: 5 [197120/387873]    Loss: 0.002016   Batch Acc: 89.84
[Train] Epoch: 5 [197248/387873]    Loss: 0.001860   Batch Acc: 92.19
[Train] Epoch: 5 [197376/387873]    Loss: 0.001814   Batch Acc: 89.06
[Train] Epoch: 5 [197504/387873]    Loss: 0.001912   Batch Acc: 90.62
[Train] Epoch: 5 [197632/387873]    Loss: 0.001940   Batch Acc: 91.41
[Train] Epoch: 5 [197760/387873]    Loss: 0.001938   Batch Acc: 86.72
[Train] Epoch: 5 [197888/387873]    Loss: 0.001940   Batch Acc: 85.16
[Train] Epoch: 5 [198016/387873]    Loss: 0.001520   Batch Acc: 92.97
[Train] Epoch: 5 [198144/387873]    Loss: 0.001988   Batch Acc: 92.19
[Train] Epoch: 5 [198272/387873]    Loss: 0.001918   Batch Acc: 89.84
[Train] Epoch: 5 [198400/387873]    Loss: 0.002361   Batch Acc: 89.06
[Train] Epoch: 5 [198528/387873]    Loss: 0.001712   Batch Acc: 90.62
[Train] Epoch: 5 [198656/387873]    Loss: 0.001748   Batch Acc: 92.19
[Train] Epoch: 5 [198784/387873]    Loss: 0.001959   Batch Acc: 92.19
[Train] Epoch: 5 [198912/387873]    Loss: 0.001880   Batch Acc: 89.84
[Train] Epoch: 5 [199040/387873]    Loss: 0.001813   Batch Acc: 92.97
[Train] Epoch: 5 [199168/387873]    Loss: 0.001905   Batch Acc: 89.84
[Train] Epoch: 5 [199296/387873]    Loss: 0.001637   Batch Acc: 90.62
[Train] Epoch: 5 [199424/387873]    Loss: 0.001739   Batch Acc: 92.97
[Train] Epoch: 5 [199552/387873]    Loss: 0.001668   Batch Acc: 89.84
[Train] Epoch: 5 [199680/387873]    Loss: 0.002099   Batch Acc: 88.28
[Train] Epoch: 5 [199808/387873]    Loss: 0.002057   Batch Acc: 89.06
[Train] Epoch: 5 [199936/387873]    Loss: 0.002153   Batch Acc: 89.84
[Train] Epoch: 5 [200064/387873]    Loss: 0.002325   Batch Acc: 87.50
[Train] Epoch: 5 [200192/387873]    Loss: 0.002306   Batch Acc: 89.06
[Train] Epoch: 5 [200320/387873]    Loss: 0.002228   Batch Acc: 87.50
[Train] Epoch: 5 [200448/387873]    Loss: 0.001815   Batch Acc: 92.19
[Train] Epoch: 5 [200576/387873]    Loss: 0.001831   Batch Acc: 91.41
[Train] Epoch: 5 [200704/387873]    Loss: 0.001862   Batch Acc: 89.06
[Train] Epoch: 5 [200832/387873]    Loss: 0.002639   Batch Acc: 82.81
[Train] Epoch: 5 [200960/387873]    Loss: 0.001954   Batch Acc: 88.28
[Train] Epoch: 5 [201088/387873]    Loss: 0.001642   Batch Acc: 92.19
[Train] Epoch: 5 [201216/387873]    Loss: 0.002065   Batch Acc: 87.50
[Train] Epoch: 5 [201344/387873]    Loss: 0.002165   Batch Acc: 88.28
[Train] Epoch: 5 [201472/387873]    Loss: 0.002056   Batch Acc: 88.28
[Train] Epoch: 5 [201600/387873]    Loss: 0.001767   Batch Acc: 89.06
[Train] Epoch: 5 [201728/387873]    Loss: 0.001961   Batch Acc: 89.06
[Train] Epoch: 5 [201856/387873]    Loss: 0.001733   Batch Acc: 93.75
[Train] Epoch: 5 [201984/387873]    Loss: 0.002001   Batch Acc: 89.06
[Train] Epoch: 5 [202112/387873]    Loss: 0.001709   Batch Acc: 92.19
[Train] Epoch: 5 [202240/387873]    Loss: 0.001987   Batch Acc: 91.41
[Train] Epoch: 5 [202368/387873]    Loss: 0.001784   Batch Acc: 91.41
[Train] Epoch: 5 [202496/387873]    Loss: 0.002231   Batch Acc: 89.84
[Train] Epoch: 5 [202624/387873]    Loss: 0.001770   Batch Acc: 91.41
[Train] Epoch: 5 [202752/387873]    Loss: 0.002908   Batch Acc: 83.59
[Train] Epoch: 5 [202880/387873]    Loss: 0.001898   Batch Acc: 89.84
[Train] Epoch: 5 [203008/387873]    Loss: 0.001410   Batch Acc: 94.53
[Train] Epoch: 5 [203136/387873]    Loss: 0.001612   Batch Acc: 92.19
[Train] Epoch: 5 [203264/387873]    Loss: 0.002121   Batch Acc: 89.84
[Train] Epoch: 5 [203392/387873]    Loss: 0.002111   Batch Acc: 89.84
[Train] Epoch: 5 [203520/387873]    Loss: 0.001807   Batch Acc: 90.62
[Train] Epoch: 5 [203648/387873]    Loss: 0.001807   Batch Acc: 91.41
[Train] Epoch: 5 [203776/387873]    Loss: 0.001618   Batch Acc: 91.41
[Train] Epoch: 5 [203904/387873]    Loss: 0.002359   Batch Acc: 86.72
[Train] Epoch: 5 [204032/387873]    Loss: 0.002085   Batch Acc: 92.97
[Train] Epoch: 5 [204160/387873]    Loss: 0.002200   Batch Acc: 89.84
[Train] Epoch: 5 [204288/387873]    Loss: 0.001832   Batch Acc: 89.06
[Train] Epoch: 5 [204416/387873]    Loss: 0.002135   Batch Acc: 85.16
[Train] Epoch: 5 [204544/387873]    Loss: 0.002041   Batch Acc: 86.72
[Train] Epoch: 5 [204672/387873]    Loss: 0.001439   Batch Acc: 93.75
[Train] Epoch: 5 [204800/387873]    Loss: 0.002309   Batch Acc: 89.06
[Train] Epoch: 5 [204928/387873]    Loss: 0.002020   Batch Acc: 91.41
[Train] Epoch: 5 [205056/387873]    Loss: 0.002477   Batch Acc: 88.28
[Train] Epoch: 5 [205184/387873]    Loss: 0.001660   Batch Acc: 91.41
[Train] Epoch: 5 [205312/387873]    Loss: 0.001912   Batch Acc: 89.06
[Train] Epoch: 5 [205440/387873]    Loss: 0.001911   Batch Acc: 89.84
[Train] Epoch: 5 [205568/387873]    Loss: 0.001641   Batch Acc: 92.19
[Train] Epoch: 5 [205696/387873]    Loss: 0.001745   Batch Acc: 90.62
[Train] Epoch: 5 [205824/387873]    Loss: 0.002057   Batch Acc: 86.72
[Train] Epoch: 5 [205952/387873]    Loss: 0.001921   Batch Acc: 89.06
[Train] Epoch: 5 [206080/387873]    Loss: 0.001844   Batch Acc: 89.84
[Train] Epoch: 5 [206208/387873]    Loss: 0.002148   Batch Acc: 88.28
[Train] Epoch: 5 [206336/387873]    Loss: 0.001717   Batch Acc: 90.62
[Train] Epoch: 5 [206464/387873]    Loss: 0.001967   Batch Acc: 89.84
[Train] Epoch: 5 [206592/387873]    Loss: 0.002584   Batch Acc: 85.94
[Train] Epoch: 5 [206720/387873]    Loss: 0.001954   Batch Acc: 92.19
[Train] Epoch: 5 [206848/387873]    Loss: 0.001919   Batch Acc: 87.50
[Train] Epoch: 5 [206976/387873]    Loss: 0.001924   Batch Acc: 90.62
[Train] Epoch: 5 [207104/387873]    Loss: 0.002268   Batch Acc: 86.72
[Train] Epoch: 5 [207232/387873]    Loss: 0.001801   Batch Acc: 90.62
[Train] Epoch: 5 [207360/387873]    Loss: 0.002457   Batch Acc: 85.94
[Train] Epoch: 5 [207488/387873]    Loss: 0.002229   Batch Acc: 88.28
[Train] Epoch: 5 [207616/387873]    Loss: 0.001790   Batch Acc: 92.19
[Train] Epoch: 5 [207744/387873]    Loss: 0.001655   Batch Acc: 92.19
[Train] Epoch: 5 [207872/387873]    Loss: 0.001997   Batch Acc: 89.84
[Train] Epoch: 5 [208000/387873]    Loss: 0.001785   Batch Acc: 90.62
[Train] Epoch: 5 [208128/387873]    Loss: 0.002058   Batch Acc: 87.50
[Train] Epoch: 5 [208256/387873]    Loss: 0.002259   Batch Acc: 86.72
[Train] Epoch: 5 [208384/387873]    Loss: 0.001634   Batch Acc: 92.19
[Train] Epoch: 5 [208512/387873]    Loss: 0.001972   Batch Acc: 89.06
[Train] Epoch: 5 [208640/387873]    Loss: 0.002274   Batch Acc: 89.06
[Train] Epoch: 5 [208768/387873]    Loss: 0.002046   Batch Acc: 88.28
[Train] Epoch: 5 [208896/387873]    Loss: 0.002113   Batch Acc: 88.28
[Train] Epoch: 5 [209024/387873]    Loss: 0.002053   Batch Acc: 89.84
[Train] Epoch: 5 [209152/387873]    Loss: 0.002037   Batch Acc: 91.41
[Train] Epoch: 5 [209280/387873]    Loss: 0.001933   Batch Acc: 91.41
[Train] Epoch: 5 [209408/387873]    Loss: 0.002015   Batch Acc: 90.62
[Train] Epoch: 5 [209536/387873]    Loss: 0.002044   Batch Acc: 91.41
[Train] Epoch: 5 [209664/387873]    Loss: 0.001457   Batch Acc: 91.41
[Train] Epoch: 5 [209792/387873]    Loss: 0.001792   Batch Acc: 89.06
[Train] Epoch: 5 [209920/387873]    Loss: 0.001883   Batch Acc: 89.06
[Train] Epoch: 5 [210048/387873]    Loss: 0.002662   Batch Acc: 85.16
[Train] Epoch: 5 [210176/387873]    Loss: 0.002846   Batch Acc: 83.59
[Train] Epoch: 5 [210304/387873]    Loss: 0.002085   Batch Acc: 92.19
[Train] Epoch: 5 [210432/387873]    Loss: 0.001907   Batch Acc: 93.75
[Train] Epoch: 5 [210560/387873]    Loss: 0.001898   Batch Acc: 89.84
[Train] Epoch: 5 [210688/387873]    Loss: 0.001644   Batch Acc: 95.31
[Train] Epoch: 5 [210816/387873]    Loss: 0.002371   Batch Acc: 87.50
[Train] Epoch: 5 [210944/387873]    Loss: 0.002146   Batch Acc: 84.38
[Train] Epoch: 5 [211072/387873]    Loss: 0.001467   Batch Acc: 93.75
[Train] Epoch: 5 [211200/387873]    Loss: 0.002152   Batch Acc: 89.84
[Train] Epoch: 5 [211328/387873]    Loss: 0.001892   Batch Acc: 89.84
[Train] Epoch: 5 [211456/387873]    Loss: 0.002189   Batch Acc: 88.28
[Train] Epoch: 5 [211584/387873]    Loss: 0.001419   Batch Acc: 92.97
[Train] Epoch: 5 [211712/387873]    Loss: 0.001991   Batch Acc: 85.94
[Train] Epoch: 5 [211840/387873]    Loss: 0.001763   Batch Acc: 92.19
[Train] Epoch: 5 [211968/387873]    Loss: 0.002637   Batch Acc: 86.72
[Train] Epoch: 5 [212096/387873]    Loss: 0.001900   Batch Acc: 89.06
[Train] Epoch: 5 [212224/387873]    Loss: 0.001932   Batch Acc: 89.06
[Train] Epoch: 5 [212352/387873]    Loss: 0.002144   Batch Acc: 87.50
[Train] Epoch: 5 [212480/387873]    Loss: 0.001805   Batch Acc: 87.50
[Train] Epoch: 5 [212608/387873]    Loss: 0.002165   Batch Acc: 91.41
[Train] Epoch: 5 [212736/387873]    Loss: 0.002143   Batch Acc: 89.06
[Train] Epoch: 5 [212864/387873]    Loss: 0.002280   Batch Acc: 85.94
[Train] Epoch: 5 [212992/387873]    Loss: 0.002111   Batch Acc: 90.62
[Train] Epoch: 5 [213120/387873]    Loss: 0.002108   Batch Acc: 89.84
[Train] Epoch: 5 [213248/387873]    Loss: 0.002332   Batch Acc: 85.94
[Train] Epoch: 5 [213376/387873]    Loss: 0.001925   Batch Acc: 91.41
[Train] Epoch: 5 [213504/387873]    Loss: 0.002175   Batch Acc: 85.94
[Train] Epoch: 5 [213632/387873]    Loss: 0.001727   Batch Acc: 89.84
[Train] Epoch: 5 [213760/387873]    Loss: 0.002305   Batch Acc: 88.28
[Train] Epoch: 5 [213888/387873]    Loss: 0.002054   Batch Acc: 89.84
[Train] Epoch: 5 [214016/387873]    Loss: 0.001474   Batch Acc: 92.97
[Train] Epoch: 5 [214144/387873]    Loss: 0.002251   Batch Acc: 87.50
[Train] Epoch: 5 [214272/387873]    Loss: 0.001954   Batch Acc: 90.62
[Train] Epoch: 5 [214400/387873]    Loss: 0.001785   Batch Acc: 89.84
[Train] Epoch: 5 [214528/387873]    Loss: 0.002279   Batch Acc: 88.28
[Train] Epoch: 5 [214656/387873]    Loss: 0.002386   Batch Acc: 85.94
[Train] Epoch: 5 [214784/387873]    Loss: 0.002960   Batch Acc: 82.81
[Train] Epoch: 5 [214912/387873]    Loss: 0.001870   Batch Acc: 91.41
[Train] Epoch: 5 [215040/387873]    Loss: 0.002068   Batch Acc: 89.06
[Train] Epoch: 5 [215168/387873]    Loss: 0.001971   Batch Acc: 88.28
[Train] Epoch: 5 [215296/387873]    Loss: 0.001496   Batch Acc: 92.97
[Train] Epoch: 5 [215424/387873]    Loss: 0.002035   Batch Acc: 88.28
[Train] Epoch: 5 [215552/387873]    Loss: 0.002070   Batch Acc: 91.41
[Train] Epoch: 5 [215680/387873]    Loss: 0.001656   Batch Acc: 90.62
[Train] Epoch: 5 [215808/387873]    Loss: 0.001916   Batch Acc: 88.28
[Train] Epoch: 5 [215936/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 5 [216064/387873]    Loss: 0.001751   Batch Acc: 91.41
[Train] Epoch: 5 [216192/387873]    Loss: 0.002004   Batch Acc: 89.06
[Train] Epoch: 5 [216320/387873]    Loss: 0.001813   Batch Acc: 92.19
[Train] Epoch: 5 [216448/387873]    Loss: 0.001694   Batch Acc: 93.75
[Train] Epoch: 5 [216576/387873]    Loss: 0.002132   Batch Acc: 89.84
[Train] Epoch: 5 [216704/387873]    Loss: 0.002489   Batch Acc: 86.72
[Train] Epoch: 5 [216832/387873]    Loss: 0.002295   Batch Acc: 86.72
[Train] Epoch: 5 [216960/387873]    Loss: 0.002170   Batch Acc: 89.84
[Train] Epoch: 5 [217088/387873]    Loss: 0.002008   Batch Acc: 88.28
[Train] Epoch: 5 [217216/387873]    Loss: 0.002268   Batch Acc: 85.16
[Train] Epoch: 5 [217344/387873]    Loss: 0.001810   Batch Acc: 89.06
[Train] Epoch: 5 [217472/387873]    Loss: 0.001918   Batch Acc: 87.50
[Train] Epoch: 5 [217600/387873]    Loss: 0.001888   Batch Acc: 89.06
[Train] Epoch: 5 [217728/387873]    Loss: 0.001749   Batch Acc: 89.84
[Train] Epoch: 5 [217856/387873]    Loss: 0.002015   Batch Acc: 89.84
[Train] Epoch: 5 [217984/387873]    Loss: 0.002047   Batch Acc: 88.28
[Train] Epoch: 5 [218112/387873]    Loss: 0.001861   Batch Acc: 89.84
[Train] Epoch: 5 [218240/387873]    Loss: 0.001766   Batch Acc: 92.19
[Train] Epoch: 5 [218368/387873]    Loss: 0.002037   Batch Acc: 90.62
[Train] Epoch: 5 [218496/387873]    Loss: 0.002327   Batch Acc: 88.28
[Train] Epoch: 5 [218624/387873]    Loss: 0.001795   Batch Acc: 89.84
[Train] Epoch: 5 [218752/387873]    Loss: 0.001997   Batch Acc: 89.06
[Train] Epoch: 5 [218880/387873]    Loss: 0.001827   Batch Acc: 88.28
[Train] Epoch: 5 [219008/387873]    Loss: 0.002047   Batch Acc: 89.06
[Train] Epoch: 5 [219136/387873]    Loss: 0.002396   Batch Acc: 87.50
[Train] Epoch: 5 [219264/387873]    Loss: 0.002723   Batch Acc: 81.25
[Train] Epoch: 5 [219392/387873]    Loss: 0.002460   Batch Acc: 84.38
[Train] Epoch: 5 [219520/387873]    Loss: 0.001362   Batch Acc: 93.75
[Train] Epoch: 5 [219648/387873]    Loss: 0.002256   Batch Acc: 89.06
[Train] Epoch: 5 [219776/387873]    Loss: 0.001524   Batch Acc: 92.19
[Train] Epoch: 5 [219904/387873]    Loss: 0.001582   Batch Acc: 94.53
[Train] Epoch: 5 [220032/387873]    Loss: 0.002110   Batch Acc: 89.06
[Train] Epoch: 5 [220160/387873]    Loss: 0.001731   Batch Acc: 89.84
[Train] Epoch: 5 [220288/387873]    Loss: 0.001756   Batch Acc: 90.62
[Train] Epoch: 5 [220416/387873]    Loss: 0.001936   Batch Acc: 89.84
[Train] Epoch: 5 [220544/387873]    Loss: 0.001508   Batch Acc: 92.19
[Train] Epoch: 5 [220672/387873]    Loss: 0.001780   Batch Acc: 91.41
[Train] Epoch: 5 [220800/387873]    Loss: 0.001741   Batch Acc: 89.06
[Train] Epoch: 5 [220928/387873]    Loss: 0.001917   Batch Acc: 90.62
[Train] Epoch: 5 [221056/387873]    Loss: 0.001734   Batch Acc: 92.19
[Train] Epoch: 5 [221184/387873]    Loss: 0.001968   Batch Acc: 90.62
[Train] Epoch: 5 [221312/387873]    Loss: 0.001616   Batch Acc: 92.19
[Train] Epoch: 5 [221440/387873]    Loss: 0.002547   Batch Acc: 89.06
[Train] Epoch: 5 [221568/387873]    Loss: 0.001696   Batch Acc: 91.41
[Train] Epoch: 5 [221696/387873]    Loss: 0.001729   Batch Acc: 91.41
[Train] Epoch: 5 [221824/387873]    Loss: 0.002059   Batch Acc: 89.06
[Train] Epoch: 5 [221952/387873]    Loss: 0.002585   Batch Acc: 84.38
[Train] Epoch: 5 [222080/387873]    Loss: 0.001819   Batch Acc: 91.41
[Train] Epoch: 5 [222208/387873]    Loss: 0.001310   Batch Acc: 95.31
[Train] Epoch: 5 [222336/387873]    Loss: 0.002825   Batch Acc: 85.16
[Train] Epoch: 5 [222464/387873]    Loss: 0.001523   Batch Acc: 93.75
[Train] Epoch: 5 [222592/387873]    Loss: 0.002075   Batch Acc: 88.28
[Train] Epoch: 5 [222720/387873]    Loss: 0.002055   Batch Acc: 88.28
[Train] Epoch: 5 [222848/387873]    Loss: 0.002060   Batch Acc: 88.28
[Train] Epoch: 5 [222976/387873]    Loss: 0.001709   Batch Acc: 89.84
[Train] Epoch: 5 [223104/387873]    Loss: 0.001870   Batch Acc: 89.84
[Train] Epoch: 5 [223232/387873]    Loss: 0.001647   Batch Acc: 92.19
[Train] Epoch: 5 [223360/387873]    Loss: 0.002525   Batch Acc: 88.28
[Train] Epoch: 5 [223488/387873]    Loss: 0.002405   Batch Acc: 86.72
[Train] Epoch: 5 [223616/387873]    Loss: 0.002181   Batch Acc: 89.06
[Train] Epoch: 5 [223744/387873]    Loss: 0.001439   Batch Acc: 94.53
[Train] Epoch: 5 [223872/387873]    Loss: 0.001796   Batch Acc: 89.84
[Train] Epoch: 5 [224000/387873]    Loss: 0.003139   Batch Acc: 80.47
[Train] Epoch: 5 [224128/387873]    Loss: 0.002087   Batch Acc: 87.50
[Train] Epoch: 5 [224256/387873]    Loss: 0.001812   Batch Acc: 92.19
[Train] Epoch: 5 [224384/387873]    Loss: 0.001677   Batch Acc: 91.41
[Train] Epoch: 5 [224512/387873]    Loss: 0.001599   Batch Acc: 90.62
[Train] Epoch: 5 [224640/387873]    Loss: 0.001752   Batch Acc: 88.28
[Train] Epoch: 5 [224768/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 5 [224896/387873]    Loss: 0.002273   Batch Acc: 88.28
[Train] Epoch: 5 [225024/387873]    Loss: 0.002384   Batch Acc: 86.72
[Train] Epoch: 5 [225152/387873]    Loss: 0.002467   Batch Acc: 85.94
[Train] Epoch: 5 [225280/387873]    Loss: 0.002384   Batch Acc: 89.84
[Train] Epoch: 5 [225408/387873]    Loss: 0.001451   Batch Acc: 96.09
[Train] Epoch: 5 [225536/387873]    Loss: 0.002249   Batch Acc: 86.72
[Train] Epoch: 5 [225664/387873]    Loss: 0.002061   Batch Acc: 87.50
[Train] Epoch: 5 [225792/387873]    Loss: 0.002542   Batch Acc: 86.72
[Train] Epoch: 5 [225920/387873]    Loss: 0.002163   Batch Acc: 85.94
[Train] Epoch: 5 [226048/387873]    Loss: 0.001979   Batch Acc: 90.62
[Train] Epoch: 5 [226176/387873]    Loss: 0.002410   Batch Acc: 88.28
[Train] Epoch: 5 [226304/387873]    Loss: 0.001847   Batch Acc: 90.62
[Train] Epoch: 5 [226432/387873]    Loss: 0.002444   Batch Acc: 84.38
[Train] Epoch: 5 [226560/387873]    Loss: 0.001880   Batch Acc: 89.84
[Train] Epoch: 5 [226688/387873]    Loss: 0.002007   Batch Acc: 90.62
[Train] Epoch: 5 [226816/387873]    Loss: 0.002015   Batch Acc: 91.41
[Train] Epoch: 5 [226944/387873]    Loss: 0.001356   Batch Acc: 94.53
[Train] Epoch: 5 [227072/387873]    Loss: 0.002217   Batch Acc: 85.16
[Train] Epoch: 5 [227200/387873]    Loss: 0.002456   Batch Acc: 87.50
[Train] Epoch: 5 [227328/387873]    Loss: 0.002158   Batch Acc: 89.06
[Train] Epoch: 5 [227456/387873]    Loss: 0.002402   Batch Acc: 85.16
[Train] Epoch: 5 [227584/387873]    Loss: 0.002070   Batch Acc: 86.72
[Train] Epoch: 5 [227712/387873]    Loss: 0.001684   Batch Acc: 91.41
[Train] Epoch: 5 [227840/387873]    Loss: 0.002112   Batch Acc: 88.28
[Train] Epoch: 5 [227968/387873]    Loss: 0.001972   Batch Acc: 92.97
[Train] Epoch: 5 [228096/387873]    Loss: 0.001939   Batch Acc: 86.72
[Train] Epoch: 5 [228224/387873]    Loss: 0.002017   Batch Acc: 89.06
[Train] Epoch: 5 [228352/387873]    Loss: 0.001957   Batch Acc: 88.28
[Train] Epoch: 5 [228480/387873]    Loss: 0.002643   Batch Acc: 84.38
[Train] Epoch: 5 [228608/387873]    Loss: 0.001762   Batch Acc: 91.41
[Train] Epoch: 5 [228736/387873]    Loss: 0.001658   Batch Acc: 91.41
[Train] Epoch: 5 [228864/387873]    Loss: 0.002102   Batch Acc: 86.72
[Train] Epoch: 5 [228992/387873]    Loss: 0.001822   Batch Acc: 91.41
[Train] Epoch: 5 [229120/387873]    Loss: 0.002353   Batch Acc: 87.50
[Train] Epoch: 5 [229248/387873]    Loss: 0.001829   Batch Acc: 92.97
[Train] Epoch: 5 [229376/387873]    Loss: 0.002428   Batch Acc: 88.28
[Train] Epoch: 5 [229504/387873]    Loss: 0.001540   Batch Acc: 92.97
[Train] Epoch: 5 [229632/387873]    Loss: 0.001995   Batch Acc: 89.84
[Train] Epoch: 5 [229760/387873]    Loss: 0.001698   Batch Acc: 91.41
[Train] Epoch: 5 [229888/387873]    Loss: 0.002186   Batch Acc: 89.84
[Train] Epoch: 5 [230016/387873]    Loss: 0.002155   Batch Acc: 91.41
[Train] Epoch: 5 [230144/387873]    Loss: 0.001753   Batch Acc: 94.53
[Train] Epoch: 5 [230272/387873]    Loss: 0.002539   Batch Acc: 83.59
[Train] Epoch: 5 [230400/387873]    Loss: 0.002038   Batch Acc: 87.50
[Train] Epoch: 5 [230528/387873]    Loss: 0.002605   Batch Acc: 85.94
[Train] Epoch: 5 [230656/387873]    Loss: 0.001937   Batch Acc: 88.28
[Train] Epoch: 5 [230784/387873]    Loss: 0.001855   Batch Acc: 87.50
[Train] Epoch: 5 [230912/387873]    Loss: 0.001676   Batch Acc: 91.41
[Train] Epoch: 5 [231040/387873]    Loss: 0.002028   Batch Acc: 87.50
[Train] Epoch: 5 [231168/387873]    Loss: 0.001987   Batch Acc: 89.06
[Train] Epoch: 5 [231296/387873]    Loss: 0.002053   Batch Acc: 86.72
[Train] Epoch: 5 [231424/387873]    Loss: 0.002258   Batch Acc: 87.50
[Train] Epoch: 5 [231552/387873]    Loss: 0.001691   Batch Acc: 92.19
[Train] Epoch: 5 [231680/387873]    Loss: 0.001507   Batch Acc: 96.09
[Train] Epoch: 5 [231808/387873]    Loss: 0.001730   Batch Acc: 92.97
[Train] Epoch: 5 [231936/387873]    Loss: 0.001983   Batch Acc: 89.06
[Train] Epoch: 5 [232064/387873]    Loss: 0.001552   Batch Acc: 92.19
[Train] Epoch: 5 [232192/387873]    Loss: 0.002159   Batch Acc: 92.19
[Train] Epoch: 5 [232320/387873]    Loss: 0.002013   Batch Acc: 89.06
[Train] Epoch: 5 [232448/387873]    Loss: 0.001944   Batch Acc: 92.19
[Train] Epoch: 5 [232576/387873]    Loss: 0.002032   Batch Acc: 88.28
[Train] Epoch: 5 [232704/387873]    Loss: 0.002232   Batch Acc: 89.84
[Train] Epoch: 5 [232832/387873]    Loss: 0.001641   Batch Acc: 92.97
[Train] Epoch: 5 [232960/387873]    Loss: 0.002147   Batch Acc: 87.50
[Train] Epoch: 5 [233088/387873]    Loss: 0.002159   Batch Acc: 86.72
[Train] Epoch: 5 [233216/387873]    Loss: 0.001750   Batch Acc: 91.41
[Train] Epoch: 5 [233344/387873]    Loss: 0.001864   Batch Acc: 89.84
[Train] Epoch: 5 [233472/387873]    Loss: 0.001976   Batch Acc: 87.50
[Train] Epoch: 5 [233600/387873]    Loss: 0.001670   Batch Acc: 91.41
[Train] Epoch: 5 [233728/387873]    Loss: 0.002243   Batch Acc: 86.72
[Train] Epoch: 5 [233856/387873]    Loss: 0.001957   Batch Acc: 89.06
[Train] Epoch: 5 [233984/387873]    Loss: 0.001884   Batch Acc: 90.62
[Train] Epoch: 5 [234112/387873]    Loss: 0.001913   Batch Acc: 89.06
[Train] Epoch: 5 [234240/387873]    Loss: 0.001947   Batch Acc: 88.28
[Train] Epoch: 5 [234368/387873]    Loss: 0.002044   Batch Acc: 89.06
[Train] Epoch: 5 [234496/387873]    Loss: 0.002792   Batch Acc: 84.38
[Train] Epoch: 5 [234624/387873]    Loss: 0.001496   Batch Acc: 92.19
[Train] Epoch: 5 [234752/387873]    Loss: 0.001657   Batch Acc: 92.97
[Train] Epoch: 5 [234880/387873]    Loss: 0.001507   Batch Acc: 92.97
[Train] Epoch: 5 [235008/387873]    Loss: 0.001910   Batch Acc: 89.06
[Train] Epoch: 5 [235136/387873]    Loss: 0.002084   Batch Acc: 89.06
[Train] Epoch: 5 [235264/387873]    Loss: 0.002271   Batch Acc: 89.06
[Train] Epoch: 5 [235392/387873]    Loss: 0.001776   Batch Acc: 90.62
[Train] Epoch: 5 [235520/387873]    Loss: 0.002381   Batch Acc: 88.28
[Train] Epoch: 5 [235648/387873]    Loss: 0.001565   Batch Acc: 92.19
[Train] Epoch: 5 [235776/387873]    Loss: 0.001901   Batch Acc: 89.06
[Train] Epoch: 5 [235904/387873]    Loss: 0.002602   Batch Acc: 84.38
[Train] Epoch: 5 [236032/387873]    Loss: 0.001857   Batch Acc: 90.62
[Train] Epoch: 5 [236160/387873]    Loss: 0.002165   Batch Acc: 91.41
[Train] Epoch: 5 [236288/387873]    Loss: 0.002720   Batch Acc: 83.59
[Train] Epoch: 5 [236416/387873]    Loss: 0.001916   Batch Acc: 89.84
[Train] Epoch: 5 [236544/387873]    Loss: 0.001525   Batch Acc: 92.97
[Train] Epoch: 5 [236672/387873]    Loss: 0.001873   Batch Acc: 92.19
[Train] Epoch: 5 [236800/387873]    Loss: 0.001646   Batch Acc: 90.62
[Train] Epoch: 5 [236928/387873]    Loss: 0.001838   Batch Acc: 91.41
[Train] Epoch: 5 [237056/387873]    Loss: 0.002265   Batch Acc: 88.28
[Train] Epoch: 5 [237184/387873]    Loss: 0.002313   Batch Acc: 83.59
[Train] Epoch: 5 [237312/387873]    Loss: 0.001750   Batch Acc: 92.97
[Train] Epoch: 5 [237440/387873]    Loss: 0.001741   Batch Acc: 92.19
[Train] Epoch: 5 [237568/387873]    Loss: 0.002478   Batch Acc: 87.50
[Train] Epoch: 5 [237696/387873]    Loss: 0.002358   Batch Acc: 85.16
[Train] Epoch: 5 [237824/387873]    Loss: 0.002208   Batch Acc: 89.84
[Train] Epoch: 5 [237952/387873]    Loss: 0.002100   Batch Acc: 89.06
[Train] Epoch: 5 [238080/387873]    Loss: 0.001920   Batch Acc: 90.62
[Train] Epoch: 5 [238208/387873]    Loss: 0.001496   Batch Acc: 93.75
[Train] Epoch: 5 [238336/387873]    Loss: 0.002266   Batch Acc: 89.06
[Train] Epoch: 5 [238464/387873]    Loss: 0.001992   Batch Acc: 86.72
[Train] Epoch: 5 [238592/387873]    Loss: 0.002200   Batch Acc: 89.06
[Train] Epoch: 5 [238720/387873]    Loss: 0.001484   Batch Acc: 93.75
[Train] Epoch: 5 [238848/387873]    Loss: 0.001917   Batch Acc: 89.84
[Train] Epoch: 5 [238976/387873]    Loss: 0.001610   Batch Acc: 92.97
[Train] Epoch: 5 [239104/387873]    Loss: 0.001429   Batch Acc: 92.97
[Train] Epoch: 5 [239232/387873]    Loss: 0.001254   Batch Acc: 94.53
[Train] Epoch: 5 [239360/387873]    Loss: 0.001620   Batch Acc: 91.41
[Train] Epoch: 5 [239488/387873]    Loss: 0.002096   Batch Acc: 89.84
[Train] Epoch: 5 [239616/387873]    Loss: 0.002016   Batch Acc: 89.06
[Train] Epoch: 5 [239744/387873]    Loss: 0.002243   Batch Acc: 87.50
[Train] Epoch: 5 [239872/387873]    Loss: 0.001949   Batch Acc: 88.28
[Train] Epoch: 5 [240000/387873]    Loss: 0.001657   Batch Acc: 92.19
[Train] Epoch: 5 [240128/387873]    Loss: 0.001877   Batch Acc: 91.41
[Train] Epoch: 5 [240256/387873]    Loss: 0.002204   Batch Acc: 89.84
[Train] Epoch: 5 [240384/387873]    Loss: 0.002180   Batch Acc: 89.06
[Train] Epoch: 5 [240512/387873]    Loss: 0.001911   Batch Acc: 87.50
[Train] Epoch: 5 [240640/387873]    Loss: 0.001838   Batch Acc: 89.84
[Train] Epoch: 5 [240768/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 5 [240896/387873]    Loss: 0.001791   Batch Acc: 92.19
[Train] Epoch: 5 [241024/387873]    Loss: 0.001893   Batch Acc: 89.06
[Train] Epoch: 5 [241152/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 5 [241280/387873]    Loss: 0.001495   Batch Acc: 90.62
[Train] Epoch: 5 [241408/387873]    Loss: 0.001982   Batch Acc: 88.28
[Train] Epoch: 5 [241536/387873]    Loss: 0.001712   Batch Acc: 93.75
[Train] Epoch: 5 [241664/387873]    Loss: 0.001707   Batch Acc: 90.62
[Train] Epoch: 5 [241792/387873]    Loss: 0.001578   Batch Acc: 93.75
[Train] Epoch: 5 [241920/387873]    Loss: 0.001716   Batch Acc: 89.06
[Train] Epoch: 5 [242048/387873]    Loss: 0.002096   Batch Acc: 90.62
[Train] Epoch: 5 [242176/387873]    Loss: 0.001880   Batch Acc: 89.84
[Train] Epoch: 5 [242304/387873]    Loss: 0.001724   Batch Acc: 92.19
[Train] Epoch: 5 [242432/387873]    Loss: 0.001915   Batch Acc: 89.84
[Train] Epoch: 5 [242560/387873]    Loss: 0.001913   Batch Acc: 92.19
[Train] Epoch: 5 [242688/387873]    Loss: 0.001529   Batch Acc: 92.97
[Train] Epoch: 5 [242816/387873]    Loss: 0.001818   Batch Acc: 90.62
[Train] Epoch: 5 [242944/387873]    Loss: 0.001896   Batch Acc: 88.28
[Train] Epoch: 5 [243072/387873]    Loss: 0.001750   Batch Acc: 92.19
[Train] Epoch: 5 [243200/387873]    Loss: 0.002528   Batch Acc: 84.38
[Train] Epoch: 5 [243328/387873]    Loss: 0.002043   Batch Acc: 89.84
[Train] Epoch: 5 [243456/387873]    Loss: 0.002534   Batch Acc: 85.16
[Train] Epoch: 5 [243584/387873]    Loss: 0.002736   Batch Acc: 82.81
[Train] Epoch: 5 [243712/387873]    Loss: 0.002297   Batch Acc: 86.72
[Train] Epoch: 5 [243840/387873]    Loss: 0.002279   Batch Acc: 89.06
[Train] Epoch: 5 [243968/387873]    Loss: 0.002338   Batch Acc: 85.94
[Train] Epoch: 5 [244096/387873]    Loss: 0.002232   Batch Acc: 89.06
[Train] Epoch: 5 [244224/387873]    Loss: 0.001597   Batch Acc: 91.41
[Train] Epoch: 5 [244352/387873]    Loss: 0.001522   Batch Acc: 94.53
[Train] Epoch: 5 [244480/387873]    Loss: 0.001960   Batch Acc: 88.28
[Train] Epoch: 5 [244608/387873]    Loss: 0.002004   Batch Acc: 87.50
[Train] Epoch: 5 [244736/387873]    Loss: 0.002260   Batch Acc: 87.50
[Train] Epoch: 5 [244864/387873]    Loss: 0.001610   Batch Acc: 92.19
[Train] Epoch: 5 [244992/387873]    Loss: 0.002480   Batch Acc: 85.94
[Train] Epoch: 5 [245120/387873]    Loss: 0.002435   Batch Acc: 85.94
[Train] Epoch: 5 [245248/387873]    Loss: 0.002202   Batch Acc: 85.94
[Train] Epoch: 5 [245376/387873]    Loss: 0.001549   Batch Acc: 96.09
[Train] Epoch: 5 [245504/387873]    Loss: 0.001552   Batch Acc: 93.75
[Train] Epoch: 5 [245632/387873]    Loss: 0.001694   Batch Acc: 92.19
[Train] Epoch: 5 [245760/387873]    Loss: 0.001578   Batch Acc: 90.62
[Train] Epoch: 5 [245888/387873]    Loss: 0.002358   Batch Acc: 84.38
[Train] Epoch: 5 [246016/387873]    Loss: 0.002649   Batch Acc: 83.59
[Train] Epoch: 5 [246144/387873]    Loss: 0.001647   Batch Acc: 92.19
[Train] Epoch: 5 [246272/387873]    Loss: 0.001895   Batch Acc: 92.19
[Train] Epoch: 5 [246400/387873]    Loss: 0.001972   Batch Acc: 89.06
[Train] Epoch: 5 [246528/387873]    Loss: 0.001962   Batch Acc: 86.72
[Train] Epoch: 5 [246656/387873]    Loss: 0.002097   Batch Acc: 89.06
[Train] Epoch: 5 [246784/387873]    Loss: 0.002535   Batch Acc: 85.16
[Train] Epoch: 5 [246912/387873]    Loss: 0.001388   Batch Acc: 95.31
[Train] Epoch: 5 [247040/387873]    Loss: 0.002241   Batch Acc: 87.50
[Train] Epoch: 5 [247168/387873]    Loss: 0.001594   Batch Acc: 92.97
[Train] Epoch: 5 [247296/387873]    Loss: 0.002130   Batch Acc: 89.84
[Train] Epoch: 5 [247424/387873]    Loss: 0.001878   Batch Acc: 89.06
[Train] Epoch: 5 [247552/387873]    Loss: 0.001848   Batch Acc: 89.06
[Train] Epoch: 5 [247680/387873]    Loss: 0.001847   Batch Acc: 91.41
[Train] Epoch: 5 [247808/387873]    Loss: 0.001940   Batch Acc: 89.06
[Train] Epoch: 5 [247936/387873]    Loss: 0.001587   Batch Acc: 92.19
[Train] Epoch: 5 [248064/387873]    Loss: 0.001920   Batch Acc: 89.06
[Train] Epoch: 5 [248192/387873]    Loss: 0.002150   Batch Acc: 88.28
[Train] Epoch: 5 [248320/387873]    Loss: 0.001803   Batch Acc: 89.84
[Train] Epoch: 5 [248448/387873]    Loss: 0.001846   Batch Acc: 90.62
[Train] Epoch: 5 [248576/387873]    Loss: 0.001674   Batch Acc: 93.75
[Train] Epoch: 5 [248704/387873]    Loss: 0.001841   Batch Acc: 89.06
[Train] Epoch: 5 [248832/387873]    Loss: 0.002288   Batch Acc: 87.50
[Train] Epoch: 5 [248960/387873]    Loss: 0.002520   Batch Acc: 84.38
[Train] Epoch: 5 [249088/387873]    Loss: 0.001383   Batch Acc: 93.75
[Train] Epoch: 5 [249216/387873]    Loss: 0.001865   Batch Acc: 90.62
[Train] Epoch: 5 [249344/387873]    Loss: 0.001946   Batch Acc: 87.50
[Train] Epoch: 5 [249472/387873]    Loss: 0.001949   Batch Acc: 88.28
[Train] Epoch: 5 [249600/387873]    Loss: 0.001612   Batch Acc: 94.53
[Train] Epoch: 5 [249728/387873]    Loss: 0.001433   Batch Acc: 92.97
[Train] Epoch: 5 [249856/387873]    Loss: 0.001622   Batch Acc: 89.84
[Train] Epoch: 5 [249984/387873]    Loss: 0.002780   Batch Acc: 82.81
[Train] Epoch: 5 [250112/387873]    Loss: 0.001951   Batch Acc: 89.84
[Train] Epoch: 5 [250240/387873]    Loss: 0.002122   Batch Acc: 88.28
[Train] Epoch: 5 [250368/387873]    Loss: 0.001781   Batch Acc: 92.19
[Train] Epoch: 5 [250496/387873]    Loss: 0.001500   Batch Acc: 92.97
[Train] Epoch: 5 [250624/387873]    Loss: 0.001948   Batch Acc: 87.50
[Train] Epoch: 5 [250752/387873]    Loss: 0.002282   Batch Acc: 85.94
[Train] Epoch: 5 [250880/387873]    Loss: 0.002125   Batch Acc: 89.06
[Train] Epoch: 5 [251008/387873]    Loss: 0.002549   Batch Acc: 87.50
[Train] Epoch: 5 [251136/387873]    Loss: 0.001544   Batch Acc: 94.53
[Train] Epoch: 5 [251264/387873]    Loss: 0.001760   Batch Acc: 89.84
[Train] Epoch: 5 [251392/387873]    Loss: 0.001651   Batch Acc: 91.41
[Train] Epoch: 5 [251520/387873]    Loss: 0.001566   Batch Acc: 93.75
[Train] Epoch: 5 [251648/387873]    Loss: 0.001664   Batch Acc: 91.41
[Train] Epoch: 5 [251776/387873]    Loss: 0.002112   Batch Acc: 88.28
[Train] Epoch: 5 [251904/387873]    Loss: 0.002037   Batch Acc: 87.50
[Train] Epoch: 5 [252032/387873]    Loss: 0.001519   Batch Acc: 92.97
[Train] Epoch: 5 [252160/387873]    Loss: 0.002509   Batch Acc: 86.72
[Train] Epoch: 5 [252288/387873]    Loss: 0.001855   Batch Acc: 92.97
[Train] Epoch: 5 [252416/387873]    Loss: 0.001646   Batch Acc: 91.41
[Train] Epoch: 5 [252544/387873]    Loss: 0.002229   Batch Acc: 89.06
[Train] Epoch: 5 [252672/387873]    Loss: 0.002049   Batch Acc: 87.50
[Train] Epoch: 5 [252800/387873]    Loss: 0.001900   Batch Acc: 91.41
[Train] Epoch: 5 [252928/387873]    Loss: 0.002763   Batch Acc: 84.38
[Train] Epoch: 5 [253056/387873]    Loss: 0.002166   Batch Acc: 88.28
[Train] Epoch: 5 [253184/387873]    Loss: 0.001622   Batch Acc: 92.97
[Train] Epoch: 5 [253312/387873]    Loss: 0.002387   Batch Acc: 89.84
[Train] Epoch: 5 [253440/387873]    Loss: 0.002333   Batch Acc: 85.94
[Train] Epoch: 5 [253568/387873]    Loss: 0.002011   Batch Acc: 89.84
[Train] Epoch: 5 [253696/387873]    Loss: 0.002505   Batch Acc: 86.72
[Train] Epoch: 5 [253824/387873]    Loss: 0.002634   Batch Acc: 87.50
[Train] Epoch: 5 [253952/387873]    Loss: 0.002158   Batch Acc: 89.84
[Train] Epoch: 5 [254080/387873]    Loss: 0.002095   Batch Acc: 87.50
[Train] Epoch: 5 [254208/387873]    Loss: 0.001605   Batch Acc: 92.97
[Train] Epoch: 5 [254336/387873]    Loss: 0.001710   Batch Acc: 92.19
[Train] Epoch: 5 [254464/387873]    Loss: 0.001616   Batch Acc: 91.41
[Train] Epoch: 5 [254592/387873]    Loss: 0.002206   Batch Acc: 87.50
[Train] Epoch: 5 [254720/387873]    Loss: 0.002058   Batch Acc: 89.84
[Train] Epoch: 5 [254848/387873]    Loss: 0.002039   Batch Acc: 88.28
[Train] Epoch: 5 [254976/387873]    Loss: 0.001992   Batch Acc: 89.84
[Train] Epoch: 5 [255104/387873]    Loss: 0.002690   Batch Acc: 83.59
[Train] Epoch: 5 [255232/387873]    Loss: 0.002329   Batch Acc: 87.50
[Train] Epoch: 5 [255360/387873]    Loss: 0.002245   Batch Acc: 89.84
[Train] Epoch: 5 [255488/387873]    Loss: 0.002019   Batch Acc: 88.28
[Train] Epoch: 5 [255616/387873]    Loss: 0.001401   Batch Acc: 96.09
[Train] Epoch: 5 [255744/387873]    Loss: 0.001649   Batch Acc: 93.75
[Train] Epoch: 5 [255872/387873]    Loss: 0.001870   Batch Acc: 89.84
[Train] Epoch: 5 [256000/387873]    Loss: 0.002121   Batch Acc: 90.62
[Train] Epoch: 5 [256128/387873]    Loss: 0.001708   Batch Acc: 91.41
[Train] Epoch: 5 [256256/387873]    Loss: 0.002110   Batch Acc: 89.84
[Train] Epoch: 5 [256384/387873]    Loss: 0.002284   Batch Acc: 87.50
[Train] Epoch: 5 [256512/387873]    Loss: 0.002513   Batch Acc: 84.38
[Train] Epoch: 5 [256640/387873]    Loss: 0.001705   Batch Acc: 92.19
[Train] Epoch: 5 [256768/387873]    Loss: 0.002540   Batch Acc: 83.59
[Train] Epoch: 5 [256896/387873]    Loss: 0.002453   Batch Acc: 88.28
[Train] Epoch: 5 [257024/387873]    Loss: 0.001993   Batch Acc: 89.84
[Train] Epoch: 5 [257152/387873]    Loss: 0.001738   Batch Acc: 94.53
[Train] Epoch: 5 [257280/387873]    Loss: 0.002725   Batch Acc: 83.59
[Train] Epoch: 5 [257408/387873]    Loss: 0.002193   Batch Acc: 87.50
[Train] Epoch: 5 [257536/387873]    Loss: 0.002383   Batch Acc: 86.72
[Train] Epoch: 5 [257664/387873]    Loss: 0.002414   Batch Acc: 84.38
[Train] Epoch: 5 [257792/387873]    Loss: 0.002128   Batch Acc: 86.72
[Train] Epoch: 5 [257920/387873]    Loss: 0.001979   Batch Acc: 87.50
[Train] Epoch: 5 [258048/387873]    Loss: 0.001916   Batch Acc: 91.41
[Train] Epoch: 5 [258176/387873]    Loss: 0.001643   Batch Acc: 91.41
[Train] Epoch: 5 [258304/387873]    Loss: 0.002348   Batch Acc: 85.16
[Train] Epoch: 5 [258432/387873]    Loss: 0.001985   Batch Acc: 89.06
[Train] Epoch: 5 [258560/387873]    Loss: 0.002237   Batch Acc: 85.16
[Train] Epoch: 5 [258688/387873]    Loss: 0.002033   Batch Acc: 87.50
[Train] Epoch: 5 [258816/387873]    Loss: 0.001844   Batch Acc: 89.06
[Train] Epoch: 5 [258944/387873]    Loss: 0.001933   Batch Acc: 89.84
[Train] Epoch: 5 [259072/387873]    Loss: 0.002270   Batch Acc: 86.72
[Train] Epoch: 5 [259200/387873]    Loss: 0.001514   Batch Acc: 94.53
[Train] Epoch: 5 [259328/387873]    Loss: 0.001965   Batch Acc: 89.84
[Train] Epoch: 5 [259456/387873]    Loss: 0.002332   Batch Acc: 85.94
[Train] Epoch: 5 [259584/387873]    Loss: 0.002261   Batch Acc: 88.28
[Train] Epoch: 5 [259712/387873]    Loss: 0.002465   Batch Acc: 85.16
[Train] Epoch: 5 [259840/387873]    Loss: 0.002105   Batch Acc: 87.50
[Train] Epoch: 5 [259968/387873]    Loss: 0.001678   Batch Acc: 91.41
[Train] Epoch: 5 [260096/387873]    Loss: 0.001733   Batch Acc: 91.41
[Train] Epoch: 5 [260224/387873]    Loss: 0.002215   Batch Acc: 86.72
[Train] Epoch: 5 [260352/387873]    Loss: 0.002115   Batch Acc: 89.06
[Train] Epoch: 5 [260480/387873]    Loss: 0.001937   Batch Acc: 92.97
[Train] Epoch: 5 [260608/387873]    Loss: 0.002275   Batch Acc: 89.84
[Train] Epoch: 5 [260736/387873]    Loss: 0.002074   Batch Acc: 87.50
[Train] Epoch: 5 [260864/387873]    Loss: 0.001644   Batch Acc: 91.41
[Train] Epoch: 5 [260992/387873]    Loss: 0.001716   Batch Acc: 91.41
[Train] Epoch: 5 [261120/387873]    Loss: 0.002169   Batch Acc: 90.62
[Train] Epoch: 5 [261248/387873]    Loss: 0.001328   Batch Acc: 93.75
[Train] Epoch: 5 [261376/387873]    Loss: 0.001938   Batch Acc: 89.84
[Train] Epoch: 5 [261504/387873]    Loss: 0.001540   Batch Acc: 93.75
[Train] Epoch: 5 [261632/387873]    Loss: 0.001749   Batch Acc: 91.41
[Train] Epoch: 5 [261760/387873]    Loss: 0.002622   Batch Acc: 83.59
[Train] Epoch: 5 [261888/387873]    Loss: 0.001741   Batch Acc: 92.19
[Train] Epoch: 5 [262016/387873]    Loss: 0.002223   Batch Acc: 88.28
[Train] Epoch: 5 [262144/387873]    Loss: 0.001883   Batch Acc: 92.97
[Train] Epoch: 5 [262272/387873]    Loss: 0.002395   Batch Acc: 85.16
[Train] Epoch: 5 [262400/387873]    Loss: 0.001548   Batch Acc: 92.97
[Train] Epoch: 5 [262528/387873]    Loss: 0.002506   Batch Acc: 84.38
[Train] Epoch: 5 [262656/387873]    Loss: 0.002449   Batch Acc: 85.94
[Train] Epoch: 5 [262784/387873]    Loss: 0.001791   Batch Acc: 89.84
[Train] Epoch: 5 [262912/387873]    Loss: 0.002125   Batch Acc: 86.72
[Train] Epoch: 5 [263040/387873]    Loss: 0.002301   Batch Acc: 89.06
[Train] Epoch: 5 [263168/387873]    Loss: 0.001743   Batch Acc: 89.06
[Train] Epoch: 5 [263296/387873]    Loss: 0.002092   Batch Acc: 85.16
[Train] Epoch: 5 [263424/387873]    Loss: 0.001572   Batch Acc: 92.97
[Train] Epoch: 5 [263552/387873]    Loss: 0.002395   Batch Acc: 84.38
[Train] Epoch: 5 [263680/387873]    Loss: 0.002019   Batch Acc: 88.28
[Train] Epoch: 5 [263808/387873]    Loss: 0.001888   Batch Acc: 92.19
[Train] Epoch: 5 [263936/387873]    Loss: 0.001862   Batch Acc: 91.41
[Train] Epoch: 5 [264064/387873]    Loss: 0.002264   Batch Acc: 86.72
[Train] Epoch: 5 [264192/387873]    Loss: 0.001965   Batch Acc: 89.06
[Train] Epoch: 5 [264320/387873]    Loss: 0.002040   Batch Acc: 88.28
[Train] Epoch: 5 [264448/387873]    Loss: 0.002161   Batch Acc: 88.28
[Train] Epoch: 5 [264576/387873]    Loss: 0.002227   Batch Acc: 90.62
[Train] Epoch: 5 [264704/387873]    Loss: 0.001921   Batch Acc: 87.50
[Train] Epoch: 5 [264832/387873]    Loss: 0.001748   Batch Acc: 89.84
[Train] Epoch: 5 [264960/387873]    Loss: 0.002082   Batch Acc: 89.06
[Train] Epoch: 5 [265088/387873]    Loss: 0.001629   Batch Acc: 92.97
[Train] Epoch: 5 [265216/387873]    Loss: 0.001845   Batch Acc: 92.97
[Train] Epoch: 5 [265344/387873]    Loss: 0.002055   Batch Acc: 86.72
[Train] Epoch: 5 [265472/387873]    Loss: 0.002334   Batch Acc: 88.28
[Train] Epoch: 5 [265600/387873]    Loss: 0.002111   Batch Acc: 89.84
[Train] Epoch: 5 [265728/387873]    Loss: 0.001892   Batch Acc: 91.41
[Train] Epoch: 5 [265856/387873]    Loss: 0.002074   Batch Acc: 89.84
[Train] Epoch: 5 [265984/387873]    Loss: 0.002193   Batch Acc: 88.28
[Train] Epoch: 5 [266112/387873]    Loss: 0.001495   Batch Acc: 91.41
[Train] Epoch: 5 [266240/387873]    Loss: 0.001441   Batch Acc: 92.97
[Train] Epoch: 5 [266368/387873]    Loss: 0.002066   Batch Acc: 90.62
[Train] Epoch: 5 [266496/387873]    Loss: 0.002552   Batch Acc: 86.72
[Train] Epoch: 5 [266624/387873]    Loss: 0.001783   Batch Acc: 92.19
[Train] Epoch: 5 [266752/387873]    Loss: 0.001779   Batch Acc: 91.41
[Train] Epoch: 5 [266880/387873]    Loss: 0.001713   Batch Acc: 89.84
[Train] Epoch: 5 [267008/387873]    Loss: 0.001602   Batch Acc: 92.19
[Train] Epoch: 5 [267136/387873]    Loss: 0.001502   Batch Acc: 92.97
[Train] Epoch: 5 [267264/387873]    Loss: 0.002504   Batch Acc: 84.38
[Train] Epoch: 5 [267392/387873]    Loss: 0.002167   Batch Acc: 87.50
[Train] Epoch: 5 [267520/387873]    Loss: 0.002457   Batch Acc: 86.72
[Train] Epoch: 5 [267648/387873]    Loss: 0.001431   Batch Acc: 93.75
[Train] Epoch: 5 [267776/387873]    Loss: 0.002219   Batch Acc: 92.19
[Train] Epoch: 5 [267904/387873]    Loss: 0.002460   Batch Acc: 89.06
[Train] Epoch: 5 [268032/387873]    Loss: 0.001608   Batch Acc: 91.41
[Train] Epoch: 5 [268160/387873]    Loss: 0.002592   Batch Acc: 87.50
[Train] Epoch: 5 [268288/387873]    Loss: 0.001983   Batch Acc: 90.62
[Train] Epoch: 5 [268416/387873]    Loss: 0.001598   Batch Acc: 91.41
[Train] Epoch: 5 [268544/387873]    Loss: 0.001988   Batch Acc: 89.84
[Train] Epoch: 5 [268672/387873]    Loss: 0.001812   Batch Acc: 92.19
[Train] Epoch: 5 [268800/387873]    Loss: 0.001945   Batch Acc: 89.06
[Train] Epoch: 5 [268928/387873]    Loss: 0.002215   Batch Acc: 91.41
[Train] Epoch: 5 [269056/387873]    Loss: 0.002206   Batch Acc: 89.06
[Train] Epoch: 5 [269184/387873]    Loss: 0.002273   Batch Acc: 89.06
[Train] Epoch: 5 [269312/387873]    Loss: 0.002960   Batch Acc: 80.47
[Train] Epoch: 5 [269440/387873]    Loss: 0.001952   Batch Acc: 86.72
[Train] Epoch: 5 [269568/387873]    Loss: 0.002339   Batch Acc: 86.72
[Train] Epoch: 5 [269696/387873]    Loss: 0.001741   Batch Acc: 92.97
[Train] Epoch: 5 [269824/387873]    Loss: 0.001606   Batch Acc: 93.75
[Train] Epoch: 5 [269952/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 5 [270080/387873]    Loss: 0.002641   Batch Acc: 82.81
[Train] Epoch: 5 [270208/387873]    Loss: 0.001298   Batch Acc: 95.31
[Train] Epoch: 5 [270336/387873]    Loss: 0.001809   Batch Acc: 90.62
[Train] Epoch: 5 [270464/387873]    Loss: 0.001712   Batch Acc: 92.19
[Train] Epoch: 5 [270592/387873]    Loss: 0.002128   Batch Acc: 87.50
[Train] Epoch: 5 [270720/387873]    Loss: 0.002742   Batch Acc: 84.38
[Train] Epoch: 5 [270848/387873]    Loss: 0.002091   Batch Acc: 89.06
[Train] Epoch: 5 [270976/387873]    Loss: 0.001656   Batch Acc: 92.97
[Train] Epoch: 5 [271104/387873]    Loss: 0.002259   Batch Acc: 89.06
[Train] Epoch: 5 [271232/387873]    Loss: 0.001661   Batch Acc: 93.75
[Train] Epoch: 5 [271360/387873]    Loss: 0.001801   Batch Acc: 91.41
[Train] Epoch: 5 [271488/387873]    Loss: 0.002647   Batch Acc: 86.72
[Train] Epoch: 5 [271616/387873]    Loss: 0.001586   Batch Acc: 90.62
[Train] Epoch: 5 [271744/387873]    Loss: 0.001873   Batch Acc: 92.19
[Train] Epoch: 5 [271872/387873]    Loss: 0.002085   Batch Acc: 86.72
[Train] Epoch: 5 [272000/387873]    Loss: 0.001799   Batch Acc: 88.28
[Train] Epoch: 5 [272128/387873]    Loss: 0.001892   Batch Acc: 89.06
[Train] Epoch: 5 [272256/387873]    Loss: 0.002316   Batch Acc: 84.38
[Train] Epoch: 5 [272384/387873]    Loss: 0.001514   Batch Acc: 92.97
[Train] Epoch: 5 [272512/387873]    Loss: 0.001631   Batch Acc: 92.97
[Train] Epoch: 5 [272640/387873]    Loss: 0.001997   Batch Acc: 88.28
[Train] Epoch: 5 [272768/387873]    Loss: 0.001416   Batch Acc: 93.75
[Train] Epoch: 5 [272896/387873]    Loss: 0.001434   Batch Acc: 92.97
[Train] Epoch: 5 [273024/387873]    Loss: 0.001753   Batch Acc: 90.62
[Train] Epoch: 5 [273152/387873]    Loss: 0.001982   Batch Acc: 91.41
[Train] Epoch: 5 [273280/387873]    Loss: 0.001986   Batch Acc: 90.62
[Train] Epoch: 5 [273408/387873]    Loss: 0.002237   Batch Acc: 86.72
[Train] Epoch: 5 [273536/387873]    Loss: 0.001347   Batch Acc: 96.09
[Train] Epoch: 5 [273664/387873]    Loss: 0.002146   Batch Acc: 89.06
[Train] Epoch: 5 [273792/387873]    Loss: 0.002682   Batch Acc: 85.94
[Train] Epoch: 5 [273920/387873]    Loss: 0.001791   Batch Acc: 91.41
[Train] Epoch: 5 [274048/387873]    Loss: 0.001717   Batch Acc: 89.84
[Train] Epoch: 5 [274176/387873]    Loss: 0.002296   Batch Acc: 86.72
[Train] Epoch: 5 [274304/387873]    Loss: 0.002148   Batch Acc: 89.06
[Train] Epoch: 5 [274432/387873]    Loss: 0.002331   Batch Acc: 87.50
[Train] Epoch: 5 [274560/387873]    Loss: 0.002107   Batch Acc: 86.72
[Train] Epoch: 5 [274688/387873]    Loss: 0.001915   Batch Acc: 86.72
[Train] Epoch: 5 [274816/387873]    Loss: 0.002294   Batch Acc: 85.94
[Train] Epoch: 5 [274944/387873]    Loss: 0.002252   Batch Acc: 85.94
[Train] Epoch: 5 [275072/387873]    Loss: 0.002029   Batch Acc: 87.50
[Train] Epoch: 5 [275200/387873]    Loss: 0.002417   Batch Acc: 87.50
[Train] Epoch: 5 [275328/387873]    Loss: 0.002357   Batch Acc: 89.06
[Train] Epoch: 5 [275456/387873]    Loss: 0.001632   Batch Acc: 92.19
[Train] Epoch: 5 [275584/387873]    Loss: 0.001993   Batch Acc: 89.06
[Train] Epoch: 5 [275712/387873]    Loss: 0.001916   Batch Acc: 88.28
[Train] Epoch: 5 [275840/387873]    Loss: 0.001779   Batch Acc: 88.28
[Train] Epoch: 5 [275968/387873]    Loss: 0.002251   Batch Acc: 88.28
[Train] Epoch: 5 [276096/387873]    Loss: 0.002776   Batch Acc: 85.16
[Train] Epoch: 5 [276224/387873]    Loss: 0.001973   Batch Acc: 90.62
[Train] Epoch: 5 [276352/387873]    Loss: 0.001679   Batch Acc: 92.19
[Train] Epoch: 5 [276480/387873]    Loss: 0.001964   Batch Acc: 86.72
[Train] Epoch: 5 [276608/387873]    Loss: 0.001998   Batch Acc: 89.84
[Train] Epoch: 5 [276736/387873]    Loss: 0.001906   Batch Acc: 89.84
[Train] Epoch: 5 [276864/387873]    Loss: 0.001407   Batch Acc: 95.31
[Train] Epoch: 5 [276992/387873]    Loss: 0.001996   Batch Acc: 90.62
[Train] Epoch: 5 [277120/387873]    Loss: 0.001972   Batch Acc: 89.84
[Train] Epoch: 5 [277248/387873]    Loss: 0.001621   Batch Acc: 92.19
[Train] Epoch: 5 [277376/387873]    Loss: 0.002613   Batch Acc: 87.50
[Train] Epoch: 5 [277504/387873]    Loss: 0.001173   Batch Acc: 94.53
[Train] Epoch: 5 [277632/387873]    Loss: 0.001905   Batch Acc: 93.75
[Train] Epoch: 5 [277760/387873]    Loss: 0.002139   Batch Acc: 89.06
[Train] Epoch: 5 [277888/387873]    Loss: 0.002096   Batch Acc: 88.28
[Train] Epoch: 5 [278016/387873]    Loss: 0.002035   Batch Acc: 87.50
[Train] Epoch: 5 [278144/387873]    Loss: 0.002153   Batch Acc: 88.28
[Train] Epoch: 5 [278272/387873]    Loss: 0.001941   Batch Acc: 92.19
[Train] Epoch: 5 [278400/387873]    Loss: 0.001914   Batch Acc: 89.06
[Train] Epoch: 5 [278528/387873]    Loss: 0.002214   Batch Acc: 91.41
[Train] Epoch: 5 [278656/387873]    Loss: 0.002089   Batch Acc: 88.28
[Train] Epoch: 5 [278784/387873]    Loss: 0.002191   Batch Acc: 86.72
[Train] Epoch: 5 [278912/387873]    Loss: 0.002223   Batch Acc: 89.06
[Train] Epoch: 5 [279040/387873]    Loss: 0.001817   Batch Acc: 89.06
[Train] Epoch: 5 [279168/387873]    Loss: 0.001861   Batch Acc: 91.41
[Train] Epoch: 5 [279296/387873]    Loss: 0.002204   Batch Acc: 89.06
[Train] Epoch: 5 [279424/387873]    Loss: 0.002073   Batch Acc: 89.84
[Train] Epoch: 5 [279552/387873]    Loss: 0.002034   Batch Acc: 89.84
[Train] Epoch: 5 [279680/387873]    Loss: 0.001707   Batch Acc: 90.62
[Train] Epoch: 5 [279808/387873]    Loss: 0.001835   Batch Acc: 87.50
[Train] Epoch: 5 [279936/387873]    Loss: 0.002653   Batch Acc: 84.38
[Train] Epoch: 5 [280064/387873]    Loss: 0.001449   Batch Acc: 92.97
[Train] Epoch: 5 [280192/387873]    Loss: 0.001994   Batch Acc: 89.06
[Train] Epoch: 5 [280320/387873]    Loss: 0.001682   Batch Acc: 91.41
[Train] Epoch: 5 [280448/387873]    Loss: 0.002056   Batch Acc: 86.72
[Train] Epoch: 5 [280576/387873]    Loss: 0.002150   Batch Acc: 88.28
[Train] Epoch: 5 [280704/387873]    Loss: 0.001802   Batch Acc: 92.19
[Train] Epoch: 5 [280832/387873]    Loss: 0.002244   Batch Acc: 89.84
[Train] Epoch: 5 [280960/387873]    Loss: 0.001789   Batch Acc: 89.06
[Train] Epoch: 5 [281088/387873]    Loss: 0.002380   Batch Acc: 88.28
[Train] Epoch: 5 [281216/387873]    Loss: 0.002088   Batch Acc: 90.62
[Train] Epoch: 5 [281344/387873]    Loss: 0.002391   Batch Acc: 88.28
[Train] Epoch: 5 [281472/387873]    Loss: 0.002202   Batch Acc: 86.72
[Train] Epoch: 5 [281600/387873]    Loss: 0.001688   Batch Acc: 92.19
[Train] Epoch: 5 [281728/387873]    Loss: 0.001927   Batch Acc: 89.84
[Train] Epoch: 5 [281856/387873]    Loss: 0.001847   Batch Acc: 91.41
[Train] Epoch: 5 [281984/387873]    Loss: 0.002103   Batch Acc: 87.50
[Train] Epoch: 5 [282112/387873]    Loss: 0.001964   Batch Acc: 87.50
[Train] Epoch: 5 [282240/387873]    Loss: 0.002279   Batch Acc: 86.72
[Train] Epoch: 5 [282368/387873]    Loss: 0.001873   Batch Acc: 92.19
[Train] Epoch: 5 [282496/387873]    Loss: 0.001411   Batch Acc: 92.97
[Train] Epoch: 5 [282624/387873]    Loss: 0.002401   Batch Acc: 85.94
[Train] Epoch: 5 [282752/387873]    Loss: 0.002136   Batch Acc: 92.19
[Train] Epoch: 5 [282880/387873]    Loss: 0.002054   Batch Acc: 87.50
[Train] Epoch: 5 [283008/387873]    Loss: 0.001925   Batch Acc: 90.62
[Train] Epoch: 5 [283136/387873]    Loss: 0.001716   Batch Acc: 91.41
[Train] Epoch: 5 [283264/387873]    Loss: 0.001727   Batch Acc: 92.19
[Train] Epoch: 5 [283392/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 5 [283520/387873]    Loss: 0.002298   Batch Acc: 88.28
[Train] Epoch: 5 [283648/387873]    Loss: 0.002274   Batch Acc: 85.94
[Train] Epoch: 5 [283776/387873]    Loss: 0.001895   Batch Acc: 92.19
[Train] Epoch: 5 [283904/387873]    Loss: 0.002105   Batch Acc: 89.06
[Train] Epoch: 5 [284032/387873]    Loss: 0.001876   Batch Acc: 89.84
[Train] Epoch: 5 [284160/387873]    Loss: 0.002550   Batch Acc: 85.94
[Train] Epoch: 5 [284288/387873]    Loss: 0.001905   Batch Acc: 91.41
[Train] Epoch: 5 [284416/387873]    Loss: 0.001772   Batch Acc: 94.53
[Train] Epoch: 5 [284544/387873]    Loss: 0.001946   Batch Acc: 89.84
[Train] Epoch: 5 [284672/387873]    Loss: 0.002698   Batch Acc: 82.03
[Train] Epoch: 5 [284800/387873]    Loss: 0.002023   Batch Acc: 90.62
[Train] Epoch: 5 [284928/387873]    Loss: 0.001573   Batch Acc: 93.75
[Train] Epoch: 5 [285056/387873]    Loss: 0.002245   Batch Acc: 86.72
[Train] Epoch: 5 [285184/387873]    Loss: 0.001544   Batch Acc: 94.53
[Train] Epoch: 5 [285312/387873]    Loss: 0.001705   Batch Acc: 92.19
[Train] Epoch: 5 [285440/387873]    Loss: 0.002092   Batch Acc: 85.94
[Train] Epoch: 5 [285568/387873]    Loss: 0.002261   Batch Acc: 85.94
[Train] Epoch: 5 [285696/387873]    Loss: 0.001885   Batch Acc: 90.62
[Train] Epoch: 5 [285824/387873]    Loss: 0.001882   Batch Acc: 89.84
[Train] Epoch: 5 [285952/387873]    Loss: 0.001609   Batch Acc: 92.97
[Train] Epoch: 5 [286080/387873]    Loss: 0.002299   Batch Acc: 89.84
[Train] Epoch: 5 [286208/387873]    Loss: 0.002069   Batch Acc: 91.41
[Train] Epoch: 5 [286336/387873]    Loss: 0.002126   Batch Acc: 87.50
[Train] Epoch: 5 [286464/387873]    Loss: 0.002045   Batch Acc: 87.50
[Train] Epoch: 5 [286592/387873]    Loss: 0.001991   Batch Acc: 88.28
[Train] Epoch: 5 [286720/387873]    Loss: 0.002247   Batch Acc: 86.72
[Train] Epoch: 5 [286848/387873]    Loss: 0.002304   Batch Acc: 83.59
[Train] Epoch: 5 [286976/387873]    Loss: 0.001803   Batch Acc: 90.62
[Train] Epoch: 5 [287104/387873]    Loss: 0.001610   Batch Acc: 92.19
[Train] Epoch: 5 [287232/387873]    Loss: 0.002060   Batch Acc: 89.06
[Train] Epoch: 5 [287360/387873]    Loss: 0.001989   Batch Acc: 89.06
[Train] Epoch: 5 [287488/387873]    Loss: 0.001956   Batch Acc: 90.62
[Train] Epoch: 5 [287616/387873]    Loss: 0.002179   Batch Acc: 89.84
[Train] Epoch: 5 [287744/387873]    Loss: 0.002027   Batch Acc: 90.62
[Train] Epoch: 5 [287872/387873]    Loss: 0.002088   Batch Acc: 85.16
[Train] Epoch: 5 [288000/387873]    Loss: 0.001904   Batch Acc: 92.19
[Train] Epoch: 5 [288128/387873]    Loss: 0.002530   Batch Acc: 88.28
[Train] Epoch: 5 [288256/387873]    Loss: 0.001948   Batch Acc: 91.41
[Train] Epoch: 5 [288384/387873]    Loss: 0.002368   Batch Acc: 86.72
[Train] Epoch: 5 [288512/387873]    Loss: 0.001669   Batch Acc: 91.41
[Train] Epoch: 5 [288640/387873]    Loss: 0.002181   Batch Acc: 89.84
[Train] Epoch: 5 [288768/387873]    Loss: 0.001887   Batch Acc: 89.06
[Train] Epoch: 5 [288896/387873]    Loss: 0.001952   Batch Acc: 87.50
[Train] Epoch: 5 [289024/387873]    Loss: 0.001867   Batch Acc: 90.62
[Train] Epoch: 5 [289152/387873]    Loss: 0.001387   Batch Acc: 95.31
[Train] Epoch: 5 [289280/387873]    Loss: 0.002020   Batch Acc: 87.50
[Train] Epoch: 5 [289408/387873]    Loss: 0.001709   Batch Acc: 93.75
[Train] Epoch: 5 [289536/387873]    Loss: 0.002765   Batch Acc: 82.03
[Train] Epoch: 5 [289664/387873]    Loss: 0.001998   Batch Acc: 91.41
[Train] Epoch: 5 [289792/387873]    Loss: 0.002214   Batch Acc: 86.72
[Train] Epoch: 5 [289920/387873]    Loss: 0.001715   Batch Acc: 90.62
[Train] Epoch: 5 [290048/387873]    Loss: 0.002300   Batch Acc: 89.06
[Train] Epoch: 5 [290176/387873]    Loss: 0.002382   Batch Acc: 88.28
[Train] Epoch: 5 [290304/387873]    Loss: 0.002148   Batch Acc: 87.50
[Train] Epoch: 5 [290432/387873]    Loss: 0.001962   Batch Acc: 86.72
[Train] Epoch: 5 [290560/387873]    Loss: 0.002190   Batch Acc: 86.72
[Train] Epoch: 5 [290688/387873]    Loss: 0.001534   Batch Acc: 92.19
[Train] Epoch: 5 [290816/387873]    Loss: 0.001990   Batch Acc: 86.72
[Train] Epoch: 5 [290944/387873]    Loss: 0.001895   Batch Acc: 89.84
[Train] Epoch: 5 [291072/387873]    Loss: 0.001760   Batch Acc: 89.84
[Train] Epoch: 5 [291200/387873]    Loss: 0.002323   Batch Acc: 85.94
[Train] Epoch: 5 [291328/387873]    Loss: 0.001678   Batch Acc: 91.41
[Train] Epoch: 5 [291456/387873]    Loss: 0.001957   Batch Acc: 89.84
[Train] Epoch: 5 [291584/387873]    Loss: 0.002190   Batch Acc: 89.84
[Train] Epoch: 5 [291712/387873]    Loss: 0.001830   Batch Acc: 90.62
[Train] Epoch: 5 [291840/387873]    Loss: 0.002154   Batch Acc: 86.72
[Train] Epoch: 5 [291968/387873]    Loss: 0.001638   Batch Acc: 92.19
[Train] Epoch: 5 [292096/387873]    Loss: 0.002404   Batch Acc: 87.50
[Train] Epoch: 5 [292224/387873]    Loss: 0.002284   Batch Acc: 88.28
[Train] Epoch: 5 [292352/387873]    Loss: 0.002102   Batch Acc: 88.28
[Train] Epoch: 5 [292480/387873]    Loss: 0.001790   Batch Acc: 89.84
[Train] Epoch: 5 [292608/387873]    Loss: 0.001921   Batch Acc: 87.50
[Train] Epoch: 5 [292736/387873]    Loss: 0.001989   Batch Acc: 92.19
[Train] Epoch: 5 [292864/387873]    Loss: 0.001519   Batch Acc: 92.97
[Train] Epoch: 5 [292992/387873]    Loss: 0.001617   Batch Acc: 92.19
[Train] Epoch: 5 [293120/387873]    Loss: 0.001735   Batch Acc: 89.84
[Train] Epoch: 5 [293248/387873]    Loss: 0.002449   Batch Acc: 82.03
[Train] Epoch: 5 [293376/387873]    Loss: 0.001699   Batch Acc: 92.97
[Train] Epoch: 5 [293504/387873]    Loss: 0.002678   Batch Acc: 85.16
[Train] Epoch: 5 [293632/387873]    Loss: 0.001954   Batch Acc: 87.50
[Train] Epoch: 5 [293760/387873]    Loss: 0.002128   Batch Acc: 86.72
[Train] Epoch: 5 [293888/387873]    Loss: 0.002391   Batch Acc: 85.94
[Train] Epoch: 5 [294016/387873]    Loss: 0.001757   Batch Acc: 92.97
[Train] Epoch: 5 [294144/387873]    Loss: 0.001841   Batch Acc: 89.84
[Train] Epoch: 5 [294272/387873]    Loss: 0.001997   Batch Acc: 89.84
[Train] Epoch: 5 [294400/387873]    Loss: 0.001665   Batch Acc: 91.41
[Train] Epoch: 5 [294528/387873]    Loss: 0.002237   Batch Acc: 85.94
[Train] Epoch: 5 [294656/387873]    Loss: 0.001888   Batch Acc: 90.62
[Train] Epoch: 5 [294784/387873]    Loss: 0.001967   Batch Acc: 92.19
[Train] Epoch: 5 [294912/387873]    Loss: 0.001651   Batch Acc: 89.84
[Train] Epoch: 5 [295040/387873]    Loss: 0.002012   Batch Acc: 88.28
[Train] Epoch: 5 [295168/387873]    Loss: 0.001406   Batch Acc: 92.19
[Train] Epoch: 5 [295296/387873]    Loss: 0.001841   Batch Acc: 89.06
[Train] Epoch: 5 [295424/387873]    Loss: 0.002839   Batch Acc: 80.47
[Train] Epoch: 5 [295552/387873]    Loss: 0.001847   Batch Acc: 90.62
[Train] Epoch: 5 [295680/387873]    Loss: 0.001770   Batch Acc: 92.19
[Train] Epoch: 5 [295808/387873]    Loss: 0.001841   Batch Acc: 91.41
[Train] Epoch: 5 [295936/387873]    Loss: 0.002912   Batch Acc: 82.03
[Train] Epoch: 5 [296064/387873]    Loss: 0.001794   Batch Acc: 92.97
[Train] Epoch: 5 [296192/387873]    Loss: 0.001768   Batch Acc: 92.19
[Train] Epoch: 5 [296320/387873]    Loss: 0.001307   Batch Acc: 95.31
[Train] Epoch: 5 [296448/387873]    Loss: 0.002204   Batch Acc: 89.06
[Train] Epoch: 5 [296576/387873]    Loss: 0.002492   Batch Acc: 83.59
[Train] Epoch: 5 [296704/387873]    Loss: 0.001615   Batch Acc: 92.19
[Train] Epoch: 5 [296832/387873]    Loss: 0.002115   Batch Acc: 89.06
[Train] Epoch: 5 [296960/387873]    Loss: 0.001782   Batch Acc: 89.84
[Train] Epoch: 5 [297088/387873]    Loss: 0.002796   Batch Acc: 85.16
[Train] Epoch: 5 [297216/387873]    Loss: 0.002576   Batch Acc: 87.50
[Train] Epoch: 5 [297344/387873]    Loss: 0.001746   Batch Acc: 92.19
[Train] Epoch: 5 [297472/387873]    Loss: 0.001627   Batch Acc: 92.19
[Train] Epoch: 5 [297600/387873]    Loss: 0.001793   Batch Acc: 91.41
[Train] Epoch: 5 [297728/387873]    Loss: 0.002507   Batch Acc: 85.94
[Train] Epoch: 5 [297856/387873]    Loss: 0.001798   Batch Acc: 88.28
[Train] Epoch: 5 [297984/387873]    Loss: 0.001671   Batch Acc: 89.06
[Train] Epoch: 5 [298112/387873]    Loss: 0.001965   Batch Acc: 90.62
[Train] Epoch: 5 [298240/387873]    Loss: 0.001529   Batch Acc: 94.53
[Train] Epoch: 5 [298368/387873]    Loss: 0.001991   Batch Acc: 88.28
[Train] Epoch: 5 [298496/387873]    Loss: 0.001608   Batch Acc: 91.41
[Train] Epoch: 5 [298624/387873]    Loss: 0.002255   Batch Acc: 89.06
[Train] Epoch: 5 [298752/387873]    Loss: 0.001622   Batch Acc: 92.97
[Train] Epoch: 5 [298880/387873]    Loss: 0.001860   Batch Acc: 92.19
[Train] Epoch: 5 [299008/387873]    Loss: 0.001843   Batch Acc: 89.84
[Train] Epoch: 5 [299136/387873]    Loss: 0.002367   Batch Acc: 85.94
[Train] Epoch: 5 [299264/387873]    Loss: 0.002118   Batch Acc: 88.28
[Train] Epoch: 5 [299392/387873]    Loss: 0.002298   Batch Acc: 88.28
[Train] Epoch: 5 [299520/387873]    Loss: 0.002011   Batch Acc: 89.06
[Train] Epoch: 5 [299648/387873]    Loss: 0.002081   Batch Acc: 89.06
[Train] Epoch: 5 [299776/387873]    Loss: 0.001619   Batch Acc: 90.62
[Train] Epoch: 5 [299904/387873]    Loss: 0.002964   Batch Acc: 86.72
[Train] Epoch: 5 [300032/387873]    Loss: 0.002421   Batch Acc: 86.72
[Train] Epoch: 5 [300160/387873]    Loss: 0.001829   Batch Acc: 89.84
[Train] Epoch: 5 [300288/387873]    Loss: 0.001932   Batch Acc: 89.06
[Train] Epoch: 5 [300416/387873]    Loss: 0.002086   Batch Acc: 86.72
[Train] Epoch: 5 [300544/387873]    Loss: 0.001962   Batch Acc: 91.41
[Train] Epoch: 5 [300672/387873]    Loss: 0.001517   Batch Acc: 92.97
[Train] Epoch: 5 [300800/387873]    Loss: 0.001863   Batch Acc: 90.62
[Train] Epoch: 5 [300928/387873]    Loss: 0.002331   Batch Acc: 88.28
[Train] Epoch: 5 [301056/387873]    Loss: 0.002385   Batch Acc: 89.84
[Train] Epoch: 5 [301184/387873]    Loss: 0.001902   Batch Acc: 88.28
[Train] Epoch: 5 [301312/387873]    Loss: 0.001918   Batch Acc: 91.41
[Train] Epoch: 5 [301440/387873]    Loss: 0.002321   Batch Acc: 88.28
[Train] Epoch: 5 [301568/387873]    Loss: 0.001979   Batch Acc: 89.06
[Train] Epoch: 5 [301696/387873]    Loss: 0.002097   Batch Acc: 89.06
[Train] Epoch: 5 [301824/387873]    Loss: 0.002933   Batch Acc: 82.03
[Train] Epoch: 5 [301952/387873]    Loss: 0.001985   Batch Acc: 89.06
[Train] Epoch: 5 [302080/387873]    Loss: 0.001735   Batch Acc: 90.62
[Train] Epoch: 5 [302208/387873]    Loss: 0.001440   Batch Acc: 93.75
[Train] Epoch: 5 [302336/387873]    Loss: 0.001528   Batch Acc: 92.19
[Train] Epoch: 5 [302464/387873]    Loss: 0.001547   Batch Acc: 91.41
[Train] Epoch: 5 [302592/387873]    Loss: 0.001964   Batch Acc: 89.84
[Train] Epoch: 5 [302720/387873]    Loss: 0.001867   Batch Acc: 91.41
[Train] Epoch: 5 [302848/387873]    Loss: 0.002479   Batch Acc: 86.72
[Train] Epoch: 5 [302976/387873]    Loss: 0.002123   Batch Acc: 89.84
[Train] Epoch: 5 [303104/387873]    Loss: 0.002545   Batch Acc: 85.94
[Train] Epoch: 5 [303232/387873]    Loss: 0.002048   Batch Acc: 88.28
[Train] Epoch: 5 [303360/387873]    Loss: 0.002536   Batch Acc: 86.72
[Train] Epoch: 5 [303488/387873]    Loss: 0.002565   Batch Acc: 85.16
[Train] Epoch: 5 [303616/387873]    Loss: 0.002047   Batch Acc: 88.28
[Train] Epoch: 5 [303744/387873]    Loss: 0.001903   Batch Acc: 89.84
[Train] Epoch: 5 [303872/387873]    Loss: 0.001805   Batch Acc: 92.97
[Train] Epoch: 5 [304000/387873]    Loss: 0.001469   Batch Acc: 94.53
[Train] Epoch: 5 [304128/387873]    Loss: 0.001892   Batch Acc: 89.06
[Train] Epoch: 5 [304256/387873]    Loss: 0.002121   Batch Acc: 92.97
[Train] Epoch: 5 [304384/387873]    Loss: 0.001814   Batch Acc: 92.19
[Train] Epoch: 5 [304512/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 5 [304640/387873]    Loss: 0.002177   Batch Acc: 88.28
[Train] Epoch: 5 [304768/387873]    Loss: 0.002561   Batch Acc: 86.72
[Train] Epoch: 5 [304896/387873]    Loss: 0.002377   Batch Acc: 89.06
[Train] Epoch: 5 [305024/387873]    Loss: 0.002151   Batch Acc: 87.50
[Train] Epoch: 5 [305152/387873]    Loss: 0.002265   Batch Acc: 91.41
[Train] Epoch: 5 [305280/387873]    Loss: 0.001777   Batch Acc: 91.41
[Train] Epoch: 5 [305408/387873]    Loss: 0.002209   Batch Acc: 89.06
[Train] Epoch: 5 [305536/387873]    Loss: 0.001904   Batch Acc: 89.84
[Train] Epoch: 5 [305664/387873]    Loss: 0.001887   Batch Acc: 90.62
[Train] Epoch: 5 [305792/387873]    Loss: 0.001319   Batch Acc: 95.31
[Train] Epoch: 5 [305920/387873]    Loss: 0.001680   Batch Acc: 90.62
[Train] Epoch: 5 [306048/387873]    Loss: 0.002251   Batch Acc: 86.72
[Train] Epoch: 5 [306176/387873]    Loss: 0.002033   Batch Acc: 89.06
[Train] Epoch: 5 [306304/387873]    Loss: 0.002061   Batch Acc: 86.72
[Train] Epoch: 5 [306432/387873]    Loss: 0.001645   Batch Acc: 92.97
[Train] Epoch: 5 [306560/387873]    Loss: 0.001973   Batch Acc: 87.50
[Train] Epoch: 5 [306688/387873]    Loss: 0.002510   Batch Acc: 85.16
[Train] Epoch: 5 [306816/387873]    Loss: 0.002165   Batch Acc: 89.84
[Train] Epoch: 5 [306944/387873]    Loss: 0.002100   Batch Acc: 89.06
[Train] Epoch: 5 [307072/387873]    Loss: 0.001881   Batch Acc: 88.28
[Train] Epoch: 5 [307200/387873]    Loss: 0.001893   Batch Acc: 89.84
[Train] Epoch: 5 [307328/387873]    Loss: 0.001762   Batch Acc: 89.06
[Train] Epoch: 5 [307456/387873]    Loss: 0.002074   Batch Acc: 90.62
[Train] Epoch: 5 [307584/387873]    Loss: 0.001959   Batch Acc: 89.84
[Train] Epoch: 5 [307712/387873]    Loss: 0.002012   Batch Acc: 88.28
[Train] Epoch: 5 [307840/387873]    Loss: 0.002728   Batch Acc: 83.59
[Train] Epoch: 5 [307968/387873]    Loss: 0.001860   Batch Acc: 89.06
[Train] Epoch: 5 [308096/387873]    Loss: 0.002070   Batch Acc: 89.06
[Train] Epoch: 5 [308224/387873]    Loss: 0.001701   Batch Acc: 89.84
[Train] Epoch: 5 [308352/387873]    Loss: 0.001567   Batch Acc: 92.19
[Train] Epoch: 5 [308480/387873]    Loss: 0.002371   Batch Acc: 85.94
[Train] Epoch: 5 [308608/387873]    Loss: 0.002369   Batch Acc: 83.59
[Train] Epoch: 5 [308736/387873]    Loss: 0.001392   Batch Acc: 95.31
[Train] Epoch: 5 [308864/387873]    Loss: 0.001844   Batch Acc: 87.50
[Train] Epoch: 5 [308992/387873]    Loss: 0.001723   Batch Acc: 90.62
[Train] Epoch: 5 [309120/387873]    Loss: 0.001713   Batch Acc: 92.97
[Train] Epoch: 5 [309248/387873]    Loss: 0.002436   Batch Acc: 84.38
[Train] Epoch: 5 [309376/387873]    Loss: 0.001996   Batch Acc: 89.06
[Train] Epoch: 5 [309504/387873]    Loss: 0.001402   Batch Acc: 91.41
[Train] Epoch: 5 [309632/387873]    Loss: 0.002770   Batch Acc: 83.59
[Train] Epoch: 5 [309760/387873]    Loss: 0.001803   Batch Acc: 92.19
[Train] Epoch: 5 [309888/387873]    Loss: 0.001633   Batch Acc: 93.75
[Train] Epoch: 5 [310016/387873]    Loss: 0.001575   Batch Acc: 93.75
[Train] Epoch: 5 [310144/387873]    Loss: 0.002130   Batch Acc: 86.72
[Train] Epoch: 5 [310272/387873]    Loss: 0.001935   Batch Acc: 86.72
[Train] Epoch: 5 [310400/387873]    Loss: 0.001527   Batch Acc: 95.31
[Train] Epoch: 5 [310528/387873]    Loss: 0.001875   Batch Acc: 91.41
[Train] Epoch: 5 [310656/387873]    Loss: 0.001872   Batch Acc: 92.19
[Train] Epoch: 5 [310784/387873]    Loss: 0.002066   Batch Acc: 89.84
[Train] Epoch: 5 [310912/387873]    Loss: 0.001791   Batch Acc: 90.62
[Train] Epoch: 5 [311040/387873]    Loss: 0.002203   Batch Acc: 89.06
[Train] Epoch: 5 [311168/387873]    Loss: 0.001898   Batch Acc: 91.41
[Train] Epoch: 5 [311296/387873]    Loss: 0.002729   Batch Acc: 84.38
[Train] Epoch: 5 [311424/387873]    Loss: 0.002136   Batch Acc: 89.06
[Train] Epoch: 5 [311552/387873]    Loss: 0.002419   Batch Acc: 89.06
[Train] Epoch: 5 [311680/387873]    Loss: 0.001623   Batch Acc: 93.75
[Train] Epoch: 5 [311808/387873]    Loss: 0.002535   Batch Acc: 87.50
[Train] Epoch: 5 [311936/387873]    Loss: 0.001812   Batch Acc: 89.84
[Train] Epoch: 5 [312064/387873]    Loss: 0.002118   Batch Acc: 92.19
[Train] Epoch: 5 [312192/387873]    Loss: 0.001783   Batch Acc: 92.19
[Train] Epoch: 5 [312320/387873]    Loss: 0.001681   Batch Acc: 90.62
[Train] Epoch: 5 [312448/387873]    Loss: 0.002354   Batch Acc: 88.28
[Train] Epoch: 5 [312576/387873]    Loss: 0.002239   Batch Acc: 85.16
[Train] Epoch: 5 [312704/387873]    Loss: 0.001946   Batch Acc: 91.41
[Train] Epoch: 5 [312832/387873]    Loss: 0.001928   Batch Acc: 92.19
[Train] Epoch: 5 [312960/387873]    Loss: 0.002515   Batch Acc: 84.38
[Train] Epoch: 5 [313088/387873]    Loss: 0.002016   Batch Acc: 89.06
[Train] Epoch: 5 [313216/387873]    Loss: 0.001892   Batch Acc: 91.41
[Train] Epoch: 5 [313344/387873]    Loss: 0.002102   Batch Acc: 89.84
[Train] Epoch: 5 [313472/387873]    Loss: 0.001399   Batch Acc: 94.53
[Train] Epoch: 5 [313600/387873]    Loss: 0.001965   Batch Acc: 89.84
[Train] Epoch: 5 [313728/387873]    Loss: 0.001585   Batch Acc: 90.62
[Train] Epoch: 5 [313856/387873]    Loss: 0.001739   Batch Acc: 90.62
[Train] Epoch: 5 [313984/387873]    Loss: 0.001732   Batch Acc: 92.97
[Train] Epoch: 5 [314112/387873]    Loss: 0.001965   Batch Acc: 90.62
[Train] Epoch: 5 [314240/387873]    Loss: 0.001413   Batch Acc: 93.75
[Train] Epoch: 5 [314368/387873]    Loss: 0.001790   Batch Acc: 91.41
[Train] Epoch: 5 [314496/387873]    Loss: 0.002350   Batch Acc: 86.72
[Train] Epoch: 5 [314624/387873]    Loss: 0.001847   Batch Acc: 89.06
[Train] Epoch: 5 [314752/387873]    Loss: 0.002143   Batch Acc: 87.50
[Train] Epoch: 5 [314880/387873]    Loss: 0.002514   Batch Acc: 85.16
[Train] Epoch: 5 [315008/387873]    Loss: 0.001979   Batch Acc: 90.62
[Train] Epoch: 5 [315136/387873]    Loss: 0.001830   Batch Acc: 92.19
[Train] Epoch: 5 [315264/387873]    Loss: 0.002209   Batch Acc: 85.94
[Train] Epoch: 5 [315392/387873]    Loss: 0.001977   Batch Acc: 90.62
[Train] Epoch: 5 [315520/387873]    Loss: 0.002241   Batch Acc: 87.50
[Train] Epoch: 5 [315648/387873]    Loss: 0.002167   Batch Acc: 86.72
[Train] Epoch: 5 [315776/387873]    Loss: 0.002060   Batch Acc: 88.28
[Train] Epoch: 5 [315904/387873]    Loss: 0.002002   Batch Acc: 89.06
[Train] Epoch: 5 [316032/387873]    Loss: 0.001903   Batch Acc: 91.41
[Train] Epoch: 5 [316160/387873]    Loss: 0.002264   Batch Acc: 86.72
[Train] Epoch: 5 [316288/387873]    Loss: 0.002135   Batch Acc: 89.06
[Train] Epoch: 5 [316416/387873]    Loss: 0.001933   Batch Acc: 89.84
[Train] Epoch: 5 [316544/387873]    Loss: 0.002165   Batch Acc: 88.28
[Train] Epoch: 5 [316672/387873]    Loss: 0.001644   Batch Acc: 92.97
[Train] Epoch: 5 [316800/387873]    Loss: 0.002919   Batch Acc: 83.59
[Train] Epoch: 5 [316928/387873]    Loss: 0.001705   Batch Acc: 92.97
[Train] Epoch: 5 [317056/387873]    Loss: 0.001737   Batch Acc: 90.62
[Train] Epoch: 5 [317184/387873]    Loss: 0.001702   Batch Acc: 92.97
[Train] Epoch: 5 [317312/387873]    Loss: 0.001764   Batch Acc: 90.62
[Train] Epoch: 5 [317440/387873]    Loss: 0.002460   Batch Acc: 88.28
[Train] Epoch: 5 [317568/387873]    Loss: 0.001571   Batch Acc: 93.75
[Train] Epoch: 5 [317696/387873]    Loss: 0.002025   Batch Acc: 88.28
[Train] Epoch: 5 [317824/387873]    Loss: 0.001919   Batch Acc: 90.62
[Train] Epoch: 5 [317952/387873]    Loss: 0.001830   Batch Acc: 91.41
[Train] Epoch: 5 [318080/387873]    Loss: 0.001844   Batch Acc: 89.84
[Train] Epoch: 5 [318208/387873]    Loss: 0.001783   Batch Acc: 92.97
[Train] Epoch: 5 [318336/387873]    Loss: 0.002357   Batch Acc: 82.81
[Train] Epoch: 5 [318464/387873]    Loss: 0.001924   Batch Acc: 90.62
[Train] Epoch: 5 [318592/387873]    Loss: 0.001396   Batch Acc: 94.53
[Train] Epoch: 5 [318720/387873]    Loss: 0.001753   Batch Acc: 92.19
[Train] Epoch: 5 [318848/387873]    Loss: 0.001634   Batch Acc: 91.41
[Train] Epoch: 5 [318976/387873]    Loss: 0.001803   Batch Acc: 92.19
[Train] Epoch: 5 [319104/387873]    Loss: 0.001836   Batch Acc: 89.84
[Train] Epoch: 5 [319232/387873]    Loss: 0.001998   Batch Acc: 90.62
[Train] Epoch: 5 [319360/387873]    Loss: 0.001768   Batch Acc: 92.19
[Train] Epoch: 5 [319488/387873]    Loss: 0.001948   Batch Acc: 90.62
[Train] Epoch: 5 [319616/387873]    Loss: 0.001750   Batch Acc: 89.84
[Train] Epoch: 5 [319744/387873]    Loss: 0.001921   Batch Acc: 89.84
[Train] Epoch: 5 [319872/387873]    Loss: 0.001570   Batch Acc: 93.75
[Train] Epoch: 5 [320000/387873]    Loss: 0.001826   Batch Acc: 89.06
[Train] Epoch: 5 [320128/387873]    Loss: 0.001632   Batch Acc: 91.41
[Train] Epoch: 5 [320256/387873]    Loss: 0.001292   Batch Acc: 92.97
[Train] Epoch: 5 [320384/387873]    Loss: 0.001954   Batch Acc: 89.06
[Train] Epoch: 5 [320512/387873]    Loss: 0.001845   Batch Acc: 90.62
[Train] Epoch: 5 [320640/387873]    Loss: 0.001986   Batch Acc: 89.06
[Train] Epoch: 5 [320768/387873]    Loss: 0.002625   Batch Acc: 82.03
[Train] Epoch: 5 [320896/387873]    Loss: 0.002305   Batch Acc: 89.06
[Train] Epoch: 5 [321024/387873]    Loss: 0.001666   Batch Acc: 89.06
[Train] Epoch: 5 [321152/387873]    Loss: 0.001855   Batch Acc: 89.84
[Train] Epoch: 5 [321280/387873]    Loss: 0.001536   Batch Acc: 92.19
[Train] Epoch: 5 [321408/387873]    Loss: 0.002584   Batch Acc: 84.38
[Train] Epoch: 5 [321536/387873]    Loss: 0.001804   Batch Acc: 89.84
[Train] Epoch: 5 [321664/387873]    Loss: 0.002090   Batch Acc: 89.84
[Train] Epoch: 5 [321792/387873]    Loss: 0.001838   Batch Acc: 92.19
[Train] Epoch: 5 [321920/387873]    Loss: 0.001305   Batch Acc: 96.88
[Train] Epoch: 5 [322048/387873]    Loss: 0.002186   Batch Acc: 88.28
[Train] Epoch: 5 [322176/387873]    Loss: 0.001300   Batch Acc: 92.97
[Train] Epoch: 5 [322304/387873]    Loss: 0.002452   Batch Acc: 84.38
[Train] Epoch: 5 [322432/387873]    Loss: 0.001799   Batch Acc: 90.62
[Train] Epoch: 5 [322560/387873]    Loss: 0.001607   Batch Acc: 90.62
[Train] Epoch: 5 [322688/387873]    Loss: 0.002276   Batch Acc: 85.94
[Train] Epoch: 5 [322816/387873]    Loss: 0.001921   Batch Acc: 87.50
[Train] Epoch: 5 [322944/387873]    Loss: 0.002169   Batch Acc: 87.50
[Train] Epoch: 5 [323072/387873]    Loss: 0.002073   Batch Acc: 87.50
[Train] Epoch: 5 [323200/387873]    Loss: 0.001962   Batch Acc: 89.84
[Train] Epoch: 5 [323328/387873]    Loss: 0.001920   Batch Acc: 91.41
[Train] Epoch: 5 [323456/387873]    Loss: 0.001433   Batch Acc: 94.53
[Train] Epoch: 5 [323584/387873]    Loss: 0.001989   Batch Acc: 90.62
[Train] Epoch: 5 [323712/387873]    Loss: 0.001924   Batch Acc: 91.41
[Train] Epoch: 5 [323840/387873]    Loss: 0.001807   Batch Acc: 92.19
[Train] Epoch: 5 [323968/387873]    Loss: 0.001869   Batch Acc: 92.19
[Train] Epoch: 5 [324096/387873]    Loss: 0.002505   Batch Acc: 85.16
[Train] Epoch: 5 [324224/387873]    Loss: 0.001826   Batch Acc: 90.62
[Train] Epoch: 5 [324352/387873]    Loss: 0.001690   Batch Acc: 92.19
[Train] Epoch: 5 [324480/387873]    Loss: 0.002076   Batch Acc: 89.84
[Train] Epoch: 5 [324608/387873]    Loss: 0.001836   Batch Acc: 89.84
[Train] Epoch: 5 [324736/387873]    Loss: 0.001838   Batch Acc: 90.62
[Train] Epoch: 5 [324864/387873]    Loss: 0.001753   Batch Acc: 89.84
[Train] Epoch: 5 [324992/387873]    Loss: 0.002114   Batch Acc: 89.84
[Train] Epoch: 5 [325120/387873]    Loss: 0.001920   Batch Acc: 88.28
[Train] Epoch: 5 [325248/387873]    Loss: 0.002169   Batch Acc: 84.38
[Train] Epoch: 5 [325376/387873]    Loss: 0.001612   Batch Acc: 92.97
[Train] Epoch: 5 [325504/387873]    Loss: 0.001685   Batch Acc: 92.19
[Train] Epoch: 5 [325632/387873]    Loss: 0.002134   Batch Acc: 89.06
[Train] Epoch: 5 [325760/387873]    Loss: 0.002378   Batch Acc: 85.94
[Train] Epoch: 5 [325888/387873]    Loss: 0.001518   Batch Acc: 92.19
[Train] Epoch: 5 [326016/387873]    Loss: 0.002079   Batch Acc: 90.62
[Train] Epoch: 5 [326144/387873]    Loss: 0.001771   Batch Acc: 89.06
[Train] Epoch: 5 [326272/387873]    Loss: 0.001561   Batch Acc: 92.19
[Train] Epoch: 5 [326400/387873]    Loss: 0.001793   Batch Acc: 89.84
[Train] Epoch: 5 [326528/387873]    Loss: 0.002215   Batch Acc: 90.62
[Train] Epoch: 5 [326656/387873]    Loss: 0.001923   Batch Acc: 89.84
[Train] Epoch: 5 [326784/387873]    Loss: 0.001784   Batch Acc: 91.41
[Train] Epoch: 5 [326912/387873]    Loss: 0.001832   Batch Acc: 90.62
[Train] Epoch: 5 [327040/387873]    Loss: 0.002318   Batch Acc: 86.72
[Train] Epoch: 5 [327168/387873]    Loss: 0.001590   Batch Acc: 91.41
[Train] Epoch: 5 [327296/387873]    Loss: 0.002145   Batch Acc: 89.84
[Train] Epoch: 5 [327424/387873]    Loss: 0.002009   Batch Acc: 89.84
[Train] Epoch: 5 [327552/387873]    Loss: 0.001685   Batch Acc: 90.62
[Train] Epoch: 5 [327680/387873]    Loss: 0.002502   Batch Acc: 82.03
[Train] Epoch: 5 [327808/387873]    Loss: 0.001535   Batch Acc: 93.75
[Train] Epoch: 5 [327936/387873]    Loss: 0.001969   Batch Acc: 94.53
[Train] Epoch: 5 [328064/387873]    Loss: 0.002171   Batch Acc: 86.72
[Train] Epoch: 5 [328192/387873]    Loss: 0.001979   Batch Acc: 88.28
[Train] Epoch: 5 [328320/387873]    Loss: 0.002329   Batch Acc: 85.94
[Train] Epoch: 5 [328448/387873]    Loss: 0.001869   Batch Acc: 91.41
[Train] Epoch: 5 [328576/387873]    Loss: 0.001724   Batch Acc: 89.06
[Train] Epoch: 5 [328704/387873]    Loss: 0.001741   Batch Acc: 90.62
[Train] Epoch: 5 [328832/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 5 [328960/387873]    Loss: 0.002215   Batch Acc: 85.94
[Train] Epoch: 5 [329088/387873]    Loss: 0.001677   Batch Acc: 90.62
[Train] Epoch: 5 [329216/387873]    Loss: 0.002284   Batch Acc: 85.94
[Train] Epoch: 5 [329344/387873]    Loss: 0.001674   Batch Acc: 89.06
[Train] Epoch: 5 [329472/387873]    Loss: 0.002184   Batch Acc: 87.50
[Train] Epoch: 5 [329600/387873]    Loss: 0.001975   Batch Acc: 90.62
[Train] Epoch: 5 [329728/387873]    Loss: 0.002188   Batch Acc: 86.72
[Train] Epoch: 5 [329856/387873]    Loss: 0.002084   Batch Acc: 89.06
[Train] Epoch: 5 [329984/387873]    Loss: 0.002056   Batch Acc: 89.84
[Train] Epoch: 5 [330112/387873]    Loss: 0.001826   Batch Acc: 88.28
[Train] Epoch: 5 [330240/387873]    Loss: 0.001502   Batch Acc: 90.62
[Train] Epoch: 5 [330368/387873]    Loss: 0.002067   Batch Acc: 92.19
[Train] Epoch: 5 [330496/387873]    Loss: 0.001675   Batch Acc: 92.19
[Train] Epoch: 5 [330624/387873]    Loss: 0.002237   Batch Acc: 87.50
[Train] Epoch: 5 [330752/387873]    Loss: 0.002034   Batch Acc: 89.06
[Train] Epoch: 5 [330880/387873]    Loss: 0.002235   Batch Acc: 87.50
[Train] Epoch: 5 [331008/387873]    Loss: 0.001960   Batch Acc: 92.19
[Train] Epoch: 5 [331136/387873]    Loss: 0.001793   Batch Acc: 89.06
[Train] Epoch: 5 [331264/387873]    Loss: 0.002119   Batch Acc: 86.72
[Train] Epoch: 5 [331392/387873]    Loss: 0.001940   Batch Acc: 90.62
[Train] Epoch: 5 [331520/387873]    Loss: 0.002408   Batch Acc: 84.38
[Train] Epoch: 5 [331648/387873]    Loss: 0.002399   Batch Acc: 87.50
[Train] Epoch: 5 [331776/387873]    Loss: 0.001875   Batch Acc: 88.28
[Train] Epoch: 5 [331904/387873]    Loss: 0.002122   Batch Acc: 91.41
[Train] Epoch: 5 [332032/387873]    Loss: 0.002032   Batch Acc: 89.84
[Train] Epoch: 5 [332160/387873]    Loss: 0.001903   Batch Acc: 90.62
[Train] Epoch: 5 [332288/387873]    Loss: 0.001402   Batch Acc: 93.75
[Train] Epoch: 5 [332416/387873]    Loss: 0.002009   Batch Acc: 85.16
[Train] Epoch: 5 [332544/387873]    Loss: 0.001864   Batch Acc: 88.28
[Train] Epoch: 5 [332672/387873]    Loss: 0.001725   Batch Acc: 92.19
[Train] Epoch: 5 [332800/387873]    Loss: 0.002115   Batch Acc: 87.50
[Train] Epoch: 5 [332928/387873]    Loss: 0.001575   Batch Acc: 92.19
[Train] Epoch: 5 [333056/387873]    Loss: 0.002525   Batch Acc: 86.72
[Train] Epoch: 5 [333184/387873]    Loss: 0.002468   Batch Acc: 87.50
[Train] Epoch: 5 [333312/387873]    Loss: 0.001466   Batch Acc: 92.19
[Train] Epoch: 5 [333440/387873]    Loss: 0.001810   Batch Acc: 89.06
[Train] Epoch: 5 [333568/387873]    Loss: 0.001883   Batch Acc: 91.41
[Train] Epoch: 5 [333696/387873]    Loss: 0.002003   Batch Acc: 89.84
[Train] Epoch: 5 [333824/387873]    Loss: 0.001947   Batch Acc: 89.06
[Train] Epoch: 5 [333952/387873]    Loss: 0.002379   Batch Acc: 85.94
[Train] Epoch: 5 [334080/387873]    Loss: 0.002017   Batch Acc: 88.28
[Train] Epoch: 5 [334208/387873]    Loss: 0.001706   Batch Acc: 91.41
[Train] Epoch: 5 [334336/387873]    Loss: 0.001764   Batch Acc: 92.19
[Train] Epoch: 5 [334464/387873]    Loss: 0.002523   Batch Acc: 83.59
[Train] Epoch: 5 [334592/387873]    Loss: 0.001356   Batch Acc: 96.09
[Train] Epoch: 5 [334720/387873]    Loss: 0.002280   Batch Acc: 85.94
[Train] Epoch: 5 [334848/387873]    Loss: 0.001686   Batch Acc: 92.97
[Train] Epoch: 5 [334976/387873]    Loss: 0.002330   Batch Acc: 87.50
[Train] Epoch: 5 [335104/387873]    Loss: 0.001637   Batch Acc: 92.19
[Train] Epoch: 5 [335232/387873]    Loss: 0.001900   Batch Acc: 91.41
[Train] Epoch: 5 [335360/387873]    Loss: 0.001800   Batch Acc: 90.62
[Train] Epoch: 5 [335488/387873]    Loss: 0.002075   Batch Acc: 87.50
[Train] Epoch: 5 [335616/387873]    Loss: 0.001965   Batch Acc: 92.19
[Train] Epoch: 5 [335744/387873]    Loss: 0.001765   Batch Acc: 90.62
[Train] Epoch: 5 [335872/387873]    Loss: 0.001853   Batch Acc: 89.84
[Train] Epoch: 5 [336000/387873]    Loss: 0.001692   Batch Acc: 88.28
[Train] Epoch: 5 [336128/387873]    Loss: 0.001979   Batch Acc: 89.84
[Train] Epoch: 5 [336256/387873]    Loss: 0.001977   Batch Acc: 90.62
[Train] Epoch: 5 [336384/387873]    Loss: 0.002092   Batch Acc: 88.28
[Train] Epoch: 5 [336512/387873]    Loss: 0.001418   Batch Acc: 92.97
[Train] Epoch: 5 [336640/387873]    Loss: 0.002512   Batch Acc: 88.28
[Train] Epoch: 5 [336768/387873]    Loss: 0.001717   Batch Acc: 92.19
[Train] Epoch: 5 [336896/387873]    Loss: 0.001918   Batch Acc: 89.84
[Train] Epoch: 5 [337024/387873]    Loss: 0.001430   Batch Acc: 94.53
[Train] Epoch: 5 [337152/387873]    Loss: 0.001411   Batch Acc: 92.19
[Train] Epoch: 5 [337280/387873]    Loss: 0.001811   Batch Acc: 91.41
[Train] Epoch: 5 [337408/387873]    Loss: 0.001427   Batch Acc: 94.53
[Train] Epoch: 5 [337536/387873]    Loss: 0.001478   Batch Acc: 93.75
[Train] Epoch: 5 [337664/387873]    Loss: 0.002041   Batch Acc: 89.84
[Train] Epoch: 5 [337792/387873]    Loss: 0.002356   Batch Acc: 85.16
[Train] Epoch: 5 [337920/387873]    Loss: 0.001166   Batch Acc: 95.31
[Train] Epoch: 5 [338048/387873]    Loss: 0.001495   Batch Acc: 92.97
[Train] Epoch: 5 [338176/387873]    Loss: 0.001580   Batch Acc: 92.19
[Train] Epoch: 5 [338304/387873]    Loss: 0.001680   Batch Acc: 92.97
[Train] Epoch: 5 [338432/387873]    Loss: 0.002316   Batch Acc: 87.50
[Train] Epoch: 5 [338560/387873]    Loss: 0.001900   Batch Acc: 90.62
[Train] Epoch: 5 [338688/387873]    Loss: 0.002673   Batch Acc: 82.03
[Train] Epoch: 5 [338816/387873]    Loss: 0.001877   Batch Acc: 89.84
[Train] Epoch: 5 [338944/387873]    Loss: 0.002050   Batch Acc: 88.28
[Train] Epoch: 5 [339072/387873]    Loss: 0.002030   Batch Acc: 88.28
[Train] Epoch: 5 [339200/387873]    Loss: 0.001841   Batch Acc: 89.84
[Train] Epoch: 5 [339328/387873]    Loss: 0.001664   Batch Acc: 93.75
[Train] Epoch: 5 [339456/387873]    Loss: 0.001897   Batch Acc: 91.41
[Train] Epoch: 5 [339584/387873]    Loss: 0.001522   Batch Acc: 93.75
[Train] Epoch: 5 [339712/387873]    Loss: 0.002480   Batch Acc: 86.72
[Train] Epoch: 5 [339840/387873]    Loss: 0.001824   Batch Acc: 89.06
[Train] Epoch: 5 [339968/387873]    Loss: 0.002172   Batch Acc: 88.28
[Train] Epoch: 5 [340096/387873]    Loss: 0.001602   Batch Acc: 89.06
[Train] Epoch: 5 [340224/387873]    Loss: 0.002284   Batch Acc: 89.84
[Train] Epoch: 5 [340352/387873]    Loss: 0.001596   Batch Acc: 89.84
[Train] Epoch: 5 [340480/387873]    Loss: 0.001604   Batch Acc: 91.41
[Train] Epoch: 5 [340608/387873]    Loss: 0.002308   Batch Acc: 88.28
[Train] Epoch: 5 [340736/387873]    Loss: 0.002109   Batch Acc: 85.94
[Train] Epoch: 5 [340864/387873]    Loss: 0.001412   Batch Acc: 95.31
[Train] Epoch: 5 [340992/387873]    Loss: 0.001887   Batch Acc: 89.84
[Train] Epoch: 5 [341120/387873]    Loss: 0.001835   Batch Acc: 91.41
[Train] Epoch: 5 [341248/387873]    Loss: 0.002317   Batch Acc: 84.38
[Train] Epoch: 5 [341376/387873]    Loss: 0.001871   Batch Acc: 88.28
[Train] Epoch: 5 [341504/387873]    Loss: 0.002155   Batch Acc: 89.84
[Train] Epoch: 5 [341632/387873]    Loss: 0.001848   Batch Acc: 90.62
[Train] Epoch: 5 [341760/387873]    Loss: 0.001911   Batch Acc: 89.84
[Train] Epoch: 5 [341888/387873]    Loss: 0.001893   Batch Acc: 88.28
[Train] Epoch: 5 [342016/387873]    Loss: 0.001751   Batch Acc: 92.19
[Train] Epoch: 5 [342144/387873]    Loss: 0.001776   Batch Acc: 89.06
[Train] Epoch: 5 [342272/387873]    Loss: 0.002293   Batch Acc: 86.72
[Train] Epoch: 5 [342400/387873]    Loss: 0.002369   Batch Acc: 89.06
[Train] Epoch: 5 [342528/387873]    Loss: 0.001764   Batch Acc: 90.62
[Train] Epoch: 5 [342656/387873]    Loss: 0.002268   Batch Acc: 89.84
[Train] Epoch: 5 [342784/387873]    Loss: 0.002066   Batch Acc: 86.72
[Train] Epoch: 5 [342912/387873]    Loss: 0.001574   Batch Acc: 91.41
[Train] Epoch: 5 [343040/387873]    Loss: 0.002160   Batch Acc: 89.84
[Train] Epoch: 5 [343168/387873]    Loss: 0.001623   Batch Acc: 92.19
[Train] Epoch: 5 [343296/387873]    Loss: 0.002074   Batch Acc: 88.28
[Train] Epoch: 5 [343424/387873]    Loss: 0.001868   Batch Acc: 89.84
[Train] Epoch: 5 [343552/387873]    Loss: 0.001720   Batch Acc: 92.19
[Train] Epoch: 5 [343680/387873]    Loss: 0.001713   Batch Acc: 89.84
[Train] Epoch: 5 [343808/387873]    Loss: 0.001950   Batch Acc: 90.62
[Train] Epoch: 5 [343936/387873]    Loss: 0.002160   Batch Acc: 88.28
[Train] Epoch: 5 [344064/387873]    Loss: 0.002026   Batch Acc: 89.84
[Train] Epoch: 5 [344192/387873]    Loss: 0.001755   Batch Acc: 91.41
[Train] Epoch: 5 [344320/387873]    Loss: 0.001620   Batch Acc: 92.97
[Train] Epoch: 5 [344448/387873]    Loss: 0.001716   Batch Acc: 92.19
[Train] Epoch: 5 [344576/387873]    Loss: 0.001678   Batch Acc: 91.41
[Train] Epoch: 5 [344704/387873]    Loss: 0.001593   Batch Acc: 95.31
[Train] Epoch: 5 [344832/387873]    Loss: 0.001977   Batch Acc: 90.62
[Train] Epoch: 5 [344960/387873]    Loss: 0.002225   Batch Acc: 88.28
[Train] Epoch: 5 [345088/387873]    Loss: 0.001799   Batch Acc: 89.84
[Train] Epoch: 5 [345216/387873]    Loss: 0.002669   Batch Acc: 86.72
[Train] Epoch: 5 [345344/387873]    Loss: 0.001505   Batch Acc: 92.19
[Train] Epoch: 5 [345472/387873]    Loss: 0.001975   Batch Acc: 89.84
[Train] Epoch: 5 [345600/387873]    Loss: 0.002112   Batch Acc: 86.72
[Train] Epoch: 5 [345728/387873]    Loss: 0.001343   Batch Acc: 92.97
[Train] Epoch: 5 [345856/387873]    Loss: 0.001275   Batch Acc: 95.31
[Train] Epoch: 5 [345984/387873]    Loss: 0.001880   Batch Acc: 89.06
[Train] Epoch: 5 [346112/387873]    Loss: 0.001827   Batch Acc: 91.41
[Train] Epoch: 5 [346240/387873]    Loss: 0.001826   Batch Acc: 90.62
[Train] Epoch: 5 [346368/387873]    Loss: 0.002651   Batch Acc: 85.94
[Train] Epoch: 5 [346496/387873]    Loss: 0.002228   Batch Acc: 88.28
[Train] Epoch: 5 [346624/387873]    Loss: 0.002334   Batch Acc: 88.28
[Train] Epoch: 5 [346752/387873]    Loss: 0.002486   Batch Acc: 84.38
[Train] Epoch: 5 [346880/387873]    Loss: 0.002432   Batch Acc: 88.28
[Train] Epoch: 5 [347008/387873]    Loss: 0.002691   Batch Acc: 86.72
[Train] Epoch: 5 [347136/387873]    Loss: 0.002036   Batch Acc: 87.50
[Train] Epoch: 5 [347264/387873]    Loss: 0.001817   Batch Acc: 89.06
[Train] Epoch: 5 [347392/387873]    Loss: 0.002185   Batch Acc: 85.94
[Train] Epoch: 5 [347520/387873]    Loss: 0.002044   Batch Acc: 91.41
[Train] Epoch: 5 [347648/387873]    Loss: 0.001710   Batch Acc: 93.75
[Train] Epoch: 5 [347776/387873]    Loss: 0.002152   Batch Acc: 86.72
[Train] Epoch: 5 [347904/387873]    Loss: 0.001697   Batch Acc: 92.97
[Train] Epoch: 5 [348032/387873]    Loss: 0.002399   Batch Acc: 89.06
[Train] Epoch: 5 [348160/387873]    Loss: 0.002166   Batch Acc: 88.28
[Train] Epoch: 5 [348288/387873]    Loss: 0.002059   Batch Acc: 89.84
[Train] Epoch: 5 [348416/387873]    Loss: 0.001900   Batch Acc: 88.28
[Train] Epoch: 5 [348544/387873]    Loss: 0.002714   Batch Acc: 83.59
[Train] Epoch: 5 [348672/387873]    Loss: 0.001942   Batch Acc: 87.50
[Train] Epoch: 5 [348800/387873]    Loss: 0.002279   Batch Acc: 86.72
[Train] Epoch: 5 [348928/387873]    Loss: 0.002015   Batch Acc: 88.28
[Train] Epoch: 5 [349056/387873]    Loss: 0.002206   Batch Acc: 87.50
[Train] Epoch: 5 [349184/387873]    Loss: 0.002059   Batch Acc: 85.94
[Train] Epoch: 5 [349312/387873]    Loss: 0.002561   Batch Acc: 85.94
[Train] Epoch: 5 [349440/387873]    Loss: 0.001692   Batch Acc: 89.84
[Train] Epoch: 5 [349568/387873]    Loss: 0.002437   Batch Acc: 85.94
[Train] Epoch: 5 [349696/387873]    Loss: 0.002321   Batch Acc: 87.50
[Train] Epoch: 5 [349824/387873]    Loss: 0.001884   Batch Acc: 89.06
[Train] Epoch: 5 [349952/387873]    Loss: 0.002037   Batch Acc: 89.84
[Train] Epoch: 5 [350080/387873]    Loss: 0.002550   Batch Acc: 84.38
[Train] Epoch: 5 [350208/387873]    Loss: 0.001956   Batch Acc: 89.84
[Train] Epoch: 5 [350336/387873]    Loss: 0.001967   Batch Acc: 88.28
[Train] Epoch: 5 [350464/387873]    Loss: 0.001631   Batch Acc: 91.41
[Train] Epoch: 5 [350592/387873]    Loss: 0.001886   Batch Acc: 89.06
[Train] Epoch: 5 [350720/387873]    Loss: 0.001695   Batch Acc: 94.53
[Train] Epoch: 5 [350848/387873]    Loss: 0.001522   Batch Acc: 90.62
[Train] Epoch: 5 [350976/387873]    Loss: 0.001950   Batch Acc: 89.84
[Train] Epoch: 5 [351104/387873]    Loss: 0.002447   Batch Acc: 86.72
[Train] Epoch: 5 [351232/387873]    Loss: 0.001887   Batch Acc: 90.62
[Train] Epoch: 5 [351360/387873]    Loss: 0.001966   Batch Acc: 89.06
[Train] Epoch: 5 [351488/387873]    Loss: 0.001689   Batch Acc: 90.62
[Train] Epoch: 5 [351616/387873]    Loss: 0.001482   Batch Acc: 93.75
[Train] Epoch: 5 [351744/387873]    Loss: 0.001745   Batch Acc: 92.19
[Train] Epoch: 5 [351872/387873]    Loss: 0.001905   Batch Acc: 87.50
[Train] Epoch: 5 [352000/387873]    Loss: 0.001969   Batch Acc: 90.62
[Train] Epoch: 5 [352128/387873]    Loss: 0.002141   Batch Acc: 87.50
[Train] Epoch: 5 [352256/387873]    Loss: 0.001820   Batch Acc: 93.75
[Train] Epoch: 5 [352384/387873]    Loss: 0.001898   Batch Acc: 92.19
[Train] Epoch: 5 [352512/387873]    Loss: 0.001703   Batch Acc: 89.84
[Train] Epoch: 5 [352640/387873]    Loss: 0.002159   Batch Acc: 87.50
[Train] Epoch: 5 [352768/387873]    Loss: 0.002029   Batch Acc: 85.16
[Train] Epoch: 5 [352896/387873]    Loss: 0.001919   Batch Acc: 90.62
[Train] Epoch: 5 [353024/387873]    Loss: 0.002046   Batch Acc: 87.50
[Train] Epoch: 5 [353152/387873]    Loss: 0.001924   Batch Acc: 90.62
[Train] Epoch: 5 [353280/387873]    Loss: 0.002362   Batch Acc: 85.16
[Train] Epoch: 5 [353408/387873]    Loss: 0.001776   Batch Acc: 91.41
[Train] Epoch: 5 [353536/387873]    Loss: 0.002484   Batch Acc: 85.16
[Train] Epoch: 5 [353664/387873]    Loss: 0.002044   Batch Acc: 89.84
[Train] Epoch: 5 [353792/387873]    Loss: 0.001316   Batch Acc: 94.53
[Train] Epoch: 5 [353920/387873]    Loss: 0.002213   Batch Acc: 88.28
[Train] Epoch: 5 [354048/387873]    Loss: 0.002338   Batch Acc: 85.94
[Train] Epoch: 5 [354176/387873]    Loss: 0.001962   Batch Acc: 86.72
[Train] Epoch: 5 [354304/387873]    Loss: 0.002713   Batch Acc: 88.28
[Train] Epoch: 5 [354432/387873]    Loss: 0.002053   Batch Acc: 89.84
[Train] Epoch: 5 [354560/387873]    Loss: 0.001642   Batch Acc: 92.97
[Train] Epoch: 5 [354688/387873]    Loss: 0.001583   Batch Acc: 90.62
[Train] Epoch: 5 [354816/387873]    Loss: 0.002141   Batch Acc: 89.06
[Train] Epoch: 5 [354944/387873]    Loss: 0.001596   Batch Acc: 92.19
[Train] Epoch: 5 [355072/387873]    Loss: 0.001685   Batch Acc: 92.97
[Train] Epoch: 5 [355200/387873]    Loss: 0.001798   Batch Acc: 88.28
[Train] Epoch: 5 [355328/387873]    Loss: 0.002106   Batch Acc: 86.72
[Train] Epoch: 5 [355456/387873]    Loss: 0.001861   Batch Acc: 91.41
[Train] Epoch: 5 [355584/387873]    Loss: 0.001837   Batch Acc: 90.62
[Train] Epoch: 5 [355712/387873]    Loss: 0.001619   Batch Acc: 92.97
[Train] Epoch: 5 [355840/387873]    Loss: 0.002528   Batch Acc: 85.94
[Train] Epoch: 5 [355968/387873]    Loss: 0.002295   Batch Acc: 88.28
[Train] Epoch: 5 [356096/387873]    Loss: 0.002893   Batch Acc: 82.81
[Train] Epoch: 5 [356224/387873]    Loss: 0.002161   Batch Acc: 85.94
[Train] Epoch: 5 [356352/387873]    Loss: 0.001930   Batch Acc: 88.28
[Train] Epoch: 5 [356480/387873]    Loss: 0.002522   Batch Acc: 88.28
[Train] Epoch: 5 [356608/387873]    Loss: 0.002110   Batch Acc: 89.84
[Train] Epoch: 5 [356736/387873]    Loss: 0.002262   Batch Acc: 89.84
[Train] Epoch: 5 [356864/387873]    Loss: 0.002229   Batch Acc: 89.06
[Train] Epoch: 5 [356992/387873]    Loss: 0.002022   Batch Acc: 89.06
[Train] Epoch: 5 [357120/387873]    Loss: 0.001524   Batch Acc: 92.97
[Train] Epoch: 5 [357248/387873]    Loss: 0.002385   Batch Acc: 84.38
[Train] Epoch: 5 [357376/387873]    Loss: 0.001597   Batch Acc: 92.97
[Train] Epoch: 5 [357504/387873]    Loss: 0.001646   Batch Acc: 90.62
[Train] Epoch: 5 [357632/387873]    Loss: 0.001946   Batch Acc: 89.84
[Train] Epoch: 5 [357760/387873]    Loss: 0.001890   Batch Acc: 88.28
[Train] Epoch: 5 [357888/387873]    Loss: 0.002084   Batch Acc: 85.16
[Train] Epoch: 5 [358016/387873]    Loss: 0.002308   Batch Acc: 87.50
[Train] Epoch: 5 [358144/387873]    Loss: 0.002729   Batch Acc: 85.94
[Train] Epoch: 5 [358272/387873]    Loss: 0.002405   Batch Acc: 85.94
[Train] Epoch: 5 [358400/387873]    Loss: 0.001405   Batch Acc: 93.75
[Train] Epoch: 5 [358528/387873]    Loss: 0.002325   Batch Acc: 85.94
[Train] Epoch: 5 [358656/387873]    Loss: 0.001687   Batch Acc: 90.62
[Train] Epoch: 5 [358784/387873]    Loss: 0.001789   Batch Acc: 90.62
[Train] Epoch: 5 [358912/387873]    Loss: 0.001876   Batch Acc: 87.50
[Train] Epoch: 5 [359040/387873]    Loss: 0.001857   Batch Acc: 89.84
[Train] Epoch: 5 [359168/387873]    Loss: 0.001997   Batch Acc: 88.28
[Train] Epoch: 5 [359296/387873]    Loss: 0.001260   Batch Acc: 93.75
[Train] Epoch: 5 [359424/387873]    Loss: 0.001741   Batch Acc: 90.62
[Train] Epoch: 5 [359552/387873]    Loss: 0.001669   Batch Acc: 91.41
[Train] Epoch: 5 [359680/387873]    Loss: 0.002404   Batch Acc: 86.72
[Train] Epoch: 5 [359808/387873]    Loss: 0.002184   Batch Acc: 87.50
[Train] Epoch: 5 [359936/387873]    Loss: 0.002277   Batch Acc: 87.50
[Train] Epoch: 5 [360064/387873]    Loss: 0.001869   Batch Acc: 89.84
[Train] Epoch: 5 [360192/387873]    Loss: 0.001906   Batch Acc: 89.06
[Train] Epoch: 5 [360320/387873]    Loss: 0.001171   Batch Acc: 96.88
[Train] Epoch: 5 [360448/387873]    Loss: 0.001659   Batch Acc: 89.84
[Train] Epoch: 5 [360576/387873]    Loss: 0.001696   Batch Acc: 91.41
[Train] Epoch: 5 [360704/387873]    Loss: 0.002016   Batch Acc: 89.84
[Train] Epoch: 5 [360832/387873]    Loss: 0.001837   Batch Acc: 92.97
[Train] Epoch: 5 [360960/387873]    Loss: 0.002285   Batch Acc: 85.16
[Train] Epoch: 5 [361088/387873]    Loss: 0.002570   Batch Acc: 85.16
[Train] Epoch: 5 [361216/387873]    Loss: 0.001394   Batch Acc: 92.97
[Train] Epoch: 5 [361344/387873]    Loss: 0.002050   Batch Acc: 90.62
[Train] Epoch: 5 [361472/387873]    Loss: 0.002783   Batch Acc: 85.16
[Train] Epoch: 5 [361600/387873]    Loss: 0.001660   Batch Acc: 89.06
[Train] Epoch: 5 [361728/387873]    Loss: 0.002127   Batch Acc: 87.50
[Train] Epoch: 5 [361856/387873]    Loss: 0.001570   Batch Acc: 92.19
[Train] Epoch: 5 [361984/387873]    Loss: 0.001841   Batch Acc: 91.41
[Train] Epoch: 5 [362112/387873]    Loss: 0.001568   Batch Acc: 92.19
[Train] Epoch: 5 [362240/387873]    Loss: 0.001969   Batch Acc: 91.41
[Train] Epoch: 5 [362368/387873]    Loss: 0.001681   Batch Acc: 93.75
[Train] Epoch: 5 [362496/387873]    Loss: 0.001796   Batch Acc: 91.41
[Train] Epoch: 5 [362624/387873]    Loss: 0.001929   Batch Acc: 91.41
[Train] Epoch: 5 [362752/387873]    Loss: 0.002239   Batch Acc: 85.94
[Train] Epoch: 5 [362880/387873]    Loss: 0.002080   Batch Acc: 89.06
[Train] Epoch: 5 [363008/387873]    Loss: 0.002843   Batch Acc: 82.81
[Train] Epoch: 5 [363136/387873]    Loss: 0.001452   Batch Acc: 94.53
[Train] Epoch: 5 [363264/387873]    Loss: 0.002303   Batch Acc: 89.06
[Train] Epoch: 5 [363392/387873]    Loss: 0.002400   Batch Acc: 87.50
[Train] Epoch: 5 [363520/387873]    Loss: 0.001864   Batch Acc: 89.84
[Train] Epoch: 5 [363648/387873]    Loss: 0.001947   Batch Acc: 88.28
[Train] Epoch: 5 [363776/387873]    Loss: 0.001988   Batch Acc: 89.84
[Train] Epoch: 5 [363904/387873]    Loss: 0.002294   Batch Acc: 88.28
[Train] Epoch: 5 [364032/387873]    Loss: 0.002452   Batch Acc: 87.50
[Train] Epoch: 5 [364160/387873]    Loss: 0.002072   Batch Acc: 88.28
[Train] Epoch: 5 [364288/387873]    Loss: 0.002306   Batch Acc: 88.28
[Train] Epoch: 5 [364416/387873]    Loss: 0.002230   Batch Acc: 84.38
[Train] Epoch: 5 [364544/387873]    Loss: 0.001625   Batch Acc: 91.41
[Train] Epoch: 5 [364672/387873]    Loss: 0.001753   Batch Acc: 91.41
[Train] Epoch: 5 [364800/387873]    Loss: 0.001872   Batch Acc: 92.97
[Train] Epoch: 5 [364928/387873]    Loss: 0.001351   Batch Acc: 94.53
[Train] Epoch: 5 [365056/387873]    Loss: 0.002079   Batch Acc: 89.84
[Train] Epoch: 5 [365184/387873]    Loss: 0.002777   Batch Acc: 81.25
[Train] Epoch: 5 [365312/387873]    Loss: 0.001803   Batch Acc: 91.41
[Train] Epoch: 5 [365440/387873]    Loss: 0.002146   Batch Acc: 87.50
[Train] Epoch: 5 [365568/387873]    Loss: 0.001623   Batch Acc: 90.62
[Train] Epoch: 5 [365696/387873]    Loss: 0.001511   Batch Acc: 96.09
[Train] Epoch: 5 [365824/387873]    Loss: 0.002025   Batch Acc: 89.84
[Train] Epoch: 5 [365952/387873]    Loss: 0.001552   Batch Acc: 92.19
[Train] Epoch: 5 [366080/387873]    Loss: 0.001779   Batch Acc: 89.84
[Train] Epoch: 5 [366208/387873]    Loss: 0.001673   Batch Acc: 91.41
[Train] Epoch: 5 [366336/387873]    Loss: 0.001886   Batch Acc: 89.84
[Train] Epoch: 5 [366464/387873]    Loss: 0.002343   Batch Acc: 86.72
[Train] Epoch: 5 [366592/387873]    Loss: 0.001980   Batch Acc: 91.41
[Train] Epoch: 5 [366720/387873]    Loss: 0.001516   Batch Acc: 93.75
[Train] Epoch: 5 [366848/387873]    Loss: 0.001996   Batch Acc: 87.50
[Train] Epoch: 5 [366976/387873]    Loss: 0.002069   Batch Acc: 86.72
[Train] Epoch: 5 [367104/387873]    Loss: 0.001779   Batch Acc: 91.41
[Train] Epoch: 5 [367232/387873]    Loss: 0.001594   Batch Acc: 92.19
[Train] Epoch: 5 [367360/387873]    Loss: 0.001850   Batch Acc: 91.41
[Train] Epoch: 5 [367488/387873]    Loss: 0.002176   Batch Acc: 87.50
[Train] Epoch: 5 [367616/387873]    Loss: 0.002172   Batch Acc: 87.50
[Train] Epoch: 5 [367744/387873]    Loss: 0.001370   Batch Acc: 95.31
[Train] Epoch: 5 [367872/387873]    Loss: 0.002272   Batch Acc: 85.94
[Train] Epoch: 5 [368000/387873]    Loss: 0.002808   Batch Acc: 83.59
[Train] Epoch: 5 [368128/387873]    Loss: 0.002177   Batch Acc: 90.62
[Train] Epoch: 5 [368256/387873]    Loss: 0.002220   Batch Acc: 85.94
[Train] Epoch: 5 [368384/387873]    Loss: 0.002233   Batch Acc: 86.72
[Train] Epoch: 5 [368512/387873]    Loss: 0.001963   Batch Acc: 90.62
[Train] Epoch: 5 [368640/387873]    Loss: 0.002044   Batch Acc: 89.06
[Train] Epoch: 5 [368768/387873]    Loss: 0.001874   Batch Acc: 91.41
[Train] Epoch: 5 [368896/387873]    Loss: 0.002004   Batch Acc: 89.84
[Train] Epoch: 5 [369024/387873]    Loss: 0.002150   Batch Acc: 86.72
[Train] Epoch: 5 [369152/387873]    Loss: 0.002188   Batch Acc: 90.62
[Train] Epoch: 5 [369280/387873]    Loss: 0.001592   Batch Acc: 90.62
[Train] Epoch: 5 [369408/387873]    Loss: 0.001829   Batch Acc: 87.50
[Train] Epoch: 5 [369536/387873]    Loss: 0.002434   Batch Acc: 85.94
[Train] Epoch: 5 [369664/387873]    Loss: 0.002147   Batch Acc: 87.50
[Train] Epoch: 5 [369792/387873]    Loss: 0.001637   Batch Acc: 91.41
[Train] Epoch: 5 [369920/387873]    Loss: 0.001848   Batch Acc: 92.97
[Train] Epoch: 5 [370048/387873]    Loss: 0.001794   Batch Acc: 91.41
[Train] Epoch: 5 [370176/387873]    Loss: 0.001694   Batch Acc: 92.19
[Train] Epoch: 5 [370304/387873]    Loss: 0.001778   Batch Acc: 91.41
[Train] Epoch: 5 [370432/387873]    Loss: 0.001888   Batch Acc: 91.41
[Train] Epoch: 5 [370560/387873]    Loss: 0.001870   Batch Acc: 88.28
[Train] Epoch: 5 [370688/387873]    Loss: 0.001892   Batch Acc: 90.62
[Train] Epoch: 5 [370816/387873]    Loss: 0.002720   Batch Acc: 85.94
[Train] Epoch: 5 [370944/387873]    Loss: 0.002504   Batch Acc: 83.59
[Train] Epoch: 5 [371072/387873]    Loss: 0.001529   Batch Acc: 94.53
[Train] Epoch: 5 [371200/387873]    Loss: 0.001980   Batch Acc: 89.06
[Train] Epoch: 5 [371328/387873]    Loss: 0.002155   Batch Acc: 89.06
[Train] Epoch: 5 [371456/387873]    Loss: 0.001618   Batch Acc: 92.19
[Train] Epoch: 5 [371584/387873]    Loss: 0.001669   Batch Acc: 91.41
[Train] Epoch: 5 [371712/387873]    Loss: 0.001757   Batch Acc: 89.84
[Train] Epoch: 5 [371840/387873]    Loss: 0.002410   Batch Acc: 83.59
[Train] Epoch: 5 [371968/387873]    Loss: 0.002205   Batch Acc: 86.72
[Train] Epoch: 5 [372096/387873]    Loss: 0.001569   Batch Acc: 91.41
[Train] Epoch: 5 [372224/387873]    Loss: 0.001533   Batch Acc: 92.97
[Train] Epoch: 5 [372352/387873]    Loss: 0.002052   Batch Acc: 90.62
[Train] Epoch: 5 [372480/387873]    Loss: 0.001842   Batch Acc: 90.62
[Train] Epoch: 5 [372608/387873]    Loss: 0.001970   Batch Acc: 90.62
[Train] Epoch: 5 [372736/387873]    Loss: 0.001447   Batch Acc: 92.97
[Train] Epoch: 5 [372864/387873]    Loss: 0.001589   Batch Acc: 92.19
[Train] Epoch: 5 [372992/387873]    Loss: 0.002636   Batch Acc: 85.94
[Train] Epoch: 5 [373120/387873]    Loss: 0.002139   Batch Acc: 88.28
[Train] Epoch: 5 [373248/387873]    Loss: 0.001863   Batch Acc: 88.28
[Train] Epoch: 5 [373376/387873]    Loss: 0.001444   Batch Acc: 93.75
[Train] Epoch: 5 [373504/387873]    Loss: 0.001931   Batch Acc: 90.62
[Train] Epoch: 5 [373632/387873]    Loss: 0.002267   Batch Acc: 89.84
[Train] Epoch: 5 [373760/387873]    Loss: 0.001398   Batch Acc: 92.97
[Train] Epoch: 5 [373888/387873]    Loss: 0.001978   Batch Acc: 91.41
[Train] Epoch: 5 [374016/387873]    Loss: 0.001670   Batch Acc: 92.19
[Train] Epoch: 5 [374144/387873]    Loss: 0.002388   Batch Acc: 83.59
[Train] Epoch: 5 [374272/387873]    Loss: 0.002085   Batch Acc: 89.06
[Train] Epoch: 5 [374400/387873]    Loss: 0.002051   Batch Acc: 89.84
[Train] Epoch: 5 [374528/387873]    Loss: 0.001974   Batch Acc: 88.28
[Train] Epoch: 5 [374656/387873]    Loss: 0.001835   Batch Acc: 90.62
[Train] Epoch: 5 [374784/387873]    Loss: 0.001306   Batch Acc: 93.75
[Train] Epoch: 5 [374912/387873]    Loss: 0.002362   Batch Acc: 86.72
[Train] Epoch: 5 [375040/387873]    Loss: 0.002232   Batch Acc: 89.06
[Train] Epoch: 5 [375168/387873]    Loss: 0.001702   Batch Acc: 89.84
[Train] Epoch: 5 [375296/387873]    Loss: 0.002458   Batch Acc: 86.72
[Train] Epoch: 5 [375424/387873]    Loss: 0.002542   Batch Acc: 84.38
[Train] Epoch: 5 [375552/387873]    Loss: 0.002233   Batch Acc: 87.50
[Train] Epoch: 5 [375680/387873]    Loss: 0.001671   Batch Acc: 91.41
[Train] Epoch: 5 [375808/387873]    Loss: 0.001812   Batch Acc: 87.50
[Train] Epoch: 5 [375936/387873]    Loss: 0.001568   Batch Acc: 90.62
[Train] Epoch: 5 [376064/387873]    Loss: 0.002197   Batch Acc: 86.72
[Train] Epoch: 5 [376192/387873]    Loss: 0.002060   Batch Acc: 88.28
[Train] Epoch: 5 [376320/387873]    Loss: 0.001958   Batch Acc: 90.62
[Train] Epoch: 5 [376448/387873]    Loss: 0.002202   Batch Acc: 88.28
[Train] Epoch: 5 [376576/387873]    Loss: 0.001932   Batch Acc: 91.41
[Train] Epoch: 5 [376704/387873]    Loss: 0.001968   Batch Acc: 88.28
[Train] Epoch: 5 [376832/387873]    Loss: 0.002307   Batch Acc: 85.16
[Train] Epoch: 5 [376960/387873]    Loss: 0.001928   Batch Acc: 85.94
[Train] Epoch: 5 [377088/387873]    Loss: 0.001742   Batch Acc: 92.19
[Train] Epoch: 5 [377216/387873]    Loss: 0.001786   Batch Acc: 89.84
[Train] Epoch: 5 [377344/387873]    Loss: 0.002284   Batch Acc: 85.94
[Train] Epoch: 5 [377472/387873]    Loss: 0.001972   Batch Acc: 88.28
[Train] Epoch: 5 [377600/387873]    Loss: 0.002148   Batch Acc: 89.84
[Train] Epoch: 5 [377728/387873]    Loss: 0.002072   Batch Acc: 89.06
[Train] Epoch: 5 [377856/387873]    Loss: 0.001666   Batch Acc: 92.97
[Train] Epoch: 5 [377984/387873]    Loss: 0.002314   Batch Acc: 87.50
[Train] Epoch: 5 [378112/387873]    Loss: 0.001686   Batch Acc: 92.97
[Train] Epoch: 5 [378240/387873]    Loss: 0.002181   Batch Acc: 88.28
[Train] Epoch: 5 [378368/387873]    Loss: 0.001489   Batch Acc: 95.31
[Train] Epoch: 5 [378496/387873]    Loss: 0.002160   Batch Acc: 82.03
[Train] Epoch: 5 [378624/387873]    Loss: 0.002382   Batch Acc: 86.72
[Train] Epoch: 5 [378752/387873]    Loss: 0.002061   Batch Acc: 89.06
[Train] Epoch: 5 [378880/387873]    Loss: 0.002109   Batch Acc: 87.50
[Train] Epoch: 5 [379008/387873]    Loss: 0.001376   Batch Acc: 96.88
[Train] Epoch: 5 [379136/387873]    Loss: 0.002081   Batch Acc: 89.06
[Train] Epoch: 5 [379264/387873]    Loss: 0.002520   Batch Acc: 81.25
[Train] Epoch: 5 [379392/387873]    Loss: 0.001666   Batch Acc: 92.19
[Train] Epoch: 5 [379520/387873]    Loss: 0.002415   Batch Acc: 84.38
[Train] Epoch: 5 [379648/387873]    Loss: 0.002513   Batch Acc: 88.28
[Train] Epoch: 5 [379776/387873]    Loss: 0.001673   Batch Acc: 93.75
[Train] Epoch: 5 [379904/387873]    Loss: 0.002326   Batch Acc: 85.16
[Train] Epoch: 5 [380032/387873]    Loss: 0.002203   Batch Acc: 88.28
[Train] Epoch: 5 [380160/387873]    Loss: 0.001511   Batch Acc: 96.09
[Train] Epoch: 5 [380288/387873]    Loss: 0.002187   Batch Acc: 85.94
[Train] Epoch: 5 [380416/387873]    Loss: 0.001789   Batch Acc: 93.75
[Train] Epoch: 5 [380544/387873]    Loss: 0.001976   Batch Acc: 88.28
[Train] Epoch: 5 [380672/387873]    Loss: 0.001916   Batch Acc: 90.62
[Train] Epoch: 5 [380800/387873]    Loss: 0.001512   Batch Acc: 92.97
[Train] Epoch: 5 [380928/387873]    Loss: 0.002316   Batch Acc: 86.72
[Train] Epoch: 5 [381056/387873]    Loss: 0.001519   Batch Acc: 90.62
[Train] Epoch: 5 [381184/387873]    Loss: 0.002272   Batch Acc: 85.16
[Train] Epoch: 5 [381312/387873]    Loss: 0.002539   Batch Acc: 84.38
[Train] Epoch: 5 [381440/387873]    Loss: 0.002336   Batch Acc: 85.16
[Train] Epoch: 5 [381568/387873]    Loss: 0.002372   Batch Acc: 89.84
[Train] Epoch: 5 [381696/387873]    Loss: 0.002097   Batch Acc: 88.28
[Train] Epoch: 5 [381824/387873]    Loss: 0.002093   Batch Acc: 88.28
[Train] Epoch: 5 [381952/387873]    Loss: 0.002361   Batch Acc: 86.72
[Train] Epoch: 5 [382080/387873]    Loss: 0.002325   Batch Acc: 87.50
[Train] Epoch: 5 [382208/387873]    Loss: 0.002290   Batch Acc: 87.50
[Train] Epoch: 5 [382336/387873]    Loss: 0.001757   Batch Acc: 89.06
[Train] Epoch: 5 [382464/387873]    Loss: 0.002080   Batch Acc: 89.06
[Train] Epoch: 5 [382592/387873]    Loss: 0.001847   Batch Acc: 91.41
[Train] Epoch: 5 [382720/387873]    Loss: 0.002057   Batch Acc: 87.50
[Train] Epoch: 5 [382848/387873]    Loss: 0.001948   Batch Acc: 88.28
[Train] Epoch: 5 [382976/387873]    Loss: 0.002083   Batch Acc: 90.62
[Train] Epoch: 5 [383104/387873]    Loss: 0.001661   Batch Acc: 92.97
[Train] Epoch: 5 [383232/387873]    Loss: 0.002006   Batch Acc: 89.06
[Train] Epoch: 5 [383360/387873]    Loss: 0.002252   Batch Acc: 89.06
[Train] Epoch: 5 [383488/387873]    Loss: 0.001841   Batch Acc: 90.62
[Train] Epoch: 5 [383616/387873]    Loss: 0.001915   Batch Acc: 88.28
[Train] Epoch: 5 [383744/387873]    Loss: 0.001179   Batch Acc: 95.31
[Train] Epoch: 5 [383872/387873]    Loss: 0.002005   Batch Acc: 92.97
[Train] Epoch: 5 [384000/387873]    Loss: 0.001880   Batch Acc: 91.41
[Train] Epoch: 5 [384128/387873]    Loss: 0.001856   Batch Acc: 89.84
[Train] Epoch: 5 [384256/387873]    Loss: 0.002920   Batch Acc: 83.59
[Train] Epoch: 5 [384384/387873]    Loss: 0.001779   Batch Acc: 89.84
[Train] Epoch: 5 [384512/387873]    Loss: 0.001601   Batch Acc: 88.28
[Train] Epoch: 5 [384640/387873]    Loss: 0.002149   Batch Acc: 90.62
[Train] Epoch: 5 [384768/387873]    Loss: 0.002423   Batch Acc: 87.50
[Train] Epoch: 5 [384896/387873]    Loss: 0.001675   Batch Acc: 90.62
[Train] Epoch: 5 [385024/387873]    Loss: 0.002095   Batch Acc: 87.50
[Train] Epoch: 5 [385152/387873]    Loss: 0.001411   Batch Acc: 94.53
[Train] Epoch: 5 [385280/387873]    Loss: 0.002161   Batch Acc: 89.06
[Train] Epoch: 5 [385408/387873]    Loss: 0.002062   Batch Acc: 91.41
[Train] Epoch: 5 [385536/387873]    Loss: 0.001569   Batch Acc: 93.75
[Train] Epoch: 5 [385664/387873]    Loss: 0.001434   Batch Acc: 94.53
[Train] Epoch: 5 [385792/387873]    Loss: 0.002455   Batch Acc: 87.50
[Train] Epoch: 5 [385920/387873]    Loss: 0.002114   Batch Acc: 89.06
[Train] Epoch: 5 [386048/387873]    Loss: 0.001682   Batch Acc: 92.97
[Train] Epoch: 5 [386176/387873]    Loss: 0.002102   Batch Acc: 88.28
[Train] Epoch: 5 [386304/387873]    Loss: 0.002292   Batch Acc: 88.28
[Train] Epoch: 5 [386432/387873]    Loss: 0.001810   Batch Acc: 90.62
[Train] Epoch: 5 [386560/387873]    Loss: 0.001725   Batch Acc: 89.84
[Train] Epoch: 5 [386688/387873]    Loss: 0.001898   Batch Acc: 89.06
[Train] Epoch: 5 [386816/387873]    Loss: 0.002201   Batch Acc: 89.84
[Train] Epoch: 5 [386944/387873]    Loss: 0.001995   Batch Acc: 88.28
[Train] Epoch: 5 [387072/387873]    Loss: 0.002128   Batch Acc: 88.28
[Train] Epoch: 5 [387200/387873]    Loss: 0.002395   Batch Acc: 84.38
[Train] Epoch: 5 [387328/387873]    Loss: 0.001774   Batch Acc: 92.19
[Train] Epoch: 5 [387456/387873]    Loss: 0.001308   Batch Acc: 94.53
[Train] Epoch: 5 [387584/387873]    Loss: 0.001845   Batch Acc: 91.41
[Train] Epoch: 5 [387712/387873]    Loss: 0.001619   Batch Acc: 93.75
[Train] Epoch: 5 [387840/387873]    Loss: 0.002088   Batch Acc: 84.38
[Train] Epoch: 5 [100023/387873]    Loss: 0.005548   Batch Acc: 90.91
Validation Done: [128/84203]
Validation Done: [256/84203]
Validation Done: [384/84203]
Validation Done: [512/84203]
Validation Done: [640/84203]
Validation Done: [768/84203]
Validation Done: [896/84203]
Validation Done: [1024/84203]
Validation Done: [1152/84203]
Validation Done: [1280/84203]
Validation Done: [1408/84203]
Validation Done: [1536/84203]
Validation Done: [1664/84203]
Validation Done: [1792/84203]
Validation Done: [1920/84203]
Validation Done: [2048/84203]
Validation Done: [2176/84203]
Validation Done: [2304/84203]
Validation Done: [2432/84203]
Validation Done: [2560/84203]
Validation Done: [2688/84203]
Validation Done: [2816/84203]
Validation Done: [2944/84203]
Validation Done: [3072/84203]
Validation Done: [3200/84203]
Validation Done: [3328/84203]
Validation Done: [3456/84203]
Validation Done: [3584/84203]
Validation Done: [3712/84203]
Validation Done: [3840/84203]
Validation Done: [3968/84203]
Validation Done: [4096/84203]
Validation Done: [4224/84203]
Validation Done: [4352/84203]
Validation Done: [4480/84203]
Validation Done: [4608/84203]
Validation Done: [4736/84203]
Validation Done: [4864/84203]
Validation Done: [4992/84203]
Validation Done: [5120/84203]
Validation Done: [5248/84203]
Validation Done: [5376/84203]
Validation Done: [5504/84203]
Validation Done: [5632/84203]
Validation Done: [5760/84203]
Validation Done: [5888/84203]
Validation Done: [6016/84203]
Validation Done: [6144/84203]
Validation Done: [6272/84203]
Validation Done: [6400/84203]
Validation Done: [6528/84203]
Validation Done: [6656/84203]
Validation Done: [6784/84203]
Validation Done: [6912/84203]
Validation Done: [7040/84203]
Validation Done: [7168/84203]
Validation Done: [7296/84203]
Validation Done: [7424/84203]
Validation Done: [7552/84203]
Validation Done: [7680/84203]
Validation Done: [7808/84203]
Validation Done: [7936/84203]
Validation Done: [8064/84203]
Validation Done: [8192/84203]
Validation Done: [8320/84203]
Validation Done: [8448/84203]
Validation Done: [8576/84203]
Validation Done: [8704/84203]
Validation Done: [8832/84203]
Validation Done: [8960/84203]
Validation Done: [9088/84203]
Validation Done: [9216/84203]
Validation Done: [9344/84203]
Validation Done: [9472/84203]
Validation Done: [9600/84203]
Validation Done: [9728/84203]
Validation Done: [9856/84203]
Validation Done: [9984/84203]
Validation Done: [10112/84203]
Validation Done: [10240/84203]
Validation Done: [10368/84203]
Validation Done: [10496/84203]
Validation Done: [10624/84203]
Validation Done: [10752/84203]
Validation Done: [10880/84203]
Validation Done: [11008/84203]
Validation Done: [11136/84203]
Validation Done: [11264/84203]
Validation Done: [11392/84203]
Validation Done: [11520/84203]
Validation Done: [11648/84203]
Validation Done: [11776/84203]
Validation Done: [11904/84203]
Validation Done: [12032/84203]
Validation Done: [12160/84203]
Validation Done: [12288/84203]
Validation Done: [12416/84203]
Validation Done: [12544/84203]
Validation Done: [12672/84203]
Validation Done: [12800/84203]
Validation Done: [12928/84203]
Validation Done: [13056/84203]
Validation Done: [13184/84203]
Validation Done: [13312/84203]
Validation Done: [13440/84203]
Validation Done: [13568/84203]
Validation Done: [13696/84203]
Validation Done: [13824/84203]
Validation Done: [13952/84203]
Validation Done: [14080/84203]
Validation Done: [14208/84203]
Validation Done: [14336/84203]
Validation Done: [14464/84203]
Validation Done: [14592/84203]
Validation Done: [14720/84203]
Validation Done: [14848/84203]
Validation Done: [14976/84203]
Validation Done: [15104/84203]
Validation Done: [15232/84203]
Validation Done: [15360/84203]
Validation Done: [15488/84203]
Validation Done: [15616/84203]
Validation Done: [15744/84203]
Validation Done: [15872/84203]
Validation Done: [16000/84203]
Validation Done: [16128/84203]
Validation Done: [16256/84203]
Validation Done: [16384/84203]
Validation Done: [16512/84203]
Validation Done: [16640/84203]
Validation Done: [16768/84203]
Validation Done: [16896/84203]
Validation Done: [17024/84203]
Validation Done: [17152/84203]
Validation Done: [17280/84203]
Validation Done: [17408/84203]
Validation Done: [17536/84203]
Validation Done: [17664/84203]
Validation Done: [17792/84203]
Validation Done: [17920/84203]
Validation Done: [18048/84203]
Validation Done: [18176/84203]
Validation Done: [18304/84203]
Validation Done: [18432/84203]
Validation Done: [18560/84203]
Validation Done: [18688/84203]
Validation Done: [18816/84203]
Validation Done: [18944/84203]
Validation Done: [19072/84203]
Validation Done: [19200/84203]
Validation Done: [19328/84203]
Validation Done: [19456/84203]
Validation Done: [19584/84203]
Validation Done: [19712/84203]
Validation Done: [19840/84203]
Validation Done: [19968/84203]
Validation Done: [20096/84203]
Validation Done: [20224/84203]
Validation Done: [20352/84203]
Validation Done: [20480/84203]
Validation Done: [20608/84203]
Validation Done: [20736/84203]
Validation Done: [20864/84203]
Validation Done: [20992/84203]
Validation Done: [21120/84203]
Validation Done: [21248/84203]
Validation Done: [21376/84203]
Validation Done: [21504/84203]
Validation Done: [21632/84203]
Validation Done: [21760/84203]
Validation Done: [21888/84203]
Validation Done: [22016/84203]
Validation Done: [22144/84203]
Validation Done: [22272/84203]
Validation Done: [22400/84203]
Validation Done: [22528/84203]
Validation Done: [22656/84203]
Validation Done: [22784/84203]
Validation Done: [22912/84203]
Validation Done: [23040/84203]
Validation Done: [23168/84203]
Validation Done: [23296/84203]
Validation Done: [23424/84203]
Validation Done: [23552/84203]
Validation Done: [23680/84203]
Validation Done: [23808/84203]
Validation Done: [23936/84203]
Validation Done: [24064/84203]
Validation Done: [24192/84203]
Validation Done: [24320/84203]
Validation Done: [24448/84203]
Validation Done: [24576/84203]
Validation Done: [24704/84203]
Validation Done: [24832/84203]
Validation Done: [24960/84203]
Validation Done: [25088/84203]
Validation Done: [25216/84203]
Validation Done: [25344/84203]
Validation Done: [25472/84203]
Validation Done: [25600/84203]
Validation Done: [25728/84203]
Validation Done: [25856/84203]
Validation Done: [25984/84203]
Validation Done: [26112/84203]
Validation Done: [26240/84203]
Validation Done: [26368/84203]
Validation Done: [26496/84203]
Validation Done: [26624/84203]
Validation Done: [26752/84203]
Validation Done: [26880/84203]
Validation Done: [27008/84203]
Validation Done: [27136/84203]
Validation Done: [27264/84203]
Validation Done: [27392/84203]
Validation Done: [27520/84203]
Validation Done: [27648/84203]
Validation Done: [27776/84203]
Validation Done: [27904/84203]
Validation Done: [28032/84203]
Validation Done: [28160/84203]
Validation Done: [28288/84203]
Validation Done: [28416/84203]
Validation Done: [28544/84203]
Validation Done: [28672/84203]
Validation Done: [28800/84203]
Validation Done: [28928/84203]
Validation Done: [29056/84203]
Validation Done: [29184/84203]
Validation Done: [29312/84203]
Validation Done: [29440/84203]
Validation Done: [29568/84203]
Validation Done: [29696/84203]
Validation Done: [29824/84203]
Validation Done: [29952/84203]
Validation Done: [30080/84203]
Validation Done: [30208/84203]
Validation Done: [30336/84203]
Validation Done: [30464/84203]
Validation Done: [30592/84203]
Validation Done: [30720/84203]
Validation Done: [30848/84203]
Validation Done: [30976/84203]
Validation Done: [31104/84203]
Validation Done: [31232/84203]
Validation Done: [31360/84203]
Validation Done: [31488/84203]
Validation Done: [31616/84203]
Validation Done: [31744/84203]
Validation Done: [31872/84203]
Validation Done: [32000/84203]
Validation Done: [32128/84203]
Validation Done: [32256/84203]
Validation Done: [32384/84203]
Validation Done: [32512/84203]
Validation Done: [32640/84203]
Validation Done: [32768/84203]
Validation Done: [32896/84203]
Validation Done: [33024/84203]
Validation Done: [33152/84203]
Validation Done: [33280/84203]
Validation Done: [33408/84203]
Validation Done: [33536/84203]
Validation Done: [33664/84203]
Validation Done: [33792/84203]
Validation Done: [33920/84203]
Validation Done: [34048/84203]
Validation Done: [34176/84203]
Validation Done: [34304/84203]
Validation Done: [34432/84203]
Validation Done: [34560/84203]
Validation Done: [34688/84203]
Validation Done: [34816/84203]
Validation Done: [34944/84203]
Validation Done: [35072/84203]
Validation Done: [35200/84203]
Validation Done: [35328/84203]
Validation Done: [35456/84203]
Validation Done: [35584/84203]
Validation Done: [35712/84203]
Validation Done: [35840/84203]
Validation Done: [35968/84203]
Validation Done: [36096/84203]
Validation Done: [36224/84203]
Validation Done: [36352/84203]
Validation Done: [36480/84203]
Validation Done: [36608/84203]
Validation Done: [36736/84203]
Validation Done: [36864/84203]
Validation Done: [36992/84203]
Validation Done: [37120/84203]
Validation Done: [37248/84203]
Validation Done: [37376/84203]
Validation Done: [37504/84203]
Validation Done: [37632/84203]
Validation Done: [37760/84203]
Validation Done: [37888/84203]
Validation Done: [38016/84203]
Validation Done: [38144/84203]
Validation Done: [38272/84203]
Validation Done: [38400/84203]
Validation Done: [38528/84203]
Validation Done: [38656/84203]
Validation Done: [38784/84203]
Validation Done: [38912/84203]
Validation Done: [39040/84203]
Validation Done: [39168/84203]
Validation Done: [39296/84203]
Validation Done: [39424/84203]
Validation Done: [39552/84203]
Validation Done: [39680/84203]
Validation Done: [39808/84203]
Validation Done: [39936/84203]
Validation Done: [40064/84203]
Validation Done: [40192/84203]
Validation Done: [40320/84203]
Validation Done: [40448/84203]
Validation Done: [40576/84203]
Validation Done: [40704/84203]
Validation Done: [40832/84203]
Validation Done: [40960/84203]
Validation Done: [41088/84203]
Validation Done: [41216/84203]
Validation Done: [41344/84203]
Validation Done: [41472/84203]
Validation Done: [41600/84203]
Validation Done: [41728/84203]
Validation Done: [41856/84203]
Validation Done: [41984/84203]
Validation Done: [42112/84203]
Validation Done: [42240/84203]
Validation Done: [42368/84203]
Validation Done: [42496/84203]
Validation Done: [42624/84203]
Validation Done: [42752/84203]
Validation Done: [42880/84203]
Validation Done: [43008/84203]
Validation Done: [43136/84203]
Validation Done: [43264/84203]
Validation Done: [43392/84203]
Validation Done: [43520/84203]
Validation Done: [43648/84203]
Validation Done: [43776/84203]
Validation Done: [43904/84203]
Validation Done: [44032/84203]
Validation Done: [44160/84203]
Validation Done: [44288/84203]
Validation Done: [44416/84203]
Validation Done: [44544/84203]
Validation Done: [44672/84203]
Validation Done: [44800/84203]
Validation Done: [44928/84203]
Validation Done: [45056/84203]
Validation Done: [45184/84203]
Validation Done: [45312/84203]
Validation Done: [45440/84203]
Validation Done: [45568/84203]
Validation Done: [45696/84203]
Validation Done: [45824/84203]
Validation Done: [45952/84203]
Validation Done: [46080/84203]
Validation Done: [46208/84203]
Validation Done: [46336/84203]
Validation Done: [46464/84203]
Validation Done: [46592/84203]
Validation Done: [46720/84203]
Validation Done: [46848/84203]
Validation Done: [46976/84203]
Validation Done: [47104/84203]
Validation Done: [47232/84203]
Validation Done: [47360/84203]
Validation Done: [47488/84203]
Validation Done: [47616/84203]
Validation Done: [47744/84203]
Validation Done: [47872/84203]
Validation Done: [48000/84203]
Validation Done: [48128/84203]
Validation Done: [48256/84203]
Validation Done: [48384/84203]
Validation Done: [48512/84203]
Validation Done: [48640/84203]
Validation Done: [48768/84203]
Validation Done: [48896/84203]
Validation Done: [49024/84203]
Validation Done: [49152/84203]
Validation Done: [49280/84203]
Validation Done: [49408/84203]
Validation Done: [49536/84203]
Validation Done: [49664/84203]
Validation Done: [49792/84203]
Validation Done: [49920/84203]
Validation Done: [50048/84203]
Validation Done: [50176/84203]
Validation Done: [50304/84203]
Validation Done: [50432/84203]
Validation Done: [50560/84203]
Validation Done: [50688/84203]
Validation Done: [50816/84203]
Validation Done: [50944/84203]
Validation Done: [51072/84203]
Validation Done: [51200/84203]
Validation Done: [51328/84203]
Validation Done: [51456/84203]
Validation Done: [51584/84203]
Validation Done: [51712/84203]
Validation Done: [51840/84203]
Validation Done: [51968/84203]
Validation Done: [52096/84203]
Validation Done: [52224/84203]
Validation Done: [52352/84203]
Validation Done: [52480/84203]
Validation Done: [52608/84203]
Validation Done: [52736/84203]
Validation Done: [52864/84203]
Validation Done: [52992/84203]
Validation Done: [53120/84203]
Validation Done: [53248/84203]
Validation Done: [53376/84203]
Validation Done: [53504/84203]
Validation Done: [53632/84203]
Validation Done: [53760/84203]
Validation Done: [53888/84203]
Validation Done: [54016/84203]
Validation Done: [54144/84203]
Validation Done: [54272/84203]
Validation Done: [54400/84203]
Validation Done: [54528/84203]
Validation Done: [54656/84203]
Validation Done: [54784/84203]
Validation Done: [54912/84203]
Validation Done: [55040/84203]
Validation Done: [55168/84203]
Validation Done: [55296/84203]
Validation Done: [55424/84203]
Validation Done: [55552/84203]
Validation Done: [55680/84203]
Validation Done: [55808/84203]
Validation Done: [55936/84203]
Validation Done: [56064/84203]
Validation Done: [56192/84203]
Validation Done: [56320/84203]
Validation Done: [56448/84203]
Validation Done: [56576/84203]
Validation Done: [56704/84203]
Validation Done: [56832/84203]
Validation Done: [56960/84203]
Validation Done: [57088/84203]
Validation Done: [57216/84203]
Validation Done: [57344/84203]
Validation Done: [57472/84203]
Validation Done: [57600/84203]
Validation Done: [57728/84203]
Validation Done: [57856/84203]
Validation Done: [57984/84203]
Validation Done: [58112/84203]
Validation Done: [58240/84203]
Validation Done: [58368/84203]
Validation Done: [58496/84203]
Validation Done: [58624/84203]
Validation Done: [58752/84203]
Validation Done: [58880/84203]
Validation Done: [59008/84203]
Validation Done: [59136/84203]
Validation Done: [59264/84203]
Validation Done: [59392/84203]
Validation Done: [59520/84203]
Validation Done: [59648/84203]
Validation Done: [59776/84203]
Validation Done: [59904/84203]
Validation Done: [60032/84203]
Validation Done: [60160/84203]
Validation Done: [60288/84203]
Validation Done: [60416/84203]
Validation Done: [60544/84203]
Validation Done: [60672/84203]
Validation Done: [60800/84203]
Validation Done: [60928/84203]
Validation Done: [61056/84203]
Validation Done: [61184/84203]
Validation Done: [61312/84203]
Validation Done: [61440/84203]
Validation Done: [61568/84203]
Validation Done: [61696/84203]
Validation Done: [61824/84203]
Validation Done: [61952/84203]
Validation Done: [62080/84203]
Validation Done: [62208/84203]
Validation Done: [62336/84203]
Validation Done: [62464/84203]
Validation Done: [62592/84203]
Validation Done: [62720/84203]
Validation Done: [62848/84203]
Validation Done: [62976/84203]
Validation Done: [63104/84203]
Validation Done: [63232/84203]
Validation Done: [63360/84203]
Validation Done: [63488/84203]
Validation Done: [63616/84203]
Validation Done: [63744/84203]
Validation Done: [63872/84203]
Validation Done: [64000/84203]
Validation Done: [64128/84203]
Validation Done: [64256/84203]
Validation Done: [64384/84203]
Validation Done: [64512/84203]
Validation Done: [64640/84203]
Validation Done: [64768/84203]
Validation Done: [64896/84203]
Validation Done: [65024/84203]
Validation Done: [65152/84203]
Validation Done: [65280/84203]
Validation Done: [65408/84203]
Validation Done: [65536/84203]
Validation Done: [65664/84203]
Validation Done: [65792/84203]
Validation Done: [65920/84203]
Validation Done: [66048/84203]
Validation Done: [66176/84203]
Validation Done: [66304/84203]
Validation Done: [66432/84203]
Validation Done: [66560/84203]
Validation Done: [66688/84203]
Validation Done: [66816/84203]
Validation Done: [66944/84203]
Validation Done: [67072/84203]
Validation Done: [67200/84203]
Validation Done: [67328/84203]
Validation Done: [67456/84203]
Validation Done: [67584/84203]
Validation Done: [67712/84203]
Validation Done: [67840/84203]
Validation Done: [67968/84203]
Validation Done: [68096/84203]
Validation Done: [68224/84203]
Validation Done: [68352/84203]
Validation Done: [68480/84203]
Validation Done: [68608/84203]
Validation Done: [68736/84203]
Validation Done: [68864/84203]
Validation Done: [68992/84203]
Validation Done: [69120/84203]
Validation Done: [69248/84203]
Validation Done: [69376/84203]
Validation Done: [69504/84203]
Validation Done: [69632/84203]
Validation Done: [69760/84203]
Validation Done: [69888/84203]
Validation Done: [70016/84203]
Validation Done: [70144/84203]
Validation Done: [70272/84203]
Validation Done: [70400/84203]
Validation Done: [70528/84203]
Validation Done: [70656/84203]
Validation Done: [70784/84203]
Validation Done: [70912/84203]
Validation Done: [71040/84203]
Validation Done: [71168/84203]
Validation Done: [71296/84203]
Validation Done: [71424/84203]
Validation Done: [71552/84203]
Validation Done: [71680/84203]
Validation Done: [71808/84203]
Validation Done: [71936/84203]
Validation Done: [72064/84203]
Validation Done: [72192/84203]
Validation Done: [72320/84203]
Validation Done: [72448/84203]
Validation Done: [72576/84203]
Validation Done: [72704/84203]
Validation Done: [72832/84203]
Validation Done: [72960/84203]
Validation Done: [73088/84203]
Validation Done: [73216/84203]
Validation Done: [73344/84203]
Validation Done: [73472/84203]
Validation Done: [73600/84203]
Validation Done: [73728/84203]
Validation Done: [73856/84203]
Validation Done: [73984/84203]
Validation Done: [74112/84203]
Validation Done: [74240/84203]
Validation Done: [74368/84203]
Validation Done: [74496/84203]
Validation Done: [74624/84203]
Validation Done: [74752/84203]
Validation Done: [74880/84203]
Validation Done: [75008/84203]
Validation Done: [75136/84203]
Validation Done: [75264/84203]
Validation Done: [75392/84203]
Validation Done: [75520/84203]
Validation Done: [75648/84203]
Validation Done: [75776/84203]
Validation Done: [75904/84203]
Validation Done: [76032/84203]
Validation Done: [76160/84203]
Validation Done: [76288/84203]
Validation Done: [76416/84203]
Validation Done: [76544/84203]
Validation Done: [76672/84203]
Validation Done: [76800/84203]
Validation Done: [76928/84203]
Validation Done: [77056/84203]
Validation Done: [77184/84203]
Validation Done: [77312/84203]
Validation Done: [77440/84203]
Validation Done: [77568/84203]
Validation Done: [77696/84203]
Validation Done: [77824/84203]
Validation Done: [77952/84203]
Validation Done: [78080/84203]
Validation Done: [78208/84203]
Validation Done: [78336/84203]
Validation Done: [78464/84203]
Validation Done: [78592/84203]
Validation Done: [78720/84203]
Validation Done: [78848/84203]
Validation Done: [78976/84203]
Validation Done: [79104/84203]
Validation Done: [79232/84203]
Validation Done: [79360/84203]
Validation Done: [79488/84203]
Validation Done: [79616/84203]
Validation Done: [79744/84203]
Validation Done: [79872/84203]
Validation Done: [80000/84203]
Validation Done: [80128/84203]
Validation Done: [80256/84203]
Validation Done: [80384/84203]
Validation Done: [80512/84203]
Validation Done: [80640/84203]
Validation Done: [80768/84203]
Validation Done: [80896/84203]
Validation Done: [81024/84203]
Validation Done: [81152/84203]
Validation Done: [81280/84203]
Validation Done: [81408/84203]
Validation Done: [81536/84203]
Validation Done: [81664/84203]
Validation Done: [81792/84203]
Validation Done: [81920/84203]
Validation Done: [82048/84203]
Validation Done: [82176/84203]
Validation Done: [82304/84203]
Validation Done: [82432/84203]
Validation Done: [82560/84203]
Validation Done: [82688/84203]
Validation Done: [82816/84203]
Validation Done: [82944/84203]
Validation Done: [83072/84203]
Validation Done: [83200/84203]
Validation Done: [83328/84203]
Validation Done: [83456/84203]
Validation Done: [83584/84203]
Validation Done: [83712/84203]
Validation Done: [83840/84203]
Validation Done: [83968/84203]
Validation Done: [84096/84203]
Validation Done: [70406/84203]
[Test] Epoch: 5 Test set: Average loss: 0.0020, Accuracy: 75574/84203 (89.75%)
{'accuracy': 0.897521465981022, 'normal': {'precision': 0.8911250149444068, 'recall': 0.7913157335975652, 'support': 28258, 'f1-score': 0.8382598264324942}, 'macro avg': {'precision': 0.8956809307508364, 'recall': 0.8712410288329233, 'support': 84203, 'f1-score': 0.8816304564347078}, 'cancer': {'precision': 0.9002368465572661, 'recall': 0.9511663240682814, 'support': 55945, 'f1-score': 0.9250010864369215}, 'weighted avg': {'precision': 0.8971789728744262, 'recall': 0.897521465981022, 'support': 84203, 'f1-score': 0.8958912622595749}}
[Train] Epoch: 6 [128/387873]    Loss: 0.001973   Batch Acc: 92.97
[Train] Epoch: 6 [256/387873]    Loss: 0.001313   Batch Acc: 95.31
[Train] Epoch: 6 [384/387873]    Loss: 0.001849   Batch Acc: 89.84
[Train] Epoch: 6 [512/387873]    Loss: 0.001602   Batch Acc: 94.53
[Train] Epoch: 6 [640/387873]    Loss: 0.002080   Batch Acc: 89.84
[Train] Epoch: 6 [768/387873]    Loss: 0.002256   Batch Acc: 85.16
[Train] Epoch: 6 [896/387873]    Loss: 0.001784   Batch Acc: 89.06
[Train] Epoch: 6 [1024/387873]    Loss: 0.002067   Batch Acc: 89.84
[Train] Epoch: 6 [1152/387873]    Loss: 0.002423   Batch Acc: 85.94
[Train] Epoch: 6 [1280/387873]    Loss: 0.001405   Batch Acc: 95.31
[Train] Epoch: 6 [1408/387873]    Loss: 0.001715   Batch Acc: 93.75
[Train] Epoch: 6 [1536/387873]    Loss: 0.001977   Batch Acc: 89.06
[Train] Epoch: 6 [1664/387873]    Loss: 0.002083   Batch Acc: 87.50
[Train] Epoch: 6 [1792/387873]    Loss: 0.001947   Batch Acc: 87.50
[Train] Epoch: 6 [1920/387873]    Loss: 0.002689   Batch Acc: 85.94
[Train] Epoch: 6 [2048/387873]    Loss: 0.002122   Batch Acc: 87.50
[Train] Epoch: 6 [2176/387873]    Loss: 0.001746   Batch Acc: 91.41
[Train] Epoch: 6 [2304/387873]    Loss: 0.001547   Batch Acc: 92.19
[Train] Epoch: 6 [2432/387873]    Loss: 0.001554   Batch Acc: 92.97
[Train] Epoch: 6 [2560/387873]    Loss: 0.002406   Batch Acc: 85.16
[Train] Epoch: 6 [2688/387873]    Loss: 0.002016   Batch Acc: 87.50
[Train] Epoch: 6 [2816/387873]    Loss: 0.002557   Batch Acc: 85.16
[Train] Epoch: 6 [2944/387873]    Loss: 0.002446   Batch Acc: 85.94
[Train] Epoch: 6 [3072/387873]    Loss: 0.002163   Batch Acc: 90.62
[Train] Epoch: 6 [3200/387873]    Loss: 0.002244   Batch Acc: 85.94
[Train] Epoch: 6 [3328/387873]    Loss: 0.001878   Batch Acc: 91.41
[Train] Epoch: 6 [3456/387873]    Loss: 0.002399   Batch Acc: 83.59
[Train] Epoch: 6 [3584/387873]    Loss: 0.001718   Batch Acc: 89.84
[Train] Epoch: 6 [3712/387873]    Loss: 0.001873   Batch Acc: 89.06
[Train] Epoch: 6 [3840/387873]    Loss: 0.001839   Batch Acc: 89.84
[Train] Epoch: 6 [3968/387873]    Loss: 0.001897   Batch Acc: 90.62
[Train] Epoch: 6 [4096/387873]    Loss: 0.001862   Batch Acc: 90.62
[Train] Epoch: 6 [4224/387873]    Loss: 0.001749   Batch Acc: 90.62
[Train] Epoch: 6 [4352/387873]    Loss: 0.002311   Batch Acc: 87.50
[Train] Epoch: 6 [4480/387873]    Loss: 0.001763   Batch Acc: 89.84
[Train] Epoch: 6 [4608/387873]    Loss: 0.001682   Batch Acc: 92.19
[Train] Epoch: 6 [4736/387873]    Loss: 0.002001   Batch Acc: 87.50
[Train] Epoch: 6 [4864/387873]    Loss: 0.001769   Batch Acc: 92.97
[Train] Epoch: 6 [4992/387873]    Loss: 0.001624   Batch Acc: 89.84
[Train] Epoch: 6 [5120/387873]    Loss: 0.001882   Batch Acc: 86.72
[Train] Epoch: 6 [5248/387873]    Loss: 0.002552   Batch Acc: 85.94
[Train] Epoch: 6 [5376/387873]    Loss: 0.001708   Batch Acc: 92.97
[Train] Epoch: 6 [5504/387873]    Loss: 0.001405   Batch Acc: 94.53
[Train] Epoch: 6 [5632/387873]    Loss: 0.002329   Batch Acc: 89.06
[Train] Epoch: 6 [5760/387873]    Loss: 0.001827   Batch Acc: 92.19
[Train] Epoch: 6 [5888/387873]    Loss: 0.001624   Batch Acc: 92.19
[Train] Epoch: 6 [6016/387873]    Loss: 0.002110   Batch Acc: 87.50
